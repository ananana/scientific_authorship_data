<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:27+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dependency parsing with latent refinements of part-of-speech tags</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Müller</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Farkas</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Szeged</orgName>
								<address>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Judea</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Heidelberg Institute for Theoretical Studies</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Center for Information and Language Processing</orgName>
								<orgName type="institution">University of Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dependency parsing with latent refinements of part-of-speech tags</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="963" to="967"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper we propose a method to increase dependency parser performance without using additional labeled or unla-beled data by refining the layer of predicted part-of-speech (POS) tags. We perform experiments on English and Ger-man and show significant improvements for both languages. The refinement is based on generative split-merge training for Hidden Markov models (HMMs).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Probabilistic Context-free Grammars with latent annotations (PCFG-LA) have been shown ( <ref type="bibr" target="#b5">Petrov et al., 2006</ref>) to yield phrase structure parsers with state-of-the-art accuracy. While Hidden Markov Models with latent annotations (HMM- LA) <ref type="bibr" target="#b3">(Huang et al., 2009)</ref>, stay somewhat behind the performance of state-of-the-art discriminative taggers <ref type="bibr" target="#b1">(Eidelman et al., 2010)</ref>. In this paper we address the question of whether the resulting la- tent POS tags are linguistically meaningful and useful for upstream tasks such as syntactic pars- ing. We find that this is indeed the case, lead- ing to a procedure that significantly increases the performance of dependency parsers. The proce- dure is attractive because the refinement of pre- dicted part-of-speech sequences using a coarse-to- fine strategy <ref type="bibr" target="#b4">(Petrov and Klein, 2007</ref>) is fast and efficient. More precisely, we show that incorpo- rating the induced POS into a state-of-the-art de- pendency parser <ref type="bibr" target="#b0">(Bohnet, 2010)</ref> gives increases in Labeled Attachment Score (LAS): from 90.34 to 90.57 for English and from 87.92 to 88.24 (resp. 88.35 to 88.51) for German without using (resp. with using) morphological features. <ref type="bibr" target="#b5">Petrov et al. (2006)</ref> introduce generative split- merge training for PCFGs and provide a fully au- tomatic method for training state-of-the-art phrase structure parsers. They argue that the resulting la- tent annotations are linguistically meaningful. <ref type="bibr" target="#b7">Sun et al. (2008)</ref> induce latent sub-states into CRFs and show that noun phrase (NP) recognition can be im- proved, especially if no part-of-speech features are available. <ref type="bibr" target="#b3">Huang et al. (2009)</ref> apply split-merge training to create HMMs with latent annotations (HMM-LA) for Chinese POS tagging. They re- port that the method outperforms standard gener- ative bigram and trigram tagging, but do not com- pare to discriminative methods. <ref type="bibr" target="#b1">Eidelman et al. (2010)</ref> show that a bidirectional variant of latent HMMs with incorporation of prosodic information can yield state-of-the-art results in POS tagging of conversational speech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Split-Merge Training for HMMs</head><p>Split-merge training for HMMs ( <ref type="bibr" target="#b3">Huang et al., 2009</ref>) iteratively splits every tag into two subtags. Word emission and tag transition probabilities of subtags are then initialized close to the values of the parent tags but with some randomness to break symmetry. Using expectation-maximization (EM) training the parameters can then be set to a local maximum of the training data likelihood. After this split phase, the merge phase reverts splits that only lead to small improvements in the likelihood function in order to increase the robustness of the model. This approach requires an approximation of the gain in likelihood of every split analogous to <ref type="bibr" target="#b5">Petrov et al. (2006)</ref> as an exact computation is not feasible.</p><p>We have observed that this procedure is not Universal Tag <ref type="table">Table 1</ref>: Induced sub-tags and their statistics, word forms (p(w|t)), treebank tag (p(b|t)) and preceding Universal tag probability (p(u|t)). Bold: linguistically interesting differences.</p><formula xml:id="formula_0">Feature Tag 0 Tag 1 English Adjectives p(w|t) more (0.05) many (0.03) last (0.03) new (0.03) other (0.03) first (0.02) (ADJ) p(u|t) VERB (0.32) ADV (0.27) NOUN (0.14) DET (0.39) ADP (0.17) ADJ (0.10) Particles p(w|t) 's (0.93) ' (0.07) to (0.89) up (0.04) out (0.02) off (0.01) (PRT) p(b|t) POS (1.00) TO (0.89) RP (0.10) Prepositions p(w|t) that (0.11) in (0.10) by (0.09) of (0.43) in (0.19) for (0.11) (ADP) p(u|t) VERB (0.46) NOUN (0.15) . (0.13) NOUN (0.84) NUM (0.06) ADJ (0.03) Pronouns p(w|t) its (0.30) their (0.15) his (0.14) it (0.21) he (0.16) they (0.12) (PRON) p(b|t) PRP$ (0.68) PRP (0.26) WP (0.05) PRP (0.87) WP (0.11) PRP$ (0.02) Verbs p(w|t) be (0.06) been (0.02) have (0.02) is (0.10) said (0.08) was (0.05) (VERB) p(u|t) VERB (0.38) PRT (0.22) ADV (0.11) NOUN (0.52) PRON (0.20) . (0.12) German Conjunctions p(w|t) daß (0.26) wenn (0.08) um (0.06) und (0.76) oder (0.07) als (0.06) (CONJ) p(b|t) KOUS (0.58) KON (0.30) KOUI (0.06) KON (0.88) KOKOM (0.10) APPR (0.02) Particles p(w|t) an (0.13) aus (0.10) ab (0.09) nicht (0.49) zu (0.46) Nicht (0.01) (PRT) p(b|t) PTKVZ (0.92) ADV (0.04) ADJD (0.01) PTKNEG (0.52) PTKZU (0.44) PTKA (0.02) Pronouns p(w|t) sich (0.13) die (0.08) es (0.07) ihre (0.06) seine (0.05) seiner (0.05) (PRON) p(b|t) PPER (0.33) PRF (0.14) PRELS (0.14) PPOSAT (0.40) PIAT (0.34) PDAT (0.16) Verbs p(w|t) werden (0.04) worden (0.02) ist (0.02) ist (0.07) hat (0.04) sind (0.03) (VERB) p(u|t) NOUN (0.46) VERB (0.22) PRT (0.10) NOUN (0.49) . (0.19) PRON (0.16)</formula><p>only a way to increase HMM tagger performance but also yields annotations that are to a consid- erable extent linguistically interpretable. As an example we discuss some splits that occurred af- ter a particular split-merge step for English and German. For the sake of comparability we ap- plied the split to the Universal Tagset (Petrov et al., 2011). <ref type="table">Table 1</ref> shows the statistics used for this analysis. The Universal POS tag set puts the three Penn-Treebank tags RP (particle), POS (pos- sessive marker) and TO into one particle tag (see "PRT" in English part of the table). The training essentially reverses this by splitting particles first into possessive and non-possessive markers and in a subsequent split the non-possessives into TO and particles. For German we have a similar split into verb particles, negation particles like nicht 'not' and the infinitive marker zu 'to' ("PRT") in the German part of the table). English prepositions get split by proximity to verbs or nouns ("ADP"). Subordinate conjunctions like that, which in the Penn-Treebank annotation are part of the prepo- sition tag IN, get assigned to the sub-class next to verbs. For German we also see a separation of "CONJ" into predominantly subordinate con- junctions (Tag 0) and predominantly coordinating conjunctions (Tag 1). For both languages adjec- tives get split by predicative and attributive use. For English the predicative sub-class also seems to hold rather atypical adjectives like "such" and "last." For English, verbs ("VERB") get split into a predominantly infinite tag (Tag 0) and a predom- inantly finite tag (Tag 1) while for German we get a separation by verb position. In German we get a separation of pronouns ("PRON") into possessive and non-possessive; in English, pronouns get split by predominant usage in subject position (Tag 0) and as possessives (Tag 1).</p><p>Our implementation of HMM-LA has been re- leased under an open-source licence. <ref type="bibr">1</ref> In the next section we evaluate the utility of these annotations for dependency parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dependency Parsing</head><p>In this section we investigate the utility of in- duced POS as features for dependency parsing. We run our experiments on the CoNLL-2009 data sets <ref type="bibr" target="#b2">(Hajič et al., 2009</ref>) for English and German. As a baseline system we use the latest version of the mate-tools parser <ref type="bibr" target="#b0">(Bohnet, 2010)</ref>. <ref type="bibr">3</ref> It was the highest scoring syntactic parser for German and English in the CoNLL 2009 shared task eval- uation. The parser gets automatically annotated lemmas, POS and morphological features as input which are part of the CoNLL-2009 data sets.</p><p>In this experiment we want to examine the ben- efits of tag refinements isolated from the improve- ments caused by using two taggers in parallel, thus we train the HMM-LA on the automatically tagged POS sequences of the training set and use it to add an additional layer of refined POS to the input data of the parser. We do this by calculating the forward-backward charts that are also used in the E-steps during training -in these charts base  <ref type="table">Table 2</ref>: LAS and UAS 1 mean (µ), best value (max) and std. deviation (σ) for the development set for English and German dependency parsing with (feat.) and without morphological features (no feat.).</p><note type="other">#Tags µLAS maxLAS σLAS µUAS maxUAS σUAS English Baseline 88.</note><p>tags of the refined tags are constrained to be iden- tical to the automatically predicted tags. We use 100 EM iterations after each split and merge phase. The percentage of splits reverted in each merge phase is set to .75.</p><p>We integrate the tags by adding one additional feature for every edge: the conjunction of latent tags of the two words connected by the edge. <ref type="table">Table 2</ref> shows results of our experiments. All numbers are averages of five independent runs. For English the smaller models with 58 and 73 tags achieve improvements of ≈.1. The improve- ments for the larger tag sets are ≈.2. The best individual model improves LAS by .3. For the German experiments without morphological fea- tures we get only marginal average improvements for the smallest tag set and improvements of ≈.15 for the bigger tag sets. The average ULA scores for 107 and 134 tags are at the same level as the ULA scores of the baseline with morph. features. The best model improves LAS by .3. For German with morphological features the absolute differ- ences are smaller: The smallest tag set does not improve the parser on average. For the tag set of 107 tags the average improvement is .08. The best model improves LAS by .38. In all experi- ments we see the highest improvements for tag set sizes of roughly the same size (115 for English, 107 for German). While average improvements are low (esp. for German with morphological fea- tures), peak improvements are substantial.</p><p>Running the best English system on the test set gives an improvement in LAS from 90.34 to 90.57; this improvement is significant 4 (p &lt; .02). For German we get an improvement from 87.92 to <ref type="bibr">4</ref> Approx. randomization test <ref type="bibr" target="#b8">(Yeh, 2000</ref>) on LAS scores 88.24 without and from 88.35 to 88.51 with mor- phological features. The difference between the values without morphological features is signifi- cant (p &lt; .05), but the difference between mod- els with morphological features is not (p = .26). However, the difference between the baseline sys- tem with morphological features and the best sys- tem without morphological features is also not sig- nificant (p = .49).</p><p>We can conclude that HMM-LA tags can sig- nificantly improve parsing results. For German we see that HMM-LA tags can substitute morpholog- ical features up to an insignificant difference. We also see that morphological features and HMM- LA seem to be correlated as combining the two gives only insignificant improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Contribution Analysis</head><p>In this section we try to find statistical evidence for why a parser using a fine-grained tag set might outperform a parser based on treebank tags only.</p><p>The results indicate that an induced latent tag set as a whole increases parsing performance. However, not every split made by the HMM-LA seems to be useful for the parser. The scatter plots in <ref type="figure" target="#fig_1">Figure 1</ref> show that there is no strict correlation between tagging accuracy of a model and the re- sulting LAS. This is expected as the latent induc- tion optimizes a tagging objective function, which does not directly translate into better parsing per- formance. An example is lexicalization. Most latent models for English create a subtag for the preposition "of". This is useful for a HMM as "of" is frequent and has a very specific context. A lexi- calized syntactic parser, however, does not benefit from such a tag.   We base the remainder of our analysis on the results of the baseline parser on the English devel- opment set and the results of the best performing latent model. The best performing model has a LAS score of 88.73 vs 88.43 for the baseline, a dif- ference of .3. If we just look at the LAS of words with incorrectly predicted POS we see a difference of 1.49. A look at the data shows that the latent model helps the parser to identify words that might have been annotated incorrectly. As an example consider plural nouns (NNS) and two of their la- tent subtags NNS 1 and NNS 2 and how often they get classified correctly and misclassified as proper nouns (NNPS): </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>We have shown that HMMs with latent anno- tations (HMMLA) can generate latent part-of- speech tagsets are linguistically interpretable and can be used to improve dependency parsing. Our best systems improve an English parser from a LAS of 90.34 to 90.57 and a German parser from 87.92 to 88.24 when not using morphological fea- tures and from 88.35 to 88.51 when using mor- phological features . Our analysis of the parsing results shows that the major reasons for the im- provements are: the separation of POS tags into more and less trustworthy subtags, the creation of POS subtags with higher correlation to certain de- pendency labels and for German a correlation of tags and morphological features such as case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Future Work</head><p>The procedure works well in general. However, not every split is useful for the parser; e.g., as discussed above lexicalization increases HMM ac- curacy, but does not help an already lexicalized parser. We would like to use additional informa- tion (e.g., from the dependency trees) to identify useless splits. The different granularities of the hi- erarchy induced by split-merge training are poten- tially useful. However, the levels of the hierarchy are incomparable: a child tag is in general not a subtag of a parent tag. We think that coupling par- ents and children in the tag hierarchy might be one way to force a consistent hierarchy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Scatter plots of LAS vs tagging accuracy for English (left) and German without (middle) and with (right) morphological features. English tag set sizes are 58 (squares), 73 (diamonds), 92 (triangles), 115 (triangles pointing downwards) and 144 (circles). German tag set sizes are 85 (squares), 107 (diamonds) and 134 (triangles). The dashed lines indicate the baselines.</figDesc></figure>

			<note place="foot" n="1"> https://code.google.com/p/cistern/ 1 Unlabeled Attachment Score 3 We use v3.3 of Bohnet&apos;s graph-based parser.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous reviewers for their comments. The first author is a recipient of the Google Europe Fellowship in Natural Lan-guage Processing, and this research is supported in part by this Google Fellowship and by DFG (grant SFB 732). Most of this work was conducted while the authors worked at the Institute for Natural Lan-guage Processing of the University of Stuttgart.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Very high accuracy and fast dependency parsing is not a contradiction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Lessons learned in part-of-speech tagging of conversational speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Eidelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Antònia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Stěpánek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improving a simple bigram hmm part-of-speech tagger by latent annotation and selftraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Eidelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Improved inference for unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning accurate, compact, and interpretable tree annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Thibaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">1104</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modeling latent-dynamic in shallow parsing: a latent conditional model with improved inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Okanohara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">More accurate tests for the statistical significance of result differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
