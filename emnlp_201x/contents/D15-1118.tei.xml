<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:08+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Automatically Solve Logic Grid Puzzles</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Mitra</surname></persName>
							<email>amitra7@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">SCIDSE Arizona State University</orgName>
								<orgName type="institution" key="instit2">SCIDSE Arizona State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Baral</surname></persName>
							<email>chitta@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">SCIDSE Arizona State University</orgName>
								<orgName type="institution" key="instit2">SCIDSE Arizona State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Automatically Solve Logic Grid Puzzles</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Logic grid puzzle is a genre of logic puzzles in which we are given (in a natural language) a scenario, the object to be deduced and certain clues. The reader has to figure out the solution using the clues provided and some generic domain constraints. In this paper, we present a system , LOGICIA, that takes a logic grid puzzle and the set of elements in the puzzle and tries to solve it by translating it to the knowledge representation and reasoning language of Answer Set Programming (ASP) and then using an ASP solver. The translation to ASP involves extraction of entities and their relations from the clues. For that we use a novel learning based approach which uses varied supervision , including the entities present in a clue and the expected representation of a clue in ASP. Our system, LO-GICIA, learns to automatically translate a clue with 81.11% accuracy and is able to solve 71% of the problems of a corpus. This is the first learning system that can solve logic grid puzzles described in natural language in a fully automated manner. The code and the data will be made publicly available at http://bioai.lab. asu.edu/logicgridpuzzles.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Understanding natural language to solve problems be it algebraic word problems ( <ref type="bibr" target="#b16">Hosseini et al., 2014</ref>) or questions from bi- ology texts <ref type="bibr" target="#b4">(Berant et al., 2014;</ref><ref type="bibr" target="#b17">Kim et al., 2011</ref>), has attracted a lot of research interest over the past few decades. For NLP, these problems are of par- ticular interest as they are concise, yet rich in in- formation. In this paper, we attempt to solve an- other problem of this kind, known as Logic Grid</p><p>Puzzle. Problem.1 shows an example of the same. Puzzle problems in the same spirit as the previ- ously mentioned science problems, do not restrict the vocabulary; they use everyday language and have diverse background stories. The puzzle prob- lems, however, are unique in their requirement of high precision understanding of the text. For a puzzle problem, the solution is never in the text and requires involved reasoning. Moreover, one needs to correctly understand each of the given clues to successfully solve a problem. Another in- teresting property is that only a small core of the world knowledge, noticeably spatial, temporal and knowledge related to numbers, is crucial to solve these problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PROBLEM .1 A LOGIC GRID PUZZLE</head><p>Waterford Spa had a full appoint- ment calendar booked today. Help Janice figure out the schedule by matching each masseuse to her client, and determine the total price for each.</p><p>And the goal is to find out which elements are linked together based on a series of given clues. Each element is used only once. Each puzzle has a unique solution and can be solved using logical reasoning. A logic grid puzzle is called a (n, m)- puzzle if it contains n categories and each category has m elements. For the example in Problem.1, there are three categories, namely clients, prices, masseuses and each category has four elements which are shown in the respective columns. A to- tal of five clues are given in free text and the goal is to find the members of the four tuples, where each tuple shall contain exactly one element from each category such that all the members in a tuple are linked together.</p><p>To solve such a puzzle problem, it is crucial to understand the clues (for example, "Hannah paid more than Teri's client."). Each clue talks about a set of entities (for example, "Hannah", "client", "Terry") and their relations ("a greater-than rela- tion between Hannah and the client of Terry on the basis of payment"). Our system, LOGICIA, learns to discover these entities and the underly- ing semantics of the relations that exist between them. Once the relations are discovered, a pair of Answer Set Programming (ASP) <ref type="bibr" target="#b3">(Baral, 2003)</ref> rules are created. The reasoning module takes these ASP rules as input and finds a group con- figuration that satisfies all the clues. LOGICIA has "knowledge" about a fixed set of predicates which models different relations that hold between enti- ties in a puzzle world. Clues in the puzzle text that are converted into ASP rules, use these predi- cates as building blocks. In this research, our goal is to build a system which can automatically do this conversion and then reason over it to find the solution. The set of predicates that the reasoning model is aware of is not sufficient to represent all logic grid puzzles. The family of logic grid puz- zles is broad and contains variety of clues. Our future work involves dealing with such a diverse set of relations. In this work we assume that the relations in <ref type="table">Table 1</ref> are sufficient to represent the clues. Following are some examples of clues that cannot be modeled using the predicates in <ref type="table">Table 1</ref>.</p><p>• Esther's brother's seat is at one end of the block of seven.</p><p>• The writer of Lifetime Ambition has a first name with more letters than that of the ten- nis star.</p><p>• Edward was two places behind Salim in one of the lines, both being in odd-numbered po- sitions.</p><p>• Performers who finished in the top three places, in no particular order, are Tanya , the person who performed the fox trot, and the one who performed the waltz.</p><p>The rest of the paper is organized as follows: in section 2, we describe the representation of a puzzle problem in ASP and delineate how it helps in reasoning; in section 3, we present our novel method for learning to automatically translate a logic problem described in natural language to its ASP counterpart. In section 4, we describe the re- lated works. In section 5, we discuss the detailed experimental evaluation of our system. Finally, section 6 concludes our paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Puzzle Representation</head><p>Answer Set Programming (ASP) <ref type="bibr" target="#b3">(Baral, 2003;</ref><ref type="bibr" target="#b21">Lifschitz, 1999;</ref><ref type="bibr" target="#b14">Gelfond and Lifschitz, 1991)</ref> has been used to represent a puzzle and reason over it. This choice is facilitated by the two important reasons: 1) non-monotonic reasoning may occur in a puzzle ( <ref type="bibr" target="#b25">Nagy and Allwein, 2004</ref>) and 2) ASP constructs greatly simplify the reasoning module, as we will see in this section. We now briefly de- scribe a part of ASP. Our discussion is informal. For a detailed account of the language, readers are referred to <ref type="bibr" target="#b3">(Baral, 2003</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Answer Set Programming</head><p>An answer set program is a collection of rules of the form,</p><formula xml:id="formula_0">L 0 | ... | L k :-L k+1 , ..., L m , not L m+1 , ..., not L n</formula><p>where each of the L i 's is a literal in the sense of a classical logic. Intuitively, the above rule means that if L k+1 , ..., L m are to be true and if L m+1 , ..., L n can be safely assumed to be false then at least one of L 0 , ..., L k must be true. The left-hand side of an ASP rule is called the head and the right-hand side is called the body. A rule with no head is often referred to as a constraint. A rule with empty body is referred to as a f act and written as,</p><formula xml:id="formula_1">L 0 | L 1 | ... | L k .</formula><p>Example fly(X) :-bird(X), not ab(X). The above program represents the knowledge that "Most birds fly". If we add the following rule (f act) to the program, bird(penguin). the answer set of the program will contain the belief that penguins can fly, {bird(penguin), f ly(penguin)}. However, adding one more fact, 'ab(penguin).', to convey that the penguin is an abnormal bird, will change the belief that the pen- guin can fly and correspondingly the answer set, {bird(penguin), ab(penguin)}, will not contain the fact, f ly(penguin).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choice Rule</head><formula xml:id="formula_2">m {p(X) : q(X)} n : −L 1 , ..., L k , ..., not L n .</formula><p>Rules of this type allow inclusion in the program's answer sets of arbitrary collections S of atoms of the form p(t) such that, m ≤| S |≤ n and if p(t) ∈ S then q(t) belongs to the corresponding answer set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Representing Puzzle Entities</head><p>A (m, n)-puzzle problem contains m categories and n elements in each category. The term 'puz- zle entity' is used to refer to any of them. Each category is assigned an unique index, denoted by the predicate cindex/1 (the number after the '/' denotes the arity of the predicate). The predicate etype/2 captures this association. Each element is represented, by the element/2 predicate which connects a category index to its element. The pred- icate eindex/1, denotes the tuple indices. The fol- lowing blocks of code shows the representation of the entities for the puzzle in Problem.1.</p><formula xml:id="formula_3">cindex(1...3). eindex(1...4).</formula><p>etype(1,clients). etype(2,prices). etype(3,masseuses). element(1,aimee;;1,ginger). element(1,freda;;1,hannah). element(2,150;;2,160). element(2,170;;2,180). element(3,lynda;;3,nancy). element(3,teri;;3,whitney).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Representing Solution</head><p>Solution to a logic grid puzzle is a set of tu- ples containing related elements. The tuple/3 predicate captures this tuple membership infor- mation of the elements. For example, the fact, tuple(2, 1, aimee), states that the element aimee from the category with index 1 is in the tuple 2. The rel/m predicate captures all the elements in a tuple for a (m, n)-puzzle and is defined using the tuple/3 predicate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Domain Constraints</head><p>In the proposed approach, the logic grid puzzle problem is solved as a constraint satisfaction prob- lem. Given a puzzle problem the goal is to enu- merate over all possible configurations of tuple/3, and select the one which does not violate the con- straints specified in the clues. However, 1) each tuple in a logic grid puzzle will contain exactly one element from each category and 2) an element will belong to exactly one tuple. These constraints come from the specification of a puzzle problem and will hold irrespective of the problem instance.  %domain constraint#2 :-tuple(G1,Cat,Elem), tuple(G2,Cat,Elem), G1!=G2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Representing clues</head><p>Each clue describes some entities and the relations that hold between them. In its simplest form, the relations will suggest if the entities are linked to- gether or not. However, the underlying semantics of such relations can be deep such as the one in clue 5 of Problem.1. There are different ways to express the same relation that holds between en- tities. For example, in Problem.1, the possessive relation has been used to express the linking be- tween clients and masseuses; and the word paid expresses the linking between the clients and the prices. Depending on the puzzles the phrases that are used to express the relations will vary and it is crucial to identify their underlying semantics to solve the problems in systematic way.</p><p>In the current version, the reasoning module has knowledge of a selected set of relations and the translation module tries to represent the clue as a conjunction of these relations. All these relations and their underlying meanings are described in ta- ble 1. In this subsection, we describe the represen- tation of a clue in terms of these relations in ASP and show how it is used by the reasoning module. In the next section, we present our approach to au- tomate this translation.</p><p>Let us consider the clues and their representa- tion from Problem.1:</p><p>[1] Hannah paid more than Teri's client.</p><formula xml:id="formula_4">clue1 :- greaterThan(hannah,1,X,1,2), sameTuple(X,1,teri,3). :-not clue1.</formula><p>The first rule clue1 evaluates to true (will be in the answer set) if the element from category 1 with value hannah is linked to some element from cat- egory 2 which has a higher value than the element from its own category which is linked to an ele- ment from category 1 which is linked to teri from category 3. Since the desired solution must sat- isfy the relations described in the clue, the second ASP rule is added. A rule of this form that does not have a head is known as a constraint and the program must satisfy it to have an answer set. As the reasoning module enumerates over all possi- ble configurations, in some cases the clue1 will not hold and subsequently those branches will be pruned. Similar constraints will be added for all clues. In the below, we show some more exam- ples. A configuration which satisfies all the clue constraints and the domain constraints described in the previous section, will be accepted as the so- lution to the puzzle.</p><p>[2] Nancy's client, Hannah and Ginger were all different clients. clue4 :- diffTuple(hannah,1,ginger,1), diffTuple(hannah,1,X,1), diffTuple(X,1,ginger,1), sameTuple(X,1,nancy,3). :-not clue4.</p><p>[3] Hannah was either the person who paid $180 or Lynda's client. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Learning Translation</head><p>To automate the translation of a clue to the pair of ASP rules, the translation module needs to identify the entities that are present in the clue, their category and their value; and the underly- ing interpretations of all the relations that hold between them. Once all the relation instances {R 1 (arg 1 , ..., arg p 1 ),..., R q (arg 1 , ..., arg pq )} , in the clue are identified, the ASP representation of the clue is generated in the following way:</p><formula xml:id="formula_5">clue : −R 1 (arg 1 ..., arg p 1 ), ..., R q (arg 1 ..., arg pq )</formula><p>The entity classification problem for logic grid puzzles poses several challenges. First, the exis- tence of a wide variety in the set of entities. Enti- ties can be names of objects, time related to some event, numbers, dates, currency, some form of ID etc. And it is not necessary that the entities in puz- zles are nouns. It can be verbs, adjectives etc. Sec- ond and of paramount important, the "category" of a puzzle "element" is specific to a puzzle prob- lem. Same element may have different category in different problems. Also, a constituent in a clue which refers to an entity in a particular prob- lem may not refer to an entity in another problem. We formalize this problem in this section and pro- pose one approach to solve the problem. Next, we discuss the method that is used to extract re- lations from clues. To the best of our knowledge, this type of entity classification problem has never been studied before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation</head><p>Interpretation sameTuple(E1, C1, E2, C2)</p><p>States that two elements, (C1,E1) and (C2,E2) are in the same tuple. The dictionary also contains the nega- tion of it, diffTuple(E1, C1, E2, C2). referrent(E1, C1, E2, C2)</p><p>States that the elements are identical. posDiff (E1, C1, E2, C2, N1, NC1) If (C1,E1) is related to (NC1,X1) and (E2,C2) is re- lated to (NC1,X2), then difference(X1,X2)=N1. Sim- ilarly the dictionary contains the predicate negDiff. greaterThan(E1, C1, E2, C2, NC1) Similar to posDiff however the difference(X1,X2) &gt; 0. The dictionary also contains its opposite predicate lessThan. members(E1, C1, E2, C2,..., EN, CN)</p><p>All the elements are distinct and do not share a tuple. eitherOr <ref type="figure" target="#fig_3">(E1, C1, E2, C2,..., EN, CN)</ref> The first element is related to one of the last N − 1 elements. The last N − 1 elements are assumed to be different unless contradicts with other beliefs. referrent22(E1, C1, E2, C2, E3, C3, E4, C4) The first two elements are different and referring to the last two elements. <ref type="table">Table 1</ref>: Describes the various relations that are part of the reasoning module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Entity Classification</head><p>The entity classification problem is defined as fol- lows:</p><p>Problem description Given m categories C 1 , ..., C m and a text T , each category C i , 1 ≤ i ≤ m, contains a collection of elements E i and an op- tional textual description d i . The goal is to find the class information of all the constituents in the text T . Each category contributes two classes, where one of them represents the category itself and the other represents an instance of that category. Also, a constituent may not refer to any category or any instance of it, in that case the class of that con- stituent is null. So, there are a total 2m+1 classes and a constituent will take one value from them.</p><p>Example In the puzzle of Problem.1, there are 3 categories with, C 1 = {Aimee, Freda, Ginger, Hannah}, C 2 = {$150, $160, $170, $180}, C 3 = {Lynda, Nancy, Terry, Whiteney} and d 1 = "clients", d 2 = "prices", d 3 = "masseuses". The text T , is the concatenation of all clues. In the last clue, there are a total 5 entities, namely "Han- nah", "person", "$180", "Lydia","client" and the corresponding classes are "Instance of C 1 ", "In- stance of C 1 ", "Instance of C 2 ", "Instance of C 3 " and "Instance of C 1 " respectively. The remaining constituents in that clue have the class value null.</p><p>The constituent "clients" in the fourth clue refers to the category C 1 .</p><p>Our approach We model the Entity Classifi- cation problem as a decoding query on Pairwise Markov Network ( <ref type="bibr" target="#b19">Koller and Friedman, 2009;</ref><ref type="bibr" target="#b18">Kindermann et al., 1980;</ref><ref type="bibr" target="#b33">Zhang et al., 2001</ref>). A pairwise Markov network over a graph H, is asso- ciated with a set of node potentials {φ(X i ) : i = 1, ..., n} and a set of edge potentials {φ(X i , X j ) : (X i , X j ) ∈ H}. Each node X i ∈ H, represents a random variable. Here, each X i can take value from the set {1...2m + 1}, denoting the class of the corresponding constituent in the text T .</p><p>In our implementation, the node potential cap- tures the chances of that node to be classified as one of the possible categories without being af- fected by the given text T . And the edge poten- tials captures hints from the context in T for clas- sification. After constructing the pairwise Markov network, a decoding query is issued to obtain the configuration that maximizes the joint probabil- ity distribution of the pairwise Markov network in consideration. The proposed approach is inspired by the following two observations: 1) to find the class of a constituent one needs some background knowledge; 2) however, background knowledge is not sufficient on its own, one also needs to under- stand the text to properly identify the class of each constituent. For example, let us consider the word "person" in clue 5 of Problem.1. Just skimming through the categories, one can discover that the word "person" is very unlikely to be a instance of the category "prices", which is from her knowl- edge about those constituents. However a proper disambiguation may face an issue here as there are two different categories of human beings. To prop- erly classify the word "person" it is necessary to go through the text.</p><p>The following paragraphs describe the con- struction of the grah H, and the algorithm that is used in the computation of associated set of node potentials and edge potentials.</p><p>Construction of the graph While constructing the graph, we assign a label, L, to each edge in H which will be used in the edge potential compu- tation. Let D G denotes the dependency graph of the text T obtained from the Stanford dependency parser ) and dep(v 1 , v 2 ) denotes the grammatical relation between (v 1 , v 2 ) ∈ D G . Then the graph, H, is constructed as fol- lows:</p><p>1. Create a node in H for each constituent w j in</p><formula xml:id="formula_6">T if w j ∈ D G . 2. Add an edge (X i , X j ) to H if the correspond- ing edge (w p , w q ) ∈ D G . L(X i , X j ) := dep(w p , w q ).</formula><p>3. Add an edge between a pair of nodes (X i , X j ) if the corresponding words are syn- onyms. L(X i , X j ) := synonymy.</p><p>4. Create a node for each element and category specified in the puzzle and add an edge from them to others if the corresponding string de- scriptions are 'same'. In this case, the edges are labeled as exact match.</p><p>5. If (X i , X j ) ∈ H and L(X i , X j ) = exact match and both of them are refer- ring to a verb, then add more edges (X i , X j ) to H with label spatial symmetry, where</p><formula xml:id="formula_7">L(X i , X i ) = L(X j , X j )</formula><p>. Determining Node potentials For each element in the m category, a set of naive regular-expression based taggers are used to detect it's type (For ex- ample, "am-pm time"). Each element type maps to a WordNet <ref type="bibr" target="#b23">(Miller, 1995)</ref> representative (For example, "time unit#n"). For each constituent w a similarity score, sim(w,c), is calculated to each class c ∈ {1...2m + 1}, in the following way:</p><p>•Class c is denoting instance of some category C i Similarity scores are computed between the tex- tual description of the constituent to both the WordNet representative of E i and the textual description d i using the HSO WordNet similar- ity algorithm <ref type="bibr" target="#b15">(Hirst and St-Onge, 1998</ref>). The similarity score, sim(w,c), is chosen to be the maximum of them.</p><p>•Class c is denoting a category C i : sim(w,c) is assigned the value of HSO Similarity between the textual description and d i .</p><p>•Class c is null : In this case similarity is calcu- lated using the following formula:</p><formula xml:id="formula_8">sim(w, null) = M AX HSO − max c =null sim(w, c)</formula><p>where M AX HSO denotes the maximum similar- ity score returned by HSO algorithm, which is 16.</p><p>Node potential for each node X i ∈ H, corre- sponding to the constituent w j , are then calculated by,</p><formula xml:id="formula_9">φ(X i = c) = 1 + sim(w j , c), ∀c</formula><p>Determining Edge potentials For each edge in the graph H, the edge potential, φ(X i , X j ) is cal- culated using the following formula,</p><formula xml:id="formula_10">φ(X i = c 1 , X j = c 2 ) = 1 + P (X i = X j |L(X i , X j )), if c 1 = c 2 P (X i = X j |L(X i , X j )), otherwise</formula><p>In the training phase, each entity in a clue is tagged with its respective class. The probability values are then calculated from the training dataset using simple count.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning To Extract Relations</head><p>The goal here is to identify all the relations R(arg 1 , ..., arg p ) that are present in a clue, where each relation belongs to the logical vocabulary described in <ref type="table">Table 1</ref> . This problem is known as Complex relation extraction <ref type="bibr" target="#b22">(McDonald et al., 2005;</ref><ref type="bibr" target="#b1">Bach and Badaskar, 2007;</ref><ref type="bibr" target="#b12">Fundel et al., 2007;</ref><ref type="bibr" target="#b35">Zhou et al., 2014</ref>). The common approach for solving the Complex relation extraction prob- lem is to first find the relation between each pair of entities and then discover the complex relations from binary ones using the definition of each rela- tion. <ref type="figure" target="#fig_3">Figure 1</ref> depicts the scenario. The goal is to identify the relation possDif f (E1, E2, E3), where E1, E2, E3 are constituents having a non- null class value. However instead of identifying posDif f (E1, E2, E3) directly, first the relation between each pair of entities will be identified. If the relations {posDif f arg 1 −arg 2 (E 1 , E 2 ), posDif f arg 2 −arg 3 (E 2 , E 3 ), posDif f arg 1 −arg 3 (E 1 ,E 3 ) } are identified, the extraction module will infer that posDif f (E1, E2, E3) holds. In a similar manner, a set of total 39 binary relations are created for all the relations described in <ref type="table">Table  1</ref>.</p><p>In the training phase, all the relations and their respective arguments in each clue are given. Using this supervision, we have built a Maxi- mum Entropy based model <ref type="bibr" target="#b5">(Berger et al., 1996;</ref><ref type="bibr" target="#b11">Della Pietra et al., 1997)</ref> to classify the relation between a pair of entities present in a clue. Max- imum entropy classifier has been successfully ap- plied in many natural language processing appli- cations <ref type="bibr" target="#b7">(Charniak, 2000;</ref><ref type="bibr" target="#b9">Chieu and Ng, 2002;</ref><ref type="bibr">Ratnaparkhi and others, 1996)</ref> and allows the in- clusion of various sources of information without necessarily assuming any independence between the features. In this model, the conditional proba- bility distribution is given by:</p><formula xml:id="formula_11">P (c|d) = j=1...K e λ i f i (d,c) c ∈C j=1...K e λ i f i (d,c )<label>(1)</label></formula><p>where the denominator is the normalization term and the parameter λ i correspond to the weight for the feature f i . Features in Maximum Entropy model are functions from context and classes to the set of real numbers. A detailed description of the model or parameter estimation method used -Generalized Iterative Scaling, can be found at <ref type="bibr" target="#b10">(Darroch and Ratcliff, 1972)</ref>. <ref type="table">Table 2</ref> describes the features that are used in the classification task. Here, path(E 1 , E 2 ) de- notes all the words that occur in the path(s) con- <ref type="table">Table 2</ref>: Features used in the classification task</p><note type="other">necting E 1 and E2 in the dependency graph of the clue. Feature Set Class of E 1 and E 2 All the grammatical relations between the words in path(E 1 , E 2 ) All the adjectives and adverbs in path(E 1 , E 2 ). POS tags of all the words in path(E 1 , E 2 ) TypeMatched = [[class of E 1 = class of E 2 ]] IsE 1 Numeric = [[class of E 1 is Numeric ]] IsE 2 Numeric = [[class of E 2 is Numeric ]] All the words that appears in the following grammatical relations advmod, amod, cop, det with the words in path(E 1 , E 2 ). hasNegativeWord = [[ ∃w ∈ path(E 1 , E 2 ) s.t. w has a neg relation starting with it.]]</note><p>The relation between each pair of entities in a clue is the one which maximizes the conditional probability in equation (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Missing Entity</head><p>In the case of comparative relations in <ref type="table">Table 1</ref>, such as greaterT han, the basis of the compar- ison can be hidden. For example, in clue 1 of the example problem, the two entities, "Hannah" and "client" have been compared on the basis of "price", however there is no constituent in the clue which refers to an element from that category. The basis of comparison is hidden in this case and is implied by the word "paid". In the current imple- mentation, the translation module does not handle this case. For puzzles that contain only one cate- gory consisting of numeric elements, the transla- tion module goes with the obvious choice. This is part of our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>There has been a significant amount of work on the representation of puzzle problems in a formal lan- guage <ref type="bibr" target="#b13">(Gelfond and Kahl, 2014;</ref><ref type="bibr" target="#b3">Baral, 2003;</ref><ref type="bibr" target="#b6">Celik et al., 2009</ref>). However, there has not been any work that can automatically solve a logic grid puz- zle. The latest work ( <ref type="bibr" target="#b2">Baral and Dzifcak, 2012)</ref> on this problem, assumes that the entities in a clue are given and the authors manually simplify the sen- tences for translation. Furthermore their represen- tation of logic grid puzzles does not consider the category of a variable in the formal representation i.e. uses element/1 and tuple/2 predicates and thus cannot solve puzzles containing more than one numeric categories.</p><p>In the same work ( <ref type="bibr" target="#b2">Baral and Dzifcak, 2012)</ref>, the authors propose to use a semantic parser to do the translation. This method works well for simple sentences such as "Donna dale does not have green fleece" however it faces several challenges while dealing with real world puzzle sentences. The difficulty arises due to the restrictions enforced in the translation models used by the existing se- mantic parsers. Traditional semantic parsers ( <ref type="bibr" target="#b30">Vo et al., 2015;</ref><ref type="bibr" target="#b32">Zettlemoyer and Collins, 2005</ref>) as- sign meanings to each word in a dictionary and combine the meaning of the words to character- ize the complete sentence. A phrase structure grammar formalism such as Combinatory Cate- gorial <ref type="bibr">Grammar (Steedman and Baldridge, 2011;</ref><ref type="bibr" target="#b30">Vo et al., 2015;</ref><ref type="bibr" target="#b32">Zettlemoyer and Collins, 2005</ref>), Context Free Grammar ( <ref type="bibr" target="#b0">Aho and Ullman, 1972;</ref><ref type="bibr" target="#b31">Wong and Mooney, 2006</ref>), is normally used to ob- tain the way words combine with each other. In the training phase, the semantic parser learns the meanings of words given a corpus of &lt;sentence, meaning&gt; pairs and stores them in a dictionary. During translation, the semantic parser uses those learned meanings to obtain the meaning of the sen- tence. Firstly, for the puzzle problems the mean- ing of the words changes drastically depending on the puzzle. A word may be an entity in one puz- zle, but, in a different problem it might not be an entity or might belong to a different category alto- gether. Thus a learned dictionary may not be use- ful while translating clues in a new puzzle. Sec- ondly, in puzzles relations are normally expressed by phrases. For example, in the clue "The per- son who played at Eden Gardens played for In- dia", the phrases "played at" and "played for" are used to express two different relations. Thus, us- ing a model that assigns meaning to each word may not be suitable here. Finally, it is difficult to identify the participants of a relation with a parse tree generated following a phrase structure gram- mar. For example, consider the parse tree of the clue "The person who trekked for 8 miles started at Bull Creek". Even though, the relation "started at" takes the word 'person' and 'Bull Creek' as its input, it receives the entire phrase "the person who trekked for 8 miles" as its argument along with the other input 'Bull Creek'.</p><p>The entity classification problem studied in this  <ref type="bibr" target="#b24">Nadeau and Sekine, 2007;</ref><ref type="bibr" target="#b34">Zhou and Su, 2002</ref>) and the Word Sense disambiguation <ref type="bibr" target="#b29">(Stevenson and Wilks, 2003;</ref><ref type="bibr" target="#b27">Sanderson, 1994)</ref> task. However, our work has a major difference; in the entity classification problem, the class of an entity varies with the problem and does not belong to a known closed set, whereas for the other two problems the possible classes are pre-specified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Evaluation</head><p>Dataset To evaluate our method we have built a dataset of logic grid puzzles along with their correct solutions. A total of 150 problems are collected from logic-puzzles.org. Out of them 100 problems are fully annotated with the entities and the relations information. The remain- ing 50 puzzles do not have any annotation except their solution. The set of annotated puzzles con- tain a total of 467 clues, 5687 words, 1681 entities and 862 relations. The set of 50 puzzles contain a total of 222 clues with 2604 words.</p><p>Tasks We evaluate LOGICIA on three tasks: 1) puzzle solving; 2) entity classification; and 3) re- lation extraction. We use the percentage of correct answers as the evaluation metric for all the three tasks. In case of a logic grid puzzle solving, an answer is considered correct if it exactly matches the solution of that puzzle.</p><p>Training-Testing Out of the 100 annotated puz- zle problems 50 are used as training samples and remaining 50 puzzles are used in testing. The set of 50 unannotated puzzles are used solely for the task of testing puzzle solving.  <ref type="table">Binary relation classification Relation extraction  Solution  with annotation  with annotation  Yes  No  Yes  No  Total  1766  960  450  50  Correct  1502  922  854  410  365  37  Percentage 85.05%</ref> 96.04% 88.95% 90.90% 81.11% 74% <ref type="table">Table 3</ref>: Accuracy on 50 annotated puzzle problems in the Test set.</p><p>Results <ref type="table">Table 3</ref> &amp; 4 shows the efficacy of our approach in solving logic grid puzzles with the se- lected set of relations. LOGICIA is able to classify the constituents with 85.05% accuracy and is able to solve 71 problems out of the 100 test puzzles. It should be noted that puzzle problems requires precise understanding of the text and to obtain the correct solution of a puzzle problem all the entities and their relations in the puzzle need to be identi- fied. Columns 2 and 3 in <ref type="table">Table 3</ref> compares the per- formance on relation extraction when it is used in conjunction with the entity classification and when it directly uses the annotated entity.</p><p>Puzzle Solving Total Correct Percentage 50 34 68% <ref type="table">Table 4</ref>: Accuracy on unannotated 50 test puzzle problems.</p><p>Error Analysis The errors in entity classifica- tion falls into two major categories. In the first category, more knowledge of similarity is needed than what is currently obtained from the WordNet. Consider for example, the categories are "class number" and "class size" and the constituent is "20 students". Even though the constituent is closer to "class size", standard WordNet based similarity methods are unable to provide such in- formation. In the second category, the WordNet similarity of the constituent to one of the classes is quite high due to their position in the WordNet hierarchy; however with respect to the particular problem the constituent is not an entity. The re- lation extraction task performs fairly well, how- ever the binary relation classification task does not jointly consider the relation between all the enti- ties and because of that if one of the necessary bi- nary relation of a complex relation is misclassified, the extraction of the entire relation gets affected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion &amp; Future Work</head><p>This paper presents a novel approach for solving logic grid puzzle. To the best of our knowledge, this is a novel work with respect to the fact that that it can automatically solve a given logic grid puzzle.</p><p>There are several advantages of our approach. The inclusion of knowledge in terms of a vocab- ulary of relations makes it scalable. For puzzles which make use of a different set of constraints, such as "Lynda sat on an even numbered position", can be easily integrated into the vocabulary and the system can then be trained to identify those relations for new puzzles. Also, the proposed ap- proach separates the representation from reason- ing. The translation module only identifies the re- lation and their arguments; it is not aware of the meaning of those relations. The reasoning mod- ule, on the other hand, knows the definition of each relation and subsequently prunes those possibili- ties when relations appearing in a clue does not hold. This separation of representation from rea- soning allows the system to deal with the complex relations that appear in a clue.</p><p>There are a few practical and theoretical issues which need to be addressed. One of those is up- dating the logical vocabulary in a scalable manner. Logic grid puzzle is a wide family of puzzles and it will require more knowledge of relations than what is currently available. Another challenge that needs to be addressed is the computation of simi- larity between complex concepts such as "size of class" and "20 students". Also, the case of "miss- ing entity" (3.2) needs to be modeled properly. This work is the first step towards further under- standing these important issues.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Following blocks of code show an elegant repre- sentation of these domain constraints in ASP along with the enumeration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Binary representation of the relation possDif f</figDesc><graphic url="image-1.png" coords="7,72.00,62.81,226.77,152.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Parse tree of an example sentence in Combinatory categorial grammar research shares many similarity with Named Entity Recognition (Nadeau and Sekine, 2007; Zhou and Su, 2002) and the Word Sense disambiguation (Stevenson and Wilks, 2003; Sanderson, 1994) task. However, our work has a major difference; in the entity classification problem, the class of an entity varies with the problem and does not belong to a known closed set, whereas for the other two problems the possible classes are pre-specified.</figDesc><graphic url="image-2.png" coords="8,307.28,62.81,226.77,164.69" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank NSF for the DataNet Federation Consor-tium grant OCI-0940841 and ONR for their grant N00014-13-1-0334 for partially supporting this re-search.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The theory of parsing, translation, and compiling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Alfred</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeffrey D Ullman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
			<publisher>PrenticeHall, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A review of relation extraction. Literature review for Language and Statistics II</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Badaskar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Solving puzzles described in english by automated translation to answer set programming and learning how to do that translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Baral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juraj</forename><surname>Dzifcak</surname></persName>
		</author>
		<idno>KR 2012</idno>
	</analytic>
	<monogr>
		<title level="m">Principles of Knowledge Representation and Reasoning: Proceedings of the Thirteenth International Conference</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Knowledge representation, reasoning and declarative problem solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Baral</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Modeling biological processes for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brad</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abby</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vander Linden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP<address><addrLine>Brittany Harding, and Peter Clark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A maximum entropy approach to natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pietra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="71" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Comparing asp and cp on four grid puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehmet</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Halit</forename><surname>Erdogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fırat</forename><surname>Tahaoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tansel</forename><surname>Uras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esra</forename><surname>Erdem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth RCRA International Workshop on Experimental Evaluation of Algorithms for Solving Problems with Combinatorial Explosion (RCRA09). CEUR Workshop Proceedings</title>
		<meeting>the Sixteenth RCRA International Workshop on Experimental Evaluation of Algorithms for Solving Problems with Combinatorial Explosion (RCRA09). CEUR Workshop Proceedings</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A maximum-entropyinspired parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference</title>
		<meeting>the 1st North American chapter of the Association for Computational Linguistics conference</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="132" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A fast and accurate dependency parser using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Named entity recognition: a maximum entropy approach using global information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Leong Chieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on Computational linguistics</title>
		<meeting>the 19th international conference on Computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Generalized iterative scaling for log-linear models. The annals of mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Darroch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ratcliff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
			<biblScope unit="page" from="1470" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Inducing features of random fields. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">Della</forename><surname>Stephen Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="380" to="393" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Relexrelation extraction using dependency parse trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Fundel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Küffner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Zimmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="365" to="371" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Knowledge representation, reasoning, and the design of intelligent agents: The answer-set programming approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gelfond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Kahl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Classical negation in logic programs and disjunctive databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gelfond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Lifschitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New generation computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="365" to="385" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Lexical chains as representations of context for the detection and correction of malapropisms. WordNet: An electronic lexical database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>St-Onge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">305</biblScope>
			<biblScope unit="page" from="305" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to solve arithmetic word problems with verb categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad Javad</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Overview of bionlp shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bossy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngan</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP Shared Task 2011 Workshop</title>
		<meeting>the BioNLP Shared Task 2011 Workshop</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Kindermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Laurie</forename><surname>Snell</surname></persName>
		</author>
		<title level="m">Markov random fields and their applications</title>
		<meeting><address><addrLine>Providence, RI</addrLine></address></meeting>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="1980" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Probabilistic graphical models: principles and techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nir</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to automatically solve algebra word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="271" to="281" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Answer set planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Lifschitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logic Programming and Nonmonotonic Reasoning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="373" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Simple algorithms for complex relation extraction with applications to biomedical ie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Kulick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Winters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pete</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="491" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A survey of named entity recognition and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Nadeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lingvisticae Investigationes</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Diagrams and non-monotonicity in puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benedek</forename><surname>Nagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Allwein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Diagrammatic Representation and Inference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="82" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A maximum entropy model for part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adwait</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Word sense disambiguation and information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 17th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, Inc</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="142" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Combinatory categorial grammar. Non-Transformational Syntax: Formal and Explicit Models of Grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Wiley-Blackwell</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Word sense disambiguation. The Oxford Handbook of Comp. Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yorick</forename><surname>Wilks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="249" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The NL2KR platform for building natural language translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ha</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015-07-26" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="899" to="908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning for semantic parsing with statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics</title>
		<meeting>the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="439" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to Map Sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Segmentation of brain mr images through a hidden markov random field model and the expectation-maximization algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="57" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Named entity recognition using an hmm-based chunk tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 40th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="473" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Biomedical relation extraction: From binary to complex. Computational and mathematical methods in medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayou</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
