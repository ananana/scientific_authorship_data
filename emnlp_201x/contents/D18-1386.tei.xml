<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Extractive Adversarial Networks: High-Recall Explanations for Identifying Personal Attacks in Social Media Posts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Carton</surname></persName>
							<email>scarton@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Michigan</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<orgName type="institution" key="instit3">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
							<email>qmei@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Michigan</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<orgName type="institution" key="instit3">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Resnick</surname></persName>
							<email>presnick@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Michigan</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<orgName type="institution" key="instit3">University of Michigan</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Extractive Adversarial Networks: High-Recall Explanations for Identifying Personal Attacks in Social Media Posts</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3497" to="3507"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3497</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce an adversarial method for producing high-recall explanations of neural text classifier decisions. Building on an existing architecture for extractive explanations via hard attention, we add an adversarial layer which scans the residual of the attention for remaining predictive signal. Motivated by the important domain of detecting personal attacks in social media comments, we additionally demonstrate the importance of manually setting a semantically appropriate &quot;default&quot; behavior for the model by explicitly manipulating its bias term. We develop a validation set of human-annotated personal attacks to evaluate the impact of these changes.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The task of explaining classifier decisions has re- cently attracted increased attention from the re- search community. It is important for several rea- sons, including: 1) The increasing performance gap between simple-and-interpretable models and complex-but-opaque models (which demand more sophisticated explanation techniques); 2) The in- creasing ubiquity of machine learning in busi- ness and government and the concomitant need to understand the decisions of models in high- stakes situations; and 3) A rising awareness of the limitations of machine learning and the need for ways to better utilize intrinsically unreliable mod- els (whose weaknesses can potentially be amelio- rated by good explanations).</p><p>A common way to explain why a model clas- sified an example a certain way is to extract a sparse subset of features that were responsible for the model's decision, sometimes described as a saliency mask or "rationale" in the case of text ( <ref type="bibr" target="#b17">Guidotti et al., 2018)</ref>. This type of local expla- nation may not completely elucidate why a given example is assigned a given outcome, but it does simplify the relationship by identifying what at- tributes were considered in the decision.</p><p>Existing work on this topic has not explicitly ad- dressed the problem of local feature redundancy. That is, when two features are equally predictive of an outcome, which of them should be included in the saliency mask for that decision? Typical sparsity constraints encourage minimal sufficient masks-unveiling just enough of the example to justify the outcome.</p><p>There are domains, however, where it may be important to produce complete explanations rather than minimal explanations. One example is the task of detecting content in online social media that violates a platform's policies. Explanatory models can potentially help human moderators make quicker and more consistent decisions about whether to remove comments ( <ref type="bibr" target="#b22">Lakkaraju et al., 2016)</ref>. However, we propose that truly minimal explanations are liable to give only a partial por- trait of why a comment is objectionable, making it harder to render a fair holistic decision. If used to explain to a poster why their post was removed, a minimal explanation can actually be misleading, by implying that some of what was objectionable about their post was benign just because it didn't add marginal signal to the overall classification.</p><p>We use an extractive explanatory neural net- work to identify which social media comments contain personal attacks and which words in those comments are the basis for classifying them as containing personal attacks. We train this model on a large dataset ( <ref type="bibr" target="#b40">Wulczyn et al., 2017</ref>) of com- ments labeled for the presence of such attacks, and use the explanatory capacity of the model to iden- tify spans that constitute personal attacks within those comments. We extend the work of ( <ref type="bibr" target="#b23">Lei et al., 2016</ref>) in using one recurrent neural net (RNN) to produce an explanatory hard-attention rationale <ref type="figure">Figure 1</ref>: An example of a highly-attacking comment from the test set, rationalized by the model and a second RNN to make a prediction, the two models trained in an end-to-end fashion.</p><p>To produce complete (i.e high-recall) explana- tions, we add to this existing architecture a sec- ond, adversarial predictive layer whose purpose is to try to make predictions based on what is left out of the rationale. We then add a term to the atten- tion layer objective function which encourages it to fool this secondary predictive layer into making poor predictions by including all predictive signal (i.e personal attacks) in the mask that it generates.</p><p>We also show that manipulating the model bias term to set a semantically appropriate "default be- havior" or "null hypothesis" for the model sig- nificantly improves performance. That is, by ex- plicitly choosing what output a zero-information, empty explanation should correspond to, the model is able to learn explanations that correspond more closely with human-generated data.</p><p>To summarize, the contributions of this paper are as follows:</p><p>• We articulate explanation as an adversarial problem and introduce an adversarial scheme for extraction of complete (high-recall) ex- planations for text classifier decisions.</p><p>• We demonstrate the value of explicitly setting a default output value in such an explanatory model via bias term manipulation.</p><p>• We apply explanatory machine learning for the first time to the task of detecting personal attacks in social media comments, and de- velop a validation dataset for this purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work 2.1 Online abuse</head><p>Online abuse (of which personal attacks are a ma- jor dimension) has recently attracted increased at- tention as a computational problem. Scholarly work has assessed the prevalence and impact of such abuse ( <ref type="bibr" target="#b24">Lenhart et al., 2016;</ref><ref type="bibr" target="#b4">Anderson et al., 2014;</ref><ref type="bibr" target="#b32">Pew, 2016;</ref><ref type="bibr" target="#b5">Anderson et al., 2016)</ref>, while several initiatives have sought to construct datasets for its study <ref type="bibr" target="#b40">(Wulczyn et al., 2017;</ref><ref type="bibr" target="#b0">Abbott et al., 2016;</ref><ref type="bibr" target="#b19">Kennedy et al., 2017;</ref><ref type="bibr" target="#b28">Napoles et al., 2017;</ref><ref type="bibr" target="#b15">Golbeck et al., 2017)</ref>. Naturally, much recent work has gone into the use of machine learning to detect online abuse and its perpetrators ( <ref type="bibr" target="#b30">Nobata et al., 2016;</ref><ref type="bibr" target="#b31">Pavlopoulos et al., 2017;</ref><ref type="bibr" target="#b10">Cheng et al., 2015)</ref>, including a work- shop at the most recent ACL conference (Associ- ation for Computational <ref type="bibr">Linguistics, 2017)</ref>. How- ever, the idea of fully-automated moderation by machine learning has attracted criticism as being subject to bias, inaccuracy, manipulation and frus- tration on the user end ( <ref type="bibr" target="#b31">Pavlopoulos et al., 2017;</ref><ref type="bibr" target="#b8">Binns et al., 2017;</ref><ref type="bibr" target="#b9">Blackwell et al., 2018;</ref><ref type="bibr" target="#b18">Hosseini et al., 2017;</ref><ref type="bibr" target="#b1">Adams and Dixon, 2017)</ref>. We propose interpretable models as one potential solution to some of these problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Interpretable machine learning</head><p>Major points of division in the interpretability lit- erature include: 1) local vs. global interpretability; 2) post-hoc vs. built-in interpretability; 3) expla- nation type; 4) input data type; and 5) evaluation metric. Our model is a built-in, feature-based lo- cally interpretable model for text that we evaluate <ref type="figure">Figure 2</ref>: An example of a not-very-attacking example from the test set, rationalized by the model relative to a human gold-standard. <ref type="bibr" target="#b17">Guidotti et al. (2018)</ref> provides a recent survey of the field.</p><p>Recent work on interpretability has focused on local (i.e. instancewise) feature-based ex- planations. Attention models implicitly produce this type of explanation in the form of attention weights over input features. <ref type="bibr" target="#b23">Lei et al. (2016)</ref> uti- lizes a regularized hard attention mechanism to identify the locally minimum sufficient subset of tokens to make accurate predictions.</p><p>Post-hoc methods seek to retroactively probe the behavior of an existing non-explanatory model. These include model-specific gradient- based attribution methods, pioneered by <ref type="bibr" target="#b35">Simonyan et al. (2013)</ref> and reviewed recently by <ref type="bibr" target="#b3">Ancona et al. (2017)</ref>, which have tended to origi- nate in the image classification domain and trans- fer to other domains such as text (e.g. <ref type="bibr" target="#b6">Arras et al. (2017)</ref>). Conversely, LIME ( <ref type="bibr" target="#b33">Ribeiro et al., 2016)</ref> is a prominent recent model-agnostic work in this space, building local linear approximations of a model and using the coefficients thereof to explain its behavior. <ref type="bibr" target="#b25">Li et al. (2016)</ref> trains a hard attention layer to flip the decisions of an existing model. While feature-based explanations are the most common approach, other forms have been pro- posed, including: similarity to learned "proto- types" which represent clusters of items from the training data ( <ref type="bibr" target="#b26">Li et al., 2017)</ref>; high-precision feature interaction rules ( <ref type="bibr" target="#b34">Ribeiro et al., 2018)</ref>; reference to predefined human-friendly concepts ; and generated natural lan- guage ( <ref type="bibr" target="#b13">Ehsan et al., 2017)</ref>. Likewise, many evalu- ation criteria have been proposed. These include fully automated evaluation ( <ref type="bibr" target="#b6">Arras et al., 2017)</ref>; comparison to human gold standards ( <ref type="bibr" target="#b23">Lei et al., 2016)</ref>; and human task performance <ref type="bibr" target="#b29">(Nguyen, 2018)</ref>. Doshi- <ref type="bibr" target="#b11">Velez and Kim (2017)</ref> and <ref type="bibr" target="#b14">Gilpin et al. (2018)</ref> both present reviews and taxonomies of evaluation types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Adversarial learning</head><p>Generative Adversarial Networks ( <ref type="bibr" target="#b16">Goodfellow et al., 2014</ref>) involve the use of a discriminative model to help a generative model match its out- put to an existing data distribution via an adver- sarial minimax game. Such models have achieved good results on various generative tasks such as image synthesis ( <ref type="bibr" target="#b42">Zhang et al., 2018</ref>) and text gen- eration ( <ref type="bibr" target="#b41">Yu et al., 2016)</ref>. Recently, adversarial schemes have begun to be adapted for non-strictly- generative tasks such as fake review detection ( <ref type="bibr" target="#b2">Aghakhani et al., 2018)</ref>, improving the robustness of predictive models to adversarial attacks ( ) and image retrieval <ref type="bibr" target="#b36">(Song, 2017)</ref>.</p><p>Ideas similar to the adversarial scheme used in this paper have come not from interpretability but rather from weakly-supervised object localization. <ref type="bibr" target="#b38">Wei et al. (2017)</ref> uses a similar scheme to accom- plish more complete detection of object shapes in images by iteratively erasing the regions that a pre- dictive model lends the most attention, and forc- ing it to adjust to the occluded image. <ref type="bibr" target="#b12">Edwards and Storkey (2016)</ref> is also similar, using an au- toencoder rather than a masking layer to remove identifying information from images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>The goal of our architecture is to highlight per- sonal attacks in text when such are present, and to highlight little or nothing when there are none, while also performing accurate overall prediction.</p><p>These requirements prompt two important edge cases: first, there may be no particular predictive signal in the comment text (i.e. no personal at- tacks); in a more typical explanatory setting there is always assumed to be some explanation for a de- cision. Second, there may be redundant signal (i.e. multiple personal attacks), more than is strictly re- quired for accurate prediction, and we assume that it is desirable to identify all of it. We address both of these cases with modifications to the original model architecture.</p><p>The model ( <ref type="figure" target="#fig_0">Figure 3A</ref>) is a hard attention ar- chitecture which uses one RNN to extract an at- tention mask of either 0 or 1 for each token, and a different RNN to make a prediction from the attention-masked text (detailed in <ref type="figure" target="#fig_0">Figure 3B</ref>). Fol- lowing ( <ref type="bibr" target="#b23">Lei et al., 2016)</ref>, we refer to the mask- producing layer g as the generator, but for clarity we call the predictive layer f the predictor rather than the encoder. Again following previous work, we refer to the output z of the generator as the ra- tionale, in that it rationalizes the prediction of the predictor. We also refer to the inverse rationale, defined as 1-z , as the antirationale.</p><p>To this basic two-layer scheme, we add a sec- ondary, adversarial predictor f 2 , which views the text masked by the antirationale rather than the ra- tionale. The secondary predictor's role is to act as an adversarial discriminator-it tries to make ac- curate predictions on the antirationale, while the generator tries to prevent it from doing so, which ensures that all predictive signal ends up in the ra- tionale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Primary predictor</head><p>The primary predictor f is an RNN which views the input text masked by the rationale produced by the generator. Its objective is simply to reduce its own squared loss:</p><formula xml:id="formula_0">cost f (z, x, y) = f (x, z) − y 2<label>(1)</label></formula><p>3.1.1 Default behavior via predictor bias term manipulation The default behavior of the model is the prediction the predictor makes if the input is entirely masked by the rationale: f (x, 0). When working with a recurrent unit that has no internal bias term, this behavior is entirely determined by the bias term of the final sigmoid output layer, σ(wx + b), which with typical random initialization of b results in a default predicted value of roughly 0.5.</p><p>However, this 0.5 default value is not always op- timal or semantically appropriate to the predictive task. In the personal attack detection task, if no attacks can be detected, the "natural" default tar- get value for a text should be close to 0. We show in the experiments that manually setting the out- put layer bias term b to logit(0.05) = −2.94, so that the default predicted value is 0.05, improves model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Secondary adversarial predictor</head><p>The secondary adversarial predictor is an RNN which views the input text masked by the antira- tionale, defined as 1 minus the rationale z. Its pur- pose is to encourage high-recall explanations by trying to make accurate predictions from the an- tirationale, while the generator tries to prevent it from doing so.</p><p>However, if the adversarial predictor's objec- tive function were simply f 2 (x, 1 − z) − y 2 , it would be able to gain an unfair advantage from the presence of masking in the antirationale. See- ing evidence of "blanked-out" tokens would tell it that personal attacks were present in that com- ment, giving it strong hint that the target value is close to 1.0 and vice-versa (see <ref type="figure" target="#fig_1">figure 4A</ref>).</p><p>To take away this advantage, the input to the adversarial predictor has to be permuted such that the mask itself is no longer correlated with the tar- get value, while still allowing it to scan the antira- tionale for residual predictive signal.</p><p>Our solution is to replace the masks of half the items in a training batch with the masks of other items in the batch. We order the batch by target value. If item x i is selected for replacement, it gets the mask of item x N −i where N is the size of the batch. We call this permutation function c:</p><formula xml:id="formula_1">c(z i ) = c(g(x i )) = g(x i ) if k i = 1 g(x N −i ) if k i = 0 x i ∈ {x 0 , ..., x N } k i ∼ Bernoulli(0.5)</formula><p>This ensures that low-target-value items get masks associated with high target values and vice-versa, to maximize the dissociation between masks and target values. <ref type="figure" target="#fig_1">Figure 4B</ref> demonstrates an example of such permutation. This may slow down the learning, since the adversarial predictor will sometimes have access to somewhat different features of the input than it will have on the test data, but it should not lead to incorrect learning, since the training data always has the correct la- bel, regardless of the mask.</p><p>With c(1 − z) as the permuted antirationale re- sulting from applying this randomization process. The objective for the secondary, adversarial pre- dictor is its predictive accuracy on this permuted antirationale:</p><formula xml:id="formula_2">cost f 2 (z, x, y) = f 2 (x, c(1 − z)) − y 2<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Generator</head><p>Given that the two predictors are trying to mini- mize error on the rationale and (permuted) antira- tionale respectively, the objective function for the generator is as follows:</p><formula xml:id="formula_3">cost g (z, x, y) = (3) f (x, z) − y 2 (3.1) +λ 1 ||z|| (3.2) +λ 1 λ 2 t |z t − z t−1 | (3.3) +λ 3 f 2 (x, 1 − z) − f 2 (x, 0) 2 (3.4)</formula><p>Terms 3.1-3.3 are present in the model of Lei et al. Term 3.1 encourages the generator to al- low the primary predictor to make accurate predic- tions, prevents it from obscuring any tokens that would prevent the predictor from doing so. Term 3.2 encourages the generator to produce minimal rationales; obscuring as many tokens as possible. Term 3.3 encourages rationale coherence by pun- ishing the number of transitions in the rationale; it encourages few contiguous phrases rather than many fragments in the rationale.</p><p>In theory, these three terms ensure high pre- cision, selecting the minimal (term 3.2) rationale with sufficient signal for accurate prediction (term 3.1), subject to a coherence constraint (term 3.3).</p><p>Term 3.4, which is new, ensures recall by en- couraging the adversarial predictor's prediction on the antirationale to be similar to the prediction it would make with no information at all (aka the default value). That is, the antirationale should contain no predictive signal. Any personal at- tacks left out of the rationale would appear in the antirationale, letting the adversarial predictor make a more accurate prediction, which would be penalized by term 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Extractive Adversarial Network</head><p>In the GAN framework ( <ref type="bibr" target="#b16">Goodfellow et al., 2014</ref>), a discriminator attempts to accurately classify syn- thetic examples which a generator is striving to match to the distribution of the true data. In our framework, the adversarial predictor attempts to accurately classify censored examples which the generator is striving to strip of all predictive sig- nal. The discriminator in the GAN framework is trained half on real data, and half on fakes; our adversarial predictor is trained half on correctly- masked items and half on items with permuted masks. Where our framework differs from GAN is instead of generating adversarial examples which are compared to true examples, our architecture extracts a modified example out of an existing ex- ample, and so can therefore be described as an Ex- tractive Adversarial Network (EAN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Implementation details</head><p>For comparability with the original algorithm, we use the same recurrent unit (RCNN) and REINFORCE-style policy gradient optimization process <ref type="bibr" target="#b39">(Williams, 1992)</ref> as <ref type="bibr" target="#b23">Lei et al. (2016)</ref> to force the generator outputs to be a discrete 0 or 1. In this framework, the continuous output of the generator on each token is treated as a probability from which the mask is then sampled to produce a discrete value for each token. The gradient across this discontinuity is approximated as:</p><formula xml:id="formula_4">∂E z∼g(x) [cost g (z, x, y)] ∂θ g = E z∼g(x) cost g (z, x, y) ∂ log p(z|x) ∂θ g</formula><p>In theory, one would sample z several times from the generator g to produce a good estimate of the gradient. In practice, we find that a single sample per epoch is sufficient. The predictors f and f 2 are trained as normal, as the error gradient with respect to their parameters is smooth.</p><p>We employ a particular hard attention model, but the idea of an adversarial critic is not limited to either hard attention or any particular recurrent unit. In a soft attention setting, our adversarial scheme will actually encourage "harder" attention by encouraging any non-zero attention weight to go to 1.0 (or else the inverse of that weight will leave predictive signal in the anti-explanation).</p><p>The attention weights produced by the genera- tor are applied to the predictor at the output rather than the input level. When the recurrent unit P of the predictor operates on a token x t modified by attention weight z t , it ingests x t normally, but de- pending on z t it either produces its own output or forwards that of the previous token:</p><formula xml:id="formula_5">P (x t , z t ) = z t P base (x t ) · (1 − z t )P base (x t−1 )</formula><p>We investigate a similar range of sparsity hy- perparameter values as the original model 1 . The weight on the inverse term only matters relative to the model sparsity, as that term cooperates rather than competing with the predictive accuracy term (because it almost never hurts accuracy to add more to the rationale). Therefore we set λ 3 to 1.0 when we want to include the inverse term.</p><p>We use Word2Vec ( <ref type="bibr" target="#b27">Mikolov et al., 2013</ref>) to cre- ate input token word vectors and Adam <ref type="bibr" target="#b21">(Kingma and Ba, 2014</ref>) for optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>To train our model of personal attacks, we use the dataset introduced by <ref type="bibr" target="#b40">(Wulczyn et al., 2017)</ref>, which consists of roughly 100,000 Wikipedia re- vision comments labeled via crowsourcing for ag- gression, toxicity and the presence of personal at- tacks. This dataset includes its own training, de- velopment and test set split, which we also use.</p><p>To this dataset we add a small validation set of personal attack rationales. 40 undergraduate stu- dents used Brat ( <ref type="bibr" target="#b37">Stenetorp et al., 2012</ref>) to high- light sections of comments that they considered to constitute personal attacks. Comments were sam- pled in a stratified manner from the development and test sets of the Wulczyn et al. dataset, and each student annotated roughly 150 comments, with each comment viewed by roughly 4 anno- tators. To calculate gold-standard rationales, we take the majority vote among annotators for each token in each comment. 1089 distinct comments were annotated, split between a development and test set of 549 and 540 examples respectively.</p><p>The Krippendorff's alpha on our validation set is 0.53 at the whole-comment level. This value is comparable with that of <ref type="bibr" target="#b40">Wulczyn et al. (2017)</ref> (0.45). Agreement at the token level is a lower 0.41, because this includes tokens which are a matter of preference among annotators, such as ar- ticles and adverbs, as well as content tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We show that both modifications to the original al- gorithm, bias term manipulation and inverse term, increase the tokenwise F1 of the predicted ratio- nales relative to our human-annotated test set. All hyperparameters were tuned to maximize token- wise F1 on the development set. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baselines</head><p>We generate six baselines for comparison with our variant of the ( <ref type="bibr" target="#b23">Lei et al., 2016)</ref> architecture. These include the following: Sigmoid predictor (logistic regression): Bag-of- words representation with a sigmoid output layer. RNN predictor: The same sequence model used for the predictor, but with no generator layer. Mean human performance: The mean token- wise performance of human annotators measured    against the majority vote for the comments they annotated (with their vote left out).</p><p>Sigmoid predictor + feature importance: Bag- of-words representation with sigmoid output layer, with post-hoc feature importance based on model coefficients. Cutoff threshold for features tuned to maximize rationale F1 on development set. RNN predictor + sigmoid generator: Rationale mask generated by sigmoid layer applied indepen- dently to each input token. Prediction layer is same as predictor. RNN predictor + LIME: Rationale mask gener- ated by applying LIME ( <ref type="bibr" target="#b33">Ribeiro et al., 2016</ref>) post- hoc to RNN layer predictions. Masking threshold tuned to maximize rationale F1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Rationale performance</head><p>In the main experiment, we evaluate model ratio- nales relative to rationales created by human anno- tators. In our validation dataset, human annotators typically chose to annotate personal attacks at the phrase level; hence in the sentence "Get a job, you hippie s***bag", the majority-vote rationale con- sists of the entire sentence, where it could arguably consist of the last two or even the last word. There- fore, in addition to tokenwise precision, recall and positive F1, we also report a relaxed "phrasewise" version of these metrics where any time we cap- ture part of a contiguous rationale chunk, that is considered a true positive. We report results for the original model (i.e. terms 3.1-3.3 in the objective function), the origi- nal model with its bias term set for a default value of 0.05, and the bias-modified model with the ad- ditional inverse term (term 3.4). For every model variant, we optimized hyperparameters for token- wise F1 on the development set. We also report results for the baselines described above. <ref type="table" target="#tab_0">Table 1</ref> displays the results. The difference in performance between the three baselines that don't use a RNN generator and the three model variants that do demonstrates the importance of context in recognizing personal attacks within text. The rel- ative performance of the three variants of the Lei et al. model show that both modifications, setting the bias term and the addition of the adversarial predictor, lead to marginal improvements in token- wise F1. The best-performing model approaches average human performance on this metric.</p><p>The phrasewise metric is relaxed. It allows a contiguous personal attack sequence to be con- sidered captured if even a single token from the sequence is captured. The results on this metric show that in an absolute sense, 87% of personal attacks are at least partially captured by the algo- rithm. The simplest baseline, which produces ra- tionales by thresholding the coefficients of a lo- gistic regression model, does deceptively well on this metric by only identifying attacking words like "jerk" and "a**hole", but its poor tokenwise performance shows that it doesn't mimic human highlighting very well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Original model tokenwise recall</head><p>A perplexing result of the rationale performance comparison is how good the tokenwise recall of the model is without the inverse term. Without it, the model is encouraged to find the minimal ra- tionale which offers good predictive performance. Comments with more than one personal attack  <ref type="figure">Figure 1</ref>) constitute 29% of those with at least one attack and 13% of all comments in our validation set. For comments like these, the model should in theory only identify one such attack. However, it tends to find more information than needed, leading to a higher-than-expected recall of .52 in the best overall version of this variant.</p><p>To explain this behavior, we run a leave-one- out experiment on the original+bias and origi- nal+bias+inverse model variants. For each dis- tinct contiguous rationale chunk predicted by each model (when it generates multi-piece rationales), we try removing this chunk from the predicted rationale, running the prediction layer on the re- duced rationale, and seeing whether the result low- ers the value of the overall objective function.</p><p>For the original+bias model variant, we find that performing this reduction improves the value of the objective function 65% of the time. However, the combined average impact of these reductions on the objective function is to worsen it. What this means is while 65% of distinct phrases discovered by the generator are unnecessary for accurate pre- diction, the 35% of them that are necessary lead to a major decrease in predictive accuracy.</p><p>That is, the generator "hedges its bets" with re- spect to predictive accuracy by including more in- formation in the rationales than it has to, and ex- periences a better global optimum as a result. This behavior is less prominent with the inclusion of the inverse term, where the percentage of unnecessary rationale phrases falls to 47%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Impact of bias term manipulation</head><p>In theory, the model should learn a good bias term for the predictor layer, and therefore the idea of ex- plicitly initializing or fixing the bias term to match <ref type="figure">Figure 6</ref>: Evolution of development set rationale F1 score over time with and without bias term manipula- tion the semantics of the task should not impact model performance or represent much of a contribution.</p><p>In practice however, as figures 5 and 6 demon- strate, the initialization of the bias term has a big impact on even the long-term learning behavior of the model. Using the best hyperparameters for the original no-bias, no-inverse-term model, <ref type="figure" target="#fig_5">figure 5</ref> shows that either initializing or permanently fix- ing the predictor bias for a default output value of 0.05 leads to improved model loss with respect to its own objective function. <ref type="figure">Figure 6</ref> shows a simi- lar pattern for tokenwise F1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and future work</head><p>One interpretation of the impact of the bias term on model behavior is that an explanation of "why" is really an explanation of "why not"-that is, an explanation is information that distinguishes an item from some alternative hypothesis, and explic- itly choosing what this alternative is can improve explanation performance (particularly precision).</p><p>Manually setting the model to produce some reasonable default value for an empty rationale makes sense in our setting, but not in domains where there is no default value, such as the beer review dataset of ( <ref type="bibr" target="#b23">Lei et al., 2016)</ref>. A more gen- eral approach would be to base explanations on confidence rather than accuracy, where the default value would simply be the mean and variance of the training data, and explanations would consist of tokens that tighten the bounds on the output.</p><p>A surprising finding is that the original algo- rithm often ends up defying its own objective and finds more complete rationales than needed. The leave-one-out experiment described above sug- gests that the reason for this behavior is that it is how the generator deals with predictive uncer- tainty, and that it achieves a better global optimum by producing locally suboptimal rationales.</p><p>While this "bug" proves useful in our case, it may not generalize. In our setting the adversarial predictor gives a modest improvement in recall; it will produce a larger improvement in settings where the unaltered algorithm is more successful at producing the minimal explanations described by its objective function. <ref type="bibr" target="#b25">Li et al. (2016)</ref> finds that a memory network predictor requires less occlu- sion than an LSTM to flip its predictions, indicat- ing that choice of model can effect completeness of explanations.</p><p>In theory, interpretable models can aid human moderaters by pointing them directly at the po- tentially objectionable content in a comment and giving them a starting point for making their own holistic decision about the comment. However, there are potential pitfalls. Adding explanations as a model output gives the model another way to be wrong-one which humans may be even less able to troubleshoot than simple misclassification. Re- latedly, explanations may inspire overconfidence in model predictions. Extensive user testing would clearly be needed before any deployment.</p><p>One final concern is the question of whether human-like explanations are really optimal expla- nations. Are high-recall explanations that mimic human highlighting tendencies really optimal for the types of moderating/self-moderating tasks in- volved in the domain of personal attacks in on- line social media? Again, this question can only be answered with human subject experimentation, which we plan to approach in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The main contribution of this paper is to frame ex- planation as an adversarial problem, thereby ad- dressing explanation recall for the first time that we are aware of. We do so by introducing an adversarial framework (an "extractive adversarial network") for ensuring that redundant predictive signal is not omitted from a model's explanations. We also show that choosing a null hypothesis for the model by setting the model bias term improves explanation precision.</p><p>Secondarily, we make a domain-specific con- tribution by applying interpretable machine learn- ing for the first time to the problem of identifying personal attacks in social media comments, with the hope of developing more transparent semi- automated moderation systems. We show that we approach human performance on a dataset we de- velop for this purpose.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: (A) Overall architecture. Generator and predictors are RNNs; (B) Detail of interaction between generator and one predictor layer. G and P are recurrent units of any kind. O is a sigmoid output layer.</figDesc><graphic url="image-3.png" coords="4,117.41,62.81,359.99,168.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: (A) Fabricated sample batch masked by antirationales. Note the correlation between mask and target; (B) The batch with some antirationales switched with those of other items. The correlation no longer holds.</figDesc><graphic url="image-4.png" coords="5,117.41,62.81,360.01,138.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Evolution of model loss over time with and without bias term manipulation</figDesc><graphic url="image-5.png" coords="8,72.00,62.81,216.00,145.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Further examples of labeled and rationalized comments. Items E) and G) show that the algorithm struggles with sarcasm.</figDesc><graphic url="image-7.png" coords="9,81.41,62.80,432.01,207.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Rationale performance relative to human annotations. Prediction accuracy is based on a binary threshold 
of 0.5. Performance of both Lei2016 model variants is significantly different from the baseline model (McNemar's 
test, p &lt; 0.05) 

</table></figure>

			<note place="foot" n="1"> λ1=[0.0003, 0.0006, 0.0009, 0.0012, 0.0015, 0.0018, 0.0021], λ2=[0, 1, 2]</note>

			<note place="foot" n="2"> λ1=0.0006 for variants without inverse term, λ1=0.0015 for variant with inverse term, λ2=2 (Tuned for maximum F1 on original model, then held constant for comparability)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This material is based upon work supported by the National Science Foundation under grant num-bers 1717688, 1633370 and 1620319. We also thank David Jurgens and Yue Wang for their help-ful comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Internet Argument Corpus 2.0: An SQL Schema for Dialogic Social Media and the Corpora to Go With It</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Resources and Evaluation Conference (LREC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Better discussions with imperfect models. The False PositiveMedium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Blog post</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hojjat</forename><surname>Aghakhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Machiry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirin</forename><surname>Nilizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Kruegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Vigna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10364[cs].ArXiv:1805.10364</idno>
		<title level="m">Detecting Deceptive Reviews using Generative Adversarial Networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Ancona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enea</forename><surname>Ceolini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cengiz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Gross</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.06104</idno>
		<idno>ArXiv: 1711.06104</idno>
		<title level="m">Towards better understanding of gradient-based attribution methods for Deep Neural Networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Nasty Effect: Online Incivility and Risk Perceptions of Emerging Technologies: Crude comments and concern</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashley</forename><forename type="middle">A</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominique</forename><surname>Brossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietram</forename><forename type="middle">A</forename><surname>Scheufele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Xenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ladwig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer-Mediated Communication</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="373" to="387" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Toxic Talk: How Online Incivility Can Undermine Perceptions of Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashley</forename><forename type="middle">A</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><forename type="middle">K</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominique</forename><surname>Brossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietram</forename><forename type="middle">A</forename><surname>Scheufele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Xenos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Public Opinion Research</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Explaining Recurrent Neural Network Predictions in Sentiment Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leila</forename><surname>Arras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grgoire</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>Mller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<meeting>the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Association for Computational Linguistics</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Abusive Language Online. ACL</title>
		<meeting>the 1st Workshop on Abusive Language Online. ACL<address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Like Trainer, Like Bot? Inheritance of Bias in Algorithmic Content Moderation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reuben</forename><surname>Binns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Veale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Van Kleek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Shadbolt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Informatics</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">10540</biblScope>
			<biblScope unit="page" from="405" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Classification and Its Consequences for Online Harassment: Design Insights from HeartMob</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lindsay</forename><surname>Blackwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Dimond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarita</forename><surname>Schoenebeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Lampe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer Supported Cooperative Work (CSCW 2018)</title>
		<meeting>the ACM Conference on Computer Supported Cooperative Work (CSCW 2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Antisocial Behavior in Online Discussion Communities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Web and Social Media</title>
		<meeting>the International Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Finale</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Velez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08608</idno>
		<idno>ArXiv: 1702.08608</idno>
		<title level="m">Towards A Rigorous Science of Interpretable Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Censoring Representations with an Adversary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Rationalization: A Neural Machine Translation Approach to Generating Natural Language Explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Upol</forename><surname>Ehsan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brent</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">O</forename><surname>Riedl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.07826</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Michael Specter, and Lalana Kagal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leilani</forename><forename type="middle">H</forename><surname>Gilpin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><forename type="middle">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayesha</forename><surname>Bajwa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00069</idno>
		<idno>ArXiv: 1806.00069</idno>
	</analytic>
	<monogr>
		<title level="m">Explaining Explanations: An Approach to Evaluating Interpretability of Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Large Labeled Corpus for Online Harassment Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Golbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Kumar Gnanasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelly</forename><forename type="middle">M</forename><surname>Raja Rajan Gunasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vichita</forename><surname>Hottle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivika</forename><surname>Jienjitlert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Khare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marianna</forename><forename type="middle">J</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shalmali</forename><surname>Martindale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heather</forename><forename type="middle">L</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Ashktorab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristine</forename><forename type="middle">M</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meghna</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Sardana Sarin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayanee</forename><surname>Shahane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thanki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM on Web Science Conference</title>
		<editor>Priyanka Vengataraman, Zijian Wan, Derek Michael Wu, Rashad O. Banjo, Alexandra Berlinger, Siddharth Bhagwan, Cody Buntain, Paul Cheakalos, Alicia A. Geller, and Quint Gergory</editor>
		<imprint>
			<biblScope unit="page" from="229" to="233" />
			<date type="published" when="2017" />
			<publisher>ACM Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative Adversarial Nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Guidotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Monreale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franco</forename><surname>Turini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dino</forename><surname>Pedreschi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.01933</idno>
		<title level="m">A Survey Of Methods For Explaining Black Box Models</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Deceiving Googles Perspective API Built for Detecting Toxic Comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sreeram</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baosen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radha</forename><surname>Poovendran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08138</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Technology Solutions to Combat Online Harassment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccollough</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Bastidas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Loo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurav</forename><surname>Sahay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Abusive Language Online</title>
		<meeting>the First Workshop on Abusive Language Online</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="73" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carrie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Wexler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rory</forename><surname>Sayres</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.11279</idno>
		<title level="m">Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>stat</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations</title>
		<meeting>the 3rd International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Interpretable Decision Sets: A Joint Framework for Description and Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himabindu</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1675" to="1684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rationalizing Neural Predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Online Harassment, Digital Abuse, and Cyberstalking in America</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Lenhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Ybarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathryn</forename><surname>Zickuhr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeshia</forename><surname>Price-Feeney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Data &amp; Society Research Institute</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.08220</idno>
		<title level="m">Understanding Neural Networks through Representation Erasure</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaofan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Rudin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.04806</idno>
		<title level="m">Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Finding Good Conversations Online: The Yahoo News Annotated Comments Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aasish</forename><surname>Pappu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrica</forename><surname>Rosato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Provenzale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Linguistic Annotation Workshop</title>
		<meeting>the 11th Linguistic Annotation Workshop</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Comparing Automatic and Human Evaluation of Local Explanations for Text Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1069" to="1078" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Abusive Language Detection in Online User Content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chikashi</forename><surname>Nobata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achint</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web</title>
		<meeting>the 25th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="145" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep Learning for User Comment Moderation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Abusive Language Online</title>
		<meeting>the First Workshop on Abusive Language Online</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
	<note>Prodromos Malakasiotis, and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The Political Environment on Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pew</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Pew Research Center</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Why Should I Trust You?&quot;: Explaining the Predictions of Any Classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Marco Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Anchors: High Precision ModelAgnostic Explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Marco Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6034[cs].ArXiv:1312.6034</idno>
		<title level="m">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Binary Generative Adversarial Networks for Image Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingkuan</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04150[cs].ArXiv:1708.04150</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">BRAT: a web-based tool for NLP-assisted text annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Topi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="102" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Object Region Mining with Adversarial Erasing: A Simple Classification to Semantic Segmentation Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.08448[cs].ArXiv:1703.08448</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Ex Machina: Personal Attacks Seen at Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellery</forename><surname>Wulczyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nithum</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web</title>
		<meeting>the 26th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1391" to="1399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lantao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient. AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08318</idno>
		<title level="m">Self-Attention Generative Adversarial Networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.11342[cs].ArXiv:1710.11342</idno>
		<title level="m">Generating Natural Adversarial Examples</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
