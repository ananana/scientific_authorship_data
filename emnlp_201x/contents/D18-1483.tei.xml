<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:27+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multilingual Clustering of Streaming News</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastião</forename><surname>Miranda</surname></persName>
							<email>sebastiao.miranda@priberam.pt, arturs.znotins@leta.lv, scohen@inf.ed.ac.uk, guntis.barzdins@lu.lv</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Art</forename><forename type="middle">¯</forename><surname>Urs Znotin¸ˇ</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Znotin¸</forename><surname>Znotin¸ˇ</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Innovation Labs LETA</orgName>
								<orgName type="institution">University of Latvia</orgName>
								<address>
									<addrLine>Marijas Str. 2</addrLine>
									<postCode>LV-1050</postCode>
									<region>Riga</region>
									<country key="LV">Latvia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">IMCS</orgName>
								<address>
									<addrLine>Rainis Blvd. 29</addrLine>
									<postCode>LV-1459</postCode>
									<region>Riga</region>
									<country key="LV">Latvia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guntis</forename><surname>Barzdins</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Innovation Labs LETA</orgName>
								<orgName type="institution">University of Latvia</orgName>
								<address>
									<addrLine>Marijas Str. 2</addrLine>
									<postCode>LV-1050</postCode>
									<region>Riga</region>
									<country key="LV">Latvia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">IMCS</orgName>
								<address>
									<addrLine>Rainis Blvd. 29</addrLine>
									<postCode>LV-1459</postCode>
									<region>Riga</region>
									<country key="LV">Latvia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priberam</forename><surname>Labs</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Henriques</roleName><forename type="first">Alameda</forename><forename type="middle">D</forename><surname>Afonso</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<postCode>1000-123</postCode>
									<settlement>Lisboa</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multilingual Clustering of Streaming News</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="4535" to="4544"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>4535</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Clustering news across languages enables efficient media monitoring by aggregating articles from multilingual sources into coherent stories. Doing so in an online setting allows scalable processing of massive news streams. To this end, we describe a novel method for clustering an incoming stream of multilingual documents into monolingual and crosslingual story clusters. Unlike typical clustering approaches that consider a small and known number of labels, we tackle the problem of discovering an ever growing number of cluster labels in an online fashion, using real news datasets in multiple languages. Our method is simple to implement, computationally efficient and produces state-of-the-art results on datasets in German, English and Spanish.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Following developing news stories is imperative to making real-time decisions on important political and public safety matters. Given the abundance of media providers and languages, this endeavor is an extremely difficult task. As such, there is a strong demand for automatic clustering of news streams, so that they can be organized into stories or themes for further processing. Performing this task in an online and efficient manner is a challenging prob- lem, not only for newswire, but also for scientific articles, online reviews, forum posts, blogs, and microblogs.</p><p>A key challenge in handling document streams is that the story clusters must be generated on the fly in an online fashion: this requires handling doc- uments one-by-one as they appear in the document stream. In this paper, we provide a treatment to the problem of online document clustering, i.e. the task of clustering a stream of documents into themes. For example, for news articles, we would want to cluster them into related news stories.</p><p>To this end, we introduce a system which aggre- gates news articles into fine-grained story clusters across different languages in a completely online and scalable fashion from a continuous stream. Our clustering approach is part of a larger media mon- itoring project to solve the problem of monitor- ing massive text and TV/Radio streams (speech- to-text). In particular, media monitors write intelli- gence reports about the most relevant events, and being able to search, visualize and explore news clusters assists in gathering more insight about a particular story. Since relevant events may be spawned from any part of the world (and from many multilingual sources), it becomes imperative to cluster news across different languages.</p><p>In terms of granularity, the type of story clusters we are interested in are the group of articles which, for example : (i) Narrate recent air-strikes in East- ern Ghouta (Syria); (ii) Describe the recent launch of Space X's Falcon Heavy rocket.</p><p>Main Contributions While most existing news clustering approaches assume a monolingual docu- ment stream -a non-realistic scenario given the di- versity of languages on the Web -we assume a gen- eral, multilingual, document stream. This means that in our problem-formulation story documents appear in multiple languages and we need to cluster them to crosslingual clusters. Our main contribu- tions are as follows:</p><p>• We develop a system that aggregates news arti- cles into fine-grained story clusters across differ- ent languages in a completely online and scalable fashion from a continuous stream. As discussed in the introduction, this is a highly relevant task for the use-case of media monitoring.</p><p>• We formulate the problem of online multilingual document clustering and the representation that such clustering takes by interlacing the problem of monolingual clustering with crosslingual clus- tering. The representation of our clusters is inter- pretable, and similarly to topic models, consists of a set of keywords and weights associated with the relevant cluster. In our formulation, a mono- lingual cluster is a group of documents, and a crosslingual cluster is a group of monolingual clusters in different languages.</p><p>• We compare our approach to our own imple- mentation of a state-of-the-art streaming method, and show much superior results for a dataset in English, Spanish and German.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Formulation</head><p>We focus on clustering of a stream of documents, where the number of clusters is not fixed and learned automatically. We denote by D a (poten- tially infinite) space of multilingual documents. Each document d is associated with a language in which it is written through a function L : D → L where L is a set of languages. For example, L(d) could return English, Spanish or German. (In the rest of the paper, for an integer n, we denote by [n] the set {1, . . . , n}.) We are interested in associating each document with a monolingual cluster via the function C(d) ∈ N, which returns the cluster label given a document. This is done independently for each language, such that the space of indices we use for each language is separate. Furthermore, we interlace the prob- lem of monolingual clustering with crosslingual clustering. This means that as part of our problem formulation we are also interested in a function E : N × L → N that associates each monolin- gual cluster with a crosslingual cluster, such that each crosslingual cluster only groups one mono- lingual cluster per different language, at a given time. The crosslingual cluster for a document d is E(C(d), L(d)). As such, a crosslingual cluster groups together monolingual clusters, at most one for each different language.</p><p>Intuitively, building both monolingual and crosslingual clusters allows the system to leverage high-precision monolingual features (e.g., words, named entities) to cluster documents of the same language, while simplifying the task of crosslingual clustering to the computation of similarity scores across monolingual clusters -which is a smaller problem space, since there are (by definition) less clusters than articles. We validate this choice in §5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Clustering Algorithm</head><p>Each document d is represented by two vectors in R k 1 and R k 2 . The first vector exists in a "mono- lingual space" (of dimensionality k 1 ) and is based on a bag-of-words representation of the document. The second vector exists in a "crosslingual space" (of dimensionality k 2 ) which is common to all lan- guages. More details about these representations are discussed in §4.</p><p>Online Clustering With our clustering algo- rithm, we maintain two types of centroid functions for each monolingual cluster. The first is a cen- troid function H : N × L → R k 1 ∪ {⊥} that as- sists in associating each document with a mono- lingual cluster. The second is a centroid function G : N → R k 2 ∪ {⊥} that assists in associating each monolingual cluster with a crosslingual cluster. The ⊥ symbol is reserved to denote documents which are not associated with any cluster yet.</p><p>In our algorithm, we need to incrementally con- struct the functions H, G (the two centroid func- tions), C (the monolingual clustering function) and E (the crosslingual clustering function). Informally, we do so by first identifying a monolingual cluster for an incoming document by finding the closest centroid with the function H, and then associate that monolingual cluster with the crosslingual clus- ter that is closest based on the function G. The first update changes C and the second update changes E. Once we do that, we also update H and G to reflect the new information that exists in the new incoming document.</p><p>Example <ref type="figure" target="#fig_0">Figure 1</ref> depicts the algorithm and the state it maintains. A document in some language (d 9 ) appears in the stream, and is clustered into one of the monolingual clusters (circles) that group together documents about the same story (for ex- ample, c 2 , DE could be a German cluster about a recent political event). Then, following this mono- lingual update, the online clustering algorithm up- dates the crosslingual clusters (round rectangles), each grouping together a set of monolingual clus- ters, one per language at the most. The centroids for the monolingual clusters are maintained by the function H. For example, H(2, English) gives the centroid of the upper left English monolingual clus- ter. The function G maintains the crosslingual clus- ters. Considering the upper-left most crosslingual cluster, a 1 , then G(1) returns its centroid. Algorithm To be more precise, the online clus- tering process works as follows. H and G start with just returning ⊥ for any cluster number, both mono- lingual and crosslingual. With a new incoming doc- ument d, represented as a vector, we compute a similarity metric Γ 0 : R k 1 × R k 1 → R between the document vector and each of the existing centroids {i | H(i, L(d)) = ⊥}. If the largest similarity ex- ceeds a threshold τ for cluster index j, then we set C(d) = j. In that case, we also update the value of H(i, L(d)) to include new information from doc- ument d, as detailed below under "H update." If none of the similarity values exceed a threshold τ , we find the first i such that H(i, L(d)) = ⊥ (the first cluster id which is still unassigned), and set C(d) = i, therefore creating a new cluster. We again follow an "H update" -this time for starting a new cluster.</p><formula xml:id="formula_0">d 5 d 4 d 1 d 2 d 8 d 9 d 3 d 6 d 7 ⟨ c 2, DE ⟩ ⟨ c 4, EN ⟩ ⟨ c 5, ES⟩ H update ⟨ c 6, ES⟩ ⟨ c 3, DE ⟩ c 1 c 2 c 2 c 6 c 4 c 3 c 5 d 9 a 1 a 4 a 2 a 3 G update ⟨ c 2, EN ⟩</formula><p>In both cases, we also update the function G, by selecting the best crosslingual cluster for the recently updated (or created) monolingual clus- ter. To this end, we use another similarity metric</p><formula xml:id="formula_1">Γ 1 : R k 2 × R k 2 → R.</formula><p>Accordingly, we compute the similarity (using Γ 1 ) between the updated (or created) monolingual cluster and all monolingual clusters in each candidate crosslingual cluster, in the crosslingual feature space. The crosslingual cluster with highest sum of similarity scores is then selected. We also experimented computing this sim- ilarity by considering just the monolingual cluster of a particular "pivot language". The pivot language is a language that serves as the main indicator for a given crosslingual cluster. In our experiments, we mostly use English as the pivot language.</p><p>H Update To update H, we maintain a centroid for each cluster that is created as the average of all monolingual representations of documents that belong to that cluster. This is done for each lan- guage separately. This update can be done in O(k 1 ) time in each step. Similarly, the update of G can be done in O(k 2 ) time. In principle, we consider an "infinite" stream of documents, which means the number of documents in each cluster can be large. As such, for efficiency purposes, updates to H are immutable, which means that when a document is assigned to a monolingual cluster, that assignment is never changed.</p><p>G Update As described, updates to function G result in associating a monolingual cluster with a crosslingual cluster (and consequently, other mono- lingual clusters). Therefore, errors committed in updating G are of a higher magnitude than those committed in H, since they involve groups of doc- uments. We also note that the best crosslingual cluster for a particular monolingual cluster might not be found right at the beginning of the process. We experiment with two types of updates to G. One which is immutable, in which changes to G are not reversed (and are described above), and one in which we introduce a novel technique to make a sequence of changes to G if necessary, as a mechanism to self-correct past clustering decisions. When a past decision is modified, it may result in a chaining of consequent modifications ("toppling of dominoes") which need to be evaluated. We coin this method "domino-toppling".</p><p>The motivation behind this technique is the change in news stories over time. The technique allows the method to modify past crosslingual clus- tering decisions and enables higher quality clus- tering results. When a past decision is modified, it may result in a chain of consequent modifications which need to be evaluated.</p><p>Our method of "domino-toppling" works by making (potentially sequences) of changes to pre- vious clustering decisions for the crosslingual clus- ters, at each step placing a residual monolingual cluster in a crosslingual cluster that is most similar to it. <ref type="figure" target="#fig_1">Figure 2</ref> gives the pseudocode for domino toppling.</p><p>This "domino-toppling" technique could have in principle a quadratic complexity in the number Inputs: A monolingual cluster c and a list of pairs aj, Γ1(c, aj), j ∈ [N ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm:</head><p>• For all pairs aj, Γ1(c, aj), j ∈ [N ], ordered by the second coordinate:</p><p>• If L(c) is not in aj, add c to aj and break.</p><p>• Otherwise, let y ← M (aj, L(c)). If Γ1(c, aj) &gt; Γ1(y, aj) then:</p><p>• Add c to aj, remove y from aj and call domino toppling with y playing the role of c and break.</p><p>• If c is left unassigned, create aN+1 and add c to it. of crosslingual clusters. However, we have veri- fied that in practice it converges very fast, and in our evaluation dataset only 1% of the crosslingual updates result in topples. We apply this technique only to update G (and not H) because reversing cluster assignments in G can be done much more efficiently than in H -the total number of mono- lingual clusters (the clustered elements in G) is significantly smaller than the number of documents (the clustered elements in H). Crosslingual cluster- ing is also a harder problem, which motivated the additional effort of developing this algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Document Representation</head><p>In this section, we give more details about the way we construct the document representations in the monolingual and crosslingual spaces. In particu- lar, we introduce the definition of the similarity functions Γ 0 and Γ 1 that were referred in §3.</p><formula xml:id="formula_2">Monolingual Representation The monolingual representation for each document d in language L(d)</formula><p>is a vector in R k 1 constructed from several TF-IDF subvectors with words, word lemmas and named entities. Each subvector is repeated for dif- ferent sections of the document, the title, the body and both of them together. Besides these text fields and document timestamps, no other metadata was used. To detect named entities, we used Priberam's Text Analysis ( <ref type="bibr" target="#b3">Amaral et al., 2008)</ref> for <ref type="bibr">English and Spanish, and Turbo Parser (Martins et al., 2013</ref>) for German. The extracted entities consist of people, organizations, places and other types.</p><p>Crosslingual Representation In the crosslin- gual space, a document representation is a vec- tor in R k 2 . Let e(d, i) be a crosslingual embed- ding of word i in the document d, which is a vec- tor of length m . Then the document representa- tion v(d) of d consists of subvectors of the form</p><formula xml:id="formula_3">v(d) = n i=1 t i e(d, i),</formula><note type="other">where t i is the TF-IDF score of the ith word in the relevant section of the document (title, body or both). As detailed further in §5 we compute IDF values from a large pre- training dataset. Furthermore, for both the mono- lingual and crosslingual cases, we also experiment with using document timestamp features, as ex- plained in §4.1. We use a new set of diverse times- tamp features in addition to the simple absolute difference (in hours) between timestamps used by Rupnik et al. (2016).</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Similarity Metrics</head><p>Our similarity metric computes weighted cosine similarity on the different subvectors, both in the case of monolingual clustering and crosslingual clustering. Formally, for the monolingual case, the similarity is given by a function defined as:</p><formula xml:id="formula_4">Γ 0 (d j , c l ) = K i=1 φ i (d j , c l ) · q 0 i + 3 i=1 γ i (d j , c l ) · q 1 i .</formula><p>(1) and is computed on the TF-IDF subvectors where K is the number of subvectors for the relevant document representation. For the crosslingual case, we discuss below the function Γ 1 , which has a similar structure.</p><p>Here, d j is the jth document in the stream and c l is a monolingual cluster. The function φ i (d j , c l ) returns the cosine similarity between the document representation of the jth document and the centroid for cluster c l . The vector q 0 denotes the weights through which each of the cosine similarity values for each subvectors are weighted, whereas q 1 de- notes the weights for the timestamp features, as detailed further. Details on learning the weights q 0 and q 1 are discussed in §4.2.</p><p>The function γ(d, c) that maps a pair of docu- ment and cluster to R 3 is defined as follows. Let</p><formula xml:id="formula_5">f (t) = exp − (t − µ) 2 2σ 2<label>(2)</label></formula><p>for a given µ and σ &gt; 0. For each document d and cluster c, we generate the following three- dimensional vector γ(d, c) = (s 1 , s 2 , s 3 ):</p><formula xml:id="formula_6">• s 1 = f (t(d) − n 1 (c)) where t(d j )</formula><p>is the times- tamp for document d and n 1 (c) is the timestamp for the newest document in cluster c.</p><p>• s 2 = f (t(d)−n 2 (c)) where n 2 (c) is the average timestamp for all documents in cluster c.</p><p>• s 3 = f (t(d) − n 3 (c)) where n 3 (c) is the times- tamp for the oldest document in cluster c.</p><p>These three timestamp 1 features model the time aspect of the online stream of news data and help disambiguate clustering decisions, since time is a valuable indicator that a news story has changed, even if a cluster representation has a reasonable match in the textual features with the incoming document. The same way a news story becomes popular and fades over time ( <ref type="bibr" target="#b12">Lerman and Hogg, 2010)</ref>, we model the probability of a document belonging to a cluster (in terms of timestamp dif- ference) with a probability distribution.</p><p>For the case of crosslingual clustering, we in- troduce Γ 1 , which has a similar definition to Γ 0 , only instead of passing document/cluster similarity feature vectors, we pass cluster/cluster similarities, across all language pairs. Furthermore, the features are the crosslingual embedding vectors of the sec- tions title, body and both combined (similarly to the monolingual case) and the timestamp features. For denoting the cluster timestamp, we use the average timestamps of all articles in it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Learning to Rank Candidates</head><p>In §4.1 we introduced q 0 and q 1 as the weight vectors for the several document representation features. We experiment with both setting these weights to just 1 (q 0 i = 1 ∀i and q 1 j = 1 ∀j ∈ <ref type="bibr">[3]</ref>) and also learning these weights using support vec- tor machines (SVMs). To generate the SVM train- ing data, we simulate the execution of the algorithm on a training data partition (which we do not get evaluated on) and in which the gold standard labels are given. We run the algorithm using only the first subvector φ 1 (d j , c l ), which is the TF-IDF vector with the words of the document in the body and title. For each incoming document, we create a col- lection of positive examples, for the document and the clusters which share at least one document in the gold labeling. We then generate 20 negative ex- amples for the document from the 20 best-matching clusters which are not correct. To find out the best- matching clusters, we rank them according to their similarity to the input document using only the first subvector φ 1 (d j , c l ).</p><p>Using this scheme we generate a collection of ranking examples (one for each document in the dataset, with the ranking of the best cluster matches), which are then trained using the SVM- Rank algorithm <ref type="bibr" target="#b9">(Joachims, 2002</ref>). We run 5-fold cross-validation on this data to select the best model, and train both a separate model for each language according to Γ 0 and a crosslingual model according to Γ 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Our system was designed to cluster documents from a (potentially infinite) real-word data stream. The datasets typically used in the literature (TDT, Reuters) have a small number of clusters (≈ 20) with coarse topics (economy, society, etc.), and therefore are not relevant to the use case of me- dia monitoring we treat -as it requires much more fine-grained story clusters about particular events. To evaluate our approach, we adapted a dataset constructed for the different purpose of binary clas- sification of joining cluster pairs. <ref type="bibr">2</ref> We processed it to become a collection of articles annotated with monolingual and crosslingual cluster labels. <ref type="bibr">3</ref> Statistics about this dataset are given in Ta- ble 1. As described further, we tune the hyper- parameter τ on the development set. As for the hyper-parameters related to the timestamp features, we fixed µ = 0 and tuned σ on the development set, yielding σ = 72 hours (3 days). <ref type="bibr">4</ref> To compute IDF scores (which are global numbers computed across a corpus), we used a different and much larger dataset that we collected from Deutsche Welle's news website (http://www.dw.com/). The dataset consists of 77,268, 118,045 and 134,243 documents for Spanish, English and German, re- spectively.</p><p>The conclusions from our experiments are: (a) the weighting of the similarity metric features using SVM significantly outperforms unsupervised base- lines such as CluStream <ref type="table">(Table 2)</ref>; (b) the SVM approach significantly helps to learn when to cre- ate a new cluster, compared to simple grid search</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Size Avg. L. C <ref type="table" target="#tab_2">Avg. S.   train  English 12,233  434  593  21  German  4,043  282  377  11  Spanish  4,527  355  416  11   test  English  8,726  521  222  39  German  2,101  440  118  18  Spanish  2,177  392  149  15   Table 1</ref>: Statistics for the development and evaluation datasets, constructed from the dataset in <ref type="bibr" target="#b17">Rupnik et al. (2016)</ref>, as explained in §5. "Size" denotes the number of documents in the collection, "Avg. L." is the aver- age number of words in a document, "C" denotes the number of clusters in the collection and "Avg. S." is the average number of documents in each cluster.</p><p>for the optimal τ <ref type="table" target="#tab_2">(Table 4</ref>); (c) separating the fea- ture space into one for monolingual clusters in the form of keywords and the other for crosslingual clusters based on crosslingual embeddings signifi- cantly helps performance.</p><p>Evaluation Method We evaluate clustering in the following manner: let tp be the number of cor- rectly clustered-together document pairs, let fp be the number of incorrectly clustered-together docu- ment pairs and let fn be the number of incorrectly not-clustered-together document pairs. Then we report precision as tp tp+fp , recall as tp tp+fn and F 1 as the harmonic mean of the precision and recall measures. We do the same to evaluate crosslingual clustering, but on a higher level: we count tp, fn and fp for the decisions of clustering clusters, as crosslingual clusters are groups of monolingual gold clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Monolingual Results</head><p>In our first set of experiments, we report results on monolingual clustering for each language sepa- rately. Monolingual clustering of a stream of doc- uments is an important problem that has been in- spected by others, such as by <ref type="bibr" target="#b1">Ahmed et al. (2011)</ref> and by <ref type="bibr" target="#b0">Aggarwal and Yu (2006)</ref>. We compare our results to our own implementation of the online micro-clustering routine presented by <ref type="bibr" target="#b0">Aggarwal and Yu (2006)</ref>, which shall be referred to as CluS- tream. We note that CluStream of <ref type="bibr" target="#b0">Aggarwal and Yu (2006)</ref> has been a widely used state-of-the-art system in media monitoring companies as well as academia, and serves as a strong baseline to this day.</p><p>In our preliminary experiments, we also evalu- ated an online latent semantic analysis method, in which the centroids we keep for the function H (see  <ref type="table">Table 2</ref>: Clustering results on the labeled dataset. We compare our algorithm (with and without timestamps) with the online micro-clustering routine of Aggarwal and Yu (2006) (denoted by CluStream). The F 1 values are for the precision (P) and recall (R) in the follow- ing columns. See <ref type="table">Table 3</ref> for a legend of the different models. Best result for each language is in bold. §3) are the average of reduced dimensional vectors of the incoming documents as generated by an in- cremental singular value decomposition (SVD) of a document-term matrix that is updated after each incoming document. However, we discovered that online LSA performs significantly worse than rep- resenting the documents the way is described in §4. Furthermore, it was also significantly slower than our algorithm due to the time it took to perform singular value decomposition. <ref type="bibr">5</ref> Clustering experiments <ref type="table">Table 2</ref> gives the final monolingual results on the three datasets. For En- glish, we see that the significant improvement we get using our algorithm over the algorithm of Ag- garwal and Yu (2006) is due to an increased recall score. We also note that the trained models surpass the baseline for all languages, and that the times- tamp feature (denoted by TS), while not required to beat the baseline, has a very relevant contribu- tion in all cases. Although the results for both the baseline and our models seem to differ across lan- guages, one can verify a consistent improvement from the latter to the former, suggesting that the score differences should be mostly tied to the differ- ent difficulty found across the datasets for each lan- guage. The presented scores show that our learning framework generalizes well to different languages and enables high quality clustering results.</p><p>To investigate the impact of the timestamp fea-feature accuracy TOKENS 85.5 TOKENS+LEMMAS 85.9 TOKENS+LEMMAS+ENTS 86.5 TOKENS+LEMMAS+ENTS+TS 96.9 <ref type="table">Table 3</ref>: Accuracy of the SVM ranker on the English training set. TOKENS are the word token features, LEM- MAS are the lemma features for title and body, ENTS are named entity features and TS are timestamp fea- tures. All features are described in detail in §4, and are listed for both the title and the body.</p><p>tures, we ran an additional experiment using only the same three timestamp features as used in the best model on the English dataset. This experi- ment yielded scores of F 1 = 61.1, P = 44.5 and R = 97.6, which lead us to conclude that while these features are not competitive when used alone (hence temporal information by itself is not suffi- cient to predict the clusters), they contribute signif- icantly to recall with the final feature ensemble. We note that as described in §3, the optimiza- tion of the τ parameter is part of the development process. The parameter τ is a similarity thresh- old used to decide when an incoming document should merge to the best cluster or create a new one. We tune τ on the development set for each language, and the sensitivity to it is demonstrated in <ref type="figure">Figure 3</ref> (this process is further referred to as τ search ). Although applying grid-search on this pa- rameter is the most immediate approach to this problem, we experimented with a different method which yielded superior results: as described further, we discuss how to do this process with an additional classifier (denoted SVM-merge), which captures more information about the incoming documents and the existing clusters.</p><p>Additionally, we also experimented with comput- ing the monolingual clusters with the same embed- dings as used in the crosslingual clustering phase, which yielded poor results. In particular, this sys- tem achieved F 1 score of 74.8 for English, which is below the bag-of-words baseline presented in <ref type="table">Table 2</ref>. This result supports the approach we then followed of having two separate feature spaces for the monolingual and crosslingual clustering sys- tems, where the monolingual space is discrete and the crosslingual space is based on embeddings.</p><p>SVM ranker experiments To investigate the im- portance of each feature, we now consider in Ta-   <ref type="table">Table 2</ref>). The first method, τ search , corre- sponds to executing grid-search to find the optimal clus- tering τ parameter (see §3). SVM-merge is an alterna- tive method in which we train an SVM binary classi- fier to decide if a new cluster should be created or not, where we use as features the maximal value of each coordinate for each document in a cluster. ble 3 the accuracy of the SVM ranker for English as described in §4.1. We note that adding features increases the accuracy of the SVM ranker, espe- cially the timestamp features. However, the times- tamp feature actually interferes with our optimiza- tion of τ to identify when new clusters are needed, although they improve the SVM reranking accu- racy. We speculate this is true because high accu- racy in the reranking problem does not necessarily help with identifying when new clusters need to be opened. To investigate this issue, we experimented with a different technique to learn when to create a new cluster. To this end, we trained another SVM classifier just to learn this decision, this time a bi- nary classifier using LIBLINEAR <ref type="bibr" target="#b5">(Fan et al., 2008)</ref>, by passing the max of the similarity of each feature between the incoming document and the current clustering pool as the input feature vector. This way, the classifier learns when the current clusters,</p><formula xml:id="formula_7">crosslingual model F 1 P R τ search (global)</formula><p>72.7 89.8 61.0 τ search (pivot) 84.0 83.0 85.0 as a whole, are of a different news story than the incoming document. As presented in <ref type="table" target="#tab_2">Table 4</ref>, this method, which we refer to as SVM-merge, solved the issue of searching for the optimal τ parame- ter for the SVM-rank model with timestamps, by greatly improving the F 1 score in respect to the original grid-search approach (τ search ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Crosslingual Results</head><p>As mentioned in §3, crosslingual embeddings are used for crosslingual clustering. We experimented with the crosslingual embeddings of <ref type="bibr" target="#b6">Gardner et al. (2015)</ref> and <ref type="bibr" target="#b4">Ammar et al. (2016)</ref>. In our preliminary experiments we found that the former worked better for our use-case than the latter.</p><p>We test two different scenarios for optimizing the similarity threshold τ for the crosslingual case. <ref type="table" target="#tab_3">Table 5</ref> shows the results for these experiments. First, we consider the simpler case of adjusting a global τ parameter for the crosslingual distances, as also described for the monolingual case. As shown, this method works poorly, since the τ grid-search could not find a reasonable τ which worked well for every possible language pair.</p><p>Subsequently, we also consider the case of using English as a pivot language (see §3), where dis- tances for every other language are only compared to English, and crosslingual clustering decisions are made only based on this distance. <ref type="bibr">6</ref> This yielded our best crosslingual score of F 1 =84.0, confirm- ing that crosslingual similarity is of higher quality between each language and English, for the em- beddings we used. This score represents only a small degradation in respect to the monolingual results, since clustering across different languages is a harder problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Early research efforts, such as the TDT pro- gram ( <ref type="bibr" target="#b2">Allan et al., 1998)</ref>, have studied news clus- tering for some time. The problem of online mono- lingual clustering algorithms (for English) has also received a fair amount of attention in the litera- ture. One of the earlier papers by <ref type="bibr" target="#b0">Aggarwal and Yu (2006)</ref> introduced a two-step clustering system with both offline and online components, where the online model is based on a streaming implemen- tation of k-means and a bag-of-words document representation. Other authors have experimented with distributed representations, such as <ref type="bibr" target="#b1">Ahmed et al. (2011)</ref>, who cluster news into storylines us- ing Markov chain Monte Carlo methods, ˇ Rehůřek and Sojka (2010) who used incremental Singular Value Decomposition (SVD) to find relevant topics from streaming data, and <ref type="bibr" target="#b18">Sato et al. (2017)</ref> who used the paragraph vector model ( <ref type="bibr" target="#b10">Le and Mikolov, 2014</ref>) in an offline clustering setting.</p><p>More recently, crosslingual linking of clusters has been discussed by <ref type="bibr" target="#b17">Rupnik et al. (2016)</ref> in the context of linking existing clusters from the Event Registry ( <ref type="bibr" target="#b11">Leban et al., 2014</ref>) in a batch fashion, and by Steinberger (2016) who also present a batch clustering linking system. However, these are not "truly" online crosslingual clustering systems since they only decide on the linking of already-built monolingual clusters. In particular, <ref type="bibr" target="#b17">Rupnik et al. (2016)</ref> compute distances of document pairs across clusters using nearest neighbors, which might not scale well in an online setting. As detailed before, we adapted the cluster-linking dataset from <ref type="bibr" target="#b17">Rupnik et al. (2016)</ref> to evaluate our online crosslingual clustering approach. Preliminary work makes use of deep learning techniques ( <ref type="bibr" target="#b20">Xie et al., 2016;</ref><ref type="bibr" target="#b8">Guo et al., 2017</ref>) to cluster documents while learning their representations, but not in an online or mul- tilingual fashion, and with a very small number of cluster labels (4, in the case of the text benchmark).</p><p>In our work, we studied the problem of mono- lingual and crosslingual clustering, having exper- imented several directions and methods and the impact they have on the final clustering quality. We described the first system which aggregates news articles into fine-grained story clusters across differ- ent languages in a completely online and scalable fashion from a continuous stream.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We described a method for monolingual and crosslingual clustering of an incoming stream of documents. The method works by maintaining cen- troids for the monolingual and crosslingual clus- ters, where a monolingual cluster groups a set of documents and a crosslingual cluster groups a set of monolingual clusters. We presented an online crosslingual clustering method which auto-corrects past decisions in an efficient way. We showed that our method gives state-of-the-art results on a mul- tilingual news article dataset for English, Spanish and German. Finally, we discussed how to leverage different SVM training procedures for ranking and classification to improve monolingual and crosslin- gual clustering decisions. Our system is integrated in a larger media monitoring project ( <ref type="bibr" target="#b13">Liepins et al., 2017;</ref><ref type="bibr" target="#b7">Germann et al., 2018)</ref> and solving the use- cases of monitors and journalists, having been vali- dated with qualitative user testing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A pictorial description of the algorithm and the state it maintains. The algorithm maintains a monolingual cluster space, in which each cluster is a set of documents in a specific language. The algorithm also maintains a crosslingual cluster space, in which a cluster is a set of monolingual clusters in different languages. Documents are denoted by d i , monolingual clusters by c i (circles) and crosslingual clusters by a i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Crosslingual "domino-toppling". a j is the jth crosslingual cluster (out of total N clusters) and Γ 1 is the similarity between them as in §4. L(c) is the language for cluster c. M (a, ) returns the monolingual cluster for language ∈ L in crosslingual cluster a. See text for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Comparison of two different cluster decision techniques for the English SVM model with all fea- tures (see</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Crosslingual clustering results when consid-
ering two different approaches to compute distances 
across crosslingual clusters on the test set for Spanish, 
German and English. See text for details. 

</table></figure>

			<note place="foot" n="1"> Timestamps are given in hours since 1970.</note>

			<note place="foot" n="2"> https://github.com/rupnikj/jair_paper 3 The code and data we used is available at https:// github.com/priberam/news-clustering. 4 This shows a relative robustness to reordering of the articles-articles within 3 days of each other could appear anywhere in that window, and the algorithm would still perform well.</note>

			<note place="foot" n="5"> More specifically, we used an object of type lsimodel from the GenSim package that implements algorithms fromŘehůřek fromˇfromŘehůřek (2010). The GenSim package can be found at https://pypi.python.org/pypi/gensim.</note>

			<note place="foot" n="6"> In this case, all crosslingual clusters will have at least one pivot monolingual cluster, except for clusters which might stay unmerged as single-language degenerated crosslingual clusters.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Esma Balkır, Nikos Pa-pasarantopoulos, Afonso Mendes, Shashi Narayan and the anonymous reviewers for their feedback. This project was supported by the European H2020 project SUMMA, grant agreement 688139 (see http://www.summa-project.eu) and by a grant from Bloomberg.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A framework for clustering massive text and categorical data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Charu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="479" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unified analysis of streaming news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qirong</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Choon Hui</forename><surname>Teo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on World wide web</title>
		<meeting>the 20th international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Topic detection and tracking pilot study: Final report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Yamron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the DARPA broadcast news transcription and understanding workshop</title>
		<meeting>the DARPA broadcast news transcription and understanding workshop</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Priberam&apos;s question answering system in QA@ CLEF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adán</forename><surname>Cassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helena</forename><surname>Figueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afonso</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Pina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cláudia</forename><surname>Pinto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop of the Cross-Language Evaluation Forum for European Languages</title>
		<meeting>the Workshop of the Cross-Language Evaluation Forum for European Languages</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.01925</idno>
		<title level="m">Massively multilingual word embeddings</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Translation invariant word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kejun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Papalexakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The summa platform: A scalable infrastructure for multi-lingual multi-media monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renars</forename><surname>Liepins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guntis</forename><surname>Barzdins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didzis</forename><surname>Gosko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastião</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Nogueira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2018</title>
		<meeting>ACL 2018</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>System Demonstrations</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improved deep embedded clustering with local structure preservation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Optimizing search engines using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><forename type="middle">Joachims</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings ACM SIGKDD</title>
		<meeting>ACM SIGKDD</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Event registry: learning about world events from news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregor</forename><surname>Leban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaz</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janez</forename><surname>Brank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marko</forename><surname>Grobelnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using a model of social dynamics to predict popularity of news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tad</forename><surname>Hogg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The SUMMA platform prototype</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renars</forename><surname>Liepins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guntis</forename><surname>Barzdins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Renals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susanne</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peggy</forename><surname>Van Der Kreeft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Prieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Klejch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Lazaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfonso</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariana</forename><forename type="middle">S C</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Balage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Dwojak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">N</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Giefer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Software Demonstrations of EACL</title>
		<editor>Hina Imran, David Nogueira, Ahmed Ali, Sebastião Miranda, Andrei PopescuBelis, Lesly Miculicich Werlen, Nikos Papasarantopoulos, Abiola Obamuyide, Clive Jones, Fahim Dalvi, Andreas Vlachos, Yang Wang, Sibo Tong, Rico Sennrich, Nikolaos Pappas, Shashi Narayan, Marco Damonte, Nadir Durrani, Sameer Khurana, Ahmed Abdelali, Hassan Sajjad, Stephan Vogel, David Sheppey, Chris Hernon, and Jeff Mitchell</editor>
		<meeting>the Software Demonstrations of EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Turning on the turbo: Fast third-order non-projective turbo parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><forename type="middle">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Fast and faster: A comparison of two streamed matrix decomposition algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radimřehůřekradimˇradimřehůřek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Radimřehůřekradimˇradimřehůřek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sojka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">News across languages-cross-lingual document similarity and event tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Rupnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Muhic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregor</forename><surname>Leban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Primoz</forename><surname>Skraba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaz</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marko</forename><surname>Grobelnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="283" to="316" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distributed document and phrase co-embeddings for descriptive clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Motoki</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Brockmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingting</forename><surname>Kontonatsios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goulermas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Jun&amp;apos;ichi Tsujii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">MediaGist: A cross-lingual analyser of aggregated news and commentaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Steinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
