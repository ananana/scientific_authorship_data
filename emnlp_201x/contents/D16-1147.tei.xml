<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Key-Value Memory Networks for Directly Reading Documents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir-Hossein</forename><surname>Karimi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<postCode>770</postCode>
									<settlement>Broadway, New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Key-Value Memory Networks for Directly Reading Documents</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1400" to="1409"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Directly reading documents and being able to answer questions from them is an unsolved challenge. To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective. Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase. In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation. To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, WIKIMOVIES, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies. Our method reduces the gap between all three settings. It also achieves state-of-the-art results on the existing WIKIQA benchmark.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question answering (QA) has been a long stand- ing research problem in natural language processing, with the first systems attempting to answer questions by directly reading documents <ref type="bibr" target="#b21">(Voorhees and Tice, 2000</ref>). The development of large-scale Knowledge Bases (KBs) such as Freebase ( <ref type="bibr" target="#b4">Bollacker et al., 2008)</ref> helped organize information into structured forms, prompting recent progress to focus on answering questions by converting them into logical forms that can be used to query such databases <ref type="bibr" target="#b3">(Berant et al., 2013;</ref><ref type="bibr" target="#b13">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b11">Fader et al., 2014)</ref>.</p><p>Unfortunately, KBs have intrinsic limitations such as their inevitable incompleteness and fixed schemas that cannot support all varieties of answers. Since information extraction (IE) ( <ref type="bibr" target="#b9">Craven et al., 2000</ref>), in- tended to fill in missing information in KBs, is neither accurate nor reliable enough, collections of raw tex- tual resources and documents such as Wikipedia will always contain more information. As a result, even if KBs can be satisfactory for closed-domain problems, they are unlikely to scale up to answer general ques- tions on any topic. Starting from this observation, in this work we study the problem of answering by directly reading documents.</p><p>Retrieving answers directly from text is harder than from KBs because information is far less struc- tured, is indirectly and ambiguously expressed, and is usually scattered across multiple documents. This explains why using a satisfactory KB-typically only available in closed domains-is preferred over raw text. We postulate that before trying to provide an- swers that are not in KBs, document-based QA sys- tems should first reach KB-based systems' perfor- mance in such closed domains, where clear compari- son and evaluation is possible. To this end, this paper introduces WIKIMOVIES, a new analysis tool that allows for measuring the performance of QA systems when the knowledge source is switched from a KB to unstructured documents. WIKIMOVIES contains ∼100k questions in the movie domain, and was de- signed to be answerable by using either a perfect KB (based on OMDb 1 ), Wikipedia pages or an imper-fect KB obtained through running an engineered IE pipeline on those pages.</p><p>To bridge the gap between using a KB and read- ing documents directly, we still lack appropriate ma- chine learning algorithms. In this work we propose the Key-Value Memory Network (KV-MemNN), a new neural network architecture that generalizes the original Memory Network ( <ref type="bibr" target="#b18">Sukhbaatar et al., 2015)</ref> and can work with either knowledge source. The KV-MemNN performs QA by first storing facts in a key-value structured memory before reasoning on them in order to predict an answer. The memory is designed so that the model learns to use keys to address relevant memories with respect to the ques- tion, whose corresponding values are subsequently returned. This structure allows the model to encode prior knowledge for the considered task and to lever- age possibly complex transforms between keys and values, while still being trained using standard back- propagation via stochastic gradient descent.</p><p>Our experiments on WIKIMOVIES indicate that, thanks to its key-value memory, the KV-MemNN consistently outperforms the original Memory Net- work, and reduces the gap between answering from a human-annotated KB, from an automatically ex- tracted KB or from directly reading Wikipedia. We confirm our findings on WIKIQA ( <ref type="bibr" target="#b26">Yang et al., 2015)</ref>, another Wikipedia-based QA benchmark where no KB is available, where we demonstrate that KV-MemNN can reach state-of-the-art results- surpassing the most recent attention-based neural network models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Early QA systems were based on information re- trieval and were designed to return snippets of text containing an answer <ref type="bibr" target="#b21">(Voorhees and Tice, 2000;</ref><ref type="bibr" target="#b2">Banko et al., 2002</ref>), with limitations in terms of ques- tion complexity and response coverage. The creation of large-scale <ref type="bibr">KBs (Auer et al., 2007;</ref><ref type="bibr" target="#b4">Bollacker et al., 2008</ref>) have led to the development of a new class of QA methods based on semantic parsing <ref type="bibr" target="#b3">(Berant et al., 2013;</ref><ref type="bibr" target="#b13">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b11">Fader et al., 2014;</ref><ref type="bibr" target="#b27">Yih et al., 2015</ref>) that can return precise answers to complicated compositional questions. Due to the sparsity of KB data, however, the main challenge shifts from finding answers to developing efficient information extraction methods to populate KBs auto- matically ( <ref type="bibr" target="#b9">Craven et al., 2000;</ref><ref type="bibr" target="#b7">Carlson et al., 2010)</ref>- not an easy problem.</p><p>For this reason, recent initiatives are returning to the original setting of directly answering from text us- ing datasets like TRECQA ( <ref type="bibr" target="#b22">Wang et al., 2007)</ref>, which is based on classical TREC resources ( <ref type="bibr" target="#b20">Voorhees et al., 1999)</ref>, and WIKIQA ( <ref type="bibr" target="#b26">Yang et al., 2015)</ref>, which is extracted from Wikipedia. Both benchmarks are or- ganized around the task of answer sentence selection, where a system must identify the sentence contain- ing the correct answer in a collection of documents, but need not return the actual answer as a KB-based system would do. Unfortunately, these datasets are very small (hundreds of examples) and, because of their answer selection setting, do not offer the option to directly compare answering from a KB against answering from pure text. Using similar resources as the dialog dataset of <ref type="bibr" target="#b10">Dodge et al. (2016)</ref>, our new benchmark WIKIMOVIES addresses both deficien- cies by providing a substantial corpus of question- answer pairs that can be answered by either using a KB or a corresponding set of documents.</p><p>Even though standard pipeline QA systems like AskMR ( <ref type="bibr" target="#b2">Banko et al., 2002</ref>) have been recently re- visited ( <ref type="bibr" target="#b19">Tsai et al., 2015)</ref>, the best published results on TRECQA and WIKIQA have been obtained by either convolutional neural networks ( <ref type="bibr" target="#b17">Santos et al., 2016;</ref><ref type="bibr" target="#b28">Yin and Schütze, 2015;</ref><ref type="bibr" target="#b23">Wang et al., 2016)</ref> or recurrent neural networks ( <ref type="bibr" target="#b16">Miao et al., 2015</ref>)- both usually with attention mechanisms inspired by ( <ref type="bibr" target="#b1">Bahdanau et al., 2015)</ref>. In this work, we introduce KV-MemNNs, a Memory Network model that oper- ates a symbolic memory structured as (key, value) pairs. Such structured memory is not employed in any existing attention-based neural network architec- ture for QA. As we will show, it gives the model greater flexibility for encoding knowledge sources and helps shrink the gap between directly reading documents and answering from a KB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Key-Value Memory Networks</head><p>The Key-Value Memory Network model is based on the Memory Network (MemNNs) model <ref type="bibr" target="#b18">Sukhbaatar et al., 2015</ref>) which has proven useful for a variety of document read- ing and question answering tasks: for reading chil- dren's books and answering questions about them ( <ref type="bibr" target="#b12">Hill et al., 2016)</ref>, for complex reasoning over sim- ulated stories  and for utilizing KBs to answer questions ( <ref type="bibr" target="#b6">Bordes et al., 2015)</ref>.</p><p>Key-value paired memories are a generalization of the way context (e.g. knowledge bases or docu- ments to be read) are stored in memory. The lookup (addressing) stage is based on the key memory while the reading stage (giving the returned result) uses the value memory. This gives both (i) greater flexibility for the practitioner to encode prior knowledge about their task; and (ii) more effective power in the model via nontrivial transforms between key and value. The key should be designed with features to help match it to the question, while the value should be designed with features to help match it to the response (an- swer). An important property of the model is that the entire model can be trained with key-value trans- forms while still using standard backpropagation via stochastic gradient descent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Description</head><p>Our model is based on the end-to-end Memory Net- work architecture of <ref type="bibr" target="#b18">Sukhbaatar et al. (2015)</ref>. A high-level view of both models is as follows: one defines a memory, which is a possibly very large ar- ray of slots which can encode both long-term and short-term context. At test time one is given a query (e.g. the question in QA tasks), which is used to it- eratively address and read from the memory (these iterations are also referred to as "hops") looking for relevant information to answer the question. At each step, the collected information from the memory is cumulatively added to the original query to build con- text for the next round. At the last iteration, the final retrieved context and the most recent query are com- bined as features to predict a response from a list of candidates. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the KV-MemNN model archi- tecture.</p><p>In KV-MemNNs we define the memory slots as pairs of vectors (k 1 , v 1 ) . . . , (k M , v M ) and denote the question x. The addressing and reading of the memory involves three steps:</p><p>• Key Hashing: the question can be used to pre- select a small subset of the possibly large array. This is done using an inverted index that finds a subset</p><formula xml:id="formula_0">(k h 1 , v h 1 ), . . . , (k h N , v h N )</formula><p>of memories of size N where the key shares at least one word with the question with frequency &lt; F = 1000 (to ignore stop words), following <ref type="bibr" target="#b10">Dodge et al. (2016)</ref>. More sophisticated retrieval schemes could be used here, see e.g. <ref type="bibr" target="#b14">Manning et al. (2008)</ref>,</p><p>• Key Addressing: during addressing, each can- didate memory is assigned a relevance probabil- ity by comparing the question to each key:</p><formula xml:id="formula_1">p h i = Softmax(AΦ X (x) · AΦ K (k h i ))</formula><p>where</p><formula xml:id="formula_2">Φ · are feature maps of dimension D, A is a d × D matrix and Softmax(z i ) = e z i / j e z j .</formula><p>We discuss choices of feature map in Sec. 3.2.</p><p>• Value Reading: in the final reading step, the values of the memories are read by taking their weighted sum using the addressing probabilities, and the vector o is returned:</p><formula xml:id="formula_3">o = i p h i AΦ V (v h i ) .</formula><p>The memory access process is conducted by the "controller" neural network using q = AΦ X (x) as the query. After receiving the result o, the query is updated with q 2 = R 1 (q + o) where R is a d × d matrix. The memory access is then repeated (specifi- cally, only the addressing and reading steps, but not the hashing), using a different matrix R j on each hop, j. The key addressing equation is transformed accordingly to use the updated query:</p><formula xml:id="formula_4">p h i = Softmax(q j+1 AΦ K (k h i )) .</formula><p>The motivation for this is that new evidence can be combined into the query to focus on and retrieve more pertinent information in subsequent accesses. Finally, after a fixed number H hops, the resulting state of the controller is used to compute a final prediction over the possible outputs:</p><formula xml:id="formula_5">ˆ a = argmax i=1,...,C Softmax(q H+1 BΦ Y (y i )</formula><p>) where y i are the possible candidate outputs, e.g. all the entities in the KB, or all possible candidate an- swer sentences in the case of a dataset like WIKIQA (see Sec. 5.2). The d × D matrix B can also be con- strained to be identical to A. The whole network is trained end-to-end, and the model learns to perform the iterative accesses to output the desired target a by minimizing a standard cross-entropy loss betweenâ betweenˆbetweenâ and the correct answer a. Backpropagation and stochastic gradient descent are thus used to learn the matrices A, B and R 1 , . . . , R H .</p><p>To obtain the standard End-To-End Memory Net- work of <ref type="bibr" target="#b18">Sukhbaatar et al. (2015)</ref> one can simply set the key and value to be the same for all memories. Hashing was not used in that paper, but is important for computational efficiency for large memory sizes, as already shown in <ref type="bibr" target="#b10">Dodge et al. (2016)</ref>. We will now go on to describe specific applications of key-value memories for the task of reading KBs or documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Key-Value Memories</head><p>There are a variety of ways to employ key-value mem- ories that can have important effects on overall per- formance. The ability to encode prior knowledge in this way is an important component of KV-MemNNs, and we are free to define Φ X , Φ Y , Φ K and Φ V for the query, answer, keys and values respectively. We now describe several possible variants of Φ K and Φ V that we tried in our experiments, for simplicity we kept Φ X and Φ Y fixed as bag-of-words representations.</p><p>KB Triple Knowledge base entries have a structure of triple "subject relation object" (see <ref type="table" target="#tab_1">Table 1</ref> for ex- amples). The representation we consider is simple: the key is composed of the left-hand side entity (sub- ject) and the relation, and the value is the right-hand side entity (object). We double the KB and consider the reversed relation as well (e.g. we now have two triples "Blade Runner directed_by Ridley Scott" and "Ridley Scott !directed_by Blade Runner" where !di- rected_by is a different entry in the dictionary than directed_by). Having the entry both ways round is important for answering different kinds of questions ("Who directed Blade Runner?" vs. "What did Rid- ley Scott direct?"). For a standard MemNN that does not have key-value pairs the whole triple has to be encoded into the same memory slot.</p><p>Sentence Level For representing a document, one can split it up into sentences, with each memory slot encoding one sentence. Both the key and the value encode the entire sentence as a bag-of-words. As the key and value are the same in this case, this is identical to a standard MemNN and this approach has been used in several papers ( <ref type="bibr" target="#b25">Weston et al., 2016;</ref><ref type="bibr" target="#b10">Dodge et al., 2016)</ref>.</p><p>Window Level Documents are split up into win- dows of W words; in our tasks we only include win- dows where the center word is an entity. Windows are represented using bag-of-words. Window represen- tations for MemNNs have been shown to work well previously ( <ref type="bibr" target="#b12">Hill et al., 2016)</ref>. However, in Key-Value MemNNs we encode the key as the entire window, and the value as only the center word, which is not possible in the MemNN architecture. This makes sense because the entire window is more likely to be pertinent as a match for the question (as the key), whereas the entity at the center is more pertinent as a match for the answer (as the value). We will compare these approaches in our experiments.</p><p>Window + Center Encoding Instead of represent- ing the window as a pure bag-of-words, thus mixing the window center with the rest of the window, we can also encode them with different features. Here, we double the size, D, of the dictionary and encode the center of the window and the value using the sec- ond dictionary. This should help the model pick out the relevance of the window center (more related to the answer) as compared to the words either side of it (more related to the question).</p><p>Window + Title The title of a document is com- monly the answer to a question that relates to the text it contains. For example "What did Harrison Ford star in?" can be (partially) answered by the Wikipedia document with the title "Blade Runner". For this reason, we also consider a representation where the key is the word window as before, but the value is the document title. We also keep all the standard (window, center) key-value pairs from the window-level representation as well, thus doubling the number of memory slots in comparison. To dif- ferentiate the two keys with different values we add an extra feature "_window_" or "_title_" to the key, depending on the value. The "_title_" version also includes the actual movie title in the key. This rep- resentation can be combined with center encoding. Note that this representation is inherently specific to datasets in which there is an apparent or meaningful title for each document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The WikiMovies Benchmark</head><p>The </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Knowledge Representations</head><p>We construct three forms of knowledge representa- tion: (i) Doc: raw Wikipedia documents consisting of the pages of the movies mentioned; (ii) KB: a clas- sical graph-based KB consisting of entities and rela- tions created from the Open Movie Database (OMDb) and MovieLens; and (iii) IE: information extraction performed on the Wikipedia pages to build a KB in a similar form as (ii). We take care to construct</p><note type="other">Doc: Wikipedia Article for Blade Runner (partially shown)</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Blade Runner is a 1982 American neo-noir dystopian science fiction film directed by Ridley Scott and starring Harrison Ford, Rutger Hauer, Sean Young, and Edward James Olmos. The screenplay, written by Hampton Fancher and David Peoples, is a modified film adaptation of the 1968 novel "Do Androids Dream of Electric Sheep?" by Philip K. Dick. The film depicts a dystopian Los Angeles in November 2019 in which</head><p>genetically engineered replicants, which are visually indistinguishable from adult humans, are manufactured by the powerful Tyrell Corporation as well as by other "mega-corporations" around the world. Their use on Earth is banned and replicants are exclusively used for dangerous, menial, or leisure work on off-world colonies. Replicants who defy the ban and return to Earth are hunted down and "retired" by special police operatives known as "Blade Runners". . . .   QA pairs such that they are all potentially answerable from either the KB from (ii) or the original Wikipedia documents from (i) to eliminate data sparsity issues. However, it should be noted that the advantage of working from raw documents in real applications is that data sparsity is less of a concern than for a KB, while on the other hand the KB has the information already parsed in a form amenable to manipulation by machines. This dataset can help analyze what methods we need to close the gap between all three settings, and in particular what are the best methods for reading documents when a KB is not available. A sample of the dataset is shown in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>Doc We selected a set of Wikipedia articles about movies by identifying a set of movies from OMDb 2 that had an associated article by title match. We keep the title and the first section (before the contents box) for each article. This gives ∼17k documents (movies) which comprise the set of documents our models will read from in order to answer questions. KB Our set of movies were also matched to the MovieLens dataset <ref type="bibr">3</ref> . We built a KB using OMDb and MovieLens metadata with entries for each movie and nine different relation types: director, writer, ac- tor, release year, language, genre, tags, IMDb rating and IMDb votes, with ∼10k related actors, ∼6k di- rectors and ∼43k entities in total. The KB is stored as triples; see <ref type="table" target="#tab_1">Table 1</ref> for examples. IMDb ratings and votes are originally real-valued but are binned and converted to text ("unheard of", "unknown", "well known", "highly watched", "famous"). We finally only retain KB triples where the entities also appear in the Wikipedia articles 4 to try to guarantee that all QA pairs will be equally answerable by either the KB or Wikipedia document sources.</p><p>IE As an alternative to directly reading documents, we explore leveraging information extraction tech- niques to transform documents into a KB format. An IE-KB representation has attractive properties such as more precise and compact expressions of facts and logical key-value pairings based on subject- verb-object groupings. This can come at the cost of lower recall due to malformed or completely missing triplets. For IE we use standard open-source soft- ware followed by some task-specific engineering to improve the results. We first employ coreference res- olution via the Stanford NLP Toolkit ( <ref type="bibr" target="#b15">Manning et al., 2014)</ref> to reduce ambiguity by replacing pronominal ("he", "it") and nominal ("the film") references with their representative entities. Next we use the SENNA semantic role labeling tool <ref type="bibr" target="#b8">(Collobert et al., 2011</ref>) to uncover the grammatical structure of each sentence and pair verbs with their arguments. Each triplet is cleaned of words that are not recognized entities, and lemmatization is done to collapse different inflec- tions of important task-specific verbs to one form (e.g. stars, starring, star → starred). Finally, we append the movie title to each triple similar to the "Window + Title" representation of Sec. 3.2, which improved results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Question-Answer Pairs</head><p>Within the dataset's more than 100,000 question- answer pairs, we distinguish 13 classes of question <ref type="bibr">Method KB IE Doc (Bordes et al., 2014</ref>) QA system 93.5 56.5 N/A Supervised Embeddings 54.4 54.4 54.4 Memory Network 78.5 63.4 69.9 Key-Value Memory Network 93.9 68.3 76.2  <ref type="table">Table 3</ref>: Development set performance (% hits@1) with differ- ent document memory representations for KV-MemNNs.</p><p>corresponding to different kinds of edges in our KB. They range in scope from specific-such as actor to movie: "What movies did Harrison Ford star in?" and movie to actors: "Who starred in Blade Runner?"-to more general, such as tag to movie: "Which films can be described by dystopian?"; see <ref type="table" target="#tab_3">Table 4</ref> for the full list. For some question there can be multiple correct answers.</p><p>Using SimpleQuestions ( <ref type="bibr" target="#b6">Bordes et al., 2015)</ref>, an existing open-domain question answering dataset based on Freebase, we identified the subset of ques- tions posed by human annotators that covered our question types. We created our question set by sub- stituting the entities in those questions with entities from all of our KB triples. For example, if the orig- inal question written by an annotator was "What movies did Harrison Ford star in?", we created a pattern "What movies did [@actor] star in?", which we substitute for any other actors in our set, and re- peat this for all annotations. We split the questions into disjoint training, development and test sets with ∼96k, 10k and 10k examples, respectively. The same question (even worded differently) cannot appear in both train and test sets. Note that this is much larger than most existing datasets; for example, the WIK- IQA dataset <ref type="bibr" target="#b26">(Yang et al., 2015</ref>) for which we also conduct experiments in Sec. 5.2 has only ∼1000 training pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>This section describes our experiments on WIKI- MOVIES and WIKIQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">WikiMovies</head><p>We conducted experiments on the WIKI- MOVIES dataset described in Sec. 4. Our main goal is to compare the performance of KB, IE and Wikipedia (Doc) sources when trying varying learning methods. We compare four approaches: (i) the QA system of <ref type="bibr" target="#b5">Bordes et al. (2014)</ref> that performs well on existing datasets WebQuestions ( <ref type="bibr" target="#b3">Berant et al., 2013</ref>) and SimpleQuestions ( <ref type="bibr" target="#b6">Bordes et al., 2015</ref>) that use KBs only; (ii) supervised embeddings that do not make use of a KB at all but learn question-to-answer embeddings directly and hence act as a sanity check ( <ref type="bibr" target="#b10">Dodge et al., 2016)</ref>; (iii) Memory Networks; and (iv) Key-Value Memory Networks. Performance is reported using the accuracy of the top hit (single answer) over all possible answers (all entities), i.e. the hits@1 metric measured in percent. In all cases hyperparameters are optimized on the development set, including the memory representations of Sec. 3.2 for MemNNs and KV-MemNNs. As MemNNs do not support key-value pairs, we concatenate key and value together when they differ instead.</p><p>The main results are given in <ref type="table" target="#tab_2">Table 2</ref>. The QA system of <ref type="bibr" target="#b5">Bordes et al. (2014)</ref> outperforms Super- vised Embeddings and Memory Networks for KB and IE-based KB representations, but is designed to work with a KB, not with documents (hence the N/A in that column). However, Key-Value Memory Networks outperform all other methods on all three data source types. Reading from Wikipedia docu- ments directly (Doc) outperforms an IE-based KB (IE), which is an encouraging result towards auto- mated machine reading though a gap to a human- annotated KB still remains (93.9 vs. 76.2). The best memory representation for directly reading doc- uments uses "Window-level + Center Encoding + Title" (W = 7 and H = 2); see <ref type="table">Table 3</ref> for a compar- ison of results for different representation types. Both center encoding and title features help the window- level representation, while sentence-level is inferior.    to Doc (and KB) on Writer, Director and Actor to Movie, perhaps because coreference is difficult in these cases -although it has other losses elsewhere too. Note that only 56% of subject-object pairs in IE match the triples in the original KB, so losses are expected. Doc loses out to KB particularly on Tag to Movie, Movie to Tags, Movie to Writer and Movie to Actors. Tag questions are hard because they can ref- erence more or less any word in the entire Wikipedia document; see <ref type="table" target="#tab_1">Table 1</ref>. Movie to Writer/Actor are hard because there is likely only one or a few refer- ences to the answer across all documents, whereas for Writer/Actor to Movie there are more possible answers to find.</p><p>KB vs. Synthetic Document Analysis To further understand the difference between using a KB versus reading documents directly, we conducted an exper- iment where we constructed synthetic documents using the KB. For a given movie, we use a simple grammar to construct a synthetic "Wikipedia" doc-Method MAP MRR Word Cnt 0.4891 0.4924 Wgt Word Cnt 0.5099 0.5132 2-gram CNN ( <ref type="bibr" target="#b26">Yang et al., 2015)</ref> 0.6520 0.6652 AP-CNN ( <ref type="bibr" target="#b17">Santos et al., 2016)</ref> 0.6886 0.6957 Attentive LSTM ( <ref type="bibr" target="#b16">Miao et al., 2015)</ref> 0.6886 0.7069 Attentive CNN ( <ref type="bibr" target="#b28">Yin and Schütze, 2015)</ref> 0.6921 0.7108 L.D.C. ( <ref type="bibr" target="#b23">Wang et al., 2016)</ref> 0.7058 0.7226 Memory Network 0.5170 0.5236 Key-Value Memory Network 0.7069 0.7265 ument based on the KB triples: for each relation type we have a set of template phrases (100 in to- tal) used to generate the fact, e.g. "Blade Runner came out in 1982" for the entry BLADE RUNNER RELEASE_YEAR 1982. We can then parameterize the complexity of our synthetic documents: (i) using one template, or all of them; (ii) using conjunctions to combine facts into single sentences or not; and (iii) using coreference between sentences where we replace the movie name with "it". <ref type="bibr">5</ref> The purpose of this experiment is to find which aspects are responsi- ble for the gap in performance to a KB. The results are given in <ref type="table" target="#tab_5">Table 5</ref>. They indicate that some of the loss (93.9% for KB to 82.9% for One Template Sen- tence) in performance is due directly to representing in sentence form, making the subject, relation and object harder to extract. Moving to a larger number of templates does not deteriorate performance much (80%). The remaining performance drop seems to be split roughly equally between conjunctions (74%) and coreference (76%). The hardest synthetic dataset combines these (All Templates + Conj. + Coref.) and is actually harder than using the real Wikipedia documents (72.5% vs. 76.2%). This is possibly be- cause the amount of conjunctions and coreferences we make are artificially too high (50% and 80% of the time, respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">WikiQA</head><p>WIKIQA ( <ref type="bibr" target="#b26">Yang et al., 2015</ref>) is an existing dataset for answer sentence selection using Wikipedia as the knowledge source. The task is, given a ques- tion, to select the sentence coming from a Wikipedia document that best answers the question, where per- formance is measured using mean average preci-sion (MAP) and mean reciprocal rank (MRR) of the ranked set of answers. The dataset uses a pre-built information retrieval step and hence provides a fixed set of candidate sentences per question, so systems do not have to consider ranking all of Wikipedia. In contrast to WIKIMOVIES, the training set size is small (∼1000 examples) while the topic is much more broad (all of Wikipedia, rather than just movies) and the questions can only be answered by reading the documents, so no comparison to the use of KBs can be performed. However, a wide range of methods have already been tried on WIKIQA, thus providing a useful benchmark to test if the same results found on WIKIMOVIES carry across to WIKIQA, in particular the performance of Key-Value Memory Networks.</p><p>Due to the size of the training set, following many other works <ref type="bibr" target="#b26">(Yang et al., 2015;</ref><ref type="bibr" target="#b17">Santos et al., 2016;</ref><ref type="bibr" target="#b16">Miao et al., 2015)</ref> we pre-trained the word vectors (matrices A and B which are constrained to be iden- tical) before training KV-MemNNs. We employed Supervised Embeddings ( <ref type="bibr" target="#b10">Dodge et al., 2016)</ref> for that goal, training on all of Wikipedia while treating the input as a random sentence and the target as the subse- quent sentence. We then trained KV-MemNNs with dropout regularization: we sample words from the question, memory representations and the answers, choosing the dropout rate using the development set. Finally, again following other successful methods <ref type="bibr" target="#b28">(Yin and Schütze, 2015)</ref>, we combine our approach with exact matching word features between question and answers. Key hashing was not used as candidates were already pre-selected. To represent the memo- ries, we used the Window-Level representation (the best choice on the dev set was W = 7) as the key and the whole sentence as the value, as the value should match the answer which in this case is a sen- tence. Additionally, in the representation all numbers in the text and the phrase "how many" in the question were replaced with the feature "_number_". The best choice of hops was also H = 2 for KV-MemNNs.</p><p>The results are given in <ref type="table" target="#tab_6">Table 6</ref>. Key-Value Mem- ory Networks outperform a large set of other methods, although the results of the L.D.C. method of ( <ref type="bibr" target="#b23">Wang et al., 2016)</ref> are very similar. Memory Networks, which cannot easily pair windows to sentences, per- form much worse, highlighting the importance of key-value memories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We studied the problem of directly reading docu- ments in order to answer questions, concentrating our analysis on the gap between such direct methods and using human-annotated or automatically con- structed KBs. We presented a new model, Key-Value Memory Networks, which helps bridge this gap, out- performing several other methods across two datasets, WIKIMOVIES and WIKIQA. However, some gap in performance still remains. WIKIMOVIES serves as an analysis tool to shed some light on the causes. Future work should try to close this gap further.</p><p>Key-Value Memory Networks are versatile models for reading documents or KBs and answering ques- tions about them-allowing to encode prior knowl- edge about the task at hand in the key and value memories. These models could be applied to storing and reading memories for other tasks as well, and future work should try them in other domains, such as in a full dialog setting.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Key-Value Memory Network model for question answering. See Section 3 for details.</figDesc><graphic url="image-1.png" coords="3,72.00,57.82,468.00,161.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>WIKIMOVIES benchmark consists of question- answer pairs in the domain of movies. It was built with the following goals in mind: (i) machine learn- ing techniques should have ample training examples for learning; and (ii) one can analyze easily the perfor- mance of different representations of knowledge and break down the results by question type. The dataset can be downloaded from http://fb.ai/babi.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>QA Breakdown A breakdown by question type comparing the different data sources for KV- MemNNs is given in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>entries for Blade Runner (subset) Blade Runner directed_by Ridley Scott Blade Runner written_by Philip K. Dick, Hampton Fancher Blade Runner starred_actors Harrison Ford, Sean Young, . . . Blade Runner release_year 1982 Blade Runner has_tags dystopian, noir, police, androids, . . . IE entries for Blade Runner (subset) Blade Runner, Ridley Scott directed dystopian, science fiction, film Hampton Fancher written Blade Runner Blade Runner starred Harrison Ford, Rutger Hauer, Sean Young. . . Blade Runner labelled 1982 neo noir special police, Blade retired Blade Runner Blade Runner, special police known Blade Questions for Blade Runner (subset) Ridley Scott directed which films? What year was the movie Blade Runner released? Who is the writer of the film Blade Runner? Which films can be described by dystopian? Which movies was Philip K. Dick the writer of? Can you describe movie Blade Runner in a few words?</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>WIKIMOVIES: Questions, Doc, KB and IE sources.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Test results (% hits@1) on WIKIMOVIES, comparing</head><label>2</label><figDesc></figDesc><table>human-annotated KB (KB), information extraction-based KB 

(IE), and directly reading Wikipedia documents (Doc). 

Memory Representation 
Doc 
Sentence-level 
52.4 
Window-level 
66.8 
Window-level + Title 
74.1 
Window-level + Center Encoding + Title 76.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 . IE loses out especially</head><label>4</label><figDesc></figDesc><table>Question Type 
KB IE Doc 
Writer to Movie 
97 72 91 
Tag to Movie 
85 35 49 
Movie to Year 
95 75 89 
Movie to Writer 
95 61 64 
Movie to Tags 
94 47 48 
Movie to Language 
96 62 84 
Movie to IMDb Votes 
92 92 92 
Movie to IMDb Rating 94 75 92 
Movie to Genre 
97 84 86 
Movie to Director 
93 76 79 
Movie to Actors 
91 64 64 
Director to Movie 
90 78 91 
Actor to Movie 
93 66 83 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 4 : Breakdown of test results (% hits@1) on WIKI-</head><label>4</label><figDesc></figDesc><table>MOVIES for Key-Value Memory Networks using different knowl-

edge representations. 

Knowledge Representation 
KV-MemNN 
KB 
93.9 
One Template Sentence 
82.9 
All Templates Sentences 
80.0 
One Template + Coreference 
76.0 
One Template + Conjunctions 
74.0 
All Templates + Conj. + Coref. 
72.5 
Wikipedia Documents 
76.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Analysis of test set results (% hits@1) for KB vs. 

Synthetic Docs on WIKIMOVIES. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Test results on WikiQA. 

</table></figure>

			<note place="foot" n="1"> http://www.omdbapi.com</note>

			<note place="foot" n="2"> http://beforethecode.com/projects/omdb/download.aspx</note>

			<note place="foot" n="3"> http://grouplens.org/datasets/movielens/ 4 The dataset also includes the slightly larger version without this constraint.</note>

			<note place="foot" n="5"> This data is also part of the WIKIMOVIES benchmark.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dbpedia: A nucleus for a web of open data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic Web Conference</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Askmsr: Question answering using the worldwide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium on Mining Answers from Texts and Knowledge Bases</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD International Conference on Management of Data</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Question answering with subgraph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weston</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weston</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02075</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Toward an architecture for never-ending language learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Betteridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning to construct knowledge bases from the world wide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dipasquo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Slattery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="69" to="113" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Evaluating prerequisite qualities for learning endto-end dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weston</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Open question answering over curated and extracted knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The goldilocks principle: Reading children&apos;s books with explicit memory representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weston</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Introduction to Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL: System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06038</idno>
		<title level="m">Neural variational inference for text processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.03609</idno>
		<title level="m">Attentive pooling networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fergus</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Webbased question answering: Revisiting askmsr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<idno>MSR-TR-2015- 20</idno>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Microsoft Research</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The trec-8 question answering track report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<editor>Trec</editor>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Building a question answering test collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Tice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">What is the jeopardy model? a quasi-synchronous grammar for qa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ittycheriah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.07019</idno>
		<title level="m">Sentence similarity learning by lexical decomposition and composition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards ai-complete question answering: a set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Wikiqa: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semantic parsing via staged query graph generation: Question answering with knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Convolutional neural network for paraphrase identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NACL: Human Language Technologies</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
