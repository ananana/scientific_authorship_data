<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Does String-Based Neural MT Learn Source Syntax?</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>November 1-5, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Shi</surname></persName>
							<email>xingshi@isi.edu, ipadhi@usc.edu, knight@isi.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences Institute &amp; Computer Science Department</orgName>
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkit</forename><surname>Padhi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences Institute &amp; Computer Science Department</orgName>
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences Institute &amp; Computer Science Department</orgName>
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Does String-Based Neural MT Learn Source Syntax?</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1526" to="1534"/>
							<date type="published">November 1-5, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We investigate whether a neural, encoder-decoder translation system learns syntactic information on the source side as a by-product of training. We propose two methods to detect whether the encoder has learned local and global source syntax. A fine-grained analysis of the syntactic structure learned by the encoder reveals which kinds of syntax are learned and which are missing.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The sequence to sequence model (seq2seq) has been successfully applied to neural machine translation (NMT) <ref type="bibr" target="#b24">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b3">Cho et al., 2014)</ref> and can match or surpass MT state-of-art. Non- neural machine translation systems consist chiefly of phrase-based systems ( <ref type="bibr" target="#b13">Koehn et al., 2003)</ref> and syntax-based systems ( <ref type="bibr" target="#b6">Galley et al., 2004;</ref><ref type="bibr" target="#b7">Galley et al., 2006;</ref><ref type="bibr" target="#b5">DeNeefe et al., 2007;</ref><ref type="bibr" target="#b18">Liu et al., 2011;</ref><ref type="bibr" target="#b4">Cowan et al., 2006</ref>), the latter of which adds syntac- tic information to source side (tree-to-string), target side (string-to-tree) or both sides (tree-to-tree). As the seq2seq model first encodes the source sentence into a high-dimensional vector, then decodes into a target sentence, it is hard to understand and interpret what is going on inside such a procedure. Consider- ing the evolution of non-neural translation systems, it is natural to ask:</p><p>1. Does the encoder learn syntactic information about the source sentence? 2. What kind of syntactic information is learned, and how much?</p><p>3. Is it useful to augment the encoder with addi- tional syntactic information? In this work, we focus on the first two questions and propose two methods:</p><p>• We create various syntactic labels of the source sentence and try to predict these syntactic la- bels with logistic regression, using the learned sentence encoding vectors (for sentence-level labels) or learned word-by-word hidden vectors (for word-level label). We find that the encoder captures both global and local syntactic infor- mation of the source sentence, and different in- formation tends to be stored at different layers.</p><p>• We extract the whole constituency tree of source sentence from the NMT encoding vec- tors using a retrained linearized-tree decoder. A deep analysis on these parse trees indicates that much syntactic information is learned, while various types of syntactic information are still missing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Example</head><p>As a simple example, we train an English-French NMT system on 110M tokens of bilingual data (En- glish side). We then take 10K separate English sen- tences and label their voice as active or passive. We use the learned NMT encoder to convert these sen- tences into 10k corresponding 1000-dimension en- coding vectors. We use 9000 sentences to train a logistic regression model to predict voice using the encoding cell states, and test on the other 1000 sen- tences. We achieve 92.8% accuracy <ref type="table">(Table 2)</ref>, far above the majority class baseline (82.8%). This means that in reducing the source sentence to a Model Accuracy Majority Class 82.8 English to <ref type="bibr">French (E2F)</ref> 92.8 English to English (E2E) 82.7 fixed-length vector, the NMT system has decided to store the voice of English sentences in an easily ac- cessible way.</p><p>When we carry out the same experiment on an English-English (auto-encoder) system, we find that English voice information is no longer easily ac- cessed from the encoding vector. We can only pre- dict it with 82.7% accuracy, no better than chance. Thus, in learning to reproduce input English sen- tences, the seq2seq model decides to use the fixed- length encoding vector for other purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related work</head><p>Interpreting Recurrent Neural Networks. The most popular method to visualize high-dimensional vectors, such as word embeddings, is to project them into two-dimensional space using t-SNE (van der <ref type="bibr" target="#b25">Maaten and Hinton, 2008)</ref>. Very few works try to interpret recurrent neural networks in NLP. <ref type="bibr" target="#b10">Karpathy et al. (2016)</ref> use a character-level LSTM lan- guage model as a test-bed and find several activation cells that track long-distance dependencies, such as line lengths and quotes. They also conduct an er- ror analysis of the predictions.  ex- plore the syntactic behavior of an RNN-based sen- timent analyzer, including the compositionality of negation, intensification, and concessive clauses, by plotting a 60-dimensional heat map of hidden unit values. They also introduce a first-order derivative based method to measure each unit's contribution to the final decision. Verifying syntactic/semantic properties. Several works try to build a good distributional representa- tion of sentences or paragraph ( <ref type="bibr" target="#b23">Socher et al., 2013;</ref><ref type="bibr" target="#b9">Kalchbrenner et al., 2014;</ref><ref type="bibr" target="#b11">Kim, 2014;</ref><ref type="bibr" target="#b28">Zhao et al., 2015;</ref><ref type="bibr" target="#b16">Le and Mikolov, 2014;</ref><ref type="bibr" target="#b12">Kiros et al., 2015)</ref>. They implicitly verify the claimed syntac- tic/semantic properties of learned representations by applying them to downstream classification tasks such as sentiment analysis, sentence classification, semantic relatedness, paraphrase detection, image- sentence ranking, question-type classification, etc.</p><p>Novel contributions of our work include:</p><p>• We locate a subset of activation cells that are responsible for certain syntactic labels. We ex- plore the concentration and layer distribution of different syntactic labels.</p><p>• We extract whole parse trees from NMT encod- ing vectors in order to analyze syntactic prop- erties directly and thoroughly.</p><p>• Our methods are suitable for large scale mod- els. The models in this work are 2-layer 1000- dimensional LSTM seq2seq models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Datasets and models</head><p>We train two NMT models, English-French (E2F) and English-German (E2G). To answer whether these translation models' encoders to learn store syntactic information, and how much, we employ two benchmark models:</p><p>• An upper-bound model, in which the encoder learns quite a lot of syntactic information. For the upper bound, we train a neural parser that learns to "translate" an English sentence to its linearized constitutional tree (E2P), following <ref type="bibr" target="#b26">Vinyals et al. (2015)</ref>.</p><p>• An lower-bound model, in which the encoder learns much less syntactic information. For the lower bound, we train two sentence auto- encoders: one translates an English sentence to itself (E2E), while the other translates a per- muted English sentence to itself (PE2PE). We already had an indication above (Section 2) that a copying model does not necessarily need to remember a sentence's syntactic structure. <ref type="figure" target="#fig_0">Figure 1</ref> shows sample inputs and outputs of the E2E, PE2PE, E2F, E2G, and E2P models.</p><p>We use English-French and English-German data from WMT2014 ( <ref type="bibr" target="#b0">Bojar et al., 2014</ref>). We take 4M English sentences from the English-German data to train E2E and PE2PE. For the neural parser (E2P), we construct the training corpus following the recipe of <ref type="bibr" target="#b26">Vinyals et al. (2015</ref>  <ref type="table">Table 2</ref>: Model settings and test-set BLEU-n4r1 scores ( <ref type="bibr" target="#b20">Papineni et al., 2002</ref>). ( <ref type="bibr" target="#b22">Pradhan and Xue, 2009</ref>) and the English Web Tree- bank ( <ref type="bibr" target="#b21">Petrov and McDonald, 2012)</ref>. In addition to these gold treebanks, we take 4M English sentences from English-German data and 4M English sen- tences from English-French data, and we parse these 8M sentences with the Charniak-Johnson parser 1 <ref type="bibr" target="#b2">(Charniak and Johnson, 2005</ref>). We call these 8,162K pairs the CJ corpus. We use WSJ Section 22 as our development set and section 23 as the test set, where we obtain an F1-score of 89.6, competitive with the previously-published 90.5 <ref type="table" target="#tab_4">(Table 4)</ref>. Model Architecture.</p><p>For all experiments 2 , we use a two-layer encoder-decoder with long short-term memory (LSTM) units <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997</ref>  For auto-encoders and translation models, we train 8 epochs. The learning rate is initially set as 0.35 and starts to halve after 6 epochs. For E2P model, we train 15 epochs. The learning rate is initialized as 0.35 and starts to decay by 0.7 once the perplexity on a development set starts to increase. All parame- ters are re-scaled when the global norm is larger than 5. All models are non-attentional, because we want the encoding vector to summarize the whole source sentence. <ref type="table" target="#tab_4">Table 4</ref> shows the settings of each model and reports the BLEU scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Syntactic Label Prediction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>In this section, we test whether different seq2seq systems learn to encode syntactic information about the source (English) sentence. With 1000 hidden states, it is impractical to in- vestigate each unit one by one or draw a heat map of the whole vector. Instead, we use the hidden states to predict syntactic labels of source sentences via lo- gistic regression. For multi-class prediction, we use a one-vs-rest mechanism. Furthermore, to identify a subset of units responsible for certain syntactic la- bels, we use the recursive feature elimination (RFE) strategy: the logistic regression is first trained using <ref type="table" target="#tab_0">Label Train Test   Number  of  classes   Most  frequent  label  Voice 9000 1000  2  Active  Tense 9000 1000  2  Non-past  TSS  9000 1000  20  NP-VP  POS 87366 9317  45  NN  SPC 81292 8706</ref> 24 NP  all 1000 hidden states, after which we recursively prune those units whose weights' absolute values are smallest. We extract three sentence-level syntactic labels: 1. Voice: active or passive. 2. Tense: past or non-past. 3. TSS: Top level syntactic sequence of the con- stituent tree. We use the most frequent 19 se- quences ("NP-VP", "PP-NP-VP", etc.) and la- bel the remainder as "Other". and two word-level syntactic labels:</p><p>1. POS: Part-of-speech tags for each word. 2. SPC: The smallest phrase constituent that above each word. Both voice and tense labels are generated using rule-based systems based on the constituent tree of the sentence. <ref type="figure" target="#fig_1">Figure 2</ref> provides examples of our five syntactic labels. When predicting these syntactic labels using corresponding cell states, we split the dataset into training and test sets. <ref type="table" target="#tab_4">Table 4</ref> shows statistics of each labels.</p><p>For a source sentence s, s = [w 1 , ..., w i , ..., w n ] the two-layer encoder will generate an array of cell vectors c during encoding, c = <ref type="figure" target="#fig_0">[(c 1,0 , c 1,1 )</ref>, ..., <ref type="figure" target="#fig_0">(c i,0 , c i,1 )</ref>, ..., (c n,0 , c n,1 )] We extract a sentence-level syntactic label L s , and predict it using the encoding cell states that will be fed into the decoder:</p><formula xml:id="formula_0">L s = g(c n,0 ) or L s = g(c n,1 )</formula><p>where g(·) is the logistic regression.</p><p>Similarly, for extracting word-level syntactic la- bels:</p><formula xml:id="formula_1">L w = [L w1 , ..., L wi , ..., L wn ]</formula><p>we predict each label L wi using the cell states im- mediately after encoding the word w i :</p><formula xml:id="formula_2">L wi = g(c i,0 ) or L W i = g(c i,1 )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Result Analysis</head><p>Test-set prediction accuracy is shown in <ref type="figure" target="#fig_2">Figure 3</ref>. For voice and tense, the prediction accuracy of two auto-encoders is almost same as the accuracy of ma- jority class, indicating that their encoders do not learn to record this information. By contrast, both the neural parser and the NMT systems achieve ap- proximately 95% accuracy. When predicting the top-level syntactic sequence (TSS) of the whole sen- tence, the Part-of-Speech tags (POS), and small- est phrase constituent (SPC) for each word, all five models achieve an accuracy higher than that of ma- jority class, but there is still a large gap between the accuracy of NMT systems and auto-encoders. These observations indicate that the NMT encoder learns significant sentence-level syntactic information-it can distinguish voice and tense of the source sen- tence, and it knows the sentence's structure to some extent. At the word level, the NMT's encoder also tends to cluster together the words that have similar POS and SPC labels.</p><p>Different syntactic information tends to be stored at different layers in the NMT models. For word- level syntactic labels, POS and SPC, the accuracy of the lower layer's cell states (C0) is higher than that of the upper level (C1  labels, especially tense, the accuracy of C1 is larger than C0. This suggests that the local features are somehow preserved in the lower layer whereas more global, abstract information tends to be stored in the upper layer.</p><p>For two-classes labels, such as voice and tense, the accuracy gap between all units and top-10 units is small. For other labels, where we use a one- versus-rest strategy, the gap between all units and top-10 units is large. However, when predicting POS, the gap of neural parser (E2P) on the lower layer (C0) is much smaller. This comparison in- dicates that a small subset of units explicitly takes charge of POS tags in the neural parser, whereas for NMT, the POS info is more distributed and implicit.</p><p>There are no large differences between encoders of E2F and E2G regarding syntactic information. When training E2F2P, we only update the parameters of lin- earized tree decoder, keeping the English encoder's parameters fixed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Extract Syntactic Trees from Encoder</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head><p>We now turn to whether NMT systems capture deeper syntactic structure as a by-product of learn- ing to translate from English to another language. We do this by predicting full parse trees from the in- formation stored in encoding vectors. Since this is a structured prediction problem, we can no longer use logistic regression. Instead, we extract a con- stituency parse tree from the encoding vector of a model E2X by using a new neural parser E2X2P with the following steps:</p><p>1. Take the E2X encoder as the encoder of the new model E2X2P. 2. Initialize the E2X2P decoder parameters with a uniform distribution. 3. Fine-tune the E2X2P decoder (while keeping its encoder parameters fixed), using the CJ cor- pus, the same corpus used to train E2P . <ref type="figure" target="#fig_3">Figure 4</ref> shows how we construct model E2F2P from model E2F. For fine-tuning, we use the same dropout rate and learning rate updating configura- tion for E2P as described in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation</head><p>We train four new neural parsers using the encoders of the two auto-encoders and the two NMT models respectively. We use three tools to evaluate and ana- lyze:</p><p>1. The EVALB tool 3 to calculate the labeled bracketing F1-score. 2. The zxx package 4 to calculate Tree edit dis- tance (TED) ( <ref type="bibr" target="#b27">Zhang and Shasha, 1989</ref>). 3. The Berkeley Parser Analyser <ref type="bibr">5 (Kummerfeld et al., 2012</ref>) to analyze parsing error types. The linearized parse trees generated by these neu- ral parsers are not always well-formed. They can be split into the following categories:</p><p>• Malformed trees: The linearized sequence can not be converted back into a tree, due to miss- ing or mismatched brackets.</p><p>• Well-formed trees: The sequence can be con- verted back into a tree. Tree edit distance can be calculated on this category.</p><p>-Wrong length trees: The number of tree leaves does not match the number of source-sentence tokens. -Correct length trees: The number of tree leaves does match the number of source- sentence tokens. Before we move to results, we emphasize the fol- lowing points:</p><p>First, compared to the linear classifier used in Sec- tion 5, the retrained decoder for predicting a lin- earized parse tree is a highly non-linear method. The syntactic prediction/parsing performance will increase due to such non-linearity. Thus, we do not make conclusions based only on absolute per- formance values, but also on a comparison against the designed baseline models. An improvement over the lower bound models indicates that the encoder learns syntactic information, whereas a decline from the upper bound model shows that the encoder loses certain syntactic information.</p><p>Second, the NMT's encoder maps a plain English sentence into a high-dimensional vector, and our goal is to test whether the projected vectors form a more syntactically-related manifold in the high- dimensional space. In practice, one could also pre- dict parse structure for the E2E in two steps: (1) use E2E's decoder to recover the original English sen- tence, and (2) parse that sentence with the CJ parser. But in this way, the manifold structure in the high- dimensional space is destroyed during the mapping. <ref type="table" target="#tab_6">Table 5</ref> reports perplexity on training and devel- opment sets, the labeled F1-score on WSJ Section 23, and the Tree Edit Distance (TED) of various sys- tems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Result Analysis</head><p>Tree Edit Distance (TED) calculates the minimum-cost sequence of node edit opera- tions (delete, insert, rename) between a gold tree and a test tree. When decoding with beam size 10, the four new neural parsers can generate well- formed trees for almost all the 2416 sentences in the WSJ section 23. This makes TED a robust metric to evaluate the overall performance of each parser.  approximately 17 TED. Among the well-formed trees, around half have a mismatch between number of leaves and number of tokens in the source sentence. The labeled F1- score is reported over the rest of the sentences only. Though biased, this still reflects the overall perfor- mance: we achieve around 80 F1 with NMT en- coding vectors, much higher than with the E2E and PE2PE encoding vectors (below 60).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Fine-grained Analysis</head><p>Besides answering whether the NMT encoders learn syntactic information, it is interesting to know what kind of syntactic information is extracted and what is not. As <ref type="table" target="#tab_6">Table 5</ref> shows, different parsers generate dif- ferent numbers of trees that are acceptable to Tree- bank evaluation software ("EVALB-trees"), having the correct number of leaves and so forth. We se- lect the intersection set of different models' EVALB- trees. We get a total of 569 shared EVALB-trees. The average length of the corresponding sentence is 12.54 and the longest sentence has 40 tokens. The average length of all 2416 sentences in WSJ section 23 is 23.46, and the longest is 67. As we do not ap- ply an attention model for these neural parsers, it is difficult to handle longer sentences. While the in- tersection set may be biased, it allows us to explore how different encoders decide to capture syntax on short sentences. <ref type="table" target="#tab_9">Table 6</ref> shows the labeled F1-scores and Part-of- Speech tagging accuracy on the intersection set. The NMT encoder extraction achieves around 86 per- cent tagging accuracy, far beyond that of the auto- encoder based parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Labeled  Besides the tagging accuracy, we also utilize the Berkeley Parser Analyzer ( <ref type="bibr" target="#b14">Kummerfeld et al., 2012)</ref> to gain a more linguistic understanding of predicted parses. Like TED, the Berkeley Parser Analyzer is based on tree transformation. It repairs the parse tree via a sequence of sub-tree movements, node inser- tions and deletions. During this process, multiple bracket errors are fixed, and it associates this group of node errors with a linguistically meaningful error type.</p><p>The first column of <ref type="figure">Figure 5</ref> shows the average number of bracket errors per sentence for model E2P on the intersection set. For other models, we report the ratio of each model to model E2P. <ref type="bibr" target="#b15">Kummerfeld et al. (2013)</ref> and <ref type="bibr" target="#b14">Kummerfeld et al. (2012)</ref> give de- scriptions of different error types. The NMT-based predicted parses introduce around twice the brack- eting errors for the first 10 error types, whereas for "Sense Confusion", they bring more than 16 times bracket errors. "Sense confusion" is the case where the head word of a phrase receives the wrong POS, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PE2PE2P</head><p>(Ratio)</p><p>Figure 5: For model E2P (the red bar), we show the average number of bracket errors per sentence due to the top 11 error types.</p><p>For other models, we show the ratio of each model's average number of bracket errors to that of model E2P . Errors analyzed on the intersection set. The table is sorted based on the ratios of the E2F 2P model. resulting in an attachment error. <ref type="figure">Figure 6</ref> shows an example.</p><p>Even though we can predict 86 percent of parts- of-speech correctly from NMT encoding vectors, the other 14 percent introduce quite a few attachment errors. NMT sentence vectors encode a lot of syntax, but they still cannot grasp these subtle details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We investigate whether NMT systems learn source- language syntax as a by-product of training on string pairs. We find that both local and global syntactic in- formation about source sentences is captured by the encoder. Different types of syntax is stored in dif- ferent layers, with different concentration degrees. We also carry out a fine-grained analysis of the con- stituency trees extracted from the encoder, highlight- ing what syntactic information is still missing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Sample inputs and outputs of the E2E, PE2PE, E2F, E2G, and E2P models.</figDesc><graphic url="image-1.png" coords="3,182.78,288.08,75.59,85.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The five syntactic labels for sentence "This time , the firms were ready".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Prediction accuracy of five syntactic labels on test. Each syntactic label is predicted using both the lower-layer cell states (C0) and higher-layer cell states (C1). For each cell state, we predict each syntactic label using all 1000 units (All), as well as the top 10 units (Top10) selected by recursive feature elimination. The horizontal blue line is the majority class accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: E2F and E2F2P share the same English encoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Voice (active/passive) prediction accuracy using the encoding vector of an NMT system. The majority class baseline</head><label>1</label><figDesc></figDesc><table>always chooses active. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Labeled F1-scores of different parsers on WSJ Section 

23. The F1-score is calculated on valid trees only. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Corpus statistics for five syntactic labels. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 reports the average TED per sentence.</head><label>5</label><figDesc></figDesc><table>Trees 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Perplexity, labeled F1-score, and Tree Edit Distance (TED) of various systems. Labeled F1-scores are calculated on 

EVALB-trees only. Tree edit distances are calculated on the well-formed trees only. EVALB-trees are those whose number of 

leaves match the number of words in the source sentence, and are otherwise accepted by standard Treebank evaluation software. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Labeled F1-scores and POS tagging accuracy on the 

intersection set of EVALB-trees of different parsers. There are 

569 trees in the intersection, and the average length of corre-

sponding English sentence is 12.54. 

</table></figure>

			<note place="foot" n="1"> The CJ parser is here https://github.com/BLLIP/bllipparser and we used the pretrained model &quot;WSJ+Gigaword-v2&quot;. 2 We use the toolkit: https://github.com/isi-nlp/Zoph RNN</note>

			<note place="foot" n="3"> http://nlp.cs.nyu.edu/evalb/ 4 https://github.com/timtadh/zhang-shasha 5 https://github.com/jkkummerfeld/berkeley-parser-analyser</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by ARL/ARO (W911NF-10-1-0533) and DARPA (HR0011-15-C-0115).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<title level="m">Proc. Ninth Workshop on Statistical Machine Translation</title>
		<editor>Matous Machacek, Christof Monz, Pavel Pecina, Matt Post, Herv SaintAmand, Radu Soricut, and Lucia Specia</editor>
		<meeting>Ninth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Example of Sense Confusion. The POS tag for word</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
	<note>beyond&quot; is predicted as &quot;RB&quot; instead of &quot;IN&quot;, resulting in a missing prepositional phrase</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Coarse-tofine n-best parsing and MaxEnt discriminative reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A discriminative model for tree-to-tree translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivona</forename><surname>Kučerová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">What can syntax-based MT learn from phrase-based MT?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Deneefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">What &apos; s in a translation rule ? Information Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scalable inference and training of context-rich syntactic translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Graehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Deneefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Thayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Visualizing and understanding recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Parser showdown at the Wall Street Corral: An empirical investigation of error types in parser output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An empirical examination of challenges in Chinese parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Tse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>James R Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qv</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visualizing and understanding neural models in nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adjoining tree-to-string translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lü</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Mitchell P Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Overview of the 2012 shared task on Parsing the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Notes of the First Workshop on Syntactic Analysis of NonCanonical Language (SANCL)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Ontonotes: the 90% solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sameer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simple fast algorithms for the editing distance between trees and related problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaizhong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Shasha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Self-adaptive hierarchical sentence model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Poupart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
