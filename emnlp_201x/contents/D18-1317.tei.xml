<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Head Attention with Disagreement Regularization</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Shenzhen Research Institute</orgName>
								<orgName type="institution" key="instit2">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baosong</forename><surname>Yang</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Macau</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Shenzhen Research Institute</orgName>
								<orgName type="institution" key="instit2">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Head Attention with Disagreement Regularization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2897" to="2903"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2897</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Multi-head attention is appealing for the ability to jointly attend to information from different representation subspaces at different positions. In this work, we introduce a disagreement regularization to explicitly encourage the diversity among multiple attention heads. Specifically, we propose three types of disagreement regularization, which respectively encourage the subspace, the attended positions, and the output representation associated with each attention head to be different from other heads. Experimental results on widely-used WMT14 English⇒German and WMT17 Chinese⇒English translation tasks demonstrate the effectiveness and universality of the proposed approach.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Attention model is now a standard component of the deep learning networks, contributing to impressive results in neural machine transla- tion ( <ref type="bibr" target="#b11">Luong et al., 2015)</ref>, image captioning ( <ref type="bibr" target="#b20">Xu et al., 2015)</ref>, speech recog- nition ( <ref type="bibr" target="#b2">Chorowski et al., 2015</ref>), among many other applications. Recently, <ref type="bibr" target="#b18">Vaswani et al. (2017)</ref> in- troduced a multi-head attention mechanism to cap- ture different context with multiple individual at- tention functions.</p><p>One strong point of multi-head attention is the ability to jointly attend to information from dif- ferent representation subspaces at different posi- tions. However, there is no mechanism to guar- antee that different attention heads indeed capture distinct features. In response to this problem, we introduce a disagreement regularization term to explicitly encourage the diversity among multiple attention heads. The disagreement regularization * Zhaopeng Tu is the corresponding author of the paper. This work was mainly conducted when Jian Li and Baosong Yang were interning at Tencent AI <ref type="bibr">Lab.</ref> serves as an auxiliary objective to guide the train- ing of the related attention component.</p><p>Specifically, we propose three types of disagree- ment regularization, which are applied to the three key components that refer to the calculation of fea- ture vector using multi-head attention. Two regu- larization terms are respectively to maximize co- sine distances of the input subspaces and output representations, while the last one is to disperse the positions attended by multiple heads with element-wise multiplication of the corresponding attention matrices. The three regularization terms can be either used individually or in combination.</p><p>We validate our approach on top of advanced TRANSFORMER model ( <ref type="bibr" target="#b18">Vaswani et al., 2017)</ref> for both English⇒German and Chinese⇒English translation tasks. Experimental results show that our approach consistently improves translation performance across language pairs. One encour- aging finding is that TRANSFORMER-BASE with disagreement regularization achieves comparable performance with TRANSFORMER-BIG, while the training speed is nearly twice faster. Bush held a talk with Sharon head1 head2</p><p>Figure 1: Illustration of the multi-head attention, which jointly attends to different representation subspaces (colored boxes) at different positions (darker color denotes higher attention probability).</p><p>Attention mechanism aims at modeling the strength of relevance between representation pairs, such that a representation is allowed to build a di- rect relation with another representation. Instead of performing a single attention function, <ref type="bibr" target="#b18">Vaswani et al. (2017)</ref> found it is beneficial to capture dif- ferent context with multiple individual attention functions. <ref type="figure">Figure 1</ref> shows an example of a two- head attention model. For the query word "Bush", green and red head pay attention to different posi- tions of "talk" and "Sharon" respectively.</p><p>Attention function softly maps a sequence of query Q = {Q 1 , . . . , Q N } and a set of key-value pairs {K, V } = {(K 1 , V 1 ), . . . , (K M , V M )} to outputs. More specifically, multi-head attention model first transforms Q, K, and V into H sub- spaces, with different, learnable linear projections, namely:</p><formula xml:id="formula_0">Q h , K h , V h = QW Q h , KW K h , V W V h ,</formula><p>where {Q h , K h , V h } are respective the query, key, and value representations of the h-th head. </p><formula xml:id="formula_1">{W Q h , W K h , W V h } ∈ R d×d</formula><formula xml:id="formula_2">O h = A h V h with A h = sof tmax( Q h K h T √ d k ).</formula><p>Here A h is the attention distribution produced by the h-th attention head. Finally, the output states are concatenated to produce the final state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. To further guaran- tee the diversity, we enlarge the distances among multiple attention heads with disagreement regu- larization (Section 3.1). Specifically, we propose three types of disagreement regularization to en- courage each head vector O i to be different from other heads (Section 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Framework</head><p>In this work, we take the machine translation tasks as application. Given a source sentence x and its translation y, a neural machine translation model is trained to maximize the conditional translation probability over a parallel training corpus.</p><p>We introduce an auxiliary regularization term in order to encourage the diversity among multiple attention heads. Formally, the training objective is revised as:</p><formula xml:id="formula_3">J(θ) = arg max θ L(y|x; θ) likelihood +λ * D(a|x, y; θ) disagreement ,</formula><p>where a is the referred attention matrices, λ is a hyper-parameter and is empirically set to 1.0 in this paper. The auxiliary regularization term D(·) guides the related attention component to capture different features from the corresponding projected subspaces. Note that the introduced regularization term works like L1 and L2 terms, which do not intro- duce any new parameters and only influence the training of the standard model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Disagreement Regularization</head><p>Three types of regularization term, which are ap- plied to three parts of the original multi-head at- tention, are introduced in this section.</p><p>Disagreement on Subspaces (Sub.) This dis- agreement is designed to maximize the cosine dis- tance between the projected values. Specifically, we first calculate the cosine similarity cos(·) be- tween the vector pair V i and V j in different value subspaces, through the dot product of the normal- ized vectors 1 , which measures the cosine of the an- gle between V i and V j . Thus, the cosine distance is defined as negative similarity, i.e, − cos(·). Our training objective is to enlarge the average cosine distance among all head pairs. The regularization term is formally expressed as: </p><formula xml:id="formula_4">D subpace = − 1 H 2 H i=1 H j=1 V i · V j V i V j .<label>(1</label></formula><formula xml:id="formula_5">D position = − 1 H 2 H i=1 H j=1 |A i A j |. (2)</formula><p>Disagreement on Outputs (Out.) This dis- agreement directly applies regularization on the outputs of each attention head, by maximizing the difference among them. Similar to the subspace strategy, we employ negative cosine similarity to measure the distance:</p><formula xml:id="formula_6">D output = − 1 H 2 H i=1 H j=1 O i · O j O i O j .<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>The regularization on attended positions is in- spired by agreement learning in prior works, which encourages alignments or hidden variables of multiple models to be similar.  We evaluate the proposed approaches on the advanced TRANSFORMER model ( <ref type="bibr" target="#b18">Vaswani et al., 2017)</ref>, and implement on top of an open-source toolkit -THUMT ( <ref type="bibr" target="#b22">Zhang et al., 2017</ref>). We fol- low <ref type="bibr" target="#b18">Vaswani et al. (2017)</ref> to set the configurations and have reproduced their reported results on the En⇒De task. All the evaluations are conducted on the test sets. We have tested both Base and Big models, which differ at hidden size (512 vs. 1024) and number of attention heads <ref type="bibr">(8 vs. 16</ref>). We study model variations with Base model on the Zh⇒En task (Section 5.2 and 5.3), and eval- uate overall performance with Big model on both Zh⇒En and En⇒De tasks (Section 5.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Effect of Regularization Terms</head><p>In this section, we evaluate the impact of differ- ent regularization terms on the Zh⇒En task us-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>Architecture Zh⇒En En⇒De Speed BLEU Speed BLEU Existing NMT systems (  GNMT n/a n/a n/a 26.30 <ref type="bibr" target="#b5">(Gehring et al., 2017</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>) CONVS2S</head><p>n/a n/a n/a 26.36 <ref type="bibr" target="#b18">(Vaswani et al., 2017</ref>) TRANSFORMER-BASE n/a n/a n/a 27.3 TRANSFORMER-BIG n/a n/a n/a 28.4 <ref type="bibr" target="#b6">(Hassan et al., 2018)</ref> TRANSFORMER-BIG n/a 24.2 n/a n/a</p><p>Our NMT systems this work   Effect of regularization on different atten- tion networks, i.e., encoder self-attention ("Enc"), encoder-decoder attention ("E-D"), and decoder self-attention ("Dec").</p><p>ing TRANSFORMER-BASE. For simplicity and efficiency, here we only apply regularizations on the encoder side. As shown in <ref type="table">Table 1</ref>, all the models with the proposed disagreement regular- izations (Rows 2-4) consistently outperform the vanilla TRANSFORMER (Row 1). Among them, the Output term performs best which is +0.65 BLEU score better than the baseline model, the Position term is less effective than the other two.</p><p>In terms of training speed, we do not observe ob- vious decrease, which in turn demonstrates the ad- vantage of our disagreement regularizations.</p><p>However, the combinations of different dis- agreement regularizations fail to further improve translation performance (Rows 5-7). One pos- sible reason is that different regularization terms have overlapped guidance, and thus combining them does not introduce too much new informa- tion while makes training more difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Effect on Different Attention Networks</head><p>The TRANSFORMER consists of three attention networks, including encoder self-attention, de- coder self-attention, and encoder-decoder atten- tion. In this experiment, we investigate how each attention network benefits from the disagreement regularization. As seen from <ref type="table" target="#tab_0">Table 2</ref>, all mod- els consistently improve upon the baseline model. When applying disagreement regularization to all three attention networks, we achieve the best per- formance, which is +0.72 BLEU score better than the baseline model. The training speed decreases by 12%, which is acceptable considering the per- formance improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Main Results</head><p>Finally, we validate the proposed disagree- ment regularization on both WMT17 Chinese-to- English and WMT14 English-to-German transla- tion tasks. Specifically, we adopt the Output dis- agreement regularization, which is applied to all three attention networks. The results are con- cluded in <ref type="table" target="#tab_5">Table 3</ref>. We can see that our im- plementation of TRANSFORMER outperforms all existing NMT systems, and matches the results of TRANSFORMER reported in previous works. Incorporating disagreement regularization consis- tently improves translation performance for both base and big TRANSFORMER models across lan- guage pairs, demonstrating the effectiveness of the proposed approach. It is encouraging to see that TRANSFORMER-BASE with disagreement regu-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regularization on</head><p>Disagreement on Sub.</p><p>Pos. Out. n/a 0.882 0.007 0.881 Subspace 0.999 0.006 0.935 Position 0.882 0.219 0.882 Output 0.989 0.006 0.997 <ref type="table">Table 4</ref>: Effect of different regularization terms on the three disagreement measurements. "n/a" de- notes the baseline model without any regulariza- tion term. Larger value denotes more disagree- ment (at most 1.0).  larization achieves comparable performance with TRANSFORMER-BIG, while the training speed is nearly twice faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Quantitative Analysis of Regularization</head><p>In this section, we empirically investigate how the regularization terms affect the multi-head atten- tion. To this end, we compare the disagreement scores on subspaces ("Sub."), attended positions ("Pos."), and outputs ("Out."). Since the scores are negative values, we list exp(D) for readabil- ity, which has a maximum value of 1.0. <ref type="table">Table 4</ref> lists the results of encoder-side multi-head atten- tion on the Zh⇒En validation set. As seen, the disagreement score on the individual component indeed increases with the corresponding regular- ization term. For example, the disagreement of outputs increases to almost 1.0 by using the Output regularization, which means that the output vec- tors are almost perpendicular to each other as we measure the cosine distance as the disagreement.</p><p>One interesting finding is that attending to dif- ferent positions may not be the essential strength of multi-head attention on the translation task. As seen, the disagreement score on the attended posi- tions for the standard multi-head attention is only 0.007, which indicates that almost all the heads at- tend to the same positions. <ref type="table" target="#tab_7">Table 5</ref> shows the dis- agreement scores on attended positions across en- coder layers. Except for the 1 st layer that attends to the input word embeddings, the disagreement scores on other layers (i.e. ranging from the 2 nd to 6 th layer) are very low, which confirms out above hypothesis.</p><p>Concerning the regularization terms, except that on position, the other two regularization terms (i.e. "Sub." and "Out.") do not increase the disagree- ment score on the attended positions. This can explain why positional regularization term does not work well with the other two terms, as shown in <ref type="table">Table 1</ref>. This is also consistent with the find- ing in ( <ref type="bibr" target="#b17">Tu et al., 2016)</ref>, which indicates that neu- ral networks can model linguistic information in their own way. In contrast to attended positions, it seems that the multi-head attention prefer to en- coding the differences among multiple heads in the learned representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we propose several disagreement reg- ularizations to augment the multi-head attention model, which encourage the diversity among at- tention heads so that different head can learn dis- tinct features. Experimental results across lan- guage pairs validate the effectiveness of the pro- posed approaches.</p><p>The models also suggest a wide range of poten- tial advantages and extensions, from being able to improve the performance of multi-head attention in other tasks such as reading comprehension and language inference, to being able to combine with other techniques <ref type="bibr" target="#b14">(Shaw et al., 2018;</ref><ref type="bibr" target="#b15">Shen et al., 2018a;</ref><ref type="bibr" target="#b4">Dou et al., 2018;</ref><ref type="bibr" target="#b21">Yang et al., 2018</ref>) to fur- ther improve performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Liang et al.</head><label></label><figDesc>(2006) first assigned agreement terms for jointly training word alignment in phrase-based statistic machine translation (Koehn et al., 2003). The idea was further extended into other natural lan- guage processing tasks such as grammar induc- tion (Liang et al., 2008). Levinboim et al. (2015) extended the agreement for general bidi- rectional sequence alignment models with model inevitability regularization. Cheng et al. (2016) further explored the agreement on modeling the source-target and target-source alignments in neu- ral machine translation model. In contrast to the mentioned approaches which assigned agree- ment terms into loss function, we deploy an align- ment disagreement regularization by maximizing the distance among multiple attention heads. As standard multi-head attention model lacks effective control on the influence of different attention heads, Ahmed et al. (2017) used a weighted mechanism to combine them rather than simple concatenation. As an alternative approach to multi-head attention, Shen et al. (2018a) and Shen et al. (2018b) extended the sin- gle relevance score to multi-dimensional attention weights, demonstrating the effectiveness of mod- eling multiple features for attention networks. Our approach is complementary to theirs: our model encourages the diversity among multiple heads, while theirs enhance the power of each head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>2 Background: Multi-Head Attention</head><label>2</label><figDesc></figDesc><table>Bush held 
a 
talk with Sharon 

head1 

head2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>)</head><label></label><figDesc></figDesc><table>Disagreement on Attended Positions (Pos.) 
Another strategy is to disperse the attended po-
sitions predicted by multiple heads. Inspired by 
the agreement regularization (Liang et al., 2006; 
Cheng et al., 2016) which encourages multiple 
alignments to be similar, in this work, we deploy 
a variant of the original term by introducing an 
alignment disagreement regularization. Formally, 
we employ the sum of element-wise multiplica-
tion of corresponding matrix cells 2 , to measure the similarity between two matrices A i and A j of two 
heads: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparing with existing NMT systems on WMT17 Chinese⇒English and WMT14 
English⇒German translation tasks. "⇑" indicates that the model is significantly better than its base-
line counterpart (p &lt; 0.01). 

Applying to 
Speed BLEU 
Enc E-D Dec 
× 
× 
× 
1.21 
24.13 

× 
× 
1.15 
24.78 


× 
1.10 
24.67 

× 

1.11 
24.69 



1.06 
24.85 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Disagreement on attended positions with respect to the levels of the encoder layers.</figDesc><table></table></figure>

			<note place="foot" n="1"> We did not employ the Euler Distance between vectors since we do not care the absolute value in each vector. 2 We also used the squared element-wise subtraction of two matrices in our preliminary experiments, and found it underperforms its multiplication counterpart, which is consistent with the results in (Cheng et al., 2016).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The work was supported by the National Nat-</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Agreement-based joint training for bidirectional attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Attention-based Models for Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Jan K Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Serdyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Clause restructuring for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kučerová</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploiting Deep Representations for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Achieving human parity on automatic chinese to english news translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Aue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Chowdhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05567</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Model invertibility regularization: Sequence alignment with or without parallel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Levinboim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Agreement-based Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Alignment by agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effective Approaches to Attentionbased Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Self-Attention with Relative Position Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DiSAN: Directional Self-Attention Network for RNN/CNNfree Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bi-directional Block SelfAttention for Fast and Memory-Efficient Sequence Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modeling coverage for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
	</analytic>
	<monogr>
		<title level="m">Bridging the gap between human and machine translation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Modeling Localness for Self-Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baosong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidia</forename><forename type="middle">S</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanzhuo</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.06415</idno>
		<title level="m">THUMT: An Open Source Toolkit for Neural Machine Translation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
