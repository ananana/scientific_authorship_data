<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sentiment Classification towards Question-Answering with Hierarchical Matching Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenlin</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changlong</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyang</forename><surname>Kang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhong</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sentiment Classification towards Question-Answering with Hierarchical Matching Network</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3654" to="3663"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3654</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In an e-commerce environment, user-oriented question-answering (QA) text pair could carry rich sentiment information. In this study, we propose a novel task/method to address QA sentiment analysis. In particular, we create a high-quality annotated corpus with specially-designed annotation guidelines for QA-style sentiment classification. On the basis, we propose a three-stage hierarchical matching network to explore deep sentiment information in a QA text pair. First, we segment both the question and answer text into sentences and construct a number of [Q-sentence, A-sentence] units in each QA text pair. Then, by leveraging a QA bidirectional matching layer, the proposed approach can learn the matching vectors of each [Q-sentence, A-sentence] unit. Finally, we characterize the importance of the generated matching vectors via a self-matching attention layer. Experimental results , comparing with a number of state-of-the-art baselines, demonstrate the impressive effectiveness of the proposed approach for QA-style sentiment classification.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentiment analysis, a.k.a. opinion mining, is a task which aims to identify the user sentiment orienta- tion of a product/brand/service by monitoring the online textual data, e.g., reviews and social me- dia messages. It has attracted huge attention in both academic and industrial communities due to its widespread applications, such like recommen- dation ( <ref type="bibr" target="#b33">Zhang et al., 2014</ref>) and social media min- ing ( <ref type="bibr" target="#b1">Chambers et al., 2015)</ref>. As the fundamental component in sentiment analysis, sentiment clas- sification mainly classifies the sentiment polarity as positive or negative, and has been well-studied from both sentence-level ( <ref type="bibr" target="#b7">Kim and Hovy, 2004</ref>) and document-level ( <ref type="bibr" target="#b31">Xu et al., 2016)</ref>. * Corresponding author  Recently, a new QA-style reviewing form, namely "customer questions &amp; answers", has be- come increasingly popular on the giant e- commerce platforms, e.g., <ref type="bibr">Amazon and Taobao.</ref> In this new form, a potential customer asks ques- tion(s) about the target product/service while other experienced user(s) can provide answer(s). With the widespread of such QA-style reviews, users find a different channel to efficiently explore rich and useful information, and service providers and scholars are paying more attention to its specific characteristics comparing with traditional reviews ( <ref type="bibr" target="#b26">Wachsmuth et al., 2014;</ref><ref type="bibr" target="#b34">Zhou et al., 2015a</ref>). Comparing to the traditional reviews, the QA style reviews can be more informative and convincing. More importantly, because answer providers are randomly picked from the users who already pur- chased the target item, this new form of review can be more reliable and trustful.</p><p>Regarding QA-style sentiment analysis, one straightforward method is to directly employ an existing sentiment classification approach that works well on traditional reviews, such as RNN ( <ref type="bibr">Nguyen and Shirai, 2015</ref>) and LSTM ( . However, because of the significant differ- ences between QA-style and classical reviews, ex- isting review mining algorithms, e.g., text-based sentiment analysis/classification, should not be di-rectly applied to this new kind of QA-style data. More detailed reasons can be found as the follow- ings.</p><p>First, in QA-style text, the question and answer text are more likely to be two parallel units rather than a sequence form. On the one hand, for in- stance, in <ref type="figure" target="#fig_0">Figure 1</ref>, sentence "It's a nice phone with high-quality screen." in Answer 1 actually does not follow sentence "How is the battery?" in Question 1 , but corresponds to sentence "Is the screen clear?" in Question 1. Therefore, when the question text and answer text are pre- sented as two units in a sequence, it is rather diffi- cult to capture the relationship between the ques- tion and its corresponding answer due to the pos- sible long distance between them. On the other hand, there often exists both positive and nega- tive sentiments in answer text according to differ- ent parts of question, and this specific case should be categorized as another category named conflict. For instance, in <ref type="figure" target="#fig_0">Figure 1</ref>, Answer 1 "It's a nice phone with high-quality screen. But the battery is not durable." is a conflict answer to Ques- tion 1. However, when this answer text is con- sidered as a sequence, it is highly possible to be predicted as the category of positive or negative rather than conflict. In order to address these prob- lems, a more appropriate approach is to segment both the question and answer text into some paral- lel sentences, and then construct the [Q-sentence, A-sentence] units in each QA text pair to detect in-depth sentiment information.</p><p>Second, although the main sentiment polarity is usually expressed from the answer text, the ques- tion text could also carry important sentiment tips to predict the sentiment polarity of a QA text pair. For instance, in <ref type="figure" target="#fig_0">Figure 1</ref>, we could hardly estimate the sentiment polarity solely based on Answer 2. However, when we take Question 2, "Is the sun cream really effective?", into consideration, it can be easier to label this QA text pair with a nega- tive tag. In this study, we propose an approach to match the sentences inside the question and an- swer text bidirectionally.</p><p>Third, in each QA text pair, the importance de- grees of different [Q-sentence, A-sentence] units can be different. For instance, in <ref type="figure" target="#fig_0">Figure 1</ref>, the [Q- sentence, A-sentence] unit, i.e., sentence "Summer is coming, I'm afraid of getting darker." in An- swer 2 and sentence "No, just depending on my own experience." in Question 2, makes tiny con- tribution to imply the sentiment polarity for the QA text pair. Therefore, a well-behaved network approach should consider the importance degrees of different [Q-sentence, A-sentence] units for pre- dicting the sentiment polarity of a QA text pair.</p><p>The contribution of this paper is twofold. First, we propose a novel problem, QA-style sentiment analysis, and build a large-scale annotated corpus tailed for this task. The dataset is released to moti- vate future investigations for this track of research. Second, we propose a hierarchical matching net- work model to address the challenges of QA-style sentiment classification. Specifically, we first seg- ment both the question and answer text into sen- tences and construct the [Q-sentence, A-sentence] units for each QA text pair. Then, by using a QA bidirectional matching layer, we encode each [Q-sentence, A-sentence] unit for exploring senti- ment information. Finally, the self-matching at- tention layer in the model can capture the impor- tance of these [Q-sentence, A-sentence] matching vectors obtained from QA bidirectional matching layer, which could effectively refine the evidence for inferring the sentiment polarity of a QA text pair. Experimental results show that the proposed approach significantly outperforms several strong baselines for QA-style sentiment classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Sentiment classification has become a hot research field in NLP since the pioneering work by <ref type="bibr" target="#b18">Pang et al. (2002)</ref>. In general, the research on traditional sentiment classification has been carried out in dif- ferent text levels, such like word-level, document- level and aspect-level.</p><p>Word-level sentiment classification has been studied in a long period in the research community of sentiment analysis. Some early studies have de- voted their efforts to predicting the sentiment po- larity of a word with different learning models and resources. <ref type="bibr" target="#b25">Turney (2002)</ref> proposed an approach to predicting the sentiment polarity of words by cal- culating Pointwise Mutual Information (PMI) val- ues between the seed words and the search hits. <ref type="bibr" target="#b5">Hassan and Radev (2010)</ref> and <ref type="bibr" target="#b4">Hassan et al. (2011)</ref> applied a Markov random walk model to deter- mine the word polarities with a large word relat- edness graph, and the synonyms and hypernyms in WordNet <ref type="bibr" target="#b16">(Miller, 1995)</ref>. More recently, some studies aim to learn better word embedding of a word rather than its polarity. <ref type="bibr" target="#b23">Tang et al. (2014)</ref> developed three neural networks to learn word em- bedding by incorporating sentiment polarities of text in loss functions. <ref type="bibr" target="#b35">Zhou et al. (2015b)</ref> em- ployed both unsupervised and supervised neural networks to learn bilingual sentiment word em- bedding. Document-level sentiment classification has also been studied in a long period in the research community of sentiment analysis. On one hand, many early studies have been devoted their efforts to various of aspects on learning approaches, such as supervised learning <ref type="bibr" target="#b18">(Pang et al., 2002;</ref><ref type="bibr" target="#b20">Riloff et al., 2006</ref>), semi-supervised learning ( <ref type="bibr" target="#b10">Li et al., 2010;</ref><ref type="bibr" target="#b30">Xia et al., 2015;</ref>, and do- main adaptation <ref type="bibr" target="#b0">(Blitzer et al., 2007;</ref><ref type="bibr" target="#b6">He et al., 2011</ref>). On the other hand, many recent studies em- ploy deep learning approaches to enhance the per- formances in sentiment classification. <ref type="bibr" target="#b21">Tang et al. (2015)</ref> proposed a user-product neural network to incorporate both user and product information for sentiment classification. <ref type="bibr" target="#b31">Xu et al. (2016)</ref> proposed a Cached Long Short-Term Memory neural net- works (CLSTM) to capture the overall semantic information in long texts. More recently, <ref type="bibr" target="#b12">Long et al. (2017)</ref> proposed a novel attention model, namely cognition-based attention, for sentiment classification.</p><p>Aspect-level sentiment classification is a rela- tively new research area in the research commu- nity of sentiment analysis and it is a fine-grained classification task. Recently, <ref type="bibr" target="#b28">Wang et al. (2016)</ref> proposed an attention-based LSTM neural net- work to aspect-level sentiment classification by exploring the connection between an aspect and the content of a sentence. <ref type="bibr" target="#b22">Tang et al. (2016)</ref> proposed a deep memory network with multiple attention-based computational layers to improve the performance. <ref type="bibr" target="#b27">Wang et al. (2018)</ref> proposed a hierarchical attention network to explore both word-level and clause-level sentiment information towards a target aspect.</p><p>Unlike all the prior studies, this paper focuses on a very different kind of text representation, i.e., QA-style text level, for sentiment classification. To the best of our knowledge, this is the first at- tempt to perform sentiment classification on this text level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data Collection and Annotation</head><p>We collect QA text pairs from "Asking All" in Taobao (Alibaba) 1 , which is the world's biggest e- commerce company. The QA text pairs are mainly from Beauty, Shoe and Electronic domains and each domain contains 10,000 QA text pairs.</p><p>We define four sentiment-related categories, i.e., positive, negative, conflict (both positive and negative sentiment) and neutral (neither positive nor negative sentiment). To guarantee a high an- notation agreement, we propose some annotation guidelines after several times of annotation pro- cesses on a small size of data. Then, we ask more coders to annotate the whole data set according to these annotation guidelines.</p><p>The annotation guidelines contain two main groups. One contains the guidelines which aim to distinguish the categories of neutral and non- neutral, i.e., (a) A QA text pair in which the question and the answer do not match is annotated as a neutral sam- ple. In this type of samples, the answer does not reply to the question correctly. E1 is an example of this type where the question talks about the screen while the answer talks about the battery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E1: Q: Is the screen clear?</head><p>A: The battery life is decent.</p><p>(b) A QA text pair with an unknown or uncertain answer is annotated as a neutral sample. E2 is an example of this type.</p><p>E2: Q: What about these sneakers? A: I don't know, I bought it for my dad.</p><p>(c) A QA text pair with only objective description is annotated as a neutral sample. E3 is an example of this type.</p><p>E3: Q: What's the operation system of the phone? A: Android.</p><p>(d) A QA text pair which compares two different products is annotated as a neutral sample. In this type of samples, two products are involved and it  <ref type="figure">Figure 2</ref>: The overview of our approach to QA-style sentiment classification where S Qi denotes the i-th sentence in question text, S Aj denotes the j-th sentence in answer text, H Qi and H Aj denote the contextual representations for S Qi and S Aj respectively, V <ref type="bibr">[i,j]</ref> denotes the bidirectional matching vector for [S Qi , S Aj ] unit through QA bidirectional matching layer, and R is the QA text pair representation refined by self-matching attention layer.</p><formula xml:id="formula_0">[SQ1,SA1] [SQ1,SAj ] [SQi ,SAj ] [SQN,SAM] HQi HAj V[1,1] V[1,j] V[N,M] V[i,j] Self-Matching Attention Layer R [SQi ,SAM] V[i,M] Sentence Segmentation</formula><p>is sometimes difficult to tell the sentiment orienta- tion of one product. E4 is an example of this type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E4: Q:</head><p>How about this phone when compared to iPhone 6s? A: It's up to you, and they're not comparable.</p><p>The other group contains the guidelines which aim to distinguish the categories of positive and negative, i.e., (e) If the answer text contains sentimental expres- sions to question like "disappointed", "terrible", and so on, we annotate it as negative. E5 is an example of this type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E5: Q: How is the rock climbing shoe?</head><p>A: I am so disappointed, my feet felt hurt when I wore them.</p><p>(f) If the answer text contains sentimental expres- sions to question like "perfect", "satisfied", and so on, we annotate it as positive. E6 is an example of this type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E6: Q: How about the fragrance?</head><p>A: I am so satisfied, it smells distinctive.</p><p>(g) If we cannot confirm the polarity of a QA text pair only depending on answer text, we annotate the polarity according to both the question and an- swer text. For instance, E7 is an example with positive polarity, while E8 is an example with neg- ative polarity. We assign two annotators to annotate each QA text pair, and the Kappa consistency check value of the annotation is 0.84. When annotators can- not reach an agreement, an expert will make the final decision, ensuring the quality of data anno- tation. <ref type="table">Table 1</ref> shows the category distribution of the corpus. To motivate other scholars to inves- tigate this novel but important task, we share the data via Github 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>In this section, we introduce the proposed hi- erarchical matching network approach for QA- style sentiment classification. <ref type="figure">Figure 2</ref> depicts the overview of the proposed approach. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">QA Bidirectional Matching Mechanism</head><note type="other">Word Encoding Layer: After sentence segmen- tation, the question text in a QA text pair contains N sentences, S Q i represents the i-th sentence in the question text.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer-to-Question</head><p>Matching Vector</p><p>Question-to-Answer Matching Vector <ref type="figure">Figure 3</ref>: The detail architecture of QA bidirectional matching mechanism.</p><p>[1, N i ] and A-sentence S A j with words w j,m , j</p><formula xml:id="formula_1">∈ [1, M ], m ∈ [1, M j ]</formula><p>, we first convert the words to their respective word embeddings (</p><formula xml:id="formula_2">x i,n ∈ R d , i ∈ [1, N ], n ∈ [1, N i ] and x j,m , j ∈ [1, M ], m ∈ [1, M j ])</formula><p>. We then use Bi-directional LSTM (namely Bi-LSTM), which can efficiently make use of past features (via forward states) and fu- ture features (via backward states) for a specific time step, to get contextual representations of S Q i and S A j individually. The representation of each word is formed by concatenating the forward and backward hidden states. For simplicity, we note contextual representation of S Q i as H Q i , and con- textual representation of S A j as H A j respectively:</p><formula xml:id="formula_3">H Q i = [h i,1 , h i,2 , ..., h i,n , ..., h i,N i ]<label>(1)</label></formula><formula xml:id="formula_4">H A j = [h j,1 , h j,2 , ..., h j,m , ..., h j,M j ] (2)</formula><p>where h i,n ∈ R d denotes the word representation in S Q i at time step n, h j,m ∈ R d denotes the word representation in S A j at time step m, and d is the dimensionality of word representation. QA Bidirectional Matching Layer: General neural network could not capture sentiment matching information in a [S Q i , S A j ] unit well. For the sake of solving this problem, we intro- duce the QA bidirectional matching layer to en- capsulate the clues and interactions between S Q i and S A j synchronously ( <ref type="bibr" target="#b24">Tay et al., 2017;</ref><ref type="bibr" target="#b14">McCann et al., 2017)</ref>. <ref type="figure">Figure 3</ref> depicts the detail architecture of QA bidirectional matching mech- anism. Specifically, we first calculate the bidirec- tional pair-wise matching matrix by using the fol- lowing formula:</p><formula xml:id="formula_5">D [i,j] = (H Q i ) · (H A j )<label>(3)</label></formula><p>where D <ref type="bibr">[i,j]</ref> ∈ R N i ×M j denotes the bidirectional matching matrix for the [S Q i , S A j ] unit. Each ele- ment in D <ref type="bibr">[i,j]</ref> is the score that measures how well the word in S Q i semantically matches the word in S A j and vice versa. Given the bidirectional matching matrix D <ref type="bibr">[i,j]</ref> , we use attention mechanism ( <ref type="bibr" target="#b32">Yang et al., 2016;</ref><ref type="bibr" target="#b3">Cui et al., 2017)</ref> to mine the sentiment matching information between question and answer from two directions, which could be seen as an Answer- to-Question attention and a Question-to-Answer attention as follows.</p><p>• Answer-to-Question Attention: We employ row-wise operations to compute the attention weight vector α r <ref type="bibr">[i,j]</ref> as follows:</p><formula xml:id="formula_6">U r [i,j] = tanh(W r · D [i,j] )<label>(4)</label></formula><formula xml:id="formula_7">α r [i,j] = softmax(w r · U r [i,j] )<label>(5)</label></formula><p>where α r [i,j] ∈ R N i is the Answer-to-Question attention weight vector regarding the importance degrees of all words in Q-sentence S Q i , W r ∈ R d ×M j and w r ∈ R d are weight matrices. Af- ter computing the Answer-to-Question attention weight vector, we can get the Answer-to-Question matching vector V r [i,j] ∈ R d as follows:</p><formula xml:id="formula_8">V r [i,j] = (H Q i ) · α r [i,j]<label>(6)</label></formula><p>• Question-to-Answer Attention: Simultane- ously, we employ column-wise operations to cal- culate the attention weight vector α c <ref type="bibr">[i,j]</ref> as follows:</p><formula xml:id="formula_9">U c [i,j] = tanh(W c · D [i,j] )<label>(7)</label></formula><formula xml:id="formula_10">α c [i,j] = softmax(w c · U c [i,j] )<label>(8)</label></formula><p>where α c [i,j] ∈ R M j is the Question-to-Answer attention weight vector regarding the importance degrees of all words in A-sentence S A j , W c ∈ R d ×N i and w c ∈ R d are weight matrices. Af- ter calculating the Question-to-Answer attention weight vector, we can get the Question-to-Answer matching vector V c [i,j] ∈ R d as follows:</p><formula xml:id="formula_11">V c [i,j] = (H A j ) · α c [i,j]<label>(9)</label></formula><p>Then, we combine Answer-to-Question and Question-to-Answer matching vectors to represent the final bidirectional matching vector of the [S Q i , S A j ] unit:</p><formula xml:id="formula_12">V [i,j] = V r [i,j] ⊕ V c [i,j]<label>(10)</label></formula><p>where ⊕ denotes the concatenate operator, and V <ref type="bibr">[i,j]</ref> denotes the bidirectional matching vector which integrates S Q i and S A j with each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Self-Matching Attention Mechanism</head><p>Through the QA bidirectional matching layer, in- formative bidirectional matching vectors are gen- erated to pinpoint the sentiment matching infor- mation in each [Q-sentence, A-sentence] unit. In- tuitively, each matching vector for [Q-sentence, A- sentence] unit holds different importance to a QA text pair. To better aggregate the evidence from these vectors for inferring the sentiment polarity of the QA text pair, we propose a self-matching attention layer, matching these informative vectors against themselves. Self-Matching Attention Layer: As aforemen- tioned, we have obtained N *M bidirectional matching vectors through QA bidirectional match- ing layer, then we calculate the attention weight vector α with these matching vectors by following formulas:</p><formula xml:id="formula_13">V = [V [1,1] , V [1,2] , ..., V [i,j] , ..., V [N,M ] ]<label>(11)</label></formula><formula xml:id="formula_14">U = tanh(W h · V )<label>(12)</label></formula><formula xml:id="formula_15">α = softmax(w h · U )<label>(13)</label></formula><p>where α is the attention weight vector which mea- sures the importance of these matching vectors, W h and w h are the weight matrices. Finally, we can get the QA text pair representa- tion R as follows:</p><formula xml:id="formula_16">R = V · α<label>(14)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Classification Model</head><p>QA text pair representation R is a high level repre- sentation which can be used for classification. In our approach, we feed R to a softmax classifier:</p><formula xml:id="formula_17">p = softmax(W l · R + b l )<label>(15)</label></formula><p>where p is a set of predicted distribution of the sen- timent categories, i.e., positive, negative, neutral, and conflict. W l is the weight matrix and b l is the bias.</p><p>To learn the whole model, we train an end-to- end model given the training data, and the goal of training is to minimize the cross-entropy loss, i.e.,</p><formula xml:id="formula_18">L(θ) = − S s=1 K k=1 y k s · logˆylogˆy k s + λθ 2 2 (16)</formula><p>where S is the number of training data. y s is the true sentiment label of the s-th sample. ˆ y s is the predicted sentiment label of the s-th sample. K is number of all sentiment categories. λ is a L 2 - regularization term, θ is the parameter set. In the above equation, the model parameters are opti- mized by using Adam <ref type="bibr" target="#b8">(Kingma and Ba, 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimentation</head><p>In this section, we evaluate the performances of the proposed approach for QA-style sentiment classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>• Data Sets: As introduced in Section 3, the an- notated QA text pairs cover three different do- mains. In each domain, we randomly split the data into a training set (80% in each category) and a test set (20% in each category). In addition, we set aside 10% from the training set as the development data for parameters tuning.</p><p>• Word Segmentation and Embeddings: Fu- danNLP 3 ( <ref type="bibr" target="#b19">Qiu et al., 2013</ref>) is employed to seg- ment text into Chinese words and word2vec <ref type="bibr">4 (Mikolov et al., 2013</ref>) is employed to pre-train word embeddings. The vector dimensionality is set to be 100.</p><p>• Sentence Segmentation: CoreNLP 5 ( <ref type="bibr" target="#b13">Manning et al., 2014</ref>) is employed to segment both the ques- tion and answer text into sentences.</p><p>• Hyper-parameters: In the experiment, all out- of-vocabulary words are initialized by sampling from the uniform distribution U (−0.01, 0.01). All weight matrices are given their initial values by sampling from uniform distribution U (−0.01, 0.01). The LSTM hidden states are set to be 128 and all models are trained by mini-batch of 32 instances. The dropout rate is set to 0.2. The other hyper-parameters are tuned according to the development data.</p><p>• Evaluation Metric: The performance is evalu- ated using standard Accuracy and Macro-F1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Beauty</head><p>Shoe Electronic Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1 Accuracy  <ref type="table">Table 2</ref>: Performance of our approaches to QA-style sentiment classification in all domains.</p><note type="other">QtoA-Match 0.573 0.751 0.647 0.807 0.608 0.752 Bidirectional-Match QA 0.583 0.760 0.666 0.815 0.617 0.764 HMN 0.598 0.776 0.683 0.827 0.640 0.779</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Results</head><p>The following baseline approaches are employed for comparison. Note that all the approaches share the same word embeddings for fair comparison.</p><p>• SVM: This baseline employs support vector machine along with word embedding features.</p><p>The question and answer text in a QA text pair are chained as a sequence.</p><p>• LSTM: A standard LSTM model utilizes word embeddings and concatenates the question and an- swer text as a sequence.</p><p>• Bi-LSTM: A bidirectional LSTM model which concatenates the question and answer text as a se- quence.</p><p>• Bidirectional-Match: This approach employs QA bidirectional matching mechanism, without taking the sentence segmentation strategy and self- matching attention mechanism.</p><p>• AtoQ-Match: This approach takes the sen- tence segmentation strategy, and employs QA uni- directional matching mechanism (i.e., only using Answer-to-Question attention), but does not em- ploy self-matching attention mechanism. We av- erage the Answer-to-Question matching vectors to represent the QA text pair.</p><p>• QtoA-Match: This approach takes the sen- tence segmentation strategy, and employs QA uni- directional matching mechanism (i.e., only using Question-to-Answer attention), but does not em- ploy self-matching attention mechanism.</p><p>• Bidirectional-Match QA: This approach takes the sentence segmentation strategy, and employs QA bidirectional matching mechanism, but does not employ self-matching attention mechanism.</p><p>• HMN: This is our hierarchical matching net- work model which takes the sentence segmenta- tion strategy and employs both QA bidirectional matching mechanism and self-matching attention mechanism. <ref type="table">Table 2</ref> summarizes the experimental results of all the approaches above, and we can find that:</p><p>(1) All LSTM-based approaches are superior to SVM, indicating the effectiveness of neural network for this task. <ref type="formula">(2)</ref> The proposed approaches, with novel QA contextual representation, outperform the other baseline approaches. (3) When only employing QA bidirectional matching mechanism, Bidirectional-Match QA, which takes the sentence segmen- tation strategy, consistently outperforms Bidirectional-Match (without sentence seg- mentation) in all domains. It confirms our hypothesis that sentence segmentation helps to extract the sentiment matching information between the question and answer. (4) When comparing to QA unidirectional matching mechanism, Bidirectional-Match QA, which employs QA bidirectional match- ing mechanism, performs better than AtoQ- Match and QtoA-Match. It confirms our hy- pothesis that both the question and answer in- formation contribute to sentiment polarity of the QA text pair. (5) Impressively, the proposed approach HMN significantly outperforms all the other ap- proaches in all domains (p-value&lt;0.05 via t- test). It verifies the advantages of both QA bidirectional matching mechanism and self- matching attention mechanism for this task.</p><p>Besides, we also implement some more recent state-of-the-art approaches for sentiment classifi- cation, which are illustrated in <ref type="table" target="#tab_5">Table 3</ref>. This result also supports the earlier findings.</p><p>• CNN-Tensor ( : This is a state- of-the-art approach to sentence-level sentiment classification, which models n-gram interactions based on tensor product and evaluates all non-   consecutive n-gram vectors as a feature mapping operator for CNNs.</p><p>• Attention-LSTM ( <ref type="bibr" target="#b28">Wang et al., 2016)</ref>: This is a state-of-the-art approach to aspect-level sentiment classification. In our implementation, we ignore the aspect embedding and directly use the outputs of LSTM to yield the attention.</p><p>• BiMPM ( : This is a state-of- the-art approach to QA matching, which matches the question and answer from multiple perspec- tives. In our implementation, we use the match- ing representation to perform QA-style sentiment classification with a softmax classifier.</p><p>• HMN: The proposed hierarchical matching network which employs both QA bidirectional matching mechanism and self-matching attention mechanism, and takes the sentence segmentation strategy. <ref type="table" target="#tab_5">Table 3</ref> shows the comparison results of these strong baseline approaches and the proposed ap- proach (HMN) in all domains. From this table, we can find that: (1) the approaches that take matching strategy, i.e., BiMPM and our approach (HMN), outperform other approaches. (2) The proposed approach (HMN) significantly outper- forms all the other baseline approaches in terms of both Macro-F1 and Accuracy (p-value&lt;0.05 via t- test), which confirms the initial hypotheses of this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E11:</head><p>True   <ref type="table" target="#tab_6">Table 4</ref> shows some examples, along with the pre- dicted categories via different approaches. We can find that: (1) the approaches based on matching strategy <ref type="figure">(BiMPM and HMN)</ref> are well-performed, as shown in E9, when question and answer car- rying different kinds of information. This is a unique challenge for QA-style sentiment mining, and traditional sentiment classification approaches can hardly address this problem. (2) The proposed approach (HMN) performs better than other ap- proaches when dealing with conflict instances, as shown in E10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Case Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Visualization of Attention</head><p>To get a better understanding of our proposed hier- archical matching network for QA-style sentiment classification, we picture the attention weights ob- tained from Equations (5), (8) and <ref type="bibr">(13)</ref>. For simplicity, we directly use the English translation of E11 for illustration and adopt the visualiza- tion approach presented by <ref type="bibr" target="#b32">Yang et al. (2016)</ref>, as shown in <ref type="figure">Figure 2</ref>. Specifically, each line is a [Q- sentence, A-sentence] unit, where the red denotes the [Q-sentence, A-sentence] unit weight, the blue denotes the word weight in each [Q-sentence, A- sentence], and the color depth indicates the impor- tance of attention weights (the darker the more im- portant).</p><p>From <ref type="figure" target="#fig_3">Figure 4</ref>, we can see that the QA bidirec- tional matching layer always assigns reasonable attention weights to words in each [Q-sentence, A- sentence] unit which makes sentence from ques- tion and sentence from answer match correctly. In addition, the self-matching attention layer is able to select informative [Q-sentence, A-sentence] unit for predicting true sentiment polarity of this exam- ple.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose a novel but impor- tant sentiment analysis task, i.e., QA-style sen- timent mining, and we build a large-scale high- quality human annotated corpus for experiment. The dataset is shared to encourage other schol- ars to investigate this interesting problem. More- over, we propose a hierarchical matching neural network model to enable QA bidirectional match- ing mechanism and self-matching attention mech- anism for this task. Empirical studies show that the proposed approach significantly outperforms other strong baseline approaches in all the test do- mains for QA-style sentiment classification.</p><p>In the future, we would like to investigate some other network structures to explore deeper in- formation in each QA text pair. Besides, we would like to test the effectiveness of the proposed approach to QA-style sentiment classification in some other languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Question 1 :</head><label>1</label><figDesc>Is the screen clear? How is the battery? Answer 1: It's a nice phone with high-quality screen. But the battery is not durable. Question 2: Summer is coming, I'm afraid of getting darker. Is the sun cream really effective? Answer 2: No, just depending on my own expe- rience.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Two examples of QA text pairs from "customer questions &amp; answers" section in Amazon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>E7: Q:</head><label></label><figDesc>Will the phone get hot when gaming? A: No. E8: Q: Is the sun cream really economic? A: No.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The attention visualizations for a QA text pair.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>] [SQi, SAj] unit SQi in Question SAj in Answer</head><label></label><figDesc></figDesc><table>Similarly, the answer text in 
this QA text pair contains M sentences, S A j rep-
resents the j-th sentence in the answer text. We 
then construct [Q-sentence, A-sentence] units by 
pairing one sentence in the question text and one 
sentence in the answer text, and we obtain N *M 
[Q-sentence, A-sentence] units at last. 
Given a [S Q i , S A j ] unit in this QA text pair, i.e., 
Q-sentence S Q i with words w i,n , i ∈ [1, N ], n ∈ softmax 

Bi-LSTM 

Word Encording 
Layer 

QA Bidirectional 
Matching Layer 

Bidirectional Matching Vector V[i, j] 

Question-to-Answer 
Attention Weight 

Answer-to-Question 
Attention Weight 

r 

V[i, j] 

c 

V[i, jHQi 
HAj 

wc · 

c 

U[i, j] 

T 

r 

U[i, j] 
wr · 

T 

c 

α[i, j] 

r 

α[i, j] 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>The proposed approach vs. several strong baseline approaches in all domains. 

E9: 
Domain: Beauty 
True Label: neutral 
Q: 
(Hey, friends, how about the spot-fading of this product? Thanks a lot!) 
A: 
(To tell you the truth, it can moisturize effectively!) 
CNN-Tensor 
Attention-LSTM 
BiMPM 
HMN 
(positive) 
(positive) 
(neutral) 
(neutral) 
E10: 
Domain: Electronic 
True Label: conflict 
Q: 
(How about this notebook? Is the battery durable? Does the OS run fast when playing games?) 
A: 
(Battery isn't much durable. The OS doesn't run fast when playing games. The other aspects are good.) 
CNN-Tensor 
Attention-LSTM 
BiMPM 
HMN 
(positive) 
(negative) 
(negative) 
(conflict) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Some examples in the test data with their predicted categories by some approaches where (or ) means 
that the predicted category is wrong (or correct). 

</table></figure>

			<note place="foot" n="1"> https://www.taobao.com/</note>

			<note place="foot" n="2"> https://github.com/clshenNLP/QASC/</note>

			<note place="foot" n="3"> https://github.com/FudanNLP/fnlp/ 4 https://code.google.com/archive/p/word2vec/ 5 http://stanfordnlp.github.io/CoreNLP/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous reviewers for their valuable comments. This work is partially supported by the National Key R&amp;D Program of China under Grant No.2017YFB1002101 and two NSFC grants No.61331011, No.61672366. This work is also supported by the joint research project of Alibaba Group and Soochow University.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2007</title>
		<meeting>ACL-2007</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="440" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Identifying political sentiment between nation states with social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Bowen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Genco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xisen</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Harihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2015</title>
		<meeting>EMNLP-2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="65" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Enhancing and combining sequential and tree LSTM for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.06038</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Attention-overattention neural networks for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2017</title>
		<meeting>ACL-2017</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="593" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Identifying the semantic orientation of foreign words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amjad</forename><surname>Abu-Jbara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2011</title>
		<meeting>ACL-2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="592" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Identifying text polarity using random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2010</title>
		<meeting>ACL-2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="395" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatically extracting polarity-bearing topics for cross-domain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harith</forename><surname>Alani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2011</title>
		<meeting>ACL-2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="123" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Determining the sentiment of opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Soo-</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-2004</title>
		<meeting>COLING-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1367" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Molding CNNs for text: non-linear, non-consecutive convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2015</title>
		<meeting>EMNLP-2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1565" to="1575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Employing personal/impersonal views in supervised and semisupervised sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia Yat Mei</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2010</title>
		<meeting>ACL-2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="414" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semi-stacking for semi-supervised sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACLIJCNLP-2015</title>
		<meeting>ACLIJCNLP-2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="27" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A cognition based attention model for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfei</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minglei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2017</title>
		<meeting>EMNLP-2017</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="462" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2014</title>
		<meeting>ACL-2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learned in translation: Contextualized word vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS2017</title>
		<meeting>NIPS2017</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6294" to="6305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS-2013</title>
		<meeting>NIPS-2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Phrasernn: Phrase recursive neural network for aspect-based sentiment analysis</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2015</title>
		<editor>Thien Hai Nguyen and Kiyoaki Shirai</editor>
		<meeting>EMNLP-2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2509" to="2514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Thumbs up?: sentiment classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivakumar</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2002</title>
		<meeting>ACL-2002</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">FudanNLP: A toolkit for Chinese natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2013</title>
		<meeting>ACL-2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="49" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Feature subsumption for opinion analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2006</title>
		<meeting>EMNLP-2006</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="440" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning semantic representations of users and products for document level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP-2015</title>
		<meeting>ACL-IJCNLP-2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1014" to="1023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Aspect level sentiment classification with deep memory network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2016</title>
		<meeting>EMNLP-2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="214" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning sentimentspecific word embedding for twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2014</title>
		<meeting>ACL-2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1555" to="1565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A compare-propagate architecture with alignment factorization for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siu Cheung</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.00102</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter D Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2002</title>
		<meeting>ACL-2002</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Modeling review argumentation for robust sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Trenkmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregor</forename><surname>Engels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-2014</title>
		<meeting>COLING-2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="553" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Aspect sentiment classification with both word-level and clause-level attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI-2018</title>
		<meeting>IJCAI-2018</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4439" to="4445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Attention-based LSTM for aspectlevel sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Xiaoyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2016</title>
		<meeting>EMNLP-2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="606" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bilateral multi-perspective matching for natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wael</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI-2017</title>
		<meeting>IJCAI-2017</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4144" to="4150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Co-training for semi-supervised sentiment classification based on dual-view bags-of-words representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin-Yu</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP-2015</title>
		<meeting>ACL-IJCNLP-2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1054" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Cached long short-term memory neural networks for document-level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danlu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2016</title>
		<meeting>EMNLP-2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1660" to="1669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Hierarchical attention networks for document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT-2016</title>
		<meeting>NAACL-HLT-2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Explicit factor models for explainable recommendation based on phrase-level sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR-2014</title>
		<meeting>SIGIR-2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A subspace learning framework for cross-lingual sentiment classification with partial parallel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingting</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wensheng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI-2015</title>
		<meeting>IJCAI-2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1426" to="1433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning bilingual sentiment word embeddings for cross-language sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fulin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Degen</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP-2015</title>
		<meeting>ACL-IJCNLP-2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="430" to="440" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
