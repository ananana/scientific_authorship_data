<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:25+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Granularity Chinese Word Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongchao</forename><surname>Yin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">† ‡</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100093</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Granularity Chinese Word Embedding</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="981" to="986"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper considers the problem of learning Chinese word embeddings. In contrast to En-glish, a Chinese word is usually composed of characters, and most of the characters themselves can be further divided into components such as radicals. While characters and radicals contain rich information and are capable of indicating semantic meanings of words, they have not been fully exploited by existing word embedding methods. In this work, we propose multi-granularity embedding (MGE) for Chi-nese words. The key idea is to make full use of such word-character-radical composition, and enrich word embeddings by further incorporating finer-grained semantics from characters and radicals. Quantitative evaluation demonstrates the superiority of MGE in word similarity computation and analogical reasoning. Qualitative analysis further shows its capability to identify finer-grained semantic meanings of words.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Word embedding, also known as distributed word representation, is to represent each word as a real- valued low-dimensional vector, through which the semantic meaning of the word can be encoded. Re- cent years have witnessed tremendous success of word embedding in various NLP tasks ( <ref type="bibr" target="#b0">Bengio et al., 2006;</ref><ref type="bibr" target="#b11">Mnih and Hinton, 2009;</ref><ref type="bibr" target="#b2">Collobert et al., 2011;</ref><ref type="bibr" target="#b18">Zou et al., 2013;</ref><ref type="bibr" target="#b5">Kim, 2014;</ref><ref type="bibr" target="#b3">Iyyer et al., 2015</ref>). The basic idea behind is to learn the distributed representation of a word using its con- text. Among existing approaches, the continuous bag-of-words model (CBOW) and Skip-Gram mod- el are simple and effective, capable of learning word embeddings efficiently from large-scale text corpo- ra ( <ref type="bibr" target="#b8">Mikolov et al., 2013a;</ref><ref type="bibr" target="#b9">Mikolov et al., 2013b</ref>). * Corresponding author: Peng Li.</p><p>Besides the success in English, word embedding has also been demonstrated to be extremely useful for Chinese language processing ( <ref type="bibr" target="#b16">Yu et al., 2015;</ref><ref type="bibr" target="#b17">Zhou et al., 2015;</ref><ref type="bibr" target="#b18">Zou et al., 2013</ref>). The work on Chinese generally follows the same idea as on English, i.e., to learn the embedding of a word on the basis of its context. However, in contrast to English where words are usually taken as basic semantic units, Chinese words may have a complicated composition structure of their seman- tic meanings. More specifically, a Chinese word is often composed of several characters, and most of the characters themselves can be further divided in- to components such as radicals (部首). 1 Both char- acters and radicals may suggest the semantic mean- ing of a word, regardless of its context. For exam- ple, the Chinese word "吃饭 (have a meal)" con- sists of two characters " 吃 (eat)" and "饭 (meal)", where " 吃 (eat)" has the radical of "口 (mouth)", and "饭 (meal)" the radical of " 饣 (food)". The se- mantic meaning of "吃饭" can be revealed by the constituent characters as well as their radicals.</p><p>Despite being the linguistic nature of Chinese and containing rich semantic information, such word- character-radical composition has not been fully ex- ploited by existing approaches.  introduced a character-enhanced word embedding model (CWE), which learns embeddings jointly for words and characters but ignores radicals. <ref type="bibr" target="#b14">Sun et al. (2014)</ref> and  utilized radical informa- tion to learn better character embeddings. Similarly, <ref type="bibr" target="#b13">Shi et al. (2015)</ref> split characters into small compo- nents based on the Wubi method, 2 and took into ac- count those components during the learning process. In their work, however, embeddings are learned on- ly for characters. For a word, the embedding is gen- erated by simply combining the embeddings of the constituent characters. Since not all Chinese word-</p><formula xml:id="formula_0">回家 (go back home) 会友 (meet friends) 口(eat) 饣(food) 回(go back) 家(home) 会(meet) 友(friends) 吃饭 (have a meal)</formula><p>hidden layer Word embeddings Character embeddings Radical embeddings Hidden layer <ref type="figure">Figure 1</ref>: A simple illustration of MGE, where embeddings are learned jointly for words, characters, and radicals. Given a sequence of words {" 回家 (go back home)", " 吃饭 (have a meal)", " 会友 (meet friends)"}, MGE predicts the central word "吃饭" by using 1) the embedding composed by each context word and its constituent characters, and 2) the embedding asso- ciated with each radical detected in the target word.</p><p>s are semantically compositional (e.g., transliterated words such as "苏打 (soda)"), embeddings obtained in this way may be of low quality for these words.</p><p>In this paper, aiming at making full use of the se- mantic composition in Chinese, we propose multi- granularity embedding (MGE) which learns embed- dings jointly for words, characters, and radicals. The framework of MGE is sketched in <ref type="figure">Figure 1</ref>. Given a word, we learn its embedding on the basis of 1) the context words (blue bars in the figure), 2) their con- stituent characters (green bars), and 3) the radicals found in the target word (orange bars). Compared to utilizing context words alone, MGE enriches the embeddings by further incorporating finer-grained semantics from characters and radicals. Similar ideas of adaptively using multiple levels of embed- dings have also been investigated in English recent- ly ( <ref type="bibr" target="#b4">Kazuma and Yoshimasa, 2016;</ref><ref type="bibr" target="#b10">Miyamoto and Cho, 2016)</ref>.</p><p>We evaluate MGE with the benchmark tasks of word similarity computation and analogical reason- ing, and demonstrate its superiority over state-of- the-art metods. A qualitative analysis further shows the capability of MGE to identify finer-grained se- mantic meanings of words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Multi-Granularity Word Embedding</head><p>This section introduces MGE based on the contin- uous bag-of-words model (CBOW) ( <ref type="bibr" target="#b9">Mikolov et al., 2013b</ref>) and the character-enhanced word embedding model (CWE) . MGE aims at improving word embedding by leveraging both characters and radicals. We denote the Chinese word vocabulary as W, the character vo- cabulary as C, and the radical vocabulary as R. Each word w i ∈ W is associated with a vector embedding w i , each character c i ∈ C a vector embedding c i , and each radical r i ∈ R a vector embedding r i . Giv- en a sequence of words D = {w 1 , · · · , w N }, MGE predicts each word w i ∈ D conditioned on 1) con- text words in a sliding window with size ℓ, denoted as W i = {w i−ℓ , ...w i−1 , w i+1 , ..., w i+ℓ }, 2) charac- ters in each context word w j ∈ W i , denoted as C j , and 3) radicals in the target word w i , denoted as R i . See <ref type="figure">Figure 1</ref> for a simple illustration.</p><p>More specifically, given the corpus D, MGE max- imizes the overall log likelihood as follows:</p><formula xml:id="formula_1">L(D) = ∑ w i ∈D log p(w i |h i ).<label>(1)</label></formula><p>Here h i is a hidden vector composed by the embed- dings of context words, constituent characters, and radicals, defined as:</p><formula xml:id="formula_2">h i = 1 2 [ 1 |W i | ∑ wj ∈Wi ( w j ⊕ 1 |C j | ∑ c k ∈Cj c k ) + 1 |R i | ∑ r k ∈Ri r k ] .<label>(2)</label></formula><p>For each context word w j ∈ W i , a word-character composition (w j ⊕ 1</p><formula xml:id="formula_3">|C j | ∑ c∈C j</formula><p>c) is first generated by the embeddings of w j and its constituent charac- ters C j . These word-character compositions are then combined with the radical embeddings in R i to pre- dict the target word. |W i |/|R i |/|C j | is the cardinality of W i /R i /C j , and ⊕ is the composition operation. <ref type="bibr">3</ref> Given h i , the conditional probability p(w i |h i ) is de- fined by a softmax function:</p><formula xml:id="formula_4">p(w i |h i ) = exp(h ⊤ i w i ) ∑ w i ′ ∈W exp(h ⊤ i w i ′ ) .<label>(3)</label></formula><p>We use negative sampling and stochastic gradient descent to solve the optimization problem. Note that 1) Not all Chinese words are semantical- ly compositional, e.g., transliterated words and enti- ty names. For such words we use neither characters nor radicals. 2) A Chinese character usually plays different roles when it appears at different positions within a word. We follow  and design a position-based MGE model (MGE+P). The key idea of MGE+P is to keep three embeddings for each character, corresponding to its appearance at the positions of "begin", "middle", and "end". For details, please refer to ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We evaluate MGE with the tasks of word similarity computation and analogical reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setups</head><p>We select the Chinese Wikipedia Dump 4 for embed- ding learning. In preprocessing, we use the THU- LAC tool <ref type="bibr">5</ref> to segment the corpus. Pure digit word- s, non-Chinese words, and words whose frequencies are less than 5 in the corpus are removed. We further crawl from an online Chinese dictionary <ref type="bibr">6</ref> and build a character-radical index with 20,847 characters and 269 radicals. We use this index to detect the radical of each character in the corpus. As such, we get a training set with 72,602,549 words, 277,200 unique words, 8,410 unique characters, and 256 unique rad- icals. Finally, we use THULAC to perform Chinese POS tagging on the training set and identify all enti- ty names. For these entity names, neither characters nor radicals are considered during learning. Actual- ly,  categorized non-compositional Chinese words into three groups, i.e., transliterat- ed words, single-morpheme multi-character words, and entity names. In their work, they used a human- annotated corpus, manually determining each word to be split or not. Since human annotation could be time-consuming and labor intensive, we just consid- er automatically identified entity names.</p><p>We compare MGE with CBOW (Mikolov et al., 2013b) 7 and CWE   <ref type="bibr">8</ref> . Both CWE and MGE are extensions of CBOW, with the for- mer taking into account characters and the latter fur- ther incorporating radical information. We further consider position-based CWE and MGE, denoted as CWE+P and MGE+P, respectively.We follow (Chen</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>WordSim-239 WordSim-293 k = 100 k = 200 k = 100 k = 200 CBOW 0.4917 0.4971 0.5667 0.5723 CWE 0.5121 0.5197 0.5511 0.5655 CWE+P 0.4989 0.5026 0.5427 0.5545 MGE 0.5670 0.5769 0.5555 0.5659 MGE+P 0.5511 0.5572 0.5530 0.5692 <ref type="table">Table 1</ref>: Results on word similarity computation.</p><p>et al., 2015) and use the same hyperparameter set- ting. For all the methods, we set the context window size to 3, and select the embedding dimension k in {100, 200}. During optimization, we use 10-word negative sampling and fix the initial learning rate to 0.025.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Word Similarity Computation</head><p>This task is to evaluate the effectiveness of embed- dings in preserving semantic relatedness between t- wo words. We use the WordSim-240 and WordSim- 296 datasets 9 provided by  for e- valuation, both containing Chinese word pairs with human-labeled similarity scores. On WordSim-240 there is a pair containing new words (i.e., words that have not appeared in the training set), and on WordSim-296 there are 3 such pairs. We remove these pairs from both datasets, and accordingly get WordSim-239 and WordSim-293. We compute the Spearman correlation coefficient ( <ref type="bibr" target="#b12">Myers et al., 2010</ref>) between the similarity scores given by the embedding models and those given by human annotators. For the embedding models, the similarity score between two words is calculated as the cosine similarity between their embeddings. The Spearman correlation coefficient is a nonparametric measure of rank correlation, assessing how well the relationship between two variables can be described. The results are shown in <ref type="table">Table 1</ref>.</p><p>From the results, we can see that 1) On WordSim- 239, MGE(+P) performs significantly better than CWE(+P), which in turn outperforms CBOW. This observation demonstrates the superiority of incor- porating finer-grained semantics, particularly from radicals. For example, MGE performs much better on word pairs such as "银行 (bank)" and " 钱 (mon- ey)", in which the two words share the same radi- cal of "钅(gold)". 2) On WordSim-293, MGE(+P)  performs equally well as CWE(+P), but both are s- lightly worse than CBOW. The reason may be that WordSim-293 contains a great many of word pairs in which the two words belonging to different domain- s, e.g., "公鸡 (rooster)" and "航程 (flying range)". These pairs usually get low human-labeled similari- ty scores. However, splitting the words in such pairs into characters, and further the characters into radi- cals will not help to effectively identify the dissimi- larity between them. <ref type="bibr">10</ref> We further investigate the influence of the context window size in word similarity computation. <ref type="figure" target="#fig_0">Fig- ure 2</ref> gives the results of CBOW, CWE, and MGE on WordSim-239, with the context window size set in {3, 4, 5, 6, 7}. The results indicate that MGE per- forms consistently better than CBOW and CWE on this dataset, unaffected by varying the context win- dow size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Word Analogical Reasoning</head><p>This task evaluates the effectiveness of embeddings in capturing linguistic regularities between pairs of words, in the form of " 伦敦 (London) : 英国 (Eng- land) ≈ 巴黎 (Paris) : 法国 (France)". We use the dataset provided by  for evalua- tion. It contains 1,124 analogies categorized into 3 types: 1) capitals of countries (677 groups); 2) s- tates/provinces of cities (175 groups); and 3) family relations (272 groups). All the words in this dataset <ref type="bibr">10</ref> This observation is inconsistent with that reported in , which shows that CWE outperforms CBOW on WordSim-296. The reason may be that  used a human-annotated corpus for embedding learning, and manually determined each word to be split or not. In contrast, we use the publicly available Chinese Wikipedia data, and automatically segment the corpus and identify entity names (words that are not to be split), without human annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Total Capital State Family CBOW 0.7498 0.8109 0.8400 0.5294 CWE 0.7248 0.8375 0.8541 0.3566 CWE+P 0.7391 0.8065 0.8114 0.5147 MGE 0.7524 0.8804 0.8686 0.3529 MGE+P 0.7720 0.8685 0.8857 0.4485 <ref type="table">Table 2</ref>: Results on word analogical reasoning (k = 200).</p><p>are covered by the training set.</p><p>For each analogy "a : b ≈ c : d ", we create a question "a : b ≈ c : ? ", and predict the answer as:</p><formula xml:id="formula_5">d * = arg max w∈W cos (b−a+c, w).</formula><p>Here a, b, c, w are the word embeddings, and cos(·, ·) the cosine similarity. The question is considered to be correctly answered if d * = d. We use accuracy as the evalua- tion metric, and report the results in <ref type="table">Table 2</ref>.</p><p>The results indicate that 1) MGE(+P) substantial- ly outperforms the baseline methods on almost all types of analogies (except for the Family type). This again demonstrates the superiority of incorporating radical information. 2) For the Capital and State types, all the words are entity names for which nei- ther characters nor radicals are used. MGE(+P) still outperforms the baselines on these two types, show- ing its capability to learn better embeddings even for non-compositional words. 3) On the Family type, both MGE(+P) and CWE(+P) perform worse than CBOW. This may be caused by the inappropriate de- composition of family words into characters. Con- sider, for example, the question " 叔叔 (uncle) : 阿 姨 (aunt) ≈ 王子 (prince) : ? ". If we split " 王子" into "王 (king)" and "子 (son)", we will more likely to predict " 女王 (queen)" rather than the correc- t answer "公主 (princess)", since "女王" contains the character " 女 (daughter)" which is usually the antonym of " 子 (son)".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Case Study</head><p>Besides quantitative evaluation, this section further provides qualitative analysis to show in what man- ner the semantic meaning of a radical, character and word can be captured by their embeddings.</p><p>Take the word "游泳 (swimming)" as an example. <ref type="table" target="#tab_1">Table 3</ref> presents the words that are most similar to it (with the highest cosine similarity between their em- beddings), discovered by MGE, CWE, and CBOW. The results show that 1) By incorporating the char- acter information, MGE and CWE are capable of MGE 潜泳(underwater swimming), 畅泳(swimming happily) 爬泳(front crawl swimming), 泳手(swimmer) 泳术(swimming skill), 冬泳(winter swimming) 裸泳(swimming skill), 田径(track and field) CWE 潜泳(underwater swimming), 畅泳(swimming happily) 爬泳(front crawl swimming), 田径(track and field) 泳手(swimmer), 习泳(learn to swim) 冬泳(winter swimming), 泳术(swimming skill) CBOW 田径(track and field), 跳高(high jump) 跳水(diving), 跳绳(rope skipping) 划船(boating), 撑竿跳(pole vaulting) 皮划艇(canoeing), 体操(gymnastics)  capturing finer-grained semantics that are more spe- cific to the word. The top words discovered by them are semantically related to "游泳 (swimming)" it- self, e.g., "潜泳 (underwater swimming)" and "爬 泳 (front crawl swimming)". But the top words dis- covered by CBOW are just other types of sports in parallel with " 游泳 (swimming)", e.g., " 跳高 (high jump)" and " 跳水 (diving)". 2) MGE performs even better than CWE by further incorporating the radical information. The less relevant word " 田径 (track and field)" is ranked 4th by CWE. But after introduc- ing the radical "氵(water)", MGE can successfully rank "泳手 (swimmer)", "泳术 (swimming skill)", and " 冬泳 (winter swimming)" before it. All these words contain the radical "氵(water)" and are more relevant to "游泳 (swimming)". We further take the radical "疒 (illness)" as an ex- ample, and list the most similar characters and words discovered by MGE in <ref type="table" target="#tab_2">Table 4</ref>. The similarity be- tween a radical and a character/word is also defined as the cosine similarity between their embeddings. From the results, we can see that almost all the char- acters and words are disease-related, e.g., "佝 (rick- ets)", "痨 (tuberculosis)", and "癣疥 (ringworm s- cabies)", and most of them share the same radical "疒 (illness)". This observation demonstrates the ra- tionality of embedding Chinese words, characters, and radicals into the same vector space, and measur- ing their similarities directly in that space. Note that this operation might be problematic for English. For example, it could be hard to figure out what kind of similarity there is between the character "i" and the word "ill". But for Chinese, this problem might be alleviated since characters and radicals themselves contain rich semantic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>In this paper we propose a new approach to Chinese word embedding, referred to as multi-granularity embedding (MGE). MGE improves word embed- ding by further leveraging both characters and radi- cals, and hence makes full use of the word-character- radical semantic composition. Experimental results on word similarity computation and analogical rea- soning demonstrate the superiority of MGE over state-of-the-art methods. A qualitative analysis fur- ther shows that by incorporating radical information MGE can identify finer-grained semantic meanings of words.</p><p>As future work, we would like to 1) Investigate more complicate composition manners among radi- cals, characters, and words, e.g., a hierarchical struc- ture of them. 2) Explore the semantic composition of higher level language units such as phrases, sen- tences, and even documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Word similarity computation results with different context window sizes on WordSim-239 (k = 200).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>The most similar words to "游泳 (swimming)". 

Radical 疒(illness) 
佝(rickets) 痼(chronic disease) 
Closest 
偻(bending one's back) 疠(epidemic disease) 
characters 痨(tuberculosis) 淬(quenching) 
疥(scabies) 痔(hemorrhoids) 
佝偻(rickets) 癣疥(ringworm scabies) 
Closest 
痘疤(pock) 瘴疠(communicable subtropical disease) 
words 
疮痍(traumata) 疮疤(scar) 
痲疹(measles) 疱疮(pemphigus) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>The most similar characters/words to "疒 (illness)". 

</table></figure>

			<note place="foot" n="3"> There are a variety of options for ⊕, e.g., addition and concatenation. This paper follows (Chen et al., 2015) and uses the addition operation.</note>

			<note place="foot" n="4"> http://download.wikipedia.com/zhwiki 5 http://thulac.thunlp.org/ 6 http://zd.diyifanwen.com/zidian/bs/ 7 https://code.google.com/p/word2vec/ 8 https://github.com/Leonard-Xu/CWE</note>

			<note place="foot" n="9"> https://github.com/Leonard-Xu/CWE/tree/master/data</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgement</head><p>We would like to thank the anonymous reviewers for their insightful comments and suggestions. This research is supported by the National Natural Sci-ence Foundation of <ref type="bibr">China (grant No. 61402465 and No. 61402466</ref>) and the Strategic Priority Research Program of the Chinese Academy of Sciences (grant No. XDA06030200).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural probabilistic language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Sébastien</forename><surname>Senécal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fréderic</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Luc</forename><surname>Gauvain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovations in Machine Learning</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="137" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Joint learning of character and 985 word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Artificial Intelligence</title>
		<meeting>the 24th International Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1236" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep unordered composition rivals syntactic methods for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Manjunatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1681" to="1691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive joint learning of compositional and noncompositional phrase embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hashimoto</forename><surname>Kazuma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsuruoka</forename><surname>Yoshimasa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Component-enhanced chinese character embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="829" to="834" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Representation learning using multi-task deep neural networks for semantic classification and information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye-Yi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="912" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Gated word-character recurrent language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasumasa</forename><surname>Miyamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01700</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A scalable hierarchical distributed language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 21</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1081" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Research design and statistical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Jerome L Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">Frederick</forename><surname>Well</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lorch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Radical embedding: Delving deeper to chinese radicals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehua</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="594" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Radical-Enhanced Chinese Character Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhou</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">chapter Proceedings of the 21st International Conference on Neural Information Processing</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="279" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Word embedding composition for data imbalances in sentiment and emotion classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqing</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="226" to="240" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Combining word embeddings and feature embeddings for fine-grained relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1374" to="1379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning continuous word embedding with metadata for question retrieval in community question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingting</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="250" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bilingual word embeddings for phrase-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1393" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
