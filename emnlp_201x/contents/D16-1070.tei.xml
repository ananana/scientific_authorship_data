<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:30+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Network for Heterogeneous Annotations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
							<email>chenhongshen@ict.ac.cn, yue zhang@sutd.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">†Key Laboratory of Intelligent Information Processing Institute of Computing Technology</orgName>
								<orgName type="department" key="dep2">Design ♢ ADAPT centre</orgName>
								<orgName type="department" key="dep3">School of Computing</orgName>
								<orgName type="institution" key="instit1">Chinese Academy of Sciences §University of Chinese Academy of Sciences ‡Singapore University of Technology</orgName>
								<orgName type="institution" key="instit2">Dublin City University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">†Key Laboratory of Intelligent Information Processing Institute of Computing Technology</orgName>
								<orgName type="department" key="dep2">Design ♢ ADAPT centre</orgName>
								<orgName type="department" key="dep3">School of Computing</orgName>
								<orgName type="institution" key="instit1">Chinese Academy of Sciences §University of Chinese Academy of Sciences ‡Singapore University of Technology</orgName>
								<orgName type="institution" key="instit2">Dublin City University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">†Key Laboratory of Intelligent Information Processing Institute of Computing Technology</orgName>
								<orgName type="department" key="dep2">Design ♢ ADAPT centre</orgName>
								<orgName type="department" key="dep3">School of Computing</orgName>
								<orgName type="institution" key="instit1">Chinese Academy of Sciences §University of Chinese Academy of Sciences ‡Singapore University of Technology</orgName>
								<orgName type="institution" key="instit2">Dublin City University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">♢</forename></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">†Key Laboratory of Intelligent Information Processing Institute of Computing Technology</orgName>
								<orgName type="department" key="dep2">Design ♢ ADAPT centre</orgName>
								<orgName type="department" key="dep3">School of Computing</orgName>
								<orgName type="institution" key="instit1">Chinese Academy of Sciences §University of Chinese Academy of Sciences ‡Singapore University of Technology</orgName>
								<orgName type="institution" key="instit2">Dublin City University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Network for Heterogeneous Annotations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="731" to="741"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Multiple treebanks annotated under heterogeneous standards give rise to the research question of best utilizing multiple resources for improving statistical models. Prior research has focused on discrete models, leveraging stacking and multi-view learning to address the problem. In this paper, we empirically investigate heterogeneous annotations using neu-ral network models, building a neural network counterpart to discrete stacking and multi-view learning, respectively, finding that neural models have their unique advantages thanks to the freedom from manual feature engineering. Neural model achieves not only better accuracy improvements, but also an order of magnitude faster speed compared to its discrete baseline, adding little time cost compared to a neural model trained on a single treebank.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For many languages, multiple treebanks have been annotated according to different guidelines. For ex- ample, several linguistic theories have been used for defining English dependency treebanks, includ- ing <ref type="bibr" target="#b42">Yamada and Matsumoto (2003)</ref>, LTH <ref type="bibr" target="#b20">(Johansson and Nugues, 2007)</ref> and Stanford dependencies <ref type="bibr" target="#b9">(De Marneffe et al., 2006</ref>). For German, there exist TIGER ( <ref type="bibr" target="#b1">Brants et al., 2002</ref>) and TüBa-D/Z ( <ref type="bibr" target="#b35">Telljohann et al., 2006</ref>). For Chinese, treebanks have been made available under various segmentation granu- larities <ref type="bibr" target="#b32">(Sproat and Emerson, 2003;</ref><ref type="bibr" target="#b12">Emerson, 2005;</ref><ref type="bibr" target="#b41">Xue, 2003)</ref>. These give rise to the research problem * Work done when the first author was visiting SUTD.</p><p>of effectively making use of multiple treebanks un- der heterogeneous annotations for improving output accuracies ( <ref type="bibr" target="#b19">Jiang et al., 2015;</ref><ref type="bibr" target="#b21">Johansson, 2013;</ref><ref type="bibr" target="#b24">Li et al., 2015</ref>).</p><p>The task has been tackled using two typical ap- proaches. The first is based on stacking <ref type="bibr" target="#b38">(Wolpert, 1992;</ref><ref type="bibr" target="#b2">Breiman, 1996;</ref><ref type="bibr" target="#b39">Wu et al., 2003</ref>). As shown in <ref type="figure">Figure 1</ref>(a), the main idea is to have a model trained using a source treebank, which is then used to guide a target treebank model by offering source-style fea- tures. This method has been used for leveraging two different treebanks for word segmentation <ref type="bibr" target="#b18">(Jiang et al., 2009;</ref><ref type="bibr" target="#b33">Sun and Wan, 2012</ref>) and dependency pars- ing ( <ref type="bibr" target="#b27">Nivre and McDonald, 2008;</ref><ref type="bibr" target="#b21">Johansson, 2013</ref>).</p><p>The second approach is based on multi-view learning <ref type="bibr" target="#b21">(Johansson, 2013;</ref><ref type="bibr" target="#b24">Li et al., 2015</ref>). The idea is to address both annotation styles simul- taneously by sharing common feature representa- tions. In particular, Johansson (2013) trained depen- dency parsers using the domain adaptation method of <ref type="bibr" target="#b8">Daumé III (2007)</ref>, keeping a copy of shared fea- tures and a separate copy of features for each tree- bank. <ref type="bibr" target="#b24">Li et al. (2015)</ref> trained POS taggers by cou- pling the labelsets from two different treebanks into a single combined labelset. A summary of such multi-view methods is shown in <ref type="figure">Figure 1</ref>(b), which demonstrates their main differences compared to stacking <ref type="figure">(Figure 1(a)</ref>).</p><p>Recently, neural network has gained increasing research attention, with highly competitive results being reported for numerous NLP tasks, including word segmentation ( <ref type="bibr" target="#b47">Zheng et al., 2013;</ref><ref type="bibr" target="#b28">Pei et al., 2014;</ref>, POS-tagging ( <ref type="bibr" target="#b26">Ma et al., 2014;</ref><ref type="bibr" target="#b29">Plank et al., 2016</ref>  <ref type="figure">Figure 1</ref>: Two main approaches to utilizing hetero- geneous annotations. <ref type="bibr" target="#b4">Manning, 2014;</ref><ref type="bibr" target="#b11">Dyer et al., 2015;</ref><ref type="bibr" target="#b36">Weiss et al., 2015;</ref>). On the other hand, the aforemen- tioned methods on heterogeneous annotations are in- vestigated mainly for discrete models. It remains an interesting research question how effective multiple treebanks can be utilized by neural NLP models, and we aim to investigate this empirically. We follow <ref type="bibr" target="#b24">Li et al. (2015)</ref>, taking POS-tagging for case study, using the methods of <ref type="bibr" target="#b18">Jiang et al. (2009)</ref> and <ref type="bibr" target="#b24">Li et al. (2015)</ref> as the discrete stacking and multi-view training baselines, respectively, and building neural network counterparts to their mod- els for empirical comparison. The base tagger is a neural CRF model ( <ref type="bibr" target="#b23">Lample et al., 2016)</ref>, which gives competitive accuracies to discrete CRF taggers.</p><p>Results show that neural stacking allows deeper integration of the source model beyond one-best out- puts, and further the fine-tuning of the source model during the target model training. In addition, the ad- vantage of neural multi-view learning over its dis- crete counterpart are many-fold. First, it is free from the necessity of manual cross-labelset inter- active feature engineering, which is far from triv- ial for representing annotation correspondence ( <ref type="bibr" target="#b24">Li et al., 2015)</ref>. Second, compared to discrete model, parameter sharing in deep neural network eliminates the issue of exponential growth of search space, and allows separated training of each label type, in the same way as multi-task learning <ref type="bibr" target="#b7">(Collobert et al., 2011</ref>). Our neural multi-view learning model achieves not only better accuracy improvements, but also an order of magnitude faster speed com- pared to its discrete baseline, adding little time cost compared to a neural model trained on a single treebank.</p><p>The C++ implementations of our neural network stacking and multi-view learning models are available under GPL, at https://github.com/chenhongshen/NNHetSeq.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Baseline Neural Network Tagger</head><p>We adopt a neural CRF with a Long-Short-Term- Memory (LSTM) <ref type="bibr" target="#b16">(Hochreiter and Schmidhuber, 1997</ref>) feature layer for baseline POS tagger. As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, the model consists of three main neural layers: the input layer calculates dense rep- resentation of input words using attention model on character embeddings; the feature layer employs a bi-directional LSTM model to extract non-local fea- tures from input vectors; the output layer uses a CRF structure to infer the most likely label for each input word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Input Layer</head><p>Given a sentence w (1:n) , the input layer builds a vec- tor representation ⃗ r i w for each word w i based on both word and character embeddings. In particular, an embedding lookup table is used to convert vocabu- lary words into their embedding forms directly. To obtain a character based embedding of w i , we de- note the character sequence of w i with c <ref type="bibr">(1:n)</ref> , where c j is the jth character in w i .</p><p>A character lookup table is used to map each char-  acter c j into a character embedding ⃗ e j c . The char- acter embeddings ⃗ e 1 c , ⃗ e 2 c , ..., ⃗ e m c are combined using an attention model( <ref type="bibr" target="#b0">Bahdanau et al., 2015)</ref>:</p><formula xml:id="formula_0">⃗ w i c = ∑ m j=1 a j c ⊙ ⃗ e j c</formula><p>, where a j c is the weight for ⃗ e j c , ⊙ is the Hadamard product function, and ∑ m j=1 a j c = 1. Each a j c is computed according to both the word embedding vector and 5-character embedding win- dow with the current character ⃗ e j c in the middle:</p><formula xml:id="formula_1">a j c = t j c ∑ m 1 t j c t j c = exp(W t ⃗ h j c + U t ⃗ e i w + ⃗ b t ) ⃗ h i c = tanh ( W c (⃗ e j−2 c ⊕ ⃗ e j−1 c ⊕ ⃗ e j c ⊕ ⃗ e j+1 c ⊕ ⃗ e j+2 c ) + ⃗ b c )</formula><p>Here ⊕ denotes vector concatenation and ⃗ e i w is the embedding of current word w i . W t , U t , W c and ⃗ b t , ⃗ b c are model parameters. Finally, ⃗ w i c is concatenated with word embedding to form final word represen- tation ⃗ r i w : </p><formula xml:id="formula_2">⃗ r i w = ⃗ e i w ⊕ ⃗ w i c</formula><formula xml:id="formula_3">x i = (⃗ r i−2 w ⊕⃗ r i−1 w ⊕⃗ r i w ⊕ ⃗ r i+1 w ⊕ ⃗ r i+2</formula><p>w ) is used to represent each word w i . We use a LSTM variation with peephole connec- tions ( <ref type="bibr" target="#b15">Graves and Schmidhuber, 2005</ref>) to extract fea- tures based on ⃗ x (1:n) . The model computes a hid- den vector ⃗ h i for each input ⃗ x i , passing information from ⃗ h 1 , ..., ⃗ h i−1 to ⃗ h n via a sequence of cell states ⃗ c 1 , ⃗ c 2 , ..., ⃗ c n . Information flow is controlled using an input gate ⃗ g i , a forget gate ⃗ f i , and an output gate ⃗ o i :</p><formula xml:id="formula_4">⃗ g i =σ(W (g) ⃗ x i + U (g) ⃗ h i−1 + V (g) ⃗ c i−1 + ⃗ b (g) ) ⃗ f i =σ(W (f ) ⃗ x i + U (f ) ⃗ h i−1 + V (f ) ⃗ c i−1 + ⃗ b (f ) ) ⃗ c i = ⃗ f i ⊙ ⃗ c i−1 + ⃗ g i ⊙ tanh(W (u) ⃗ x i + U (u) ⃗ h i−1 + ⃗ b (u) ) ⃗ o i =σ(W (o) ⃗ x i + U (o) ⃗ h i−1 + V (o) ⃗ c i + ⃗ b (o) ) ⃗ h i =⃗ o i ⊙ tanh( ⃗ c i ),</formula><p>where σ denotes the component-wise sigmoid func- tion.</p><formula xml:id="formula_5">W (g) , W (f ) , W (u) , W (o) , U (g) , U (f ) , U (u) , U (o) , V (g) , V (f ) , V (o) , ⃗ b (g) , ⃗ b (f ) , ⃗ b (u) , ⃗ b (o) are model parameters.</formula><p>Bi-directional extension of the above LSTM structure is applied in both the left-to-right direc- tion and the right-to-left direction, resulting in two hidden vector sequences h</p><formula xml:id="formula_6">(1:n) l , h (1:n) r , respectively. Each ⃗ h i l is combined with its corresponding ⃗ h i r for final feature vector ⃗ h i f : ⃗ h i f = tanh(W l ⃗ h i l + W r ⃗ h i r + ⃗ b)</formula><p>, where W l , W r and ⃗ b are model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Output Layer</head><p>The output layer employs a conditional random field (CRF) to infer the POS t i of each word w i based on the feature layer outputs. The conditional probabil- ity of a tag sequence given an input sentence is:</p><formula xml:id="formula_7">p(⃗ y|⃗ x) = ∏ n i=1 Ψ(⃗ x, ⃗ y i ) ∏ n i=1 Φ(⃗ x, ⃗ y i , ⃗ y i−1 ) Z(⃗ x) ,</formula><p>where Z(⃗ x) is the partition function:</p><formula xml:id="formula_8">Z(⃗ x) = ∑ ⃗ y n ∏ i=1 Ψ(⃗ x, ⃗ y i ) n ∏ i=1 Φ(⃗ x, ⃗ y i , ⃗ y i−1 )</formula><p>In particular, the output clique potential Ψ(⃗ x, ⃗ y i ) shows the correlation between inputs and output la- bels: Ψ(⃗ x, ⃗ y i ) = exp(⃗ s i ), with the emission vector ⃗ s i being defined as:</p><formula xml:id="formula_9">⃗ s i = ⃗ θ 0 ⃗ h i f ,<label>(1)</label></formula><p>where ⃗ θ 0 is the model parameter. The edge clique potential shows the correlation between consecutive output labels using a single transition weight τ (⃗ y i , ⃗ y i−1 ).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Stacking</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Discrete Stacking</head><p>Stacking integrates corpora A and B by first training a tagger on corpus A, and then using the A tagger to provide additional features to a corpus B model. <ref type="figure">Figure 1</ref>(a) shows the training and testing of dis- crete stacking models, where the B tagger extracts features from both the raw sentence and A tagger output. This method achieves feature combination at the one-best-output level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Neural Stacking</head><p>Figure 3(a) and (b) shows the two neural stacking methods of this paper, respectively. Shallow Integration. <ref type="figure" target="#fig_1">Figure 3</ref>(a) is a variation of discrete stacking, with the output tags from tagger A being converted to a low-dimensional dense embed- ding features, and concatenated to the word embed- ding inputs to tagger B. Formally, for each word w i , denote the tagger A output as t i a , we concatenate the embedding form of t i a , denoted as ⃗ e i a , to the word representation ⃗ r i w .</p><formula xml:id="formula_10">⃗ r i ′ w = ⃗ r i w ⊕ ⃗ e i a = ⃗ e i w ⊕ ⃗ w i c ⊕ ⃗ e i a<label>(2)</label></formula><p>Deep Integration. <ref type="figure" target="#fig_1">Figure 3</ref>(b) offers deeper inte- gration between the A and B models, which is fea- sible only with neural network features. We call this method feature-level stacking. For feature-level in- tegration, the emission vector ⃗ s i in Eq.(1) is taken for input to tagger B via a projection:</p><formula xml:id="formula_11">⃗ w i a = tanh(W s ⃗ s i ) ⃗ r i w = ⃗ e i w ⊕ ⃗ w i c ⊕ ⃗ w i a ,</formula><p>where W s is a model parameter.</p><p>Fine-tuning. Feature-level stacking further al- lows tagger A to be fine-tuned during the training  <ref type="formula">)</ref>). This is a further benefit of neural stacking compared with discrete stacking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Multi-view Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Discrete Label Coupling</head><p>As shown in <ref type="figure">Figure 1</ref>(b), multi-view learning ( <ref type="bibr" target="#b24">Li et al., 2015</ref>) utilizes corpus A and corpus B simultane- ously for training. The coupled tagger directly learns the logistic correspondences between both corpora, therefore can lead a more comprehensive usage of corpus A compared with stacking. In order to better capture such correlation, specifically designed fea- ture templates between two tag sets are essential.</p><p>For each training instances, both A and B labels are needed. However, one type of tag is missing. <ref type="bibr" target="#b24">Li et al. (2015)</ref> used a mapping function to supple- ment the missing annotations with the help of the annotated tag. The result is a set of sentence with bundled tags in both annotations, but with ambigu- ities on one side, due to one-to-many mappings. <ref type="bibr" target="#b24">Li et al. (2015)</ref> showed that speed can be significantly improved by manually restricting possible mappings between the labelsets, but a full mapping without re- striction yields the highest accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Neural Multi-task Learning</head><p>Neural multi-task learning is free from manual fea- ture engineering, and avoids manual mapping func-tions between tag sets by establishing two separate output layers, one for each type of label, with shared low-level parameters. The general structure of a neural multi-view model is shown in <ref type="figure" target="#fig_2">Figure 4</ref>, which can be regarded as a variation of the parameter shar- ing model of <ref type="bibr" target="#b3">Caruana (1993)</ref> </p><note type="other">and Collobert et al. (2011). Leveraging heterogeneous annotations for the same task, compared to parameter sharing be- tween different NLP tasks (Collobert et al., 2011), can benefit from tighter integration of information, and hence allows deeper parameter sharing. These are verified empirically in the experiments.</note><p>In training and testing, sentences from both cor- pora go through the same input layer and feature layer. The outputs of each type of tag is then com- puted separately according to the shared parameters. The conditional probability of a tag sequence given an input sentence and its corpus type is:</p><formula xml:id="formula_12">p(⃗ y|⃗ x, T ) = ∏ n i=1 Ψ T (⃗ x, ⃗ y i ) ∏ n i=1 Φ T (⃗ x, ⃗ y i , ⃗ y i−1 ) Z T (⃗ x) ,</formula><p>where T is the corpus type, T ∈ {A, B}. Ψ T (⃗ x, ⃗ y i ) and Φ T (⃗ x, ⃗ y i , ⃗ y i−1 ) are the corresponding output clique potential and edge clique potential, respec- tively. Z T (⃗ x) is the partition function:</p><formula xml:id="formula_13">Z T (⃗ x) = ∑ ⃗ y n ∏ i=1 Ψ T (⃗ x, ⃗ y i ) n ∏ i=1 Φ T (⃗ x, ⃗ y i , ⃗ y i−1 )</formula><p>This indicates that each time only one output layer is activated according to the corpus type of input sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Training</head><p>A max-margin objective is used to train the full set of model parameters Θ:</p><formula xml:id="formula_14">L(Θ) = 1 D D ∑ d=1 l( ⃗ x d , ⃗ y d , Θ) + λ 2 ∥Θ∥ 2 ,</formula><p>where</p><formula xml:id="formula_15">⃗ x d , ⃗ y d | D d=1</formula><p>are the training examples, λ is a regularization parameter, and l(⃗ x d , ⃗ y d , Θ) is the max-margin loss function towards one example (⃗ x d , ¯ y d ). The max-margin loss function is defined as:</p><formula xml:id="formula_16">l(⃗ x d , ⃗ y d , Θ) = max y ( s(⃗ y|⃗ x d , Θ) + δ(⃗ y, ⃗ y d ) ) − s(⃗ y d |⃗ x d , Θ),</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Neural multi-view training</head><p>Input: Two training datasets:</p><formula xml:id="formula_17">D (1) = (x (1) n , y (1) n )| N n=1 , D (2) = (x (2) m , y<label>(2)</label></formula><p>m )| M m=2 ; Parameters: E, A, R Output: Θ 1: for i = 1 to E do 2:</p><p>Sample A instances from D <ref type="formula" target="#formula_9">(1</ref> where ⃗ y is the model output, s(⃗ y|⃗ x) = logP (⃗ y|⃗ x) is the log probability of ⃗ y and δ(⃗ y, ⃗ y d ) is the Hamming distance between ⃗ y and ⃗ y d .</p><p>We adopt online learning, updating parameters using AdaGrad <ref type="bibr" target="#b10">(Duchi et al., 2011</ref>). To train the neural stacking model, we first train a base tagger using corpus A. Then, we train the stacked tagger with corpus B, where the parameters of the A tagger has been pretrained from corpus A and the B tagger is randomly initialized.</p><p>For neural multi-view model, we follow <ref type="bibr" target="#b24">Li et al. (2015)</ref> and take a the corpus-weighting strategy to sample a number of training instances from both cor- pora for each training iteration, as shown in Algo- rithm 1. At each epoch, we randomly sample from the two datasets according to a corpus weights ratio, namely the ratio between the number of sentences in each dataset used for training, to form a training set for the epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Settings</head><p>We adopt the Penn Chinese Treebank version 5.0 (CTB5) ( <ref type="bibr" target="#b40">Xue et al., 2005</ref>) as our main corpus, with the standard data split following previous work <ref type="bibr" target="#b43">(Zhang and Clark, 2008;</ref><ref type="bibr" target="#b24">Li et al., 2015</ref>). People's Daily (PD) is used as second corpus with a differ- ent scheme. We filter out PD sentences longer than 200 words. Details of the datasets are listed in <ref type="table">Table  1</ref>. The standard token-wise POS tagging accuracy is used as the evaluation metric. The systems are implemented with LibN3L ( .</p><p>For all the neural models, we set the hidden layer size to 100, the initial learning rate for Adagrad to 0.01 and the regularization parameter λ to 10 −8 . word2vec 1 is used to pretrain word embeddings. The Chinese Giga-word corpus version 5 ( <ref type="bibr" target="#b14">Graff and Chen, 2005</ref>), segmented by zpar 2 ( <ref type="bibr" target="#b44">Zhang and Clark, 2011)</ref>, is used for the training corpus for word em- beddings. The size of word embedding is 50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Development Experiments</head><p>We use the development dataset for two main pur- poses. First, under each setting, we tune the model parameters, such as the number of training epochs. Second, we study the influence of several important hyper-parameters using the development dataset. For example, for the NN multi-view learning model, the corpus weights ratio (section 5) plays an im- portant role for the performance. We determine the parameters of the model by studying the accuracy along with the increasing epochs.</p><p>Effect of batch size and dropout. The batch size affects the speed of training convergence and the fi- nal accuracies of the neural models, and the dropout rate has been shown to significantly influence the performance ( . We investigate the effects of these two hyper-parameters by adopting a corpus weight ratio of 1 : 1 (All the CTB train- ing data is used, while the same amount of PD is sampled randomly), drawing the accuracies of the neural multi-view learning model against the num- ber of training epochs with various combinations of the dropout rate d and batch size b.  shown for the multi-view learning model. For the stacking model, we use b=100 for the PD sub model. The results are shown in <ref type="figure">Figure 5</ref>, where the two dashed lines on the top at epoch 30 represent the dropout rate of 20%, the two solid lines in the mid- dle represent zero dropout rate, and the two dotted lines in the bottom represent a dropout rate 50%. Without using dropout, the performance increases in the beginning, but then decreases as the number of training epochs increases beyond 10. This indi- cates that the NN models can overfit the training data without dropout. However, when a 50% dropout rate is used, the initial performances are significantly worse, which implies that the 50% dropout rate can be too large and leads to underfitting. As a result, we choose a dropout rate of 20% for the remaining ex- periments, which strikes the balance between over-System Accuracy CRF Baseline ( <ref type="bibr" target="#b24">Li et al., 2015)</ref> 94.10 CRF Stacking ( <ref type="bibr" target="#b24">Li et al., 2015)</ref> 94.81 CRF Multi-view ( <ref type="bibr" target="#b24">Li et al., 2015)</ref> 95 <ref type="table">Table 2</ref>: Accuracies on CTB-test.</p><note type="other">.00 NN Baseline 94.24 NN Stacking 94.74 NN Feature Stacking 95.01 NN Feature Stacking &amp; Fine-tuning 95.32 NN Multi-view 95.40 Integrated NN Multi-view &amp; Stacking 95.53</note><p>fitting and underfitting. <ref type="figure">Figure 5</ref> also shows that the batch size has a rela- tive small influence on the accuracies, which varies according to the dropout rate. We simply choose a batch size of 1 for the remaining experiments ac- cording to the performance at the dropout rate 20%.</p><p>Effect of corpus weights ratio. <ref type="figure">Figure 6</ref> shows the effects of different corpus weights ratios. In par- ticular, a corpus weights ratio of 1:0.2 yields relative low accuracies. This is likely because it makes use of the least amount of PD data. The ratios of 1:1 and 1:4 give comparable performances. We choose the former for our final tests because it is a much faster choice. <ref type="table">Table 2</ref> shows the final results on the CTB test data. We lists the results of stacking method of <ref type="bibr" target="#b18">Jiang et al. (2009)</ref> re-implemented by <ref type="bibr" target="#b24">Li et al. (2015)</ref>, and CRF multi-view method reported by <ref type="bibr" target="#b24">Li et al. (2015)</ref>. We adopt pair-wise significance test <ref type="bibr" target="#b6">(Collins et al., 2005</ref>) when comparing the results between two dif- ferent models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Final Results</head><p>Stacking. For baseline tagging using only CTB, NN model achieves a result of 94.24, slightly higher than CRF baseline (94.10). NN stacking model in- tegrating PD data achieves comparable performance (94.74) compared with CRF stacking model (94.81). Compared with NN baseline, NN stacking model boosts the performance from 94.24 to 94.74, which is significant at the confidence level p &lt; 10 −5 . This demonstrates that neural network model can utilize one-best prediction of the PD model for the CTB task as effectively as the discrete stacking method of <ref type="bibr" target="#b18">Jiang et al. (2009)</ref>.</p><p>One advantage of NN stacking as compared with discrete stacking method is that it can directly lever- age features of PD model for CTB tagging. Com- parison between feature-level stacking and one-best- output level stacking of the NN stacking model shows that the former gives significantly higher re- sults, namely 95.01 vs 94.74 at the confidence level p &lt; 10 −3 .</p><p>One further advantage of NN stacking is that it allows the PD model to be fine-tuned as an integral sub-model during CTB training. This is not possible for the discrete stacking model, because the output of the PD model are used as atomic feature in the stacking CTB model rather than a gradient admis- sive neural layer. By fine-tuning the PD sub-model, the performance is further improved from 95.01 to 95.32 at the confidence level p &lt; 10 −3 . The final NN stacking model improves over the NN baseline model from 94.24 to 95.32. The improvement is sig- nificantly higher compared to that by using discrete stacking which improves over the discrete baseline from 94.01 to 94.74. The final accuracy of the NN stacking model is higher than that of the CRF stack- ing model, namely 94.81 vs 95.32 at the confidence level p &lt; 10 −3 . This shows that neural stacking is a preferred choice for stacking.</p><p>Multi-view training. With respect of the multi- view training method, the NN model improves over the NN baseline from 94.24 to 95.40, by a margin of +1.16, which is higher than that of 0.90 brought by discrete method of <ref type="bibr" target="#b24">Li et al. (2015)</ref> over its base- line, from 94.10 to 95.00. NN multi-view training method gives relatively higher improvements com- pared with NN stacking method. This is consis- tent with the observation of <ref type="bibr" target="#b24">Li et al. (2015)</ref>, who showed that discrete label coupling training gives slightly better improvement compared with discrete stacking. The final accuracies of NN multi-view training is also higher than that of its CRF counter- part, namely 95.00 vs 95.40 at the confidence level p &lt; 10 −3 . The difference between the final NN multi-view training result of 95.40 and the final NN stacking results is not significant. <ref type="bibr">3</ref> Integration. The flexibility of the NN models further allows both stacking (on the input) and multi- viewing (on the output) to be integrated. When   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Speed Test</head><p>We compare the efficiencies of neural and discrete multi-view training by running our models and the model of <ref type="bibr" target="#b24">Li et al. (2015)</ref>  <ref type="bibr">4</ref> with default configura- tions on the CTB5 training data. The CRF baseline is adapted from <ref type="bibr" target="#b24">Li et al. (2015)</ref>. All the systems are implemented in C++ running on an Intel E5-1620 CPU. The results are shown in <ref type="table" target="#tab_7">Table 3</ref>. The NN baseline model is slower than the CRF baseline model. This is due to the higher computa- tion cost of a deep neural network on a CPU. Com- pared with the CRF baseline, the CRF multi-view model is significantly slower because of its large fea- ture set and the multi-label search space. However, the NN multi-view model achieves almost the same time cost with the NN baseline, and is much more efficient than the CRF counterpart. This shows the efficiency advantage of the NN multi-view model by parameter sharing and output splitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Early research on heterogeneous annotations fo- cuses on annotation conversion. For example, <ref type="bibr" target="#b13">Gao et al. (2004)</ref> proposed a transformation-based method to convert the annotation style of a word segmentation corpus to that of another. Manually designed transformation templates are used, which makes it difficult to generalize the method to other tasks and treebanks. <ref type="bibr" target="#b18">Jiang et al. (2009)</ref> described a stacking-based model for heterogeneous annotations, using a pipeline to integrate the knowledge from one cor- pus to another. <ref type="bibr" target="#b33">Sun and Wan (2012)</ref> proposed a structure-based stacking model, which makes use of structured features such as sub-words for model combination. These feature integration is stronger compared to those of <ref type="bibr" target="#b18">Jiang et al. (2009)</ref>. Johansson (2013) introduced path-based feature templates in using one parser to guide another. In contrast to the above discrete methods, our neural stacking method offers further feature integration by directly connect- ing the feature layer of the source tagger with the in- put layer of the target tagger. It also allows the fine- tuning of the source tagger. As one of the reviewers mentioned, two extensions of CRFs, dynamic CRFs ( <ref type="bibr" target="#b34">Sutton et al., 2004</ref>) and hidden-state CRFs <ref type="bibr" target="#b31">(Quattoni et al., 2004</ref>), can also perform similar deep in- tegration and fine-tuning.</p><p>For multi-view training, Johansson (2013) used a shared feature representation along with separate individual feature representation for each treebank. <ref type="bibr" target="#b30">Qiu et al. (2013)</ref> proposed a multi-task learning model to jointly predict two labelsets given an in- put sentences. The joint model uses the union of baseline features for each labelset, without consid- ering additional features to capture the interaction between the two labelsets. <ref type="bibr" target="#b24">Li et al. (2015)</ref> im- proves upon this method by using a tighter integra- tion between the two labelsets, treating the Carte- sian product of the base labels as a single combined labelset, and exploiting joint features from two la- belsets. Though capturing label interaction, their method suffers speed penalty from the sharply in- creased search space. In contrast to their methods, our neural approach enables parameter sharing in the hidden layers, thereby modeling label interaction without directly combining the two output labelsets. This leads to a lean model with almost the same time efficiency as a single-label baseline.</p><p>Recently, <ref type="bibr" target="#b45">Zhang and Weiss (2016)</ref> proposed a stack-propagation model for learning a stacked pipeline of POS tagging and dependency parsing. Their method is similar to our neural stacking in fine-tuning the stacked module which yields features for the target model. While their multi-task learning is on heterogenous tasks, our multi-task learning is defined on heterogenous treebanks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We investigated two methods for utilizing heteroge- neous annotations for neural network models, show- ing that they have respective advantages compared to their discrete counterparts. In particular, neural stacking allows tighter feature integration compared to discrete stacking, and neural multi-view training is free from the feature and efficiency constraints of discrete one. On a standard CTB test, the neu- ral method gives the best integration effect, with a multi-view training model enjoying the same speed as its single treebank baseline.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Baseline neural network tagger.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Neural stacking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Neural multi-view model. of tagger B, with the loss function being back propagated to tagger A via the ⃗ w i a layer (shown in the red dotted lines in Figure 3(b)). This is a further benefit of neural stacking compared with discrete stacking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: Accuracy on CTB-dev with different batch sizes and dropout rates for a multi-view learning model. b represents batch size, d denotes dropout rate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>System</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><head>Table 3 : Time for testing CTB training data.</head><label>3</label><figDesc></figDesc><table>NN multi-view training is combined with a fine-
tuned NN feature stacking model, the performance 
further increases from 95.40 to 95.53. This is the 
best results we are aware of on this dataset. The 
improvement is significant at the confidence level 
p &lt; 10 −2 compared with fine-tuned NN stacking 
model (95.32). This indicates that NN multi-view 
training and stacking model each provide unique ad-
vantages for heterogeneous annotations. 

</table></figure>

			<note place="foot" n="3"> Note, however, NN stacking method with one-best PD output gives significantly lower accuracies (94.74). It is the finetuning strategy that allows stacking to give comparable results compared to multi-view training for the NN models.</note>

			<note place="foot" n="4"> http://hlt.suda.edu.cn/zhli/resources/zhenghua-acl2015resources.zip</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The corresponding author is Yue Zhang. We thank Zhenghua Li and Meishan Zhang for providing data and the anonymous reviewers for their constructive comments, which helped to improve the paper. This work is supported by Singapore Ministry of Educa-tion Tier 2 Grant T2MOE201301 and Natural Sci-ence Foundation of China (61379086).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The tiger treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Dipper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Lezius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on treebanks and linguistic theories</title>
		<meeting>the workshop on treebanks and linguistic theories</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">168</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Stacked regressions. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="49" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multitask learning: A knowledge-based source of inductive bias1</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Richard A Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Machine Learning</title>
		<meeting>the Tenth International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A fast and accurate dependency parser using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Long short-term memory neural networks for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Clause restructuring for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivona</forename><surname>Kučerová</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd annual meeting on association for computational linguistics</title>
		<meeting>the 43rd annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="531" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="256" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="449" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Transitionbased dependeny parsing with stack long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53 rd Annual Meeting of the Association of Computational Linguistics and the 7 th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53 rd Annual Meeting of the Association of Computational Linguistics and the 7 th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The second international chinese word segmentation bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Emerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth SIGHAN workshop on Chinese language Processing</title>
		<meeting>the fourth SIGHAN workshop on Chinese language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">133</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Ning</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongqiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinsong</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haowei</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 42nd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page">462</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Chinese gigaword. LDC Catalog No.: LDC2003T09, ISBN</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="58563" to="58230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Bidirectional lstm-crf models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic adaptation of annotation standards: Chinese word segmentation and pos tagging: a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="522" to="530" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic adaptation of annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Yajuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Extended constituent-to-dependency conversion for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NODALIDA 2007</title>
		<meeting>NODALIDA 2007<address><addrLine>Tartu, Estonia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-05-25" />
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Training parsers on incompatible treebanks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="127" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Improving sentence compression by learning to predict gaze</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sigrid</forename><surname>Klerke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.03357</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01360</idno>
		<title level="m">Neural architectures for named entity recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Coupled sequence labeling on heterogeneous annotations: pos tagging as a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1783" to="1792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Finegrained opinion mining with recurrent neural networks and word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Tagging the web: Building a robust web tagger with neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="144" to="154" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Integrating graph-based and transition-based dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="950" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Maxmargin tensor neural network for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="293" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.05529</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Joint chinese word segmentation and pos tagging on heterogeneous annotated corpora with multiple task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="658" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariadna</forename><surname>Quattoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<title level="m">Conditional random fields for object recognition. Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1097" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The first international chinese word segmentation bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Sproat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Emerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second SIGHAN workshop on Chinese language processing</title>
		<meeting>the second SIGHAN workshop on Chinese language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="133" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Reducing approximation and estimation errors for chinese lexical processing with heterogeneous annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khashayar</forename><surname>Rohanimanesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="693" to="723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Stylebook for the tübingen treebank of written german (tüba-d/z)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Telljohann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erhard</forename><forename type="middle">W</forename><surname>Hinrichs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Zinsmeister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathrin</forename><surname>Beck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seminar fur Sprachwissenschaft, Universitat Tubingen</title>
		<meeting><address><addrLine>Tubingen, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Structured training for neural network transition-based parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd</title>
		<meeting>the 53rd</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="323" to="333" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="259" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A stacked, voted, stacked model for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003</title>
		<meeting>the seventh conference on Natural language learning at HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="200" to="203" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The penn chinese treebank: Phrase structure annotation of a large corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Dong</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural language engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="207" to="238" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Chinese word segmentation as character tagging. Computational Linguistics and Chinese Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="29" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Statistical dependency analysis with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyasu</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWPT</title>
		<meeting>IWPT</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A tale of two parsers: investigating and combining graph-based and transition-based dependency parsing using beamsearch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="562" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Syntactic processing using the generalized perceptron and beam search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="151" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Stack-propagation: Improved representation learning for syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1557" to="1566" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Libn3l:a lightweight package for neural nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyang</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Goggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marko</forename><surname>Grobelnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bente</forename><surname>Maegaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Mariani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Helene Mazo, Asuncion Moreno, Jan Odijk; Paris, France, may</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Nicoletta Calzolari (Conference Chair). European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep learning for chinese word segmentation and pos tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="647" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">End-to-end learning of semantic role labeling using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A neural probabilistic structured-prediction model for transition-based dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1213" to="1222" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
