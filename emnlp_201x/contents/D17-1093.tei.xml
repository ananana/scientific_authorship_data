<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:12+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ranking Kernels for Structures and Embeddings: A Hybrid Preference and Classification Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Tymoshenko</surname></persName>
							<email>{kateryna.tymoshenko,d.bonadiman}@unitn.it</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Bonadiman</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
							<email>amoschitti@gmail.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DISI</orgName>
								<orgName type="institution" key="instit2">University of Trento</orgName>
								<address>
									<postCode>38123</postCode>
									<settlement>Povo</settlement>
									<region>TN</region>
									<country>Italy Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Computing Research Institute</orgName>
								<orgName type="institution" key="instit2">HBKU</orgName>
								<address>
									<postCode>34110</postCode>
									<region>Doha</region>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ranking Kernels for Structures and Embeddings: A Hybrid Preference and Classification Model</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="897" to="902"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent work has shown that Tree Kernels (TKs) and Convolutional Neural Networks (CNNs) obtain the state of the art in answer sentence reranking. Additionally, their combination used in Support Vector Machines (SVMs) is promising as it can exploit both the syntactic patterns captured by TKs and the embeddings learned by CNNs. However, the embeddings are constructed according to a classification function, which is not directly exploitable in the preference ranking algorithm of SVMs. In this work, we propose a new hybrid approach combining preference ranking applied to TKs and pointwise ranking applied to CNNs. We show that our approach produces better results on two well-known and rather different datasets: WikiQA for answer sentence selection and SemEval cQA for comment selection in Community Question Answering.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent work on learning to rank (L2R) has shown that deep learning and kernel methods are two very effective approaches, given their ability of engineering features. In particular, in question answering (QA), Convolutional Neural Networks (CNN), e.g., <ref type="bibr" target="#b12">(Severyn and Moschitti, 2015;</ref><ref type="bibr" target="#b6">Miao et al., 2016;</ref><ref type="bibr" target="#b18">Yin et al., 2016)</ref> can automatically learn the representation of question and answer passage (Q/AP) in terms of word embeddings and their non-linear transformations. These are then used by the other layers of the network to mea- sure Q/AP relatedness. In contrast, Convolution Tree Kernels (CTK) can be applied to relational structures built on top of syntactic/semantic struc- tures derived from Q/AP text ( <ref type="bibr" target="#b15">Tymoshenko et al., 2016a</ref>). CNNs as well as CTKs can achieve the state of the art in ranking APs or also ques- tions. Considering their complementary approach for generating features, studying ways to com- bine them is very promising. In ( <ref type="bibr" target="#b15">Tymoshenko et al., 2016a</ref>), we investigated the idea of extract- ing layers from CNNs and using them in a ker- nel function to be further combined with CTKs in a composite reranking kernel. This was used in an SVM <ref type="bibr">Rank (Joachims, 2002</ref>) model, which ob- tained a significant improvement over the individ- ual methods. However, the simple use of CNN layers as vectors in a preference ranking approach is intutively not optimal since such layers are basi- cally learnt in a classification model, thus they are not optimized for SVM <ref type="bibr">Rank .</ref> In this work, we further compare and investi- gate different ways of combining CTKs and CNNs in reranking settings. In particular, we follow the intuition that as CNNs learn the embeddings in a classification setting they should be used in the same way for building the reranking kernel, i.e., we need to use the embeddings in a pointwise reranking fashion. Therefore, we propose a hy- brid preference-pointwise kernel, which consists in (i) a standard reranking kernel based on CTKs applied to the Q/AP structural representations; and (ii) a classification kernel based on the embed- dings learned by neural networks. The intuition about the hybrid models is to add CNN layer vec- tors, not their difference, to the preference CTK. That is, CNN layers are still used as they were used in a classification setting whereas CTKs fol- low the standard SVM Rank approach.</p><p>We tested our proposed models on the answer sentence selection benchmark, <ref type="bibr">WikiQA (Yang et al., 2015)</ref>, and the benchmark from cQA SemEval-2016 Task 3.A 1 corpus. We show that the proposed hybrid kernel consistently outper- forms standard reranking models in all settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Answer Sentence/Comment Selection</head><p>We focus on two question answering subtasks: an- swer sentence selection task (AST) and the com- ment selection task from cQA.</p><p>AST consists in selecting correct answer sen- tences (i.e., an AP composed of only one sentence) for a question Q from a set of candidate sentences, S = {s 1 , ..., s N }. In factoid question answering, Q typically asks for an entity or a fact, e.g., time location and date. S is typically a result of so- called primary search, a result of fast-recall/low- precision search for potential answer candidates. For example, it could be a set of candidate APs re- turned when running a search engine over a large corpus using Q as a search query. Many such APs are typically not pertinent to the original question, thus automatic approaches for selecting those use- ful are very valuable.</p><p>cQA proposes a task similar to AST, where Q is a question asked by a user in a web forum and S are the potential answers to the question posted as comments by other users. Again, many com- ments in a cQA thread do not contain an answer to the original question, thus raising the need for automatic comment selection.</p><p>The crucial features for both tasks capture infor- mation about the relations between Q and an AP. Manual feature engineering can provide competi- tive results ( <ref type="bibr" target="#b9">Nicosia et al., 2015)</ref>, however, it re- quires significant human expertise in the specific domain and is time-consuming. Thus, machine learning methods for automatic feature engineer- ing are extremely valuable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CTK and CNN models</head><p>Our baselines are the standalone CTK and CNN models originally proposed in <ref type="bibr">(Severyn et al., task3/ 2013;</ref><ref type="bibr" target="#b12">Severyn and Moschitti, 2015)</ref> and further advanced in ( <ref type="bibr">Tymoshenko et al., 2016a,b)</ref>. The following subsections provide a brief overview of these models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">CTK structures</head><p>The CTK models are applied to syntactic struc- tural representations of Q and AP. We used shal- low chunk-based and constituency tree represen- tations in AST ( <ref type="bibr" target="#b15">Tymoshenko et al., 2016a</ref>) and cQA ( <ref type="bibr" target="#b16">Tymoshenko et al., 2016b</ref>), respectively. We follow the tree construction algorithms provided in the work above. Due to the space restrictions, we present only high-level details below.</p><p>A shallow chunk-based representations of a text contains lemma nodes at leaf level and their part- of-speech (POS) tag nodes at the preterminal level. The latter are further grouped under the chunk and sentence nodes.</p><p>A constituency tree representation is an ordi- nary constituency parse tree. In all representa- tions, we mark lemmas that occur in both Q and AP by prepending the REL tag to the labels of the corresponding preterminal nodes and their par- ents.</p><p>Moreover, in the AST setting, often question and focus classification information is used ( <ref type="bibr" target="#b4">Li and Roth, 2002</ref>), thus we enrich our representa- tion with the question class and focus information, when is available.</p><p>Additionally, we mark AP chunks containing named entities that match the expected answer type of the question by prepending REL-FOCUS- &lt;QC&gt; to them. Here, the &lt; QC &gt; placeholder is substituted with the actual question class. <ref type="figure" target="#fig_0">Fig. 1</ref> il- lustrates a shallow chunk-based syntactic structure enriched with relational tags. We use a sentence model built with a convolu- tion operation followed by a k-max pooling layer with k = 1. The sentence vectors, x s i , are con- catenated together and given in input to standard NN layers, which are constituted by a non-linear hidden layer and a sigmoid output layer. The sen- tence encoder, x s i = f (s i ) outputs a fixed-size vector representation of the input sentence s i (we will refer to f (s i ) as question embedding, QE, and answer embedding, AE, respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Convolutional Neural Networks</head><p>Additionally, we encode the relational informa- tion between Q and AP, by injecting relation fea- tures into the network. In particular, we associate each word w of the input sentences with a word overlap binary feature indicating if w is shared by both Q and AP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Hybrid learning to rank model</head><p>We represent a Q/AP pair as p = (q, a, x), where q and a are the structural representations of Q and AP (as described in Sec. 3), and x is a feature vec- tor that incorporates the features characterizing the Q/AP pair (e.g., similarity features between Q and AP or their embeddings learned by an NN).</p><p>Reranking kernel. This kernel captures differ- ences between two Q/AP pairs, p 1 and p 2 , and pre- dicts which pair should be ranked higher, i.e., in which pair, AP has higher probability to provide a correct answer to Q. In the reranking setting, a training/classification instance is a pair of Q/AP pairs, p 1 = (q, a 1 , x 1 ), p 2 = (q, a 2 , x 2 ). The instance is positive if p 1 is ranked higher than p 2 , and negative otherwise. One approach for pro- ducing training data is to form pairs both using p <ref type="bibr" target="#b13">Shen and Joshi, 2003)</ref>:</p><note type="other">1 , p 2 and p 2 , p 1 , thus generating both positive and negative examples. However, since these are clearly redundant as formed by the same members, it is more efficient training with a reduced set of examples such that members are not swapped. Algorithm 1 describes how we generate a more compact set of positive (E + ) and negative (E − ) training examples for a specific Q. Given a pair of examples, p 1 , p 2 and p 1 , p 2 , we used the following preference kernel (</note><formula xml:id="formula_0">R K (p 1 , p 2 , p 1 , p 2 ) = K(p 1 , p 1 )+ +K(p 2 , p 2 ) − K(p 1 , p 2 ) − K(p 2 , p 1 ),<label>(1)</label></formula><p>which is equivalent to the dot product between vector subtractions, i.e.,</p><formula xml:id="formula_1">φ(p 1 )−φ(p 2 ) · φ(p 1 )− φ(p 2 )</formula><p>, used in preference reranking, where φ is a feature map. Additionally, we indicate (i) with R T K the preference kernel using TKs applied to q and a trees, i.e., T K(p i , p j ) = T K(q i , q j ) + T K(a i , a j ); and (ii) with R V , the preference ker- nel applied to vectors, i.e., V (p i , p j ) = V ( x i , x j ). Our final reranking kernel is:</p><formula xml:id="formula_2">RK(p 1 , p 2 , p 1 , p 2 ) = R T K (p 1 , p 2 , p 1 , p 2 )+ +R V (p 1 , p 2 , p 1 , p 2 )<label>(2)</label></formula><p>Now, if we substitute the explicit form for R V , we have:</p><formula xml:id="formula_3">RK(p 1 , p 2 , p 1 , p 2 ) = R T K (p 1 , p 2 , p 1 , p 2 )+ +V (p 1 , p 1 ) + V (p 2 , p 2 ) − V (p 1 , p 2 ) − V (p 2 , p 1 )</formula><p>Since our vectors are internal network layers in order to not lose important information with differ- ences (operated by R V ), we only keep V (p 1 , p 1 ) (or equivalently V (p 2 , p 2 )), i.e.,</p><formula xml:id="formula_4">RK(p 1 , p 2 , p 1 , p 2 ) = R T K (p 1 , p 2 , p 1 , p 2 )+ V (p 1 , p 1 )<label>(3)</label></formula><p>Note that our approach also works when using Alg. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Generating training data for reranking</head><p>Require: Sq+, Sq− -(q, a, x)-triplets for correct and wrong answer sentences per question Q 1: E+ ← ∅, E− ← ∅, f lip ← true 2: for all s+ ∈ Sq+ do 3:</p><p>for all s− ∈ Sq− do 4: if f lip == true then 5:</p><p>E+ ← E+ ∪ (s+, s−) 6:</p><p>f lip ← false 7: else 8:</p><formula xml:id="formula_5">E− ← E− ∪ (s−, s+) 9:</formula><p>f lip ← true 10: return E+, E−</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In our experiments, we compare various methods of combining CTKs and CNNs, using standard and our hybrid reranking kernels. The software for reproducing our experimental results is avail- able at https://github.com/iKernels/ RelTextRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental setup</head><p>WikiQA, sentence selection dataset: this was created for open domain QA. Text Preprocessing: we used the Illinois chun- ker <ref type="bibr" target="#b10">(Punyakanok and Roth, 2001</ref>) and the Stanford CoreNLP ( <ref type="bibr" target="#b5">Manning et al., 2014</ref>) toolkit, v3.6.0. When experimenting with SemEval-2016, we per- form preprocessing as in ( <ref type="bibr" target="#b15">Tymoshenko et al., 2016a</ref>), e.g., we truncate all the comments to 2000 symbols and sentences to 70 words.</p><p>CTKs: we trained our models with SVM-Light- TK 4 using the partial tree kernel (PTK) and the subset tree kernel (STK). We use PTK for WikiQA and STK for SemEval as suggested in our previ- ous work ( <ref type="bibr" target="#b15">Tymoshenko et al., 2016a</ref>) with default <ref type="table" target="#tab_0">Dataset  Q  AP  Q with AP  WikiQA-train 2,118 20,360  873  WikiQA-test  633  6,165  243  WikiQA-dev  296  2,733  126   Table 1</ref>: WikiQA statistics.</p><p>parameters and the polynomial kernel (P) of de- gree 3 on all feature vectors, which are embed- dings learned as described in Section 3.2.</p><p>Neural Network (CNN) setup: we used the same setup and parameters as (Tymoshenko et al., 2016a): we pre-initialize the word embeddings with skipgram embedding of dimensionality 50 trained on the English Wikipedia dump ( <ref type="bibr" target="#b7">Mikolov et al., 2013)</ref>. We used a single non-linear hidden layer (with hyperbolic tangent activation, Tanh), whose size is equal to the size of the previous layer, i.e., the join layer. The network is trained us- ing SGD with shuffled mini-batches using the Rm- sprop update rule <ref type="bibr" target="#b14">(Tieleman and Hinton, 2012</ref>). The model is trained until the validation loss stops improving. The size of the sentences embedding (QE and AE) and of the join layer is set as 200.</p><p>QA metrics: we report our results in terms of Mean Average Precision (MAP), Mean Recipro- cal Rank (MRR) and P@1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ranking with trees and embeddings</head><p>We evaluate the combination techniques proposed in Sec. 4 on the SemEval-2016 and WikiQA de- velopment (DEV) and test (TEST) sets. Addition- ally, to have more reliable results, it is standard practice to apply n-fold cross-validation. How- ever, we cannot do this on the training (TRAIN) sets, since the embeddings learned in Sec. 3.2 are trained on TRAIN by construction, and therefore cross-validation on TRAIN would exhibit unreal- istically high performance. Thus, we employed the following disjoint Cross Validation approach: we train 5 models as in traditional 5-fold cross- validation on TRAIN. Then, we merged WikiQA DEV and TEST sets, split the resulting set into 5 subsets, and use i-th subset to test the model trained in i-th fold (i=1,..,5). <ref type="table" target="#tab_2">Table 2</ref> reports the performance of the models. Here, Rank corresponds to the traditional rerank- ing model described by Eq. 2 in Sec. 4. Hybrid refers to our new reranking/classification kernels described by Eq. 3. V means that the model uses a kernel applied to the embedding feature vectors only. T specifies that the model employs struc-  <ref type="table" target="#tab_0">Task 3.A  DEV  TEST  Cross Validation  DEV  TEST  MRR  MAP  P@1  MRR  MAP  P@1  MRR  MAP  P@1  MAP  MRR  MAP  MRR  Rank:T  72.</ref>  tural representations with a tree kernel. Finally, V +T means that both embedding feature vectors and trees are used. The experiments show that: in general, a stan- dalone model with CTKs applied to the syntac- tic structures (Rank:T) outperforms the standalone feature-based models using embeddings as feature vectors (V).</p><formula xml:id="formula_6">- - - - - - ABCNN - - - 71.27 69.14 - - - - - - - - KeLP (#1) - - - - - - - - - - - 79.19 86.42 ConvKN (#2) - - - - - - - - - - - 77.66 84.93</formula><p>Then, the straightforward combination of tree and polynomial kernels applied to the syntactic structural representations and embeddings (Rank: T+V) does not improve over the Rank: T model. At the same time, the Hybrid model consistently outperforms all the other models in all possible ex- perimental configurations, thus confirming our hy- pothesis that the classification setting is more ap- propriate when using embeddings as feature vec- tors in the kernel-based ranking models.</p><p>Additionally, for reference, we report the per- formance of the CNN we used to obtain the em- beddings. It is consistently outperformed by the Hybrid model on all the datasets.</p><p>Finally, in the last four lines of Tab. 2, we re- port the performance of the state-of-the-art mod- els from previous work, measured on exactly the same experimental settings we used.</p><p>Here Rank':T+V is our model described in ( <ref type="bibr" target="#b15">Tymoshenko et al., 2016a</ref>), based on the tradi- tional reranking model. Our updated version ob- tains comparable performance on WikiQA-DEV and slightly lower performance on WikiQA-TEST (probably, just due to differences in preprocessing after we updated our pre-processing pipelines). ABCNN ( <ref type="bibr" target="#b18">Yin et al., 2016</ref>) is another state-of- the-art system based on advanced attention-based convolutional networks. All our models involving CTKs outperform it.</p><p>KeLP (#1) ( <ref type="bibr" target="#b1">Filice et al., 2016</ref>) and ConvKN (#2) <ref type="bibr" target="#b0">(Barrón-Cedeño et al., 2016</ref>) are the two top- performing SemEval 2016, Task 3.A competition systems <ref type="bibr">(Nakov et al., 2016)</ref>. ConvKN (#2) is an earlier version of our approach, which also em- ploys CTKs and embeddings. Both KeLP and ConvKN (i) employ cQA-domain-specific hand- crafted features, which also consider the thread- level information, while in this work, we do not use manually engineered features; (ii) they employ PTK, which is capable of learning more power- ful features than SST, but it is more computation- ally complex; (iii) KeLP system parameters were optimized in cross-validation on the training set, while, in this work, we perform no parameter op- timization. Nevertheless, the performance of our Hybrid:T+V models on SemEval TEST is compa- rable to that of ConvKN (#2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we have studied and compared state- of-the-art feature engineering approaches, namely CTKs and CNNs, on two different QA tasks, AST and cQA. We investigated the ways of combining the two approaches into a single model and pro- posed a hybrid reranking-classification kernel for combining the structural representations and em- beddings learned by CNNs.</p><p>We have shown that the combination of CTKs and CNNs with a hybrid kernel in the reranking setting outperforms the state of the art on AST and is comparable to the state of the art in cQA. In par- ticular, in cQA, a combination of CTKs and CNNs performs comparably to the systems using domain specific features that were manually engineered.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Shallow chunk-based tree representation of a question in the Q/AP pair: Q: "Who wrote white Christmas?", AP: "White Christmas is an Irving Berlin song".</figDesc><graphic url="image-1.png" coords="2,72.00,63.80,464.64,67.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>A</head><label></label><figDesc>Figure 2: CNN architecture to compute the similarity between question and answer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 provides</head><label>1</label><figDesc>the statistics regarding this dataset. Following Yang et al. (2015), we discard questions that have either only correct or only incorrect answers. cQA, SemEval-2016 dataset: we used the En- glish data from Task 3, Subtask A 2 . We can ex- actly compare with the state of the art in SemEval. It contains questions collected from the Qatar Liv- ing forum 3 and the first ten comments per question manually annotated. The train, dev. and test sets contain 1790, 244 and 327 questions, respectively.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Experimental results on WikiQA and SemEval-2016 Task 3.A corpora 

</table></figure>

			<note place="foot" n="1"> http://alt.qcri.org/semeval2016/</note>

			<note place="foot" n="2"> http://alt.qcri.org/semeval2016/ task3/index.php?id=description-of-tasks 3 http://www.qatarliving.com/forum 4 http://disi.unitn.it/moschitti/ Tree-Kernel.htm</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been partially supported by the EC project CogNet, 671625 (H2020-ICT-2014-2, Re-search and Innovation action). We would like to thank Raniero Romagnoli for helping us to review an early draft of this paper. Many thanks to the anonymous reviewers for their professional work and valuable suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">ConvKN at SemEval-2016 Task 3: Answer and Question Selection for Question Answering on Arabic and English Fora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Alobaidli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Romeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="896" to="903" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Kelp at semeval-2016 task 3: Learning semantic relations between questions and answers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Filice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of SemEval</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1116" to="1123" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Optimizing search engines using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM KDD</title>
		<meeting>ACM KDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning question classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL: System Demonstrations</title>
		<meeting>ACL: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural variational inference for text processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishu</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NIPS 26</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">task 3: Community question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Márquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Freihat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval &apos;16. ACL</title>
		<meeting>SemEval &apos;16. ACL</meeting>
		<imprint/>
	</monogr>
<note type="report_type">Randeree. 2016. SemEval-2016</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">QCRI: Answer selection for community question answering-experiments for Arabic and English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nicosia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Filice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Darwish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Magdy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The use of classifiers in sequential inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="995" to="1001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning adaptable patterns for passage reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nicosia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">75</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to rank short text pairs with convolutional deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An SVM based voting algorithm with application to parse reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CONLL, CONLL &apos;03</title>
		<meeting><address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tijmen</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COURSERA: Neural Networks for Machine Learning</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convolutional neural networks vs. convolution kernels: Feature engineering for answer sentence reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Bonadiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1268" to="1278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to rank nonfactoid answers: Comment selection in web forums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Bonadiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2049" to="2052" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Wikiqa: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
		<editor>EMNLP. ACL</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Abcnn: Attention-based convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Wenpeng Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="259" to="272" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep Learning for Answer Sentence Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Pulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
