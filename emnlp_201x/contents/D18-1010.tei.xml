<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TWOWINGOS: A Two-Wing Optimization Strategy for Evidential Claim Verification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">TWOWINGOS: A Two-Wing Optimization Strategy for Evidential Claim Verification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="105" to="114"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>105</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Determining whether a given claim is supported by evidence is a fundamental NLP problem that is best modeled as Textual En-tailment. However, given a large collection of text, finding evidence that could support or refute a given claim is a challenge in itself, amplified by the fact that different evidence might be needed to support or refute a claim. Nevertheless , most prior work decouples evidence identification from determining the truth value of the claim given the evidence. We propose to consider these two aspects jointly. We develop TWOWINGOS (two-wing optimization strategy), a system that, while identifying appropriate evidence for a claim, also determines whether or not the claim is supported by the evidence. Given the claim, TWOWINGOS attempts to identify a subset of the evidence candidates; given the predicted evidence, it then attempts to determine the truth value of the corresponding claim. We treat this challenge as coupled optimization problems, training a joint model for it. TWOWINGOS offers two advantages: (i) Unlike pipeline systems, it facilitates flexible-size evidence set, and (ii) Joint training improves both the claim verification and the evidence identification. Experiments on a benchmark dataset show state-of-the-art performance. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A claim, e.g., "Marilyn Monroe worked with Warner Brothers", is an assertive sentence that may be true or false. While the task of claim verification will not tell us the absolute truth of this claim, it is expected to determine whether the claim is supported by evidence in a given text col- lection. Specifically, given a claim and a text cor- pus, evidential claim verification, demonstrated in <ref type="bibr">1</ref>  Figure 1: Illustration of evidential claim verification task. For a claim, we determine its truth value by evi- dence identified from a text corpus. <ref type="figure">Figure 1</ref>, aims at identifying text snippets in the corpus that act as evidence that supports or refutes the claim. This problem has broad applications. For exam- ple, knowledge bases (KB), such as Freebase ( <ref type="bibr" target="#b2">Bollacker et al., 2008)</ref>, <ref type="bibr">YAGO (Suchanek et al., 2007)</ref>, can be augmented with a new relational statement such as "(Afghanistan, is source of, Kushan Dy- nasty)". This needs to be first verified by a claim verification process and supported by evidence ( <ref type="bibr" target="#b15">Roth et al., 2009;</ref><ref type="bibr" target="#b3">Chaganty et al., 2017</ref>). More broadly, claim verification is a key component in any technical solution addressing recent concerns about the trustworthiness of online content <ref type="bibr" target="#b19">(Vydiswaran et al., 2011;</ref><ref type="bibr" target="#b13">Pasternack and Roth, 2013;</ref><ref type="bibr" target="#b8">Hovy et al., 2013)</ref>. In both scenarios, we care about whether or not a claim holds, and seek re- liable evidence in support of this decision.</p><p>Evidential claim verification requires that we address three challenges. First, to locate text snip- pets in the given corpus that can potentially be used to determine the truth value of the given claim. This differs from the conventional textual entailment (TE) problem <ref type="bibr" target="#b5">(Dagan et al., 2013</ref>) as here we first look for the premises given a hypoth- esis. Clearly, the evidence one seeks depends on the claim, as well as on the eventual entailment decision -the same claim would require different supporting than refuting evidence. This motivates us to develop an approach that can transfer knowl- edge from claim verification to evidence identifi- cation. Second, the evidence for a claim might re- quire aggregating information from multiple sen- tences and even multiple documents (rf. #3 in <ref type="table">Ta- ble 4</ref>). Therefore, a set, rather than a collection of independent text snippets, should be chosen to act as evidence. And, finally, in difference from TE, given a set of evidence sentences as a premise, the truth value of the claim should depend on all of the evidence, rather than on a single sentence there.</p><p>The discussion above suggests that claim verifi- cation and evidence identification are tightly cou- pled. Claim should influence the identification of appropriate evidence, and "trusted evidence boosts the claim's veracity" <ref type="bibr" target="#b19">(Vydiswaran et al., 2011</ref>). Consequently, we propose TWOWINGOS, a two- wing optimization strategy 2 , to support this pro- cess. As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, we consider a set of sentences S as the candidate evidence space, a claim x, and a decision space Y for the claim veri- fication. In the optimal condition, a one-hot vector over Y indicates which decision to make towards the claim, and a binary vector over S indicates a subset of sentences S e (in blue in <ref type="figure" target="#fig_0">Figure 2</ref>) to act as evidence.</p><p>Prior work mostly approached this problem as a pipeline procedure -first, given a claim x, de- termine S e by some similarity matching; then, conduct textual entailment over (S e , x) pairs. Our framework, TWOWINGOS, optimizes the two subtasks jointly, so that both claim verification and evidence identification can enhance each other. TWOWINGOS is a generic framework making use of a shared representation of the claim to co- train evidence identification and claim verifica- tion.</p><p>TWOWINGOS is tested on the FEVER bench- mark ( <ref type="bibr" target="#b17">Thorne et al., 2018)</ref>, showing ≈30% F 1 im- provement for evidence identification, and ≈23% accuracy increase in claim verification. Our analy- sis shows that (i) entity mentions in claims provide a strong clue for retrieving relevant passages; (ii) composition of evidence clues across sentences helps claim verification; and that (iii) the joint training scheme provides significant benefits of a pipeline architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Most work focuses on the dataset construction while lacking advanced models to handle the prob- lem. <ref type="bibr" target="#b18">Vlachos and Riedel (2014)</ref> propose and de- fine the "fact checking" problem, without a con- crete solution. <ref type="bibr" target="#b7">Ferreira and Vlachos (2016)</ref> re- lease the dataset "Emergent" for rumor debunking. Each claim is accompanied by an article headline as evidence. Then a three-way logistic regression model is used over some rule-based features. No need to search for evidence. <ref type="bibr" target="#b21">Wang (2017)</ref> release a larger dataset for fake news detection, and propose a hybrid neural network to integrate the statement and the speaker's meta data to do classification. However, the presentation of evidences is ignored. <ref type="bibr" target="#b9">Kobayashi et al. (2017)</ref> release a similar dataset to <ref type="bibr" target="#b17">(Thorne et al., 2018</ref>), but they do not consider the evaluation of evidence reasoning.</p><p>Some work mainly pays attention to determin- ing whether the claim is true or false, assuming ev- idence facts are provided or neglecting presenting evidence totally, e.g., <ref type="bibr" target="#b0">(Angeli and Manning, 2014)</ref> -given a database of true facts as premises, pre- dicting whether an unseen fact is true and should belong to the database by natural logic inference. Open-domain question answering (QA) against a text corpus ( <ref type="bibr" target="#b22">Yin et al., 2016;</ref><ref type="bibr" target="#b4">Chen et al., 2017;</ref><ref type="bibr" target="#b20">Wang et al., 2018</ref>) can also be treated as claim ver- ification problem, if we treat (question, correct an- swer) as a claim. However, little work has studied how well a QA system can identify all the answer evidence.</p><p>Only a few works considered improving the evi- dence presentation in claim verification problems. <ref type="bibr" target="#b15">Roth et al. (2009)</ref> introduce the task of Entailed Relation Recognition -given a set of short para- graphs and a relational fact in the triple form of (argument 1 , relation, argument 2 ), finding the para- graphs that can entail this fact. They first use Ex- panded Lexical Retrieval to rank and keep the top- k paragraphs as candidates, then build a TE clas- sifier over each (candidate, statement) pair. The work directly related to us is by <ref type="bibr" target="#b17">Thorne et al. (2018)</ref>. Given claims and a set of Wikipages, <ref type="bibr" target="#b17">Thorne et al. (2018)</ref> use a retrieval model based on TF-IDF to locate top-5 sentences in top-5 pages as evidence, then utilize a neural entailment model to classify (evidence, claim) pairs.</p><p>In contrast, our work tries to optimize the claim verification as well as the evidence identification in a joint training scheme, which is more than just supporting or refuting the claims. <ref type="figure" target="#fig_0">Figure 2</ref> illustrates the two-wing optimization problem addressed in this work: given a collec- tion of evidence candidates S={s 1 , s 2 , · · · , s i , · · · , s m }, a claim x and a decision set Y = {y 1 · · · , y n }, the model TWOWINGOS predicts a binary vector p over S and a one-hot vector o over Y against the ground truth, a binary vector q and a one-hot vec- tor z, respectively. A binary vector over S means a subset of sentences (S e ) act as evidence, and the one-hot vector indicates a single decision (y i ) to be made towards the claim x given the evidence S e . Next, we use two separate subsections to elab- orate the process of evidence identification (i.e., optimize p to q) and the claim verification (i.e., optimize o to z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The TWOWINGOS Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evidence identification</head><p>A simple approach to identifying evidence is to de- tect the top-k sentences that are lexically similar to the claim, as some pipeline systems ( <ref type="bibr" target="#b15">Roth et al., 2009;</ref><ref type="bibr" target="#b17">Thorne et al., 2018)</ref> do. However, a claim- unaware fixed k is less optimal, adding noise or missing key supporting factors, consequently lim- iting the performance.</p><p>In this work, we approach the evidence by mod- eling sentences S={s 1 , · · · , s i , · · · , s m } with the claim x as context in a supervised learning scheme. For each s i , the problem turns out to be learning a probability: how likely s i can entail the claim conditioned on other candidates as context, as shown by the blue items in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>To start, a piece of text t (t ∈ S ∪ {x}) is repre- sented as a sequence of l hidden states, forming a feature map T ∈ R d×l , where d is the dimension- ality of hidden states. We first stack a vanilla CNN (convolution &amp; max-pooling) ( <ref type="bibr" target="#b10">LeCun et al., 1998)</ref> over T to get a representation for t. As a result, each evidence candidate s i has a representation s i , and the claim x has a representation x. To get a probability for each s i , we need first to build its claim-aware representation r i .</p><p>Coarse-grained representation. We directly concatenate the representation of s i and x, gen- erated by the vanilla CNN, as:</p><formula xml:id="formula_0">r i = [s i , x, s i · x T ]<label>(1)</label></formula><p>This coarse-grained approach makes use of merely the sentence-level representations while neglect- ing more fine-grained interactions between the sentences and the claim.</p><p>Fine-grained representation. Instead of di- rectly employing the sentence-level representa- tions, here we explore claim-aware representations for each word in sentence s i , then compose them as the sentence representation r i , inspired by the Attentive Convolution ( <ref type="bibr" target="#b23">Yin and Schütze, 2017)</ref>. For each word s j i in s i , we first calculate its matching score towards each word x z in x, by dot product over their hidden states. Then the repre- sentation of the claim, as the context for the word s j i , is formed as: </p><formula xml:id="formula_1">c j i = z softmax(s j i · (x z ) T ) · x z<label>(2)</label></formula><formula xml:id="formula_2">i j i = tanh(W · [s j−1 i , s j i , s j+1 i , c j i ] + b) (3) where parameters W ∈ R d×4d , b ∈ R d .</formula><p>To compose those claim-aware word represen- tations as the representation for sentence s i , we use a max-pooling over {i j i } along with j, gener- ating i i .</p><p>We use term f int (s i , x) to denote this whole process, so that:</p><formula xml:id="formula_3">i i = f int (s i , x)<label>(4)</label></formula><p>At this point, the fine-grained representation for evidence candidate s i is:</p><formula xml:id="formula_4">r i = [s i , x, s i · x T , i i ]<label>(5)</label></formula><p>Loss function. With a claim-aware representa- tion r i , the sentence s i subsequently gets a prob- ability, acting as the evidence, α i ∈ (0, 1) via a non-linear sigmoid function:</p><formula xml:id="formula_5">α i = sigmoid(v · r T i )<label>(6)</label></formula><p>where parameter vector v has the same dimension- ality as r i .</p><p>In the end, all evidence candidates in S have a ground-truth binary vector q and the predicted probability vector α; then loss l ev ("ev": evidence) is implemented as a binary cross-entropy:</p><formula xml:id="formula_6">l ev = m i=1 −(q i log(α i )+(1−q i ) log(1−α i )) (7)</formula><p>As the output of this evidence identification module, we binarize the probability vector α by</p><formula xml:id="formula_7">p i = [α i &gt; 0.5] ("[x]</formula><p>" is 1 if x is true or 0 other- wise). p i indicates s i is evidence or not. All {s i } with p i = 1 act as evidence set S e .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Claim verification</head><p>As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, to figure out an entailment decision y i for the claim x, the evidence S e pos- sibly consists of more than one sentence. Further- more, those evidence sentences are not necessar- ily in textual order nor from the same passage. So, we need a mechanism that enables each evi- dence or even each word inside to be aware of the content from other evidence sentences. Similar to the aforementioned approach to evidence identifi- cation, we come up with three methods, with dif- ferent representation granularity, to learn a repre- sentation for (S e , x), i.e., the input for claim veri- fication, shown in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>Coarse-grained representation. In this case, we treat S e as a whole, constructing its represen- tation e by summing up the representations of all sentences in S e in a weighted way:</p><formula xml:id="formula_8">e = m i=1 α i · p i · s i<label>(8)</label></formula><p>where α i , from Equation 6, is the probability of s i being the evidence. Then the (S e , x) pair gets a coarse-grained con- catenated representation: <ref type="bibr">[e, x]</ref>. It does not model the interactions within the evidence nor the in- teractions between the evidence and the claim. Based on our experience in evidence identification module, the representation of a sentence is better learned by composing context-aware word-level representations. Next, we introduce how to learn fine-grained representation for the (S e , x) pair.</p><p>Single-channel fine-grained representation. By "single-channel," we mean each sentence s i is aware of the claim x as its single context. </p><note type="other">f int (s i , x) for s i and x i = f int (x, s i ) for x.</note><p>For (S e , x), we compose all the {i i } and all the {x i } along with i, via a weighted max-pooling:</p><formula xml:id="formula_9">e = maxpool i (α i · p i · i i ) (9) x = maxpool i (α i · p i · x i )<label>(10)</label></formula><p>This weighted max-pooling ensures that the sentences with higher probabilities of being evi- dence have a higher chance to present their fea- tures. As a result, (S e , x) gets a concatenated rep- resentation: <ref type="bibr">[e, x]</ref> Two-channel fine-grained representation. By "two-channel," we mean that each evidence s i is aware of two kinds of context, one from the claim x, the other from the remaining evidences.</p><p>Our first step is to accumulate evidence clues within S e . To start, we concatenate all sentences in S e as a fake long sentencê S consisting of hidden states {ˆs}{ˆs}. Similar to Equation 2, for each word s j i in sentence s i , we accumulate all of its related clues (c j i ) fromˆSfromˆ fromˆS as follows:</p><formula xml:id="formula_10">c j i = z softmax(s j i · (ˆ s z ) T ) · ˆ s z<label>(11)</label></formula><p>Then we update s j i , the representation of word s j i , by element-wise addition:</p><formula xml:id="formula_11">s j i = s j i ⊕ c j i<label>(12)</label></formula><p>This step enables the word s j i to "see" all related clues from S e . The reason we add s j i and c j i is mo- tivated by a simple experience: Assume the claim "Lily lives in the biggest city in Canada", and one sentence contains a clue "· · · Lily lives in Toronto · · · " and another sentence contains a clue "· · · Toronto is Canada's largest city· · · ". The most simple yet effective approach to aggregating the two clues is to sum up their representation vectors (Blacoe and Lapata, 2012) (we do not concatenate them, as those clues have no consistent textual or- der across different s j i ). After updating the representation of each word in s i , we perform the aforementioned "single- channel fine-grained representation" between the updated s i and the claim x, generating <ref type="bibr">[e, x]</ref>.</p><p>Loss function. For the claim verification input (S e , x), we forward its representation <ref type="bibr">[e, x]</ref>  <ref type="table" target="#tab_4">to a   #SUPPORTED #REFUTED #NEI  train  80,035  29,775  35,639  dev  3,333  3,333  3,333  test  3,333  3,333  3,333   Table 1</ref>: Statistics of claims in FEVER dataset logistic regression layer in order to infer a proba- bility distribution o over the label space Y :</p><formula xml:id="formula_12">o = softmax(W · [e, x] + b)<label>(13)</label></formula><p>where W ∈ R n×2d , b ∈ R n The loss l cv ("cv": claim verification) is imple- mented as negative log-likelihood:</p><formula xml:id="formula_13">l cv = − log(o · z T )<label>(14)</label></formula><p>where z is the ground truth one-hot label vector for the claim x on the space Y .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Joint optimization</head><p>Given the loss l ev in evidence identification and the loss l cv in claim verification, the overall train- ing loss is represented by:</p><formula xml:id="formula_14">l = l ev + l cv<label>(15)</label></formula><p>To ensure that we jointly train the two coupled subtasks with intensive knowledge communica- tion instead of simply putting two pipeline neural networks together, our TWOWINGOS has follow- ing configurations:</p><p>• Both subsystems share the same set of word embeddings as parameters; the vanilla CNNs for learning sentence and claim representations share parameters as well.</p><p>• The output binary vector p by the evidence identification module is forwarded to the module of claim verification, as shown in Equations 8-10.</p><p>• Though the representation of a claim's deci- sion y i is not put explicitly into the module of ev- idence identification, the claim's representation x will be fine-tuned by the y i , so that the evidence candidates can get adjustment from the decision y i , since the claims are shared by two modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>Dataset. In this work, we use FEVER ( <ref type="bibr" target="#b17">Thorne et al., 2018</ref>). The claims in FEVER were gen- erated from the introductory parts of about 50K Each claim is labeled as SUPPORTED, RE- FUTED or NOTENOUGHINFO (NEI). In addition, evidence sentences, from any wiki page, are re- quired to be provided for SUPPORTED and RE- FUTED. <ref type="table">Table 1</ref> lists the data statistics. <ref type="figure">Figure 4</ref> shows the distributions of sentence sizes and page sizes in FEVER's evidence set. We can see that roughly 28% of the evidence covers more than one sentence, and approximately 16.3% of the ev- idence covers more than one wiki page.</p><p>This task has three evaluations: (i) NOSCOREEV -accuracy of claim verifica- tion, neglecting the validity of evidence; (ii) SCOREEV -accuracy of claim verification with a requirement that the predicted evidence fully covers the gold evidence for SUPPORTED and RE- FUTED; (iii) F 1 -between the predicted evidence sentences and the ones chosen by annotators. We use the officially released evaluation scorer 3 .</p><p>Wiki page retrieval 4 . For each claim, we search in the given dictionary of wiki pages in the form of {title: sentence list}, and keep the top-5 ranked pages for fair comparison with <ref type="bibr" target="#b17">Thorne et al. (2018)</ref>. Algorithm 1 briefly shows the steps of wiki page retrieval. To speed up, we first build an inverted index from words to titles, then for each claim, we only search in the titles that cover at least one claim word.</p><p>Input: A claim, wiki={title: page vocab} Output: A ranked top-k wiki titles Generate entity mentions from the claim; while each title do if claim.vocab∩title.vocab is empty then discard this title else title score = the max recall value of title.vocab in claim and in entity mentions of the claim; if title score = 1.0 then title.score = title score else page score = recall of claim in page vocab; title.score = title score + page score end end end Sort titles by title.score in descending order Algorithm 1: Algorithm description of wiki page retrieval for FEVER claims.</p><p>All sentences of the top-5 retrieved wiki pages are kept as evidence candidates for claims in train, dev and test. It is worth mentioning that this page retrieval step is a reasonable preprocessing which controls the complexity of evidence searching in real-world, such as the big space -5.4 million -in this work.</p><p>Training setup. All words are initialized by 300D Word2Vec ( <ref type="bibr" target="#b11">Mikolov et al., 2013</ref>) embed- dings, and are fine-tuned during training. The whole system is trained by <ref type="bibr">AdaGrad (Duchi et al., 2011</ref>). Other hyperparameter values include: learning rate 0.02, hidden size 300, mini-batch size 50, filter width 3.</p><p>Baselines. In this work, we first consider the two systems reported by <ref type="bibr" target="#b17">Thorne et al. (2018)</ref>: (i) MLP: A multi-layer perceptron with one hidden layer, based on TF-IDF cosine similarity between the claim and the evidence (all evidence sentences are concatenated as a longer text piece) ( <ref type="bibr" target="#b14">Riedel et al., 2017)</ref>; (ii) Decomp-Att ( <ref type="bibr" target="#b12">Parikh et al., 2016)</ref>: A decomposable attention model that develops atten-k <ref type="bibr" target="#b17">(Thorne et al., 2018</ref>  <ref type="table">Table 2</ref>: Wikipage retrieval evaluation on dev. "rate": claim proportion, e.g., x%, if its gold passages are fully retrieved (for "SUPPORT" and "REFUTE" only); "acc ceiling": x%·(#S+#R)+#N</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>#S+#R+#N</head><p>, the upper bound of accuracy for three classes if the coverage x% satisfies. tion mechanisms to decompose the problem into subproblems to solve in parallel. Note that both systems first employed an IR system to keep top- 5 relevant sentences from the retrieved top-5 wiki pages as static evidence for claims.</p><p>We further consider the following variants of our own system TWOWINGOS:</p><p>• Coarse-coarse: Both evidence identification and claim verification adopt coarse-grained repre- sentations.</p><p>To further study our system, we test this "coarse-coarse" in three setups: (i) "pipeline" - train the two modules independently. Forward the predicted evidence to do entailment for claims; (ii) "diff-CNN" -joint training with separate CNN pa- rameters to learn sentence/claim representations; (iii) "share-CNN" -joint training with shared CNN parameters.</p><p>The following variants are in joint training.</p><p>• Fine&amp;sentence-wise: Given the evidence with multiple sentences, a natural baseline is to do entailment reasoning for each (sentence, claim), then compose. We do entailment reasoning be- tween each predicted evidence sentence and the claim, generating a probability distribution over the label space Y . Then we sum up all the distribu- tion vectors element-wise, as an ensemble system, to predict the label;</p><p>• Four combinations of different grained rep- resentation learning:</p><p>"coarse&amp;fine(single)", "coarse&amp;fine(two)", "fine&amp;coarse" and "fine&amp;fine(two)".</p><p>"Single" and "two" refer to the single/two-channel cases respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Performance of passage retrieval. <ref type="table">Table 2</ref> compares our wikipage retriever with the one in <ref type="bibr" target="#b17">(Thorne et al., 2018)</ref>, which used a document re- triever 5 from DrQA ( <ref type="bibr" target="#b4">Chen et al., 2017)</ref>.</p><p>Our document retrieval module surpasses the competitor by a big margin in terms of the cover- age of gold passages: 89.63% vs. 55.30% (k = 5 in all experiments). Its powerfulness should be attributed to: (i) Entity mention detection in the claims. (ii) As wiki titles are entities, we have a bi-channel way to match the claim with the wiki page: one with the title, the other with the page body, as shown in Algorithm 1.</p><p>Performance on FEVER <ref type="table" target="#tab_4">Table 3</ref> lists the performances of baselines and the TWOWIN- GOS variants on FEVER (dev&amp;test). From the dev block, we observe that:</p><p>• TWOWINGOS (from "share-CNN") sur- passes prior systems in big margins. Overall, fine-grained schemes in each subtask contribute more than the coarse-grained counterparts;</p><p>• In the three setups -"pipeline", "diff-CNN" and "share-CNN" -of coarse-coarse, "pipeline" gets better scores than ( <ref type="bibr" target="#b17">Thorne et al., 2018</ref>) in terms of evidence identification. "Share-CNN" has comparable F 1 as "diff-CNN" while gaining a lot on NOSCOREEV (72.32 vs. 39.22) and SCOREEV (50.12 vs. 21.04). This clearly shows that the claim verification gains much knowledge transferred from the evidence identification mod- ule. Both "diff-CNN" and "share-CNN" perform better than "pipeline" (except for the slight inferi- ority at SCOREEV: 21.04 vs. 22.26).</p><p>• Two-channel fine-grained representations show more effective than the single-channel counterpart in claim verification (NOSCOREEV: 78.77 vs. 75.65, SCOREEV: 53.64 vs. 52.65). As we expected, evidence sentences should collaborate in inferring the truth value of the claims. Two-channel setup enables an evidence candidate aware of other candidates as well as the claim.</p><p>• In the last three rows of dev, there is no clear difference among their evidence identifica- tion scores. Recall that "sent-wise" is essentially an ensemble system over each (sentence, claim) entailment result. "Coarse-grained", instead, first sums up all sentence representation, then performs ( (sentence), claim) reasoning. We can also treat this "sum up" as an ensemble. Their com- parison shows that these two kinds of tricks do not   Figure 5: Performance vs. #sentence in evidence. Our system has robust precisions. The overall performance NOSCOREEV is not influenced by the decreasing re- call; this verifies the fact that the truth value of most claims can be determined by a single identified evi- dence sentence.</p><p>make much difference.</p><p>If we adopt "two-channel fine-grained repre- sentation" in claim verification, big improvements are observed in both NOSCOREEV (+7.42%) and SCOREEV (+3%).</p><p>In the test block, our system (fine&amp;fine(two)) beats the prior top system across all measurements by big margins -F 1 : 47.15 vs. 17.47; SCOREEV: 54.33 vs. 31.87; NOSCOREEV: 75.99 vs. 50.91.</p><p>In both dev and test blocks, we can observe that our evidence identification module consistently obtains balanced recall and precision. In con- trast, the pipeline system by <ref type="bibr" target="#b17">Thorne et al. (2018)</ref> has much higher recall than precision <ref type="bibr">(45.89 vs. 10.79)</ref>. It is worth mentioning that the SCOREEV metric is highly influenced by the recall value, since SCOREEV is computed on the claim in- stances whose evidences are fully retrieved, re- gardless of the precision. So, ideally, a system can set all sentences as evidence, so that SCOREEV can be promoted to be equal to NOSCOREEV. Our system is more reliable in this perspective.</p><p>Performance vs. #sent. in evidence. <ref type="figure">Figure 5</ref> shows the results of the five evaluation measures against different sizes of gold evidence sentences in test set. We observe that: (i) Our system has robust precisions across #sentence; however, the recall decreases. This is not that surprising, since the more ground-truth sentences in evidence, the harder it is to retrieve all of them; (ii) Due to the decrease in recall, the SCOREEV also gets influ- enced for bigger #sentence. Interestingly, high precision and worse recall in evidence with more sentences still make consistently strong overall performance, i.e., NOSCOREEV. This should be due to the fact that the majority (83.18% ( <ref type="bibr" target="#b17">Thorne et al., 2018)</ref>) of claims can be correctly entailed by a single ground truth sentence, even if any remain- ing ground truth sentences are unavailable.</p><p>Error analysis. The case #1 in <ref type="table">Table 4</ref> shows that our system identifies two pieces of evidence # G/P claim gold evidence predicted evidence 1 0/1 Telemundo is an English-language television network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(Telemundo, 0) (Telemundo, 0) (Telemundo, 1) (Telemundo, 4) (Telemundo, 4) (Fourth television network, 0) (Telemundo, 5) (Fourth television network, 4) (Hispanic and Latino Americans, 0) 2 1/2</head><p>Home for the Holidays stars a famous American actor.  <ref type="table">Table 4</ref>: Error cases of TWOWINGOS in FEVER. "G/P": gold/predicted label ("0": refute; "1": support; "2": not enough information). To save space, we use "(title, i)" to denote the i th sentence in the corresponding wiki page.</p><p>(i.e., (Telemundo, 0) and (Telemundo, 4)) cor- rectly; however, it falsely predicts the claim la- bel. (Telemundo, 0): Telemundo is an Amer- ican Spanish-language terrestrial television · · · . We can easily find that the keyword "Spanish- language" should refute the claim. However, both "Spanish-language" in this evidence and the "English-language" in the claim are unknown to- kens with randomly initialized embeddings. This hints that a more careful data preprocessing may be helpful. In addition, to refute the claim, an- other clue comes from the combination of (Tele- mundo, 4) and (Hispanic and Latino Americans, 0). (Telemundo, 4): "The channel · · · aimed at Hispanic and Latino American audiences"; (Hispanic and Latino Americans, 0): "Hispanic Americans and Latino Americans · · · are descen- dants of people from countries of Latin America and Spain.". Our system only retrieved (Telemu- ndo, 4). And this clue is hard to grasp as it re- quires some background knowledge -people from Latin America and Spain usually are not treated as English-speaking. In the case #2, our system fails to iden- tify any evidence. This is due to the failure of our passage retrieval module: it detects entity mentions "Home", "Holidays" and "American", and the top-5 retrieved pas- sages are "Home", "Home for the Holidays", "American Home", "American" and "Home for the Holidays (song)", which un- fortunately cover none of the four ground truth passages. Interestingly, (i) given the falsely re- trieved passages, our system predicts "no sentence is valid evidence" (denoted as ∅ in <ref type="table">Table 4</ref>); (ii) given the empty evidence, our system predicts "NoEnoughInfo" for this claim. Both make sense.</p><p>In the case #3, a successful classification of the claim requires information aggregation over the three gold evidence sentences: (Weekly Idol, 0): "Weekly Idol is a South Korean variety show · · · "; (Weekly Idol, 1): "The show is hosted by come- dian Jeong Hyeong-don and rapper Defconn."; (Defconn, 0): "Defconn (born Yoo Dae-joon; Jan- uary <ref type="bibr">6 , 1977</ref> ) is a · · · ". To successfully retrieve the three sentences as a whole set of evidence is challenging in evidence identification. Addition- ally, this example relies on the recognition and matching of digital numbers <ref type="bibr">(1983 vs. 1977)</ref>, which is beyond the expressivity of word embed- dings, and is expected to be handled by rules more easily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Summary</head><p>In this work, we build TWOWINGOS, a two-wing optimization framework to address the claim veri- fication problem by presenting precise evidence. Differing from a pipeline system, TWOWIN- GOS ensures the evidence identification mod- ule and the claim verification module are trained jointly, in an end-to-end scheme. Experiments show the superiority of TWOWINGOS in the FEVER benchmark.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: TWOWINGOS, a generic two-wing optimization framework. A subset of the evidence candidates S e = {s 1 ,. .. , s m−1 , s m } is chosen via a binary vector (left), and an n-valued entailment decision y i ∈ Y is chosen (right), with respect to the claim x.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Now</head><label></label><figDesc>, word s j i has left context s j−1 i , right con- text s j+1 i in s i , and the claim-aware context c j i from x. A convolution encoder generates its claim-aware representation i j i :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Three representation learning methods in claim verification. Green arrows act as context in attentive convolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>For a single pair (s i , x), we utilize the func- tion f int () in Equation 4 to build the fine-grained representations for both s i and x, obtaining i i =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Performance on dev and test of FEVER. TWOWINGOS outperforms prior systems if vanilla CNN parameters are shared by evidence identification and claim verification subsystems. It gains more if fine-grained representations are adopted in both subtasks.</figDesc><table></table></figure>

			<note place="foot" n="2"> By &quot;two-wing optimization&quot;, we mean that the same object, i.e., the claim, is mapped into two target spaces in a joint optimization scheme.</note>

			<note place="foot" n="3"> https://github.com/sheffieldnlp/fever-scorer</note>

			<note place="foot" n="4"> Our retrieval results are released as well.</note>

			<note place="foot" n="5"> It compares passages and claims as TF-IDF weighted bag-of-bigrams.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank group colleagues (Nitish Gupta and Jen-nifer Sheffield) and Dr. Mo Yu from IBM AI Foundations Lab for providing insightful com-ments and critiques. This work was supported by Contract HR0011-15-2-0025 with the US Defense Advanced Research Projects Agency (DARPA). Approved for Public Release, Distribution Unlim-ited. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Govern-ment.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Naturalli: Natural logic inference for common sense reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="534" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A comparison of vector-based representations for semantic composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Blacoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="546" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGMOD</title>
		<meeting>SIGMOD</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Importance sampling for unbiased on-demand evaluation of knowledge base population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Arun Tejasvi Chaganty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1038" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Recognizing textual entailment: Models and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Massimo</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zanzoto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Emergent: a novel data-set for stance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1163" to="1168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning whom to trust with MACE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1120" to="1130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automated historical fact-checking by passage retrieval, word statistics, and virtual question-answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mio</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ai</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chikara</forename><surname>Hoshino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Miyashita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="967" to="975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A decomposable attention model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ankur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2249" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Latent credibility analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Pasternack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1009" to="1020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A simple but tough-to-beat baseline for the fake news challenge stance detection task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><forename type="middle">P</forename><surname>Spithourakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno>abs/1707.03264</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A framework for entailed relation recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
	<note>Vinod Vydiswaran</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Yago: a core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">FEVER: a large-scale dataset for fact extraction and verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Christos Christodoulopoulos, and Arpit Mittal</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fact checking: Task definition and dataset construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Language Technologies and Computational Social Science@ACL</title>
		<meeting>the Workshop on Language Technologies and Computational Social Science@ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="18" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Content-driven trust propagation framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Vinod Vydiswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="974" to="982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">R 3 : Reinforced ranker-reader for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerry</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Liar, Liar Pants on Fire&quot;: A new benchmark dataset for fake news detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="422" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Attention-based convolutional neural network for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Workshop on Human-Computer Question Answering</title>
		<meeting>the NAACL Workshop on Human-Computer Question Answering</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="15" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Attentive convolution. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno>abs/1710.00519</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
