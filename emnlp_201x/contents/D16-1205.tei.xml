<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Representing Verbs with Rich Contexts: an Evaluation on Verb Similarity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuele</forename><surname>Chersoni</surname></persName>
							<email>emmanuelechersoni@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Aix-Marseille University</orgName>
								<orgName type="institution" key="instit2">The Hong Kong Polytechnic University</orgName>
								<orgName type="institution" key="instit3">University of Pisa</orgName>
								<orgName type="institution" key="instit4">Marseille University</orgName>
								<orgName type="institution" key="instit5">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Santus</surname></persName>
							<email>esantus@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Aix-Marseille University</orgName>
								<orgName type="institution" key="instit2">The Hong Kong Polytechnic University</orgName>
								<orgName type="institution" key="instit3">University of Pisa</orgName>
								<orgName type="institution" key="instit4">Marseille University</orgName>
								<orgName type="institution" key="instit5">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
							<email>alessandro.lenci@unipi.it</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Aix-Marseille University</orgName>
								<orgName type="institution" key="instit2">The Hong Kong Polytechnic University</orgName>
								<orgName type="institution" key="instit3">University of Pisa</orgName>
								<orgName type="institution" key="instit4">Marseille University</orgName>
								<orgName type="institution" key="instit5">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Blache</surname></persName>
							<email>philippe.blache@univ-amu.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Aix-Marseille University</orgName>
								<orgName type="institution" key="instit2">The Hong Kong Polytechnic University</orgName>
								<orgName type="institution" key="instit3">University of Pisa</orgName>
								<orgName type="institution" key="instit4">Marseille University</orgName>
								<orgName type="institution" key="instit5">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
							<email>churen.huang@polyu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Aix-Marseille University</orgName>
								<orgName type="institution" key="instit2">The Hong Kong Polytechnic University</orgName>
								<orgName type="institution" key="instit3">University of Pisa</orgName>
								<orgName type="institution" key="instit4">Marseille University</orgName>
								<orgName type="institution" key="instit5">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Representing Verbs with Rich Contexts: an Evaluation on Verb Similarity</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1967" to="1972"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Several studies on sentence processing suggest that the mental lexicon keeps track of the mutual expectations between words. Current DSMs, however, represent context words as separate features, thereby loosing important information for word expectations, such as word interrelations. In this paper, we present a DSM that addresses this issue by defining verb contexts as joint syntactic dependencies. We test our representation in a verb similarity task on two datasets, showing that joint contexts achieve performances comparable to single dependencies or even better. Moreover, they are able to overcome the data sparsity problem of joint feature spaces, in spite of the limited size of our training corpus.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Distributional Semantic Models (DSMs) rely on the Distributional Hypothesis <ref type="bibr" target="#b11">(Harris, 1954;</ref><ref type="bibr" target="#b22">Sahlgren, 2008)</ref>, stating that words occurring in similar con- texts have similar meanings. On such theoretical grounds, word co-occurrences extracted from cor- pora are used to build semantic representations in the form of vectors, which have become very popular in the NLP community. Proximity between word vec- tors is taken as an index of meaning similarity, and vector cosine is generally adopted to measure such proximity, even though other measures have been proposed ( <ref type="bibr" target="#b26">Weeds et al., 2004;</ref><ref type="bibr" target="#b23">Santus et al., 2016</ref>).</p><p>Most of DSMs adopt a bag-of-words approach, that is they turn a text span (i.e., a word window or a parsed sentence) into a set of words and they regis- ter separately the co-occurrence of each word with a given target. The problem with this approach is that valuable information concerning word interrelations in a context gets lost, because words co-occurring with a target are treated as independent features. This is why works like Ruiz- <ref type="bibr" target="#b21">Casado et al. (2005)</ref>, <ref type="bibr" target="#b0">Agirre et al. (2009)</ref> and <ref type="bibr" target="#b19">Melamud et al. (2014)</ref> pro- posed to introduce richer contexts in distributional spaces, by using entire word windows as features. These richer contexts proved to be helpful to seman- tically represent verbs, which are characterized by highly context-sensitive meanings, and complex ar- gument structures. In fact, two verbs may share in- dependent words as features despite being very dis- similar from the semantic point of view. For instance kill and heal share the same object nouns in The doc- tor healed the patient and the The poison killed the patient, but are highly different if we consider their joint dependencies as a single context. Nonetheless, richer contexts like these suffer from data sparsity, therefore requiring either larger corpora or complex smoothing processes.</p><p>In this paper, we propose a syntactically savvy no- tion of joint contexts. To test our representation, we implement several DSMs and we evaluate them in a verb similarity task on two datasets. The re- sults show that, even using a relatively small corpus, our syntactic joint contexts are robust with respect to data sparseness and perform similarly or better than single dependencies in a wider range of parameter settings.</p><p>The paper is organized as follows. In Section 2, we provide psycholinguistic and computational background for this research, describing recent mod- els based on word windows. In Section 3, we de- scribe our reinterpretation of joint contexts with syn- tactic dependencies. Evaluation settings and results are presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A number of studies in sentence processing sug- gests that verbs activate expectations on their typ- ical argument nouns and vice versa <ref type="bibr" target="#b17">(McRae et al., 1998;</ref><ref type="bibr" target="#b18">McRae et al., 2005</ref>) and nouns do the same with other nouns occurring as co-arguments in the same events <ref type="bibr" target="#b10">(Hare et al., 2009;</ref><ref type="bibr" target="#b3">Bicknell et al., 2010)</ref>. Experimental subjects seem to exploit a rich event knowledge to activate or inhibit dynamically the representations of the potential arguments. This phenomenon, generally referred to as thematic fit <ref type="bibr" target="#b17">(McRae et al., 1998</ref>), supports the idea of a mental lexicon arranged as a web of mutual expectations.</p><p>Some past works in computational linguistics ( <ref type="bibr" target="#b2">Baroni and Lenci, 2010;</ref><ref type="bibr" target="#b15">Lenci, 2011;</ref><ref type="bibr" target="#b24">Sayeed and Demberg, 2014;</ref><ref type="bibr" target="#b9">Greenberg et al., 2015</ref>) modeled thematic fit estimations by means of dependency- based or of thematic roles-based DSMs. However, these semantic spaces are built similarly to tradi- tional DSMs as they split verb arguments into sepa- rate vector dimensions. By using syntactic-semantic links, they encode the relation between an event and each of its participants, but they do not encode di- rectly the relation between participants co-occurring in the same event.</p><p>Another trend of studies in the NLP community aimed at the introduction of richer contextual fea- tures in DSMs, mostly based on word windows. The first example was the composite-feature model by <ref type="bibr" target="#b21">Ruiz-Casado et al. (2005)</ref>, who extracted word win- dows through a Web Search engine. A composite feature for the target word watches is Alicia always ____ romantic movies, extracted from the sentence I heard that Alicia always watches romantic movies with Antony (the placeholder represents the target position). Thanks to this approach, Ruiz-Casado and colleagues achieved 82.50 in the TOEFL synonym detection test, outperforming Latent Semantic Anal- ysis (LSA; see <ref type="bibr" target="#b14">Landauer et al. (1998)</ref>) and several other methods. <ref type="bibr" target="#b0">Agirre et al. (2009)</ref> adopted an analogous ap- proach, relying on a huge learning corpus (1.6 Ter- aword) to build composite-feature vectors. Their model outperformed a traditional DSM on the sim- ilarity subset of the WordSim-353 test set ( <ref type="bibr" target="#b8">Finkelstein et al., 2001</ref>).</p><p>Melamud et al. <ref type="formula">(2014)</ref> introduced a probabilistic similarity scheme for modeling the so-called joint context. By making use of the Kneser-Ney language model ( <ref type="bibr" target="#b13">Kneser and Ney, 1995)</ref> and of a probabilis- tic distributional measure, they were able to over- come data sparsity, outperforming a wide variety of DSMs on two similarity tasks, evaluated on Verb- Sim ( <ref type="bibr" target="#b27">Yang and Powers, 2006</ref>) and on a set of 1,000 verbs extracted from WordNet <ref type="bibr" target="#b7">(Fellbaum, 1998)</ref>.</p><p>On the basis of their results, the authors claimed that composite-feature models are particularly advanta- geous for measuring verb similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Syntactic joint contexts</head><p>A joint context, as defined in <ref type="bibr" target="#b19">Melamud et al. (2014)</ref>, is a word window of order n around a target word. The target is replaced by a placeholder, and the value of the feature for a word w is the probability of w to fill the placeholder position. Assuming n=3, a word like love would be represented by a collection of contexts such as the new students ____ the school campus. Such representation introduces data sparse- ness, which has been addressed by previous studies either by adopting huge corpora or by relying on n- gram language models to approximate the probabil- ities of long sequences of words.</p><p>However, features based on word windows do not guarantee to include all the most salient event par- ticipants. Moreover, they could include unrelated words, also differentiating contexts describing the same event (e.g. consider Luis ____ the red ball and Luis ____ the blue ball).</p><p>For these reasons, we introduce the notion of syn- tactic joint contexts, further abstracting from linear word windows by using dependencies. Each feature of the word vector, in our view, should correspond to a typical verb-argument combination, as an approx-imation to our knowledge about typical event par- ticipants. In the present study, we are focusing on verbs because verb meaning is highly context sen- sitive and include information about complex argu- ment configurations. Therefore, verb representation should benefit more from the introduction of joint features <ref type="bibr" target="#b19">(Melamud et al., 2014</ref>).</p><p>The procedure for defining of our representations is the following:</p><p>• we extract a list of verb-argument dependencies from a parsed corpus, and for each target verb we extract all the direct dependencies from the sentence of occurrence. For instance, in Fi- nally, the dictator acknowledged his failure, we will have: target = 'acknowledge-v'; subject = 'dictator-n'; and object = 'failure-n'.</p><p>• for each sentence, we generate a joint context feature by joining all the dependencies for the grammatical relations of interest. From the ex- ample above, we would generate the feature dictator-n.subj+____+failure-n.obj.</p><p>For our experiments, the grammatical relations that we used are subject, object and complement, where complement is a generic relation grouping to- gether all dependencies introduced by a preposition. Our distributional representation for a target word is a vector of syntatic joint contexts. For instance, the word vector for the verb to begin would include features like {jury-n.subj+____+deliberation-n.obj, operation-n.subj+____+on-i_thursday-n.comp, recruit-n.subj+____+training-n.obj+on-i_street- n.comp ...}. The value of each joint feature will be the frequency of occurrence of the target verb with the corresponding argument combination, possibly weighted by some statistical association measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Corpus and DSMs</head><p>We trained our DSMs on the RCV1 corpus, which contains approximately 150 million words ( <ref type="bibr" target="#b16">Lewis et al., 2004</ref>). The corpus was tagged with the tagger described in Dell'Orletta (2009) and dependency- parsed with DeSR ( <ref type="bibr" target="#b1">Attardi et al., 2009</ref>). RCV1 was chosen for two reasons: i) to show that our joint context-based representation can deal with data sparseness even with a training corpus of limited size; ii) to allow a comparison with the results re- ported by <ref type="bibr" target="#b19">Melamud et al. (2014)</ref>.</p><p>All DSMs adopt Positive Pointwise Mutual Infor- mation (PPMI; <ref type="bibr" target="#b5">Church and Hanks (1990)</ref>) as a con- text weighting scheme and vary according to three main parameters: i) type of contexts; ii) number of dimensions; iii) application of Singular Value De- composition (SVD; see <ref type="bibr" target="#b14">Landauer et al. (1998)</ref>).</p><p>For what concerns the first parameter, we devel- oped three types of DSMs: a) traditional bag-of- words DSMs, where the features are content words co-occurring with the target in a window of width 2; b) dependency-based DSMs, where the features are words in a direct dependency relation with the target; c) joint context-based DSMs, using the joint features described in the previous section. The sec- ond parameter refers instead to the number of con- texts that have been used as vector dimensions. Sev- eral values were explored (i.e. 10K, 50K and 100K), selecting the contexts according to their frequency. Finally, the third parameter concerns the application of SVD to reduce the matrix. We report only the results for a number k of latent dimensions ranging from 200 to 400, since the performance drops sig- nificantly out of this interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Similarity Measures</head><p>As a similarity measure, we used vector cosine, which is by far the most popular in the existing lit- erature ( <ref type="bibr" target="#b25">Turney et al., 2010)</ref>. <ref type="bibr" target="#b19">Melamud et al. (2014)</ref> have proposed the Probabilistic Distributional Simi- larity (PDS), based on the intuition that two words, w 1 and w 2 , are similar if they are likely to occur in each other's contexts. PDS assigns a high similarity score when both p(w 1 | contexts of w 2 ) and p(w 2 | contexts of w 1 ) are high. We tried to test variations of this measure with our representation, but we were not able to achieve satisfying results. Therefore, we report here only the scores with the cosine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Datasets</head><p>The DSMs are evaluated on two test sets: Verb- Sim ( <ref type="bibr" target="#b27">Yang and Powers, 2006</ref>) and the verb subset of SimLex-999 ( <ref type="bibr" target="#b12">Hill et al., 2015</ref>). The former in- cludes 130 verb pairs, while the latter includes 222 verb pairs. Both datasets are annotated with similarity judge- ments, so we measured the Spearman correlation be- tween them and the scores assigned by the model. The VerbSim dataset allows for comparison with <ref type="bibr" target="#b19">Melamud et al. (2014)</ref>, since they also evaluated their model on this test set, achieving a Spearman correlation score of 0.616 and outperforming all the baseline methods.</p><p>The verb subset of SimLex-999, at the best of our knowledge, has never been used as a benchmark dataset for verb similarity. The SimLex dataset is known for being quite challenging: as reported by <ref type="bibr" target="#b12">Hill et al. (2015)</ref>, the average performances of simi- larity models on this dataset are much lower than on alternative benchmarks like WordSim ( <ref type="bibr" target="#b8">Finkelstein et al., 2001</ref>) and MEN ( <ref type="bibr" target="#b4">Bruni et al., 2014</ref>).</p><p>We exclude from the evaluation datasets all the target words occurring less than 100 times in our corpus. Consequently, we cover 107 pairs in the VerbSim dataset (82.3, the same of <ref type="bibr" target="#b19">Melamud et al. (2014)</ref>) and 214 pairs in the SimLex verbs dataset (96.3). <ref type="table" target="#tab_0">Table 1</ref> reports the Spearman correlation scores for the vector cosine on our DSMs. At a glance, we can notice the discrepancy between the results ob- tained in the two datasets, as SimLex verbs confirms to be very difficult to model. We can also recog- nize a trend related to the number of contexts, as the performance tends to improve when more con- texts are taken into account (with some exceptions). Single dependencies and joint contexts perform very similarly, and no one has a clear edge on the other. Both of them outperform the bag-of-words model on the VerbSim dataset by a nice margin, whereas the scores of all the model types are pretty much the same on SimLex verbs. Finally, it is noteworthy that the score obtained on VerbSim by the joint context model with 100K dimensions goes very close to the result reported by <ref type="bibr">Melamud et al. (2014) (0.616)</ref>. <ref type="table" target="#tab_1">Table 2</ref> and <ref type="table" target="#tab_2">Table 3</ref> report the results of the mod- els with SVD reduction. Independently of the num- ber of dimensions k, the joint contexts almost always outperform the other model types. Overall, the per- formance of the joint contexts seems to be more sta- ble across several parameter configurations, whereas bag-of-words and single dependencies are subject to bigger drops. Exceptions can be noticed only for the VerbSim dataset, and only with a low number of dimensions. Finally, the correlation coefficients for the two datasets seem to follow different trends, as the models with a higher number of contexts per- form better on SimLex verbs, while the opposite is true for the VerbSim dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>On the VerbSim dataset, both single dependencies and joint contexts have again a clear advantage over bag-of-words representations Although they achieve a similar performance with 10K contexts, the corre- lation scores of the former decrease more quickly as the number of contexts increases, while the latter are more stable. Moreover, joint contexts are able to outperform single dependencies. On SimLex verbs, all the models are very close and -differently from the previous dataset -the higher- dimensional DSMs are the better performing ones. Though differences are not statistically significant, joint context are able to achieve top scores over the other models.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Conclusions</head><p>In this paper, we have presented our proposal for a new type of vector representation based on joint fea- tures, which should emulate more closely the gen- eral knowledge about event participants that seems to be the organizing principle of our mental lexicon. A core issue of previous studies was the data sparse- ness challenge, and we coped with it by means of a more abstract, syntactic notion of joint context. The models using joint dependencies were able at least to perform comparably to traditional, dependency-based DSMs. In our experiments, they even achieved the best correlation scores across sev- eral parameter settings, especially after the applica- tion of SVD. We want to emphasize that previous works such as <ref type="bibr" target="#b0">Agirre et al. (2009)</ref> already showed that large word windows can have a higher discrimi- native power than indipendent features, but they did it by using a huge training corpus. In our study, joint context-based representations derived from a small corpus such as RCV1 are already showing competi- tive performances. This result strengthens our belief that dependencies are a possible solution for the data sparsity problem of joint feature spaces.</p><p>We also believe that verb similarity might not be the best task to show the usefulness of joint con- texts for semantic representation. The main goal of the present paper was to show that joint contexts are a viable option to exploit the full potential of distributional information. Our successful tests on verb similarity prove that syntactic joint contexts do not suffer of data sparsity and are also able to beat other types of representations based on independent word features. Moreover, syntactic joint contexts are much simpler and more competitive with respect to window-based ones. The good performance in the verb similarity task motivates us to further test syntactic joint contexts on a larger range of tasks, such as word sense dis- ambiguation, textual entailment and classification of semantic relations, so that they can unleash their full potential. Moreover, our proposal opens interest- ing perspectives for computational psycholinguis- tics, especially for modeling those semantic phe- nomena that are inherently related to the activation of event knowledge (e.g. thematic fit).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>1 More in general, the best results are obtained with SVD reduction and k=200. The joint context-based DSM with 10K dimensions and k = 200 achieves 0.65, which is above the result of Melamud et al. (2014), although the difference between the two cor- relation scores is not significant. As for SimLex verbs, the best result (0.283) is obtained by the joint context DSM with 100K dimensions and k = 200.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Spearman correlation scores for VerbSim and for the 

verb subset of SimLex-999. Each model is identified by the type 

and by the number of features of the semantic space. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Spearman correlation scores for VerbSim, after the 

application of SVD with different values of k. 

Model 
k = 200 k = 300 k = 400 
Bag-of-Words-10K 
0.127 
0.113 
0.111 
Single -10k 
0.168 
0.172 
0.165 
Joint -10k 
0.190 
0.177 
0.181 
Bag-of-Words-50K 
0.196 
0.191 
0.21 
Single -50k 
0.218 
0.228 
0.222 
Joint -50k 
0.256 
0.250 
0.227 
Bag-of-Words-100K 
0.222 
0.18 
0.16 
Single -100k 
0.225 
0.218 
0.199 
Joint -100k 
0.283 
0.256 
0.222 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Spearman correlation scores for the verb subset of 

SimLex-999, after the application of SVD with different values 

of k. 

</table></figure>

			<note place="foot" n="1"> p-values computed with Fisher&apos;s r-to-z transformation comparing correlation coefficients between the joint contextDSMs and the other models on the same parameter settings.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This paper is partially supported by HK PhD Fellow-ship Scheme, under PF12-13656. Emmanuele Cher-soni's research is funded by a grant of the University Foundation A*MIDEX.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A study on similarity and relatedness using distributional and wordnet-based approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Kravalova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 conference of the NAACL-HLT</title>
		<meeting>the 2009 conference of the NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Accurate dependency parsing with a stacked multilayer perceptron</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Attardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felice</forename><surname>Dell&amp;apos;orletta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Simi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EVALITA, 9</title>
		<meeting>EVALITA, 9</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distributional memory: A general framework for corpus-based semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="673" to="721" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Effects of event 1971 knowledge in processing verbal arguments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klinton</forename><surname>Bicknell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Jeffrey L Elman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Mcrae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kutas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="489" to="505" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multimodal distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam-Khanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res.(JAIR)</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Word association norms, mutual information, and lexicography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">Ward</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Hanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ensemble system for part-ofspeech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felice</forename><surname>Dell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;apos;</forename><surname>Orletta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EVALITA, 9</title>
		<meeting>EVALITA, 9</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<editor>WordNet. Wiley Online Library</editor>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Placing search in context: The concept revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zach</forename><surname>Solan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gadi</forename><surname>Wolfman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th international conference on World Wide Web</title>
		<meeting>the 10th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="406" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improving unsupervised vector-space thematic fit evaluation via role-filler prototype clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asad</forename><surname>Sayeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vera</forename><surname>Demberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 conference of the NAACLHLT</title>
		<meeting>the 2015 conference of the NAACLHLT<address><addrLine>Denver, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Activating event knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Mcrae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="167" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
		<title level="m">Distributional structure. Word</title>
		<imprint>
			<date type="published" when="1954" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="146" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Simlex-999: Evaluating semantic models with (genuine) similarity estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improved backing-off for m-gram language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Kneser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="181" to="184" />
		</imprint>
	</monogr>
	<note>ICASSP95</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An introduction to latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thomas K Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename><surname>Foltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Discourse processes</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="259" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Composing and updating verb argument expectations: A distributional semantic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Cognitive Modeling and Computational Linguistics</title>
		<meeting>the 2nd Workshop on Cognitive Modeling and Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="58" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rcv1: A new benchmark collection for text categorization research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>David D Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><forename type="middle">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="361" to="397" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modeling the influence of thematic fit (and other constraints) in on-line sentence comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Mcrae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spivey-Knowlton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tanenhaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="283" to="312" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A basis for generating expectancies for verbs from nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Mcrae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Jeffrey L Elman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ferretti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1174" to="1184" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Probabilistic modeling of joint-context in distributional similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Melamud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="181" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using context-window overlapping in synonym discovery and ontology extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Ruiz-Casado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Castells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RANLP</title>
		<meeting>RANLP</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The distributional hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magnus</forename><surname>Sahlgren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Italian Journal of Linguistics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="54" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Testing APSyn against Vector Cosine on Similarity Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Santus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuele</forename><surname>Chersoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Blache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Pacific Asia Conference on Language, Information and Computing</title>
		<meeting>the Pacific Asia Conference on Language, Information and Computing</meeting>
		<imprint>
			<publisher>PACLIC</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Combining unsupervised syntactic and semantic models of thematic fit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asad</forename><surname>Sayeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vera</forename><surname>Demberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first Italian Conference on Computational Linguistics</title>
		<meeting>the first Italian Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>CLiC-it</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">From frequency to meaning: Vector space models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Peter D Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Characterising measures of lexical distributional similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Weeds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Weir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics, page 1015. Association for Computational Linguistics</title>
		<meeting>the 20th international conference on Computational Linguistics, page 1015. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Verb similarity on the taxonomy of WordNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongqiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Powers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Masaryk University</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
