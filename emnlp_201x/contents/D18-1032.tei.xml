<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichun</forename><surname>Wang</surname></persName>
							<email>zcwang@bnu.edu.cn {lqs,lanxh,zybnu}@mail.bnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information Science and Technique</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<postCode>100875</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingsong</forename><surname>Lv</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information Science and Technique</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<postCode>100875</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohan</forename><surname>Lan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information Science and Technique</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<postCode>100875</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information Science and Technique</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<postCode>100875</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="349" to="357"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>349</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Multilingual knowledge graphs (KGs) such as DBpedia and YAGO contain structured knowledge of entities in several distinct languages, and they are useful resources for cross-lingual AI and NLP applications. Cross-lingual KG alignment is the task of matching entities with their counterparts in different languages, which is an important way to enrich the cross-lingual links in multilingual KGs. In this paper , we propose a novel approach for cross-lingual KG alignment via graph convolutional networks (GCNs). Given a set of pre-aligned entities, our approach trains GCNs to embed entities of each language into a unified vector space. Entity alignments are discovered based on the distances between entities in the embedding space. Embeddings can be learned from both the structural and attribute information of entities, and the results of structure embedding and attribute embedding are combined to get accurate alignments. In the experiments on aligning real multilingual KGs, our approach gets the best performance compared with other embedding-based KG alignment approaches.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graphs (KGs) represent human knowl- edge in the machine-readable format, are becom- ing the important basis of many applications in the areas of artificial intelligence and natural lan- guage processing. Multilingual KGs such as DB- pedia ( <ref type="bibr" target="#b0">Bizer et al., 2009</ref>), <ref type="bibr">YAGO (Suchanek et al., 2008;</ref><ref type="bibr" target="#b12">Rebele et al., 2016)</ref>, and BabelNet (Nav- igli and Ponzetto, 2012) are especially valuable if cross-lingual applications are to be built. Besides the knowledge encoded in each distinct language, multilingual KGs also contain rich cross-lingual links that match the equivalent entities in different languages. The cross-lingual links play an impor- tant role to bridge the language gap in a multilin- gual KG; however, not all the equivalent entities are connected by cross-lingual links in most mul- tilingual KGs. Therefore, increasingly more re- search work studies the problem of cross-lingual KG alignment, aiming to match entities in differ- ent languages in a multilingual KG automatically.</p><p>Traditional cross-lingual KG alignment ap- proaches either rely on machine translation tech- nique or defining various language-independent features to discover cross-lingual links. Most recently, several embedding-based approaches have been proposed for cross-lingual KG align- ment, including <ref type="bibr">MTransE (Chen et al., 2017</ref>) and JAPE ( . Given two KGs and a set of pre-aligned entities of them, embedding-based approaches project entities into low-dimensional vector spaces; entities are matched based on the computations on their vector representations. Fol- lowing very similar ideas as above, JE <ref type="bibr" target="#b5">(Hao et al., 2016</ref>) and ITransE ( <ref type="bibr" target="#b19">Zhu et al., 2017)</ref> are embedding-based approaches for matching entities between heterogeneous KGs, and they can also work for the problem of cross-lingual KG alignment. The above embedding-based approaches can achieve promising performance without machine translation or feature engineer- ing.</p><p>However, we find that the above approaches all try to jointly model the cross-lingual knowl- edge and the monolingual knowledge in one uni- fied optimization problem. The loss of two kinds of knowledge has to be carefully balanced dur- ing the optimization. For example, JE, MTransE, and ITransE all use hyper-parameters to weight the loss of entity alignments in the loss functions of their models; JAPE uses the pre-aligned entities to combine two KGs as one, and adds weight to the scores of negative samples in its loss function. In the above approaches, entities' embeddings have to encode both the structural information in KGs and the equivalent relations of entities. Further-more, the attributes of entities (e.g., the age of a people, the population of a country) have not been fully utilized in the existing models. MTransE and ITransE cannot use attributional information in KGs; although JAPE includes the attribute types in the model, the attribute values of entities are ig- nored. We believe that considering the attribute values can further improve the results of KG align- ment.</p><p>Having the above observations, we propose a new embedding-based KG alignment approach which directly models the equivalent relations be- tween entities by using graph convolutional net- works (GCNs). GCN is a kind of convolu- tional network which directly operates on graph- structured data; it generates node-level embed- dings by encoding information about the nodes' neighborhoods. The adjacencies of two equiva- lent entities in KGs usually contain other equiv- alent entities, so we choose GCNs to gener- ate neighborhood-aware embeddings of entities, which are used to discover entity alignments. Our approach can also provide a simple and effec- tive way to include entities' attribute values in the alignment model. More specifically, our approach has the following advantages:</p><p>• Our approach uses the entity relations in each KG to build the network structure of GCNs, and it only considers the equivalent relations between entities in model training. Our ap- proach has small model complexity and can achieve encouraging alignment results.</p><p>• Our approach only needs pre-aligned entities as training data, and it does not require any pre-aligned relations or attributes between KGs.</p><p>• Entity relations and entity attributes are effec- tively combined in our approach to improve the alignment results.</p><p>In the experiments on aligning real multilingual KGs, our approach gets the best performance com- pared with the baseline methods. The rest of this paper is organized as fol- lows, Section 2 reviews some related work, Sec- tion 3 introduces some background knowledge, Section 4 describes our proposed approach, Sec- tion 5 presents the evaluation results, Section 6 is the conclusion and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">KG Embedding</head><p>In the past few years, much work has been done on the problem of KG embedding. KG embedding models embed entities and relations in a KG into a low-dimensional vector space while preserving the original knowledge. The embeddings are usu- ally learned by minimizing a global loss function of all the entities and relations in a KG, which can be further used for relation prediction, informa- tion extraction, and some other tasks. TransE is a representative KG embedding approach ( <ref type="bibr" target="#b1">Bordes et al., 2013)</ref>, which projects both entities and rela- tions into the same vector space; if a triple (h, r, t) holds, TransE wants that h + r ≈ t. The embed- dings are learned by minimizing a margin-based ranking criterion over the training set. TransE model is simple but powerful, and it gets promis- ing results on link prediction and triple classifica- tion problems. To further improve TransE, several enhanced models based on it have been proposed, including TransR ( <ref type="bibr" target="#b9">Lin et al., 2015</ref>), TransH ( <ref type="bibr" target="#b18">Wang et al., 2014</ref>) and TransD ( <ref type="bibr" target="#b7">Ji et al., 2015)</ref> etc. By introducing new representations of relational translation, later approaches achieve better perfor- mance at the cost of increasing model complexity. There are many other KG embedding approaches, recent surveys ( <ref type="bibr" target="#b17">Wang et al., 2017;</ref><ref type="bibr" target="#b11">Nickel et al., 2016)</ref> give detailed introduction and comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Embedding-based KG Alignment</head><p>Here we introduce the KG Alignment approaches most related to ours, and discuss the main differ- ences between our approach and them. JE ( <ref type="bibr" target="#b5">Hao et al., 2016</ref>) jointly learns the embed- dings of multiple KGs in a uniform vector space to align entities in KGs. JE uses a set of seed entity alignments to connect two KGs, and then learns the embeddings by using a modified TransE model, which adds a loss of entity alignments in its global loss function.</p><p>MTransE <ref type="bibr" target="#b3">(Chen et al., 2017</ref>) encodes entities and relations of each KG in a separated embed- ding space by using TransE; it also provides tran- sitions for each embedding vector to its cross- lingual counterparts in other spaces. The loss function of MTransE is the weighted sum of two component models' loss (i.e., knowledge model and alignment model). To train the alignment model, MTransE needs a set of aligned triples of two KGs. JAPE ( ) combines structure em- bedding and attribute embedding to match enti- ties in different KGs. Structure embedding fol- lows the TransE model, which learns vector rep- resentations of entities in the overlay graph of two KGs. Attribute embedding follows the Skip-gram model, which aims to capture the correlations of attributes. To get desirable results, JAPE needs the relations and attributes of two KGs to be aligned in advance.</p><p>ITransE ( <ref type="bibr" target="#b19">Zhu et al., 2017</ref>) is a joint knowledge embedding approach for multiple KGs, which is also suitable for the cross-lingual KG alignment problem. ITransE first learns both entity and rela- tion embeddings following TransE; then it learns to map knowledge embeddings of different KGs into a joint space according to a set of seed en- tity alignments. ITransE performs iterative entity alignment by using the newly discovered entity alignments to update joint embeddings of entities. ITransE requires all relations being shared among KGs.</p><p>The above approaches follow the similar frame- work to match entities in different KGs. They all rely on TransE model to learn entity embeddings, and then define some kinds of transformation be- tween embeddings of aligned entities. Compared with these approaches, our approach uses an en- tirely different framework; it uses GCNs to embed entities in a unified vector space, where aligned entities are expected to be as close as possible. Our approach only focuses on matching entities in two KGs, and it does not learn embeddings of re- lations. MTransE, JAPE, and ITransE all require relations being aligned or shared in KGs; our ap- proach does not need this kind of prior knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>KGs represent knowledge about real-world en- tities as triples. Here we consider two kinds of triples in KGs: relational triples, and attri- butional triples. Relational triples represents re- lations between entities, and it has the form entity 1 , relation, entity 2 . Attributional triples describe attributes of entities, and it has the form entity, attribute, value. For example in the data of YAGO, graduatedFrom is a relation, and (Albert Einstein, graduatedFrom, ETH Zurich) is a relational triple; diedOnDate is an attribute, and <ref type="bibr">(Albert Einstein, diedOnDate, 1955</ref>) is an attri- butional triple. Both relational and attributional triples describe important information about enti- ties, we will take both of them into account in the task of cross-lingual KG alignment.</p><p>Formally, we represent a KG as G = (E, R, A, T R , T A ), where E, R, A are sets of en- tities, relations and attributes, respectively; T R ⊂ E × R × E is the set of relational triples, T A ⊂ E × A × V is the set of attributional triples, where V is the set of attribute values.</p><p>Let</p><formula xml:id="formula_0">G 1 = (E 1 , R 1 , A 1 , T R 1 , T A 1 ) and G 2 = (E 2 , R 2 , A 2 , T R 2 , T A 2 ) be two KGs in different lan- guages, and S = {(e i 1 , e i 2 )|e i 1 ∈ E 1 , e i 2 ∈ E 2 } m i=1</formula><p>be a set of pre-aligned entity pairs between G 1 and G 2 . We define the task of cross-lingual KG alignment as finding new entity alignments based on the existing ones. In multilingual KGs such as DBpedia and YAGO, the cross-lingual links in them can be used to build the sets of pre-aligned entity pairs. The already known entity alignments are used as seeds or training data in the process of KG alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Proposed Approach</head><p>The framework of our proposed approach is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Given two KGs G 1 and G 2 in different languages, and a set of known aligned entity pairs S = {(e i 1 , e i 2 )} m i=1 between them, our approach automatically find new entity alignments based on GCN-based entity embeddings. The basic idea of our approach is to use GCNs to embed enti- ties from different languages into a unified vector space, where equivalent entities are expected to be as close as possible. Entity alignments are pre- dicted by applying a pre-defined distance function to entities' GCN-representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">GCN-based Entity Embedding</head><p>GCNs ( <ref type="bibr" target="#b2">Bruna et al., 2014;</ref><ref type="bibr" target="#b6">Henaff et al., 2015;</ref><ref type="bibr" target="#b4">Defferrard et al., 2016;</ref> are a type of neural network that directly operates on graph data. GCNs allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. The inputs of a GCN are feature vectors of nodes and the structure of the graph; the goal of a GCN is to learn a function of features on the input graph and produces a node- level output. GCNs can encode information about the neighborhood of a node as a real-valued vec- tor, which was usually used for classification or re- gression. When solving the problem of KG align- ment, we assume that (1) equivalent entities tend</p><formula xml:id="formula_1">G C N G C N KG1 KG2 f (e i , e j ) = e i − e j 1</formula><p>Knowledge graphs (KGs) represent human </p><formula xml:id="formula_2">H (l+1) = σ ˆ D − 1 2 ˆ A ˆ D − 1 2 H (l) W (l)<label>(1)</label></formula><p>where σ is an activation function; A is a n×n con- nectivity matrix that represents the structure infor- mation of the graph; ˆ A = A + I, and I is the iden- tity matrix; ˆ D is the diagonal node degree matrix ofˆAofˆ ofˆA; W (l) ∈ R d (l) ×d (l+1) is the weight matrix of the l-th layer in the <ref type="bibr">GCN, d (l+1)</ref> is the dimension- ality of new vertex features.</p><p>Structure and Attribute Embedding. In our ap- proach, GCNs are used to embed entities of two KGs in a unified vector space. To utilize both structure and attribute information of entities, our approach assigns two feature vectors to each entity in GCN layers, structure feature vector h s and at- tribute feature vector h a . In the input layer, h</p><p>s is randomly initialized and updated during the train- ing process; h (0) a is the attribute vectors of entities and it is fixed during the model training. Let H s and H a be the structure and attribute feature ma- trices of all the entities, we redefine the convolu- tional computation as:</p><formula xml:id="formula_4">[H (l+1) s ; H (l+1) a ] = σ ˆ D − 1 2 ˆ A ˆ D − 1 2 [H (l) s W (l) s ; H (l) a W (l) a ]<label>(2)</label></formula><p>where W Model Configuration. More specifically, our ap- proach uses two 2-layer GCNs, and each GCN processes one KG to generate embeddings of its entities. As defined in Section 3, we denote two KGs as to what extent the information of alignments propagates from the i-th entity to the j-th entity. The probability of two entities being equivalent differs greatly considering they connect to aligned entities by different relations (e.g., has- Parent vs. hasFriend). Therefore, we compute two measures, which are called functionality and inverse functionality, for each relation:</p><formula xml:id="formula_5">G 1 = (E 1 , R 1 , A 1 , T R 1 , T A 1 ) and G 2 = (E 2 , R 2 , A 2 , T R 2 , T A</formula><p>f un(r) = #Head Entities of r #T riples of r</p><p>if un(r) = #T ail Entities of r #T riples of r</p><p>where #T riples of r is the number of triples of relation r; #Head Entities of r and #T ail Entities of r are the numbers of head entities and tail entities of r, respectively. To measure the influence of the i-th entity over the j-the entity, we set a ij ∈ A as: </p><formula xml:id="formula_8">a ij = e i ,r</formula><formula xml:id="formula_9">D(e i , v j ) =β f (h s (e i ), h s (v j ) d s + (1 − β) f (h a (e i ), h a (v j )) d a<label>(6)</label></formula><p>where f (x, y) = x − y 1 , h s (·) and h a (·) denote the structure embedding and attribute em- bedding of an entity, respectively; d s and d a are dimensionalities of structure embeddings and at- tribute embeddings; β is a hyper-parameter that balances the importance of two kinds of embed- dings.</p><p>The distance is expected to be small for equiva- lent entities and large for non-equivalent ones. For a specific entity e i in G 1 , our approach computes the distances between e i and all the entities in G 2 , and returns a list of ranked entities as candidate alignments. The alignment can be also performed from G 2 to G 1 . In the experiments, we report the results of both directions of KG alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Training</head><p>To enable GCNs to embed equivalent entities as close as possible in the vector space, we use a set of known entity alignments S as training data to train GCN models. The model training is per- formed by minimizing the following margin-based ranking loss functions:</p><formula xml:id="formula_10">L s = (e,v)∈S (e ,v )∈S (e,v) [f (h s (e), h s (v)) + γ s − f (h s (e ), h s (v )] + (7) L a = (e,v)∈S (e ,v )∈S (e,v) [f (h a (e), h a (v)) + γ a − f (h a (e ), h a (v )] +<label>(8)</label></formula><p>where [x] + = max{0, x}, S (e,v) denotes the set of negative entity alignments constructed by corrupt- ing (e, v), i.e. replacing e or v with a randomly chosen entity in G 1 or G 2 ; γ s , γ a &gt; 0 are margin hyper-parameters separating positive and negative entity alignments. L s and L a are loss functions for structure embedding and attribute embedding, re- spectively; they are independent of each other and hence are optimized separately. We adopt stochas- tic gradient descent (SGD) to minimize the above loss functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We use the DBP15K datasets in the experiments, which were built by . The datasets were generated from DBpedia, a large-scale multi- lingual KG containing rich inter-language links between different language versions. Subsets of Chinese, English, Japanese and French ver- sions of DBpedia are selected following certain rules. <ref type="table" target="#tab_3">Table 2</ref> outlines the detail information of the datasets. Each dataset contains data two KGs in different languages and 15 thousand inter- language links connecting equivalent entities in two KGs. In the experiments, the known equiv- alent entity pairs are used for model training and testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment Settings</head><p>In the experiments, we compared our approach with JE, MTransE and JAPE. We also build JAPE , a variant of JAPE which does not use pre-aligned relations and attributes. Because the approach ITransE performs iterative alignment and it re- quires two KGs sharing the same relations, we do not include it in the comparison. The inter- language links in each dataset are used as the gold standards of entity alignments. For all the com- pared approaches, we use 30% of inter-language links for training and 70% of them for testing; the split of training and testing are the same for all approaches. We use Hits@k as the evalua- tion measure to assess the performance of all the approaches. Hits@k measures the proportion of correctly aligned entities ranked in the top k candi- dates. For the parameters of our approach, we set d s = 1, 000, d a = 100; the margin γ s = γ a = 3 in the loss function, and β in the distance measure is emperically set to 0.9. <ref type="table" target="#tab_4">Table 3</ref> shows the results of all the compared approaches on DBP15K datasets. We report Hits@1, Hits@10 and Hits@50 of approaches on each dataset. Because we use the same datasets as in ( , the results of JE, MTransE, and JAPE are obtained from . For JAPE and JAPE , each of them has three variants: Structure Embedding without negative triples (SE w/o neg.), Structure Embedding (SE), Structure and attribute joint embedding (SE+AE). We use GCN(SE) and GCN(SE+AE) to denote two variants of our approach: one only uses re- lational triples to perform structure embedding, and the other uses both relational and attributional triples to perform structure and attribute embed- ding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GCN(SE) vs. GCN(SE+AE)</head><p>We first compare the results of GCN(SE) and GCN(SE+AE) to see whether the attributional in- formation is helpful in the KG alignment task. According to the results, adding attributes in our approach do lead to slightly better results. The improvements range from 1% to 10%, which are very similar to the improvements of JAPE(SE) over JAPE(SE+AE). It shows that the KG align- ment mainly relays on the structural information in KGs, but the attributional information is still use- ful. Our approach uses the same framework for embedding structure and attribute information, the combination of two kinds of embeddings works effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GCN(SE+AE) vs. Baselines</head><p>On the dataset of DBP15K ZH−EN , JAPE(SE+AE) performs best and gets five best Hits@k values; our approach GCN(SE+AE) gets the best Hits@1 in the alignment direction of ZH→EN. The results of GCN(SE+AE) and JAPE gets very close results regarding Hits@1 and Hits@10 in the direction of ZH→EN. In the alignment direction of EN→ZH, JAPE(SE+AE) outperforms GCN(SE+AE) by about 2-3%. But it should be noticed that JAPE uses additional aligned relations and attributes as its inputs,    Comparing with all the baselines, both GCN(SE) and GCN(SE+AE) outperform JE and MTransE significantly. Among all the baselines, JAPE is the strongest one; it might due to its ability of using both relational and attributional triples, and the extra alignments of relations and attributes that it consumes. Our approach achieves better results than JAPE on two datasets; Al- though JAPE performs better than our approach, the differences between their results are small. If there are no existing relation and attribute alignments between two KGs, our approach will have distinct advantage over JAPE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GCN vs. JAPE using different sizes of train- ing data</head><p>To investigate how the size of training set affects the results of our approach, we further compare our approach with JAPE by using different number of pre-aligned entities as training data. For JAPE, the pre-aligned entities are used as seeds to make their vectors overlapped. In our approach, all the pre-aligned entities are used to train GCN models. Intuitively, the more pre-aligned entities used, the better results should be obtained by both GCN and JAPE.</p><p>Here we use different proportions of pre-aligned entities as training data, which ranges 10% to 50% with step 10%; all the rest of pre-aligned entities are used for testing. <ref type="figure" target="#fig_2">Figure 2</ref> shows the Hits@1 of two approaches in three datasets. It shows that both approaches perform better as the size of train- ing data increases. And our approach always out- performs JAPE except using 40% pre-aligned en- tities as training data in <ref type="figure" target="#fig_2">Figure 2</ref>(a). Especially in the tasks of aligning Japanese to English and French to English, our approach has a distinct ad- vantage over JAPE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>This paper presents a new embedding-based KG alignment approach which discovers entity align- ments based on the entity embeddings learned by GCNs. Our approach can make use of both the relational and the attributional triples in KGs to discover the entity alignments. We evaluate our method on the data of real multilingual KGs, and the results show the advantages of our approach over the compared baselines.</p><p>In the future work, we will explore more ad- vanced GCN models for KG alignment task, such as Relational GCNs ( <ref type="bibr" target="#b13">Schlichtkrull et al., 2017)</ref> and Graph Attention Networks (GATs) <ref type="bibr">(Velickovic et al., 2017)</ref>. Furthermore, how to iteratively discover new entity alignments in the framework of our approach is another interesting direction that we will study in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Framework of our approach (dashed blue lines connects equivalent entities in two KGs)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>a</head><label></label><figDesc>are the weight matrices for structure features and attribute features in the l-th layer, respectively; [ ; ] denotes the concatenation of two matrices. The activation function σ is cho- sen as ReLU (·) = max(0, ·).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: GCN and JAPE using different sizes of training data (horizontal coordinates: proportions of pre-aligned entities used in training data; vertical coordinates: Hits@1 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>2 ); and let their corresponding GCN models be denoted as GCN 1 and GCN 2 . As for the structure feature vectors of entities, we set the dimensionality of feature vectors to d s in all the layers of GCN 1 and GCN 2 ; and two GCN models share the weight matrices Wfor the structure features in two layers. As for the attribute vectors of entities, we set the dimen- sionality of output feature vectors to d a . Because two KGs may have different number of attributes (i.e. |A 1 | = |A 2 |), the dimensionalities of the in- put attribute feature vectors in two GCN models are different. The first layer of each GCN model transforms the input attribute feature vectors into vectors of size d a ; and two GCN-models gener- ate attribute embeddings of the same dimensional- ity. Table 1 outlines the parameters of two GCNs in our approach. The final outputs of two GCNs are (d s + d a )-dimensional embeddings of entities, which are further used to discover entity align- ments.</figDesc><table>(1) 
s 

and W 

(2) 
s 

Parameter 
GCN1 
GCN2 

Initial Structure Feature Matrices 
H 

(0) 

s1 ∈ R |E 1 |×ds 
H 

(0) 

s2 ∈ R |E 2 |×ds 
Weight Matrix for Structure Features in Layer 1 
W 

(1) 
s 

∈ R ds×ds 

Weight Matrix for Structure Features in Layer 2 
W 

(2) 
s 

∈ R ds×ds 

Output Structure Embeddings 
H 

(2) 

s1 ∈ R |E 1 |×ds 
H 

(2) 

s2 ∈ R |E 2 |×ds 
Initial Attribute Feature Matrices 
H 

(0) 

a1 ∈ R |E 1 |×|A 1 | H 

(0) 

a2 ∈ R |E 2 |×|A 2 | 
Weight Matrix for Attribute Features in Layer 1 
W 

(1) 

a1 ∈ R |A 1 |×da 
W 

(1) 

a2 ∈ R |A 2 |×da 
Weight Matrix for Attribute Features in Layer 2 
W 

(2) 
a 

∈ R da×da 

Output Attribute Embeddings 
H 

(2) 

a1 ∈ R |E 1 |×da 
H 

(2) 

a2 ∈ R |E 2 |×da 

Table 1: Parameters of two GCNs 

Computation of Connectivity Matrix. In a 
GCN model, the connectivity matrix A defines 
the neighborhoods of entities in the convolutional 
computation. For an undirected graph, the adja-
cency matrix can be directly used as A s . But KGs 
are relational multi-graphs, entities are connected 
by typed relations. Therefore, we design a par-
ticular method for computing A of a KG; we let 
a ij ∈ A indicate </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Details of the datasets 

DBP 15KZH−EN 
ZH → EN 
EN → ZH 
Hits@1 Hits@10 Hits@50 Hits@1 Hits@10 Hits@50 

*JE 
21.27 
42.77 
56.74 
19.52 
39.36 
53.25 

*MTransE 
30.83 
61.41 
79.12 
24.78 
52.42 
70.45 

*JAPE 
SE w/o neg. 
38.34 
68.86 
84.07 
31.66 
59.37 
76.33 
SE 
39.78 
72.35 
87.12 
32.29 
62.79 
80.55 
SE + AE 
41.18 
74.46 
88.90 
40.15 
71.05 
86.18 

JAPE 
SE w/o neg. 
30.10 
62.58 
80.28 
23.04 
52.91 
72.17 
SE 
30.54 
66.41 
83.94 
23.91 
57.02 
77.31 
SE + AE 
33.32 
69.28 
86.40 
33.02 
66.92 
85.15 

GCN 
SE 
38.42 
70.34 
81.24 
34.43 
65.68 
77.03 
SE + AE 
41.25 
74.38 
86.23 
36.49 
69.94 
82.45 

DBP 15KJA−EN 
JA → EN 
EN → JA 
Hits@1 Hits@10 Hits@50 Hits@1 Hits@10 Hits@50 

*JE 
18.92 
39.97 
54.24 
17.80 
38.44 
52.48 

*MTransE 
27.86 
57.45 
75.94 
23.72 
49.92 
67.93 

*JAPE 
SE w/o neg. 
33.10 
63.90 
80.80 
29.71 
56.28 
73.84 
SE 
34.27 
66.39 
83.61 
31.40 
60.80 
78.51 
SE + AE 
36.25 
68.50 
85.35 
38.37 
67.27 
82.65 

JAPE 
SE w/o neg. 
28.90 
60.61 
80.03 
25.34 
53.36 
71.94 
SE 
29.35 
63.31 
82.76 
26.37 
57.35 
76.87 
SE + AE 
31.06 
64.11 
81.57 
32.45 
62.21 
79.08 

GCN 
SE 
38.21 
72.49 
82.69 
36.90 
68.50 
79.51 
SE + AE 
39.91 
74.46 
86.10 
38.42 
71.81 
83.72 

DBP 15KF R−EN 
F R → EN 
EN → F R 
Hits@1 Hits@10 Hits@50 Hits@1 Hits@10 Hits@50 

*JE 
15.38 
38.84 
56.50 
14.61 
37.25 
54.01 

*MTransE 
24.41 
55.55 
74.41 
21.26 
50.60 
69.93 

*JAPE 
SE w/o neg. 
29.55 
62.18 
79.36 
25.40 
56.55 
74.96 
SE 
29.63 
64.55 
81.90 
26.55 
60.30 
78.71 
SE + AE 
32.39 
66.68 
83.19 
32.97 
65.91 
82.38 

JAPE 
SE w/o neg. 
28.23 
60.99 
78.47 
24.68 
55.25 
74.19 
SE 
27.58 
62.03 
79.98 
24.93 
58.95 
77.79 
SE + AE 
30.21 
65.81 
82.57 
31.42 
63.86 
80.95 

GCN 
SE 
36.51 
73.42 
85.93 
36.08 
72.37 
85.44 
SE + AE 
37.29 
74.49 
86.73 
36.77 
73.06 
86.39 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results comparison of cross-lingual KG alignment (* marks the results obtained from (Sun et al., 
2017)) 

while our approach does not use these kinds 
of prior knowledge. If compared with JAPE , 

GCN(SE+AE) performs better than it regrading 
Hits@1 and Hits@10. While compared with </table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The work is supported by the National Natural Sci-ence Foundation of China (No. 61772079) and the National Key R&amp;D Program of China (No. 2017YFC0804004).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Dbpedia-a crystallization point for the web of data. Web Semantics: science, services and agents on the world wide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="154" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garciaduran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in neural information processing systems (NIPS2013)</title>
		<meeting>Advances in neural information processing systems (NIPS2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spectral networks and locally connected networks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations</title>
		<meeting>International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multilingual knowledge graph embeddings for cross-lingual knowledge alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (AAAI2017)</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence (AAAI2017)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1511" to="1517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Advances in Neural Information Processing Systems (NIPS2016)</title>
		<meeting>Advances in Neural Information Processing Systems (NIPS2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A joint embedding method for entity alignment of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of China Conference on Knowledge Graph and Semantic Computing (CCKS2016)</title>
		<meeting>China Conference on Knowledge Graph and Semantic Computing (CCKS2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05163</idno>
		<title level="m">Deep convolutional networks on graph-structured data</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding via dynamic mapping matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="687" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR2017)</title>
		<meeting>International Conference on Learning Representations (ICLR2017)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI2015)</title>
		<meeting>the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="2181" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Babelnet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="217" to="250" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A review of relational machine learning for knowledge graphs. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="11" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Yago: A multilingual knowledge base from wikipedia, wordnet, and geonames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Rebele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><forename type="middle">Asia</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erdal</forename><surname>Kuzey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth International Semantic Web Conference (ISWC2016)</title>
		<meeting>the Fifteenth International Semantic Web Conference (ISWC2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="177" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06103</idno>
		<title level="m">Modeling relational data with graph convolutional networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Yago: A large ontology from wikipedia and wordnet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Fabian M Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics: Science, Services and Agents on the World Wide Web</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="217" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cross-lingual entity alignment via joint attributepreserving embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth International Semantic Web Conference (ISWC2017)</title>
		<meeting>the Sixteenth International Semantic Web Conference (ISWC2017)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="628" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<idno>abs/1710.10903</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding: A survey of approaches and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhendong</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2724" to="2743" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentyeighth AAAI Conference on Artificial Intelligence (AAAI2014)</title>
		<meeting>the Twentyeighth AAAI Conference on Artificial Intelligence (AAAI2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1112" to="1119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Iterative entity alignment via joint knowledge embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-sixth International Joint Conference on Artificial Intelligence (IJCAI2017)</title>
		<meeting>the Twenty-sixth International Joint Conference on Artificial Intelligence (IJCAI2017)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4258" to="4264" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
