<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Document Retrieval for Deep Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Kratzwald</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Chair of Management Information Systems ETH Zurich Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Feuerriegel</surname></persName>
							<email>{bkratzwald, sfeuerriegel}@ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Chair of Management Information Systems ETH Zurich Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive Document Retrieval for Deep Question Answering</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Association for Computational Linguistics</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">576</biblScope>
							<biblScope unit="page" from="576" to="581"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>State-of-the-art systems in deep question answering proceed as follows: (1) an initial document retrieval selects relevant documents, which (2) are then processed by a neural network in order to extract the final answer. Yet the exact interplay between both components is poorly understood, especially concerning the number of candidate documents that should be retrieved. We show that choosing a static number of documents-as used in prior research-suffers from a noise-information trade-off and yields suboptimal results. As a remedy, we propose an adaptive document retrieval model. This learns the optimal candidate number for document retrieval, conditional on the size of the corpus and the query. We report extensive experimental results showing that our adaptive approach out-performs state-of-the-art methods on multiple benchmark datasets, as well as in the context of corpora with variable sizes.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question-answering (QA) systems proceed by fol- lowing a two-staged process <ref type="bibr" target="#b1">(Belkin, 1993)</ref>: in a first step, a module for document retrieval se- lects n potentially relevant documents from a given corpus. Subsequently, a machine compre- hension module extracts the final answer from the previously-selected documents. The latter step often involves hand-written rules or machine learning classifiers (c. f. <ref type="bibr" target="#b16">Shen and Klakow, 2006;</ref><ref type="bibr" target="#b9">Kaisser and Becker, 2004)</ref>, and recently also deep neural networks (e. g. <ref type="bibr" target="#b5">Chen et al., 2017;</ref><ref type="bibr" target="#b18">Wang et al., 2018)</ref> The number of candidate documents n affects the interplay between both document retrieval and machine comprehension component. A larger n improves the recall of document retrieval and thus the chance of including the relevant information.</p><p>However, this also increases the noise and might adversely reduce the accuracy of answer extrac- tion. It was recently shown that a top-1 system can potentially outperform a system selecting more than one document ( <ref type="bibr" target="#b10">Kratzwald and Feuerriegel, 2018)</ref>. This finding suggests that a static choice of n can result a suboptimal performance.</p><p>Contributions. This work analyzes the in- terplay between document retrieval and machine comprehension inside neural QA systems. We first reason numerically why a fixed choice of n in doc- ument retrieval can negatively affect the perfor- mance of question answering. We thus propose a novel machine learning model that adaptively se- lects the optimal n i for each document retrieval. The resulting system outperforms state-of-the-art neural question answering on multiple benchmark datasets. Notably, the overall size of the corpus affects the optimal n considerably and, as a result, our system evinces as especially superior over a fixed n in settings where the corpus size is un- known or grows dynamically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Taxonomy of QA systems. Question answering systems are frequently categorized into two main paradigms. On the one hand, knowledge-based systems draw upon manual rules, ontologies and large-scale knowledge graphs in order to deduce answers (e. g. <ref type="bibr" target="#b2">Berant et al., 2013;</ref><ref type="bibr" target="#b11">Lopez et al., 2007;</ref><ref type="bibr" target="#b17">Unger et al., 2012</ref>). On the other hand, QA system incorporate a document retrieval mod- ule which selects candidate documents based on a chosen similarity metric, while a subsequent mod- ule then processes these in order to extract the answer (e. g. <ref type="bibr" target="#b4">Cao et al., 2011;</ref><ref type="bibr" target="#b7">Harabagiu et al., 2000</ref>).</p><p>Deep QA. Recently, <ref type="bibr" target="#b5">Chen et al. (2017)</ref> devel- oped a state-of-the-art deep QA system, where the (a) Exact matches with correct answer (b) Recall at top-n (c) Avg. number of relevant documents corpus size number of relevant documents <ref type="figure">Figure 1</ref>: Comparison of how top-n document retrieval affects deep QA. Plot (a) shows the percentage of exact matches with the correct answering, thereby measuring the end-to-end performance of the complete system. Plot (b) gives the recall at top-n, i. e. the fraction of samples where at least once the correct answer is returned. Plot (c) depicts the average number of documents that contain the ground-truth answer. As a result, the recall lowers with increasing corpus size, yet this not necessarily compromises a top-n system, as it often contains the correct answer more than once.</p><p>answer is extracted from the top n = 5 documents. This choice stems from computing the dot product between documents and a query vector; with tf-idf weighting of hashed bi-gram counts. <ref type="bibr" target="#b18">Wang et al. (2018)</ref> extended this approach by implementing a neural re-ranking of the candidate document, yet keeping the fixed number of n selected documents unchanged. In particular, the interplay between both modules for document retrieval and machine comprehension has not yet been studied. This es- pecially pertains to the number of candidate docu- ments, n, that should be selected during document retrieval.</p><p>Component interactions. Extensive research has analyzed the interplay of both document re- trieval and machine comprehension in the con- text of knowledge-based systems (c. f. <ref type="bibr" target="#b13">Moldovan et al., 2003)</ref> and even retrieval-based systems with machine learning (c. f. <ref type="bibr" target="#b3">Brill et al., 2002</ref>). How- ever, these findings do not translate to machine comprehension with deep learning. Deep neu- ral networks consist of a complex attention mech- anism for selecting the context-specific answer ( <ref type="bibr" target="#b8">Hermann et al., 2015</ref>) that has not been avail- able to traditional machine learning and, more- over, deep learning is highly sensitive to settings involving multiple input paragraphs, often strug- gling with selecting the correct answer <ref type="bibr" target="#b6">(Clark and Gardner, 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Noise-Information Trade-Off in Document Retrieval</head><p>In the following, we provide empirical evidence why a one-fits-all n can be suboptimal. For this purpose, we run a series of experiments in order to obtain a better understanding of the interplay between document retrieval and machine compre- hension modules. That is, we specifically com- pare the recall of document retrieval to the end-to- end performance of the complete QA system; see <ref type="figure">Fig. 1</ref>. Our experiments study the sensitivity along two dimensions: on the one hand, we change the number of top-n documents that are returned dur- ing document retrieval and, on the other hand, we vary the corpus size. Our experiments utilize the TREC QA dataset as a well-established benchmark for open-domain question answering. It contains 694 question- answer pairs that are answered with the help of Wikipedia. We vary the corpus between a small case (where each question-answer pair contains only one Wikipedia article with the correct an- swer plus 50 % articles as noise) and the complete Wikipedia dump containing more than five million documents. Our experiments further draw upon the DrQA system ( <ref type="bibr" target="#b5">Chen et al., 2017</ref>) for question answering that currently stands as a baseline in deep question answering. We further modified it to return different numbers of candidate documents. <ref type="figure">Fig. 1 (a)</ref> shows the end-to-end performance across different top-n document retrievals as mea- sured by the exact matches with ground truth. For a small corpus, we clearly register a superior per- formance for the top-1 system. However, we ob- serve a different pattern with increasing corpus size. <ref type="figure">Fig. 1 (b)</ref> and (c) shed light into the un- derlying reason by reporting how frequently the correct answer is returned and, as the correct an-  swer might appear multiple times, how often it is included in the top-n. Evidently, the recall in (b) drops quickly for a top-1 system when augment- ing the corpus. Yet it remains fairly stable for a top-n system, due to the fact that it is sufficient to have the correct answer in any of the n documents. According to (c), the correct answer is often more than once returned by a top-n system, increasing the chance of answer extraction.</p><p>The above findings result in a noise-information trade-off. A top-1 system often identifies the cor- rect answer for a small corpus, whereas a larger corpus introduces additional noise and thus im- pedes the overall performance. Conversely, a top-n system accomplishes a higher density of rel- evant information for a large corpus as the answer is often contained multiple times. This effect is visualized in an additional experiment shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. We keep the corpus size fixed and vary only n, i.e. the number of retrieved documents. We see the recall converging fast, while the average num- ber of relevant documents keeps growing, leading to a higher density of relevant information. As a result, a top-n system might not be compromised by a declining recall, since it contains the correct answer over-proportionally often. This logic mo- tivates us in the following to introduce an adap- tive n i that optimizes the number of documents re- trievals in a top-n system independently for every query q i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Adaptive Document Retrieval</head><p>This section advances deep question answering by developing adaptive methods for document re- trieval. Our methods differ from conventional doc- ument retrieval in which the number of returned documents is set to a fixed n. Conversely, we ac- tively optimize the choice of n i for each document</p><note type="other">retrieval i. Formally, we select n i between 1 and a maximum τ (e. g. τ = 20), given documents [d (1) i , . . . , d (τ ) i ]. These entail further scores denot- ing the relevance, i. e. s</note><formula xml:id="formula_0">i = [s (1) i , . . . , s (τ ) i ] T with normalization s. t. j s (j) i = 1.</formula><p>The scoring func- tion is treated as a black-box and thus can be based on simple tf-idf similarity but also complex prob- abilistic models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Threshold-Based Retrieval</head><p>As a na¨ıvena¨ıve baseline, we propose a simple threshold-based heuristic. That is, n i is deter- mined such that the cumulative confidence score reaches a fixed threshold θ ∈ (0, 1]. Formally, the number n i of retrieved documents is given by</p><formula xml:id="formula_1">n i = max k k j=1 s (j) i &lt; θ.<label>(1)</label></formula><p>In other words, the heuristic fills up documents un- til surpassing a certain confidence threshold. For instance, if the document retrieval is certain that the correct answer must be located within a spe- cific document, it automatically selects fewer doc- uments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ordinal Regression</head><p>We further implement a trainable classifier in the form of an ordinal ridge regression which is tai- lored to ranking tasks. We further expect the cu- mulative confidence likely to be linear. The classi- fier then approximates n i with a prediction y i that denotes the position of the first relevant document containing the desired answer. As such, we learn a function</p><formula xml:id="formula_2">y i = f ([s (1) i , . . . , s (τ ) i ]) = s T i β,<label>(2)</label></formula><p>where . . . denotes the ceiling function. The ridge coefficients are learned through a cus- tom loss function</p><formula xml:id="formula_3">L = Xβ − y 1 + λ β 2 ,<label>(3)</label></formula><p>where X is a matrix containing scores of our train- ing samples. In contrast to the classical ridge re- gression, we introduce a ceiling function and re- place the mean squared error by a mean absolute error in order to penalize the difference from the optimal rank. The predicted cut-offˆnoffˆ offˆn i for docu- ment retrieval is then computed for new observa- tions</p><formula xml:id="formula_4">s i viâ n i = s T i ˆ β + b.</formula><p>The linear offset b is added in order to ensures that n i ≤ ˆ n i holds, i. e. reducing the risk that the first relevant document is not included.</p><p>We additionally experimented with non-linear predictors, including random forests and feed- forward neural networks; however; we found no significant improvement that justified the addi- tional model complexity over the linear relation- ship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We first compare our QA system with adaptive document retrieval against benchmarks from the literature. Second, we specifically study the sen- sitivity of our adaptive approach to variations in the corpus size. All our experiments draw upon the DrQA implementation <ref type="bibr" target="#b5">(Chen et al., 2017</ref>), a state-of-the-art system for question answering in which we replaced the default module for docu- ment retrieval with our adaptive scheme (but leav- ing all remaining components unchanged, specifi- cally without altering the document scoring or an- swer extraction).</p><p>For the threshold-based model, we set τ = 15 and the confidence threshold to θ = 0.75. For the ordinal regression approach, we choose τ = 20 and use the original SQuAD train-dev split from the full corpus also as the basis for training across all experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overall Performance</head><p>In a first series of experiments, we refer to an ex- tensive set of prevalent benchmarks for evaluating QA systems, namely, SQuAD ( <ref type="bibr" target="#b14">Rajpurkar et al., 2016)</ref>, Curated TREC (Baudiš andŠediv´yandˇandŠediv´andŠediv´y, 2015), <ref type="bibr">WikiMovies (Miller et al., 2016)</ref> and WebQues- tions ( <ref type="bibr" target="#b2">Berant et al., 2013</ref>) in order to validate the robustness of our findings. Based on these, we then evaluate our adaptive QA systems against the na¨ıvena¨ıve DrQA system in order to evaluate the rela- tive performance. We included the deep QA sys- tem R 3 as an additional, top-scoring benchmark from recent literature ( <ref type="bibr" target="#b18">Wang et al., 2018</ref>) for bet- ter comparability.</p><p>Tbl. 1 reports the ratio of exact matches for the different QA systems. The results demonstrate the effectiveness of our adaptive scheme: it yields the best-performing system for three out of four datasets. On top of that, it outperforms the na¨ıvena¨ıve DrQA system consistently across all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Sensitivity: Adaptive QA to Corpus Size</head><p>We earlier observed that the corpus size affects the best choice of n and we thus study the sensitivity with regard to the size. For this purpose, we repeat the experiments from Section 3 in order to evaluate the performance gain from our adaptive scheme. More precisely, we compare the ordinal regression (b = 1) against document retrieval with a fixed document count n. <ref type="figure" target="#fig_2">Fig. 3</ref> shows the end-to-end performance, con- firming the overall superiority of our adaptive doc- ument retrieval. For instance, the top-1 system reaches a slightly higher rate of exact matches for small corpus sizes, but is ranked last when considering the complete corpus. The high per- formance of the top-1 system partially originates from the design of the experiment itself, where we initially added one correct document per question, which is easy to dissect by adding little additional noise. On the other hand, the top-10 system ac- complishes the best performance on the complete corpus, whereas it fails to obtain an acceptable performance for smaller corpus sizes.</p><p>To quantify our observations, we use a nota- tion of regret. Formally, let µ nm denote the per- formance of the top-n system on a corpus of size m. Then the regret of choosing system n at evaluation point m is the difference between the best performing system µ * m and the chosen sys- tem r nm = µ * m − µ nm . The total regret of sys- tem n is computed by averaging the regret over all observations of system n, weighted with the span in-between observations in order to account for the logarithmic intervals. The best top-n sys- tem yields a regret of 0.83 and 1.12 respectively, whereas our adaptive control improves it down to 0.70.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Robustness Check</head><p>Experiments so far have been conducted on the DrQA system. To show the robustness of our ap- proach, we repeat all experiments on a different QA system. Different from DrQA, this system op- erates on paragraph-level information retrieval and End-to-end perfor- mance of adaptive informa- tion retrieval over static top- n configurations and a grow- ing corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SQuAD TREC WebQuestions WikiMovies</head><p>DrQA <ref type="formula">(</ref>   <ref type="table">Table 2</ref>: End-to-end performance measured in percentages of exact matching answers of a second QA system that operates on paragraph-level information retrieval. We compare two configurations of the system using the top-50 and top-80 ranked paragraphs to extract the answer against our threshold-based approach and regression approach that selects the cutoff within the first 250 paragraphs.</p><p>uses cosine similarity to score tf-idf-weighted bag- of-word (unigram) vectors. The reader is a modi- fied version of the DrQA document reader with an additional bi-directional attention layer ( <ref type="bibr" target="#b15">Seo et al., 2017</ref>). We are testing two different configura- tions 1 of this system: one that selects the top-50 paragraphs and one that selects the top-80 para- graphs against our approach as shown in Tab. 2. We see that, owed to the paragraph-level infor- mation retrieval, the number of top-n passages gains even more importance. Both variations of the system outperform a system without adaptive retrieval, which confirms our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Our contribution is three-fold. First, we establish that deep question answering is subject to a noise- information trade-off. As a consequence, the num- ber of selected documents in deep QA should not be treated as fixed, rather it must be carefully tai- lored to the QA task. Second, we propose adap- tive schemes that determine the optimal document 1 Best configurations out of {30, 40, 50, 60, 70, 80, 90, and 100} on SQuAD train split.</p><p>count. This can considerably bolster the perfor- mance of deep QA systems across multiple bench- marks. Third, we further demonstrate how cru- cial an adaptive document retrieval is in the con- text of different corpus sizes. Here our adaptive strategy presents a flexible strategy that can suc- cessfully adapt to it and, compared to a fixed doc- ument count, accomplishes the best performance in terms of regret.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility</head><p>Code to integrate adaptive document retrieval in custom QA system and future research is freely available at https://github.com/ bernhard2202/adaptive-ir-for-qa</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Recall (a) and average number of relevant documents (b) for growing top-n configurations and a static corpus size (full Wikipedia dump). While the recall is converging the number of relevant documents keeps growing resulting in a higher density of relevant information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: End-to-end performance of adaptive information retrieval over static topn configurations and a growing corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>End-to-end performance of the plain DrQA system measured in 
exact matches. Performance of two threshold based and two regression 
based adaptive retreival improvements as well as other state-of-the art 
systems. Experiments are based on the full Wikipedia dump containing 
more than 5 million documents. 

SQuAD TREC WebQuestions WikiMovies 

Top-50 System 
27.0 
23.5 
15.1 
24.4 
Top-80 System 
27.2 
25.9 
14.9 
26.0 

Threshold-based (θ = 0.75, τ = 100) 
27.2 
27.1 
15.4 
26.3 
Ordinal regression (b = 3, τ = 250) 
27.3 
27.1 
16.7 
26.5 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their help-ful comments. We gratefully acknowledge the support of NVIDIA Corporation with the dona-tion of the Titan Xp GPU used for this research. Cloud computing resources were provided by a Microsoft Azure for Research award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Modeling of the question answering task in the yodaqa system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Baudiš</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Sediv´ysediv´y</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="222" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Interaction with texts: Information retrieval as information-seeking behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Belkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An analysis of the AskMSR question-answering system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Askhermes: An online question answering system for complex clinical questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonggang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pippa</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lamont</forename><surname>Antieau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Cimino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Ely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="277" to="288" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10723</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Falcon: Boosting knowledge for answer engines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roxana</forename><surname>Girju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasile</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Morarescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="479" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočisk´kočisk´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1693" to="1701" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Question answering by searching large corpora with linguistic methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kaisser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tilman</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Putting question-answering systems into practice: Transfer learning for efficient domain customization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Kratzwald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Feuerriegel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07097</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Aqualog: An ontology-driven question answering system for organizational semantic intranets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Uren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Motta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Pasin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics: Science, Services and Agents on the World Wide Web</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="72" to="105" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1400" to="1409" />
		</imprint>
	</monogr>
	<note>AmirHossein Karimi, Antoine Bordes, and Jason Weston</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Performance issues and error analysis in an open-domain question answering system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Pas¸capas¸ca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="154" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploring correlation of dependency relation paths for answer extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietrich</forename><surname>Klakow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="889" to="896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Template-based question answering over rdf data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenz</forename><surname>Bühmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on World Wide Web</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">639</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">R3: Reinforced ranker-reader for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
