<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:27+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Theme-Rewriting Approach for Generating Algebra Word Problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>November 1-5, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ioannis Konstas</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ioannis Konstas</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ioannis Konstas</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Theme-Rewriting Approach for Generating Algebra Word Problems</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1617" to="1628"/>
							<date type="published">November 1-5, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Texts present coherent stories that have a particular theme or overall setting, for example science fiction or western. In this paper, we present a text generation method called rewriting that edits existing human-authored narratives to change their theme without changing the underlying story. We apply the approach to math word problems, where it might help students stay more engaged by quickly transforming all of their homework assignments to the theme of their favorite movie without changing the math concepts that are being taught. Our rewriting method uses a two-stage decoding process, which proposes new words from the target theme and scores the resulting stories according to a number of factors defining aspects of syntactic, semantic, and thematic coherence. Experiments demonstrate that the final stories typically represent the new theme well while still testing the original math concepts, outperforming a number of baselines. We also release a new dataset of human-authored rewrites of math word problems in several themes.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Storytelling is the complex activity of expressing a plot, its events and participants in words meaning- ful to an audience. Automatic storytelling systems can be used for customized sport commentaries, en- riching video games with personalized or dynamic plot-lines ( <ref type="bibr" target="#b0">Barros and Musse, 2007)</ref>, or providing customized learning materials which meet each indi- vidual student's needs and interests <ref type="bibr" target="#b1">(Bartlett, 2004)</ref>. In this paper, we focus on generating narrative-style  math word problems ( <ref type="figure" target="#fig_1">Figure 1</ref>) and demonstrate that it is possible to design an algorithm that can auto- matically change the overall theme of a text without changing its underlying story, for example to create more engaging homework that is in the theme of a student's favorite movie.</p><p>A math word problem is a coherent story that provides the student with good clues to the cor- rect mathematical operations between the numerical quantities described therein. However, the particular theme of a problem, whether it be about collecting apples or traveling distances through space, can vary significantly so long as the correlation between the story and underlying equation is maintained. Stu- dents' success at solving a word problem is tied to their interest in the problem's theme <ref type="bibr" target="#b44">(Renninger et al., 2002</ref>), and personalizing word problems in- creases student understanding, engagement, and per- formance in the problem solving process <ref type="bibr" target="#b16">(Hart, 1996;</ref><ref type="bibr" target="#b6">Davis-Dorsey et al., 1991)</ref>.</p><p>Motivated by this need for thematically diverse, highly coherent stories, we address the problem of story rewriting, or transforming human-authored stories into novel, coherent stories in a new theme. Rather than synthesizing first a story plot <ref type="bibr" target="#b33">(McIntyre and Lapata, 2009;</ref><ref type="bibr" target="#b34">McIntyre and Lapata, 2010)</ref> or script ( <ref type="bibr" target="#b2">Chambers and Jurafsky, 2009;</ref><ref type="bibr" target="#b43">Pichotta and Mooney, 2016;</ref><ref type="bibr" target="#b15">Granroth-Wilding and Clark, 2016)</ref> from scratch, we instead begin from an existing story and iteratively edit it towards a thematically novel but -most crucially-semantically compatible story. This approach allows us to reuse much, but not all, of the syntactic and semantic structure of the original text, resulting in the creation of more coher- ent and solvable math word problems.</p><p>We define a theme to be a collection of refer- ence texts, such as a movie script or series of books. Given a theme, the rewrite algorithm constructs new texts by substituting thematically appropriate words and phrases, as measured with automatic metrics over the theme text collection, for parts of the orig- inal texts. This process optimizes for a number of metrics of overall text quality, including syntactic, semantics, and discourse scores. It uses no hand crafted templates and requires no theme-specific tuning data, making it easy to apply for new themes in practice. <ref type="table" target="#tab_6">Tables 4-6</ref> show example stories gener- ated from the rewrite system.</p><p>To evaluate performance, we collected a corpus of 450 rewrites of math word problems in Star Wars and Children's Cartoon themes via crowdsourcing. <ref type="bibr">1</ref> Experiments with automated metrics and human evaluations demonstrate that the approach described here outperforms a number of baselines and can pro- duce solvable problems in multiple different themes, even with no in-domain tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our approach is related to the previous work in story generation (e.g., <ref type="bibr" target="#b34">McIntyre and Lapata (2010)</ref>) and sentence rewriting (e.g., text simplification ( <ref type="bibr" target="#b61">Xu et al., 2016)</ref>), as reviewed in this section. It has three major differences from all these approaches: First, we focus on multi-sentence stories where preserving the coherence, discourse relations, and solvability is essential. Previous work mainly focuses on rewrit- ing single sentences. Second, we build a theme from a text corpus and show how the stories can be adapted to new themes. Third, our method leverages the human-authored story to capture the semantic skeleton and the plot of the current story, rather than synthesizing the story plot. To our knowledge, we are the first to introduce a text rewriting formulation for story generation.</p><p>Story generation has been of long interest to AI researchers <ref type="bibr" target="#b36">(Meehan, 1976;</ref><ref type="bibr" target="#b28">Lebowitz, 1987;</ref><ref type="bibr" target="#b55">Turner, 1993;</ref><ref type="bibr" target="#b31">Liu and Singh, 2002;</ref><ref type="bibr" target="#b40">Mostafazadeh et al., 2016)</ref>. Recent methods in story generation first syn- thesize candidate plots for a story and then compile those plots into text. <ref type="bibr" target="#b30">Li et al. (2013)</ref> use crowd- sourcing to build plot graphs. <ref type="bibr" target="#b33">McIntyre and Lapata (2009;</ref> address story generation through the automatic deduction and reassembly of scripts ( <ref type="bibr" target="#b48">Schank and Abelson, 1977)</ref>, or structured represen- tations of events and their participants, and causal relationships involved. Leveraging the automatic script learning methods of <ref type="bibr" target="#b2">Chambers and Jurafsky (2009)</ref>, <ref type="bibr" target="#b34">McIntyre and Lapata (2010)</ref> learn candidate entity-centered plot graphs, or possible events in- volving the entity and an ordering between these events, with the use of a genetic algorithm. Then plots are compiled into stories through the use of a rule-based text surface realizer <ref type="bibr" target="#b27">(Lavoie and Rambow, 1997</ref>) and reranked using a language model. <ref type="bibr" target="#b43">Polozov et al. (2015)</ref> automatically generate math word problems tailored to a student's interest us- ing Answer Set Programming to satisfy a collec- tion of pedagogical and narrative requirements. This method naturally produces highly coherent, person- alized story problems that meet pedagogical require- ments, at the expense of building the thematic on- tologies and discourse constraints by hand. <ref type="bibr">2</ref> Additionally, there is related work in text simpli- fication ( <ref type="bibr">Wubben et al., 2012;</ref><ref type="bibr" target="#b22">Kauchak, 2013;</ref><ref type="bibr" target="#b64">Zhu et al., 2010;</ref><ref type="bibr" target="#b56">Vanderwende et al., 2007;</ref><ref type="bibr" target="#b59">Woodsend and Lapata, 2011b;</ref><ref type="bibr" target="#b21">Hwang et al., 2015</ref>), sentence compression ( <ref type="bibr" target="#b9">Filippova and Strube, 2008;</ref><ref type="bibr" target="#b47">Rush et al., 2015)</ref>, and paraphrasing ( <ref type="bibr" target="#b12">Ganitkevitch et al., 2013;</ref><ref type="bibr" target="#b3">Chen and Dolan, 2011;</ref><ref type="bibr" target="#b11">Ganitkevitch et al., 2011</ref>). All these tasks are focused on rewriting sen- tences under a predefined set of constraints, such as simplicity. Different rule-based and data-driven ap- proaches are introduced by <ref type="bibr" target="#b42">Petersen and Ostendorf (2007)</ref>, <ref type="bibr" target="#b57">Vickrey and</ref><ref type="bibr" target="#b57">Koller (2008), and</ref><ref type="bibr" target="#b52">Siddharthan (2004)</ref>. Most data-driven approaches take advantage of machine translation techniques, use source-target sentence pairs, and learn rewrite operations ( <ref type="bibr" target="#b62">Yatskar et al., 2010;</ref><ref type="bibr" target="#b58">Woodsend and Lapata, 2011a)</ref>, or use additional external paraphrasing resources ( <ref type="bibr" target="#b61">Xu et al., 2016)</ref>.</p><p>Finally, this work is related to those on auto- matically solving math word problems. Specific topics include number word problems ( <ref type="bibr" target="#b51">Shi et al., 2015)</ref>, logic puzzle problems ( <ref type="bibr" target="#b39">Mitra and Baral, 2015)</ref>, arithmetic word problems ( <ref type="bibr" target="#b18">Hosseini et al., 2014;</ref><ref type="bibr" target="#b45">Roy and Roth, 2015)</ref>, algebra word prob- lems ( <ref type="bibr" target="#b63">Zhou et al., 2015;</ref><ref type="bibr">Koncel-Kedziorski et al., 2015a;</ref>, and geometry word problems ( <ref type="bibr" target="#b50">Seo et al., 2015;</ref><ref type="bibr" target="#b49">Seo et al., 2014</ref>). Several datasets of word problems are available ( <ref type="bibr" target="#b25">Koncel-Kedziorski et al., 2016;</ref><ref type="bibr" target="#b19">Huang et al., 2016)</ref>, though none address the need for thematic text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>Our system takes as input a story s and a theme t, and outputs the best rewrite s * from generated can- didates S.</p><p>A theme t is defined as a textual corpus that de- scribes a topic or a domain. This is an intentionally broad definition that allows a variety of textual re- sources to serve as themes. For example, the collec- tion of all Science Fiction stories from the Project Gutenberg can be a theme, or the script of a single movie, or a sampling of fan fiction from the Inter- net. This flexibility adds to the utility of our work, as varying amounts of thematic text may be avail- able.</p><p>The generated candidate s * is the most themati- cally fit problem that is syntactically and semanti- cally coherent given the original problem s and the new theme t. We represent a story in terms of the words it contains, so that s = {w 1 , w 2 , . . . w n } and Sam had 2 dogs. Each had 3 puppies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntactic relations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Candidates (s')</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic relations</head><p>Luke Skywalker had 2 ships. Each had 3 droids. </p><formula xml:id="formula_0">s = f (w 1 ), f (w 2 ), . . . f (w n )</formula><p>where the function f (w) : V o → V K t ∪ ∅, rewrites a word from the vocabulary of the original problem V o to either a word, a trivial noun compound of length K (e.g., multi-word named entity) from the vocab- ulary of the the thematic vocabulary V t , or reduces to the empty symbol, i.e., omits the input word en- tirely; hence the length of s can differ from that of the original problem.</p><p>Formally, our goal is to select the candidate s ∈ S by maximizing a scoring function R over the- matic, syntactic and semantic constraints, subject to a set of parameters θ:</p><formula xml:id="formula_1">s * = arg max s ∈S R(s |s, t; θ)<label>(1)</label></formula><p>In order to find the best story s * , our problem reduces to generating candidate stories s from the space of possible rewrites of the human-authored story s in a new theme t (Section 5). Since there are exponentially many rewrites, we follow a two- stage decoding approach: first we identify only the content words w i in the input problem, and provide for each a list of the top-k most salient thematic can- didate words and trivial noun compounds. We then search the space by progressively introducing more rewrites in the beam, and scoring them according to R (Section 4). <ref type="figure" target="#fig_2">Figure 2</ref> shows the overview of the scoring function for a candidate sentence s .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Scoring Stories</head><p>The scoring function R decomposes into three com- ponents, capturing aspects of syntactic compatibil- ity, semantic coherence, and thematicity:</p><formula xml:id="formula_2">R(s |s, t; θ) =α × Sem(s |s) + β × Syn(s |s) (2) + γ × Th(s |s, t)</formula><p>The syntactic (Syn) and semantic (Sem) coherence components measure the coherence of the words in the new story s , as well as their compatibility to the syntactic and semantic relations in the original story s. On the other hand, thematicity (Th) scores the relevance and importance of words in the new story with respect to theme t. We describe each of these components and the de- coding process in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Thematicity</head><p>Recall that a theme t is defined as a collection of documents that share a common topic, such as books in the science fiction genre, or scripts of hor- ror movies. We define thematicity of a word w as the measure of salience, or how discriminative that word is to a given theme. <ref type="bibr">3</ref> For example, robot and spaceship are expected to be highly thematic with respect to Star Wars. In our setting we extend this definition to a candidate problem s given s and t as:</p><formula xml:id="formula_3">Th(s |s, t) = |s| i Sal(w i , t)<label>(3)</label></formula><p>where w i is a word from the candidate problem, and Sal is its salience score with respect to the theme. In the context of this work we argue that the the- matic adaptation of the content words, i.e., nouns, verbs, named entities, and adjectives, plays the most important role in forming a new thematic problem. Therefore, we define their salience (except named entities) based on their tf-idf score over the theme t, and set it to zero for function words. Since named entities have relatively low frequencies in the theme corpus we set their salience to 1− 1</p><formula xml:id="formula_4">c(w i )</formula><p>, where c(w i )</p><p>is the number of times w i occurs in the theme. In the example story in <ref type="figure" target="#fig_2">Figure 2</ref> the thematicity score is derived as Sal(Luke Skywalker) + Sal(ships) + Sal(droids).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Syntactic compatibility</head><p>This work offers a new method for syntactic and discourse coherence based on preserving human- authored syntactic structure in generated text (hence our use of the term rewriting). The syntactic con- structs in a document play a distinctive role in main- taining cohesion across sentences. We consider the human-authored syntax of the original story s as gold standard, and use it to score a candidate prob- lem s by considering how well the syntactic rela- tions of s apply to s .</p><p>Formally, given a dependency triple (w i , w j , l) from a parse of a sentence in s, we compute the likelihood for the corresponding triple (w i , w j , l) for w i , w j in s . We define the syntactic score for all sentences in s as:</p><formula xml:id="formula_5">Syn(s |s) = i,j,l|(w i ,w j ,l)∈Dep(s) L Dep (w i , w j , l) (4)</formula><p>where Dep(s) are the dependency parse trees for all sentences in s; L Dep is a 3-gram language model over dependency triples which gives the likelihood of an arc label l being used between a pair of words (w i , w j ). For example in <ref type="figure" target="#fig_2">Figure 2</ref>, the syntactic compatibility score includes dependency likelihoods of L Dep (ship, 2, num), L Dep (had, ship, dobj).</p><p>Therefore, the Syn function prefers stories s that (a) have similar dependency structure to the origi- nal story s and (b) make use of a common syntactic configuration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Semantic Coherence</head><p>The semantic coherence component expresses how well a candidate s rewrites individual words and realizes the semantic relationships that exist in the human-authored story s. Ideally, we would like to preserve enough of the semantics of s in order to produce a coherent story s , yet we are populating s with words taken from an unrelated theme. There- fore, we model the semantics of a story s in terms of the lexical semantics contributed by individual words as well as semantic relationships that exist be- tween its elements. Note that the relationships can cross the sentence boundaries, promoting discourse coherence.</p><p>We decompose semantic relations in a story into a set of local, lexical relationships between pairs of words. Specifically, we consider semantic relations for noun-noun and verb-verb pairs as provided by WordNet <ref type="bibr" target="#b38">(Miller, 1995)</ref>. Since some relations are not directly outlined in these resources (e.g., the se- lectional preferences of nouns with regard to their adjectival modifiers), we also consider the word- embedding similarity between words. For example in <ref type="figure" target="#fig_2">Figure 2</ref> the semantic relationships are denoted with blue arrows between pairs of content words in the story (e.g., {Sam, dogs}, {dogs, puppies}, etc).</p><p>More formally, we define the semantic coherence of s with respect to s as:</p><formula xml:id="formula_6">Sem(s |s) = |s | i Sem Lex (w i , w i )<label>(5)</label></formula><formula xml:id="formula_7">+ i,j∈CW Sem P air ({w i , w j }, {w i , w j })</formula><p>where CW is the set of pairs of indices of content words (nouns, verbs, adjectives, and named entities) from s. We focus on the content words of the orig- inal problem, as they carry most of the semantic in- formation. Sem Lex and Sem P air functions are se- mantic adaptation scores for individual words and semantic relations respectively, described below. Semantic Compatibility between words (Sem Lex ) is defined as:</p><formula xml:id="formula_8">Sem Lex (w i , w i ) = cos(w i , w i ) + Resnik(w i , w i )<label>(6)</label></formula><p>where cos(w i , w i ) denotes the cosine similarity be- tween the vector space embeddings of two words w i and w i 4 , and Resnik(w i , w i ) expresses the informa- tion content of the lowest subsumer of {w i , w i } in WordNet. For example in <ref type="figure" target="#fig_2">Figure 2</ref>, the semantic compatibility score incorporates lexical similarities Sem Lex (dog, ship), etc.</p><p>Compatibility score between semantic relations (Sem P air ) is defined by adding two components: P airSim and Analogy that compute how seman- tic relations between pairs of words are preserved in the new story:</p><formula xml:id="formula_9">P airSim = cos(w i , w j ) * cos(w i , w j ) (7) Analogy = cos(w i + w j − w i , w j )<label>(8)</label></formula><p>P airSim preserves the similarity between pairs of words {w i , w j } in s and the corresponding pair {w i , w j } in the new story s . Intuitively, if w i and w j are semantically close to each other, we would like the corresponding words to be close in the new story as well. For example in <ref type="figure" target="#fig_2">Figure 2</ref>, 'dog' and 'puppy' are similar in the original story, we expect the cor- responding words 'ship' and 'droid' to be similar in the new story. The Analogy function, inspired by <ref type="bibr" target="#b37">Mikolov et al. (2013)</ref>, computes the analogy of w j from w i given the relationship that holds between w i and w j in the vector space. For example in <ref type="figure" target="#fig_2">Figure 2</ref>, the relation between 'Sam' and 'dog' is similar to the relation between 'Luke Skywalker' and 'ship'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Decoding</head><p>Our decoding process begins by first identifying the content words w i (nouns, verbs, adjectives and named entities) in the original problem s that will be considered as initial points for rewriting. For each of these lexical classes we extract the top-k most thematic words and trivial noun compounds from the theme t. For example, in <ref type="figure" target="#fig_2">Figure 2</ref>, candidate nouns are: 'ships', 'robots', 'droids', etc., and for verbs: 'blast', 'soar', 'command', etc. Recall that the space of candidate rewrites is large, prohibiting an exhaustive enumeration. We therefore do approx- imate search with a beam by considering simultane- ously all possible paths that start at the different ini- tial points. At each step the decoder considers an additional rewrite from the list of candidates, adds it to the existing hypothesis path, and scores it accord- ing to function R (Equation 2).</p><p>All the counterpart scores are locally optimal, as they factor over each new word w i or pair of {w i , w j }, where w j is a rewrite already existing in the hypothesis path. At any given step we may re- combine hypotheses that share the same prefix hy- pothesis path, and keep the top scoring one. The process terminates when there are no more rewrites left. We also experimented decoding with a variety of orderings of the text in the original problem s, including left-to-right, and head-first following the dependency tree of each sentence and then concate- nating these linearizations; we observed that consid- ering multiple paths achieves the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Data Collection</head><p>For the set of human-authored stories {s}, we use a corpus of math word problems described in <ref type="bibr">KoncelKedziorski et al. (2016)</ref>. We select a subset of 150 problems targeting 5th and 6th grade levels, all of which involve a single equation in one variable. These problems have 2.7 sentences and 29.4 words on average, 12.6 of which are considered content words by our system. In order to tune and evaluate our model, we collect a corpus of human-authored rewrites produced by workers from Amazon Me- chanical Turk based on two themes: Star Wars, and Adventure Time (a children's cartoon).</p><p>We experimented with different ways of helping to define the theme for the workers, including of- fering automatically generated word clouds or en- forcing that a response includes one of several key- words. In practice, we have found that using specific cultural elements as themes (such as famous movie or cartoon franchises) attracts workers who already have a strong knowledge of the theme, resulting in higher quality work.</p><p>To help explain the rewriting process, we show workers three examples of thematic rewrites with varying degrees of correlation to the original prob- lems. We then show workers a random problem from the original set {s} and a corresponding equa- tion for that problem. We instruct the workers to "rewrite" the problem according to the theme, en- suring that their rewritten problem can be solved by the provided equation. The final dataset collection comprises of 450 human-authored rewrites. We col- lect 3 rewrites for 100 of the original problems for the Star Wars theme (based on the popular Star Wars sequel movies), and 3 rewrites for the rest of the 50 original problems, for the Children Cartoons Theme (CARTOON), based on the Adventure Time TV show. We keep 150 examples from the Star Wars theme for development (STAR dev ), and the rest 150 for testing (STAR test ).</p><p>We collected the STAR dev and CARTOON data based on workers with the "master" designation and at least 95% approval rating. Then we pro- ceeded collecting STAR test by a subset of the authors of STAR dev who self-identify as theme experts and whose quality of work is manually confirmed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Setup</head><p>Implementation Details We pre-process the themes using the Stanford CoreNLP tools ) for tokenization, Named Entity Recognition ( <ref type="bibr" target="#b10">Finkel et al., 2005</ref>), and dependency parsing <ref type="bibr" target="#b4">(Chen and Manning, 2014</ref>). For calculating salience scores, we use the ScriptBase dataset of movie scripts <ref type="bibr" target="#b14">(Gorinski and Lapata, 2015)</ref>. The Star Wars theme is constructed from the available script, roughly 7300 words. The Cartoon theme is constructed from fan-authored scripts of the first 10 episodes of the show (Springfield, 2016) totaling 1370 words. Since our thematic options are taken from arbitrary text, we use the lists of offensive terms published by The Racial Slur database <ref type="bibr">(Database, 2016)</ref> and FrontGate Media <ref type="bibr" target="#b35">(Media, 2016)</ref> to filter out offensive content. To prohibit overgeneration, we forbid the transformation of stop words or math-specific words <ref type="bibr">(Survivors, 2013;</ref><ref type="bibr" target="#b24">Koncel-Kedziorski et al., 2015b</ref>).</p><p>For syntactic compatibility score Syn (Equa- tion 4) we use the English Fiction subset of the Google Syntactic N-grams corpus (Goldberg and Orwant, 2013) and train a 3-gram language model using KenLM <ref type="bibr" target="#b17">(Heafield, 2011)</ref>. For Sem Lex , P airSim and Analogy (Equations 6-8) we use the pretrained word embeddings of <ref type="bibr" target="#b29">Levy and Goldberg (2014)</ref>. These embeddings are trained using dependency contexts rather than windows of ad- jacent words, allowing them to capture functional word similarity. Finally, we tune the parameters of our model (Equation 2) on the development set STAR dev and pick those values 5 that maximize ME- TEOR score <ref type="bibr" target="#b7">(Denkowski and Lavie, 2014</ref>) against 3 human references.</p><p>Evaluation We compare two ablated configura- tions of our method against our full model (FULL): -SYN that only uses semantic and thematicity com- ponents and does not incorporate the syntactic com- patibility score, -SEM replaces the semantic coher- ence score with the simpler cos(w i , w i ), effectively rewriting only single words, and not pairs. We re- frained from ablating the thematicity score as it is the core part of our model that drives the rewriting process into a new theme.</p><p>We evaluate our method using an automatic met- ric, and via eliciting human judgments on Ama- zon Mechanical Turk. For automatic evaluation, we compute the METEOR score, comparing the out- put of each model for a given problem and theme to the 3 human rewrites we collected, on STAR dev , STAR test and CARTOON. METEOR is a recall- oriented metric, widely used in the MT community; the additional stemming, synonym and paraphrase matching modules make it more applicable for our use, given the nature of our rewriting task. <ref type="bibr">6</ref> For human evaluation, we conduct pairwise com- parison tests, pairing FULL against a human rewrite (HUMAN), FULL against -SYN, and FULL against -SEM. Participants were given a short description of the theme, and the output of each system. For each test we asked 40 subjects to select which prob- lem they preferred over 5 pairs of outputs; we ob- tained a total of 200 (5x40) responses for STAR test and CARTOON.</p><p>In order to better understand the strengths and weaknesses of the generated stories, we conducted a more detailed human evaluation. 8 participants were presented with the output of the three automatic sys- tems, human rewrites (HUMAN), and a theme. The participants were asked to rate the stories across three dimensions: coherence (how coherent is the text of the problem?), solvability (can elementary school students solve it?), and thematicity (how well does the problem express them?) on a scale from 1 to 5. We collected ratings over 16 outputs from <ref type="bibr">6</ref> The average METEOR score comparing 1 annotator against the other 2 is 0.26, indicating that there are diverse cor- rect strategies for solving the rewriting problem.   STAR test , resulting in 128 responses.  <ref type="table" target="#tab_3">Table 3</ref> shows the results of the detailed com- parison of Thematicity, Coherence, and Solvability. This table clearly shows the strong contribution of the semantic component of our system. The specific contribution of the syntactic component is to pro-Star Wars s 1 . Wendy bought 4 new chairs and 4 new tables for her house. If she spent 6 minutes on each piece fur- niture putting it together, how may minutes did it take her to finish? s 1 . Leia bought 4 new ships and 4 new guns for her room. If she spent 6 minutes on each wasteland weapon putting it together, how many minutes did it take her to terminate?  duce overall more solvable and thematically satisfy- ing problems, although it can slightly affect coher- ence especially when automatic parses fail. Finally, the overall high ratings for human-authored stories across all three dimensions, confirm the high quality of the crowd-sourced stories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Qualitative Examples</head><p>Table 4-6 shows some problems generated by our method. Recall that since our system needs no an- notated thematic training data, we can easily gen- erate from any theme where thematic text is avail- able. To demonstrate this fact, we include gener- ated examples in a Western theme from novels from the Project Gutenberg corpus. Many of the results of our system are very legible, with only minor agreement errors. Coherent, thematic semantic re- lations are evident in problems such as s 1 , where ships, guns, and weapons combine to effect the Star Wars theme; this is also evident in s 5 , where people with western sounding names like Kurt and Made- line trade in cigarettes, an old-fashioned pre-cursor to e-cigarettes.</p><p>In some cases, semantic inconsistencies result in weird sounding problems, such as in s 6 where the main character receives "wheat of grub". But be- cause of the syntactic compatibility component, our model scores this candidate higher because of the Cartoon s 7 . Dave was helping the cafeteria workers pick up lunch trays, but he could only carry 9 trays at a time <ref type="table" target="#tab_4">.  If he had to pick up 17 trays from one table and 55</ref> trays from another, how many trips will he make? s 7 . Finn was helping the cupboard men pick up candy bottles, but he could only carry 9 bottles at a time. If he had to pick up 17 bottles from one ring and 55 bottles from another, how many swords will he make?  connection between "wheat" and "graze". Semantic incoherence is less of a problem in the cartoon theme, where absurd interactions between characters are expected. However, a difficulty for our system is demonstrated in s 7 , where the physical entity "swords" is substituted for the nominalization of an event "trips". Improvements to the semantic coherence component could resolve such issues. <ref type="table">Table 7</ref> shows some instances where the rewrite algorithm produces unusable results. An example of under-generation is s 10 . Here, too many words are left untouched, resulting in both ungrammatical- ity and semantic incoherence. In s 11 , we witness some limitations of using word vectors. The rare word "Ferris" is not close to anything in the Star Wars theme, and is thus mapped almost arbitrarily to "int" (movie script shorthand for an interior shot). Better treatment of noun compounds and the use of phrase vectors would reduce such errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We formalized the problem of story rewriting as au- tomatically changing the theme of a text without Western s 4 . Christians father and the senior ranger gathered firewood as they walked towards the lake in the park ... s 4 . Christian 's partner and the lone sheriff harvested barley as they strolled towards the hip in the orchard ...  altering the underlying story and developed an ap- proach for rewriting algebra word problems where the rewriting model optimized for a number of mea- sures of overall text coherence. Experiments on a newly gathered dataset demonstrated our model can produce themed texts that are usually solvable. Future work could improve the thematicity and solvability components by incorporating domain- specific and commonsense knowledge, leveraging information extraction. Additionally, neural net- work architectures (e.g., LSTMs, seq2seq) can be trained to rewrite coherently with less reliance on brittle syntactic parses. Additionally, we plan to study rewriting in other domains such as children's short stories and extend the model to generate math word problems directly from equations. Finally, we intend to incorporate the generated problems in ed- ucational technology and tutoring systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Jim walked 0.2 of a mile from school to David's house and 0.7 of a mile from David's house to his own house. How many miles did Jim walk in all? Star Wars Uncle Owen walked 0.2 of a mile from hangar to Luke Skywalker's room and 0.7 of a mile from Luke Sky- walker's room to his own room. How many miles did Uncle Owen walk in all? Cartoon Finn squished 0.2 of a mile from cupboard to Melissa's dock and 0.7 of a mile from Melissa's dock to his own dock. How many miles did Finn squish in all? Western Duane strolled 0.2 of a mile from barn to Madeline's camp and 0.7 of a mile from Madeline's camp to his own camp. How many miles did Duane stroll in all?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example story and rewrites in 3 themes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An overview of our method for scoring a candidate story s given a human-authored story s and a theme t. Syn(s |s): compatibility of syntactic relations (purple arrows), Sem pair (s |s): coherence of semantic relations (blue arrows), Sem Lex (s |s): semantic mapping of individual words, and T h(s |s, t): thematicity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Human evaluation results on pairwise compar-
isons between FULL and -SYN, and FULL and HUMAN, 
on STAR test and CARTOON datasets. 

Model Thematicity Coherence Solvability 

HUMAN 

3.7 
3.175 
4.025 

FULL 

3.7 
3.025 
3.9 

-SYN 

3.375 
3.075 
3.825 

-SEM 

3.325 
2.65 
3.7 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Human evaluation results for FULL, -SYN, 
-SEMand HUMAN on thematicity, coherence and solv-
ability on STAR test . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 1 reports</head><label>1</label><figDesc></figDesc><table>METEOR; we notice that removing 
the semantic coherence scores in -SEM hurts the per-
formance compared to FULL; this confirms our claim 
that semantic compatibility is crucial for building 
coherent stories. On the other hand, -SYN performs 
similarly to FULL. Closer inspection of the -SYN sys-
tem's output reveals a greater diversity in thematic 
elements as a result of the relaxed syntactic compat-
ibility constraints. Hence it is more likely to have 
greater overlap with any of the reference rewrites, 
resulting in higher METEOR scores. 
However, a pairwise comparison between 
FULL and -SYN (Table 2) reveals that human sub-
jects consistently prefer the output of FULL instead 
of -SYN both for STAR test and CARTOON. Table 2 
also reports that HUMAN outperforms the output 
of the FULL model, and a pairwise comparison of 
FULL and -SEM which yields a result in line with the 
METEOR scores. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>s 2 .</head><label>2</label><figDesc></figDesc><table>My car gets 20 miles per gallon of gas. How many 
miles can I drive on 5 gallons of gas? 
s 
2 . My cruiser gets 20 miles per gallon of light. How 
many miles can I drive on 5 gallons of light? 

s 3 .Tyler had 15 dogs. Each dog had 5 puppies. How 
many puppies does Tyler now have? 
s 
3 . Biggs had 15 creatures. Each creature had 5 crea-
tures. How many creatures does Biggs now have? 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Examples of the original stories s i and rewritten 
math word problems s 
i in Star War theme. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>s 8 .</head><label>8</label><figDesc></figDesc><table>If books came from all the 4 continents that Bryan 
had been into and he collected 122 books per conti-
nent, how many books does he have from all 4 conti-
nents combined? 
s 
8 . If dances came from all the 4 mountains that Finn 
had been into and he collected 122 dances per moun-
tain, how many dances does he have from all 4 moun-
tains combined? 

s 9 . A bucket contains 3 gallons of water. If Derek 
adds 6.8 gallons more, how many gallons will there 
be in all? 
s 
9 . A bottle makes 3 gallons of serum. If Finn adds 
6.8 gallons more, how many gallons will there be in 
all? 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Examples of the original stories s i and rewritten 
math word problems s 
i in Cartoon theme. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>s 5 .</head><label>5</label><figDesc></figDesc><table>Sally had 27 cards. Dan gave her 41 new cards. 
Sally bought 20 cards. How many cards does Sally 
have now? 
s 
5 . Madeline had 27 cigarettes. Kurt gave her 41 new 
cigarettes. Madeline bought 20 cigarettes. How many 
cigarettes does madeline have now? 

s 6 . For Halloween Megan received 11 pieces of candy 
from neighbors and 5 pieces from her older sister. If 
she only ate 8 pieces a day, how long would the candy 
last her? 
s 
6 . For Halloween Madeline received 11 wheat of 
grub from proprietors and 5 wheat from her nameless 
partner. If she only grazed 8 wheat a day, how long 
would the grub last her? 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Examples of the original stories s i and rewritten 
math word problems s 
i in Western theme. 

</table></figure>

			<note place="foot" n="1"> Data and code available at https://gitlab.cs. washington.edu/kedzior/Rewriter/.</note>

			<note place="foot" n="2"> According to Polozov et al. (2015) building small thematic ontologies of types, relations, and discourse tropes (100-200 entries) for each of only 3 literary settings took 1-2 person months.</note>

			<note place="foot" n="3"> We will be interchangeably referring to w as either the word or the head of the multi-word noun compound that rewrites the equivalent word w in the original problem.</note>

			<note place="foot" n="4"> For the ease of notation, we represent the embedding of the words with wi as well.</note>

			<note place="foot" n="5"> We set α = 0.1, β = 0.1 and γ = 1</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the NSF (IIS 1616112), Allen Institute for AI (66-9175), Allen Distinguished Investigator Award, DARPA (FA8750-13-2-0008) and a Google research faculty</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Planning algorithms for interactive storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leandro</forename><surname>Motta Barros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soraia Raupp Musse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Entertainment (CIE)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Expanding teacher work roles: a resource for retention or a recipe for overwork?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lora</forename><surname>Bartlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Education Policy</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="565" to="582" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Narrative Schemas and Their Participants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="602" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Collecting highly parallel data for paraphrase evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A fast and accurate dependency parser using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="740" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The Racial Slur Database. 2016. The racial slur database</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The role of rewording and context personalization in the solving of mathematical word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Davis-Dorsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary R</forename><surname>Steven M Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Morrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">61</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Meteor Universal: Language Specific Translation Evaluation for 1625</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Any Target Language</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EACL 2014 Workshop on Statistical Machine Translation</title>
		<meeting>the EACL 2014 Workshop on Statistical Machine Translation</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dependency tree based sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Filippova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Natural Language Generation Conference (INLG))</title>
		<meeting>the Fifth International Natural Language Generation Conference (INLG))</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">PPDB: The paraphrase database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="758" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Dataset of syntactic-Ngrams over Time from a Very Large Corpus of English Books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Orwant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second Joint Conference on Lexical and Computational Semantics (* SEM)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="241" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Movie script summarization as graph-based scene extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Gorinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">What happens next? event prediction using a compositional neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Granroth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Wilding</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI-16)</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence (AAAI-16)<address><addrLine>Phoenix, Arizona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Effect of Personalized Word Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janis M</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Teaching Children Mathematics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="504" to="505" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">KenLM: Faster and smaller language model queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation, WMT &apos;11</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation, WMT &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="187" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning to Solve Arithmetic Word Problems with Verb Categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad Javad</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="523" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">How well do computers solve math word probl ems? large-scale dataset construction and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<title level="m">North American Chapter of the ACL (NAACL HLT)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Aligning Sentences from Standard Wikipedia to Simple Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improving text simplification language modeling using unsimplified text data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kauchak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Conference of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<title level="m">Ashish Sabharwal, Oren Etzioni, and Siena Ang. 2015a. Parsing Algebraic Word Problems into Equations. TACL</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Parsing algebraic word problems into equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siena</forename><surname>Ang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="585" to="597" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">MAWPS: A Math Word Problem Repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aida</forename><surname>Aimini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to Automatically Solve Algebra Word Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="271" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Fast and Portable Realizer for Text Generation Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Lavoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth conference on Applied natural language processing</title>
		<meeting>the fifth conference on Applied natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="265" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Planning Stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lebowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the cognitive science society</title>
		<meeting>the cognitive science society<address><addrLine>Hillsdale</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="234" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">DependencyBased Word Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Story generation with crowdsourced plot graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lee-Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">O</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI Conferece on Artificial Intelligence (AAAI)</title>
		<meeting>AAAI Conferece on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">MAKEBELIEVE: Using Commonsense Knowledge to Generate Stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Push</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI/IAAI</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="957" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association for Computational Linguistics: System Demonstrations (ACL)</title>
		<meeting>the Conference of the Association for Computational Linguistics: System Demonstrations (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning to Tell Tales: A Data-driven Approach to Story Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Mcintyre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="217" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Plot Induction and Evolutionary Search for Story Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Mcintyre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1562" to="1572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Terms to block</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frontgate</forename><surname>Media</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Richard Meehan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Metanovel: Writing Stories by Computer</title>
		<imprint>
			<date type="published" when="1976" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">WordNet: A Lexical Database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning to automatically solve logic grid puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Baral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A corpus and evaluation framework for deeper understanding of commonsense stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<title level="m">North American Chapter of the ACL (NAACL HLT)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Text simplification for langauge learners: A corpus analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Speech and Language Technology in Education Workshop (SLaTE)</title>
		<meeting>the Speech and Language Technology in Education Workshop (SLaTE)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning statistical scripts with LSTM recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pichotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney ; Oleksandr Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleanor</forename><surname>Orourke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoran</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Popovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI</title>
		<meeting>the 24th International Joint Conference on Artificial Intelligence (IJCAI<address><addrLine>Phoenix, Arizona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI-16). To appear</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Individual interest as context in expository text and mathematical word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Renninger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Ewen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lasher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning and Instruction</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="490" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Solving General Arithmetic Word Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Equation parsing : Mapping sentences to grounded equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A neural attention model for abstractive sentence summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Alexander M Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Scripts, Plans, Goals, and Understanding: An Inquiry into Human Knowledge Structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert P Abelson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Lawrence Erlbaum</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Diagram Understanding in Geometry Questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min Joon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Solving Geometry Problems: Combining Text and Diagram Interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clint</forename><surname>Malcolm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Automatically Solving Number Word Problems by Semantic Parsing and Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuehui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Rui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Syntactic simplification and text cohesion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research on Language and Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="109" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Adventure time with finn &amp; jake episode scripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springfield</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Key words for math problems</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Ladder Survivors</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Minstrel: A Computer Model of Creativity and Storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scott R Turner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Beyond sumbasic: Task-focused summarization with sentence simplification and lexical expansion. Information Processing and Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisami</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Sentence simplification for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vickrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Conference of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="344" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning to simplify sentences with quasi-synchronous grammar and integer programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Woodsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Wikisimple: Automatic simplification of wikipedia articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Woodsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Advancement of Artificial Intelligence Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the Association for Advancement of Artificial Intelligence Conference on Artificial Intelligence (AAAI)<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="927" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Antal Van Den Bosch, and Emiel Krahmer. 2012. Sentence simplification by monolingual machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Wubben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Conference of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<biblScope unit="page" from="1015" to="1024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Optimizing statistical machine translation for text simplification. Transactions of Association of Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanze</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">For the sake of simplicity: Unsupervised extraction of lexical simplifications from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescumizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Learn to Solve Algebra Word Problems Using Quadratic Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lipu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuaixiang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A monolingual tree-based translation model for sentence simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhemin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delphine</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics (COLING)</title>
		<meeting>the International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
