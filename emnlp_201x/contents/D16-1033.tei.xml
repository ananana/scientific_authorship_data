<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Dataset and Evaluation Metrics for Abstractive Compression of Sentences and Short Paragraphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Redmond</orgName>
								<address>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Redmond</orgName>
								<address>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><forename type="middle">M</forename><surname>Tran</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Amsterdam Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saleema</forename><surname>Amershi</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Microsoft Research Redmond</orgName>
								<address>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Dataset and Evaluation Metrics for Abstractive Compression of Sentences and Short Paragraphs</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="340" to="350"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce a manually-created, multi-reference dataset for abstractive sentence and short paragraph compression. First, we examine the impact of single-and multi-sentence level editing operations on human compression quality as found in this corpus. We observe that substitution and rephrasing operations are more meaning preserving than other operations, and that compressing in context improves quality. Second, we systematically explore the correlations between automatic evaluation metrics and human judgments of meaning preservation and grammaticality in the compression task, and analyze the impact of the linguistic units used and precision versus recall measures on the quality of the met-rics. Multi-reference evaluation metrics are shown to offer significant advantage over single reference-based metrics.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automated sentence compression condenses a sen- tence or paragraph to its most important content in order to enhance writing quality, meet document length constraints, and build more accurate docu- ment summarization systems <ref type="bibr" target="#b1">(Berg-Kirkpatrick et al., 2011;</ref><ref type="bibr" target="#b28">Vanderwende et al., 2007)</ref>. Though word deletion is extensively used (e.g., <ref type="bibr" target="#b5">(Clarke and Lapata, 2008)</ref>), state-of-the-art compression models <ref type="bibr" target="#b8">(Cohn and Lapata, 2008;</ref><ref type="bibr" target="#b26">Rush et al., 2015</ref>) bene- fit crucially from data that can represent complex abstractive compression operations, including sub- stitution of words and phrases and reordering. This paper has two parts. In the first half, we in- troduce a manually-created multi-reference dataset for abstractive compression of sentences and short paragraphs, with the following features:</p><p>• It contains approximately 6,000 source texts with multiple compressions (about 26,000 pairs of source and compressed texts), representing business letters, newswire, journals, and tech- nical documents sampled from the Open Amer- ican National Corpus (OANC 1 ).</p><p>• Each source text is accompanied by up to five crowd-sourced rewrites constrained to a preset compression ratio and annotated with quality judgments. Multiple rewrites permit study of the impact of operations on human compres- sion quality and facilitate automatic evaluation.</p><p>• This dataset is the first to provide compressions at the multi-sentence (two-sentence paragraph) level, which may present a stepping stone to whole document summarization. Many of these two-sentence paragraphs are compressed both as paragraphs and separately sentence-by- sentence, offering data that may yield insights into the impact of multi-sentence operations on human compression quality.</p><p>• A detailed edit history is provided that may allow fine-grained alignment of original and compressed texts and measurement of the cog- nitive load of different rewrite operations.</p><p>Our analysis of this dataset reveals that abstrac- tion has a significant positive impact on meaning preservation, and that application of trans-sentential context has a significant positive impact on both meaning preservation and grammaticality.</p><p>In the second part, we provide a systematic em- pirical study of eighty automatic evaluation met- rics for text compression using this dataset, corre- lating them with human judgments of meaning and grammar. Our study shows strong correlation of the best metrics with human judgments of meaning, but weaker correlations with judgments of grammar. We demonstrate significant gains from multiple refer- ences. We also provide analyses of the impact of the linguistics units used (surface n-grams of differ- ent sizes versus parse-based triples), and the use of precision versus recall-based measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Prior studies of human compression: Clarke (2008) studied the properties of manually-collected deletion-based compressions in the news genre, comparing them with automatically-mined data from the Ziff-Davis corpus in terms of compression rate, length of deleted spans, and deletion probabil- ity by syntactic constituent type. <ref type="bibr" target="#b17">Jing and McKeown (1999)</ref> identified abstractive operations (other than word deletion) employed by professional writers, in- cluding paraphrasing and re-ordering of phrases, and merging and reordering sentences, but did not quan- tify their impact on compression quality.</p><p>Deletion-based compression corpora: Currently available automatically-mined deletion corpora are single-reference and have varying (uncontrolled) compression rates. <ref type="bibr" target="#b20">Knight and Marcu (2002)</ref> auto- matically mined a small parallel corpus (1,035 train- ing and 32 test sentences) by aligning abstracts to sentences in articles. <ref type="bibr" target="#b9">Filippova and Altun (2013)</ref> extracted deletion-based compressions by aligning news headlines to first sentences, yielding a corpus of 250,000 parallel sentences. The same approach was used by <ref type="bibr" target="#b10">Filippova et al. (2015)</ref> to create a set of 2M sentence pairs. Only a subset of 10,000 parallel sentences from the latter has been publicly released. <ref type="bibr" target="#b4">Clarke and Lapata (2006)</ref> and <ref type="bibr" target="#b5">Clarke and Lapata (2008)</ref> provide two manually-created two-reference corpora for deletion-based compression: 2 their sizes are 1,370 and 1,433 sentences, respectively.</p><p>Abstractive compression corpora: <ref type="bibr" target="#b26">Rush et al. (2015)</ref> have mined 4 million compression pairs from news articles and released their code to extract data from the Annotated Gigaword ( <ref type="bibr" target="#b23">Napoles et al., 2012)</ref>. A news-domain parallel sentence corpus containing 1,496 parallel examples has been culled from multi- reference Chinese-English translations by <ref type="bibr" target="#b12">Ganitkevitch et al. (2011)</ref>. The only publicly-available manually-created abstractive compression corpus is that described by <ref type="bibr" target="#b8">Cohn and Lapata (2008)</ref>, which comprises 575 single-reference sentence pairs.</p><p>Automatic metrics: Early automatic metrics for evaluation of compressions include success rate <ref type="bibr" target="#b18">(Jing, 2000</ref>), defined as accuracy of individual word or constituent deletion decisions; Simple String Ac- curacy (string edit distance), introduced by Banga- lore et al. <ref type="formula">(2000)</ref> for natural language generation tasks; and Word Accuracy ( <ref type="bibr" target="#b3">Chiori and Furui, 2004</ref>), which generalizes <ref type="bibr" target="#b0">Bangalore et al. (2000)</ref> to multi- ple references. <ref type="bibr" target="#b25">Riezler et al. (2003)</ref> introduced the use of F-measure over grammatical relations. Word unigram and word-bigram F-measure have also been used ( <ref type="bibr" target="#b27">Unno et al., 2006;</ref><ref type="bibr" target="#b10">Filippova et al., 2015)</ref>. Vari- ants of ROUGE <ref type="bibr" target="#b21">(Lin, 2004)</ref>, used for summarization evaluation, have also been applied to sentence com- pressions ( <ref type="bibr" target="#b26">Rush et al., 2015)</ref>. <ref type="bibr" target="#b25">Riezler et al. (2003)</ref> show that F-measure over grammatical relations agrees with human ratings on the relative ranking of three systems at the corpus level. <ref type="bibr" target="#b4">Clarke and Lapata (2006)</ref> evaluate two deletion-based automatic compression systems against a deletion-based gold-standard on sets of 20 sentences. Parse-based F-1 was shown to have high sentence-level Pearson's ρ correlation with human judgments of overall quality, and to have higher ρ than Simple String Accuracy.  have pointed to the need of multiple references and studies of evaluation met- rics. For the related tasks of document and multi- document summarization, Graham (2015) provides a fine-grained comparison of automated evaluation methods. However, to the best of our knowledge, no studies of automatic evaluation metrics exist for abstractive compression of shorter texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Length</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text</head><p>Operations 1-Sent Source Think of all the ways everyone in your household will benefit from your membership N/A in Audubon. Ref-1</p><p>Imagine how your household will benefit from your Audubon membership. paraphrase + deletion + transformation Ref-2 Everyone in your household will benefit from membership in Audubon. deletion 2-Sent Source Will the administration live up to its environmental promises? Can we save the last of N/A our ancient forests from the chainsaw? Ref-1</p><p>Can the administration keep its promises? Can we save the last of our forests from loss? two-sentences + deletion + paraphrase Ref-2</p><p>Will the administration live up to its environmental promises to save our ancient forests? merge + deletion  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset: Annotation and Properties</head><p>We sampled single sentences and two-sentence para- graphs from several genres in the written text section of the Manually Annotated Sub-Corpus (MASC) ( <ref type="bibr" target="#b15">Ide et al., 2008;</ref><ref type="bibr" target="#b16">Ide et al., 2010</ref>) of the Open Amer- ican National Corpus (OANC), supplemented by ad- ditional data from the written section of OANC. Two-sentence paragraphs account for approximately 23% of multi-sentence paragraphs in the OANC.</p><p>The two-sentence paragraphs we sampled contain at least 25 words. <ref type="table" target="#tab_1">Table 2</ref> breaks the sampled texts down by genre. Non-news genres are better repre- sented in our sample than the newswire typically used in compression tasks. The Letters examples are expected to be useful for learning to compress emails. The Journal texts are likely to be challeng- ing as their purpose is often more than to convey in- formation. The Non-Fiction collection includes ma- terial from technical academic publications, such as PLoS Medicine, an open access journal. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Annotation</head><p>Compressions were created using UHRS, an in- house crowd-sourcing system similar to Amazon's Mechanical Turk, in two annotation rounds, one for shortening and a second to rate compression quality.</p><p>Generating compressions: In the first round, we asked five workers (editors) to abridge each source text by at least 25%, while remaining grammatical and fluent, and retaining the meaning of the orig- inal. This requirement was enforced programmat- 3 http://journals.plos.org/plosmedicine/ ically on the basis of character count. The 25% rate is intended to reflect practical editing scenarios (e.g., shrink 8 pages to 6). To facilitate meeting this requirement, the minimum source text length pre- sented to editors was 15 words. For a subset of para- graphs, we collected compressions both as indepen- dent rewrites of their component sentences, and of the paragraph as a whole. <ref type="table" target="#tab_0">Table 1</ref> show compres- sion examples and strategies.</p><p>Evaluating compression quality: In the second round, we asked 3-5 judges (raters) to evaluate the grammaticality of each compression on a scale from 1 (major errors, disfluent) through 3 (fluent), and again analogously for meaning preservation on a scale from 1 (orthogonal) through 3 (most impor- tant meaning-preserving). <ref type="bibr">4</ref> We later used the same process to evaluate compressions produced by auto- matic systems. The full guidelines for the editors and raters are available with the data release.</p><p>Quality controls: All editors and raters were based in the US, and the raters were required to pass a qualification test which asked them to rate the meaning and grammaticality for a set of examples with known answers. To further improve the qual- ity of the data, we removed low-quality compres- sions. We computed the quality of each compression as the average of the grammar and meaning quality as judged by the raters. We then computed the mean quality for each editor, and removed compressions authored by the bottom 10% of editors. We did the same for the bottom 10% of the raters.   <ref type="table" target="#tab_3">Table 3</ref> shows the number of compressions in the cleaned dataset, as well as the average number of compressions per source text (CPS) and the average meaning and grammar scores. Meaning quality and grammaticality scores are relatively good, averag- ing 2.78 and 2.82 respectively. The filtered crowd- sourced compressions were most frequently judged to retain the most important meaning (80% of the time), or much of the meaning (17% of the time), with the lowest rating of 1 appearing only 3% of the time. This distribution is quite different from that of automatic compression systems in Section 4.</p><p>We provide a standard split of the data into train- ing, development and test sets. <ref type="bibr">6</ref> There are 4,936 source texts in the training, 448 in the development, and 785 in the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Inter-Annotator Agreement</head><p>Crowd Workers: Since a different set of judges performs each task, large sets of inputs judged by the same two raters are unavailable. To simulate two raters, we follow <ref type="bibr" target="#b24">Pavlick and Tetrault (2016)</ref>: for each sentence, we randomly choose one anno- tator's output as the category for annotator A, and select the rounded average ranking for the remain- ing annotators as the category for annotator B. We then compute quadratic weighted κ <ref type="bibr" target="#b7">(Cohen, 1968)</ref> for this pair over the whole corpus. We repeat the process 1000 times to compute the mean and vari- ance of κ. The first row of the <ref type="table" target="#tab_5">Table 4</ref> reports the absolute agreement and κ, where the absolute agree- ment measures the fraction of times that A is equal to B. The 95% confidence intervals for κ are narrow, with width at most .01.  Expert Raters: A small sample of 116 sentence pairs was rated by two expert judges. We used quadratic weighted κ directly, without sampling. To assess agreement between experts and non-experts, we computed weighted κ between the (rounded) av- erage of the expert judgments and the (rounded) av- erage of the crowd judgments, using 25,000 boot- strap replications each. The results are shown in the last two rows of <ref type="table" target="#tab_5">Table 4</ref>. The confidence intervals for κ are wide due to the small sample size, and span values up to .17 away from the mean. Over- all, agreement of experts with the average crowd- sourced ratings is moderate (approaching substan- tial) for meaning, and fair for grammar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis of Editing Operations</head><p>Frequency analysis: To analyze the editing oper- ations used, we applied the state-of-the-art monolin- gual aligner Jacana ( <ref type="bibr" target="#b32">Yao et al., 2013)</ref> to align input to compressed texts. Out of the 26,423 compres- sions collected, 25.2% contained only token dele- tions. Those containing deletion and reordering amounted to a mere 9.1%, while those that also con- tain substitution or rephrasing (abstractive compres- sions) is 65.6%. Although abstraction is present in the large majority of compressions, these statistics do not indicate that paraphrasing is more prevalent than copying at the token level. The word align- ments for target compression words indicate that 7.1% of target tokens were inserted, 75.4% were copied and 17.3% were paraphrased. From the alignments for source text words, we see that 31% of source words were deleted. The fraction of inserted and deleted words is probably overestimated by this approach, as it is likely that sequences of source words were abstracted as shorter sequences of target words in many-to-one or many-to-many alignment patterns that are difficult to detect automatically. For the subset of examples where the input text   contained more than one sentence, we computed the frequency of sentence-merging and sentence dele- tion when compressing. Of the compressions for two-sentence paragraphs, 72.4% had two sentences in the output, 0.4% had one sentence deleted, and 27.3% had the two source sentences merged.</p><p>Impact of operations: Because the dataset con- tains multiple compressions of the same sources, we are able to estimate the impact of different editing operations. These were classified using the Jacana word alignment tool. <ref type="table" target="#tab_2">Table 5</ref> presents the average judgment scores for meaning preservation and gram- maticality for four operations. The upper two rows apply to all texts, the lower two to two-sentence paragraphs only. The statistical significance of their impact was tested using the Wilcoxon signed-rank test on paired observations. It appears that raters view compressions that involve substitutions as sig- nificantly more meaning-preserving than those that do not (p &lt; 0.0001), but judge their grammatical- ity to be lower than that of deletion-based compres- sions. Note that the reduced grammaticality may be due to typographical errors that have been in- troduced during rephrasing, which could have been avoided had a more powerful word processor been used as an editing platform. Reordering has no sig- nificant impact on meaning, but leads to substantial degradation in grammatically. Conversely, abridg- ments that merge or delete sentences are rated as sig- nificantly less meaning preserving, but score higher for grammaticality, possibly reflecting greater skill on the part of those editors.. Impact of sentence context: <ref type="table" target="#tab_8">Table 6</ref> shows that the context provided by 2-sentence sources yields significantly improved scores for both meaning and grammaticality. Here we used the matched pairs de- sign to compare the average quality of two-sentence paragraph compressions with the average quality of the compressions of the same paragraphs produced by separately compressing the two sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluating Evaluation Metrics</head><p>Progress in automated text compression is stan- dardly measured by comparing model outputs at the corpus level. To train models discriminatively and to perform fine-grained system comparisons, how- ever, it is also necessary to have evaluation of sys- tem outputs at the individual input level. Below, we examine automated metric correlation with human judgments at both levels of granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Automatic Metrics</head><p>The goal of this analysis is to develop an under- standing of the performance of automatic evalua- tion metrics for text compression, and the factors contributing to their performance. To this end, we group automatic metrics according to three crite- ria. The first is the linguistic units used to compare system and reference compressions. Prior work on compression evaluation has indicated that a parse- based metric is superior to one based on surface sub- strings ( <ref type="bibr" target="#b4">Clarke and Lapata, 2006</ref>), but the contribu- tion of the linguistic units has not been isolated, and surface n-gram units have otherwise been success- fully used for evaluation in related tasks <ref type="bibr" target="#b14">(Graham, 2015)</ref>. Accordingly, we empirically compare met- rics based on surface uni-grams (LR-1), bi-grams (LR-2), tri-grams (LR-3), and four-grams (LR-4), as well skip bi-grams (with a maximum of four inter- vening words as in ROUGE-S4) (SKIP-2), and de- pendency tree triples obtained from collapsed de- pendencies output from the Stanford parser (PARSE- 2). <ref type="bibr">7</ref> The second criterion is the scoring measure used to evaluate the match between two sets of lin- guistic units corresponding to a system output and a reference compression. We compare Precision, Re- call, F-measure, and Precision+Brevity penalty (as in BLEU). The third criterion is whether multiple references or a single reference is used, and in the case of multiple references, the method used to ag- gregate information from multiple references. We investigate two previously applied methods and in- troduce a novel approach that often outperforms the standard methods. To illustrate, we introduce some notation and use a simple example. Consider a sub-phrase of one of the sentences in <ref type="table" target="#tab_0">Table 1</ref>, think about your household, as an input text to compress. Let us assume that we have two reference compressions, R1: imagine your household, and R2: your household. Each metric m is a function from a pair of a system output o and a list of references r 1 , r 2 , . . . , r k to the reals. To com- pute most metrics, we first compute a linguistic unit feature vector for each reference Φ(r j ), as well as for the set of references Φ(r 1 , r 2 , . . . , r k ). Similarly, we compute a linguistic unit vector for the output Φ(o) and measure the overlap between the system and reference vectors. The vectors of the example references, if we use surface bigram units, would be, for R1, {imagine your:1, your household:1}, and for R2, {your household:1}. The weights of all n-grams in individual references and system outputs are equal to 1. 8 If we use dependency- parse triples instead, the vector of R2 would be {nmod:poss(household, your):1}.</p><p>The precision of a system output against a refer- ence is defined as the match Φ(r) T Φ(o) divided by the number of units in the vector of o; the latter can be expressed as the L 1 norm of Φ(o) because all weights are positive: Precision(o, r) = Φ(r) T Φ(o)</p><formula xml:id="formula_0">|Φ(o)| 1 .</formula><p>The recall against a single reference can be similarly defined as the match divided by the number of units in the reference:</p><formula xml:id="formula_1">Recall(o, r) = Φ(r) T Φ(o) |Φ(r)| 1 .</formula><p>We distinguish three methods for aggregating in- formation from multiple references: MULT-MAX which uses the single reference out of a set that results in the highest single-reference score, and two further methods, MULT-ALL and MULT-PROB, that construct an aggregate linguistic unit vector Φ(r 1 , . . . , r k ) before matching. MULT-ALL is the standard method used in multi-reference BLEU, where the vector for a set of references is defined as the union of the features of the set. For our ex- ample, the combined vector of R1 and R2 is equal to the vector of R1, because R2 adds no new bigrams. MULT-PROB, a new method that we propose here, is motivated by the observation that although judg- ments of importance of content are subjective, the more annotators assert some information is impor- tant, the more this information should contribute to the matching score. <ref type="bibr">9</ref> In MULT-PROB we define the weight of a linguistic unit in the combined reference vector as the proportion of references that include the unit. For our example, Φ MULT-PROB (R1, R2) is {imagine your:.5, your household:1}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Models for Text Compression</head><p>For the purpose of analysis, we trained and eval- uated four compression systems. These include both deletion-based and abstractive models: (1) ILP, an integer linear programing approach for deletion- based compression <ref type="bibr" target="#b5">(Clarke and Lapata, 2008)</ref>, <ref type="formula">(2)</ref> T3, a tree transducer-based model for abstractive compression <ref type="bibr" target="#b8">(Cohn and Lapata, 2008)</ref>, (3) Seq2seq, a neural network model for deletion-based compres- sion ( <ref type="bibr" target="#b10">Filippova et al., 2015)</ref>, and (4) NAMAS, a neural model for abstractive compression and sum- marization ( <ref type="bibr" target="#b26">Rush et al., 2015</ref>). We are not con- cerned with the relative performance of these mod- els so much as we are concerned with evaluating the automatic evaluation metrics themselves. We have sought to make the models competitive, but have not required that all systems use identical training data.</p><p>All of the models are evaluated on the test set portion of our dataset. All models use the train- ing portion of the data for training, and two models (Seq2Seq and NAMAS 10 ) additionally use external training data. The external data is summarized in <ref type="table" target="#tab_10">Table 7</ref>. The Gigaword set was extracted from the Annotated Gigaword ( <ref type="bibr" target="#b23">Napoles et al., 2012)</ref>, using the implementation provided by <ref type="bibr" target="#b26">Rush et al. (2015)</ref>. The Headline data was extracted in similar fashion using an in-house news collection.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ILP:</head><p>We use an open-source implementation 11 of the semi-supervised ILP model described in <ref type="bibr" target="#b5">(Clarke and Lapata, 2008)</ref>. The model uses a trigram lan- guage model trained on a 9 million token subset of the OANC corpus. The ILP model requires parsed sentences coupled with deletion-based com- pressions for training, so we filtered and prepro- cessed our dataset to satisfy these constraints. We used all single sentence inputs with their corre- sponding deletion-based compressions, and addi- tionally used two-sentence paragraph input/output pairs split into sentences by heuristically aligning source to target sentences in the paragraphs. T3: We use the authors' implementation of the tree transducer system described in <ref type="bibr" target="#b8">Cohn and Lapata (2008)</ref>. T3 similarly requires sentence-level in- put/output pairs, but can also learn from abstractive compressions. We thus used a larger set of approx- imately 28,000 examples (single sentences with ab- stractive compressions taken directly from the data or as a result of heuristic sentence-level alignment of two-sentence paragraphs). We obtained parse trees using the Stanford parser ( <ref type="bibr" target="#b19">Klein and Manning, 2003)</ref>, and used Jacana ( <ref type="bibr" target="#b32">Yao et al., 2013</ref>) for word alignment. The performance obtained by T3 in our experiments is substantially weaker (relative to ILP) than that reported in prior work <ref type="bibr" target="#b8">(Cohn and Lapata, 2008)</ref>. We therefore interpret this system output solely as data for evaluating automatic metrics. NAMAS: We run the publicly available implemen- tation of NAMAS 12 with the settings described by <ref type="bibr" target="#b26">Rush et al. (2015)</ref>. We modified the beam search al- gorithm to produce output with a compression ratio similar to that of the human references, since this ra- tio is a large factor in compression quality (Napoles et al., 2011), and systems generally perform better if allowed to produce longer output, up to the max- imum length limit. We enforced output length be-tween 50% and 75% of input length, which resulted in improved performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Seq2seq:</head><p>We implemented the sequence-to- sequence model 13 described in <ref type="bibr" target="#b10">Filippova et al. (2015)</ref>. A deletion-based model, it uses the deletion- based subset of our training dataset and the deletion- based subset from the external data in <ref type="table" target="#tab_10">Table 7</ref>. The encoder and decoder have three stacked LSTM lay- ers, the hidden dimension size is 512, and the vocab- ulary size is 30,000. The compression rate was con- trolled in the same range as for the NAMAS model.</p><p>All models produce output on all inputs in the test set. For all models, we generated outputs for multi- sentence inputs by concatenating outputs for each individual sentence. <ref type="bibr">14</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Overall, we consider 80 metric variants, consisting of combinations of six types of linguistic units, com- bined with three scoring methods (Precision, Recall, and F-measure) and four settings of single reference SINGLE-REF or three ways of scoring against multi- ple references MULT-ALL,MULT-MAX,MULT-PROB. Additionally, we include the standard single and multi-reference versions of BLEU-2,BLEU-3,BLEU- 4, and ROUGE-L.</p><p>We compare automatic metrics to human judge- ments at the level of individual outputs or groups of outputs (the whole corpus). For a single output o, the human quality judgment is defined as the average assigned by up to five human raters. We denote the meaning, grammar, and combined quality values by M (o), G(o), and C(o) = .5M (o) + .5G(o), respec- tively. We define the quality for a group of outputs as the arithmetic mean of judgments over the outputs in the group. We use the arithmetic mean of automat- ing metrics at the individual output level to define automatic corpus quality metrics as well. <ref type="bibr">15</ref> To com- pare different metrics and establish statistical signif- icance of the difference between two metrics, we use Williams test of the significance of the difference   between dependent Pearson correlations with hu- man judgments <ref type="bibr" target="#b29">(Williams, 1959)</ref> as recommended for summarization evaluation <ref type="bibr" target="#b14">(Graham, 2015)</ref> and other NLP tasks (e.g. <ref type="figure">(Yannakoudakis et al., 2011)</ref>). <ref type="table" target="#tab_12">Table 8</ref> shows the average human ratings of the four systems, separately in meaning and grammar, as well as the combined measure (an arithmetic mean of meaning and grammar judgments). Even though the performance of some systems is simi- lar, the differences between all pairs of systems in meaning and grammar are significant p &lt; 0.0001 according to a paired t-test. It is interesting to note that ILP outperforms the more recently devel- oped neural network systems Seq2Seq and NAMAS. This might seem to contradict recent results show- ing that the new models are superior to traditional baselines, such as ILP. We note however that per- formance on the test corpus in our study might not substantially improve through the use of large au- tomatically mined data-sets of headlines and corre- sponding news article sentences, due to differences in genre and domain. Using such data-sets for ef- fective training of neural network models for non- newswire domains remains an open problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Corpus-level metrics</head><p>For each of the 80 metrics, we compared the rank- ing of the four systems with the ranking according to average human quality. Fifty three of the metrics achieved perfect Spearman ρ and Kendall τ B cor- relation with human judgments of combined mean- ing and grammar quality. Due to the small sample size (four systems), we are unable to find statisti- cally significant differences among metrics at the corpus level. We only note that precision-based met- rics involving large linguistic units (four-grams) had negative correlations with human judgments. We can conclude, however, that evaluation at the corpus level is robust for a wide variety of standard metrics using linguistic units of size three or smaller.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Single input-level pairwise system comparisons</head><p>We can garner greater insight into the difference of metric performance when we compare metrics at the single input level. To gauge the ability of met- rics to comparatively evaluate the quality of two sys- tems, we compute single input-level correlations of automatic metrics with human judgments following the protocol of <ref type="bibr" target="#b11">Galley et al. (2015)</ref>. Each system A produces a sequence of outputs o 1 A , . . . , o n A , corre- sponding to inputs x 1 , . . . , x n . For each system out- put, we use Q(a) to denote a generic human quality metric, varying over meaning, grammar, and their combination. For each pair of systems A and B, and each metric m, we compute the difference in qual- ity for corresponding system outputs for each input</p><formula xml:id="formula_2">x i : m(o i A ) − m(o i B )</formula><p>and the difference in quality according to human judgments:</p><formula xml:id="formula_3">Q(o i A ) − Q(o i B )</formula><p>, and compute the correlation between these two se- quences. We can thus compute the single input-level correlation between m and Q for each pair of sys- tems A and B, resulting in a total of six correlation values (for the six pairs of systems) for each metric. For each pair of metrics m 1 and m 2 , and for each pair of systems A and B, we compute the statisti- cal significance of the difference between the Pear- son correlations of these metrics with human judge- ments. We say that m 1 is significantly better than m 2 on the A vs. B comparison if its Pearson cor- relation with human quality Q is significantly bet- ter (according to the Williams test of the difference in dependent correlations) than that of m 2 with a p- value less than .05. We say that m 1 dominates m 2 overall if it is significantly better than m 2 on at least 80% of the pair-wise system comparisons. <ref type="table" target="#tab_14">Table 9</ref> shows the main correlation results at the level of individual inputs. We report correlations with meaning, grammar, and combined quality sep- arately. For each human quality metric, we see the top automatic metrics in the first group of rows. The top metrics are ones that, for at least 80% of the sys- tem comparisons, are not significantly dominated by any other metric. In addition, we show the impact of each of the three criteria: linguistic units, scoring measure, and multiple references, in corresponding groups of rows. For each linguistic unit type, we show the best-performing metric that uses units of   this type. Similarly, for the other criteria, we show the best performing metric for each value of the cri- terion. Metrics with a * suffix in each group signif- icantly dominate metrics with a − suffix. Metrics with a − suffix in a group are dominated by at least one other metric, possibly outside of the group. The lowest group of rows in each main column presents the performance of other metrics that cannot be clas- sified directly based on the three criteria.</p><p>A high-level observation that can be made is that the correlations with meaning are much higher than the correlations with grammar. The best corre- lations in meaning can be classified as "strong", whereas the best correlations in grammar are in the "medium" range. Unigrams are heavily domi- nated by higher order n-grams in all settings. Four- grams are also weaker that other units in measuring meaning preservation. Dependency triple (parse- based) metrics are strong, in particular in measuring grammaticality, but do not significantly dominate skip bi-grams or contiguous bi-grams. The scor- ing measure used has a strong impact. We see that precision-based metrics are substantially dominated by metrics that incorporate recall, except for gram- mar evaluation. Importantly, we see that multiple references contribute substantially to metric qual- ity, as all methods that use multiple references out- perform single-reference metrics. In both meaning and combined evaluation, this difference was statis- tically significant. Finally, we observe that standard BLEU metrics and ROUGE-L were not competitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have introduced a large manually collected multi-reference abstractive dataset and quantified the impact of editing operations and context on hu- man compression quality, showing that substitution and rephrasing operations are more meaning pre- serving than other operations, and that compression in context improves quality. Further, in the first sys- tematic study of automatic evaluation metrics for text compression, we have demonstrated the impor- tance of utilizing multiple references and suitable linguistic units, and incorporating recall.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Data</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>System</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>51 LR-2+Recall+MULT-PROB .51 LR-2+F-1+MULT-ALL .50 LR-1+Recall+MULT-PROB .44 - LR-2+Recall+MULT-PROB .51 * LR-3+F-1+MULT-ALL .50 * LR-4+Recall+MULT-ALL .47 SKIP-2+Recall+MULT-MAX .51 * PARSE-2+Recall+MULT-PROB .52 * PARSE-2+Recall+MULT-PROB .52 SKIP-2+Precision+MULT-ALL .37 - LR-2+F-1+MULT-ALL .50 SKIP-2+Recall+SINGLE-REF .44 - PARSE-2+Recall+MULT-MAX .52 PARSE-2+Recall+MULT-PROB .52 LR-2+F-1+MULT-ALL .50 BLEU-3+PrecBrev+MULT-ALL .45 - ROUGE-L+Recall+MULT-MAX .43</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples of 1-and 2-sentence crowd-sourced compressions, illustrating different rewrite types. 

Newswire Letters Journal Non-fiction 
#texts 
695 
1,591 
1,871 
2,012 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Overview of the dataset by genre.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>5</head><label>5</label><figDesc></figDesc><table>Description 

Texts 
Quality 
Source Target Avg CPS Meaning Grammar 
All 
6,169 26,423 
4.28 
2.78 
2.82 
Per Source Length 
1-Sent 
3,764 15,523 
4.12 
2.78 
2.81 
2-Sent 
2,405 10,900 
4.53 
2.78 
2.83 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Overview of the dataset, presenting the overall number 

of source and target texts, the average quality of the compressed 

texts, and breakdown by length of source (number of sentences). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 : Agreement on meaning preservation and grammati-</head><label>4</label><figDesc></figDesc><table>cally between crowd workers and experts. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><head>Table 5 : Meaning and grammaticality judgments by compres-</head><label>5</label><figDesc></figDesc><table>sion operation. *p = 0.002. **p &lt; 0.0001. 

Source Type Meaning Grammar 
2-Sentence 
2.86** 
2.87** 
1-Sentence 
2.78 
2.82 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Meaning and grammaticality judgments for compress-

ing two sentences jointly versus individually. **p &lt; 0.0001. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>#src tokens #trg tokens #sents</head><label>#src</label><figDesc></figDesc><table>Abstractive 
Gigaword 
114.1M 
30.0M 3.6M 
Headline 
6.0M 
1.4M 0.2M 

Deletion-based 
Gigaword 
1,353K 
329K 
47K 
Headline 
59K 
11K 
2K 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 7 : External data statistics.</head><label>7</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 8 : Average human ratings of system outputs for meaning and grammar separately and in combination.</head><label>8</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" validated="false"><head>Table 9 :</head><label>9</label><figDesc>Left to right: Pearson correlation of automatic metrics with human ratings for meaning, grammar, and combined quality.</figDesc><table></table></figure>

			<note place="foot">* This research was conducted during the author&apos;s internship at Microsoft Research.</note>

			<note place="foot" n="1"> http://www.anc.org/data/oanc</note>

			<note place="foot" n="2"> http://jamesclarke.net/research/ resources</note>

			<note place="foot" n="4"> Pilot studies suggested that a scale of 1-3 offered better inter-annotator agreement than the standard 5-point Likert-type scale, at the cost of granularity. 5 This was motivated by the observation that the quality of work produced by judges is relatively constant (Gao et al., 2015).</note>

			<note place="foot" n="6"> The dataset can be downloaded from the project&apos;s website https://www.microsoft.com/en-us/research/ project/intelligent-editing/.</note>

			<note place="foot" n="7"> Clarke and Lapata (2006) used the RASP parser (Briscoe and Carroll, 2002), but we expect that the Stanford parser is similarly robust and would lead to similar correlations.</note>

			<note place="foot" n="8"> We handle repeating n-grams by assigning each subsequent n-gram of the same type a distinct type, so that the i-th the of a system output can match the i-th the of a reference.</note>

			<note place="foot" n="9"> A similar insight was used in one of the component metrics of the SARI evaluation metric used for text simplification evaluation (Xu et al., 2016). 10 The original works introducing these models employed much larger training corpora, believed to be key to improving the accuracy of neutral network models with large parameter spaces.</note>

			<note place="foot" n="11"> https://github.com/cnap/ sentence-compression 12 https://github.com/facebook/NAMAS</note>

			<note place="foot" n="13"> https://github.com/ketranm/tardis 14 In small scale preliminary manual evaluation, we found that, although some models are theoretically able to make use of context beyond the sentence boundary, they performed better if they compressed each sentence in a sequence independently. 15 This method has been standard for ROUGE, but has not for BLEU. We find that averaging sentence-level metrics is also advantageous for BLEU .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to Jaime Teevan, Shamsi Iqbal, Dan Liebling, Bill Dolan, Michel Galley, and Wei Xu, to-gether with the three anonymous reviewers for their helpful advice and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Evaluation metrics for generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Bangalore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Whittaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INLG</title>
		<meeting>INLG</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Jointly learning to extract and compress</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-HLT</title>
		<meeting>ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust accurate statistical annotation of general text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John A</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Speech summarization: an approach through word extraction and a method for evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hori</forename><surname>Chiori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadaoki</forename><surname>Furui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE Transactions on Information and Systems</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="25" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Models for sentence compression: A comparison across domains, training requirements and evaluation measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-COLING</title>
		<meeting>ACL-COLING</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Global inference for sentence compression: An integer linear programming approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page" from="399" to="429" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Global Inference for Sentence Compression: An Integer Linear Programming Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Univeristy of Edinburgh</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">213</biblScope>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sentence compression beyond word deletion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Overcoming the lack of parallel data in sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasemin</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sentence compression by deletion with LSTMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">A</forename><surname>Colmenares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">deltableu: A discriminative metric for generation tasks with intrinsically diverse targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP</title>
		<meeting>ACL-IJCNLP</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cost optimization in crowdsourcing translation: Low cost translations made even cheaper</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkun</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Re-evaluating automatic summarization with BLEU and 192 shades of ROUGE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MASC: the manually annotated sub-corpus of american english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Collin</forename><forename type="middle">F</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The manually annotated sub-corpus: A community resource for and by the people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Collin</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The decomposition of human-written summary sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kathleen R Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sentence reduction for automatic text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ANLP</title>
		<meeting>ANLP</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Summarization beyond sentence extraction: A probabilistic approach to sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="107" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text summarization branches out: Proceedings of the ACL-04 workshop</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating sentence compression: Pitfalls and suggested remedies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Monolingual Text-To-Text Generation</title>
		<meeting>the Workshop on Monolingual Text-To-Text Generation</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Annotated gigaword</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction</title>
		<meeting>the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An empirical analysis of formality in online communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetrault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="61" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for lexical-functional grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tracy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Crouch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaenen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A neural attention model for abstractive sentence summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Trimming CFG parse trees for sentence compression using machine learning approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuya</forename><surname>Unno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Ninomiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-ACL</title>
		<meeting>COLING-ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Beyond sumbasic: Task-focused summarization with sentence simplification and lexical expansion. Information Processing &amp; Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisami</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1606" to="1618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Regression analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><forename type="middle">James</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Williams</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1959" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimizing statistical machine translation for text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanze</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A new dataset and method for automatically grading esol texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Medlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-HLT</title>
		<meeting>ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A lightweight and high performance monolingual word aligner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callisonburch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
