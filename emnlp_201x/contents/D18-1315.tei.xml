<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Encoder-Decoder Approach to the Paradigm Cell Filling Problem</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018. 2883</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miikka</forename><surname>Silfverberg</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics</orgName>
								<orgName type="department" key="dep2">Department of Linguistics</orgName>
								<orgName type="institution" key="instit1">University of Colorado</orgName>
								<orgName type="institution" key="instit2">University of Helsinki</orgName>
								<orgName type="institution" key="instit3">University of Colorado</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mans</forename><surname>Hulden</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics</orgName>
								<orgName type="department" key="dep2">Department of Linguistics</orgName>
								<orgName type="institution" key="instit1">University of Colorado</orgName>
								<orgName type="institution" key="instit2">University of Helsinki</orgName>
								<orgName type="institution" key="instit3">University of Colorado</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Encoder-Decoder Approach to the Paradigm Cell Filling Problem</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2883" to="2889"/>
							<date type="published">October 31-November 4, 2018. 2018. 2883</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The Paradigm Cell Filling Problem in morphology asks to complete word inflection tables from partial ones. We implement novel neural models for this task, evaluating them on 18 data sets in 8 languages, showing performance that is comparable with previous work with far less training data. We also publish a new dataset for this task and code implementing the system described in this paper. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>An important learning question in morphology- both for NLP and models of language acquisition-is the so-called Paradigm Cell Filling Problem (PCFP). So dubbed by <ref type="bibr" target="#b0">Ackerman et al. (2009)</ref>, this problem asks how it is that speakers of a language can reliably produce inflectional forms of most lexemes without ever witnessing those forms before. For example, a Finnish noun or adjective can be inflected in 2,263 ways if one includes case forms, number, and clitics <ref type="bibr" target="#b17">(Karlsson, 2008)</ref>. However, it is unlikely that a Finnish speaker would have heard all forms for even a single, highly frequent lexical item. It is also unlikely that all 2,263 forms are found in the aggregate of all the witnessed inflected forms over different lexemes and speakers must be able to assess the felicity of, and possibly produce such inflectional combinations they have never witnessed for any noun or adjective. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the PCFP.</p><p>This paper investigates PCFP in three different settings: (1) when we know n &gt; 1 randomly se- lected forms in each of a number of inflection ta- bles, (2) when we know a set of frequent word forms in each table (this most closely resembles an L1 language learning setting), and finally <ref type="formula">(3)</ref> 1 https://github.com/mpsilfve/pcfp-data when we know exactly n = 1 word form from each table.</p><p>We treat settings <ref type="formula">(1)</ref> and <ref type="formula">(2)</ref> as traditional morphological reinflection tasks ( <ref type="bibr" target="#b11">Cotterell et al., 2016</ref>) as explained in Section 2. In contrast, set- ting (3) is substantially more challenging because it cannot be handled using a traditional reinflec- tion approach. To overcome this problem, we uti- lize an adaptive dropout mechanism which will be discussed in Section 2. This allows us to train the reinflection system in a manner reminiscent of de- noising autoencoders <ref type="bibr" target="#b25">(Vincent et al., 2008)</ref>. Related Work Neural models have recently been shown to be highly competitive in many dif- ferent tasks of learning supervised morphological inflection <ref type="bibr" target="#b13">(Faruqui et al., 2016;</ref><ref type="bibr" target="#b16">Kann and Schütze, 2016;</ref><ref type="bibr" target="#b19">Makarov et al., 2017;</ref><ref type="bibr" target="#b1">Aharoni and Goldberg, 2017</ref>) and derivation ( <ref type="bibr" target="#b12">Cotterell et al., 2017b</ref>). Most current architectures are based on encoder- decoder models <ref type="bibr" target="#b24">(Sutskever et al., 2014)</ref>, and usu- ally contain an attention component ( <ref type="bibr" target="#b5">Bahdanau et al., 2015</ref>). The SIGMORPHON ( <ref type="bibr" target="#b11">Cotterell et al., 2016</ref>) and CoNLL-SIGMORPHON ( <ref type="bibr">Cotterell et al., 2017a</ref><ref type="bibr" target="#b18">Cotterell et al., , 2018</ref> shared tasks in recent years have explored morphological inflection but not explicitly the PCFP. In the 2017 task, participants were given full paradigms-i.e. a listing of all forms-of lexemes during training after which they were given incomplete paradigms which had to be com- pleted at test time. This is a slightly unrealistic setting in an L1-style learning scenario  where arguably very few full paradigms are ever witnessed and where general- ization has to proceed on a number of very gappy paradigms. Of course, such gaps form a distri- bution where frequently used lexemes have fewer gaps than infrequent ones, which we will attempt to model in this work.  evaluate an extension to a linguistically informed symbolic paradigm model based on stem extraction from the longest common subsequence (LCS) shared among re- lated forms <ref type="bibr" target="#b2">(Ahlberg et al., 2014</ref><ref type="bibr" target="#b3">(Ahlberg et al., , 2015</ref>. While the original LCS paradigm extraction method was intended to learn from complete inflection ta- bles <ref type="bibr" target="#b14">(Hulden, 2014)</ref>,  present modifications to allow learning from in- complete paradigms as well, and apply it to the PCFP. Comparing against their results, shows that our neural model consistently outperforms such a subsequence-based learning model. <ref type="bibr" target="#b15">Kann et al. (2017)</ref> report results on so-called multi-source reinflection in which several input forms are used to generate one output form. This task is related to the PCFP; however, <ref type="bibr" target="#b15">Kann et al. (2017)</ref> use full inflection tables for training. More- over, their approach is applicable for PCFP only when 3 or more forms are given in the input ta- bles. Since this mostly excludes our experimental settings, we do not compare to their system. <ref type="bibr" target="#b20">Malouf (2016</ref><ref type="bibr" target="#b21">Malouf ( , 2017</ref> documents an experiment with a generator LSTM in completing inflection tables in up to seven languages with either 10% or 40% of table entries missing. Our work differs from this in that Malouf gives as input a two-hot encoding of both the lexeme and the desired slot during train- ing and testing for which an inflection table is to be completed, which means the system cannot com- plete paradigms which it has not seen examples of in the training data. By contrast, our system has no notion of lexeme and we simply work from the symbol strings which are collections of inflected forms of a lexeme given in the test data which may in principle be completely disjoint from train- ing data lexemes. We use the Malouf system as a baseline to compare against.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Encoder-Decoder Models for PCFP</head><p>We explore two different models for paradigm fill- ing. The first model is applicable when n &gt; 1 forms are given in each inflection table. When ex- actly one (n = 1) form is given, we use another model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case n&gt;1</head><p>When more than one form is given in training tables, PCFP can be treated as a mor- phological reinflection task ( <ref type="bibr" target="#b11">Cotterell et al., 2016)</ref>, where the aim is to translate inflected word forms and their tags into target word forms. For ex- ample, a model would translate tried+PAST into the present participle (PRES,PCPLE) form try- ing. We adopt a common approach employed by <ref type="bibr" target="#b16">Kann and Schütze (2016)</ref> and many oth- ers: we build a model which translates an input word form, its tag and a target tag, for example tried+PAST+PRES,PCPLE, into the target word form trying.</p><p>Our model closely follows the formulation of the encoder-decoder LSTM model for morpholog- ical reinflection proposed by <ref type="bibr" target="#b16">Kann and Schütze (2016)</ref>. We use a 1-layer bidirectional LSTM en- coder for encoding the input word form into a se- quence of state vectors and a 1-layer LSTM de- coder with an attention mechanism over encoder states for generating the output word form.</p><p>We form training pairs by using the given forms in each table, i.e. take the cross-product of the given forms and learn to reinflect each given form in a table to another given form in the same table as demonstrated in <ref type="figure">Figure 2</ref>. <ref type="bibr">2</ref> During test time, we predict forms for missing slots based on each of the given forms in the table and take a majority vote of the results. 3</p><p>Case n=1 When only one form is given in each inflection table, we cannot train the model as a tra- ditional reinflection model. The best we can do is to train a model to reinflect forms into the same form walked+PAST+PAST → walked and then try to apply this model for reinflection to fill in missing forms walked+PAST+PRES,PCPLE → walking. According to preliminary experiments, this however leads to massive over-fitting and the model simply learns to only copy input forms.  <ref type="table">,DAT,SG  augšanā  N,LOC,SG  augšana  N,NOM,SG  augšana  N,VOC,SG  augšanas  N,GEN,SG  augšanu  N,ACC,SG  augšanu  N,INST,</ref> The idea for our approach in case n = 1 is to first learn to segment word forms into a stem and an affix, for example walk+ed. We then hide the affix in the input form and learn to inflect. In other words, we map the word form walked into walk$$ and then learn a mapping walk$$+PAST → walked. This model suffers less from over- fitting and we can use it to find missing forms in partial inflection tables.</p><p>Since we do not have access to segmented train- ing data, we cannot directly train a segmentation model. Instead, we use the forms in the train- ing data to train an LSTM language model con- ditioned on morphological tags. We then use the language model for identifying which characters belong to stems and which characters belong to affixes.</p><p>As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, the language model in general gives higher confidence for predictions of characters in the affix than in the word stem. Nev- ertheless, it only gives a probabilistic segmenta- tion into a stem and affix(es). Therefore, we do not perform a deterministic segmentation. Instead we use the language model to guide a character dropout mechanism in our word inflection model. When the language model is very confident, as in the case of affix characters, we frequently drop characters. In contrast, when the language model   <ref type="bibr">(2017)</ref>, who used cross-validation, we train one system for each language. Therefore, we only report standard deviation for the results in Column 2.</p><p>is less confident, as in the case of stem characters, we typically keep the character. Apart from this adaptive dropout applied during training, our in- flection system in case n = 1 is exactly the same as in case n &gt; 1. More precisely, given an input word form, which is a sequence of characters x = x 1 , ..., x T , the LSTM language model emits a probabil- ity p(x t+1 , h t , E xt , E y ) for the next character x t+1 based on the entire previous input sequence x 1 , ..., x t . Here h t is the hidden state vector of the language model at position t, E a joint tag and character embedding and y the morphologi- cal tag of the input word form. The embedding vector E y is in fact a sum of sub-tag embeddings. For example, E PAST+PCPLE denotes E PAST + E PCPLE . This allows us to handle combinations of sub- tags which we have not seen in the training data. Guided by the language model, we replace in- put characters x t+1 during training of the rein- flection system with a dropout character $ with probability equal to language model confidence p(x t+1 , h t , E xt , E y ). 4</p><p>Baseline Model As a baseline model, we use the neural system presented by <ref type="bibr" target="#b20">Malouf (2016</ref><ref type="bibr" target="#b21">Malouf ( , 2017</ref> for solving PCFP. It is an LSTM generator which is conditioned on the table number of the partial inflection tables and the morphological tag index. The model is trained to generate training word forms in inflection tables. During testing, it can then generate missing forms by conditioning on morphological tags for the missing forms.</p><p>In order to assure fair comparison, we perform the paradigm completion experiment described in <ref type="bibr" target="#b21">Malouf (2017)</ref>, where 90% of the word forms in the data set is used for training and the remaining 10% for testing. <ref type="bibr">5</ref> As the results in <ref type="table" target="#tab_1">Table 1</ref> show, our results very closely replicate those reported by <ref type="bibr" target="#b21">Malouf (2017)</ref>.</p><p>Implementation details We use 1-layer bidirec- tional LSTM encoders, decoders and generators with embeddings and hidden states of size 100. We train the language model for case n &gt; 1 for 20 epochs and all other models for 60 epochs with- out batching. We train 10 models for every lan- guage and part-of-speech and apply majority vot- ing to get the final output forms. All models were implemented using DyNet ( <ref type="bibr">Neubig et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>We use UniMorph morphological paradigm data in our experiments ( <ref type="bibr" target="#b18">Kirov et al., 2018)</ref>. Uni- morph data sets are crowd-sourced collections of morphological inflection tables based on Wik- tionary. We conduct experiments on noun and verb paradigms from eight languages. <ref type="bibr">6</ref> Not all lan- guages have 1,000 noun and verb tables. Hence, our selection is not complete as seen in <ref type="table" target="#tab_5">Table 3</ref>.</p><p>We conduct experiments on two different sets of tables: (1) we randomly sample 1,000 tables for each language and part-of-speech, and (2) we se- lect Unimorph tables including some of the 10,000 most common word forms according to Wikipedia frequency. The Wikipedia word frequencies are based on plain Wikipedia text dumps from the Polyglot project (Al- <ref type="bibr" target="#b4">Rfou et al., 2013</ref>). Georgian and Latin did not have a Polyglot Wikipedia so we excluded those. Moreover, we excluded Lat- vian verbs because there was very little overlap between the most frequent Wikipedia word forms and Unimorph table entries (&lt; 200 forms occurred in both). Details for both types of data sets are given in <ref type="table" target="#tab_3">Tables 3 and 2.</ref> # <ref type="table" target="#tab_4">Tables Table Size   FINNISH</ref>   however, we did not have access to the exact splits into train- ing and test data used by <ref type="bibr" target="#b21">Malouf (2017)</ref>. This may influence results. 6 Finnish (fin), French (fre), Georgian (geo), German (ger), Latin (lat), Latvian (lav), Spanish (spa) and Turkish (tur).   <ref type="table">Table 4</ref>: Overall results for filling in missing forms when the 10,000 most frequent forms are given in the inflection tables. We give the 0.99 confidence intervals as given by a one-sided t-test. Figures where one system significantly outperforms the other one are in boldface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>We perform two experiments. In the first one, we take the set of 1,000 randomly sampled inflection tables for each language and part-of-speech and then randomly select n=1, 2 or 3 training forms from each table. We then train a reinflection sys- tem on these forms and use the resulting system to predict the missing forms. We report accuracy on correctly predicted missing forms and on re- constructing the entire paradigm correctly. In our second experiment, we consider Unimorph tables which contain entries from a list of 10,000 most common word tokens compiled using a Wikipedia dump of the language as explained above. We take the forms in the top-10,000 list as given and train a model which is used to reconstruct the remaining forms in each table. We train an identical model as in the case n &gt; 1 on tables with more than one given form. As in the first task, we evaluate with regard to accuracy for reconstructed forms and full tables. Results are presented in <ref type="table" target="#tab_6">Tables 4 and 5</ref>, and <ref type="figure" target="#fig_3">Figure 4</ref>. <ref type="table">Table 4</ref> shows results for completing tables for common lexemes. Our system significantly out- <ref type="table" target="#tab_1">Baseline  1 form  2 forms  3 forms  1 form  2 forms  3 forms   FIN N</ref> 18.87 ± 0.41 (0.00 ± 0.00) 81.72 ± 0.78 (16.50 ± 3.76) 93.07 ± 0.71 (54.80 ± 4.27) 6.07 ± 0.29 (0.00 ± 0.00) 46.64 ± 0.97 ( 0.00 ± 0.00) 65.60 ± 1.25 ( 0.80 ± 0.65)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FIN V</head><p>19.88 ± 0.69 (0.00 ± 0.00) 87.73 ± 0.36 (59.20 ± 5.73) 94.63 ± 0.41 (75.50 ± 3.82) 12.35 ± 0.58 (0.00 ± 0.00) 63.56 ± 0.89 ( 0.90 ± 0.90) 81.49 ± 0.42 (17.20 ± 2.21) FRE V 15.66 ± 0.65 (0.00 ± 0.00) 78.30 ± 0.66 (23.50 ± 4.06) 83.64 ± 0.72 (35.60 ± 4.63) 11.46 ± 0.33 (0.00 ± 0.00) 61.01 ± 0.79 ( 0.40 ± 0.53) 74.07 ± 1.00 ( 7.60 ± 2.53) GEO N 28.66 ± 1.12 (0.00 ± 0.00) 90.53 ± 0.48 (53.20 ± 6.03) 96.02 ± 0.48 (84.80 ± 3.28) 21.14 ± 0.84 (0.00 ± 0.00) 78.91 ± 0.56 (23.50 ± 4.03) 90.61 ± 0.76 (51. <ref type="bibr">30 ± 6.19)</ref> GER N 39.46 ± 2.18 (2.50 ± 1.83) 84.65 ± 2.00 (61.30 ± 4.33) 93.38 ± 0.86 (78. <ref type="bibr">30 ± 3.14)</ref> 40.25 ± 2.09 (4.40 ± 1.83) 72.26 ± 1.70 (32.70 ± 4.70) 86.49 ± 2.09 (57.30 ± 5.11) GER V 43.38 ± 0.68 (0.00 ± 0.00) 92.73 ± 0.41 (54.70 ± 3.75) 95.83 ± 0.38 (70.00 ± 4.99) 33.97 ± 1.13 (0.00 ± 0.00) 83.32 ± 0.48 (17.10 ± 3.27) 90.51 ± 0.62 <ref type="bibr">(34.90 ± 3.92)</ref> LAT N 16.89 ± 1.20 (0.00 ± 0.00) 83.59 ± 1.20 (49.50 ± 5.13) 91.02 ± 0.76 (68.70 ± 4.47) 23.62 ± 1.19 (0.10 ± 0.32) 63.27 ± 1.25 (17.40 ± 4.09) 77.96 ± 1.34 (32.90 ± 5.60) LAT V 17.34 ± 0.37 (0.00 ± 0.00) 83.01 ± 0.30 (27.00 ± 2.65) 89.66 ± 0.44 ( 2.80 ± 1.35) 5.96 ± 0.21 (0.00 ± 0.00) 52.68 ± 0.43 ( 0.00 ± 0.00) 68.95 ± 0.47 ( 0.00 ± 0.00) LAV N 30.11 ± 1.27 (2.00 ± 1.37) 85.41 ± 1.07 (48.50 ± 4.00) 94.83 ± 0.53 (83.40 ± 4.37) 22.35 ± 0.88 (2.60 ± 1.39) 64.76 ± 1.28 (22.20 ± 3.17) 79.21 ± 1.13 (40.80 ± 4.41) SPA V 27.78 ± 0.69 (0.00 ± 0.00) 87.44 ± 0.34 (32.20 ± 5.71) 94.81 ± 0.25 (59.00 ± 6.71) 10.88 ± 0.35 (0.00 ± 0.00) 70.67 ± 0.27 ( 0.40 ± 0.53) 84.08 ± 0.38 (11.60 ± 2.91) TUR N 15.70 ± 0.44 (0.00 ± 0.00) 88.90 ± 0.60 (19.20 ± 4.89) 92.07 ± 0.37 <ref type="bibr">(22.80 ± 4.22)</ref> 7.94 ± 0.39 (0.00 ± 0.00) 61.95 ± 0.72 ( 5.60 ± 2.95) 77.02 ± 0.49 (11.40 ± 3.82)  The blue bars (on the left) denote accuracy for our system and green bars (on the right) accuracy for the baseline system. The graphs show accuracy separately for tables where 1, 2, 3, 4, and &gt; 4 forms are given.</p><p>performs the baseline on all other datasets apart from German nouns. We believe that the rea- son for the German outlier is the high degree of syncretism in German noun tables. To see why syncretism is harmful, consider the German noun Gräben. Its paradigm consists of eight forms but four of those are identical: Gräben. Only this form is observed among the top 10,000 forms in the German Wikipedia. Following Section 2, this gives rise to 12 training examples where both the input and output form are Gräben. This strongly biases the system to copying input forms into the output. However, this will never give the correct output because, by design, missing forms cannot be Gräben. 7 This can be seen as a problem with our datasets rather than the model itself. Conse- quently, an important future work in addressing the PCFP from an acquisition perspective is to create realistic and accurate data sets that model <ref type="bibr">7</ref> If the same word form occurs in multiple slots, all of them are considered known. learner exposure both in word types and frequen- cies to enable assessment of the true difficulty of the PCFP.</p><p>There is a notable transition from witnessing one form in each inflection table to witnessing two forms. With only two forms given, we already ap- proach accuracies reported in earlier work <ref type="bibr" target="#b20">(Malouf, 2016</ref><ref type="bibr" target="#b21">(Malouf, , 2017</ref>) that used almost complete tables to train-only 10% of the forms were missing. Additionally, our encoder-decoder model strongly outperforms that generator model designed for the same task with the same amount of training data on nearly all of our datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of the PCFP using a fraction of Spanish verb tables: given such partially filled paradigms, the task is to fill in all the missing forms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 2: Partial inflection table for the Latvian noun augana 'growth'. From a partial inflection table with two given forms, we get two training examples. With n given forms in a table, we hence produce n(n − 1) training examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Detailed results for filling in missing forms when the 10,000 most frequent forms are given in the inflection tables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>We reproduce experiments in Malouf (2017) using 

our own implementation of the model. In contrast to Malouf 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Details for inflection tables chosen according to</head><label>2</label><figDesc></figDesc><table>Wikipedia word frequency. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table Size Unique</head><label>Size</label><figDesc></figDesc><table>Forms 
per Table 

FIN N 
27.7 
25.7 
FIN V 
39.0 
37.6 
FRE V 
47.5 
36.1 
GEO N 
19.0 
16.9 
GER V 
28.9 
12.3 
LAT N 
11.9 
7.2 
LAT V 
99.8 
94.8 
LAV N 
11.6 
7.6 
SPA V 
62.5 
52.1 
TUR N 
74.4 
54.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Details for randomly sampled inflection tables. The 

data for each language and part-of-speech consist of 1,000 
tables. 

Our system 
Baseline 

FINNISH NOUNS 63.64 ± 3.24 25.63 ± 1.63 
FINNISH VERBS 
24.82 ± 1.13 16.14 ± 1.14 
FRENCH VERBS 
31.34 ± 1.18 14.34 ± 0.87 
GERMAN NOUNS 18.73 ± 1.26 67.16 ± 3.20 
GERMAN VERBS 61.21 ± 1.85 50.18 ± 2.58 
LATVIAN NOUNS 76.90 ± 5.30 57.28 ± 2.05 
SPANISH VERBS 
27.27 ± 0.72 16.61 ± 0.70 
TURKISH NOUNS 33.87 ± 2.03 25.00 ± 2.52 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Accuracy for filling in missing forms when n=1,2 or 3 forms are given in the inflection table (accuracy for complete 

paradigms in parentheses). We give the 0.99 confidence intervals as given by a one-sided t-test. Figures where one system 
significantly outperforms the other one are in boldface. 

</table></figure>

			<note place="foot" n="2"> Note that the CoNLL-SIGMORPHON data provides a &apos;citation form&apos; that identifies each table; we do not use this form and the model has no knowledge of it. 3 When only two forms are given in the partial inflection table, we randomly choose one of the resulting output forms since the vote is always tied.</note>

			<note place="foot" n="4"> In practice, we pad input forms with end-of-sequence characters in order to be able to drop x1 if needed. 5 We perform the the experiments on the original data sets,</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The first author was supported by The Society of Swedish Literature in Finland (SLS). NVIDIA Corp. donated the Titan Xp GPU used for this re-search.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Parts and wholes: Implicative patterns in inflectional paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farrell</forename><surname>Ackerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">P</forename><surname>Blevins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Malouf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page" from="54" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Morphological inflection generation with hard monotonic attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roee</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semi-supervised learning of morphological paradigms and lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malin</forename><surname>Ahlberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Forsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mans</forename><surname>Hulden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="569" to="578" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Paradigm classification in supervised learning of morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malin</forename><surname>Ahlberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Forsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mans</forename><surname>Hulden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL</title>
		<meeting><address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1024" to="1029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Polyglot: Distributed word representations for multilingual NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Computational Natural Language Learning</title>
		<meeting>the Seventeenth Conference on Computational Natural Language Learning<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Analogy in Grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">P</forename><surname>Blevins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliette</forename><surname>Blevins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Géraldine</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arya</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The CoNLLSIGMORPHON 2018 shared task: Universal morphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrett</forename><surname>Mielke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miikka</forename><surname>Nicolai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silfverberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL-SIGMORPHON 2018 Shared Task: Universal Morphological Reinflection</title>
		<meeting>the CoNLL-SIGMORPHON 2018 Shared Task: Universal Morphological Reinflection<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Jason Eisner, and Mans Hulden</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Jason Eisner, and Mans Hulden. 2017a. CoNLL-SIGMORPHON 2017 shared task: Universal morphological reinflection in 52 languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Géraldine</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL SIGMORPHON 2017</title>
		<meeting>the CoNLL SIGMORPHON 2017</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Shared Task: Universal Morphological Reinflection, pages 1-30, Vancouver. Association for Computational Linguistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The SIGMORPHON 2016 shared taskmorphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
		<meeting>the 14th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="10" to="22" />
		</imprint>
	</monogr>
	<note>Jason Eisner, and Mans Hulden</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Paradigm completion for derivational morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="714" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Morphological inflection generation using character sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generalizing inflection tables into paradigms with finite state operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mans Hulden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM</title>
		<meeting>the 2014 Joint Meeting of SIGMORPHON and SIGFSM</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural multi-source morphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="514" to="524" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Singlemodel encoder-decoder with explicit morphological representation for reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="555" to="560" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Finnish: An essential grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Karlsson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unimorph 2.0: Universal morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graldine</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><forename type="middle">J</forename><surname>Mielke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arya</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K ¨</forename><surname>Sandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Jason Eisner, and Mans Hulden. European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Align and copy: UZH at SIGMORPHON 2017 shared task for morphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Makarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Ruzsics</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL SIGMORPHON 2017</title>
		<meeting>the CoNLL SIGMORPHON 2017</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Generating morphological paradigms with a recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Malouf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>San Diego Linguistic Papers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Abstractive morphological learning with a recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Malouf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Morphology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="431" to="458" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Clothiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adhiguna</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Michel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.03980</idno>
		<title level="m">Swabha Swayamdipta, and Pengcheng Yin. 2017. DyNet: The dynamic neural network toolkit</title>
		<meeting><address><addrLine>Yusuke Oda, Matthew Richardson, Naomi Saphra</addrLine></address></meeting>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A computational model for the linguistic notion of morphological paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miikka</forename><surname>Silfverberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mans</forename><surname>Hulden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1615" to="1626" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
