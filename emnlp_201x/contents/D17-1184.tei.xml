<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sparsity and Noise: Where Knowledge Graph Embeddings Fall Short</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Pujara</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Santa Cruz</orgName>
								<orgName type="institution">University of California</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eriq</forename><surname>Augustine</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Santa Cruz</orgName>
								<orgName type="institution">University of California</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
							<email>getoor@soe.ucsc.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Santa Cruz</orgName>
								<orgName type="institution">University of California</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sparsity and Noise: Where Knowledge Graph Embeddings Fall Short</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1751" to="1756"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Knowledge graph (KG) embedding techniques use structured relationships between entities to learn low-dimensional representations of entities and relations. One prominent goal of these approaches is to improve the quality of knowledge graphs by removing errors and adding missing facts. Surprisingly, most embedding techniques have been evaluated on benchmark datasets consisting of dense and reliable subsets of human-curated KGs, which tend to be fairly complete and have few errors. In this paper, we consider the problem of applying embedding techniques to KGs extracted from text, which are often incomplete and contain errors. We compare the sparsity and unreliability of different KGs and perform empirical experiments demonstrating how embedding approaches degrade as sparsity and un-reliability increase.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently knowledge graphs (KGs), structured representations of knowledge bases, have be- come an essential component of systems that perform question-answering ( <ref type="bibr" target="#b0">Berant et al., 2013)</ref>, provide decision support, and enable exploration and discovery <ref type="bibr" target="#b3">(Dong et al., 2014)</ref>. Initial efforts to create KGs focused on struc- tured information sources or relied extensively on manual curation. However, the diversity of knowledge available on resources like the World Wide Web have spurred many projects that tackle the more difficult task of automat- ically constructing <ref type="bibr">KGs (Nickel et al., 2016a</ref>).</p><p>Unfortunately, information extraction ap- proaches for KG construction must overcome complex, unreliable, and incomplete data. Many machine learning methods have been proposed to address the challenge of cleaning and completing KGs. One popular class of methods learn embeddings that translate en- tities and relationships into a latent subspace, then use this latent representation to derive additional, unobserved facts and score exist- ing facts <ref type="bibr" target="#b2">(Bordes et al., 2013;</ref><ref type="bibr" target="#b17">Wang et al., 2014;</ref><ref type="bibr" target="#b6">Lin et al., 2015)</ref>.</p><p>Embedding methods have shown state-of- the-art results on several benchmark datasets. However, by construction, these benchmark datasets differ from data in real KGs. First, benchmark datasets have largely been re- stricted to the most frequently occurring en- tities in the KG. However in most KGs, en- tities are associated with a sparse set of ob- servations. Second, benchmark datasets con- sist only of highly reliable facts from cu- rated knowledge bases. In contrast, many KG construction projects extract knowledge from noisy data such as text or images, which in- troduces unreliable information.</p><p>In this paper, we evaluate popular KG em- bedding approaches on KGs that have sparse entities and unreliable candidate facts. We ap- ply embedding methods to an extracted KG and modify existing benchmarks by varying the sparsity and reliability of training data used to learn embedding models. Using this suite of datasets, we characterize where em- bedding approaches are successful and the con- ditions that result in degrading results. Based on our insights, we provide recommendations for improving embedding models and identify promising areas of future exploration. <ref type="table" target="#tab_2">Triples  E  R  EE  RE ED  RD  prec   Freebase  1B  124M  15K  14  3.2 16  68K  1  WordNet  380K  116K  27  21  2.3  7  21K  1  NELL1000  92M  4.8M  435  21  4.9 19  210K 0.45   FB15K  592K  15K  1.3K  16  5.1 79  440  1  WN18  151K  40K  18</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>Diverse strategies for knowledge base con- struction include manually-crafted ontologies for common-sense reasoning <ref type="bibr" target="#b5">(Lenat, 1995)</ref>, community-driven collaborative efforts <ref type="bibr" target="#b1">(Bollacker et al., 2008)</ref>, ontology-based extraction from structured and textual sources ( <ref type="bibr" target="#b8">Mitchell et al., 2015)</ref>, and "open" approaches that rely on textual information ( <ref type="bibr" target="#b7">Mausam et al., 2012)</ref>. In this paper, we contrast the properties of two knowledge graphs that have clean, human- vetted facts with two knowledge graphs that are extracted from textual data. Semantically meaningful embeddings of text have been a longstanding topic of study in NLP research <ref type="bibr" target="#b16">(Turney and Pantel, 2010)</ref>. More recently, knowledge graphs, which cap- ture structured relationships between entities, has inspired methods such as matrix factor- ization ( <ref type="bibr" target="#b14">Riedel et al., 2013)</ref>, tensor factor- ization <ref type="bibr" target="#b12">(Nickel et al., 2011)</ref>, and deep learn- ing ( <ref type="bibr" target="#b15">Socher et al., 2013</ref>) that embed enti- ties while preserving this relationship struc- ture. We consider four state-of-the-art em- bedding methods ( <ref type="bibr" target="#b2">Bordes et al., 2013;</ref><ref type="bibr" target="#b17">Wang et al., 2014;</ref><ref type="bibr" target="#b11">Nickel et al., 2016b;</ref><ref type="bibr" target="#b9">Nguyen et al., 2016)</ref> and assess their performance on knowl- edge graphs with different properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Comparing Properties of KGs</head><p>In <ref type="table">Table 1</ref>, we introduce three knowledge graphs and a parallel set of benchmark datasets derived from these KGs. Each KG takes the form of triples that specify a rela- tionship between a subject and an object. The first two KGs, Freebase and WordNet, benefit from human curation that results in precisely defined entities and relationships and highly reliable facts. The third KG, NELL, is ex- tracted from a large Web text corpus using an iterative co-training process and a pre-defined set of relations and types. Due to the itera- tive nature, NELL is a dynamic dataset and the table reports statistics of the 1000 th itera- tion. FB15K and WN18, derived from Free- base and WordNet, respectively, have been used to train and evaluate many embedding strategies. NELL165, based on an earlier iter- ation of NELL, has been used as a benchmark for probabilistic models. We compare the vital statistics of these six datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Size and Sampling</head><p>Despite the reliance on curation, Freebase is the largest KG with more facts (T ), unique entities (E), and relationship types (R) than others. NELL, is a tenth the size of Free- base with substantially fewer entities and lim- ited relations. WordNet, focused on NLP, is the smallest and expresses only 27 relation- ships between different words. The derived benchmark datasets are substantially smaller than the source KGs, with the largest, NELL, containing 1M facts. FB15K is generated by sampling a subset of the KG centered around 15K entities. WN18 is generated by restricting to 18 relations. NELL165 performs no sam- pling, but is limited by the comprehensiveness of patterns learned during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Diversity</head><p>To understand the distribution of entities and relationships in the KG, we introduce an entropy-based measure using the probability an entity or relation will occur in a randomly selected triple. For triples T of the form (s, p, o), relations R, entities E, We define the entity and relation probabilities as the proba- bility that a randomly selected triple will con- tain a particular relation or entity. More for- mally, we define these probabilities:</p><formula xml:id="formula_0">P (r) = |t.p = r| T ; P (e) = |t.s = e| + |t.o = e| T</formula><p>Using these definitions, we define:</p><formula xml:id="formula_1">RE = r∈R −P (r) log P (r)</formula><p>We compute entity entropy (EE) and rela- tion entropy (RE) for each dataset. Higher entropy values indicate more uniform distri- butions of facts across entities and relations, lower values signal biases in the facts. For example, the low RE values for Freebase and NELL165 are due to an abundance of facts specifying entity types (such as person), rela- tive to other relations between entities. While Freebase has the most facts and entities, these facts are less diverse compared to other KGs. Through sampling, FB15K rebalances Free- base, increasing the diversity of entities and relations. In contrast, WordNet and WN18 have similar diversity statistics. Compared to NELL1000, NELL165 has a more diverse set of entities and a less diverse set of relations. All KGs have much higher EE than RE, since they use a manually defined set of relations but include many diverse entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sparsity</head><p>In addition to diversity, KGs have differing lev- els of factual information for each entity or re- lation. One sparsity metric is information den- sity, defined as the average triples per entity or relation. We formally define densities:</p><formula xml:id="formula_2">RD = T R ; ED = 2T E</formula><p>We compare the datasets using entity den- sity (ED) and relational density (RD). Most datasets have a similar ED, but the benchmark dataset FB15K has much higher entity density while the benchmark dataset NELL165 has a much lower entity density. NELL1000 has the highest RD, since extractions are focused on a small set of relations, while FB15K has a particularly low RD value due to the entity- centric approach to construction. We note that FB15K has much higher ED and much lower RD than parent Freebase, due to the sampling choices made during its construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Reliability</head><p>Embedding approaches rely on using facts that are reliable. Human-curated KGs generally have high precision due to strong oversight. In contrast, extracted KGs are far noisier, in- cluding erroneous relationships between enti- ties. Extracted KGs are often evaluated on small, manually-labeled evaluation sets to esti- mate precision. In recent evaluations (Mitchell et al., 2015) using 11K annotations, NELL facts had a precision of ranging from 0.75-0.85 for confident extractions and 0.35-0.45 across the broader set of extractions.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Empirical Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Extracted Knowledge Graphs</head><p>In Section 3, we noted that the extracted NELL165 dataset is sparse, with fewer (can- didate) facts per relation or entity than the FB15K benchmarks. Moreover, the preci- sion of these candidates can be far lower than benchmark datasets. To evaluate whether embeddings can succeed under such challeng- ing conditions, we applied four state-of-the-art embedding techniques, We evaluated all methods on 4.5K manually-labeled facts ( <ref type="bibr" target="#b4">Jiang et al., 2012)</ref>, reporting the area under the precision-recall curve (AUPRC) and the F1 score, computed with parameters that maximize performance on the labeled training set. We compare against a baseline that simply applies a threshold to NELL extractor confidences (but cannot score novel facts), the NELL promo- tion strategy, and a probabilistic approach PSL-KGI ( <ref type="bibr" target="#b13">Pujara et al., 2015)</ref>, that reasons collectively about KG facts using ontological constraints and supports open-world reason- ing. The results, in <ref type="table" target="#tab_2">Table 2</ref>, suggest that embedding approaches cannot cope with the sparse and low-quality extractions, perform- ing more poorly than the baseline approaches and substantially trailing the probabilistic model. In the next two experiments, we analyze whether this failure can be attributed to sparsity or sensitivity to noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sensitivity to Sparsity</head><p>One potential explanation for the lackluster performance of embedding approaches on ex- tracted KGs is the sparsity of these datasets. To assess the impact of sparsity on the qual- ity of learned embeddings, we remove triples from FB15K using two different techniques. The first technique, sparse, removes triples uniformly at random, with a constraint that such removal does not eliminate any entity or relation from the dataset. The second tech- nique, stable, removes all triples for a par- ticular relation, leaving other relations intact. stable is calibrated so that the training set size does not vary more than 2% between tech- niques. <ref type="figure" target="#fig_0">Fig. 1</ref> shows the filtered hits@10 metric (proportion of correct triples in top ten triples excluding training data) for both sparse and stable using the TransE, TransH, HolE, and STransE embeddings. Performance univer- sally decreases as the training set diminishes. However, in the sparse treatment, perfor- mance deteriorates much more rapidly than in stable. Our experiments show that more complex representations such as TransH and HolE suffer more from sparsity, while TransE and the more sophisticated STransE have somewhat better performance. Ultimately, when half the triples have been randomly re- moved, corresponding to a (relatively high) RD value of 220, the stable outperforms sparse by as much as 60%. The contrast be- tween a dense set of facts for each relation (stable) and a sparse set of relational training data is a vivid demonstration that embedding quality relies on dense training data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Sensitivity to Unreliability</head><p>Beyond sparsity, candidate facts generated by knowledge extraction approaches can also be unreliable. To understand the sensitivity of embedding techniques to noise, we modi- fied the FB15K dataset to include unreliable triples. Our approach to introducing noise, corrupt involved "corrupting" triples, substi- tuting a replacement entity or relation for the true subject, predicate or object. The embed- ding approach is then trained with a corrupted version of the benchmark. <ref type="figure" target="#fig_1">Fig. 2</ref> show how the Hits@10 metric suffers as increasing numbers of facts are either corrupted (corrupt) or re- moved (sparse). We find that across all meth- ods, removing training data is better than pro- viding incorrect training data to the learning algorithm, but surprisingly the deficit between sparse and corrupt remains relatively stable across all embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Trading off Sparsity and Noise</head><p>In many real-world scenarios, constructing a KG requires navigating a tradeoff between sparsity and noise. A sparse, high-quality set of extractions may be insufficient to learn meaningful embeddings. However, the bene- fit of incorporating additional, unreliable facts may also be questionable. We explore this tradeoff by randomly removing 300K triples from FB15K and incrementally adding unre- liable triples at differing noise levels, where noise measures the probability a newly-added training triple is corrupted. We generate train- ing sets for each noise level and size, train TransE, and compute the filtered Hits@10 metric on the test set. <ref type="figure" target="#fig_1">Fig. 2</ref> shows all embed- dings have an initial benefit from new training data, but noise level dictates the improvement as more data is introduced. For low noise settings, performance climbs steadily, while higher noise results in plateauing or diminish- ing performance. Surprisingly, even with 90% noise embeddings demonstrate a small net improvement, suggesting that for embedding methods a large, unreliable corpus may be bet- ter than an extremely sparse, high-quality one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we analyze several knowledge graphs and discuss key metrics for diversity, sparsity, and unreliability in realistic KGs. Our experimental evaluation concludes that KG embeddings are sensitive to sparse and unreliable data, and perform poorly on KGs extracted from text. These findings suggest a rich area of future research, determining new strategies to extend embeddings to cope with sparse and unreliable data. Three promising approaches include revising the closed-world assumption frequently used in training em- beddings, combining embeddings and collec- tive probabilistic models that perform well on extracted KGs, and devising an optimization approach for embeddings that exploits confi- dence from knowledge extraction systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Triples are removed from FB15K to preserve relational density (stable, solid) or to increase sparsity (sparse, dotted). Sparse training sets have a pronounced impact on the learned embedding, as measured by HITS@10 on the test set.</figDesc><graphic url="image-1.png" coords="4,318.19,62.81,196.43,171.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Randomly corrupting triples (corrupt, dashed) during training decreases embedding quality relative to randomly removing triples (sparse, dotted).</figDesc><graphic url="image-2.png" coords="5,72.00,62.81,218.27,188.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Starting with a sparse training set, adding unreliable triples can help embedding performance recover if the noise level is low.</figDesc><graphic url="image-3.png" coords="5,307.28,62.81,218.25,188.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Embedding performance on the sparse and 

noisy NELL165 benchmark is poor, failing to beat a 
baseline that simply selects the top extractions, and 
substantially underperforming probabilistic models. 

</table></figure>

			<note place="foot" n="1"> Code for experiments is available at https://www. github.com/linqs/pujara-emnlp17</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic Parsing on Freebase from Question-Answer Pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Translating Embeddings for Modeling Multi-relational Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garciaduran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Knowledge Vault: A Web-Scale Approach to Probabilistic Knowledge Fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geremy</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilko</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to Refine an Automatically Extracted Knowledge Base Using Markov Logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shangpu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejing</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cyc: A large-scale investment in knowledge infrastructure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Douglas B Lenat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning Entity and Relation Embeddings for Knowledge Graph Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Open Language Learning for Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Betteridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Platanios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Samadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wijaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saparov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Greaves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Welling</surname></persName>
		</author>
		<title level="m">Never-Ending Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>AAAI</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">STransE: A Novel Embedding Model of Entities and Relationships in Knowledge Bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kairit</forename><surname>Dat Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Sirts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Review of Relational Machine Learning for Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Holographic Embeddings of Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Using Semantics &amp; Statistics to Turn Data into Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<pubPlace>AI Magazine</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin M</forename><surname>Marlin</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">From frequency to meaning: Vector space models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAIR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Knowledge Graph Embedding by Translating on Hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
