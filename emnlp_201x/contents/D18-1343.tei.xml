<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Multi-View Learning: Multilingual and Multi-Representation Entity Typing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Montreal</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">LMU Munich Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sch¨</forename><surname>Schütze</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">LMU Munich Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Multi-View Learning: Multilingual and Multi-Representation Entity Typing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3060" to="3066"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3060</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Knowledge bases (KBs) are paramount in NLP. We employ multiview learning for increasing accuracy and coverage of entity type information in KBs. We rely on two metaviews: language and representation. For language, we consider high-resource and low-resource languages from Wikipedia. For representation , we consider representations based on the context distribution of the entity (i.e., on its embedding), on the entity&apos;s name (i.e., on its surface form) and on its description in Wikipedia. The two metaviews language and representation can be freely combined: each pair of language and representation (e.g., Ger-man embedding, English description, Spanish name) is a distinct view. Our experiments on entity typing with fine-grained classes demonstrate the effectiveness of multiview learning. We release MVET, a large multiview-and, in particular, multilingual-entity typing dataset we created. Mono-and multilingual fine-grained entity typing systems can be evaluated on this dataset.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Accurate and complete knowledge bases (KBs) are paramount in NLP. Entity typing, and in par- ticular fine-grained entity typing, is an important component of KB completion with applications in NLP and knowledge engineering. Studies so far have been mostly for English <ref type="bibr" target="#b21">(Yaghoobzadeh and Schütze, 2015)</ref>, but also for Japanese ( <ref type="bibr" target="#b15">Suzuki et al., 2016)</ref>.</p><p>We employ multiview learning for increasing accuracy and coverage of entity type information in KBs. We rely on two metaviews: language and representation. For language, we take high-and low-resource languages from Wikipedia. For rep- resentation, we consider representations based on the context distribution of the entity (i.e., on its embedding), on the entity's name (i.e., on its sur- face form) and on its description in Wikipedia. The two metaviews language and representation can be freely combined: each pair of language and representation (e.g., German embedding, English description, Spanish name) is a distinct view.</p><p>Views are defined as kinds of information about an instance that have three properties <ref type="bibr" target="#b1">(Blum and Mitchell, 1998;</ref><ref type="bibr" target="#b18">Xu et al., 2013)</ref>. (i) Sufficiency. Each view is sufficient for classification on its own. (ii) Compatibility. The target functions in all views predict the same labels for cooccurring features with high probability. (iii) Conditional independence. The views are conditionally inde- pendent given the class label.</p><p>As in most cases of multiview learning, these three properties are only approximately true for our problem. (i) Not every view is sufficient for every instance. While a name like "George Wash- ington Bridge" is sufficient for typing the entity as "bridge", the name "Washington" is not suffi- cient for entity typing. (ii) Cases of incompatibil- ity exist. For example, the "Bering Land Bridge" is not a bridge. (iii) Views have some degree of conditional dependence. For example, if a bridge is a viaduct, not a bridge proper, then the descrip- tion of the bridge will contain more occurrences of the word "viaduct" than for proper bridges whose name does not contain the word "viaduct".</p><p>In summary, we make three main contributions. (i) We formalize entity typing as a multiview prob- lem by introducing two metaviews, language and representation; each combination of instances of these two metaviews defines a distinct view. (ii) We show that this formalization is effective for en- tity typing as a key task in KB completion: mul- tiview and crossview learning outperform single- view learning by a large margin, especially for rare entities and low-resource languages. (iii) We re- lease MVET (Multiview Entity Typing), a large multiview and, in particular, multilingual dataset, for entity typing <ref type="bibr">1</ref> . This dataset can be used for mono-and multilingual fine-grained entity typing evaluations. In contrast to prior work on entity typing based on Clueweb (a commercial corpus), all our data can be released publicly because it is based on Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Multilingual Multi-Representation Entity Typing</head><p>We address the task of entity typing <ref type="bibr" target="#b21">(Yaghoobzadeh and Schütze, 2015)</ref>, i.e., as- signing to a given entity one or more types from a set of types T . E.g., Churchill is a politician and writer.</p><p>Our key idea is that we can tap two different information sources for entity typing, which we will refer to as metaviews: language and repre- sentation. For the language metaview, we con- sider N languages (English, German, . . . ). For the representation metaview, we consider three repre- sentations: based on the entity's context distribu- tion, based on its canonical name and based on its description. Each combination of language and representation defines a separate view of the en- tity, i.e., we have up to 3N views. The views are not completely independent of each other: what is written about an entity in English and German is correlated and information derived from the entity name is correlated with its description; see discus- sion in §1. Still, each view contains information complementary to each other view.</p><p>For the context view of the representa- tion metaview, we use entity embeddings <ref type="bibr" target="#b21">(Yaghoobzadeh and Schütze, 2015)</ref>: each mention of an entity in Wikipedia -identified using Wikipedia hyperlinks -is replaced by the entity's unique identifier. We can then run standard embedding learning. For the name view, we take the sum of the embeddings of the words of the entity name. The description view is based on the entity's Wikipedia page; see §3.</p><p>We represent view j of an entity e as the vector or embedding v j ∈ R d j . We combine these em- beddings into a multiview representation p ∈ R d of entity e. As discussed above, each v j con- tributes potentially complementary information.</p><p>After learning p, a one-hidden-layer perceptron computes the type predictionsˆypredictionsˆ predictionsˆy ∈ R |T | :</p><formula xml:id="formula_0">ˆ y = σ W o f W h p (1) f is leaky rectifier, W h ∈ R h×d , W o ∈ R |T |×h .</formula><p>The cost function is binary cross entropy summed over types and training examples:</p><formula xml:id="formula_1">i,t (y i,t log(ˆ y i,t ) + (1−y i,t )(log(1−ˆ y i,t ))) (2)</formula><p>where y i,t andˆyandˆ andˆy i,t are the gold and prediction for type t of example i.</p><p>A simple and effective way of computing the representation p of an entity is what we refer to as MULTIVIEW-CON: a concatenation of the n view embeddings, followed by a non-linear trans- formation:</p><formula xml:id="formula_2">p = tanh(W 1 [v 1 ; v 2 ; ...; v n ] )</formula><p>where</p><formula xml:id="formula_3">W 1 ∈ R d×(Σ n j=1 d j ) is the transformation matrix.</formula><p>Concatenation may not be effective because some entities have pages in all Wikipedias and thus have 200 × 3 = 600 views whereas others occur only in one. Also, the views might have dif- ferent qualities. Therefore, we consider attention- based weighted average or MULTIVIEW-ATT as an alternative to MULTIVIEW-CON. Embed- dings v j live in different spaces, so we first trans- form them using language specific matrices W j ∈ R d×d j :</p><formula xml:id="formula_4">p j = tanh(W j v j )<label>(3)</label></formula><p>Then, we compute the attention weights:</p><formula xml:id="formula_5">α j = softmax(a T p j )</formula><p>where a ∈ R d is a vector that is trained to weight the vectors p j . The MULTIVIEW-ATT repre- sentation is then defined as:</p><formula xml:id="formula_6">p = j α j p j</formula><p>A schematic architecture is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. We also experiment with two alternatives. MULTIVIEW-AVG: We set all α j = 1/n, i.e., the entity representation is a simple average. MULTIVIEW-MAX: We apply per-dimension maxpooling, p i = max j p j i . The idea here is to capture the most significant features across views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset and Experiments</head><p>In this section, we first introduce our new dataset and then describe our results.</p><p>Multiview entity typing (MVET) dataset. Wikipedia and Freebase are our sources for cre- ation of MVET. We try to map each English Wikipedia article of an entity to Freebase. Free- base types are mapped to 113 FIGER tags ( <ref type="bibr" target="#b8">Ling and Weld, 2012)</ref>. We use Wikipedia interlin- gual links to build multilingual datasets by iden- tifying corresponding Wikipedia articles in non- English languages. So for each entity, we have the English article name as well as the names in other languages (if they exist) and FIGER types of the entity. We use these multilingual names and Wikipedias to build our representation views as described in §3.</p><p>We experiment with ten languages: English (EN), German (DE), Farsi (FA), Spanish (ES); and Arabic (AR), French (FR), Italian (IT). Pol- ish (PL), Portuguese (PT), Russian (RU). The pro- cedure described above gives us around 2M enti- ties. We divide them into train (50%), dev (20%) and test (30%) and, for efficient training, sample them stratified by type to ensure enough entities per type. The final dataset used in our experiments contains about 74k / 35k / 50k train / dev / test enti- ties and 102 FIGER types. Dev is used to optimize model hyperparameters. Appendix A gives some more statistics for MVET.</p><p>Learning representation views. We refer to the three instances of the representation metaview (see §1) as CTXT (contexts), NAME (name) and DESC (description).</p><p>For learning CTXT embeddings, we train WANG2VEC ( <ref type="bibr" target="#b7">Ling et al., 2015</ref>) on Wikipedia after having replaced hyperlinked mentions of an entity with its ID. NAME is derived from publicly avail- able 300-dimensional fastText ( <ref type="bibr" target="#b2">Bojanowski et al., 2017)</ref> embeddings. We use the average of the words in a name as its NAME embedding 2 . If a word does not have a fastText embedding, we ap- ply the fastText model to compute it. So there are no unknown words in our dataset. For DESC, we extract the keywords (using tf-idf) of the first para- graph of the Wikipedia article of an entity. The DESC embedding is the average fastText embed- ding of the keywords.</p><p>To reiterate the complementarity of the three representation views: names are ambiguous, but if we use the names of an entity in different lan- guages, we can mitigate this ambiguity. E.g., "Ap- ple" can refer to an entity or a fruit in English, but only to an entity in French. Similarly, the descrip- tion of an entity is a high quality textual source to extract information from. The simplest case of complementarity is that not all views are available. An entity can be completely missing from one of the languages; it may not have a description be- cause only a stub is provided; etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results</head><p>Evaluation metric. Following prior work in en- tity typing , we evaluate by micro F 1 , a global summary score of all system predictions. Entity frequency is an im- portant variable, so we report results for tail (fre- quency &lt;10, n=35,533), head (frequency &gt;100, n=2,638) and all entities. <ref type="table">Table 1</ref> shows results for entity typing on our dataset, MVET. We start with FIGMENT ) baseline re- sults on MVET dataset (line 0), which is the state- of-the-art system in entity typing. FIGMENT is equivalent to our MULTIVIEW-CON model with only English-CTXT, -NAME and -DESC repre- sentations.</p><p>Lines 1-4, 9-12, 17-20 are singleview results, e.g., F 1 for tail is 62.0 for the English-CTXT view. Lines 5-8, 13-16, 21-24 combine the four lan- guages; so these are multiview results for the lan- guage metaview. All four multiview models are better than the corresponding singleview models in the same block. Lines 25-28 show results for the combination of the two metaviews; a total of twelve views are combined (four languages times three representations). The multi-multi-view mod- els on lines 25-28 outperform all other results. Comparing line 25 and FIGMENT (line 0), adding representations from three more languages result in .5%, .4%, .9% improvements for all, tail and head entities. Line 26 by using ATT improves the results further especially for the tail entities. These results confirm the effectiveness of our contribu- tions: adding language as a metaview, and using ATT instead of CON to combine multiple views.</p><p>Lines <ref type="bibr">[29]</ref><ref type="bibr">[30]</ref><ref type="bibr">[31]</ref><ref type="bibr">[32]</ref> show results for using NAME rep- resentations in six additional languages: AR, FR, IT, PL, PT, RU. F 1 is up to more than one percent better than on lines 13-16. This demonstrates the benefit of using more languages -although the ef- fect is limited since only the long tail of entities can improve.</p><p>Lines 33-36 vs. lines 25-28 make the same comparison (NAME4 vs. NAME10) for multi- multi-view. By ATT, we get a small improvement for tail, but not for head (line 34 vs. line 26). Ap- parently, there is noise added by considering more languages and this hurts the results for head enti- ties.</p><p>A general tendency is that ATT performs better compared to MAX, AVG and CON as the number of views increases (lines 30 and 34) and so the av- erage number of views without information (i.e., missing views) for an entity increases. In contrast to MAX, ATT can combine different views. In contrast to CON and AVG, ATT can ignore some of them based on low attention weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Analysis: Crossview Learning</head><p>To analyze whether sharing parameters across views is important, <ref type="table" target="#tab_2">Table 2</ref> compares (i) SIN- GLE: twelve different singleview models with (ii) CROSS: a single crossview model that is trained on a training set that combines the twelve indi- vidual singleview training sets. For CROSS, we use Eq. 3 with view specific transformation matri- ces, mapping views in different spaces into a com- mon space, and then Eq. 1 with shared parameters across views. The number of parameters in appli- cation is the same for SINGLE and CROSS. <ref type="table" target="#tab_2">Table 2</ref> shows consistent and clear improve- ments of CROSS compared to SINGLE, ex- cept for English CTXT and NAME. The English Wikipedia is much larger than the others, so that embeddings based on it have high quality. But our  results demonstrate that training one model with common parameters over all inputs is helping the classification for non high-resource views.</p><p>Multiview learning exploits the complementar- ity of views: if an entity's type cannot be inferred from one view, then other views may have the re- quired information. <ref type="table" target="#tab_2">Table 2</ref> shows that using mul- tiple views has a second beneficial effect: even if applied to a single view, a model trained on mul- tiple views performs better. <ref type="bibr" target="#b5">Kan et al. (2016)</ref>'s image recognition and Pappas and Popescu-Belis (2017)'s document classification findings are sim- ilar. Thus, not only does the increased amount of available information boost performance in the multiview setup, but also we can enable crossview transfer and learn a model that makes better pre- dictions even if information is only available from a single view.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Entity and mention typing. In this work, we as- sume that a predefined set of fine-grained types is given. Entity typing, i.e., predicting types of a knowledge base entity ( <ref type="bibr" target="#b10">Neelakantan and Chang, 2015;</ref><ref type="bibr" target="#b21">Yaghoobzadeh and Schütze, 2015)</ref>, is the focus of this paper. Mention typing, i.e., pre- dicting types of a mention in a particular con- text ( <ref type="bibr" target="#b8">Ling and Weld, 2012;</ref><ref type="bibr" target="#b13">Rabinovich and Klein, 2017;</ref><ref type="bibr" target="#b14">Shimaoka et al., 2017;</ref><ref type="bibr" target="#b9">Murty et al., 2018</ref>), is a related task. Mention typing models can be evaluated for entity typing when aggregating their predictions ( <ref type="bibr" target="#b21">Yaghoobzadeh and Schütze, 2015;</ref><ref type="bibr" target="#b19">Yaghoobzadeh et al., , 2018</ref>. Therefore, our public and large entity typing dataset, MVET, can be used as an alternative to the small manually annotated mention typing datasets like the com- monly used FIGER ( <ref type="bibr" target="#b8">Ling and Weld, 2012</ref>). We leave this to the future work. Multilingual entity typing. We build multilin- gual dataset and models for entity typing. Most work on entity typing has been monolingual; e.g., <ref type="bibr">Yaghoobzadeh and Schütze (2015) (English);</ref><ref type="bibr">and Suzuki et al. (2016) (Japanese)</ref>. There is work on mention typing <ref type="bibr" target="#b3">(van Erp and Vossen, 2017)</ref>. <ref type="bibr" target="#b6">Lin et al. (2017)</ref> that uses mono-and crosslin- gual attention for relation extraction. Crosslingual entity linking is an important related task, where the task is to link mentions of entities in multi- lingual text to a knowledge base <ref type="bibr" target="#b16">(Tsai and Roth, 2016</ref>). Many entities are not sufficiently anno- tated in Wikipedia, and therefore crosslingual en- tity linking is necessary to learn informative con- text representations from multiple languages.</p><p>Multi-representation of entities. Aggregat- ing information from multiple sources to learn entity representations has been explored for en- tity typing <ref type="bibr" target="#b19">Yaghoobzadeh et al., 2018)</ref>, entity linking ( <ref type="bibr" target="#b4">Gupta et al., 2017</ref>) and relation extraction ( <ref type="bibr" target="#b17">Wang and Li, 2016)</ref>. Here, we add language as a new "dimen- sion" to multi-representations: each language con- tributes a different CTXT, NAME and DESC rep- resentation.</p><p>Our multilingual and multi-representation mod- els are examples of multiview learning. <ref type="bibr" target="#b18">Xu et al. (2013)</ref> and <ref type="bibr" target="#b23">Zhao et al. (2017)</ref> review the litera- ture on multiview learning. <ref type="bibr" target="#b0">Amini et al. (2009)</ref> cast multilingual text classification, a task related to entity typing, as multiview learning. <ref type="bibr" target="#b12">Qu et al. (2017)</ref> address node classification and link predic- tion by attention-based multiview representations of graph nodes. We also adopt a similar approach in our multiview representations for entity typing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We formalized entity typing as a multiview prob- lem by introducing two metaviews, language and representation; each combination of their in- stances defines a distinct view. Our experiments showed the effectivess of this formalization by outperforming the state-of-the-art model. Our ba- sic idea of metaview learning is general and is ap- plicable to related tasks, e.g., to relation extrac- tion. We release a large and public multiview and, in particular, multilingual, entity typing dataset.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A MVET Dataset Statistics</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Attention-based multiview learning. View specific representations v j of the entity are transformed to a shared space and summed by attention weights α j into aggregated multiview representation p. A onehidden-layer perceptron computes output vectorˆyvectorˆ vectorˆy.</figDesc><graphic url="image-1.png" coords="2,76.82,72.77,208.62,137.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>all</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>CTXT</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Micro F 1 (all entities) for twelve singleview 
models (SINGLE) and one crossview model (CROSS) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>The statistics of our MVET dataset for each 
language and representation view. The total number of 
entities is 160,083 with 102 types. </table></figure>

			<note place="foot" n="1"> Our dataset and code are available at: http:// github.com/yyaghoobzadeh/MVET</note>

			<note place="foot" n="2"> Some of the Wikipedia titles contain a category inside parentheses, e.g.., &quot;Washington (state)&quot;. We remove these parentheses and their content from the titles, if they exist, and then use the titles as our names.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Ehsaneddin Asgari, Katharina Kann, T.J. Hazen and the anonymous reviewers for their helpful feedback on earlier drafts. This work was partially supported by the European Re-search Council, Advanced Grant NonSequeToR # 740516.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning from multiple partially observed views-an application to multilingual text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massih-Reza</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems</title>
		<meeting>the Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="28" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Combining labeled and unlabeled data with co-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avrim</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh Annual Conference on Computational Learning Theory</title>
		<meeting>the Eleventh Annual Conference on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multilingual fine-grained entity typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piek</forename><surname>Marieke Van Erp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language, Data, and Knowledge-First International Conference</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="262" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Entity linking via joint encoding of types, descriptions, and context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2681" to="2690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-view deep network for cross-view classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meina</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 2016 IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4847" to="4855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural relation extraction with multi-lingual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Two/too simple adaptations of word2vec for syntax problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings fo the 2015 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>fo the 2015 Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1299" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fine-grained entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Sixth AAAI Conference on Artificial Intelligence<address><addrLine>Toronto, Ontario, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hierarchical losses and new resources for fine-grained entity typing and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Murty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irena</forename><surname>Radovanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="97" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="515" to="525" />
		</imprint>
	</monogr>
	<note>ferring missing entity type instances for knowledge base completion: New dataset and methods</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multilingual hierarchical attention networks for document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Popescu-Belis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Joint Conference on Natural Language Processing</title>
		<meeting>8th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An attentionbased collaboration framework for multi-view network representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM Int. Conf. on Information and Knowledge Management</title>
		<meeting>the 2017 ACM Int. Conf. on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Fine-grained entity typing with high-multiplicity assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno>abs/1704.07751</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Neural architectures for fine-grained entity type classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonse</forename><surname>Shimaoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1271" to="1280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Finegrained named entity classification with wikipedia article vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koji</forename><surname>Matsuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE/WIC/ACM International Conference on Web Intelligence</title>
		<meeting><address><addrLine>WI; Omaha, NE, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-10-13" />
			<biblScope unit="page" from="483" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cross-lingual wikification using multilingual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="589" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Text-enhanced representation learning for knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan-Zi</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-07" />
			<biblScope unit="page" from="1293" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A survey on multi-view learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<idno>abs/1304.5634</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Corpus-level fine-grained entity typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schuetze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="835" to="862" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Noise mitigation for neural entity typing and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1183" to="1194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Corpus-level fine-grained entity typing using contextual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="715" to="725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-level representations for fine-grained typing of knowledge base entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="578" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-view learning overview: Recent progress and new challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xijiong</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiliang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="43" to="54" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
