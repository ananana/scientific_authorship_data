<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Somm: Into the Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengli</forename><surname>Hu</surname></persName>
							<email>sh2264@cornell.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Somm: Into the Model</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1153" to="1159"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1153</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>To what extent could the sommelier profession , or wine stewardship, be displaced by machine learning algorithms? There are at least three essential skills that make a qualified sommelier: wine theory, blind tasting, and beverage service, as exemplified in the rigorous certification processes of certified somme-liers and above (advanced and master) with the most authoritative body in the industry, the Court of Master Sommelier (hereafter CMS). We propose and train corresponding machine learning models that match these skills, and compare algorithmic results with real data collected from a large group of certified wine professionals. We find that our machine learning models outperform human sommeliers on most tasks-most notably in the section of blind tasting, where both hierarchically supervised Latent Dirichlet Allocation outperforms sommeliers&apos; judgment calls by over 6% in terms of F1-score; in the section of beverage service-wine and food pairing, a modified Siamese neural networks based on BiLSTM achieves better results than sommeliers by 2%. This demonstrates, contrary to popular opinion in the industry, that the sommelier profession is at least to some extent automatable, barring economic (Kleinberg et al., 2017) and psychological (Dietvorst et al., 2015) complications.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction and Related Work</head><p>Thanks to the Somm documentaries and a gen- eral increase in awareness about wine, somme- liers, and the Court of Master Sommeliers, there is now a certain celebrity status, a glamor associ- ated with becoming a sommelier. When encoun- tered with the question -"is the sommelier pro- fession going to be negatively affected by recent advances in machine learning and artificial intel- ligence?" during informal interviews conducted by authors in the sommelier community, there ap- pears to be a general consensus among profession- als that the high standards of hospitality upheld by qualified sommeliers are well beyond the capabil- ities of machines.</p><p>The current study asks the question, to what ex- tent would the sommelier profession be displaced by machine learning algorithms? What aspects of the sommelier profession could be outperformed, and therefore perhaps displaced by what kinds of applications of machine learning?</p><p>What makes a qualified sommelier or wine pro- fessional? According to the Court of Master Som- melier 1 , one of the two organizations held in the highest esteem in the global industry, there are at least three indispensable components as exempli- fied in the certification exams leading up to the Master Sommelier diploma: theory, blind tasting, and service.</p><p>To satisfy the theoretical requirement, somme- lier candidates are required to sit on a timed exam of various questions covering a wide range of wine topics including geography, soil, viticulture, laws, history, language, etc. without any officially struc- tured study guides 2 . We argue that this particu- lar task maps to the stream of research concern- ing open-domain Question Answering (hereafter, OQA), where the model is given a question and access to a large corpus <ref type="bibr">(Chen et al., 2017)</ref>, com- bining and therefore leveraging both the Informa- tion <ref type="bibr">Retrieval (Weinberger et al., 2009</ref>) and Ma- chine Comprehension literature ( <ref type="bibr" target="#b3">Hermann et al., 2015;</ref><ref type="bibr">Chen et al., 2016)</ref>. In Section 3, we train an open-domain QA model building upon <ref type="bibr">Chen et al. (2017)</ref>, on a large corpus of wine topics drawn from recommended study resources by CMS. We contrast the machine performance with somme- liers' performance on equivalent test questions.</p><p>To satisfy the blind tasting requirement, candi- dates have to blind taste a flight of wines, pre- cisely describe the wine, and accurately identify the grape varietal, the region (thus the country), the vintage, and the quality level of each. Accord- ing to wine programs such as CMS or WSET 3 , blind tasting consists of two steps -tasting and deduction. Tasting refers to the sensory experience associated with evaluating wines -color, aroma, favor, aftertaste, etc. Proficient candidates are ex- pected be able to detect a wide range of charac- teristics of the focal wine, and precisely describe the wine with meaningful descriptors accordingly. Deduction is the logical process that leads the can- didate to conclude on the identity of the wine given the characteristics he detects in the first step. Ac- cording to wine educators and master sommeliers such as Geoff Kruth M.S., it is the deduction part of blind tasting that separates great blind tasters from mediocre ones, mostly due to the fact that it requires greater logical thinking and reasoning. We propose that the deduction step maps exactly to the machine learning task of structured predic- tion ( <ref type="bibr" target="#b17">Taskar et al., 2005;</ref><ref type="bibr">Belanger and McCallum, 2016;</ref><ref type="bibr">Barutcuoglu et al., 2006;</ref><ref type="bibr" target="#b14">Rousu et al., 2006</ref>). In Section 4, we demonstrate that a hi- erarchical supervised Latent Dirichlet Allocation model <ref type="bibr" target="#b11">(Perotte et al., 2011;</ref><ref type="bibr" target="#b9">Nguyen et al., 2013</ref>) trained on a large corpus of textual descriptions of wines of different grape varietals, regions, vin- tages, and quality levels, outperforms sommeliers in deduction by a large margin.</p><p>To satisfy the service requirement, candidates are grilled on questions of wines and spirits, food and wine pairing, salesmanship, and service me- chanics in a restaurant setting. In Section 5, we showcase a modified Siamese Neural Net- work ( <ref type="bibr" target="#b7">Mueller and Thyagarajan, 2016;</ref><ref type="bibr" target="#b8">Neculoiu et al., 2016;</ref><ref type="bibr" target="#b10">Pei et al., 2016;</ref><ref type="bibr">Bertinetto et al., 2016</ref>) coupled with Bidirectional Long Short-term Memory Networks <ref type="bibr" target="#b4">(Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr" target="#b16">Schuster and Paliwal, 1997;</ref>) trained on corpora of wine reviews <ref type="bibr" target="#b2">(Hendrickx et al., 2016)</ref> and cook- ing recipes ( <ref type="bibr" target="#b18">Tasse and Smith, 2008;</ref><ref type="bibr" target="#b5">Jermsurawong and Habash, 2015)</ref> outperforms sommeliers' per- <ref type="bibr">3</ref> Wine &amp; Spirit Education Trust formance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data Collection and Preprocessing</head><p>Our datasets consist of three parts: (1) Study Re- sources: a large corpus consisting of all the rec- ommended resources for sommelier certification by the CMS, for the Question Answering -The- ory Component detailed in Section 3; (2) Wine Reviews: a massive repository of expert wine re- views with rich meta-data, based on reviews from Decanter, Vinous, Wine Spectator, and Wine En- thusiast, the four widely recognized media outlets in the industry, for the Structured Prediction - Deduction in Blind Tasting Component detailed in Section 4; (3) Survey Responses from 1, 305 certi- fied wine professionals, covering topics on theory, deductive tasting, and wine and food pairing, thus providing experts' performance data with which we compare results from our corresponding ma- chine learning models in Section 3, Section 4, and Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing</head><p>The study resource dataset consists of documents of various categories and topics from the Guild- Somm. We treat texts under each sub-category as a document -there are 752 documents in our dataset and the average length of documents is 1, 384 words.</p><p>For the wine review dataset, we only consider wines for which we had at least 200 reviews in the training set, leading to 850, 119 reviews com- bined. When different names were used for the same grape, we normalize these to the same cat- egory. For instance, Pinot Bianco (Italy), Pinot Blanc (France), and Weissburgunder (Germany) are mapped together and renamed Pinot Blanc ac- cording to the wine grape encyclopedia <ref type="bibr" target="#b13">(Robinson et al., 2013;</ref><ref type="bibr" target="#b12">Robinson and Harding, 2015)</ref>. We preprocessed all the text data in standard proce- dures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Summary of Datasets</head><p>We plot the country and point distributions of our review dataset in <ref type="figure" target="#fig_1">Figure 1</ref> , grouped by media out- let. Interestingly, Vinous appears proportionally much more focused on Italian wines and its ratings are more skewed to the right compared to others (a.k.a. greater rating inflation), somehow contrary to the brand image; Wine Spectator is much more focused on Old World whereas Wine Enthusiast is more evenly distributed across countries.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Survey Details</head><p>We administered timed online surveys to wine pro- fessionals in several active sommelier communi- ties such as the Guild of Sommeliers, the Society of Wine Educators, etc. Each survey consists of three sections that correspond to the three com- ponents respectively -theory, deductive tasting, and pairing. Each section lasts no longer than 15 minutes and consists of 30 questions, randomly drawn from a large pool of practice questions from the Guild of Sommeliers and the Society of Wine Educators.</p><p>In the first section, we administered two sets of</p><note type="other">questions varying difficulty level -one on the level of certified sommelier (CMS level 2), the other on the level of advanced sommelier (CMS level 3). The Question Answering (wine theory) pool consists of 1, 400 questions (700 equivalent to level 2 difficulty, 700 equivalent to level 3 dif- ficulty) from Society of Wine Educators' Certified Specialist of Wine and Certified Specialist of Spir- its programs, and 1, 480 questions (740 at level 2 difficulty and 740 at level 3 difficulty) from Guild of Sommelier practice repository. 2, 304 questions were used for training, and the rest for testing. In the second section, we randomly drew 30 textual descriptions from our</note><p>pool of 850, 119 reviews de- tailed in Section 2, and asked the subject to deduce the varietal, vintage range, region, and quality level of the wine being described. In the third sec- tion, we randomly drew 30 wines (Title and Tast- ing note) from the repository of wine reviews and 30 recipes from the CMU Recipe Database CURD ( <ref type="bibr" target="#b18">Tasse and Smith, 2008)</ref>, and asked the subject to rate the pairings on a scale from 1 to 5. We circulated our survey to members of the Guild of Sommeliers and Society of Wine Educators com- munities and received 1, 412 responses. The first section of theory questions serves not only as a dataset compared against QA models, but also as a validation and screening procedure: we removed the responses with fewer than 18 4 correct answers to the 30 questions in section 1, reducing our sam- ple size to 1, 305. Sommelier scores were calcu- lated aggregating all the participants' answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Wine Theory: open-domain Question Answering</head><p>We implemented an open-domain Question An- swering system modeled after <ref type="bibr">Chen et al. (2017)</ref>, consisting of a Document Retriever module and a Document Reader module. The Document Retriever module finds the three most relevant documents by comparing docu- ments and questions as TF-IDF weighted bag-of- word vectors that include bigrams. We also adopt the hashing of <ref type="bibr" target="#b19">Weinberger et al. (2009)</ref> for map- ping bigrams with an unsigned murmur3 hash. The Document Reader module is essentially a bidirectional Long Short-term Memory Network (BiLSTM) <ref type="bibr" target="#b4">(Hochreiter and Schmidhuber, 1997;</ref>) applied to each paragraph in relevant documents, the predicted answers of which are finally aggregated. For detailed proce- dures of implementation, we refer readers to <ref type="bibr">Chen et al. (2017)</ref>. The only differences are, our batch size is 25 and we adopted a dropout rate of 0.1. We document the results in <ref type="table">Table 1</ref>. Surprisingly, our OQA results converge to the high levels of accuracies achievable by machine comprehension models. We argue that it is because our corpus is relatively small and concentrated on wine-related topics, which results in few complications arising from the integration of large-scale information re- trieval and machine comprehension, and therefore more germane to single machine comprehension models. Note that we removed survey results be- low 60% accuracy, stacking the odds against us because now the sommeliers' performance results are inflated, which could provide partial explana- tions for OQA being behind. The comparison still looks promising, despite the 4.8% disparity in per- formance. Comparing the accuracies across regions, we find sommeliers did much better than DrQA in old world regions while DrQA edged out on most new world regions. It might echo the greater emphasis of sommelier training in real life on the old world, and/or reflect the more complications introduced by French, Italian, German, and Spanish termi- nologies which we didn't correct for when dealing with the old world wine regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Blind Tasting: HSLDA</head><p>We implemented the Hierarchically Supervised Latent Dirichlet Allocation (HSLDA) model <ref type="bibr" target="#b11">(Perotte et al., 2011</ref>) for deduction in blind tasting based on textual descriptions of wines, because of the natural fit in-between -the texts describ- ing wines are hierarchically (from top to bottom: grape varietal, country, region, vintage, quality) and multiply (blends vs. monovarietals)) labeled bag-of-word (simple and performant for reviews) data. For model details, we refer readers to <ref type="bibr" target="#b11">Perotte et al. (2011)</ref>. We use the subset of wine reviews published in Wine Enthusiast and De- canter for this task. It contains 183, 660 wine descriptions for training and 39, 150 for testing. There are 41.1 terms on average in each docu- ment, with a 11.6 standard deviation. There are 12, 132 unique (sub-)categories in the form of "Sangiovese, Italy, Tuscany, 2015, Riserva". We use a Gaussian prior over the regression parame- ters where a range of values for µ, the mean prior parameter for regression coefficients are evaluated (µ ∈ {−3, −2.5, −2, . . . , 1}). We set the num- ber of topics to 20 based on small sample testing and CMS tasting grid. Prior distributions of hy- perparameters are gamma distributed with a shape parameter of 1 and a scale parameter of 1, 000.</p><p>Initial results were less satisfying and most er- rors occurred because mono-varietals were pre- dicted to be blends and vice versa. Therefore we explored two solutions: (1) we separated our data into mono-varietals (Model 1), and blends (Model 2), and trained HSLDAd separately; (2) we cre- ated a smaller yet more balanced training set re- garding mono-varietals and blends (Model 3).</p><p>In Model 1, we simplified "testable" (i.e., in- cluded in Court of Master Sommelier tasting ex- ams) blends in our dataset such as "Southern Rhone red blend", "Marsanne Roussanne blend", "Sangiovese blend", and such were treated the same as the mono-varietals. Model 2 and 3 were trained using the exact blending grape varietals. We believe Model 1 is closest to the decision mak- ing processes encountered by sommeliers in CMS certification exams, whereas Model 3 is more likely to resemble sommelier challenges such as Top Somm.</p><p>We computed precision and recall of all the cat- egories, yielding a 12, 132 × 12, 132 sparse confu- sion matrix for Model 3, a 11, 672×11, 672 sparse confusion matrix for Model 1, and a 386 × 386 confusion matrix for Model 2. We then aver- aged them to get a single real number measure- ment. <ref type="table" target="#tab_2">Table 2</ref> shows the average F1 scores of different models versus sommeliers' performance.</p><p>Likewise, the sommeliers' performance measures represent a conservative(ly higher) estimate since scores lower than 60% in section 1 were removed. We find the HSLDA model, especially of monova- rietals, outperforms sommeliers by 6.3%, as mea- sured by F1. In aggregate, sommeliers did signif-  icantly better in red and sparkling wines, and in French, German, and Californian wines, whereas Model 1 edged out in white wines, south America wines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Food and Wine Pairing: Siamese Neural Networks with LSTM</head><p>For food and wine pairing, we trained an un- tied and modified version of Manhattan LSTM <ref type="bibr" target="#b7">(Mueller and Thyagarajan, 2016)</ref>, where we pre- processed the texts differently and applied LSTM- Based Importance Weighting in place of the original simple similarity function coupled with LSTM. We retained from the recipes only ingre- dients, serving ingredients and essential actions, which were passed to the BiLSTM ( . For a given pair of wine and recipe descrip- tions, we applied a weight compatibility function . For model architecture and other implementation details we refer readers to <ref type="bibr" target="#b7">Mueller and Thyagarajan (2016)</ref> and <ref type="bibr" target="#b15">Rücklé and Gurevych (2017)</ref>.</p><formula xml:id="formula_0">g(h (a) Ta , h (b) T b ) = exp(−||a T h (a) Ta −b T h (b) T b || 1 ),</formula><p>We obtained our ground-truth labels for wine and recipe pairings on a scale from 1 to 5 using an automated weighting scheme based on wine and food pairing principles ( <ref type="bibr" target="#b1">Goldstein and Goldstein, 2006</ref>) 5 leveraging the GuildSomm tasting notes of grape varietals and recipe ingredients, under close guidance of a certified sommelier with the CMS. Details of the weighting scheme is included in our online supplementary documents. In the end we simplified our scale to binary -{1, 2} converted to 0, {3, 4, 5} converted to 1. We document our ac- curacies in <ref type="table" target="#tab_4">Table 3</ref>. Surprisingly, the model edged out by 1.7%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy</head><p>Training  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>We examine how machine learning can be used to understand, assist, and improve human decision- making, echoing recent studies in computational social sciences <ref type="bibr" target="#b0">(Dietvorst et al., 2015;</ref><ref type="bibr" target="#b6">Kleinberg et al., 2017)</ref>. We dissect sommelier skills into three parts and train ML models for each. We show with our choices of suitable models, col- lection of valuable datasets and annotations, that ML algorithms outperform sommeliers in essen- tial skills. Future work could improve on:</p><p>1. fine-tuning the Open-domain Question An- swering for wine knowledge;</p><p>2. connecting our HSLDA or hierarchical multi- label classification to robotic sensors to fully mimic the blind tasting task;</p><p>3. exploring other simpler and more efficient ML models for pairing tasks;</p><p>4. training a joint multi-task model, since it is accepted in the industry that a solid knowl- edge of wine theory helps immensely in blind tasting and wine service. It would be inter- esting to quantify the synergy in the learning process;</p><p>5. exploring ML applications to other aspects of the service component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>Zafer </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Country and Point Distribution of Wine Reviews</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>where a T and b T are shared network weights applied to BiLSTM representations h a Ta and h b T b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Evaluation results of HSLDAs in compar-
ison with sommeliers' performance. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Evaluation results of Modified MaLSTM 
in comparison to sommeliers' performance. 

</table></figure>

			<note place="foot" n="1"> &quot;The Court of Master Sommeliers sets the global standard of excellence for beverage service within the hospitality industry with integrity, exemplary knowledge, and humility.&quot;-https://www.mastersommeliers.org/ 2 There are indeed a list of recommended references and an unofficial source of study guides popular among candidates: https://www.guildsomm.com, which we use as our training data.</note>

			<note place="foot" n="4"> We choose the cutoff rate of 60% because it is the the pass rate in real sommelier exams both for the certified and advanced.</note>

			<note place="foot" n="5"> One of the few recommended resources for certified sommelier candidates on wine and food pairing.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Algorithm aversion: People erroneously avoid algorithms after seeing them err</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berkeley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">P</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cade</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Massey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">114</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Perfect Pairings: A Master Sommeliers Practical Advice for Partnering Wine with Food</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><surname>Goldstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Univ of California Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Very quaffable and great fun: Applying nlp to wine reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iris</forename><surname>Hendrickx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Els</forename><surname>Lefever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilja</forename><surname>Croijmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asifa</forename><surname>Majid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antal</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bosch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="306" to="312" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1693" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Predicting the structure of cooking recipes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jermsak</forename><surname>Jermsurawong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="781" to="786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Human decisions and machine predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himabindu</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sendhil</forename><surname>Mullainathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="237" to="293" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Siamese recurrent architectures for learning sentence similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Thyagarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2786" to="2792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning text similarity with siamese recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Neculoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Versteegh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Rotaru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Representation Learning for NLP</title>
		<meeting>the 1st Workshop on Representation Learning for NLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="148" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lexical and hierarchical topic regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><forename type="middle">L</forename><surname>Viet-An Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Modeling time series similarity with siamese recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Tax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Der Maaten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04713</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hierarchically supervised latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Adler J Perotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noemie</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Elhadad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bartlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2609" to="2617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The Oxford companion to wine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jancis</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Harding</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>American Chemical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Wine Grapes: A complete guide to 1,368 vine varieties, including their origins and flavours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jancis</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Harding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Vouillamoz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>Penguin UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Kernel-based learning of hierarchical multilabel classification models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Rousu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandor</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1601" to="1626" />
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Representation learning for answer selection with lstmbased importance weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Rücklé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWCS 201712th International Conference on Computational SemanticsShort papers</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuldip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning structured prediction models: A large margin approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassil</forename><surname>Chatalbashev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on Machine learning</title>
		<meeting>the 22nd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="896" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Sour cream: Toward semantic processing of recipes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Tasse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<idno>CMU-LTI-08- 005</idno>
		<imprint>
			<date type="published" when="2008" />
			<pubPlace>Pittsburgh</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Feature hashing for large scale multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Attenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1113" to="1120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Plateclick: Bootstrapping food preferences through an adaptive visual interface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">P</forename><surname>Pollak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th acm international on conference on information and knowledge management</title>
		<meeting>the 24th acm international on conference on information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bidirectional long short-term memory networks for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation</title>
		<meeting>the 29th Pacific Asia Conference on Language, Information and Computation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="73" to="78" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
