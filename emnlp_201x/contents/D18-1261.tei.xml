<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluating Theory of Mind in Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018. 2392</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aida</forename><forename type="middle">Nematzadeh</forename><surname>Deepmind</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley</orgName>
								<orgName type="institution" key="instit2">UC Berkeley</orgName>
								<orgName type="institution" key="instit3">UC Berkeley</orgName>
								<orgName type="institution" key="instit4">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaylee</forename><surname>Burns</surname></persName>
							<email>kayleeburns@berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley</orgName>
								<orgName type="institution" key="instit2">UC Berkeley</orgName>
								<orgName type="institution" key="instit3">UC Berkeley</orgName>
								<orgName type="institution" key="instit4">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Grant</surname></persName>
							<email>eringrant@berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley</orgName>
								<orgName type="institution" key="instit2">UC Berkeley</orgName>
								<orgName type="institution" key="instit3">UC Berkeley</orgName>
								<orgName type="institution" key="instit4">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alison</forename><surname>Gopnik</surname></persName>
							<email>gopnik@berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley</orgName>
								<orgName type="institution" key="instit2">UC Berkeley</orgName>
								<orgName type="institution" key="instit3">UC Berkeley</orgName>
								<orgName type="institution" key="instit4">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley</orgName>
								<orgName type="institution" key="instit2">UC Berkeley</orgName>
								<orgName type="institution" key="instit3">UC Berkeley</orgName>
								<orgName type="institution" key="instit4">Princeton University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Evaluating Theory of Mind in Question Answering</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2392" to="2400"/>
							<date type="published">October 31-November 4, 2018. 2018. 2392</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a new dataset for evaluating question answering models with respect to their capacity to reason about beliefs. Our tasks are inspired by theory-of-mind experiments that examine whether children are able to reason about the beliefs of others, in particular when those beliefs differ from reality. We evaluate a number of recent neural models with memory augmentation. We find that all fail on our tasks, which require keeping track of inconsistent states of the world; moreover, the models&apos; accuracy decreases notably when random sentences are introduced to the tasks at test. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Reasoning About Beliefs</head><p>Possessing a capacity similar to human reasoning has been argued to be necessary for the success of artificial intelligence systems (e.g., <ref type="bibr" target="#b21">Levesque et al., 2011)</ref>. One well-studied domain that re- quires reasoning is question answering, where simply memorizing and looking up information is often not enough to correctly answer a question. For example, given the very simple scenario in Ta- ble 1, searching for the word "Mary" and returning a nearby word is not a correct strategy; instead, a model needs to recognize that Mary is currently at the second location (office and not the bathroom).</p><p>Recent research has focused on developing neural models that succeed in such scenarios ( <ref type="bibr" target="#b19">Henaff et al., 2017)</ref>. As a benchmark to evaluate these models, <ref type="bibr" target="#b27">Weston et al. (2016)</ref> released a dataset -Facebook bAbi -that provides a set of toy tasks, each examining a spe- cific type of reasoning. For example, the scenario in <ref type="table">Table 1</ref> evaluates the capacity to reason us- ing a single supporting fact. However, the bAbi tasks are already too simple for the current mod- els. Only a few years after their release, existing models fail at only one or two (out of 20) tasks ( <ref type="bibr" target="#b24">Rae et al., 2016;</ref>. Moreover, all except two of the reasoning tasks in this dataset only require transitive inference ( <ref type="bibr" target="#b20">Lee et al., 2016)</ref>.</p><p>Mary went to the bathroom. John moved to the hallway. Mary travelled to the office. Where is Mary? A: office <ref type="table">Table 1</ref>: A task from the bAbi dataset ( <ref type="bibr" target="#b27">Weston et al., 2016</ref>).</p><p>People reason not just about their own obser- vations and beliefs but also about others' mental states (such as beliefs and intentions). The capac- ity to recognize that others can have mental states different than one's own -theory of mind -marks an important milestone in the development of chil- dren and has been extensively studied by psychol- ogists (for a review, see <ref type="bibr" target="#b16">Flavell, 2004</ref>). Artifi- cial intelligence (AI) systems will also require a similar reasoning capacity about mental states as they are expected to be able to interact with peo- ple (e.g., <ref type="bibr">Chandrasekaran et al., 2017;</ref><ref type="bibr" target="#b3">Grant et al., 2017;</ref><ref type="bibr" target="#b23">Rabinowitz et al., 2018)</ref>.</p><p>However, the bAbi dataset does not include tasks that evaluate a model's ability to reason about beliefs. <ref type="bibr" target="#b3">Grant et al. (2017)</ref> created a bAbi- style dataset inspired by an influential experiment on the theory of mind called the Sally-Anne task (e.g. <ref type="bibr" target="#b13">Baron-Cohen et al., 1985)</ref>. Their goal was to examine whether the end-to-end memory net- work (  can answer ques- tions such as "where does Sally think the milk is?" in situations that Sally's belief about the location of milk does not match the reality. For example, Sally thinks that the milk is in the fridge but the milk is actually on the table.</p><p>The dataset of <ref type="bibr" target="#b3">Grant et al. (2017)</ref> provides a first step in designing benchmarks to evaluate the mental-state reasoning capacity of question- answering models, but it is still limited in the types of reasoning it probes. For example, it only considered first-order beliefs (e.g., Sally's be- lief about the location of milk). People also rea- son about second-order (and higher-order) beliefs (e.g., Anne's belief about Sally's belief about the location of the milk). More importantly, similarly to the bAbi dataset, success in each task is defined as correctly answering one question. This does not guarantee that a model has an understanding of the state of the world; in fact, even in developmental theory-of-mind experiments, children are asked a few questions (e.g., "where is milk really?") to ensure that their correct answer reflects their un- derstanding and is not simply due to chance.</p><p>In this paper, we address these shortcomings by designing a new dataset that enables us to eval- uate a model's capacity to reason about different types of beliefs as well as whether it maintains a correct understanding of the world. To this end, we evaluate a number of different models that per- form well on the bAbi tasks: the end-to-end mem- ory network , the multiple observer model ( <ref type="bibr" target="#b3">Grant et al., 2017)</ref>, the recurrent entity network ( <ref type="bibr" target="#b19">Henaff et al., 2017)</ref>, and Relation- Network ( . We find that none of these models succeed at our tasks, suggesting that they are not able to keep track of inconsistent states of the world, in particular when someone's belief does not match the history or reality of a sit- uation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Theory of Mind Experiments</head><p>Behavioral research shows that children gradually develop a theory of mind (for a review, see <ref type="bibr" target="#b17">Gopnik and Astington, 1988)</ref>. At the age of two, most chil- dren have an understanding of others' desires and perceptions -if someone wants something, they will try to get it and if something is in their sight, they can see it. Children begin to understand oth- ers' beliefs around the age of three, but this under- standing is still limited. For example, they might not be able to reason that someone's actions are a result of their beliefs. By the age of five, most chil- dren have a unified theory of mind and are able to represent and reason about others' desires, percep- tions, and beliefs. Developmental psychologists have designed various experimental paradigms to examine to what extent children are able to reason about others' mental states. We use these exper- iments as guidelines for designing tasks to evalu- ate the reasoning capacity of question-answering models. We first explain these experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Sally-Anne Experiment</head><p>The Sally-Anne false-belief experiment, proposed by <ref type="bibr" target="#b13">Baron-Cohen et al. (1985)</ref>, examines children's ability to reason about others' false beliefs, i.e., when someone's belief does not match the real- ity. In this experiment, the participants observe two agents, Sally and Anne, with their containers, a basket and a box. After putting a marble in her basket, Sally leaves the room (and is not able to observe the events anymore). After Sally's depar- ture, Anne moves the marble to her box. Then, Sally returns to the room (see <ref type="figure" target="#fig_0">Figure 1</ref>). The par- ticipants are asked the following questions:</p><p>• "Where will Sally look for her marble?"</p><p>(belief question) • "Where is the marble really?"</p><p>(reality question) • "Where was the marble in the beginning?"</p><p>(memory question) The first question tests the participants' ability to reason about Sally's belief about the location of her marble. Interestingly, most children before the age of 3 answer this question incorrectly and say that Sally will look at the box (where the marble really is) instead of the basket (where Sally thinks the marble is). These children are not able to rea- son about Sally's belief which is different from the reality of the world. The reality and memory ques- tions are used to confirm that children's correct an- swer to the belief question is not due to chance; but because they have a correct understanding of the state of world and others' beliefs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Icecream Van Experiment</head><p>The Sally-Anne experiment examines the ability to reason about another person's belief or a first- order belief. People are also able to reason about beliefs about beliefs, for example, Anne thinks that Sally believes that the marble is in basket. <ref type="bibr" target="#b22">Perner and Wimmer (1985)</ref> performed a set of experiments to examine children's reasoning ca- pacity about such higher-order beliefs. In their set-up Mary and John together see an ice cream van in the park, and the icecream man tells them that he will be in the park until later in the af- ternoon. Mary leaves the park and goes home. A bit after she leaves, the icecream man decides to leave the park and tells John that he is going to the church. On his way to the church he runs into Mary and informs her that he will be selling icecreams close to the church all afternoon. The participants are then asked the following second- order question: "Where does John think Mary goes to get icecream?" Note that John does not know that Mary has been told about the new lo- cation of the icecream van; he has a second-order false belief about Mary's belief. The participants are also asked a few control questions (e.g., "does Mary know that the van is in the church?") to en- sure that they do not correctly answer the second- order question by chance. <ref type="bibr" target="#b22">Perner and Wimmer (1985)</ref> found that 6-and 7-year old children are able to answer the second-order questions, sug- gesting that reasoning about higher-order beliefs (as compared to a first-order belief) is a harder cognitive task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Theory of Mind Task Dataset</head><p>Inspired by the theory-of-mind experiments ex- plained in Section 2 and building on the work of <ref type="bibr" target="#b3">Grant et al. (2017)</ref>, we created a dataset based on three tasks designed to capture increasingly com- plex theory-of-mind reasoning: true-, false-, and second-order false-belief tasks. Examples of each task type are given in <ref type="figure">Figure 2</ref>. In the true-belief task, Sally observes the world and as a result she has a first-order true belief about the location of the milk -her belief matches reality. In the false- belief task, Sally's first-order belief differs from reality (i.e., she has a false belief ) because she was absent when the state of the world changed. In the second-order false-belief task, Sally observes the new location of the milk; thus, she has a true be- lief about the milk's location. However, Anne's belief about Sally's mental state does not match reality because Anne does not know that Sally has observed the change in the environment. As a re- sult, Anne has a false belief about Sally's beliefs.</p><p>These tasks are more challenging than the bAbI scenarios, because a model needs to learn whether each agent has a true or false belief about a given world state to succeed, where the world state now includes the mental states of each agent.</p><p>Note that we assume all containers are transpar- ent in the underlying world; whenever an agent en- ters a location, they become aware of the objects true location. We made this decision to keep the tasks as structurally similar as possible. This pre- vents models from simply learning to produce a specific answer for a task type when a sentence like "Sally looks inside the pantry" is present in the story. The container-transparency property is consistent throughout all task-question pairs.</p><p>Question types. To examine the reasoning ca- pacity of each model about beliefs and second- order beliefs, we employ four question types in- spired by theory-of-mind experiments discussed in Section 2; see <ref type="table" target="#tab_0">Table 2</ref> for examples of these question types. These questions enable us to test whether a model can reason about first-order and second-order beliefs, and at the same time, knows the initial and current correct location of an object; thus, we can distinguish between when a model answers a question by chance and when it actually understands the entire state of the world. <ref type="table">Table 3</ref> gives the answers for the 12 combina- tions of task type and question. Given a true-belief or false-belief task, the answers to the first-order and second-order questions are the same (e.g., "pantry" in the true-belief condition and "fridge" in the false-belief condition for the tasks in <ref type="figure">Fig- ure 2</ref>). However, they are different in the second- order false belief task because Anne has a false belief about Sally's belief.</p><p>Dataset variants. We use these tasks to gener- ate two datasets: ToM and ToM-easy. The primary difference between these two datasets is that, in ToM-easy, each story has only one task, while ToM can have multiple tasks within a single story. Each dataset contains a training set with 10 000 exam- ples with each of the 12 combinations of task and question types.</p><p>In ToM, the tasks are randomly grouped into sets of 5 to form stories, which is the same num- ber used in the bAbI dataset. In the test set for ToM, each story contains 4 tasks, but there is only one question present at the end. Because questions that come closer to the beginning of a story have</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>True Belief</head><p>False Belief Second-order False Belief Anne entered the kitchen.</p><p>Anne entered the kitchen. Anne entered the kitchen. Sally entered the kitchen.</p><p>Sally entered the kitchen. Sally entered the kitchen. The milk is in the fridge.</p><p>The milk is in the fridge. The milk is in the fridge. Anne moved the milk to the pantry. Sally exited the kitchen.</p><p>Sally exited the kitchen. Anne moved the milk to the pantry. Anne moved the milk to the pantry.</p><p>Anne exited the kitchen. Sally entered the kitchen.</p><p>Figure 2: An example story from each of the three task types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Memory</head><p>Where was the milk at the beginning?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reality</head><p>Where is the milk really?</p><p>First-order</p><p>Where will Sally look for the milk?</p><p>Second-order Where does Anne think that Sally searches for the milk?  <ref type="table">Table 3</ref>: The correct answer to each question for true- belief (TB), false-belief (FB), and second-order false- belief (SOFB) tasks. Here, "first" and "second" are the ini- tial and actual locations of the object of interest, respectively (e.g., fridge and pantry in <ref type="figure">Figure 2</ref>).</p><p>fewer distracting sentences (i.e., potential answer words) that may confound a model, they are eas- ier to answer. We found that this testing procedure gave us a more precise understanding of the per- formance of the model by separating the difficulty of a question due to its position in a story from the inherent difficulty of the question itself.</p><p>Generating the data. Each reasoning task in <ref type="bibr" target="#b27">Weston et al. (2016)</ref> can be formalized with a grammar. The training and test data are then the derivations of this grammar. We refer to each derivation as a story (e.g., <ref type="figure">Figure 2</ref>). We follow <ref type="bibr" target="#b3">Grant et al. (2017)</ref> in writing grammars for our new tasks. In particular, all the task grammars con- sist of a set of entities (people and objects in the stories) and predicates that take entities as subject or object. The grammars also specify the prop- erties of entities -which predicates take them as subjects or objects. A predicate can include ac- tions that are ways an agent interact with the world (e.g., place, move, enter, exit) and beliefs that are mental state terms (e.g., believe, think). As an ex- ample, Sally with the property is agent can per- form the action displace on apple with the prop- erty is object. Similar to the previous work, we use a restricted set of action and belief predicates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Models</head><p>We briefly describe the models that we evaluate in this paper. We chose these models based on the novelty in their architecture or their near state- of-the-art results in the bAbi tasks. More specif- ically, given 10k examples and joint-training on the bAbi tasks, the best end-to-end memory net- work ( ) and relation net- work (Santoro et al., 2017) fail at 6 and 2 tasks, respectively. Given the same training dataset and per-task training, the recurrent entity network suc- ceed at all tasks (but the authors do not report the results of joint-training). Recall that the bAbi tasks are structured as a set of sentences followed by a question about them (e.g., a story from <ref type="figure">Fig- ure 2</ref> followed by a question from <ref type="table" target="#tab_0">Table 2</ref>).</p><p>The End-to-End Memory Network.  proposed a neural memory- augmented model, the end-to-end memory net- work (MemN2N), that extends the memory net- work architecture ( <ref type="bibr" target="#b28">Weston et al., 2014</ref>). Similarly to its predecessor, MemN2N has a memory com- ponent in which sentences are embedded and an attention function that weights the embedded sen- tences based on their similarity to a given question. The MemN2N model introduces multiple layers of memory (hops) by stacking memory components such that the question embedding at layer k + 1 is the sum of the output and question embedding of layer k. The Multiple Observer Model. To perform well on the false-belief and second-order false- belief conditions, a model needs to identify that agents have experienced different events, and, as a result, have differing knowledge about the state of the world. Although having multiple layers of memory in the MemN2N model enables it to com- bine attention to different memory slots (i.e., em- bedded sentences) at each layer, the model does not have access to each agent's unique perspec- tive. For example, the model is not explicitly told that Sally does not observe the change of the lo-cation of the milk in the false-belief condition. To address this, <ref type="bibr" target="#b3">Grant et al. (2017)</ref> propose the Multi- ple Observer model that integrates MemN2N with individual memory modules for each agent in the story. An agent's memory only receives the sen- tences for which the agent is present and observes the world. Their model has an additional attention function that weighs the memory modules based on their relevance to the question. The model is expected to learn to attend to Sally's memory mod- ule if the question is about her belief about a state of the world. The Recurrent Entity Network. <ref type="bibr" target="#b19">Henaff et al. (2017)</ref> propose a memory-augmented architec- ture, EntNet, with two interesting properties; first, their model is a recurrent neural network and thus can capture the sequential nature of the events in a story. Second, instead of keeping a whole sentence embedding in a memory slot, their model can learn the important entities of a story (e.g., a person) and their properties (e.g., location) through a set of gated recurrent units and two weight matrices. The Relation Network.  pro- pose a neural model for relational reasoning. Their model consider the possibility of a relation among each two possible pairs of objects. To model the bAbi tasks, they consider each pair of sentences together with the question as inputs to their rela- tion network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>Experiment set-up We train all models jointly over all task types without noise, but evaluate them independently on different task and question pairs. We choose the best-performing models by select- ing hyperparameters on the validation set. Sim- ilarly to , we consider a model successful only when its accuracy exceeds 95% across the entire task suite.</p><p>MemN2N and Multiple Observer Models. We first examine how each model performs across a range of parameter and initialization values. MemN2N models are very sensitive to the network initialization and for each set of parameters, the best result out of 10 runs is reported ( ). We first visualize the accuracy of all runs as a box plot to identify how sensitive each model is to random initialization (of parameters and internal states) and thus difficult to train. We also report the results for the best run in each ex- periment. We use a memory size of 50, the same as experiments of , to en- sure that the memory contains all sentences of a given story.</p><p>EntNet. We report results averaged over 3 ini- tializations because we observed little randomness due to initialization. We selected the learning rate on a held out validation set separately for ToM- easy and ToM; all otehr the same hyperparame- ters as <ref type="bibr" target="#b19">Henaff et al. (2017)</ref>: 20 memory slots and an embedding size of 100 We trained until the training error hit zero, which occurred around 50 epochs for both datasets. .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RelNet.</head><p>We report results using a single seed be- cause we saw little randomness due to initializa- tion; this is in accordance with the authors' find- ings ( ). We selected model hy- perparameters on a held-out validation set sepa- rately for each of the ToM and ToM-easy datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overall Performance on ToM-easy</head><p>We expect the models perform well on this dataset, given that there is only one task in the memory during both training and test and as a result unre- lated events do not interfere with a model's rea- soning in this condition.</p><p>Despite the large variance in accuracy across runs, the MemN2N models often succeed at the memory, reality, and second-order questions <ref type="figure" target="#fig_1">(Fig- ure 3a)</ref>. Note that the median accuracy (the dark blue line in box) is close to 1 for these questions. However, the model often fails (median accuracy around 0.5) given the first-order question ("where will Sally look for the milk") and the false-belief and second-order false-belief tasks. This pattern is different from the empirical findings on people; the second-order question is harder than the first order one for people. We observe that the perfor- mance of the Multiple Observer model is similar to the MemNet for most question-task pairs (ex- pect one) but there is less variation in the accuracy values. Interestingly, the median accuracy is close to one for the first-order question and the second- order false-belief task but the Multiple Observer model still performs poorly for this question on the false-belief task.</p><p>Why is the first-order question harder for the MemN2N model? To investigate this, we look more closely at our task-question pairs. As shown in <ref type="table">Table 3</ref>, the answers to the first-order ques- tion are different for the false-belief and second- order false-belief tasks but are the same for the  Memory Network and Multiple Observer Model Performance Across Task and Question Types.</p><p>Pink indicates that the answer to the question is the first container that contained the object in that task. Blue indicates that the answer is the last container that contained the object before the question was asked. Grey indicates that the answer was the first container that contained the object in the entire story which may or may not be the same as the pink.</p><p>(a) Memory Network with memory size 50 evaluated on the ToM-easy dataset.</p><p>(b) Multiple Observer Model with memory size 50 evaluated on the ToM-easy dataset.</p><p>(c) Memory Network with memory size 50 evaluated on the ToM dataset. second-order one. We suspect that it is harder for the MemN2N model to learn two distinct an- swers for the same question given the the simi- larities of the two false-belief tasks. To test this hypothesis, we altered the data such that the an- swers to first-order question are (incorrectly) the same for both false-belief and second-order false- belief tasks (and also the second-order question). We observe that the median accuracy is close to 1 for all conditions suggesting that the model can learn the distinction between two of the tasks but not all three.</p><p>We observe that EntNet and RelNet models are not too sensitive to the initialization value, and thus just report the result on best-performing mod- els. Both EntNet and RelNet best models succeed at the ToM-easy tasks; their mean error is 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Overall Performance on ToM</head><p>This dataset is more similar to the bAbi dataset in that, during both training and test, the memory contains a story with multiple tasks; as a result, it is harder for the model to identify the entities relevant to a given question.</p><p>As shown in <ref type="figure" target="#fig_1">Figure 3c</ref>, the MemN2N performs worse on all the questions with the exception of the reality question, where performance is slightly worse but has lower variance. (cf. the ToM-easy dataset). The first-and second-order questions are, overall, harder for the model. The performance of the Multiple Observer model is better for most of the questions (see <ref type="figure" target="#fig_1">Figure 3d)</ref>, especially the second-order, but it is slightly worse for the mem- ory question. This suggests that adding agent- specific memory modules is not enough to succeed on all the ToM tasks, and that the increased com- plexity of inference with multiple memory mod- ules harms performance on another task.</p><p>We also look at the best-performing MemN2N and Multiple Observer models over all question- task pairs. These models are selected based on their performance on the validation dataset. We observe that none of these models succeed on the ToM tasks, but, interestingly, the Multiple Ob- server model performs better overall as compared to the original MemN2N model (see <ref type="table">Table 4</ref>).</p><p>ToM and bAbi. How are ToM and bAbi tasks similar? The combination of our true-belief task and the reality question is very similar to bAbi task 1 (single supporting fact). To correctly an- swer the reality question ("where is the milk re- ally?", a model need to use a single fact from the story ("Anne moved the milk to the pantry."). The MemN2N model succeeds at both bAbi task 1 and the reality question given the true-belief task. However, the correct answer to the memory ques- tion ("where was the milk at the beginning?") for the true-belief task also requires a single fact ("the milk is in the fridge."). Interestingly, the error of MemN2N on the memory question is much higher than the reality question. The model (unlike peo- ple) cannot learn two representations (initial and current location) for an object. This result demon- strates the importance of representing alternative states of the world, whether it be past states of re- ality (i.e., where the "milk" used to be) or men- tal states about the world (i.e., where an agent be- lieves the "milk" to be).</p><p>EntNet and RelNet. We also report results of two relevant memory-augmented neural network models on our tasks, EntNet ( <ref type="bibr" target="#b19">Henaff et al., 2017)</ref> and RelNet ( , in <ref type="table">Table 4</ref>. Again, because we did not observe sensitivity to initialization for these models, only average per- formance of their best-performing model is re- ported. We see that even though these models suc- ceed on the ToM-easy dataset, they fail on the ToM tasks, suggesting that these models cannot simul- taneously deal with inconsistent (i.e., past, present, and mental) states of the world.</p><p>We further investigate which questions are the hardest for each best model; see <ref type="table">Table 5</ref>. We observe that each of the MemN2N, Multiple Ob- server and RelNet models perform poorly on some combination of the first-and second-order ques- tions, but are successful at answering the reality question. We hypothesize that this phenomenon occurs because the reality question is the most similar to the bAbi tasks. In addition, all models fail the memory question for each task type. While this is to be expected for EntNet due to its recur- rent nature and therefore bias towards recency, it is surprising that the other models, which exhibit only a small positional bias, cannot correctly rep- resent a past state of the world in order to answer the memory question correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimenting with Noise</head><p>We examine to what extent each model's architec- ture is sensitive to the position of sentences in each story. We do so by adding a novel sentence at ran- dom locations in each story at test time. For any setting of the noise, p, there is a p% probability of a noise sentence occurring before each sentence in the story. Noise sentences cannot follow other noise sentences in the story. In this paper, we re- port results with p = .1. We observe that the ac- curacy of all best models decreases notably in the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>ToM-easy ToM-easy (noised) ToM ToM (noised) <ref type="bibr" target="#b1">MemN2N (Sukhbaatar et al., 2015)</ref> 100.00% 90.28% 82.38% 77.00% Multiple Observer ( <ref type="bibr" target="#b3">Grant et al., 2017)</ref> 100.00% 95.81% 91.11% 87.43% EntNet ( <ref type="bibr" target="#b19">Henaff et al., 2017)</ref> 100.00% 94.61% 93.67% 88.63% RelNet (  100.00% 87.82% 94.31% 76.84% <ref type="table">Table 4</ref>: A comparison of model performance. All models succeed on the ToM-easy dataset without noise. Multiple Observer model performs best on ToM-easy with noise, RelNet performs best on ToM, and EntNet performs best on ToM with noise. <ref type="table">Table 5</ref>: Model accuracy on failed questions given the ToM task (without noise); M, R, FOB, and SOB are the memory, reality, first-and second-order questions, respectively. The number in the parentheses is the accuracy for that question on that task.</p><p>presence of noise (see <ref type="table">Table 4</ref>). This result is par- ticularly interesting as it shows that none of the models are able to use the semantics of the sen- tences in a story in their reasoning -they are all sensitive to the presence of distractor sentences. Interestingly, the RelNet model is the best per- former amongst the models we considered on the ToM dataset, yet it is also the most sensitive to noise. Moreover, the Multiple Observer model - with explicit memories for each agent -is the most robust to noise; it has the minimum decrease in accuracy between each dataset and its noised ver- sion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experimenting with Memory</head><p>In the experiments of  the memory size is fixed to 50, which is necessary to capture the entire story in memory (e.g. the answer to the memory question in ToM may rely on infor- mation at the beginning of a story). We observed that smaller memory sizes artificially improved the performance of the MemN2N and Multiple Ob- server model on ToM tasks. For example, using a memory size of 10, our best MemN2N model per- formance boosts on the hardest task of ToM (FB task with first order belief question) from 5.1% to 97.5% and on the easiest task from 98.3% to 100.0% (SOFB task with reality question). This result is not surprising because given a small mem- ory size, ToM and ToM-easy are very similar tasks; the memory size of 10 allows for at most two full tasks in memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Recent research has emphasized the importance of modeling and understanding people's mental states for AI systems. <ref type="bibr" target="#b15">Eysenbach et al. (2016)</ref> created a dataset of scene-description pairs where each scene is a set of visual frames and some frames include people with mistaken beliefs. <ref type="bibr">2</ref> The authors build a regression model for identifying a mistaken belief and the person who has such a be- lief in a given frame. Our work differs with theirs in that we are interested in understanding whether a model can reason about people's true and false beliefs to correctly answer questions as opposed to identifying mistaken beliefs. <ref type="bibr" target="#b3">Grant et al. (2017)</ref> studied whether the end-to- end memory network of  can pass a false-belief test -correctly answer where Sally would search for an object in false- and true-belief situations. They created a dataset inspired by the bAbi dataset to examine whether the model can reason about interaction of beliefs and actions in these situations -how actions cause beliefs and vice versa. They show that MemN2N fails at the false-belief test, and their extension of that model with separate memories for each agent and an observer outperforms MemN2N. <ref type="bibr" target="#b23">Rabinowitz et al. (2018)</ref> formulate the capacity to reason about others' beliefs as a meta-learning problem. They propose a neural network, ToM- net, that learns to predict the behavior of different agents given their past and current trajectory. Sim- ilarly to <ref type="bibr" target="#b3">Grant et al. (2017)</ref>, in addition to individ- ual agents, they model an "observer" that has ac- cess to states and actions of all agents (though this information can be noisy and partial). Interest- ingly, their model successfully predicts an agent's behavior in a false-belief situation -the agent's be- havior reflects its false-belief as opposed to the re- ality of the world.</p><p>Finally, <ref type="bibr">Chandrasekaran et al. (2017)</ref> take a dif-ferent approach by studying whether people can understand the "beliefs" of a visual-question an- swering system. More specifically, they exam- ine whether the participants can predict when the model would fail in answering a question as well as if they can predict the model's answer. They find that even with a few examples, people get bet- ter at answering these questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>We propose a dataset for evaluating question- answering models. Our dataset -inspired by semi- nal theory-of-mind experiments in children -mea- sures to what extent recently introduced neural models can reason about beliefs and states of the world that are potentially mututally inconsistent. We evaluate three of the recent neural question an- swering models (and an extension of one) on our tasks. We find that none of the models are able to succeed fully on a suite of tasks that requires keeping track of inconsistent beliefs or states of the world. These inconsistencies arise from differ- ences between the past and the present, as well as the mental states of agents who may have false be- liefs about the world or about the mental states of other agents. The purpose of the dataset introduced in this work is not to test advanced language fluency; in- stead, consistency in the linguistic structure of the tasks allows us to isolate the performance of the models' reasoning capabilities. Even though the language is simple, the models struggle to achieve good performance. Furthermore, we note that the proposed dataset should be treated as a diagnos- tic tool and that good performance on similar toy tasks is not sufficient for reasoning capabilities.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Sally-Anne experiment setup from BaronCohen et al. (1985).</figDesc><graphic url="image-1.png" coords="2,317.61,520.22,197.60,147.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3</head><label>3</label><figDesc>Figure 3: Memory Network and Multiple Observer Model Performance Across Task and Question Types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>:</head><label></label><figDesc>Figure 3: Memory Network and Multiple Observer Model Performance Across Task and Question Types.</figDesc><graphic url="image-2.png" coords="6,72.00,119.74,453.52,134.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>(</head><label></label><figDesc>d) Multiple Observer Model with memory size 50 evaluated on the ToM dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 2 : Examples of the four question types.</head><label>2</label><figDesc></figDesc><table>TB 
FB 
SOFB 
Memory 
first 
first 
first 
Reality 
second second second 
First-order 
second first 
second 
Second-order second first 
first 

</table></figure>

			<note place="foot" n="1"> Code to generate dataset and replicate results is available at github.com/kayburns/tom-qa-dataset.</note>

			<note place="foot" n="2"> For example, a scene where a person gets sick eating mushrooms is paired with the sentence &quot;the couple mistakenly thinks it&apos;s ok to eat the mushrooms&quot;.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Model True-belief False-belief Second-order False-belief</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Memn2n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sukhbaatar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">94</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">FOB (78.2)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Multiple</forename><surname>Observer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Grant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">SOB (92.5)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">SOB (90.3)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Entnet (henaff</surname></persName>
		</author>
		<idno>2017) M (74.0</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">M (76.1)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Relnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Santoro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">7%</title>
		<imprint>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">FOB (71.37%)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">M (78.5%)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">9%</title>
		<imprint>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">FOB (81.8%)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Does the autistic child have a theory of mind?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Baron-Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">M</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uta</forename><surname>Frith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deshraj</forename><surname>Yadav</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00717</idno>
		<title level="m">Prithvijit Chattopadhyay, Viraj Prabhu, and Devi Parikh. 2017. It takes two to tango: Towards theory of AI&apos;s mind</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Who is mistaken?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Eysenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.01175</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Theory-of-mind development: Retrospect and prospect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flavell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Merrill-Palmer Quarterly</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="274" to="290" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Children&apos;s understanding of representational change and its relation to the understanding of false belief and the appearance-reality distinction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alison</forename><surname>Gopnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janet</forename><forename type="middle">W</forename><surname>Astington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Child develop</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="26" to="37" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Griffiths. 2017. How can memory-augmented neural networks pass a false-belief task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aida</forename><surname>Nematzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 39th Annual Conference of the Cognitive Science Society</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tracking the world state with recurrent entity networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reasoning in vector space: An exploratory study of question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moontae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Wen Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smolensky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernest</forename><surname>Hector J Levesque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leora</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Morgenstern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page">47</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Attribution of second-order beliefs by 5-to 10-year-old children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Perner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinz</forename><surname>Wimmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental child psychology</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="437" to="471" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
	<note>John thinks that Mary thinks that</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Machine theory of mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Perbet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Ali Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scaling memory-augmented neural networks with sparse reads and writes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">J</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">W</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 30th Conference on Neural Information Processing Systems</title>
		<meeting>30th Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A simple neural network module for relational reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 29th Conference on Neural Information Processing Systems</title>
		<meeting>29th Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Towards AI-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Memory Networks. ArXiv e-prints</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
