<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Topical Coherence for Graph-based Extractive Summarization</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daraksha</forename><surname>Parveen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">‡SAP SE Walldorf</orgName>
								<orgName type="laboratory">†NLP Group and Research Training Group AIPHES Heidelberg Institute for Theoretical Studies gGmbH Heidelberg</orgName>
								<address>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Martin</forename><surname>Ramsl</surname></persName>
							<email>hans-martin.ramsl@sap.com</email>
							<affiliation key="aff0">
								<orgName type="department">‡SAP SE Walldorf</orgName>
								<orgName type="laboratory">†NLP Group and Research Training Group AIPHES Heidelberg Institute for Theoretical Studies gGmbH Heidelberg</orgName>
								<address>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">‡SAP SE Walldorf</orgName>
								<orgName type="laboratory">†NLP Group and Research Training Group AIPHES Heidelberg Institute for Theoretical Studies gGmbH Heidelberg</orgName>
								<address>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Topical Coherence for Graph-based Extractive Summarization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an approach for extractive single-document summarization. Our approach is based on a weighted graphical representation of documents obtained by topic modeling. We optimize importance, coherence and non-redundancy simultaneously using ILP. We compare ROUGE scores of our system with state-of-the-art results on scientific articles from PLOS Medicine and on DUC 2002 data. Human judges evaluate the coherence of summaries generated by our system in com-parision to two baselines. Our approach obtains competitive performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Summarization systems take a long document as input and generate a concise document as out- put. Several summarization variants exist such as generic, query-based, multi-document and single document, but the basic requirements for summa- rization remain the same. Summaries should con- tain salient information so that the reader will not miss anything from the original document. Also, the reader is not interested in repetitive informa- tion, so summaries should not include redundant information. Finally, summaries should be coher- ent and of high readability.</p><p>We introduce a completely unsupervised graph- based summarization using latent drichlet alloca- tion (LDA, <ref type="bibr" target="#b0">Blei and Lafferty (2009)</ref>). LDA is a simple model for topic modeling where topic probabilities are assigned words in documents. The probabilities can be used to measure the se- mantic relatedness between words and hence the topical coherence of a document. We use topi- cal coherence as a means to ensure the coherence of extractive single-document summaries. Re- mus and <ref type="bibr" target="#b13">Biemann (2013)</ref> apply LDA to compute lexical chains while <ref type="bibr" target="#b3">Gorinski and Lapata (2015)</ref> also develop a graph-based summarization system which takes coherence into account.</p><p>Our work is based on the bipartite entity graph introduced by <ref type="bibr" target="#b4">Guinaudeau and Strube (2013)</ref>. However, in their graph one set of nodes corre- sponds to entities whereas in our graph it corre- sponds to topics. The entity graph has already been used by <ref type="bibr" target="#b12">Parveen and Strube (2015)</ref> for sum- marization. Their graph is unweighted and sparse, whereas our topical graph is weighted and dense.</p><p>We apply our topical graph on the dataset in- troduced by <ref type="bibr" target="#b12">Parveen and Strube (2015)</ref>. This dataset contains scientific articles from the jour- nal PLOS Medicine 1 . Every PLOS Medicine ar- ticle is accompanied by an editor's summary and an authors' abstract. We use both as gold sum- maries for evaluation. Results obtained on the PLOS Medicine dataset using the topical graph are as good as using the entity graph and significantly better than several baselines and the graph-based system TextRank ( <ref type="bibr" target="#b11">Mihalcea and Tarau, 2004</ref>). We use the DUC 2002 dataset to compare our results with state-of-the-art techniques. In contrast to the PLOS Medicine data the DUC 2002 dataset con- tains very small articles. Still, our technique gives comparable results to the state-of-the-art. This shows that our technique is flexible and scalable despite being unsupervised.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Document Representation</head><p>A graph-based representation has been used by well known summarization systems such as LexRank ( <ref type="bibr" target="#b2">Erkan and Radev, 2004</ref>) and TextRank ( <ref type="bibr" target="#b11">Mihalcea and Tarau, 2004</ref>). The graph used by both is of one mode type where sentences are nodes which are connected by weighted edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weights express sentence similarity.</head><p>We use a bipartite graph representation of doc- uments ( <ref type="figure" target="#fig_0">Figure 1</ref>). The bipartite graph, G = (V s , V t , E t,s ), has two sets of nodes where V s rep- resents sentences and V t topics. The two sets of nodes are connected with edge E t,s , if a word in a sentence s is present in a topic t. If multiple words are present in topic t of sentence s, then the edge weight is the logarithmic sum of probabilities of words in topic t. We normalize the edge weight by dividing them by the length of the sentence. Hence long sentences will not benefit from their lengths. We call the resulting graph topical graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sentence Ranking</head><p>The final summary should contain only important sentences. Therefore, we give a score to every sentence in a document to obtain important sen- tences. Following <ref type="bibr" target="#b12">Parveen and Strube (2015)</ref> we apply the HITS (Hyperlink Induced Topic Search) <ref type="bibr" target="#b7">(Kleinberg, 1999</ref>) algorithm for ranking sentences by importance, since our graph is a bipartite graph. It puts nodes of a graph in two sets: hub nodes and authority nodes.</p><p>For the HITS algorithm the rank of nodes needs to be initialized. We initialize the topic rank Rank t i = 1 and the sentence rank Rank s i = 1+sim(s i , title). The title in the sentence rank is the title of the article. sim(s i , title) is the cosine similarity between the sentence s i and the title of the article. After initialization of all nodes in the weighted topical graph, the HITS algorithm is ap- plied to obtain ranks of sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Coherence Measure</head><p>Guinaudeau and Strube (2013) represent a docu- ment by the entity graph, a bipartite graph consist- ing of sentence and entity nodes. They perform a one-mode projection on sentence nodes, com- pute the coherence of a document on the basis of the one-mode projections and use the coherence measure for summary coherence rating. Building upon this work, <ref type="bibr" target="#b12">Parveen and Strube (2015)</ref> inte- grate this coherence measure to directly generate coherent summaries. Instead of the entity graph we here use the topical graph to incorporate the co- herence measure. <ref type="bibr" target="#b12">Parveen and Strube (2015)</ref> use an unweighted projection graph whereas we use a weighted projection graph of a topical graph to compute the coherence. The weighted one mode projection of the topical graph is shown in <ref type="figure" target="#fig_0">Figure  1</ref>, bottom right.</p><p>weighted coh(si, P ) = weighted Outdegree(si, P )</p><p>( <ref type="formula">1)</ref> norm weighted coh(si, P ) = weighted coh(si, P ) weighted coh(si, P )</p><p>Equation 1 calculates the outdegree of every sen- tence from the weighted projection graph. How- ever weighted coh(s i , P ) in Equation 1 is not a normalized value. The normalized coherence value is in Equation 2. Afterwards, we use this coherence value in the optimization phase for the selection of sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Optimization</head><p>McDonald <ref type="formula" target="#formula_0">(2007)</ref> introduces summarization as an optimization task which takes care of importance, redundancy and coherence simultaneously. In this paper, we also propose a model for single doc- ument summarization which is based on integer linear programming (ILP). We consider ranks ob- tained by the HITS algorithm as sentence impor- tance. The weighted coherence measure is cal- culated using Equation 1 and Equation 2. PLOS Medicine articles are very long and contain repeti- tive information, so we have to deal with redun- dancy even in single-document summarization. Therefore we model non-redundancy as topic cov- erage in the final summary: the more topics in a summary, the less redundant the summary will be. The ILP objective function is shown in Equation 3. f i (X) is the function which maximizes im- portance, f c (X) maximizes coherence, and f t (Y ) maximizes topic coverage.</p><p>Objective f unction : max</p><formula xml:id="formula_1">X,Y (fi(X) + fc(X) + ft(Y ))<label>(3)</label></formula><p>X is a variable for sentences which contains boolean variables x i , where 0 &lt; i &lt; n is the num- ber of sentences. Y is a variable for topics which contains boolean variables y j , where 0 &lt; j &lt; m is the number of topics.</p><formula xml:id="formula_2">ft(Y ) = m j=1 yj (4)</formula><p>Constraints ensure that the system satisfies addi- tional requirements such as summary length:</p><formula xml:id="formula_3">n i=1 xi ≤ Len(summary)<label>(5)</label></formula><formula xml:id="formula_4">j∈T i yj ≥ |T opicsx i | · xi, for i = 1, . . . , n<label>(6)</label></formula><p>S1 WHO recommends prompt diagnosis and quinine plus clindamycin for treatment of uncomplicated malaria in the first trimester and artemisinin-based combination therapies in subsequent trimesters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S2</head><p>We undertook a systematic review of women's access to and healthcare provider adherence to WHO case management policy for malaria in pregnant women.</p><p>S3 Data were appraised for quality and content.</p><p>S4 Determinants of women's access and providers' case management practices were extracted and compared across studies. </p><p>The final summary should be shorter than the original text and it should also have a length limit (Equation 5). The results on PLOS medicine data (Section 3) are limited to 5 sentences. We have also experimented with multiple lengths. Increas- ing the summary length increases ROUGE scores. DUC 2002 summaries are limited to 100 words.</p><p>Equation 6 shows that topics present in sen- tence x i are selected, when sentence x i is selected. Therefore, x i = 1 and T i = T opics x i . The con- straint holds, because j∈T i y j = |T opics x i |. Fur- thermore, if sentence x i = 0, i.e., it is not se- lected, then there must be topics which are al- ready present in selected sentences. Hence, the constraint holds, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Following <ref type="bibr" target="#b12">Parveen and Strube (2015)</ref>, we evaluate on the science genre, i.e. PLOS Medicine articles, and on the news genre, i.e. DUC 2002 data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>PLOS Medicine articles are considerably longer than DUC 2002 documents. The average num- ber of sentences per document is 154 in PLOS Medicine and 25 in DUC 2002. Benefits of using PLOS Medicine articles for experiments are:</p><p>• They are accompanied by an authors' abstract.</p><p>• They have a summary written by an editor.</p><p>• They are formatted in XML.</p><p>• They contain explicit full forms of abbrevia- tions.</p><p>Editor's summaries have a different perspective, writing style and length than authors' abstracts. We use both as gold summaries for evaluation. Following Parveen and Strube (2015) we re- port the results using editor's summaries and au- thor's abstracts independently. To compare with the state-of-the-art in single-document summa- rization, we also evaluate on DUC 2002 data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Setup</head><p>We use the XML version of PLOS Medicine ar- ticles. We extract the contents excluding figures, tables and references. Editor's summary and au- thors' abstract are separated from the content for evaluation. The PLOS Medicine XML provides explicit full forms when abbreviations are intro- duced. We replace abbreviations with their full form in the summary. We then remove non- alphabetical characters. After this we parse ar- ticles using the Stanford parser <ref type="bibr" target="#b6">(Klein and Manning, 2003</ref>). We perform pronoun resolution using the coreference resolution system by Martschat (2013) 2 . We use gensim to generate the topics. For generating topics we use a dataset contain- ing scientific articles from biology, which con- tains 221,385 documents and about 50 million sentences 3 . We also use Wikipedia to compare with topics from a general domain.</p><p>The HITS algorithm is applied on the bipar- tite graph for computing sentence importance. We calculate the coherence values of sentences on weighted one-mode projection graphs. The impor- tance and coherence of a sentence is used in the optimization phase 4 which returns a binary value for each sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>Results on PLOS Medicine are shown in <ref type="table" target="#tab_1">Tables  1 and 2</ref>. We evaluate using ROUGE-SU4 and ROUGE-2 (Lin, 2004). We limit the length of the summaries to five sentences and the number of topics to 2000 in the topical graph. We also experimented with varying numbers of topics, i.e. 500, 1000 and 2000, and varying summary length limits. The results changed only marginally. The general trends remained the same. We compare our system with four different baselines and two versions of the entity graph. Lead selects the top five sentences, Random five sentences randomly. MMR is an implementation of maximal marginal relevance <ref type="bibr" target="#b1">(Carbonell and Goldstein, 1998)</ref>. TextRank is the graph-based system by <ref type="bibr" target="#b11">Mihalcea and Tarau (2004)</ref>  <ref type="bibr">5</ref> . Egraph is the entity graph based system by <ref type="bibr" target="#b12">Parveen and Strube (2015)</ref>. Egraph + Coh. is their system  which includes a coherence measure, which is cal- culated by using the unweighted projection graph. Egraph + Coh. + Pos. combines the coherence measure and positional information.</p><note type="other">Systems R-SU4 R-2 Lead 0.</note><p>Our system outperforms all baselines substan- tially, as shown in <ref type="table">Tables 1 (editor's summaries)</ref> and 2 (authors' abstracts). We observe improve- ments in the results when including coherence in the topical graph. We obtain best results with Tgraph + Coh., where the number of topics is 2000. In Tgraph, penalizing coherence mea- sures with positional information lowers ROUGE scores. While including positional information into the entity graph obtains the best results on the PLOS Medicine dataset, positional informa- tion does not appear to be beneficial for the topical graph. Absolute ROUGE scores are higher when using abstracts as gold summaries, because the ab- stracts are shorter than editor's summaries.</p><p>We compare results using biology journals (Ta- ble 3) and Wikipedia <ref type="table" target="#tab_3">(Table 4)</ref> to generate top- ics. The topical graph is denser when using bi- ology journals compared to the graph generated from Wikipedia. Results using the in-domain bi- ology journals as data to generate topics are better than using general domain Wikipedia data. The scores are highest with 2000 topics. For Bio topic the differences are negligible, however.</p><p>We also compare results on DUC 2002 to Topics R-1 R-2 R-SU4 Tgraph (n=500) + Coh.</p><p>0.279 0.090 0.125 Tgraph (n=1000) + Coh. 0.289 0.093 0.128 Tgraph (n=2000) + Coh. 0.291 0.095 0.129   <ref type="table" target="#tab_4">Table 5</ref>, because important information appears in the initial lines of news articles. DUC 2002 Best is the result reported by the top perform- ing system at DUC 2002. This system actually obtains better results than TextRank ( <ref type="bibr" target="#b11">Mihalcea and Tarau, 2004</ref>) and the more recent system Uniform- Link (Wan and Xiao, 2010). Our system Tgraph + Coh. performs better than the well known best systems on DUC 2002 and slightly better than Egraph + Coh. However the difference between the results of Tgraph and Egraph are not signifi- cant. In contrast to the entity graph based system, the coherence measure in our system is calculated by using a topic-based weighted projection graph, which is denser and hence more informative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Human Coherence Judgements</head><p>In addition to ROUGE scores, we use human judgements for evaluating the coherence of our summaries. We asked four PhD students in natural language processing to evaluate our summaries on the basis of coherence. We randomly selected ten summaries of scientific articles from three differ- ent systems, TextRank, Lead and Tgraph + Coh. We asked the human judges to rank the summaries according to their coherence. So, the summary  which is best in coherence gets rank 1, second best gets rank 2, and worst gets rank 3. We calculated the Kendall concordance coefficient (W ) <ref type="bibr" target="#b14">(Siegel and Castellan, 1988)</ref> to measure the judges' agree- ment. We obtain W = 0.61, which indicates a relatively high agreement.</p><p>To compare the three systems, we take the aver- age over the ranks. The overall rank of TextRank is 2.625, Lead is 1.675 and Tgraph + Coh. is 1.8. Lead performs best, because it selects the top five consecutive sentences, which are coherent as the original authors intended them to be. However, the overall ranks of Lead and Tgraph + Coh. are not significantly different, whereas TextRank's over- all rank is significantly worse than both. Hence, Tgraph + Coh. performs very well in our human judgement coherence experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>In this paper we introduced the topical graph for single document summarization. We experi- mented with multiple numbers of topics on the sci- entific article dataset. Our system performs well when including the weighted coherence measure in the optimization phase. The results are compa- rable with the entity graph. However, the entity graph is less informative and very sparse as com- pared to the topical graph. Our system does not need annotated training data and, except for the number of topics, no optimization of parameters. Hence, we consider it unsupervised.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Abstract from PLOS Medicine, topical grid, bipartite topical graph, one-mode projection</figDesc><graphic url="image-1.png" coords="3,74.73,273.46,304.90,93.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Equation 7 constrains the selection of topics. If topic y j = 1, then at least one sentence containing this topic has been selected. Therefore i∈S j x i ≥ 1, and the constraint holds. If topic y j = 0, then sentences containing this topic are not selected, so i∈S j x i = 0, and the constraint holds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : PLOS Medicine, authors' abstracts</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 : PLOS Medicine, editor's summ., Bio topic</head><label>3</label><figDesc></figDesc><table>Topics 
R-1 
R-2 
R-SU4 
Tgraph (n=500) + Coh. 
0.208 0.060 
0.098 
Tgraph (n=1000) + Coh. 0.258 0.073 
0.106 
Tgraph (n=2000) + Coh. 0.283 0.086 
0.121 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>PLOS Medicine, editor's summ., Wiki 
topic 

check against the state-of-the-art on a well-known 
dataset. Lead performs well on DUC 2002 as 
shown in </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 : DUC 2002, single-document summariza- tion</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://journals.plos.org/ plosmedicine/</note>

			<note place="foot" n="2"> http://www.smartschat.de/software/ 3 http://www.datawrangling.com/ some-datasets-available-on-the-web/ 4 We use Gurobi, http://www.gurobi.com 5 https://kenai.com/projects/ textsummarizer</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been funded by the Klaus Tschira Foundation, Heidelberg, Germany. The first au-thor has been supported by a Heidelberg Insti-tute for Theoretical Studies Ph.D. scholarship. This work has been supported by the German Re-search Foundation as part of the Research Training Group "Adaptive Preparation of Information from Heterogeneous Sources" (AIPHES) under grant No. GRK 1994/1. We would like to thank our colleagues Sebastian Martschat, Nafise Moosavi, Alex Judea and Mohsen Mesgar who served as hu-man subjects and commented on earlier drafts.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Mining: Classification, Clustering, and Applications</title>
		<editor>A. Srivastava and M. Sahami</editor>
		<meeting><address><addrLine>Boca Raton, Flo</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman &amp; Hall</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The use of MMR, diversity-based reranking for reordering documents and producing summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jade</forename><surname>Goldstein</surname></persName>
		</author>
		<idno>24-28 Au- gust 1998</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 21st Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="335" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LexRank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Günesgünes¸günes¸erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Movie script summarization as graph-based scene extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Gorinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Col.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-31" />
			<biblScope unit="page" from="1066" to="1076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camille</forename><surname>Guinaudeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graph-based local coherence modeling</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08-09" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="93" to="103" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-07" />
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Authoritative sources in a hyperlinked environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="604" to="632" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Summarization Branches Out Workshop at ACL &apos;04</title>
		<meeting>the Text Summarization Branches Out Workshop at ACL &apos;04<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multigraph clustering for unsupervised coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">51st Annual Meeting of the Association for Computational Linguistics: Proceedings of the Student Research Workshop</title>
		<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A study of global inference algorithms in multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Information Retrieval</title>
		<meeting>the European Conference on Information Retrieval<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-04" />
			<biblScope unit="page" from="2" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">TextRank: Bringing order into texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Integrating importance, non-redundancy and coherence in graph-based extractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daraksha</forename><surname>Parveen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 24th International Joint Conference on Artificial Intelligence<address><addrLine>Buenos Aires, Argentina</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="1298" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Three knowledge-free methods for automatic lexical chain extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Remus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="989" to="999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Nonparametric Statistics for the Behavioral Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sidney</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N. John</forename><surname>Castellan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exploiting neighborhood knowledge for single document summarization and keyphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">pages</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
