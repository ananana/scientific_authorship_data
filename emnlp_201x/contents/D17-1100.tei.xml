<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deriving continous grounded meaning representations from referentially structured multimodal contexts</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sina</forename><surname>Zarrieß</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dialogue Systems Group // CITEC // Faculty of Linguistics and Literary Studies</orgName>
								<orgName type="institution">Bielefeld University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dialogue Systems Group // CITEC // Faculty of Linguistics and Literary Studies</orgName>
								<orgName type="institution">Bielefeld University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deriving continous grounded meaning representations from referentially structured multimodal contexts</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="959" to="965"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Corpora of referring expressions paired with their visual referents are a good source for learning word meanings directly grounded in visual representations. Here, we explore additional ways of extracting from them word representations linked to multi-modal context: through expressions that refer to the same object , and through expressions that refer to different objects in the same scene. We show that continuous meaning representations derived from these contexts capture complementary aspects of similarity , even if not outperforming tex-tual embeddings trained on very large amounts of raw text when tested on standard similarity benchmarks. We propose a new task for evaluating grounded meaning representations-detection of potentially co-referential phrases-and show that it requires precise denotational representations of attribute meanings, which our method provides.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Various routes for linking language to extra- linguistic context have been explored in recent years. A lot of research has looked at integrating visual representations, either directly ( <ref type="bibr" target="#b20">Matuszek et al., 2012;</ref><ref type="bibr" target="#b13">Krishnamurthy and Kollar, 2013;</ref><ref type="bibr" target="#b30">Yu et al., 2016;</ref><ref type="bibr" target="#b24">Schlangen et al., 2016)</ref> or through mapping into a multi-modal distributional space <ref type="bibr" target="#b7">(Feng and Lapata, 2010;</ref><ref type="bibr" target="#b2">Bruni et al., 2012;</ref><ref type="bibr" target="#b10">Kiela and Bottou, 2014;</ref><ref type="bibr" target="#b16">Lazaridou et al., 2015)</ref>. <ref type="bibr" target="#b29">Young et al. (2014)</ref> have explored a less direct link, by representing the extension of phrasal expressions as sets of images, and deriving from this a pre- cise notion of denotational similarity. In very re- grounded language, and similarity relations that can be de- rived from it, image from MSCOCO ( <ref type="bibr" target="#b18">Lin et al., 2014))</ref> cent work, <ref type="bibr" target="#b3">Cocos and Callison-Burch (2017)</ref> use spatial context from geo-located tweets to induce word embeddings that capture situational similar- ity between lexical items.</p><p>In this paper, we explore an approach that com- bines aspects of several of these paths. Start- ing point is the observation that corpora of ex- ophoric referring expressions provide richly struc- tured contexts that go beyond just linking indi- vidual expressions with their denotations. As an example consider the scene in <ref type="figure" target="#fig_0">Figure 1</ref> depicting several referents and corresponding referring ex- pressions produced by different speakers. This scene provides a learner not only with an exam- ple of a referent for the word lady, it also pro- vides the information that lady can co-refer with girl, and that its denotations can spatially / situ- ationally co-occur with those of table and cake. From these types of information we infer word embeddings, following the method from <ref type="bibr" target="#b17">Levy and Goldberg (2014)</ref> for training embeddings on arbi-trary non-linear context, and we show that these capture complementary aspects of word similarity that purely textual induction methods conflate. We also show that these representations handle a more directly referential similarity task better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Word Embeddings from Multi-Modal Referential Contexts</head><p>We base our study on the REFERIT and REF- COCO corpus <ref type="bibr" target="#b9">(Kazemzadeh et al., 2014;</ref><ref type="bibr" target="#b30">Yu et al., 2016</ref>) building upon image collections by <ref type="bibr" target="#b8">(Grubinger et al., 2006</ref>) and ( <ref type="bibr" target="#b18">Lin et al., 2014)</ref>; for the latter, we also use referring expressions collected by <ref type="bibr" target="#b19">Mao et al. (2015)</ref>. This corpus gives us visual scenes containing sets of objects, s = o 1 , . . . , o n . Each object is associated with a set of referring expressions r 1 , . . . , r m ; and we use a standard method (a ConvNet) for providing a visual rep- resentation vis i for it. Each referring expression, in turn, is defined as a linear sequence of words r i = w 1 . . . w k . In the following, we structure this context into four dimensions-visual, textual, sit- uational and denotational-which we use to derive different word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Textual Context (TXT)</head><p>We learn standard distributional word embeddings from our corpus, ignoring extra-linguistic context. We train a skip-gram model ( <ref type="bibr" target="#b21">Mikolov et al., 2013</ref>) with negative sampling with window width 5, 300 dimensions. For comparison, we also use the tex- tual word embeddings provided by <ref type="bibr" target="#b0">Baroni et al. (2014)</ref>, trained on a much larger web corpus (5- word context window, 10 negative samples, 400 dimensions). We distinguish the two textual em- beddings using the subscripts TXT ref , TXT web .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Grounding (VIS)</head><p>Given a set of referring expressions contain- ing the word w and their corresponding referent (o j , r j ), w ∈ r j , we can derive a visual context for the word w by averaging over the visual rep- resentations of its referents vis j , as proposed for instance by <ref type="bibr" target="#b10">Kiela and Bottou (2014)</ref>. The vi- sual context of a word can be seen as a 'visual prototype'. We derive representations of our vi- sual inputs with a convolutional neural network, "GoogLeNet" ( <ref type="bibr">Szegedy et al., 2015)</ref>, that was trained on data from the ImageNet corpus <ref type="bibr" target="#b5">(Deng et al., 2009)</ref>, and extract the final fully-connected layer before the classification layer, to give us a 1024 dimensional representation of the region. Following ( <ref type="bibr" target="#b24">Schlangen et al., 2016)</ref>, we also add 7 features that encode information about the region relative to the image, the full representation hence is a vector of 1031 features. Each word is then represented as the average over its visual vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Situational Grounding (SIT)</head><p>We also train word embeddings (dim. 300) that predict words paired with their situational con- text, following the method by <ref type="bibr" target="#b17">Levy and Goldberg (2014)</ref>. This captures similarities between words occurring for different objects in the same scene, e.g. cake in the context of table in <ref type="figure" target="#fig_0">Fig- ure 1</ref>. Given a pair of referring expressions (r i , o i ), (r j , o j ), o i = o j , r i and r j are co- situational expressions. Thus, for a word w i ∈ r i , we consider all words w j ∈ r j as its situational context. In practice, we compute situational con- texts only for the head nouns of each referring ex- pression, as we expect situational similarities to be useful for capturing similarities between nouns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Denotational Grounding (DEN)</head><p>As our data typically records multiple co- referential expressions for an object (3 expressions on average in the REFCOCO data), we define the denotational context based on sets of expressions referring to the same object</p><formula xml:id="formula_0">(r 1 , o i ) . . . (r n , o i ).</formula><p>For a word w i ∈ r i , we consider all words w j l (with w j l ∈ r j ) as denotational context, where r j and r i refer to the same object. When two words occur in a denotational context, we have strong evidence that they are semantically com- patible, i.e. can refer to the same objects as girl and lady in <ref type="figure" target="#fig_0">Figure 1</ref> do. Similar to our train- ing procedure for situational embeddings, we now learn 300-dimensional word embeddings that pre- dict occurrences of a word based on co-referential contexts, pairing each word with all words from referring expressions describing the same object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Word Similarity and Relatedness</head><p>We now have four different continuous representa- tions for words; in the following, we evaluate them for how well they predict semantic relations.</p><p>Similarity We evaluate on some similarity data sets, reporting Spearman ρ correlations between human ratings and cosine similarities for word vectors. We use the MEN ( <ref type="bibr" target="#b2">Bruni et al., 2012</ref>) and <ref type="bibr" target="#b25">Silberer and Lapata (2014)</ref>'s data with semantic (SemSim) and visual similarity (VisSim) ratings.</p><p>Compatibility As generic semantic similarity judgements are known to be "fuzzy" <ref type="bibr" target="#b6">(Faruqui et al., 2016)</ref>, we also evaluate on <ref type="bibr" target="#b14">Kruszewski and Baroni (2015)</ref>'s benchmark on semantic compat- ibility. They define two words as being semanti- cally compatible "if they can potentially refer to the same thing". We expect our denotational and visual embeddings to be highly useful for this task. We report unsupervised results obtained from co- sine similarities between word embeddings.</p><p>Hypernym Directionality We adopt an evalu- ation procedure by <ref type="bibr" target="#b12">Kiela et al. (2015b)</ref> on hy- pernym pairs in the BLESS data set ( <ref type="bibr" target="#b1">Baroni and Lenci, 2011</ref>). Given a general (e.g. 'animal') and a concrete noun (e.g. 'dog') that stand in the hyper- nym relation, the task is to identify the noun that is more general. <ref type="bibr" target="#b16">Lazaridou et al. (2015)</ref> found that the generality or concreteness of a noun's meaning is reflected in the entropy of its embedding, and we adopt that measure for our purposes. Thus, we compute entropies of our word embeddings and report accuracies corresponding to the proportion of noun pairs where the entropy of the more gen- eral noun is higher than the more concrete noun.</p><p>Vocabulary We intersect the vocabularies cov- ered by the different embeddings, which amounts to 1960 words in total. We restrict evaluation to the corresponding word pairs in the above data sets, coverage is reported in <ref type="table">Table 1</ref>.</p><p>Results As shown in <ref type="table">Table 1</ref>, the performance of embeddings learned on referring expression cor- pora are generally below state-of-the-art distribu- tional vectors trained on large web corpora. How- ever, some interesting tendencies can be observed by comparing embeddings learned from different context dimensions. Denotational embeddings in isolation provide a precise representation of mean- ing that outperforms the other types of embed- dings on semantic similarity judgements in MEN and SemSim, and detects hypernym directionality most accurately. An interesting exception is the compatibility data set where visual embeddings clearly outperform textual and denotational em- beddings. Situational embeddings perform less well than textual and denotational embeddings but, interestingly, are similar in performance to vi- sual embeddings on semantic similarity, suggest-  ing that visual and situational similarity seem to be equally important aspects of general semantic similarity. Concatenation of denotational and tex- tual embeddings yields the best results for corre- lations with human similarity judgements. This is expected as denotational similarity is probably too restricted for generic semantic similarity. We ex- perimented with further embedding combinations, but only the fusion of the textual and denotational dimension outperformed the embeddings obtained from a particular grounding dimension. <ref type="table" target="#tab_1">Table 2</ref> shows correlations on cosine similari- ties on all word pairs from MEN, SemSim, VisSim and Compatibility between our word embeddings. This further corroborates the finding that different dimensions of grounding lead to complementary notions of similarity. In particular, correlation be- tween visual and situational embeddings is rela- tively low, as compared to more fuzzy textual em- beddings which correlate well with denotational embeddings. For a qualitative analysis, more ex- amples are shown in Appendix A. <ref type="table" target="#tab_2">Table 3</ref> illustrates sim- ilarities learned from different grounding dimen- sions by means of some qualitative examples. Whereas denotational and visual embeddings rank semantically compatible words on top (e.g. grass- grassy), situational embeddings clearly focus more on topical similarity (grass-clouds). Given these examples, the finding that visual embed- dings outperform denotational embeddings on the semantic compatibility task (see <ref type="table">Table 1</ref>) seems rather contradictory. A preliminary error analy- sis suggests that the compatibility ratings that hu- mans provide 'out of context' in a rating task differ to some extent from referential choices in our cor- pus. As an example, in the compatibility data set, the words pigeon and mother are rated as being equally similar to animal. However, in our cor- pus of referring expressions, mother is never used to refer to animal entities and our denotational embeddings predict them to be highly dissimilar, whereas visual embeddings are slightly more ro- bust in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qualitative Discussion</head><p>More generally, textual embeddings learned from referring expressions captures a much more fuzzy and generic notion of similarity than de- notational, visual or situational embeddings, e.g. grass is similar to shrubs and to sand in the tex- tual space. This fuzziness has been found for word embeddings trained on large amounts of raw text as well <ref type="bibr" target="#b6">(Faruqui et al., 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Approximate Co-Reference Detection</head><p>Another important testbed for models of lexical meaning is their ability to capture semantic in- ference, with textual entailment as a well-known paradigm: here the task is to predict whether a textual hypothesis h can be inferred from a given premise p ( <ref type="bibr" target="#b4">Dagan et al., 2006</ref>). <ref type="bibr" target="#b29">Young et al. (2014)</ref> have proposed a less strict variant of this called "approximate textual entailment". The main idea is that premise and hypothesis candidates can be automatically extracted from a corpus of cap- tioned images. Given a set of captions known to describe the same image and an hypothesis, the task is to determine whether the hypothesis can de- scribe the same image as the premise.</p><p>Inspired by this approach, we use the multi- modal corpus of referring expressions to set up a new task for evaluating word embeddings, which consists of capturing approximate inferential re- lations between referring expressions. Thus, in our case, the hypothesis and the premise are ex- pressions referring to objects, and the task is to determine whether they could (potentially) refer to the same object. Note that this is also similar to the notion of semantic compatibility proposed by <ref type="bibr" target="#b14">Kruszewski and Baroni (2015)</ref>, but extended to phrasal expressions. We can automatically ex- tract positive and negative pairs from the data (see Section 2) by looking at pairs of expressions re- ferring to objects in the same image and distin- guishing coreferential expressions referring to the same entity (e.g. grandma -old lady), and non-coreferential expressions referring to differ- ent entities, e.g. old lady -young lady. In con- trast to the majority of existing similarity and re- latedness benchmarks which are centered around nouns, this task requires precise meaning repre- sentations for attribute-like words (e.g. left-right, old-young) which occur frequently in our data and which are frequently used to distinguish between objects occurring in the same situation. In partic- ular, as the scenes in our data sets contain many objects of the same category (e.g. in the REF- COCO data), the distinction can often not be made by looking at the noun only, e.g. for classifying 'old lady' -'young lady' as non-coreferential.</p><p>We call this task approximate coreference de- tection as the premise and hypothesis might de- scribe complementary aspects of the same object such that the distinction cannot be made perfectly without the original perceptual context. For in- stance, in some cases, lady in blue and young lady might denote the same referent, in others not (see <ref type="figure" target="#fig_0">Figure 1</ref>). Thus, we note that the upper bound for automatic (or human) performance in this task is clearly not 100%. In future work, we plan to com- bine this with a reference resolution system that grounds the expressions in a given image.</p><p>Data and Set-up Given an image with several objects and a set of expressions referring to these, we compute the set of expression pairs P for that image. This set now divides into positive in- stances, i.e. expressions that both refer to the same object in the image, and negative instances, i.e. expressions that describe distinct entities in the scene. As this gives us a lot of data, we adopt a su- pervised learning approach for modeling the task of approximate co-reference detection. Thus, we use our embeddings to extract a range of similarity measures between the expression pairs and feed these metrics as features into a classifier, trained to predict whether two phrases co-refer. This set-up is largely similar to <ref type="bibr" target="#b29">Young et al. (2014)</ref>'s evalua- tion setting for approximate textual entailment.</p><p>Similarity Measures Given a pair P of ex- pressions r i = w i 1 . . . w in , r j = w j 1 . . . w jm , we extract pairwise cosine similarities be- tween the embeddings cos(w ix , w jy ), using av- erage (</p><formula xml:id="formula_1">(w i ,w j )∈P cos(w i , w j ) × 1 |P | )</formula><p>, maximum (max (w i ,w j )∈P cos(w i , w j )) and minimum dis- tance (min (w i ,w j )∈P cos(w i , w j )) as features for classification. Furthermore, we restrict the words in each expression such that they are disjunct sets excluding words that occur in both expressions, w i = w j , ∀(w i , w j ) ∈ P . We extract the same average, maximum and minimum distance mea- sures on these lexically disjunct expressions. Fi- nally, we compose word embeddings for each ex- pressions via addition (r i = w i 1 + . . . + w in ) and add the cosine between the composed embeddings (cos(r i , r j )) to our list of features. Here, we com- pare textual, visual and denotational embeddings, as our situational embeddings only cover nouns.</p><p>Training From REFERIT, we extract 161K training and 18K test pairs, dividing into 66% non-coreferential and 34% coreferential expres- sions. We re-train our embeddings on the train- ing portions of this data. We only consider non- coreferential expressions that refer to objects of the same type, according to their label annotated in the data set. From REFCOCO, we extract 300k pairs from the training set and 95k pairs from the test set, dividing into roughly 70% non- coreferential and 30% coreferential expressions. We randomly sample these pairs, the overall num- ber of possible pairs in REFCOCO exceeds 2 mil- lion. We train a binary logistic regression classi- fier on each corpus, given the similarity measures extracted for each word embedding.</p><p>Results We report accuracies on co-referential expression detection in <ref type="table" target="#tab_4">Table 4</ref>, on REFERIT and REFCOCO. Similarities derived from denotational embeddings clearly outperform the other classi- fiers on both data sets, including state-of-the-art textual embeddings learned on a much larger web corpus. On REFCOCO, only denotational embed- dings lead to a clear improvement over the major- ity baseline. While the low performance of stan- dard distributional embeddings is rather expected   on this task (see previous findings on e.g. pre- dicting antonyms <ref type="bibr" target="#b22">(Nguyen et al., 2016)</ref>), the clear advange of denotational over visual embeddings is noteworthy. Whereas visual grounding is rel- atively effective for modeling compatibility be- tween nouns (see <ref type="table">Table 1</ref>), it does not seem to capture attribute meaning accurately as illustrated in <ref type="table" target="#tab_5">Table 5</ref>. Here, the average of all visual ob- jects referred to as e.g. small seems to be rather noisy and lead to high similarity with rather ran- dom words (directly) whereas denotational em- beddings model accurate compatibility relations between e.g. small-smaller.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Whereas it is notoriously difficult to tailor or spe- cialise distributional meaning representations in- ferred from text to particular aspects of seman- tic relatedness ( <ref type="bibr" target="#b11">Kiela et al., 2015a;</ref><ref type="bibr" target="#b22">Nguyen et al., 2016;</ref><ref type="bibr" target="#b23">Rimell et al., 2017)</ref>, this work has shown that a multi-modal corpus of referring expressions can be used to derive a range of continuous mean- ing representations grounded in different aspects of context, capturing different notions of similar- ity. As compared to visual embeddings used in previous works, we found that denotational em- beddings are particularly useful for detecting se- mantic relations. Other, recently proposed tasks related to modeling word association <ref type="bibr" target="#b28">(Vuli´cVuli´c et al., 2017)</ref>, commonsense knowledge ( <ref type="bibr" target="#b27">Vedantam et al., 2015)</ref> or child-directed input ( <ref type="bibr" target="#b15">Lazaridou et al., 2016</ref>) provide interesting testbeds for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Dimensions of context in referential, visually</figDesc><graphic url="image-8.png" coords="1,365.65,402.09,81.00,81.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Model correlations</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 : Top nearest neighbours for some example noun embeddings</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Accuracies for co-referential expression detection 

top txt ref upper, bototm, bottom, bottem 
den upper, topmost, tippy, above 
vis upper, above, of, corner 
red 
text yellow, purple, maroon, blue 
den maroon, redman, reddish, allmiddle 
vis and, purple, yellow, pink 
small txt ref large, smaller, big, tiny 
den smaller, smallest, little, littiest 
vis directly, of, between, slightly 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Top nearest neighbours for some example adjec-

tives embeddings 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We acknowledge support by the Cluster of Excellence "Cognitive Interaction Technology" (CITEC; EXC 277) at Bielefeld University, which is funded by the German Research Foundation (DFG).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Don&apos;t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">How we blessed distributional semantic evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics</title>
		<meeting>the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distributional semantics in technicolor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namkhanh</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="136" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The language of place: Semantic value from geospatial context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Cocos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="99" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR09</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Problems with evaluation of word embeddings using word similarity tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpendre</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 1st Workshop on Evaluating Vector Space Representations for NLP</title>
		<meeting>of the 1st Workshop on Evaluating Vector Space Representations for NLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visual information in semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The IAPR TC-12 benchmark: a new evaluation resource for visual information systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Language Resources and Evaluation (LREC 2006)</title>
		<meeting>the International Conference on Language Resources and Evaluation (LREC 2006)<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="13" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ReferItGame: Referring to Objects in Photographs of Natural Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahar</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Matten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="787" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning Image Embeddings using Convolutional Neural Networks for Improved Multi-Modal Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Specializing word embeddings for similarity or relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2044" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting image generality for lexical entailment detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="119" to="124" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Jointly learning to parse and perceive: Connecting natural language to the physical world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kollar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="193" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">So similar and yet incompatible: Toward the automated identification of semantically compatible words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="964" to="969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multimodal semantic learning from child-directed input</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Chrupała</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="387" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Combining language and vision with a multimodal skip-gram model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nghia The</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
	<note>Denver</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dependencybased word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision ECCV</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">8693</biblScope>
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Generation and comprehension of unambiguous object descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhua</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oana</forename><surname>Camburu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<idno>abs/1511.02283</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ArXiv / CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Joint Model of Language and Perception for Grounded Attribute Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liefeng</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS 2013</title>
		<meeting>NIPS 2013<address><addrLine>Lake Tahoe, Nevada, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Integrating distributional lexical contrast into word embeddings for antonymsynonym distinction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Kim Anh Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Schulte Im Walde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="454" to="459" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to negate adjectives with bilinear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amandla</forename><surname>Mabona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luana</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Resolving references to objects in photographs using the words-as-classifiers model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sina</forename><surname>Zarriess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Kennington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54rd Annual Meeting of the Association for Computational Linguistics (ACL 2016)</title>
		<meeting>the 54rd Annual Meeting of the Association for Computational Linguistics (ACL 2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>page To appear</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning grounded meaning representations with autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="721" to="732" />
		</imprint>
	</monogr>
	<note>Baltimore</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2015</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning common sense through visual abstraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanmay</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2542" to="2550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Evaluation by association: A systematic study of quantitative word association evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="163" to="175" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="67" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Modeling Context in Referring Expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Licheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Poirson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
