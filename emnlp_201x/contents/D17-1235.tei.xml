<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis</forename><surname>Shao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Britz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Goldie</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Strope</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Kurzweil</surname></persName>
						</author>
						<title level="a" type="main">Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2210" to="2219"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
					<note>1 Google Research and 2 Google Brain Mountain View, CA, USA and 3 Google Brain London, UK</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Sequence-to-sequence models have been applied to the conversation response generation problem where the source sequence is the conversation history and the target sequence is the response. Unlike translation, conversation responding is inherently creative. The generation of long, informative, coherent, and diverse responses remains a hard task. In this work, we focus on the single turn setting. We add self-attention to the de-coder to maintain coherence in longer responses, and we propose a practical approach, called the glimpse-model, for scaling to large datasets. We introduce a stochastic beam-search algorithm with segment-by-segment reranking which lets us inject diversity earlier in the generation process. We trained on a combined data set of over 2.3B conversation messages mined from the web. In human evaluation studies, our method produces longer responses overall, with a higher proportion rated as acceptable and excellent as length increases, compared to baseline sequence-to-sequence models with explicit length-promotion. A back-off strategy produces better responses overall, in the full spectrum of lengths.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Building computer systems capable of general- purpose conversation is a challenging problem. However, it is a necessary step toward building in- telligent agents that can interact with humans via * Both authors contributed equally to this work.</p><p>† Work done as a member of the Google Brain Residency program (g.co/brainresidency).</p><p>natural language, and for eventually passing the Turing test. The sequence-to-sequence (seq2seq) model has proven very popular as a purely data- driven approach in domains that can be cast as learning to map to and from variable-length se- quences, with state-of-the art results in many do- mains, including machine translation ( <ref type="bibr" target="#b9">Sutskever et al., 2014;</ref><ref type="bibr">Wu et al., 2016)</ref>. Neural conversation models are the latest devel- opment in the domain of conversation modeling, with the promise of training computers to converse in an end-to-end fashion ( <ref type="bibr" target="#b11">Vinyals and Le, 2015;</ref><ref type="bibr" target="#b7">Shang et al., 2015;</ref><ref type="bibr" target="#b8">Sordoni et al., 2015;</ref><ref type="bibr" target="#b13">Wen et al., 2016)</ref>. Despite promising results, there are still many challenges with this approach. In particu- lar, these models produce short, generic responses that lack diversity ( <ref type="bibr" target="#b8">Sordoni et al., 2015;</ref><ref type="bibr" target="#b7">Li et al., 2015)</ref>. Even when longer responses are explicitly encouraged (e.g. via length normalization), they tend to be incoherent ("The sun is in the center of the sun."), redundant ("i like cake and cake"), or contradictory ("I don't own a gun, but I do own a gun.").</p><p>In this paper, we provide two methods to ad- dress these issues with minimal modifications to the standard seq2seq model. First, we present a glimpse model that only trains on fixed-length segments of the target-side at a time, allowing us to scale up training to larger data sets. Sec- ond, we introduce a segment-based stochastic de- coding technique which injects diversity earlier in the generated responses. Together, we find that these two methods lead to both longer re- sponses and higher ratings, compared to a baseline seq2seq model with explicit length and diversity- promoting heuristics integrated into the generation procedure (see <ref type="table">Table 1</ref> for examples generated us- ing our model).</p><p>In Section 2, we present a high-level overview of these two techniques. We then discuss each technique in more detail in Sections 3 and 4. Fi- nally, we report small and large-scale experimen- tal evaluations of the proposed techniques in Sec- tion 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview and Motivation</head><p>A major difference between translation and re- sponding to conversations is that, in the former, the high-level semantic content to generate in the tar- get sequence y is completely given by the source sequence, i.e., given the source x, there is low con- ditional entropy in the target distribution P (y|x). In the seq2seq approach, the decoder network therefore only has to keep track of where it is in the output, and the content to generate can be trans- formed from the relevant parts in the source via the attention mechanism ( ). In contrast, in conversation response generation, the prompt turn may be short and general (e.g., "what do you have planned tonight"), while an appropri- ate response may be long and informative.</p><p>The standard seq2seq model struggles with gen- erating long responses, since the decoder has to keep track of everything output so far in its fixed- length hidden state vector, which leads to incoher- ent or even contradictory outputs. To combat this, we propose to integrate target-side attention into the decoder network, so it can keep track of what has been output so far. This frees up capacity in the hidden state for modeling the higher-level se- mantics required during the generation of coherent longer responses. We were able to achieve small perplexity gains using this idea on the small Open- Subtitles 2009 data set <ref type="bibr" target="#b10">(Tiedemann, 2009)</ref>. How- ever, we found it to be too memory-intensive when scaling up to larger data sets.</p><p>As a trade-off, we propose a technique (called the 'glimpse model') which interpolates between source-side-only attention on the encoder, and source and target-side attention on the encoder and decoder, respectively. Our solution simply trains the decoder on fixed-length glimpses from the target side, while having both the source se- quence and the part of the target sequence before the glimpse on the encoder, thereby sharing the at- tention mechanism on the encoder. This can be implemented as a simple data-preprocessing tech- nique with an unmodified standard seq2seq imple- mentation, and allows us to scale training to very large data sets without running into any memory issues. See <ref type="figure">Figure 1</ref> for a graphical overview, where we illustrate this idea with a glimpse-model of length 3.</p><p>Given such a trained model, the next chal- lenge is how to generate long, coherent, and di- verse responses with the model. As observed in the previous section and in other work, stan- dard maximum a posteriori (MAP) decoding us- ing beam search often yields short, uninforma- tive, and high-frequency responses. One ap- proach to produce longer outputs is to em- ploy length-promoting heuristics (such as length- normalization ( <ref type="bibr">Wu et al., 2016)</ref>) during decod- ing. We find this increases the length of the out- puts, however often at the expense of coherence. Another approach to explicitly create variation in the generated responses is to rerank the N -best MAP-decoded list of responses from the model us- ing diversity-promoting heuristics ( <ref type="bibr" target="#b7">Li et al., 2015)</ref> or a backward <ref type="bibr">RNN (Wen et al., 2015</ref>). We find this works for shorter responses, but not for long responses, primarily for two reasons: First, the method relies on the MAP-decoding to pro- duce the N -best list, and as mentioned above, MAP-decoding prefers short, generic responses. Second, it is too late to delay reranking in the beam search until the whole sequence has been generated, since beam-search decoding tends to yield beams with low diversity per given prompt, even when the number of beams is high. In- stead, our solution is to break up the reranking over shorter segments, and to rerank segment-by- segment, thereby injecting diversity earlier during the decoding process, where it has the most impact on the resulting diversity of the generated beams.</p><p>To further improve variation in the generated responses, we replace the deterministic MAP- decoding of the beam search procedure with sam- pling. If a model successfully captures the distri- bution of responses given targets, one can expect simple greedy sampling to produce reasonable re- sponses. However, due to model underfitting, the learned distributions are often not sharp enough, causing step-by-step sampling to accumulate er- rors along the way, manifesting as incoherent out- puts. We find that integrating sampling into the beam-search procedure yields responses that are more coherent and with more variation overall.</p><p>In summary, the contributions of this work are the following:</p><p>1. We propose to integrate target-side attention in neural conversation models, and provide a PROMPT:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESPONSE FROM BASELINE (A) vs OUR METHOD (B)</head><p>what do you have planned tonight A: I have no idea what I want to do with my life. I have no idea what I want to (Bad, Mediocre, Bad) B: I was planning on doing a few of these, but I'm not sure what to choose. I need to find a place to camp, and I don't have a lot of time to make a plan. (Excellent, Good, Mediocre) I'd like to read a good science fiction novel. Haven't read scifi in a while.</p><p>A: If you like sci fi you should check out The Name of the Wind by Patrick Rothfuss (Excellent, Excellent, Excellent) B: If you want to know what sci-fi is, read the first book by Neil Gaiman. It's a sci-fi sci-fi sci-fi novel. It is really good and I recommend it to all of you. It has a great premise. (Acceptable, Excellent, Acceptable)</p><p>Got any big weekend plans? A: I have plans for the weekend but I don't know if I will be able to make it to the (Bad, Mediocre, Bad) B: I don't really have much to do on Saturday. But I plan on going to the movies at the mall and going to the show. (Good, Good, Bad) Sometimes flying messes my ears, because of the air pressure. Especially if I have a cold or something, flying gets me messed up.</p><p>A: I don't know why, but when I was a kid I used to do this all the time when I was younger. (Good, Bad, Bad) B: I have no idea why, but I feel exactly the same way. I don't know why, but my brain is so sensitive to air that it makes my nose twitch. (Excellent, Mediocre, Good) Yeah. I have this friend, and we get bored just hanging out here sometimes, so we take little trips to places. We went to Seattle a couple of months ago.</p><p>A: What kind of things do you like to do? (Excellent, Excellent, Excellent) B: That sounds like a great time. I have a lot of friends that go to Seattle, so I was wondering if you could share any of the locations? <ref type="bibr">(Excellent, Excellent, Excellent)</ref> have you seen Suicide Squad?</p><p>A: I have not, but I will check it out. (Good, Good, Good) B: I saw it in a theater once and it was great. It was very... I don't know, a little dark. I like the psychological effects and the way it portrays the characters in the movie. (Excellent, Excellent, Excellent) Actually I like the snow too, except for today. It's all slushy and it's all over the sidewalks and it's gross.</p><p>A: I hate the snow. I hate the snow. I hate the snow. I hate the snow. I hate the snow. I hate the snow. I hate the snow. I hate the snow. (Acceptable, Good, Good) B: I'm in the same boat as you. I hate it when it's snowy and I don't like to shovel it all day. :( So this is a perfect excuse to not get out of bed and go somewhere else. (Excellent, Good, Acceptable)</p><p>What do you hope to see in the future? A: I want to be able to go back in time to when I was born. I want to be (Mediocre, Bad, Mediocre) B: I want to see an actual movie where the characters have the ability to hide the fact that they are actually in the movie. (Good, Acceptable, Acceptable)</p><p>what dangers could happen with the singularity? A: I don't think it would be that big of a deal. (Acceptable, Mediocre, Acceptable) B: If you look at it from the perspective of an alien, you can't say that there aren't any alternative ways to deal with it. (Accept- able, Mediocre, Acceptable)</p><p>I think you're a little crazy.  <ref type="table">Table 1</ref>: Some example responses generated from the baseline (A) compared to our model (B), with human ratings in parentheses. These were selected for quality. See the appendix for an unbiased sample.</p><p>practical approach, referred to as the glimpse model, which scales well and is easy to im- plement on top of the standard sequence-to- sequence model.</p><p>2. We introduce a stochastic beam-search pro- cedure with segment-by-segment reranking which improves the diversity of the generated responses.</p><p>3. We present large-scale experiments with hu- man evaluations showing the proposed tech- niques improve over strong baselines.</p><p>4. We release our collection of context-free con- versation prompts used in our evaluations as a benchmark for future open-domain conver- sation response research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Seq2Seq Model with Attention on Target</head><p>We discuss conversation response generation in the sequence-to-sequence problem setting. In this setting, there is a source sequence x = (x 1 , x 2 , ..., x M ), and a target sequence y = (y 0 , y 1 , y 2 , ..., y N ). We assume y 0 is always the start-of-sequence token and y N is the end-of- sequence token. In a typical sequence-to-sequence model, the encoder gets its input from the source sequence x and the decoder models the condi- tional language model P (y|x) of the target se- quence y, given x.</p><p>Seq2seq models with attention ( ) parameterize the per-symbol conditional probability as:</p><formula xml:id="formula_0">P y i |y [0:i−1] ; x = DecoderRNN ((h i ) y i−1 , h i−1 , Attention (h i−1 , x))<label>(1)</label></formula><p>for 1 ≤ i ≤ N , where DecoderRNN() is a re- current neural network that map the sequence of decoder symbols into fixed-length vectors, and At- tention() is a function that yields a fixed-size vec- tor summary of the encoder symbols x (the 'fo- cus') most relevant to predicting y i , given the pre- vious recurrent state of the network h i−1 (the 'con- text'). The full conditional probability follows from the product rule, as:</p><formula xml:id="formula_1">P (y|x) = N i=1 P y i |y [0:i−1] ; x<label>(2)</label></formula><p>We propose to implement target-side attention by augmenting the attention mechanism to include the part of the target sequence already generated, i.e., we include y   <ref type="figure">Figure 1</ref>: The vanilla seq2seq with attention on the left, and our proposed target-glimpse model on the right. The symbol "&gt;" and "&lt;" are start-of-sequence and end-of-sequence, respectively. and the majority of its response sequences are shorter than 10 tokens. This may prevent us from seeing bigger gains, since our method is designed to help with longer outputs. In order to train on the much larger Reddit data set, we implemented this method on top of the GNMT model ( <ref type="bibr">Wu et al., 2016)</ref>. Unfortunately, we met with frequent out- of-memory issues, as the 8-layer GNMT model is already very memory-intensive, and adding target- side attention made it even more so. Ideally, we would like to retain the model's capacity in or- der to train a rich response model, and therefore a more efficient approach is necessary.</p><p>To this end, we propose the target-glimpse model which has a fixed-length decoder. The target-glimpse model is implemented as a stan- dard sequence-to-sequence model with attention, where the decoder has a fixed length K. Dur- ing training, we split the target sequence into non- overlapping, contiguous segments (glimpses) with fixed length K, starting from the beginning. We then train on each of these glimpses, one at a time on the decoder, while putting all target-side sym- bols before the glimpse on the encoder. For ex- ample, if a sequence y is split into two glimpses y 1 and y 2 , each with length K (y 2 may be shorter than K), then we will train the model with two ex- amples, (x → y 1 ), and (x, y 1 → y 2 ). Each time the concatenated sequence on the left of the arrow is put on the encoder and the sequence on the right is put on the decoder. <ref type="figure">Figure 1(b)</ref> illustrates the training of (x, y 1 → y 2 ) when K = 3. In our im- plementation, we always put the source-side end- of-sequence token at the end of the whole encoder sequence, and we split the glimpses according to the decoder time steps. For example, if the se- quence y is y 0 , y 1 , y 2 , ..., y 10 , and K = 3, the first example will have y 0 , y 1 , y 2 on the input layer of the decoder, and y 1 , y 2 , y 3 on the output layer of the decoder. The second example has y 3 , y 4 , y 5 as input of the decoder and y 4 , y 5 , y 6 as the output of the decoder, and so on. In our experiments, we use K = 10.</p><p>While decoding each glimpse, the decoder therefore attends to both the source sequence and the part of the target sequence that precedes the glimpse, thereby benefiting from the GNMT en- coder's bidirectional RNN. Through generaliza- tion, the decoder should learn to decode a glimpse of length K in any arbitrary position of the target sequence (which we will exploit in our decoding technique discussed in Section 4). One drawback of this model, however, is that the context inputs to the attention mechanism only include the words that have been generated so far in this glimpse, rather than the words from the full target side. The workaround that we use is to simply connect the last hidden state of the GNMT-encoder to the ini- tial hidden state of the decoder 1 , thereby giving the decoder access to all previous symbols regardless of the starting position of the glimpse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Stochastic Decoding with Segment-by-Segment Reranking</head><p>We now turn our attention from training to in- ference (decoding). Our strategy is to perform reranking with a normalized score at the seg- ment level, where we generate the candidate seg- ments using a trained glimpse-model and using a stochastic beam search procedure, which we dis- cuss next. The full decoding algorithm proceeds segment by segment. The standard beam search algorithm generates symbols step-by-step by keeping a set of the B highest-scoring beams generated so far at each step 2 . The algorithm adds all possible single-token extensions to every existing beam, and then selects the top B beams. In our stochastic beam search algorithm, we replace this deterministic top-B se- lection by a stochastic sampling operation in order to encourage variation. Further, to discourage a single beam from dominating the search and de- creasing the final response diversity, we perform a two-step sampling procedure: 1) For each single- token extension of an individual beam we don't enumerate all possibilities, but instead sample a fixed number of D candidate tokens to be added to the beam. This yields a total of B ×D beams, each with one additional symbol. 2) We then compute the accumulated conditional log-probabilities for each beam (normalized across all B × D beams), and treat these as the logits for sub-sampling B beams for the next step. We repeat this procedure until we reach the desired segment-length H, or until a segment ends with the end-of-sequence to- ken.</p><p>For a given source sequence, we can use this stochastic beam search algorithm to generate B candidate H-length segments as the beginning of the target sequence. We then perform a rerank- ing step (described below), and keep one of these. The concatenation of the source and the first tar- get segment is then used as the input for generat- ing the next B candidate segments. The algorithm continues until the segment selected ends with an end-of-sequence token.</p><p>This algorithm behaves similarly to standard beam search when the categorical distribution used during the process is sharp ('peaked'), since the samples are likely to be the top categories (words) . However, when the distribution is smooth, many of the choices are likely. In con- versation response generation we are dealing with a conditional probability model with high entropy, so this is what often happens in practice.</p><p>For the reranking, we normalize the scores using random prompts. In particular, suppose y k = y 1 , ..., y k−1 is a candidate segment, and (x, y 1:k−1 ) is the input to the stochastic beam search. The normalized score is then computed as follows:</p><formula xml:id="formula_2">S (y k |x, y 1:k−1 ) = P (y k |x, y 1:k−1 ) x ∈Φ P (y k |x , y 1:k−1 )<label>(3)</label></formula><p>In this equation, the set Φ is a collection of ran- domly sampled source sequences (prompts). In our experiments, we randomly select Q prompts from the context-free evaluation set (introduced in the Experiments section).</p><p>It is worth noting that when Φ is an unbi- ased sample from P (x), the summation in the denominator is a Monte-Carlo approximation of P (y k |y 1:k−1 ). In the case of reranking whole target sequences y, this becomes the marginal P (y), which corresponds to the same diversity- promoting objective used in <ref type="figure" target="#fig_2">(Li et al., 2015)</ref>. However, we found that our approximation works better in terms of N-choose-1 accuracy (see Sec- tion 5.2), which suggests that its value may be closer to the true conditional probability.</p><p>In our experiments, we set number of random prompts Q to 15, segment length H to 10, num- ber of beams B to 2, and samples per beam D to 10. We select a small value for B, since we find that larger values makes the algorithm behave more like standard beam search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>In this section we present experimental results for evaluating the target-glimpse model and the stochastic decoding method that we presented. We train the model using the Google neural machine translation model (GNMT, ( <ref type="bibr">Wu et al., 2016)</ref>), on a data set that combines multiple sources mined from the Web:</p><p>1. The full Reddit data 3 that contains 1.7 billion messages (221 million conversations).</p><p>2. The 2009 Open Subtitles data (0.5 million conversations, <ref type="bibr" target="#b10">(Tiedemann, 2009)</ref>).</p><p>3. The Stack Exchange data (0.8 million conver- sations).</p><p>4. Dialogue-like texts that we recognized and extracted from the web (17 million conver- sations).</p><p>For all these data sets, we extract pairs of mes- sages where one can be considered as a response to the other. For example, in the Reddit data set, the messages belonging to the same post are or- ganized as a tree. A child node is a message that replies to its parent. This may not necessarily be true as people may be replying to other messages that are also visually close. However, for our cur- rent single-turn experiments, we treat these as a single exchange.</p><p>In this setting, the GNMT model trained on prompt-to-response pairs works surprisingly well without modification when generating short re- sponses with beam search. Similar to previous work on neural conversation models, we find that the generated responses are almost always gram- matical, and sometimes even interesting. They are also usually on topic. In addition, we found that even greedy sampling from the 8-layer GNMT model produces grammatical responses most of the time, although these responses are more likely to be semantically-broken than responses gener- ated using standard beam search. We would like to leverage the benefits of greedy sampling, because the induced variation generates more surprises and may potentially help improve user-engagement, and we found that our proposed segment-based beam sampling procedure accomplishes this to some extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation Metric</head><p>It is difficult to come up with an objective eval- uation metric for conversation response genera- tion that can be computed automatically. The con- ditional distribution P (y|x) is supposed to have high entropy in order to be interesting (many pos- sible valid responses to a given prompt). Therefore BLEU scores used in translation are not a good fit (also see ( <ref type="bibr" target="#b6">Liu et al., 2016)</ref>). Other than looking at the evaluation set perplexity, we use two met- rics, the N-choose-1 accuracy and 5-scale side- by-side human evaluation. In the N-choose-K metric, we use the model as a retriever. Given a prompt, we ask the model to rank N candidate responses, where one is the ground truth and the other N − 1 are random responses from the same data set. We then calculate the N-choose-K ac- curacy as the proportion of trials where the true response is in the top K. The prompts used for evaluation are selected randomly from the same data set. This metric isn't necessarily correlated well with the true response quality, but provides a useful first diagnostic for faster experimental itera- tion. It takes about a day to train a small model on a single GPU that reaches 2-choose-1 accuracies of around 70% or 80%, but it is much harder to make progress on the 50-choose-1 accuracy. As a reference, human performance on the 10-choose-1 task is around 45% accuracy.</p><p>In the 5-scale human evaluation, we use a collection of 200 context-free prompts <ref type="bibr">4</ref> . These prompts are collected from the following sources, and filtered to prompts that are context-free (i.e. do not depend on previous turns in the conversa- tion), general enough, and by eliminating near du- plicates:</p><p>1. The questions and statements that users asked an internal testing bot.</p><p>2. The Fisher corpus ( <ref type="bibr" target="#b3">David et al., 2004</ref>).</p><p>3. User inputs to the Jabberwacky chatbot 5 .</p><p>These can be either generic or specific. Some example prompts from this collection are shown in <ref type="table">Table 1</ref>. These prompts are open-domain (not about any specific topic), and include a wide range of topics. Many require some creativity for an- swering, such as "Tell me a story about a bear." Our evaluation set is therefore not from the same distribution as our training set. However, since our goal is to produce good general conversation re- sponses, we found it to be a good general purpose evaluation set.</p><p>The evaluation itself is done by human raters. They are well-trained for the purpose of ensuring rating quality, and they are native English speak- ers. The A 5-scale rating is produced for each prompt-response pair: Excellent, Good, Accept- able, Mediocre, and Bad. For example, the in- structions for rating Excellent is "On topic, inter- esting, shows understanding, moves the conver- sation forward. It answers the question." The instruction for Acceptable is "On topic but with flaws that make it seem like it didnt come from a human. It implies an answer." The instruction for Bad is "A completely off-topic statement or question, nonsensical, or grammatically broken. It does not provide an answer."</p><p>In our experiments, we perform the evaluations side-by-side, each time using responses generated from two methods. Every prompt-response pair is rated by three raters. We rate 200 pairs in total for every method, garnering 600 ratings overall. After the evaluation, we report aggregated results from each method individually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Motivating Experiments</head><p>To see whether generating long responses is in- deed a challenging problem, we trained the plain seq2seq with the GNMT model where the encoder holds the source sequence and the decoder holds the target sequence. We experimented with the standard beam search and the beam search with length normalization α = 0.8 similar to ( <ref type="bibr">Wu et al., 2016)</ref>. With this length normalization the gener- ated responses are indeed longer. However, they are more often semantically incoherent. It pro- duces "I have no idea what you are talking about." more often, similarly observed in ( <ref type="bibr" target="#b5">Li et al., 2016</ref>). The human evaluation results are summarized in <ref type="figure" target="#fig_2">Figure 2</ref>(b). Methods that generate longer re- sponses have more Bad and less Excellent / Good ratings.</p><p>We also performed the N-choose-1 evaluation on the baseline model using different normal- ization schemes. The results are shown in Ta- ble 2(a). No Normalization means that we use P (y|x) for scoring, Normalize by Marginal uses P (y|x)/P (y), as suggested in ( <ref type="bibr" target="#b7">Li et al., 2015)</ref>, and Normalize by Random Prompts is our scoring objective described in Section 4. The significant boost when using both normalization schemes in- dicates that the conditional log probability pre- dicted by the model may be biased towards the language model probability of P (y). After adding the normalization, the score may be closer to the true conditional log probability.</p><p>Overall, this reranking evaluation indicates that our heuristic is preferred to scoring using the marginal. However, it is unfortunately hard to di- rectly make use of this score during beam search decoding (i.e., generation), since the resulting se- quences are usually ungrammatical, as also ob- served by . This is the motivation for using a segment-by-segment reranking proce- dure, as described in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Large-Scale Experiments</head><p>For our large-scale experiments, we train our target-glimpse model on the full combined data set. <ref type="figure" target="#fig_2">Figure 2(d)</ref> shows the training progress curve. In this <ref type="figure">figure,</ref> we also include the curve for K = 1, that is, the glimpse model with decoder-length 1. It is clear enough that this model progresses much slower, so we terminated it early. How- ever, it is surprising that the glimpse model with K = 10 progresses faster than the baseline model with only source-side attention, because the model is trained on examples with decoder-length fixed at 10, while the average response length is 38 in our data set. This means it takes on average 3.8x training steps for the glimpse model to train on the same number of raw training-pairs as the baseline model. Despite this, the faster progress indicates that target-side attention indeed helps the model generalize better.</p><p>The human evaluation results shown in <ref type="figure" target="#fig_2">Figure 2</ref> compare our proposed method with the baseline seq2seq model. For this, we trained a length-10 target-glimpse model and decoded with stochastic beam-search using segment-by-segment rerank- ing. In our experiments, we were unable to gen- erate better long, coherent responses using the whole-sequence level reranking method from ( <ref type="bibr" target="#b7">Li et al., 2015</ref>) compared to using standard beam search with length-normalization <ref type="bibr">6</ref> . We therefore choose the latter as our baseline, because it is the only method which generates responses that are long enough that we can compare to. <ref type="figure" target="#fig_2">Figure 2</ref> shows that our proposed method gen- erates more long responses overall. One third of all responses are longer than 100 characters, while the baseline model produces only a neg- ligible fraction. Although we do not employ any length-promoting objectives in our method, length-normalization is used for the baseline. For responses generated by our method, the proportion of Acceptable and Excellent responses remains constant or even increases as the responses grow longer. Conversely, human ratings decline sharply with length for the baseline model.</p><p>The percentage of test cases with major agree- ment is high for both methods. We consider a test to have major agreement if two ratings out of the three are the same. For the baseline method, 80% of the responses have major agreements, and for our method it is 70%.</p><p>However, shorter responses have a much smaller search space, and we find that standard beam search tends to generate better ("safer") short responses. To maximize cumulative re- sponse quality, we therefore implemented a back- off strategy that combines the strengths of the two methods. We choose to fallback to the baseline model without length normalization when the lat- ter produces a response shorter than 40 characters, otherwise we use the response from our method. This corresponds to the white histogram in <ref type="figure" target="#fig_2">Fig- ure 2(b)</ref>. Compared to the other methods in the fig-ure, the combined strategy results in more ratings of Excellent, Good, Acceptable, and Mediocre, and fewer Bad ratings. With this strategy, among the responses generated for the same 200 prompts, 133 were from the standard beam search and 67 were from our model. Out of the 67 long re- sponses, two thirds were longer than 60 characters and half were longer than 75 characters. To com- pare the combined model's performance with the baseline, we generated responses from both mod- els using the same 200 prompts. For 20 of the re- sponse pairs, human raters had no preference, but for the remaining 180, human raters preferred the combined model's response in 103 cases and the baseline's in only 77, indicating a significant win.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The research of building end-to-end systems that can engage in general-purpose conversation is still in its infancy. More significant progress is ex- pected to be made with more advanced neural ar- chitectures. However, our results reported in this paper show that minimal modeling change and a slightly more advanced decoding technique, com- bined with training over very large data sets, can still lead to noticeable improvements in the quality of responses generated using neural conversation models. Overall, we found using fixed-lengths in the decoder to make it easier to train on large data sets, as well as to allow us to improve the diversity and coherence of the generated responses earlier during generation, when it has most impact. While the focus of this work has been on conversation modeling, we expect some of these results to carry over to other sequence-to-sequence settings, such as machine translation or image-captioning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N for computing</head><p>"N-choose-1" 50  <ref type="table" target="#tab_1">Overall Human Eval  Beam search on plain seq2seq  Beam search with length normalization 0.8  Segment Beam Sample with Glimpse Model  With fallback to beam</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>A: I don't think you know what that word means. (Acceptable, Good, Good) B: I am, actually. I don't think I'm crazy though. I certainly am. (Acceptable, Mediocre, Acceptable)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>[0:i−2] in the arguments to the at- tention function: Attention(h i−1 , y [0:i−2] , x</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: (a) N-choose-1 evaluation on the baseline model. (d) Training progress of different models on the full combined data set. Length-1 and Length-10 are the target-glimpse models we propose, and Plain Seq2seq is the baseline model we described. (b)(c)(e)(f): Human evaluation results on the conversation data. (b) The histogram of 5 ratings per method. (c) The length thresholds (horizontal axis) and the number of responses generated that are above the length threshold (vertical axis); (e) The proportion of responses above the length-threshold that are judged at least Acceptable; (f) The proportion of responses above the length-threshold that are judged as Excellent. The length thresholds are all measured in number of characters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>2</head><label>2</label><figDesc></figDesc><table>No Normalization 
0.047 
0.15 
0.56 

Normalize by 
Marginal 
0.44 
0.65 
0.91 

Normalize by 
Random Prompts 
(our heuristics) 

0.61 
0.78 
0.97 

(a) 

Bad 
Mediocre Acceptable 
Good 
Excellent 
0 

50 

100 

150 

200 

250 

300 

Number of Ratings 

</table></figure>

			<note place="foot" n="1"> This is the default in standard seq2seq models, but not in the GNMT model. 2 Beams are also called &apos;hypotheses&apos;, and B is referred to as the &apos;beam width&apos;.</note>

			<note place="foot" n="3"> Download links are at https://redd.it/3bxlg7</note>

			<note place="foot" n="4"> This list will be released to the community. 5 http://www.jabberwacky.com/</note>

			<note place="foot" n="6"> This is because the method reranks the responses in the N-best list resulting from the beam search, which tend to be short with not much variation to begin with.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Quoc Le, Oriol Vinyals and Jakob Uszkoreit for many helpful discussions, and Scott Benson, Fuchun Peng for collecting the context-free prompt set, and Amin Ahmad for setting up the human evaluation, and Rami Eid, Daniel Cer for collecting training data sets, and Yonghui Wu, Zhifeng Chen, Mike Schuster for help on training the GNMT model.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Levenberg</surname></persName>
		</author>
		<ptr target="http://tensorflow.org/" />
		<title level="m">TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow</title>
		<meeting><address><addrLine>Dan Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
	<note>Holger Schwenk, and Yoshua Bengio</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The fisher corpus: a resource for the next generations of speech-to-text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher Cieri</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 4th International Conference on Language Resources and Evaluation</title>
		<meeting>4th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="69" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03055</idno>
		<title level="m">A diversity-promoting objective function for neural conversation models</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno>CoRR abs/1606.01541</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D16-1230" />
	</analytic>
	<monogr>
		<title level="m">EMNLP. ACL</title>
		<meeting><address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">21222132</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02364</idno>
		<title level="m">Neural responding machine for short-text conversation</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.06714</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">News from OPUS-A Collection of Multilingual Parallel Corpora with Tools and Interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Advances in Natural Language Processing</title>
		<editor>N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov</editor>
		<meeting><address><addrLine>Benjamins, Amsterdam/Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="237" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05869</idno>
		<title level="m">A neural conversational model</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Stochastic language generation in dialogue using recurrent neural networks with convolutional sentence reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongho</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">J</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<idno>CoRR abs/1508.01755</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Conditional generation and snapshot learning in neural dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">M Rojas</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D16-1233" />
	</analytic>
	<monogr>
		<title level="m">EMNLP. ACL</title>
		<meeting><address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2153" to="2162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apurva</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshikiyo</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideto</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oriol Vinyals</title>
		<imprint>
			<publisher>Greg Corrado, Macduff Hughes</publisher>
		</imprint>
	</monogr>
	<note>and Jeffrey Dean. 2016. Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
