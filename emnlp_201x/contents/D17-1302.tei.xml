<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-Lingual Transfer Learning for POS Tagging without Cross-Lingual Resources</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joo-Kyung</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Amazon Alexa</orgName>
								<address>
									<postCode>98121</postCode>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Amazon Alexa</orgName>
								<address>
									<postCode>98121</postCode>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Fosler-Lussier</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The Ohio State University</orgName>
								<address>
									<postCode>43210</postCode>
									<settlement>Columbus</settlement>
									<region>OH</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-Lingual Transfer Learning for POS Tagging without Cross-Lingual Resources</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2832" to="2838"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Training a POS tagging model with cross-lingual transfer learning usually requires linguistic knowledge and resources about the relation between the source language and the target language. In this paper , we introduce a cross-lingual transfer learning model for POS tagging without ancillary resources such as parallel corpora. The proposed cross-lingual model utilizes a common BLSTM that enables knowledge transfer from other languages, and private BLSTMs for language-specific representations. The cross-lingual model is trained with language-adversarial training and bidirectional language modeling as auxiliary objectives to better represent language-general information while not losing the information about a specific target language. Evaluating on POS datasets from 14 languages in the Universal Dependencies corpus, we show that the proposed transfer learning model improves the POS tagging performance of the target languages without exploiting any linguistic knowledge between the source language and the target language.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Bidirectional Long Short-Term Memory (BLSTM) based models ( <ref type="bibr" target="#b9">Graves and Schmidhuber, 2005</ref>), along with word embeddings and character embeddings, have shown competitive performance on Part-of-Speech (POS) tagging given sufficient amount of training examples ( <ref type="bibr" target="#b19">Ling et al., 2015;</ref><ref type="bibr" target="#b18">Lample et al., 2016;</ref><ref type="bibr" target="#b24">Plank et al., 2016;</ref><ref type="bibr" target="#b28">Yang et al., 2017)</ref>.</p><p>Given insufficient training examples, we can improve the POS tagging performance by cross- lingual POS tagging, which exploits affluent POS tagging corpora from other source languages. This approach usually requires linguistic knowledge or resources about the relation between the source language and the target language such as paral- lel corpora <ref type="bibr" target="#b26">(Täckström et al., 2013;</ref><ref type="bibr" target="#b5">Duong et al., 2013;</ref><ref type="bibr" target="#b14">Kim et al., 2015a;</ref><ref type="bibr" target="#b29">Zhang et al., 2016)</ref>, mor- phological analyses ( <ref type="bibr" target="#b10">Hana et al., 2004</ref>), dictionar- ies ( <ref type="bibr" target="#b27">Wisniewski et al., 2014)</ref>, and gaze features ( <ref type="bibr" target="#b1">Barrett et al., 2016)</ref>.</p><p>Given no linguistic resources between the source language and the target language, transfer learning methods can be utilized instead. Trans- fer learning for cross-lingual cases is a type of transductive transfer learning, where the input do- mains of the source and the target are different <ref type="bibr" target="#b22">(Pan and Yang, 2010)</ref> since each language has its own vocabulary space. When the input space is the same, lower layers of hierarchical models can be shared for knowledge transfer <ref type="bibr" target="#b4">(Collobert et al., 2011;</ref><ref type="bibr" target="#b16">Kim et al., 2015b;</ref><ref type="bibr" target="#b28">Yang et al., 2017)</ref>, but that approach is not directly applicable when the input spaces differ. <ref type="bibr" target="#b28">Yang et al. (2017)</ref> used shared character em- beddings for different languages as a cross-lingual transfer method while using different word em- beddings for different languages. Although the ap- proach showed improved performance on Named Entity Recognition, it is limited to character-level representation transfer and it is not applicable for knowledge transfer between languages without overlapped alphabets.</p><p>In this work, we introduce a cross-lingual trans- fer learning model for POS tagging requiring no cross-lingual resources, where knowledge transfer is made in the BLSTM layers on top of word em- beddings and character embeddings. Inspired by <ref type="bibr" target="#b15">Kim et al. (2016)</ref>'s multi-task slot-filling model, our model utilizes a common BLSTM for repre- senting language-generic information, which al-  lows knowledge transfer from other languages, and private BLSTMs for representing language- specific information. The common BLSTM is additionally encouraged to be language-agnostic with language-adversarial training <ref type="bibr" target="#b3">(Chen et al., 2016)</ref> so that the language-general representations to be more compatible among different languages.</p><p>Evaluating on POS datasets from 14 different target languages with English as the source lan- guage in the Universal Dependencies corpus 1.4 ( <ref type="bibr">Nivre et al., 2016</ref>), the proposed model showed significantly better performance when the source language and the target language are in the same language family, and competitive performance when the language families are different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>Cross-Lingual Training <ref type="figure" target="#fig_0">Figure 1</ref> shows the overall architecture of the proposed model. The baseline POS tagging model is similar to <ref type="bibr" target="#b24">Plank et al. (2016)</ref>'s model, and it corresponds to having only word+char embeddings, common BLSTM, and Softmax Output in <ref type="figure" target="#fig_0">Figure 1</ref>. Given an input word sequence, a BLSTM is used for the character sequence of each word, where the outputs of the ends of the character sequences from the forward LSTM and the backward LSTM are concatenated to the word vector of the current word to supple- ment the word representation. These serve as an input to a BLSTM, and an output layer are used for POS tag prediction.</p><p>For the cross-lingual transfer learning, the char- acter embedding, the BLSTM with the character embedding ( <ref type="bibr" target="#b28">Yang et al., 2017</ref>), 1 and the common BLSTM are shared for all the given languages while word embeddings and private BLSTMs have different parameters for different languages.</p><p>The outputs of the common BLSTM and the private BLSTM of the current language are summed to be used as the input to the softmax layer to predict the POS tags of given word se- quences. The loss function of the POS tagging can be formulate as:</p><formula xml:id="formula_0">L p = − S i=1 N j=1 p i,j log (ˆ p i,j ) ,<label>(1)</label></formula><p>where S is the number of sentences in the current minibatch, N is the number of words in the current sentence, p i,j is the label of the j-th tag of the i-th sentence in the minibatch, andˆpandˆ andˆp i,j is the predicted tag. In addition to this main objective, two more objectives for improving the transfer learning are described in the following subsections.</p><p>Language-Adversarial Training We encour- age the outputs of the common BLSTM to be language-agnostic by using language-adversarial training <ref type="bibr" target="#b3">(Chen et al., 2016</ref>) inspired by domain- adversarial training ( <ref type="bibr" target="#b7">Ganin et al., 2016;</ref><ref type="bibr" target="#b2">Bousmalis et al., 2016</ref>). First, we encode a BLSTM output sequence as a single vector using a CNN/MaxPool encoder, which is implemented the same as a CNN for text classification <ref type="bibr" target="#b13">(Kim, 2014</ref>). The encoder is with three convolution filters whose sizes are 3, 4, and 5. For each filter, we pass the BLSTM output sequence as the input sequence and obtain a single vector from the filter output by using max pool- ing, and then tanh activation function is used for transforming the vector. Then, the vector outputs of the three filters are concatenated and forwarded to the language discriminator through the gradient reversal layer. The discriminator is implemented as a fully-connected neural network with a single hidden layer, whose activation function is Leaky ReLU ( <ref type="bibr" target="#b20">Maas et al., 2013</ref>), where we multiply 0.2 to negative input values as the outputs. Since the gradient reversal layer is below the language classifier, the gradients minimizing lan- guage classification errors are passed back with opposed sign to the sentence encoder, which ad- versarially encourages the sentence encoder to be language-agnostic. The loss function of the lan- guage classifier is formulated as:</p><formula xml:id="formula_1">L a = − S i=1 l i logîlogˆlogî i ,<label>(2)</label></formula><p>where S is the number of sentences, l i is the lan- guage of the i-th sentence, andîandˆandî i is the softmax output of the tagging. Note that though the lan- guage classifier is optimized to minimize the lan- guage classification error, the gradient from the language classifier is negated so that the bottom layers are trained to be language-agnostic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bidirectional Language Modeling</head><p>Rei <ref type="formula" target="#formula_0">(2017)</ref> showed the effectiveness of the bidirectional lan- guage modeling objective, where each time step of the forward LSTM outputs predicts the word of the next time step, and each of the backward LSTM outputs predicts the previous word. For example, if the current sentence is "I am happy", the forward LSTM predicts "am happy &lt;eos&gt;" and the back- ward LSTM predicts "&lt;bos&gt; I am". This objec- tive encourages the BLSTM layers and the embed- ding layers to learn linguistically general-purpose representations, which are also useful for specific downstream tasks <ref type="bibr" target="#b25">(Rei, 2017)</ref>. We adopted the bidirectional language modeling objective, where the sum of the common BLSTM and the private BLSTM is used as the input to the language mod- eling module. It can be formulated as:</p><formula xml:id="formula_2">L l = − S i=1 N j=1 log (P (w j+1 |f j )) + log (P (w j−1 |b j )) ,<label>(3)</label></formula><p>where f j and b j represent the j-th outputs of the forward direction and the backward direction, re- spectively, given the output sum of the common BLSTM and the private BLSTM. All the three loss functions are added to be op- timized altogether as:</p><formula xml:id="formula_3">L = w s (L p + λL a + λL l ) ,<label>(4)</label></formula><p>where λ is gradually increased from 0 to 1 as epoch increases so that the model is stably trained with auxiliary objectives ( <ref type="bibr" target="#b7">Ganin et al., 2016)</ref>. w s is used to give different weights to the source lan- guage and the target language. Since the source language has a larger train set and we are focusing on improving the performance of the target lan- guage, w s is set to 1 when training the target lan- guage. For the source language, instead, it is set as the size of the target train set divided by the size of the source train set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>For the evaluation, we used the POS datasets from 14 different languages in Universal Dependencies corpus 1.4 ( <ref type="bibr">Nivre et al., 2016</ref>). We used English as the source language, which is with 12,543 train- ing sentences. <ref type="bibr">2</ref> We chose datasets with 1k to 14k training sentences. The number of tag labels dif- fers for each language from 15 to 18 though most of them are overlapped within the languages. <ref type="table" target="#tab_2">Table 1</ref> shows the POS tagging accuracies of different transfer learning models when we limited the number of training sentences of the target lan- guages to be the same as 1,280 for fair comparison among different languages. The remainder train- ing examples of the target languages are still used for both language-adversarial training and bidirec- tional language modeling since the objectives do not require tag labels. Training with only the train sets in the target languages (c) showed 91.61% on average. When bidirectional language modeling objective is used (c, l), the accuracies were signifi- cantly increased to 92.82% on average. Therefore, we used the bidirectional language modeling for all the transfer learning evaluations.</p><p>With transfer learning, the three cases of us- ing only the common BLSTM (c), using only the private BLSTMs (p), and using both (c, p) were evaluated. They showed better average ac- curacies than target only cases, but they showed mixed results. However, our proposed model (c, p, l + a), which utilizes both the common BLSTM with language-adversarial training and the private BLSTMs, showed the highest average score, 93.26%. For all the Germanic languages, where the source language also belongs to, the accuracies are significantly higher than those of Target only Source (English) → <ref type="table">Target  Language Family Language  c  c,l  c,l  p,l  c,p,l  c,</ref>  other transfer learning models. For the languages belonging to Slavic, Romance, or Indo-Iranian, our model shows competitive performance with the highest average accuracies among the com- pared models. Since languages in the same fam- ily are more likely to be similar and compatible, it is expected that the gain from the knowledge transfer to the languages in the same family to be higher than transferring to the languages in dif- ferent families, which was shown in the results. This shows that utilizing both language-general representations that are encouraged to be more language-agnostic and language-specific represen- tations effectively helps improve the POS tagging performance with transfer learning. <ref type="table" target="#tab_4">Table 2</ref> shows the results when using 320 tag- labeled training sentences. In this case, transfer learning methods still show better accuracies than target-only approaches on average. However, the performance gain is weakened compared to us- ing 1,280 labeled training sentences and there are some mixed results. In several cases, just utiliz- ing private BLSTMs without the common BLSTM showed better accuracies than utilizing the com- mon BLSTM.</p><p>When training with only 32 tag-labeled sen- tences, which is an extremely low-resourced set- ting, transfer learning methods still showed bet- ter accuracies than target-only methods on aver- age. However, not using the common BLSTM in transfer learning models showed better perfor- mance than using it on average. <ref type="bibr">3</ref> The main rea- son would be that we are not given a sufficient number of labeled training sentences to train both the common BLSTM and the private BLSTMs. In this case, just having private BLSTMs without the common BLSTM can show better performance. We also evaluated the opposite cases, which use all the tag-labeled training sentences in the target lan- guages, and they showed mixed results. For exam- ple, the accuracy of German with the target only model is 93.31% while that of the proposed model is 93.04%. This is expected since transfer learning is effective when the target train set is small.</p><p>An extension of this work is utilizing multiple languages as the source languages. Since we have four languages for each of Germanic, Slavic, and Romance language families, we evaluated the per- formance of those languages using the other lan- guages in the same families as the source lan- guages expecting that languages in the same lan- guage family are more likely to be helpful each other. For the efficiency, we performed multi-task learning for multiple languages rather than differ- entiating the targets from sources. When we tried to use 1,280, 320, and 32 tag-labeled training sen- tences for each language in the multi-source set- tings, the results showed noticeably better per-  formance than the results of using English as a single source language. Considering that utiliz- ing 1,280*3=3,840, 320*3=960, or 32*3=96 tag labels from three other languages showed better results than using 12,543 English tag labels as the source, we can see that the knowledge trans- fer from multiple languages can be more help- ful than that from single resource-rich source lan- guage. We also tried to use Wasserstein distance ( <ref type="bibr" target="#b0">Arjovsky et al., 2017)</ref> for the adversarial training in the multi-source settings, but there were no sig- nificant differences on average. 4</p><p>Implementation Details All the models were optimized using ADAM ( <ref type="bibr" target="#b17">Kingma and Ba, 2015)</ref>  <ref type="bibr">5</ref> with minibatch size 32 for total 100 epochs and we picked the parameters showing the best accu- racy on the development set to report the score on the test set. The dimensionalites of all the BLSTM related layers follow <ref type="bibr" target="#b24">Plank et al. (2016)</ref>'s model. Each word vector is 128 dimensional and each character vector is 100 dimensional. They are ran- domly initialized with Xavier initialization <ref type="bibr" target="#b8">(Glorot and Bengio, 2010)</ref>. For stable training, we use gra- dient clipping, where the threshold is set to 5. The dimensionality of each hidden output of LSTMs is 100, and the hidden outputs of both forward LSTM and backward LSTM are concatenated, thereby the output of each BLSTM for each time step is 200. Therefore, the input to the common BLSTM and the private BLSTM is 128+200=328 <ref type="bibr">4</ref> The extended work in detail are shown in <ref type="bibr" target="#b12">Kim (2017)</ref>. 5 learning rate=0.001, β1 = 0.9, β2 = 0.999, = 1e − 8.</p><p>dimensional. The inputs and the outputs of the BLSTMs are regularized with dropout rate 0.5 ( <ref type="bibr" target="#b23">Pham et al., 2014</ref>). For the consistent dropout usages, we let the dropout masks to be identical for all the time steps of each sentence ( <ref type="bibr" target="#b6">Gal and Ghahramani, 2016)</ref>. For all the BLSTMs, for- get biases are initialized with 1 ( <ref type="bibr" target="#b11">Jozefowicz et al., 2015)</ref> and the other biases are initialized with 0. Each convolution filter output for the sentence en- coding is 64 dimensional, and the three filter out- puts are concatenated to represent each sentence with a 192 dimensional vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We introduced a cross-lingual transfer learn- ing model for POS tagging which uses sepa- rate BLSTMs for language-general and language- specific representations. Evaluating on 14 differ- ent languages, including the source language im- proved tagging accuracies in almost all the cases. Specifically, our model showed noticeably better performance when the source language and the target languages belong to the same language fam- ily, and competitively performed with the highest average accuracies for target languages in differ- ent families.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Model architecture: blue modules share parameters for all the languages and red modules have different parameters for different languages. wi and ei denote the i-th word vector and the i-th character vector composition, respectively. h cf i , h cb i , h pf i , and h pb i denote the i-th hidden outputs of the forward common LSTM, the backward common LSTM, the forward private LSTM, and the backward private LSTM, respectively. h c i and h p i denote the concatenated output of the common BLSTM and the private BLSTM, respectively. Violet circles represent target labels that are predicted with different parameters for different languages, where the inputs are output summation of the common BLSTM and the private BLSTM. The model is trained with three objectives denoted with red boxes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>l+a c,p,l+a Germanic Swedish 93.26 94.31 94.36 94.39 94.51 94.38 94.63 Danish 92.13 93.41 93.34 93.76 94.05 93.74 94.26 Dutch 83.24 84.73 85.20 84.92 84.85 84.99 85.83 German 89.27 90.69 90.06 90.40 90.01 90.14 90.71 Avg 89.47 90.78 90.74 90.87 90.86 90.82 91.36</figDesc><table>Slavic 

Slovenian 
93.06 93.79 93.83 94.06 94.20 93.93 94.06 
Polish 
91.30 91.30 91.69 92.11 91.86 91.77 92.11 
Slovak 
86.53 89.56 90.11 89.88 89.98 90.40 90.01 
Bulgarian 
93.45 95.27 95.33 95.50 95.52 95.25 95.65 
Avg 
91.09 92.48 92.74 92.89 92.89 92.84 92.95 

Romance 

Romanian 
93.20 94.09 94.22 94.17 94.05 93.91 94.20 
Portuguese 94.23 95.18 95.42 95.15 95.55 95.36 95.51 
Italian 
93.80 95.95 95.79 95.61 95.84 95.70 95.92 
Spanish 
91.94 93.34 93.34 93.31 93.29 92.94 93.44 
Avg 
93.29 94.64 94.69 94.56 94.68 94.48 94.77 
Indo-Iranian 
Persian 
93.91 94.63 94.68 94.79 94.78 94.49 94.83 
Uralic 
Hungarian 
93.20 93.27 94.40 94.66 94.69 94.29 94.45 
Total Avg 
91.61 92.82 92.98 93.05 93.08 92.95 93.26 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 : POS tagging accuracies (%) when setting the numbers of the tag-labeled training examples of the target languages</head><label>1</label><figDesc></figDesc><table>to be the same as 1,280 (The remaining training examples are still used for the language modeling and the adversarial training.) 
c: using common BLSTM, p: using private BLSTMs, l: bidirectional language modeling objectives, a: language-adversarial 
training. (Underlined scores denote that the differences between the highest score of the other models and those scores are 
statistically insignificant with McNemar's χ 2 test with p-value &lt; 0.05.) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>POS tagging accuracies (%) with 320 tag-labeled training examples for each target language. All the training 

examples are still used for the other objectives. 

</table></figure>

			<note place="foot" n="1"> We also tried isolated character-level modules but the overall performance was worse.</note>

			<note place="foot" n="2"> The accuracies of English POS tagging are 94.01 and 94.33 for models without the bidirectional language modeling and with it, respectively.</note>

			<note place="foot" n="3"> The results in detail are shown in the first authors dissertation Kim (2017).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their help-ful comments. All the experiments in this work were conducted with machines at Ohio Supercom-puter <ref type="bibr">Center (1987)</ref>.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cross-lingual transfer of correlations between parts of speech and gaze features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1330" to="1339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29 (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="343" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Adversarial deep averaging networks for cross-lingual sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Athiwaratkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01614</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learing Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simpler unsupervised POS tagging with bilingual projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="634" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A theoretically grounded application of dropout in recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29 (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1019" to="1027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franois</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2016" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<meeting>the 13th International Conference on Artificial Intelligence and Statistics (AISTATS)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional LSTM and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="602" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A resource-light approach to Russian morphology: Tagging Russian using Czech resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Hana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An empirical exploration of recurrent network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML)</title>
		<meeting>the 32nd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2342" to="2350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Linguistic Knowledge Transfer for Enriching Vector Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joo-Kyung</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>The Ohio State University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Part-of-speech taggers for lowresource languages using CCA features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1292" to="1302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Frustratingly easy neural domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="387" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">New transfer learning techniques for disparate label sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACLIJCNLP)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACLIJCNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="473" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">ADAM: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Finding function in form: Compositional character models for open vocabulary word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Luís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luís</forename><surname>Marujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramón</forename><forename type="middle">Fernández</forename><surname>Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1520" to="1530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Awni</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2013 Workshop on Deep Learning for Audio, Speech, and Language Processing</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeljko</forename><surname>Agi´cagi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Ahrenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Jesus</forename><surname>Aranzabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayuki</forename><surname>Asahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitziber</forename><surname>Atutxa</surname></persName>
		</author>
		<ptr target="http://osc.edu/ark:/19495/f5s1ph73" />
		<imprint>
			<date type="published" when="1987" />
			<pubPlace>Ohio Supercomputer Center</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering (TKDE)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dropout improves recurrent neural networks for handwriting recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Théodore</forename><surname>Vu Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Bluche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérôme</forename><surname>Kermorvant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Louradour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th International Conference on Frontiers in Handwriting Recognition (ICFHR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="285" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="412" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semi-supervised multitask learning for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Token and type constraints for cross-lingual part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cross-lingual part-of-speech tagging through ambiguous learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Wisniewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Pécheux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Souhir</forename><surname>Gahbiche-Braham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1779" to="1785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Transfer learning for sequence tagging with hierarchical recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ten pairs to tag-multilingual POS tagging via coarse mapping between embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gaddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1307" to="1317" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
