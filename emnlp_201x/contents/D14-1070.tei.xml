<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Neural Network for Factoid Question Answering over Paragraphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
							<email>Jordan.Boyd.Graber@colorado.edu, richard@socher.org</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Colorado</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Claudino</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><forename type="middle">Daumé</forename><surname>Iii</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Neural Network for Factoid Question Answering over Paragraphs</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="633" to="644"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Text classification methods for tasks like factoid question answering typically use manually defined string matching rules or bag of words representations. These methods are ineffective when question text contains very few individual words (e.g., named entities) that are indicative of the answer. We introduce a recursive neural network (rnn) model that can reason over such input by modeling textual composition-ality. We apply our model, qanta, to a dataset of questions from a trivia competition called quiz bowl. Unlike previous rnn models, qanta learns word and phrase-level representations that combine across sentences to reason about entities. The model outperforms multiple baselines and, when combined with information retrieval methods, rivals the best human players.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep neural networks have seen widespread use in natural language processing tasks such as parsing, language modeling, and sentiment analysis ( <ref type="bibr" target="#b0">Bengio et al., 2003;</ref><ref type="bibr" target="#b24">Socher et al., 2013a;</ref><ref type="bibr" target="#b26">Socher et al., 2013c</ref>). The vector spaces learned by these models cluster words and phrases together based on similarity. For exam- ple, a neural network trained for a sentiment analysis task such as restaurant review classifi- cation might learn that "tasty" and "delicious" should have similar representations since they are synonymous adjectives.</p><p>These models have so far only seen success in a limited range of text-based prediction tasks, Later in its existence, this polity's leader was chosen by a group that included three bishops and six laymen, up from the seven who traditionally made the decision. Free imperial cities in this polity included Basel and Speyer. Dissolved in 1806, its key events included the Investiture Controversy and the Golden Bull of 1356. Led by Charles V, Frederick Barbarossa, and Otto I, for 10 points, name this polity, which ruled most of what is now Germany through the Middle Ages and rarely ruled its titular city. where inputs are typically a single sentence and outputs are either continuous or a limited dis- crete set. Neural networks have not yet shown to be useful for tasks that require mapping paragraph-length inputs to rich output spaces.</p><p>Consider factoid question answering: given a description of an entity, identify the per- son, place, or thing discussed. We describe a task with high-quality mappings from natural language text to entities in Section 2. This task-quiz bowl-is a challenging natural lan- guage problem with large amounts of diverse and compositional data.</p><p>To answer quiz bowl questions, we develop a dependency tree recursive neural network in Section 3 and extend it to combine predic- tions across sentences to produce a question answering neural network with trans-sentential averaging (qanta). We evaluate our model against strong computer and human baselines in Section 4 and conclude by examining the latent space and model mistakes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Matching Text to Entities: Quiz Bowl</head><p>Every weekend, hundreds of high school and college students play a game where they map raw text to well-known entities. This is a trivia competition called quiz bowl. Quiz bowl ques- tions consist of four to six sentences and are associated with factoid answers (e.g., history questions ask players to identify specific battles, presidents, or events). Every sentence in a quiz bowl question is guaranteed to contain clues that uniquely identify its answer, even without the context of previous sentences. Players an- swer at any time-ideally more quickly than the opponent-and are rewarded for correct answers. Automatic approaches to quiz bowl based on existing nlp techniques are doomed to failure. Quiz bowl questions have a property called pyramidality, which means that sentences early in a question contain harder, more obscure clues, while later sentences are "giveaways". This design rewards players with deep knowl- edge of a particular subject and thwarts bag of words methods. Sometimes the first sen- tence contains no named entities-answering the question correctly requires an actual un- derstanding of the sentence <ref type="figure" target="#fig_0">(Figure 1</ref>). Later sentences, however, progressively reveal more well-known and uniquely identifying terms.</p><p>Previous work answers quiz bowl ques- tions using a bag of words (na¨ıvena¨ıve Bayes) ap- proach ). These mod- els fail on sentences like the first one in <ref type="figure" target="#fig_0">Figure 1</ref>, a typical hard, initial clue. Recursive neural networks (rnns), in contrast to simpler models, can capture the compositional aspect of such sentences ( <ref type="bibr" target="#b10">Hermann et al., 2013)</ref>.</p><p>rnns require many redundant training exam- ples to learn meaningful representations, which in the quiz bowl setting means we need multiple questions about the same answer. Fortunately, hundreds of questions are produced during the school year for quiz bowl competitions, yield- ing many different examples of questions ask- ing about any entity of note (see Section 4.1 for more details). Thus, we have built-in re- dundancy (the number of "askable" entities is limited), but also built-in diversity, as difficult clues cannot appear in every question without becoming well-known.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dependency-Tree Recursive Neural Networks</head><p>To compute distributed representations for the individual sentences within quiz bowl ques- tions, we use a dependency-tree rnn (dt-rnn). These representations are then aggregated and fed into a multinomial logistic regression clas- sifier, where class labels are the answers asso- ciated with each question instance. In previous work, <ref type="bibr" target="#b27">Socher et al. (2014)</ref> use dt-rnns to map text descriptions to images. dt-rnns are robust to similar sentences with slightly different syntax, which is ideal for our problem since answers are often described by many sentences that are similar in meaning but different in structure. Our model improves upon the existing dt-rnn model by jointly learning answer and question representations in the same vector space rather than learning them separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Description</head><p>As in other rnn models, we begin by associ- ating each word w in our vocabulary with a vector representation x w ∈ R d . These vectors are stored as the columns of a d × V dimen- sional word embedding matrix W e , where V is the size of the vocabulary. Our model takes dependency parse trees of question sentences <ref type="bibr" target="#b4">(De Marneffe et al., 2006</ref>) and their correspond- ing answers as input.</p><p>Each node n in the parse tree for a partic- ular sentence is associated with a word w, a word vector x w , and a hidden vector h n ∈ R d of the same dimension as the word vectors. For internal nodes, this vector is a phrase-level rep- resentation, while at leaf nodes it is the word vector x w mapped into the hidden space. Un- like in constituency trees where all words reside at the leaf level, internal nodes of dependency trees are associated with words. Thus, the dt- rnn has to combine the current node's word vector with its children's hidden vectors to form h n . This process continues recursively up to the root, which represents the entire sentence.</p><p>We associate a separate d×d matrix W r with each dependency relation r in our dataset and learn these matrices during training. 1 Syntac- tically untying these matrices improves com-This city 's economy depended on subjugated peasants called helots positionality over the standard rnn model by taking into account relation identity along with tree structure. We include an additional d × d matrix, W v , to incorporate the word vector x w at a node into the node vector h n . Given a parse tree <ref type="figure" target="#fig_1">(Figure 2</ref>), we first com- pute leaf representations. For example, the hidden representation h helots is</p><formula xml:id="formula_0">h helots = f (W v · x helots + b),<label>(1)</label></formula><p>where f is a non-linear activation function such as tanh and b is a bias term. Once all leaves are finished, we move to interior nodes with already processed children. Continuing from "helots" to its parent, "called", we compute</p><formula xml:id="formula_1">h called =f (W DOBJ · h helots + W v · x called + b).<label>(2)</label></formula><p>We repeat this process up to the root, which is</p><formula xml:id="formula_2">h depended =f (W NSUBJ · h economy + W PREP · h on + W v · x depended + b).<label>(3)</label></formula><p>The composition equation for any node n with children K(n) and word vector x w is</p><formula xml:id="formula_3">h n = f (W v · x w + b + k∈K(n) W R(n,k) · h k ), (4)</formula><p>where R(n, k) is the dependency relation be- tween node n and child node k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training</head><p>Our goal is to map questions to their corre- sponding answer entities. Because there are a limited number of possible answers, we can view this as a multi-class classification task. While a softmax layer over every node in the tree could predict answers <ref type="bibr" target="#b23">(Socher et al., 2011;</ref><ref type="bibr" target="#b13">Iyyer et al., 2014</ref>), this method overlooks that most answers are themselves words (features) in other questions (e.g., a question on World War II might mention the Battle of the Bulge and vice versa). Thus, word vectors associated with such answers can be trained in the same vector space as question text, 2 enabling us to model relationships between answers instead of assuming incorrectly that all answers are independent.</p><p>To take advantage of this observation, we depart from <ref type="bibr" target="#b27">Socher et al. (2014)</ref> by training both the answers and questions jointly in a single model, rather than training each sep- arately and holding embeddings fixed during dt-rnn training. This method cannot be ap- plied to the multimodal text-to-image mapping problem because text captions by definition are made up of words and thus cannot include im- ages; in our case, however, question text can and frequently does include answer text.</p><p>Intuitively, we want to encourage the vectors of question sentences to be near their correct answers and far away from incorrect answers. We accomplish this goal by using a contrastive max-margin objective function described be- low. While we are not interested in obtaining a ranked list of answers, 3 we observe better per- formance by adding the weighted approximate- rank pairwise (warp) loss proposed in <ref type="bibr" target="#b32">Weston et al. (2011)</ref> to our objective function.</p><p>Given a sentence paired with its correct an- swer c, we randomly select j incorrect answers from the set of all incorrect answers and denote this subset as Z. Since c is part of the vocab- ulary, it has a vector x c ∈ W e . An incorrect answer z ∈ Z is also associated with a vector x z ∈ W e . We define S to be the set of all nodes in the sentence's dependency tree, where an individual node s ∈ S is associated with the hidden vector h s . The error for the sentence is</p><formula xml:id="formula_4">C(S, θ) = s∈S z∈Z L(rank(c, s, Z))max(0, 1 − x c · h s + x z · h s ), (5)</formula><p>where the function rank(c, s, Z) provides the rank of correct answer c with respect to the incorrect answers Z. We transform this rank into a loss function 4 shown by <ref type="bibr" target="#b28">Usunier et al. (2009)</ref> to optimize the top of the ranked list,</p><formula xml:id="formula_5">L(r) = r i=1 1/i.</formula><p>Since rank(c, s, Z) is expensive to compute, we approximate it by randomly sampling K incorrect answers until a violation is observed (x c · h s &lt; 1 + x z · h s ) and set rank(c, s, Z) = (|Z| − 1)/K, as in previous work <ref type="bibr" target="#b32">(Weston et al., 2011;</ref><ref type="bibr" target="#b11">Hermann et al., 2014</ref>). The model mini- mizes the sum of the error over all sentences T normalized by the number of nodes N in the training set,</p><formula xml:id="formula_6">J(θ) = 1 N t∈T C(t, θ).<label>(6)</label></formula><p>The parameters θ = (W r∈R , W v , W e , b), where R represents all dependency relations in the data, are optimized using AdaGrad <ref type="bibr" target="#b5">(Duchi et al., 2011)</ref>. <ref type="bibr">5</ref> In Section 4 we compare perfor- mance to an identical model (fixed-qanta) that excludes answer vectors from W e and show that training them as part of θ produces signif- icantly better results. The gradient of the objective function,</p><formula xml:id="formula_7">∂C ∂θ = 1 N t∈T ∂J(t) ∂θ ,<label>(7)</label></formula><p>is computed using backpropagation through structure <ref type="bibr" target="#b7">(Goller and Kuchler, 1996</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">From Sentences to Questions</head><p>The model we have just described considers each sentence in a quiz bowl question indepen- dently. However, previously-heard sentences within the same question contain useful infor- mation that we do not want our model to ignore.</p><p>4 Our experiments show that adding this loss term to the objective function not only increases performance but also speeds up convergence <ref type="bibr">5</ref> We set the initial learning rate η = 0.05 and reset the squared gradient sum to zero every five epochs.</p><p>While past work on rnn models have been re- stricted to the sentential and sub-sentential levels, we show that sentence-level representa- tions can be easily combined to generate useful representations at the larger paragraph level.</p><p>The simplest and best 6 aggregation method is just to average the representations of each sentence seen so far in a particular question. As we show in Section 4, this method is very powerful and performs better than most of our baselines. We call this averaged dt-rnn model qanta: a question answering neural network with trans-sentential averaging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We compare the performance of qanta against multiple strong baselines on two datasets. qanta outperforms all baselines trained only on question text and improves an information retrieval model trained on all of Wikipedia. qanta requires that an input sentence de- scribes an entity without mentioning that entity, a constraint that is not followed by Wikipedia sentences. <ref type="bibr">7</ref> While ir methods can operate over Wikipedia text with no issues, we show that the representations learned by qanta over just a dataset of question-answer pairs can significantly improve the performance of ir systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We evaluate our algorithms on a corpus of over 100,000 question/answer pairs from two differ- ent sources. First, we expand the dataset used in Boyd-Graber et al. <ref type="formula" target="#formula_0">(2012)</ref> with publically- available questions from quiz bowl tournaments held after that work was published. This gives us 46,842 questions in fourteen different cate- gories. To this dataset we add 65,212 questions from naqt, an organization that runs quiz bowl tournaments and generously shared with us all of their questions from 1998-2013.</p><p>Because some categories contain substan- tially fewer questions than others (e.g., astron- omy has only 331 questions), we consider only literature and history questions, as these two categories account for more than 40% of the corpus. This leaves us with 21,041 history ques- tions and 22,956 literature questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Data Preparation</head><p>To make this problem feasible, we only consider a limited set of the most popular quiz bowl an- swers. Before we filter out uncommon answers, we first need to map all raw answer strings to a canonical set to get around formatting and redundancy issues. Most quiz bowl answers are written to provide as much information about the entity as possible. For example, the follow- ing is the raw answer text of a question on the Chinese leader Sun Yat-sen: Sun Yat-sen; or Sun Yixian; or Sun Wen; or Sun Deming; or Nakayama Sho; or Nagao Takano. Quiz bowl writers vary in how many alternate acceptable answers they provide, which makes it tricky to strip superfluous information from the answers using rule-based approaches.</p><p>Instead, we use Whoosh, 8 an information re- trieval library, to generate features in an active learning classifier that matches existing answer strings to Wikipedia titles. If we are unable to find a match with a high enough confidence score, we throw the question out of our dataset. After this standardization process and manual vetting of the resulting output, we can use the Wikipedia page titles as training labels for the dt-rnn and baseline models. <ref type="bibr">9</ref> 65.6% of answers only occur once or twice in the corpus. We filter out all answers that do not occur at least six times, which leaves us with 451 history answers and 595 literature answers that occur on average twelve times in the corpus. These pruning steps result in 4,460 usable history questions and 5,685 liter- ature questions. While ideally we would have used all answers, our model benefits from many training examples per answer to learn mean- ingful representations; this issue can possibly be addressed with techniques from zero shot learning ( <ref type="bibr" target="#b19">Palatucci et al., 2009;</ref><ref type="bibr" target="#b20">Pasupat and Liang, 2014</ref>), which we leave to future work.</p><p>We apply basic named entity recogni- tion (ner) by replacing all occurrences of answers in the question text with single entities (e.g., Ernest Hemingway becomes Ernest Hemingway). While we experimented with more advanced ner systems to detect non-answer entities, they could not handle multi-word named entities like the book Love in the Time of Cholera (title case) or battle names (e.g., Battle of Midway). A simple search/replace on all answers in our corpus works better for multi-word entities.</p><p>The preprocessed data are split into folds by tournament. We choose the past two na- tional tournaments 10 as our test set as well as questions previously answered by players in Boyd-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and assign all other questions to train and dev sets. History results are reported on a training set of 3,761 ques- tions with 14,217 sentences and a test set of 699 questions with 2,768 sentences. Literature results are reported on a training set of 4,777 questions with 17,972 sentences and a test set of 908 questions with 3,577 sentences.</head><p>Finally, we initialize the word embedding matrix W e with word2vec ( <ref type="bibr" target="#b17">Mikolov et al., 2013)</ref> trained on the preprocessed question text in our training set. <ref type="bibr">11</ref> We use the hierarchical skip- gram model setting with a window size of five words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>We pit qanta against two types of baselines: bag of words models, which enable comparison to a standard NLP baseline, and information retrieval models, which allow us to compare against traditional question answering tech- niques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BOW</head><p>The bow baseline is a logistic regres- sion classifier trained on binary unigram indi- cators. <ref type="bibr">12</ref> This simple discriminative model is an improvement over the generative quiz bowl answering model of Boyd- .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BOW-DT</head><p>The bow-dt baseline is identical to bow except we augment the feature set with dependency relation indicators. We include this baseline to isolate the effects of the depen- dency tree structure from our compositional model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IR-QB</head><p>The ir-qb baseline maps questions to answers using the state-of-the-art Whoosh ir engine. The knowledge base for ir-qb consists of "pages" associated with each answer, where each page is the union of training question text for that answer. Given a partial question, the text is first preprocessed using a query lan- guage similar to that of Apache Lucene. This processed query is then matched to pages uses bm-25 term weighting, and the top-ranked page is considered to be the model's guess. We also incorporate fuzzy queries to catch misspellings and plurals and use Whoosh's built-in query ex- pansion functionality to add related keywords to our queries. IR-WIKI The ir-wiki model is identical to the ir-qb model except that each "page" in its knowledge base also includes all text from the associated answer's Wikipedia article. Since all other baselines and dt-rnn models operate only on the question text, this is not a valid comparison, but we offer it to show that we can improve even this strong model using qanta.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">DT-RNN Configurations</head><p>For all dt-rnn models the vector dimension d and the number of wrong answers per node j is set to 100. All model parameters other than W e are randomly initialized. The non-linearity f is the normalized tanh function, 13</p><formula xml:id="formula_8">f (v) = tanh(v) tanh(v) .<label>(8)</label></formula><p>qanta is our dt-rnn model with feature averaging across previously-seen sentences in a question. To obtain the final answer prediction given a partial question, we first generate a feature representation for each sentence within that partial question. This representation is computed by concatenating together the word embeddings and hidden representations aver- aged over all nodes in the tree as well as the <ref type="bibr">13</ref> The standard tanh function produced heavy sat- uration at higher levels of the trees, and corrective weighting as in <ref type="bibr" target="#b27">Socher et al. (2014)</ref> hurt our model because named entities that occur as leaves are often more important than non-terminal phrases. root node's hidden vector. Finally, we send the average of all of the individual sentence fea- tures 14 as input to a logistic regression classifier for answer prediction.</p><p>fixed-qanta uses the same dt-rnn configu- ration as qanta except the answer vectors are kept constant as in the text-to-image model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Human Comparison</head><p>Previous work provides human answers (Boyd- Graber et al., 2012) for quiz bowl questions. We use human records for 1,201 history guesses and 1,715 literature guesses from twenty-two of the quiz bowl players who answered the most questions. <ref type="bibr">15</ref> The standard scoring system for quiz bowl is 10 points for a correct guess and -5 points for an incorrect guess. We use this metric to com- pute a total score for each human. To obtain the corresponding score for our model, we force it to imitate each human's guessing policy. For example, <ref type="figure">Figure 3</ref> shows a human answering in the middle of the second sentence. Since our model only considers sentence-level increments, we compare the model's prediction after the first sentence to the human prediction, which means our model is privy to less information than humans.</p><p>The resulting distributions are shown in <ref type="figure" target="#fig_3">Fig- ure 4</ref>-our model does better than the average player on history questions, tying or defeat- ing sixteen of the twenty-two players, but it does worse on literature questions, where it only ties or defeats eight players. The figure indicates that literature questions are harder than history questions for our model, which is corroborated by the experimental results dis- cussed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In this section, we examine why qanta im- proves over our baselines by giving examples of questions that are incorrectly classified by all baselines but correctly classified by qanta. We also take a close look at some sentences that all models fail to answer correctly. Finally, we visualize the answer space learned by qanta.   Red bars indicate that the human is winning, while blue bars indicate that the model is winning. qanta+ir-wiki outperforms most humans on history questions but fails to defeat the "average" human on literature questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>History</head><p>A minor character in this play can be summoned by a bell that does not always work; that character also doesn't have eyelids. Near the end, a woman who drowned her illegitimate child attempts to stab another woman in the Second Empire-style 3 room in which the entire play takes place. For 10 points, Estelle and Ines are characters in which existentialist play in which Garcin claims "Hell is other people", written by Jean-Paul Sartre? <ref type="figure">Figure 3</ref>: A question on the play "No Exit" with human buzz position marked as 3 . Since the buzz occurs in the middle of the second sentence, our model is only allowed to see the first sentence. <ref type="table" target="#tab_0">Table 1</ref> shows that when bag of words and information retrieval methods are restricted to question data, they perform significantly worse than qanta on early sentence positions. The performance of bow-dt indicates that while the dependency tree structure helps by itself, the compositional distributed representations learned by qanta are more useful. The signif- icant improvement when we train answers as part of our vocabulary (see Section 3.2) indi- cates that our model uses answer occurrences within question text to learn a more informa- tive vector space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Results</head><p>The disparity between ir-qb and ir-wiki indicates that the information retrieval models need lots of external data to work well at all sentence positions. ir-wiki performs better than other models because Wikipedia contains many more sentences that partially match spe- cific words or phrases found in early clues than the question training set. In particular, it is impossible for all other models to answer clues in the test set that have no semantically similar or equivalent analogues in the training ques- tion data. With that said, ir methods can also operate over data that does not follow the special constraints of quiz bowl questions (e.g., every sentence uniquely identifies the answer, answers don't appear in their corresponding questions), which qanta cannot handle. By combining qanta and ir-wiki, we are able to leverage access to huge knowledge bases along with deep compositional representations, giv- ing us the best of both worlds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Where the Attribute Space Helps Answer Questions</head><p>We look closely at the first sentence from a literature question about the author Thomas Mann: "He left unfinished a novel whose title character forges his father's signature to get out of school and avoids the draft by feigning desire to join". All baselines, including ir-wiki, are unable to predict the correct answer given only this sentence. However, qanta makes the correct prediction. The sentence contains no named entities, which makes it almost impossible for bag of words or string matching algorithms to predict correctly. <ref type="figure" target="#fig_5">Figure 6</ref> shows that the plot description associated with the "novel" node is strongly indicative of the answer. The five highest-scored answers are all male authors, 16 which shows that our model is able to learn the answer type without any hand-crafted rules.</p><p>Our next example, the first sentence in Ta- ble 2, is from the first position of a question on John Quincy Adams, which is correctly an- swered by only qanta. The bag of words model guesses Henry Clay, who was also a Sec- retary of State in the nineteenth century and helped John Quincy Adams get elected to the presidency in a "corrupt bargain". However, the model can reason that while Henry Clay was active at the same time and involved in the same political problems of the era, he did not represent the Amistad slaves, nor did he negotiate the Treaty of Ghent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Where all Models Struggle</head><p>Quiz bowl questions are intentionally written to make players work to get the answer, especially at early sentence positions. Our model fails to <ref type="bibr">16</ref> three of whom who also have well-known unfinished novels answer correctly more than half the time after hearing only the first sentence. We examine some examples to see if there are any patterns to what makes a question "hard" for machine learning models.</p><p>Consider this question about the Italian ex- plorer John Cabot: "As a young man, this native of Genoa disguised himself as a Muslim to make a pilgrimage to Mecca".</p><p>While it is obvious to human readers that the man described in this sentence is not actu- ally a Muslim, qanta has to accurately model the verb disguised to make that inference. We show the score plot of this sentence in <ref type="figure" target="#fig_6">Figure 7</ref>. The model, after presumably seeing many in- stances of muslim and mecca associated with Mughal emperors, is unable to prevent this information from propagating up to the root node. On the bright side, our model is able to learn that the question is expecting a human answer rather than non-human entities like the Umayyad Caliphate.</p><p>More examples of impressive answers by qanta as well as incorrect guesses by all sys- tems are shown in <ref type="table">Table 2</ref>. <ref type="figure" target="#fig_4">Figure 5</ref> shows a t-SNE visualization <ref type="bibr" target="#b29">(Van der Maaten and Hinton, 2008)</ref> of the 451 answers in our history dataset. The vector space is divided into six general clusters, and we focus in particular on the us presidents. Zooming in on this section reveals temporal clustering: presidents who were in office during the same timeframe occur closer together. This observa- tion shows that qanta is capable of learning attributes of entities during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Examining the Attribute Space</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>There are two threads of related work relevant to this paper. First, we discuss previous ap- plications of compositional vector models to related NLP tasks. Then, we examine existing work on factoid question-answering and review the similarities and differences between these tasks and the game of quiz bowl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Recursive Neural Networks for NLP</head><p>The principle of semantic composition states that the meaning of a phrase can be derived  from the meaning of the words that it con- tains as well as the syntax that glues those words together. Many computational models of compositionality focus on learning vector spaces ( <ref type="bibr" target="#b34">Zanzotto et al., 2010;</ref><ref type="bibr" target="#b6">Erk, 2012;</ref><ref type="bibr" target="#b33">Yessenalina and Cardie, 2011)</ref>. Recent approaches towards modeling compositional vector spaces with neural net- works have been successful, although simpler functions have been proposed for short phrases <ref type="bibr" target="#b18">(Mitchell and Lapata, 2008)</ref>. Recursive neural networks have achieved state-of-the-art performance in sentiment anal- ysis and parsing <ref type="bibr" target="#b26">(Socher et al., 2013c;</ref><ref type="bibr" target="#b10">Hermann and Blunsom, 2013;</ref><ref type="bibr" target="#b24">Socher et al., 2013a</ref>). rnns have not been previously used for learning at- tribute spaces as we do here, although recursive tensor networks were unsuccessfully applied to a knowledge base completion task <ref type="bibr" target="#b25">(Socher et al., 2013b</ref>). More relevant to this work are the dialogue analysis model proposed by <ref type="bibr" target="#b14">Kalchbrenner &amp; Blunsom (2013)</ref> and the paragraph vec- tor model described in <ref type="bibr" target="#b16">Le and Mikolov (2014)</ref>, both of which are able to generate distributed representations of paragraphs. Here we present a simpler approach where a single model is able to learn complex sentence representations and average them across paragraphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Factoid Question-Answering</head><p>Factoid question answering is often functionally equivalent to information retrieval. Given a knowledge base and a query, the goal is to Each cell in the heatmap corresponds to the score (inner product) between a node in the parse tree and the given answer, and the dependency parse of the sentence is shown on the left. All of our baselines, including ir- wiki, are wrong, while qanta uses the plot description to make a correct guess. return the answer. Many approaches to this problem rely on hand-crafted pattern matching and answer-type classification to narrow down the search space <ref type="bibr" target="#b22">(Shen, 2007;</ref><ref type="bibr" target="#b2">Bilotti et al., 2010;</ref><ref type="bibr" target="#b31">Wang, 2006</ref>). More recent factoid qa systems incorporate the web and social media into their retrieval systems ( <ref type="bibr" target="#b1">Bian et al., 2008)</ref>. In contrast to these approaches, we place the burden of learning answer types and patterns on the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Future Work</head><p>While we have shown that dt-rnns are effec- tive models for quiz bowl question answering, other factoid qa tasks are more challenging. Questions like what does the aarp stand for? from trec qa data require additional infras- tructure. A more apt comparison would be to IBM's proprietary Watson system <ref type="bibr" target="#b15">(Lally et al., 2012)</ref> for Jeopardy, which is limited to single sentences, or to models trained on Yago <ref type="bibr" target="#b12">(Hoffart et al., 2013)</ref>.</p><p>We would also like to fairly compare qanta with ir-wiki. A promising avenue for future work would be to incorporate Wikipedia data into qanta by transforming sentences to look like quiz bowl questions ( <ref type="bibr" target="#b30">Wang et al., 2007)</ref> and to select relevant sentences, as not every sen- tence in a Wikipedia article directly describes its subject. Syntax-specific annotation <ref type="bibr" target="#b21">(Sayeed et al., 2012</ref>) may help in this regard. Finally, we could adapt the attribute space learned by the dt-rnn to use information from knowledge bases and to aid in knowledge base completion. Having learned many facts about entities that occur in question text, a dt-rnn could add new facts to a knowledge base or check existing relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We present qanta, a dependency-tree recursive neural network for factoid question answering that outperforms bag of words and informa- tion retrieval baselines. Our model improves upon a contrastive max-margin objective func- tion from previous work to dynamically update answer vectors during training with a single model. Finally, we show that sentence-level representations can be easily and effectively combined to generate paragraph-level represen- Q he also successfully represented the amistad slaves and negotiated the treaty of ghent and the annexation of florida from spain during his stint as secretary of state under james monroe A john quincy adams, henry clay, andrew jack- son Q this work refers to people who fell on their knees in hopeless cathedrals and who jumped off the brooklyn bridge A howl, the tempest, paradise lost Q despite the fact that twenty six martyrs were crucified here in the late sixteenth century it remained the center of christianity in its coun- try A nagasaki, guadalcanal, ethiopia Q this novel parodies freudianism in a chapter about the protagonist 's dream of holding a live fish in his hands A billy budd, the ambassadors, all my sons Q a contemporary of elizabeth i he came to power two years before her and died two years later A grover cleveland, benjamin harrison, henry cabot lodge <ref type="table">Table 2</ref>: Five example sentences occuring at the first sentence position along with their top three answers as scored by qanta; correct an- swers are marked with blue and wrong answers are marked with red. qanta gets the first three correct, unlike all other baselines. The last two questions are too difficult for all of our models, requiring external knowledge (e.g., Freudianism) and temporal reasoning.</p><p>tations with more predictive power than those of the individual sentences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example quiz bowl question about the Holy Roman Empire. The first sentence contains no words or named entities that by themselves are indicative of the answer, while subsequent sentences contain more and more obvious clues.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Dependency parse of a sentence from a question about Sparta.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparisons of qanta+ir-wiki to human quiz bowl players. Each bar represents an individual human, and the bar height corresponds to the difference between the model score and the human score. Bars are ordered by human skill. Red bars indicate that the human is winning, while blue bars indicate that the model is winning. qanta+ir-wiki outperforms most humans on history questions but fails to defeat the "average" human on literature questions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: t-SNE 2-D projections of 451 answer vectors divided into six major clusters. The blue cluster is predominantly populated by U.S. presidents. The zoomed plot reveals temporal clustering among the presidents based on the years they spent in office.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: A question on the German novelist Thomas Mann that contains no named entities, along with the five top answers as scored by qanta. Each cell in the heatmap corresponds to the score (inner product) between a node in the parse tree and the given answer, and the dependency parse of the sentence is shown on the left. All of our baselines, including irwiki, are wrong, while qanta uses the plot description to make a correct guess.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: An extremely misleading question about John Cabot, at least to computer models. The words muslim and mecca lead to three Mughal emperors in the top five guesses from qanta; other models are similarly led awry.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Accuracy for history and literature at the first two sentence positions of each question and the full question. The top half of the table compares models trained on questions only, while the IR models in the bottom half have access to Wikipedia. qanta outperforms all baselines that are restricted to just the question data, and it substantially improves an IR model with access to Wikipedia despite being trained on much less data.</figDesc><table>Literature 

</table></figure>

			<note place="foot" n="1"> We had 46 unique dependency relations in our quiz bowl dataset.</note>

			<note place="foot" n="2"> Of course, questions never contain their own answer as part of the text. 3 In quiz bowl, all wrong guesses are equally detrimental to a team&apos;s score, no matter how &quot;close&quot; a guess is to the correct answer.</note>

			<note place="foot" n="6"> We experimented with weighting earlier sentences less than later ones in the average as well as learning an additional RNN on top of the sentence-level representations. In the former case, we observed no improvements over a uniform average, while in the latter case the model overfit even with strong regularization. 7 We tried transforming Wikipedia sentences into quiz bowl sentences by replacing answer mentions with appropriate descriptors (e.g., &quot;Joseph Heller&quot; with &quot;this author&quot;), but the resulting sentences suffered from a variety of grammatical issues and did not help the final result.</note>

			<note place="foot" n="8"> https://pypi.python.org/pypi/Whoosh/ 9 Code and non-naqt data available at http://cs. umd.edu/ ~ miyyer/qblearn.</note>

			<note place="foot" n="10"> The tournaments were selected because naqt does not reuse any questions or clues within these tournaments. 11 Out-of-vocabulary words from the test set are initialized randomly. 12 Raw word counts, frequencies, and TF-IDF weighted features did not increase performance, nor did adding bigrams to the feature set (possibly because multi-word named entities are already collapsed into single words).</note>

			<note place="foot" n="14"> Initial experiments with L2 regularization hurt performance on a validation set. 15 Participants were skilled quiz bowl players and are not representative of the general population.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers, Stephanie Hwa, Bert Huang, and He He for their insight-ful comments. We thank Sharad Vikram, R. Hentzel, and the members of naqt for pro-viding our data. This work was supported by nsf Grant IIS-1320538. Boyd-Graber is also supported by nsf Grant CCF-1018625. Any opinions, findings, conclusions, or recommen-dations expressed here are those of the authors and do not necessarily reflect the view of the sponsor.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Jauvin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Finding the right facts in the crowd: factoid question answering over social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rank learning for factoid question answering with linguistic and semantic constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Bilotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Elsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Besting the quiz master: Crowdsourcing incremental classification games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brianna</forename><surname>Satinoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>He He, and Hal Daume III</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">999999</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Vector space models of word meaning and phrase meaning: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Linguistics Compass</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning task-dependent distributed representations by backpropagation through structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Goller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kuchler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Neural Networks</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Multi-step regression learning for compositional distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao-Zhong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrnoosh</forename><surname>Sadrzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Role of Syntax in Vector Space Models of Compositional Semantics</title>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<editor>Karl Moritz Hermann and Phil Blunsom</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">not not bad&quot; is not &quot;bad&quot;: A distributional account of negation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Continuous Vector Space Models and their Compositionality</title>
		<meeting>the ACL Workshop on Continuous Vector Space Models and their Compositionality</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semantic frame identification with distributed word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Yago2: A spatially and temporally enhanced knowledge base from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fabian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="28" to="61" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Political ideology detection using recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Enns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Recurrent convolutional neural networks for discourse compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Workshop on Continuous Vector Space Models and their Compositionality</title>
		<meeting>the 2013 Workshop on Continuous Vector Space Models and their Compositionality</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Question analysis: How watson reads a clue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Boguraev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Fodor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chu-Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Vector-based models of semantic composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Zero-shot learning with semantic output codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Zero-shot entity extraction from web pages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Grammatical structures for word-level sentiment detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Asad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Sayeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Rusk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using semantic role to improve question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Parsing With Compositional Vector Grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reasoning With Neural Tensor Networks For Knowledge Base Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Grounded compositional semantics for finding and describing images with sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Ranking with ordered weighted pairwise classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Buffoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">What is the Jeopardy model? a quasisynchronous grammar for QA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A survey of answer extraction techniques in factoid question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Wsabie: Scaling up to large vocabulary image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Compositional matrix-space models for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ainur</forename><surname>Yessenalina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Estimating linear models for compositional distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Massimo Zanzotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Korkontzelos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Fallucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
