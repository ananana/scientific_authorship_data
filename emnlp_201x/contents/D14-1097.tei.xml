<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Experimental Comparison of Active Learning Strategies for Partially Labeled Sequences</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
							<email>diego.marcheggiani@isti.cnr.it</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LIP6 Pierre et Marie Curie University Paris</orgName>
								<orgName type="institution">Istituto di Scienza e Tecnologie dell&apos;Informazione Consiglio Nazionale delle Ricerche Pisa</orgName>
								<address>
									<country>Italy, France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Artì</surname></persName>
							<email>thierry.artieres@lip6.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LIP6 Pierre et Marie Curie University Paris</orgName>
								<orgName type="institution">Istituto di Scienza e Tecnologie dell&apos;Informazione Consiglio Nazionale delle Ricerche Pisa</orgName>
								<address>
									<country>Italy, France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Experimental Comparison of Active Learning Strategies for Partially Labeled Sequences</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="898" to="906"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Active learning (AL) consists of asking human annotators to annotate automatically selected data that are assumed to bring the most benefit in the creation of a classifier. AL allows to learn accurate systems with much less annotated data than what is required by pure supervised learning algorithms, hence limiting the tedious effort of annotating a large collection of data. We experimentally investigate the behavior of several AL strategies for sequence labeling tasks (in a partially-labeled scenario) tailored on Partially-Labeled Conditional Random Fields, on four sequence labeling tasks: phrase chunking, part-of-speech tagging, named-entity recognition, and bio-entity recognition.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Today, the state-of-the-art methods in most natural lan- guage processing tasks are supervised machine learn- ing approaches. Their main problem lies in their need of large human-annotated training corpus, which re- quires a tedious and expensive work from domain ex- perts. The process of active learning (AL) employs one or more human annotators by asking them to label new samples which are supposed to be the most informa- tive in the creation of a new classifier. A classifier is incrementally retrained with all the data labeled by the annotator. AL has been demonstrated to work well and to produce accurate classifiers while saving much hu- man annotation effort. One critical issue is to define a measure of the informativeness which should reflect how much new information a new example would give in the learning of a new classifier once annotated.</p><p>A lot of work has been done on the AL field in the past years (see <ref type="bibr" target="#b11">(Settles, 2012)</ref> for an exhaustive overview). In particular, AL proved its usefulness in se- quence labeling tasks <ref type="bibr" target="#b10">(Settles and Craven, 2008</ref>). Yet, researchers have always adopted as annotation unit an entire sequence (i.e., the annotator is asked to anno- tate the whole sequence) while it looks like it could be much more relevant to ask for labeling only small parts of it (e.g., the ones with highest ambiguity). A few works have investigated this idea. For instance, <ref type="bibr" target="#b18">Wanvarie et al. (2011)</ref> proposed to use Partially-Labeled Conditional Random Fields (PL-CRFs) ( <ref type="bibr" target="#b17">Tsuboi et al., 2008</ref>), a semi-supervised variation of Conditional Ran- dom Fields (CRFs) ( <ref type="bibr" target="#b5">Lafferty et al., 2001</ref>) able to deal with partially-labeled sequences, thus enabling to adopt as annotation unit single tokens and still learning from full sequences. AL with partially labeled sequences has proven to be effective in substantially reducing the amount of annotated data with respect to common AL approaches (see <ref type="bibr" target="#b18">(Wanvarie et al., 2011)</ref>).</p><p>In this work we focus on AL strategies for partially labeled sequences adopting the single token as annota- tion unit and PL-CRFs as learning algorithm given its nature in dealing with partially labeled sequences. We propose several AL strategies based on measures of un- certainty adapted for the AL with partially labeled se- quences scenario and tailored on PL-CRFs. We further propose two strategies that exploit the finer granularity given by the partially-labeled scenario. We also show that the choice of single-token annotation can bring to unpredictable results on sequence labeling tasks in which the structure of the sequences is not regular, e.g., named-entity recognition. We propose a first solution to the problem of unpredictability. The aim of this work is thoroughly compare the effectiveness and the behavior of all the proposed AL strategies on four stan- dard sequence labeling tasks, phrase chunking, part- of-speech tagging, named-entity recognition and bio- entity recognition.</p><p>The remainder of this paper is as follows. In Sec- tion 2 we summarize the related work in AL, in Sec- tion 3 we describe PL-CRFs, the semi-supervised al- gorithm we adopt in this work. Section 4 describes in details the AL framework and the AL strategies we propose. Section 5 provides a description of the experi- mental setting, the datasets, and discusses the empirical results. Section 6 summarizes our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work belongs to the pool-based AL framework. It considers the case in which a large amount (pool) of unlabeled examples is available, from which samples to be labeled must be chosen. This framework fits all the sequence labeling problems we consider here. For a more exhaustive survey on other AL frameworks see <ref type="bibr" target="#b11">(Settles, 2012)</ref>.</p><p>Most of the AL works on sequence labeling adopted the entire sequence as annotation unit <ref type="bibr" target="#b10">(Settles and Craven, 2008)</ref> which was demonstrated by <ref type="bibr" target="#b18">Wanvarie et al. (2011)</ref> to be less effective than using the single token as annotation unit. The main AL works in this latter line of work are <ref type="bibr" target="#b12">(Shen et al., 2004</ref>),  and <ref type="bibr" target="#b18">(Wanvarie et al., 2011</ref>). <ref type="bibr" target="#b12">Shen et al. (2004)</ref> adopted SVMs as learning algorithm and proposed two strategies that combine three criteria, in- formativeness, representativeness and diversity. SVMs allowed them to use as annotation unit a subset of the tokens in a sequence, without annotating, in any way, the rest of the tokens in the sequence. In , the most uncertain tokens of the sequence are singularly annotated, but the rest of the labels in the sequence are then chosen by the classifier in a semi- supervised fashion. <ref type="bibr" target="#b18">Wanvarie et al. (2011)</ref> is the clos- est work to ours, they adopt a minimum confidence se- lection strategy with re-estimation using the PL-CRFs. Differently from our work, <ref type="bibr" target="#b18">Wanvarie et al. (2011)</ref> show that adopting the AL with partially labeled sequences using re-estimation, the annotation cost can be dramat- ically reduced (by annotating from 8% to 10% of the tokens of the entire training set), obtaining the same level of performance of the classifier trained on the en- tire, fully-labeled, training set. We started our work from this conclusion and we focused on AL with par- tially labeled sequences using re-estimation by compar- ing several AL strategies in order to find the strategy that allows to create the best classifier with the mini- mum annotation effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Partially-Labeled</head><p>Conditional Random Fields</p><p>Nowadays, CRFs are the de-facto standard for the so- lution of sequence labeling tasks <ref type="bibr" target="#b8">(Sarawagi, 2008)</ref>. In traditional CRFs ( <ref type="bibr" target="#b5">Lafferty et al., 2001</ref>) the conditional probability of a sequence of labels y given a sequence of observed feature vectors x is given by:</p><formula xml:id="formula_0">p(y|x) = 1 Z(x) T t=1 Ψ t (y, x)<label>(1)</label></formula><p>where a standard choice for sequence labeling tasks are the so called Linear-chain CRFs:</p><formula xml:id="formula_1">p(y|x) = 1 Z(x) T t=1 Ψ t (y t , y t−1 , x t )<label>(2)</label></formula><p>with:</p><formula xml:id="formula_2">Ψ t (y t , y t−1 , x t ) = Ψ u (y t , x t )Ψ b (y t , y t−1 ) (3)</formula><p>where Ψ u (y t , x t ) models the co-occurrence between features x t , and label y t at time t, and Ψ b (y t , y t−1 ) models the co-occurrence between two adjacent labels y t and y t−1 . PL-CRFs introduced by <ref type="bibr" target="#b17">Tsuboi et al. (2008)</ref> allow to learn a CRF model using partially-labeled sequences, marginalizing on those tokens that do not have an as- signed label. In PL-CRFs, L denotes a partially labeled information about a sequence. It consists of a sequence of sets L t in which L t = Y (where Y is the set of all the possible labels) if there is no label information for token at time t. L t is a singleton containing y t if the label of the token at time t is known, and Y L is the set of label sequences that fits the partial label information L. Then the probability of a partial labeling may be computed as:</p><formula xml:id="formula_3">p(Y L |x) = y∈Y L p(y|x)<label>(4)</label></formula><p>In order to perform inference and parameter learning on PL-CRFs, some modifications on traditional CRFs inference algorithms are required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Forward-Backward Algorithm</head><p>Differently from traditional CRFs, the forward and backward scores (respectively α and β), are calculated as follows:</p><formula xml:id="formula_4">α t,L (j) =        0 if j ∈ L t Ψ 1 (j, y 0 , x 1 ) else if t = 1 and j ∈ L t SA(j) otherwise (5) β t,L (i) =        0 if j ∈ L t 1 else if t = T and j ∈ L t SB(j) otherwise (6)</formula><p>where</p><formula xml:id="formula_5">SA(j) = i∈Lt−1 α t−1,L (i)Ψ t (j, i, x t )<label>(7)</label></formula><formula xml:id="formula_6">SB(j) = j∈Lt+1 β t+1,L (j)Ψ t+1 (j, i, x t+1 )<label>(8)</label></formula><p>and y 0 is a special label that encodes the beginning of a sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Marginal Probability</head><p>The marginal probability p(y t = j|x, L) is calculated as:</p><formula xml:id="formula_7">p(y t = j|x, L) = α t,L (j) · β t,L (j) Z L (x)<label>(9)</label></formula><p>with:</p><formula xml:id="formula_8">∀t, Z L (x) = j∈Lt α t,L (j) · β t,L (j)<label>(10)</label></formula><p>In case there is no label information, the formulas for forward and backward scores (Equations <ref type="formula">(5)</ref> and <ref type="formula">(6)</ref>) and for the marginal probabilities (Equation <ref type="formula" target="#formula_7">(9)</ref>) yield the standard results of CRFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Viterbi Algorithm</head><p>The most probable sequence assignment may be de- rived with a Viterbi algorithm by recursively comput- ing the following quantities:</p><formula xml:id="formula_9">δ t,L (j) =        0 if j ∈ L t Ψ 1 (j, y 0 , x 1 ) else if t = 1 and j ∈ L t M (j)</formula><p>otherwise <ref type="formula" target="#formula_0">(11)</ref> where</p><formula xml:id="formula_10">M (j) = max i∈Lt−1 δ t−1,L (i)Ψ t (j, i, x t )<label>(12)</label></formula><p>The most probable assignment is then calculated as:</p><formula xml:id="formula_11">y * = argmax y p(y|x, L)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Log-Likelihood</head><p>PL-CRFs's parameters θ are learnt through maximum log-likelihood estimation, that is to maximize the log- likelihood function LL(θ):</p><formula xml:id="formula_12">LL(θ) = N i=1 log p(Y L (i) |x (i) ) = N i=1 log Z Y L (i) (x (i) ) − log Z Y (x (i) )<label>(13)</label></formula><p>The parameters θ that maximize Equation <ref type="formula" target="#formula_0">(13)</ref> are computed via the LBFGS optimization method <ref type="bibr" target="#b0">(Byrd et al., 1994</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Active Learning Strategies</head><p>Pool-based AL (see ( <ref type="bibr" target="#b6">Lewis and Catlett, 1994)</ref>) is prob- ably the most common scenario in AL, where one has a large amount (pool) of unlabeled examples U 1 and a small amount of labeled examples T 1 . In this scenario, the process of AL consists in a series of n iterations where a classifier Φ i is trained with labeled examples T i , and then is used to classify the unlabeled examples U i . At this point an AL strategy S will select a number of examples B that once labeled will hopefully improve the performance of the next classifier Φ i+1 . Algorithm 1 shows the pool-based AL framework for partially annotated sequences as introduced in ( <ref type="bibr" target="#b18">Wanvarie et al., 2011</ref>). Differently from AL for fully labeled sequences ( , thanks to the finer granularity of the partially labeled model, we use the token as basic annotation unit, instead of the entire sequence.</p><p>The point of using the partial labeling is in saving the request for human annotations on tokens whose labels are already known (inferred) by the classifier and con- centrate on those tokens that the classifier finds hard to label. Using the semi-supervised approach of the PL- CRFs we can take advantage of single-labeled tokens instead of an entire labeled sequence.</p><p>The entire pool-based AL process with partially la- beled sequences is summarized in Algorithm 1. The</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Pool-based active learning framework</head><p>Require: T 1 , the initial training set U 1 , the initial unlabeled set S, the selected AL strategy n, the number of iterations B, the dimension of the update batch 1: for i ← 1 to n do 2:</p><formula xml:id="formula_13">Φ i ← train(T i ) 3: L i ← Φ i (U i ) 4:</formula><p>for b ← 1 to B do 5:</p><formula xml:id="formula_14">x (b) * ← arg min xt∈x,x∈Li S(t, x) 6: L i ← L i − x (b) ∪ Φ i (x (b) , y * ) 7: U i ← U i − x (b) * ∪ (x (b) * , y * )</formula><p>8:</p><formula xml:id="formula_15">T i ← T i − x (b) * ∪ (x (b) * , y * ) 9: U i+1 ← U i 10: T i+1 ← T i function S(t, x)</formula><p>is what, hereafter, we call an AL strat- egy. S(t, x) takes as input an automatically annotated sequence x and an element t of this sequence, from the set of sequences L i annotated by the PL-CRF classi- fier Φ i , and returns a measure of informativeness as a function of the classifier decision. For each iteration through the update batch B, the most informative element x (b) * , according to the AL strategy, is chosen. The subscript * , in this case, repre- sents the most informative token, while the superscript (b) represents the sequence in which the token appears. After the choice of the most informative token the sets L i , U i and T i are updated. L i is updated by remov- ing the annotated sequence x (b) and all the informa- tion given by the classifier, and by adding the same se- quence with the new manually labeled token (y * ) and all the re-estimated annotation given by the classifier Φ i (x (b) , y * ). In the unlabeled set U i and the training set T i the most informative token x (b) * is updated with its manually labeled version (x (b) * , y * ) 1 . After B token annotations, the unlabeled set and the training set for the next iteration, respectively U i+1 and T i+1 , are up- dated.</p><p>The inference methods of Section 3 allow not only to train a CRF model with partially labeled sequences, but give the possibility of classifying partially labeled sequences, using the known labels as support for the prediction of the other ones. Thus, in this AL scenario, each time a token is chosen it is immediately labeled, and this new information, as we can see from line 6 of Algorithm 1, is promptly used to re-estimate the infor- mativeness of the other tokens in the sequence in which the chosen token appears.</p><p>One may argue that, for a human annotator, anno-tating only one or few tokens, instead of the entire se- quence, is a difficult task. This would be correct in the scenario in which the text is presented to the hu- man annotator without any visual clue about the an- notations. However, in <ref type="bibr" target="#b1">(Culotta and McCallum, 2005</ref>) it is shown that presenting to the human annotator the highlighted sequence to be annotated along with the as- sociated sequence of labels obtained by the classifier requires much less effort from the annotator than per- forming the annotation without any visual and contex- tual clue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Greedy Strategies</head><p>In this section we present three AL strategies that select the most informative tokens, regardless of the assign- ment performed by the Viterbi algorithm. The ratio- nale behind these strategies is that, even though we are looking for the most probable sequence assignment, we also want to annotate the most informative tokens sin- gularly.</p><p>The Minimum Token Probability (MTP) strategy employs as measure of informativeness the probability of the most probable assignment at time t. This strategy greedily samples the tokens whose highest probability among the labels is lowest.</p><formula xml:id="formula_16">S M T P (t, x) = max j∈Y p(y t = j|x, L)<label>(14)</label></formula><p>The Maximum Token Entropy (MTE) strategy relies on the entropy measure to evaluate the ambiguity about the label of a token. The rationale of it is that, if more than one label have the same assigned marginal proba- bility, the entropy will be high, that is,</p><formula xml:id="formula_17">S M T E (t, x) = j∈Y p(y t = j|x, L) · log p(y t = j|x, L)<label>(15)</label></formula><p>In order to directly plug the S M T E strategy into the AL framework of Algorithm 1, we removed the minus sign at the beginning of the entropy formula. This allow us to use the min operator with a maximum entropy approach.</p><p>The Minimum Token Margin (MTM) strategy is a variant of the margin sampling strategy introduced in ( <ref type="bibr" target="#b9">Scheffer et al., 2001</ref>). It calculates the informative- ness by considering the two most probable assignments and by subtracting the highest probability by the low- est. With max that calculates the second maximum value, MTM is defined as:</p><formula xml:id="formula_18">S M T M (t, x) = max j∈Y p(y t =j|x, L) − max j∈Y p(y t = j|x, L)<label>(16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Viterbi Strategies</head><p>The following AL strategies take into consideration the most probable sequence assignments obtained from the Viterbi algorithm computed on already known labels in the sequence.</p><p>The rationale is that, with these strategies, the mea- sure of uncertainty is chosen according to the informa- tion obtained from the outcome of the Viterbi algorithm (i.e., the most probable sequence assignment).</p><p>The Minimum Viterbi Probability (MVP) is the base strategy adopted in ( <ref type="bibr" target="#b18">Wanvarie et al., 2011</ref>). It takes as measure of informativeness the probability of the label chosen by the Viterbi algorithm.</p><formula xml:id="formula_19">S M V P (t, x) = p(y * t |x, L)<label>(17)</label></formula><p>where y * t is the label assignment chosen by the Viterbi algorithm. In general, the token assignments that max- imize the probability of the sequence assignment y * t are different from the token assignments that maxi- mize the probability of the individual token assign- ments argmax j∈Y p(y t = j).</p><p>The Maximum Viterbi Pseudo-Entropy (MVPE) strategy calculates for each token the "pseudo" entropy of the most probable sequences at the variation of the label at position t. The prefix pseudo is used because even though it is calculated as an entropy, the summa- tion is over all the possible labels that can be associated to a token, and not all the possible sequence assign- ments.</p><formula xml:id="formula_20">S M V P E (t, x) = j∈Y p(y * yt=j |x, L) · log p(y * yt=j |x, L) (18)</formula><p>where y * yt=j represents the most probable assignment with the label at time t constrained to the value j. As in the MTE strategy the minus sign is removed in order to plug the functions directly into the AL framework of Algorithm 1.</p><p>The Minimum Viterbi Margin (MVM) strategy calculates the difference of the sequence probabili- ties of the two most probable sequence assignments at the variation of the label at time t. When the dif- ference at time t is low, the Viterbi algorithm, in that time, chooses between two almost equally probable, se- quence assignments. Formally:</p><formula xml:id="formula_21">S M V M (t, x) = p(y * y * t |x, L) − p(y * y * t |x, L) (19)</formula><p>where y * is the second most probable assignment.</p><p>PL-CRFs allow us to inspect one token at time in or- der to decide if it is worth to annotate. This fact give us the possibility of exploit two quantities in order to estimate the informativeness of a token, the sequence probability, usually adopted in the traditional AL for sequence labeling, and the marginal probabilities of the single tokens as in Section 4.1. The Minimum Expec- tation (ME) strategy combines the marginal probabili- ties, p(y t = j|x, L) and p(y * yt=j |x, L).</p><formula xml:id="formula_22">S M E (t, x) = j∈Y p(y t = j|x, L) · p(y * yt=j |x, L)<label>(20)</label></formula><p>Here the maximum sequence probability is seen as a function, and what we calculate is the expected value of this very function. The rationale of this strategy is pick- ing those tokens in which both, the sequence probabil- ity returned by the Viterbi algorithm, and the marginal probability of the considered labels are low. Given that the ME strategy gives a high weight to the sequence probability, one might expect that tokens that belongs to longer sequences are selected more fre- quently, given that, the sequence probability of longer sequences is usually lower than shorter ones. One way to normalize this difference is subtracting the current maximum sequence probability, that is, the maximum sequence probability calculated without any new label estimation, to the expected value obtained from the es- timation of the label assignment of the token. This is the Minimum Expectation Difference (MED) strat- egy.</p><formula xml:id="formula_23">S M ED (t, x) = S M E (t, x) − p(y * |x, L)<label>(21)</label></formula><p>The rationale of this strategy is that when the expected value is far from the maximum value, that is the value returned by the Viterbi algorithm, it means that we have uncertainty on the token taken into consideration. The Random (RAND) strategy samples random to- kens without any external information. It is used as baseline to compare the real effectiveness of the pro- posed strategy.</p><p>At the best of our knowledge the strategies presented in this section (with the exception of the MVP strategy) have never been applied in the context of AL with par- tially labeled sequences scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We have experimented and evaluated the AL strate- gies of Section 4 on four sequence labeling tasks, part-of-speech tagging, phrase chunking, named-entity recognition and bio-entity recognition. We used the CoNLL2000 dataset <ref type="bibr" target="#b13">(Tjong Kim Sang and Buchholz, 2000</ref>) for the phrase chunking task, the CoNLL2003 dataset <ref type="bibr" target="#b14">(Tjong Kim Sang and De Meulder, 2003)</ref>, for the named-entity recognition task, the NLPBA2004 dataset ( <ref type="bibr" target="#b4">Kim et al., 2004</ref>), for the biomedical entity recognition task and the CoNLL2000POS dataset 2 for the part-of-speech labeling task. All the datasets are publicly available and are standard benchmarks in se- quence labeling tasks. <ref type="table">Table 1</ref> shows some statistics of the datasets in terms of dimensions, number of labels, distribution of the labels, etc. The data heterogeneity of the different datasets allowed us to test the AL strate- gies on different "experimental settings", thus to have a more robust empirical evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Setting</head><p>We tested the AL strategies described in Section 4 on test sets composed by 2012 sequences and 47377 tokens for the CoNLL2000 and CoNLL2000POS datasets, by 3452 sequences and 46394 tokens for the CoNLL2003 dataset and by 3856 sequences and 101039 tokens for the NLPBA2004 dataset. We chose an initial training set T 1 of ∼5 sequences on CoNLL2000 and CoNLL2000POS datasets, ∼7 se- quences on CoNLL2003 dataset and ∼4 sequences on NLPBA2004 dataset, for a total of ∼100 labeled tokens for each dataset. The dimension of the batch update B has been chosen as a trade-off between an ideal case in which the system is retrained after every single anno- tation (i.e., B = 1) and a practical case with higher B to limit the algorithmic complexity (since the PL-CRF classifier must be retrained every iteration). We used in our experiments B = 50. We fixed the number of AL iterations n at 40 because what matters here is how the strategies behave in the beginning of AL process when the annotation effort remains low. For each strategy and for each dataset, we report averaged results of three runs with a different randomly sampled initial training set T 1 .</p><p>For each dataset we adopted a standard set of fea- tures. For the CoNLL2000 dataset we adopted the same standard features used in ( <ref type="bibr" target="#b18">Wanvarie et al., 2011</ref>) for the same dataset, for the CoNLL2003 and the NLPBA2004 dataset we adopted the features used in ( <ref type="bibr" target="#b18">Wanvarie et al., 2011</ref>) for the CoNLL2003 dataset, while for the CoNLL2000POS dataset we used the features pre- sented in <ref type="bibr" target="#b7">(Ratnaparkhi, 1996)</ref>. As evaluation measure we adopted the token variant of the F 1 measure, intro- duced by . This variant, in- stead of the entire annotation (chunk/entity), calculates T P s, F P s, and F N s, singularly for each token that compose the annotation, bringing to a finer evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>From the learning curves of <ref type="figure" target="#fig_0">Figure 1</ref> and <ref type="figure">Figure 2</ref> it is clear that most of the strategies have the same trend throughout the different datasets. This results is some- what different from the results obtained in <ref type="bibr" target="#b10">(Settles and Craven, 2008</ref>) in which there is not a clear winner among the strategies they proposed in a fully-labeled scenario. The strategies that perform particularly bad (worse than the RAND strategy in CoNLL2000POS and in CoNLL2003 dataset) in all the datasets are the MTE and MTP. This is expected, because the choice of the measure of informativeness related to the token without taking in consideration the Viterbi path is sub- optimal in this task. Surprisingly, the MTM strategy even though based on the same principle of MTE and MTP, is very effective in most of the datasets. The most effective strategies, that is, the ones that are the faster at helping the classifier to reach a better accu- racy are the MTM, MVM, and MVP, in particular the margin-based strategies perform very good in all the <ref type="table">Table 1</ref>: Training Data Statistics. #S is the number of total sequences in the dataset, #T is the number of tokens in the dataset, #L is the number of positive labels (labels different from the negative label O), AAL is the average length, in tokens, of annotations (sequence of tokens that refer to the same instance of a label), APT is the average number of token in a sequence annotated with a positive label, ASL is the average length of a sequence, AA is the average number of annotations in a sequence, %AC is the percentage of sequences with more than one positive annotation, %DAC is the percentage of sequences that have two or more annotations with different labels.  datasets. The MVPE strategy performs particularly bad in the CoNLL2003 dataset but it performs better than the RAND strategy in the other datasets. The perfor- mance of the ME strategy is always above the aver- age, in particular it is the best performing strategy in the NLPBA2004 dataset. However, in the CoNLL2003 dataset its performance is similar to the RAND's per- formance. Looking at the data, as expected, ME tends to choose tokens belonging to the longest sequences, regardless if the sequence is already partially anno- tated, that is, it tends to choose tokens from the same sequences. This behavior is not particularly relevant on the CoNLL2003 dataset given that the average num- ber of positive tokens per sentence is not high (2.5, see <ref type="table">Table 1</ref>). For the other datasets, the average num- ber of positive tokens per sentence is high, and so the ME strategy is particularly effective. The MED strategy has the most heterogeneous behavior among the datasets. It shows average performances in the CoNLL2000 dataset and NLPBA2004 dataset, but is slower than the RAND strategy in the CoNLL2003 and CoNLL2000POS datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>In <ref type="figure">Figure 2</ref> (left) we can notice that there are some strategies that are consistently worse than the RAND strategy. The difference between the strategies below the RAND strategy and the RAND strategy itself might be due to the fact that those strategies ask to label to- kens that are "outliers" (if we imagine tokens as points of the features space) that rarely appear in the training and test set, and on which the classifier is very uncer- tain. Given that we are in a semi-supervised setting, with very few training examples, these "outliers" can introduce a lot of noise in the created models and so yielding poor results. This phenomenon does not hap- pen in the RAND strategy given that it samples uni- formly from the unlabeled set and given that the "out- liers" (special cases) are not many, the probability of randomly selecting an "outlier" is low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Performance Drop</head><p>The AL strategies applied on the CoNLL2003 dataset <ref type="figure">(Figure 2 (left)</ref>) suffer of some "random" drop of per- formance. We believe that the first reason that yield such a behavior is that named entities often appear once in a sentence, and have heterogeneous structures with respect to some homogenous structures as the chunk and POS. The second reason is that, it may happen that the strategies are not accurate enough to localize pre- cisely the best token to label or that getting the label of an isolated token does not help the classifier much 903  A similar phenomenon, called missed class effect , happens in AL when the strate- gies inspect regions of the example space around the decision boundaries, bringing to a slow AL process. In ) the missed class effect prob- lem is solved by helping the AL strategies to inspect regions far from the decision boundaries, that is, by choosing an entire sequence instead of a single to- ken. This solution is not suitable in this context given that we will loose all the advantages we have in the partially-labeled scenario, thus, we decided to anno- tate for each chosen token the previous token and the next token. The learning curves of the AL strategies adopting this method <ref type="figure">(Figure 3)</ref> show a monotonically increasing performance in function of the number of annotated tokens.</p><p>By annotating three tokens at time, the tokens that were considered "outliers" in the scenario with a single token annotation are now supported by other tokens of the sequence. This fact helps to decrease the noise in- troduced in the semi-supervised model yielding better results. <ref type="figure">Figure 4</ref> reports a few statistics that highlight the be- havior of the methods on one of the datasets. One may see for instance that the MVM and ME strategies are very different from the other methods in that they se- lect tokens that belong to significantly longer sentences on average. Also it may be seen that MVM in partic- ular selects tokens that are far from already annotated tokens in the sentence. This strategy probably yields a particular behavior with respect to exploration and ex- ploitation that seems to suit the two tasks well. The other strategies do exhibit different behaviors that intu- itively should not work well. For instance the MED and the MVPE strategies select tokens from new fully unla- beled sentences (not shown statistics), preferably short, so that the distance from selected tokens to already la- beled tokens in the sentence (when any) is low. These curves look like relevant indicators of the behavior of the methods, and it would probably be worth monitor- ing these all along the AL process to make sure the learning exhibit a suitable behavior. This will be a fu- ture study that is out of the scope of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Statistical Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we have presented several AL strategies tailored for the PL-CRFs in a pool-based scenario. We have tested the proposed strategies on four different datasets for four different sequence labeling tasks. Dif- ferently from other similar work in the field of AL, in this study we have shown that margin-based strate- gies constantly achieve good performance on four tasks with very different data characteristics. Furthermore, we have found that on datasets with certain character- istics a particular phenomenon that makes the entire 904  <ref type="figure">Figure 4</ref>: Behavior of the methods on CoNLL2000 dataset as a function of the number of the iterations (x-axis, from 1 to 40). Average length of the sentence the tokens that are selected by the AL strategy belong to (left) and average distance from a token that is selected to the closest already labeled token in the sentence, if any (right).</p><p>AL process highly unpredictable shows up. This phe- nomenon consists in random drops of accuracy of the classifiers learnt during the AL process. We have pro- posed a first solution for this problem that does not have a relevant impact on the human annotation effort.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: F 1 results on CoNLL2000 dataset (left) and CoNLL2000POS dataset (right). For both datasets the maximum number of annotated tokens used (2100) represents ∼1% of the entire training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: F 1 results on CoNLL2003 dataset (left) and NLPBA2004 dataset (right). 2100 annotated tokens represent the ∼0.8% and ∼0.4% respectively of the CoNLL2003 training set and the NLPBA2004 training set.</figDesc></figure>

			<note place="foot" n="1"> In order to have a light notation we omit the fact that when the most informative token is the first annotated token of a sentence, the whole sentence, with just one annotated token, is added to the training set Ti</note>

			<note place="foot" n="2"> This is the CoNLL2000 dataset annotated with part-ofspeech labels instead of chunking labels.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We kindly thank Fabrizio Sebastiani and Andrea Esuli for their help and valuable comments, and Dittaya Wanvarie for providing us her implementation of partially-labeled CRFs.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Representations of quasi-Newton matrices and their use in limited memory methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathemathical Programming</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="129" to="156" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>Schnabel</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reducing labeling effort for structured prediction tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth National Conference on Artificial Intelligence and the Seventeenth Innovative Applications of Artificial Intelligence Conference, (AAAI 2005)</title>
		<meeting>the Twentieth National Conference on Artificial Intelligence and the Seventeenth Innovative Applications of Artificial Intelligence Conference, (AAAI 2005)<address><addrLine>Pittsburgh, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Evaluating information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010)</title>
		<meeting>the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010)<address><addrLine>Padova, IT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="100" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sentence-based active learning strategies for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Italian Information Retrieval Workshop (IIR 2010)</title>
		<meeting>the First Italian Information Retrieval Workshop (IIR 2010)<address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="41" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Introduction to the bio-entity recognition task at JNLPBA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications</title>
		<meeting>the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications<address><addrLine>Geneva, CH</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="70" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Machine Learning</title>
		<meeting>the 18th International Conference on Machine Learning<address><addrLine>Williamstown, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Heterogeneous uncertainty sampling for supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Catlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 11th International Conference on Machine Learning (ICML 1994)</title>
		<meeting>11th International Conference on Machine Learning (ICML 1994)<address><addrLine>New Brunswick, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A maximum entropy model for part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adwait</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Information extraction. Foundations and Trends in Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="261" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Active hidden Markov models for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Scheffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Decomain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Wrobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Advances in Intelligent Data Analysis</title>
		<meeting>the 4th International Conference on Advances in Intelligent Data Analysis<address><addrLine>Cascais, PT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An analysis of active learning strategies for sequence labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing<address><addrLine>Honolulu, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1070" to="1079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Synthesis Lectures on Artificial Intelligence and Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
	<note>Active learning</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-criteria-based active learning for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew-Lim</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL 2004)</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL 2004)<address><addrLine>Barcelona, ES</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="589" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2000 shared task: Chunking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Buchholz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Learning Language in Logic and 4th Conference on Computational Natural Language Learning (LLL/CoNLL</title>
		<meeting>the 2nd Workshop on Learning Language in Logic and 4th Conference on Computational Natural Language Learning (LLL/CoNLL<address><addrLine>Lisbon, PT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="127" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien De</forename><surname>Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Conference on Natural Language Learning (CONLL 2003)</title>
		<meeting>the 7th Conference on Natural Language Learning (CONLL 2003)<address><addrLine>Edmonton, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semisupervised active learning for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Tomanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udo</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP 2009)</title>
		<meeting>the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP 2009)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1039" to="1047" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On proper unit selection in active learning: co-selection effects for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Tomanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Laws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udo</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing</title>
		<meeting>the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing<address><addrLine>Boulder, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="9" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Training conditional random fields using incomplete annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Tsuboi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisashi</forename><surname>Kashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008)</title>
		<meeting>the 22nd International Conference on Computational Linguistics (COLING 2008)<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="897" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Active learning with subsequence sampling strategy for sequence labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dittaya</forename><surname>Wanvarie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroya</forename><surname>Takamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Okumura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Media Technologies</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="680" to="700" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
