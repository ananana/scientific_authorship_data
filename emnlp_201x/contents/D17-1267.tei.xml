<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Identifying Cognate Sets Across Dictionaries of Related Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">St</forename><surname>Arnaud</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept of Computing Science</orgName>
								<orgName type="department" key="dep2">Dept of Linguistics</orgName>
								<orgName type="department" key="dep3">Dept of Computing Science</orgName>
								<orgName type="institution" key="instit1">University of Alberta</orgName>
								<orgName type="institution" key="instit2">University of Alberta</orgName>
								<orgName type="institution" key="instit3">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Beck</surname></persName>
							<email>dbeck@ualberta.ca</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept of Computing Science</orgName>
								<orgName type="department" key="dep2">Dept of Linguistics</orgName>
								<orgName type="department" key="dep3">Dept of Computing Science</orgName>
								<orgName type="institution" key="instit1">University of Alberta</orgName>
								<orgName type="institution" key="instit2">University of Alberta</orgName>
								<orgName type="institution" key="instit3">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
							<email>gkondrak@ualberta.ca</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept of Computing Science</orgName>
								<orgName type="department" key="dep2">Dept of Linguistics</orgName>
								<orgName type="department" key="dep3">Dept of Computing Science</orgName>
								<orgName type="institution" key="instit1">University of Alberta</orgName>
								<orgName type="institution" key="instit2">University of Alberta</orgName>
								<orgName type="institution" key="instit3">University of Alberta</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Identifying Cognate Sets Across Dictionaries of Related Languages</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2519" to="2528"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a system for identifying cog-nate sets across dictionaries of related languages. The likelihood of a cognate relationship is calculated on the basis of a rich set of features that capture both pho-netic and semantic similarity, as well as the presence of regular sound correspondences. The similarity scores are used to cluster words from different languages that may originate from a common proto-word. When tested on the Algonquian language family, our system detects 63% of cognate sets while maintaining cluster purity of 70%.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cognates are words in related languages that have originated from the same word in an ancestor lan- guage; for example English earth and German Erde. On average, cognates display higher pho- netic and semantic similarity than random word pairs between languages that are indisputably re- lated <ref type="bibr" target="#b17">(Kondrak, 2013)</ref>. The term cognate is some- times used within computational linguistics to de- note orthographically similar words that have the same meaning ( <ref type="bibr" target="#b24">Nakov and Tiedemann, 2012)</ref>. In this work, however, we adhere to the strict linguis- tic definition of cognates and aim to distinguish them from lexical borrowings by detecting regular sound correspondences.</p><p>Cognate information between languages is crit- ical to the field of historical and comparative lin- guistics, where it plays a central role in determin- ing the relations and structures of language fami- lies <ref type="bibr" target="#b29">(Trask, 1996)</ref>. Automated phylogenetic recon- structions often rely on cognate information as in- put <ref type="bibr" target="#b3">(Bouchard-Côté et al., 2013)</ref>. The percentage of shared cognates can also be used to estimate the time of pre-historic language splits <ref type="bibr" target="#b7">(Dyen et al., 1992</ref>). While cognates are valuable to linguists, their identification is a time-consuming process, even for experts, who have to sift through hun- dreds or even thousands of words in related lan- guages. The languages that are the least well stud- ied, and therefore the ones in which historical lin- guists are most interested, often lack cognate in- formation.</p><p>A number of computational methods have been proposed to automate the process of cognate iden- tification. Many of the systems focus on iden- tifying cognates within classes of semantically equivalent words, such as Swadesh lists of basic concepts. Those systems, which typically con- sider only the phonetic or orthographic forms of words, can be further divided into the ones that operate on language pairs (pairwise) vs. multilin- gual approaches. However, because of seman- tic drift, many cognates are no longer exact syn- onyms, which severely limits the effectiveness of such systems. For example, a cognate pair like En- glish bite and French fendre "to split" cannot be detected because these words are listed under dif- ferent basic meanings in the Comparative Indoeu- ropean <ref type="bibr">Database (Dyen et al., 1992)</ref>. In addition, the number of basic concepts is typically small.</p><p>In this paper, we address the challenging task of identifying cognate sets across multiple languages directly from dictionary lists representing related languages, by taking into account both the forms of words and their dictionary definitions (c.f. <ref type="figure" target="#fig_0">Fig- ure 1</ref>). Our methods are designed for less-studied languages -we assume only the existence of ba- sic dictionaries containing a substantial number of word forms in a semi-phonetic notation, with the meaning of words conveyed using one of the major languages. Such dictionaries are typically created before Bible translations, which have been accom- plished for most of the world's languages.</p><p>While our approach is unsupervised, assuming no cognate sets from the analyzed language fam-  ily to start with, it incorporates supervised ma- chine learning models that either leverage cognate data from unrelated families, or use self-training on subsets of likely cognate pairs. We derive two types of models to classify pairs of words across languages as either cognate or not. The language-independent general model employs a number of features defined on both word forms and definitions, including word vector representa- tions. The additional specific models exploit regu- lar sound correspondences between specific pairs of languages. The scores from the general and specific models inform a clustering algorithm that constructs the proposed cognate sets. We evaluate our system on dictionary lists that represent four indigenous North American lan- guages from the Algonquian family. On the task of pairwise classification, we achieve a 42% error reduction with respect to the state of the art. On the task of multilingual clustering, our system de- tects 63% of gold sets, while maintaining a cluster purity score of 70%. The system code is publicly available. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Most previous work in automatic cognate identi- fication only consider words as cognates if they have identical definitions. As such, they make lim- ited or no use of semantic information. The sim- plest variant of this task is to make pairwise cog- nate classifications based on orthographic or pho- 1 https://github.com/ajstarna/SemaPhoR netic forms. <ref type="bibr" target="#b30">Turchin et al. (2010)</ref> apply a heuris- tic based on consonant classes to identify the ratio of cognate pairs to non-cognate pairs between lan- guages in an effort to determine the likelihood that they are related. <ref type="bibr" target="#b6">Ciobanu and Dinu (2013)</ref> find cognate pairs by referring to dictionaries contain- ing etymological information. Rama (2015) ex- periments with features motivated by string ker- nels for pairwise cognate classification.</p><p>A more challenging version of the task is to cluster cognates within lists of words that have identical definitions. <ref type="bibr" target="#b12">Hauer and Kondrak (2011)</ref> use confidence scores from a binary classifier that incorporates a variety of string similarity features to guide an average score clustering algorithm. <ref type="bibr">Klein (2010, 2011</ref>) define generative models that model the evolution of words along a phylogeny according to automatically learned sound laws in the form of parametric edit dis- tances. <ref type="bibr" target="#b21">List and Moran (2013)</ref> propose an ap- proach based on sound class alignments and an av- erage score clustering algorithm. <ref type="bibr" target="#b20">List et al. (2016)</ref> extend the approach to include partial cognates within word lists.</p><p>Cognate identification that considers semantic information is a less-studied problem. Again, the task can be framed as either a pairwise classifi- cation or multi-lingual clustering. In a pairwise context, Kondrak (2004) describes a system for identifying cognates between language dictionar- ies which is based on phonetic similarity, com- plex multi-phoneme correspondences, and seman-tic information. The method of <ref type="bibr" target="#b32">Wang and Sitbon (2014)</ref> employs word sense disambiguation com- bined with classic string similarity measures for finding cognate pairs in parallel texts to aid lan- guage learners.</p><p>Finally, very little has been published on creat- ing cognate sets based on both phonetic and se- mantic information, which is the task that we fo- cus on in this paper.  com- bine phonetic and sound correspondence scores with a simple semantic heuristic, and create cog- nate sets by using graph-based algorithms on con- nected components. <ref type="bibr" target="#b28">Steiner et al. (2011)</ref> aim at a fully automated approach to the comparative method, including cognate set identification and language phylogeny construction. Neither of those systems and datasets are publicly available for the purpose of direct comparison to our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>In this section, we describe the design of our language-independent general model, as well as the language-specific models. Given a pair of words from related languages, the models produce a score that reflects the likelihood of the words being cognate. The models are implemented as Support Vector Machine (SVM) classifiers via the software package SVM-Light (Joachims, 1999). The scores from both types of models are used to cluster words from different languages into cog- nate sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Features of the General Model</head><p>The general model is a supervised classifier that makes cognate judgments on pairs of words ac- companied by their semantic definitions. The model is intended to be language-independent, so that it can be trained on cognate annotations from well-studied languages, and applied to completely unrelated families. The features of the general model are of two kinds: phonetic, which pertain to the analyzed word forms, and semantic, which refer to their definitions.</p><p>The phonetic features are defined on the word forms, represented in ASJP format ( <ref type="bibr" target="#b4">Brown et al., 2008)</ref>, which is a simplified phonetic representa- tion.</p><p>• Normalized edit distance is calculated at the character level, and normalized by the length of the longer word.</p><p>• LCSR is the longest common subsequence ra- tio of the words.</p><p>• Alignment score reflects an overall phonetic similarity, provided by the ALINE phonetic aligner <ref type="bibr" target="#b16">(Kondrak, 2009</ref>).</p><p>• Consonant match returns the number of aligned consonants normalized by the num- ber of consonants in the longer word.</p><p>For example, consider the words meškwe:kenwi and maehki:kan (meSkwekenwi and mEhkikan in ASJP notation) from cognate set 1725 in <ref type="figure" target="#fig_0">Figure 1</ref>. The corresponding values for the above four fea- tures are 0.364, 0.364, 0.523, and 0.714, respec- tively.</p><p>The semantic features refer to the dictionary definitions of words. We assume that the defini- tions are provided in a single meta-language, such as English or Spanish. We consider not only a def- inition in its entirety, but also its sub-definitions, which are separated by commas and semicolons. We distinguish between a closed class of about 300 stop words, which express grammatical re- lationships, and an open class of content words, which carry a meaning. Filtering out stopwords re- duces the likelihood of spurious matches between dictionary definitions.</p><p>Our semantic features can be divided into those that focus on surface definition resemblance, and those that attempt to detect the affinity of meaning. The features of the first type are the following:</p><p>• Sub-definition match denotes an exact match between any of the word sub-definitions (c.f. set 42 of <ref type="figure" target="#fig_0">Figure 1</ref>).</p><p>• Sub-definition content match is performed af- ter removing stop words from definitions.</p><p>• Normalized word-level edit distance calcu- lates the minimum distance between sub- definitions at the level of words, normalized by the length of the longer sub-definition.</p><p>• Content overlap fires if any sub-definitions have at least one content word in common.</p><p>The second type of semantic features are aimed at detecting deeper meaning connections between definitions. We use WordNet <ref type="bibr" target="#b8">(Fellbaum, 1998)</ref> to identify the relations of synonymy and hyper- nymy, and to associate different inflectional forms of words. The WordNet-based features are as fol- lows:</p><p>• Synonym overlap indicates a WordNet syn- onymy relation between content words across sub-definitions (e.g. "ease" and "repose").</p><p>• Hypernym overlap indicates a WordNet hy- pernymy relation between content words across sub-definitions (e.g. "flannel" and "cloth").</p><p>• Inflection overlap is a feature that associates inflectional variants of content words (e.g. "scrape" and "scraping").</p><p>• Inflection synonym overlap indicates a syn- onymy relation between lemmas of content words (e.g. "scratches" and "scraping").</p><p>• Inflection hypernym overlap is defined analo- gously to the inflection synonym overlap fea- ture.</p><p>In order to detect subtle definition similarity that goes beyond inflectional variants and simple se- mantic relations, we add two features designed to take advantage of recent advances in word vec- tor representations. The two vector-based features are:</p><p>• Vector cosine similarity is the cosine sim- ilarity between the two vectors that repre- sent the average of each vector within a sub- definition.</p><p>• Content vector cosine similarity is analogous, but only includes content words.</p><p>As an example, consider the definitions "he is in mourning" and "she is widowed," from <ref type="table">Table 5</ref>, which do not fire any of the WordNet-based fea- tures. Using the entire definitions yields a vec- tor cosine similarity of 0.566, while considering only the content words "mourning" and "wid- owed" produces a feature value of 0.146.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Regular Correspondences</head><p>The features described in the previous section are language-independent, but we would also like to take into account cognate information that is specific to pairs of languages, namely regular sound correspondences. For example, th/d is a sound correspondence between English and Ger- man, occurring in words such as think/denken and leather/Leder. A model trained on another lan- guage family would not be able to learn that a cor- responding th and d is an important indicator of cognation in English/German pairs. For each language pair, we derive a specific model by implementing the approach of <ref type="bibr" target="#b1">Bergsma and Kondrak (2007)</ref>. As features, we extract pairs of substrings, up to length 3, that are consistent with the alignment induced by the minimum edit distance algorithm. The models are able to learn when a certain substring in one language corre- sponds to a certain substring in another language.</p><p>In order to train the specific models, we need a substantial number of cognate pairs, which are not initially available in our unsupervised setting. We use a heuristic method to overcome this lim- itation. We create sets of words that satisfy the following two constraints: (1) identical dictionary definition, and (2) identical first letter. For ex- ample, this heuristic will correctly cluster the two words defined as "red cloth" in <ref type="figure" target="#fig_0">Figure 1</ref>, but will miss the two other cognates from Set 1725. We ensure that every set contains words from at least two languages. The resulting word sets are mu- tually exclusive, and contain mostly cognates. (In fact, we use this method as our baseline in the Ex- periments section.) We extract positive training examples from these high-precision sets, and cre- ate negative examples by sampling random entries from the language dictionaries. A separate specific model is learned for each language pair in order to capture regular sound correspondences. Note that the specific models include no semantic features. We combine the specific models with the general model by simply averaging their respective scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cognate Clustering</head><p>We apply our general and specific models to score pairs of words across languages. Featurizing all possible pairs of words from all languages is very time consuming, so we first filter out dissimilar word pairs that obtain a normalized score below 0.35 from ALINE. In development experiments, we observed that over 95% of cognate pairs ex- ceed this threshold.</p><p>Once pairwise scores have been computed, we cluster words into putative cognate sets using a variant of the UPGMA clustering algorithm <ref type="bibr" target="#b27">(Sokal and Michener, 1958)</ref>, which has been used in pre- vious work on cognate clustering <ref type="bibr" target="#b12">(Hauer and Kondrak, 2011;</ref><ref type="bibr" target="#b20">List et al., 2016</ref>). Initially, all words are placed into their own cluster. The score be- tween clusters is computed as the average of all pairwise scores between the words within those clusters. In each iteration, the two clusters with the highest average score are merged. For effi- ciency reasons, only positive scores are included in the pairwise similarity matrix, which implies that merges are only performed if all pairwise scores between two clusters are positive. The al- gorithm terminates when no pair of clusters have a positive average score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we discuss two evaluation exper- iments. After describing the datasets, we com- pare our cognate classifier to the current state of the art in pairwise classification. We then consider the evaluation metrics for our main task of cog- nate set recovery from raw language dictionaries, which is followed by the results on the Algonquian dataset. We refer to our system as SemaPhoR, to reflect the fact that it exploits three kinds of ev- idence: Semantic, Phonetic, and Regular Sound Correspondences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Sets</head><p>Our experiments involve three different language families: Algonquian, Polynesian, and Totonacan.</p><p>The Algonquian dataset consists of four dic- tionary lists (c.f. <ref type="figure" target="#fig_0">Figure 1</ref>) compiled by Hewson (1993) and normalized by <ref type="bibr" target="#b15">Kondrak (2004)</ref>. We convert the phonetic forms into a Unicode en- coding. The gold-standard annotation consists of 3661 cognate sets, which were established by Hewson on the basis of the regular correspon- dences identified by <ref type="bibr" target="#b2">Bloomfield (1946)</ref>. The dataset contains as many as 22,747 unique defini- tions, which highlights the difference between our task and previous work in cognate identification within word lists, where cognate relationships are restricted to a limited set of basic concepts.</p><p>The second dataset corresponds to a version of POLLEX, a large-scale comparative dictionary of over 60 Polynesian languages ( <ref type="bibr" target="#b9">Greenhill and Clark, 2011</ref>). <ref type="table">Table 1</ref> shows that nearly 99% of words in the POLLEX dataset belong to a cognate set, meaning that it is composed almost entirely of cognate sets rather than language dictionaries. This makes the POLLEX dataset unsuitable for system evaluation; however, we use it to train our general classifier, by randomly selecting 25,000 cognate and 250,000 non-cognate word pairs. For calculating our word vector based features, we use the Python package gensim ( ˇ Rehůřek and Sojka, 2010) applied to word vectors pre-trained on ap- Lang. <ref type="table" target="#tab_2">Entries  Sets  Cognates  Algonquian  4  26,985 3,661  8,675  Polynesian  62  27,049 3,690  26,699  Totonacan  10</ref> 43,073 ? ? <ref type="table">Table 1</ref>: The number of languages, total dictionary entries, cognate sets, and cognate words for each language family.</p><p>proximately 100 billion English words using the approach of <ref type="bibr" target="#b23">Mikolov et al. (2013)</ref>. <ref type="bibr">2</ref> The posi- tive training instances are constrained to involve languages that belong to different Polynesian sub- families.</p><p>The final dataset consists of 10 dictionaries of the Totonacan language family spoken in Mexico. Since the definitions of the Totonacan dictionar- ies are in Spanish, we use the Spanish WordNet, a list of 200 stop words, and approximately 1 bil- lion pre-trained Spanish word vectors <ref type="bibr" target="#b5">(Cardellino, 2016</ref>) for this dataset. <ref type="bibr">3</ref> The Totonacan data is yet to be fully analyzed by historical linguists, and as such provides an important motivation for devel- oping our system.</p><p>Although the Totonacan dataset includes no cognate information, we manually evaluated a number of candidate cognate sets generated by our system in the development stage. From these annotations, we created a pairwise development set, including all possible 6755 cognate pairs and 67,550 randomly selected non-cognate pairs, and used it for testing our general model that was trained on the Polynesian dataset. The resulting pairwise F-Score of 88.0% shows that our cognate classification model need not be trained on the same language family that it is applied to. More- over, it confirms that our system can function on datasets where definitions are written in a meta- language that is different from the one used in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Pairwise Classification Results</head><p>Although our main objective is multilingual clus- tering, the goal of the first experiment is to com- pare the effectiveness of our pairwise classifiers against the system of <ref type="bibr" target="#b15">Kondrak (2004)</ref>, which was designed to process one language pair at a time. As much as possible, we try to follow the original evaluation methodology, which reports 11-point interpolated precision ( <ref type="bibr" target="#b22">Manning et al., 2008</ref>  158) on lists of positively classified word pairs that have been sorted according to their confidence scores. We also use the same dataset, which is limited to the nouns in the Algonquian data. As the original system contained no machine-learning component, it required no training data, but the Cree-Ojibwa language pair served as the develop- ment and tuning set.</p><p>We evaluate two variants of our general model: one trained on the Cree-Ojibwa (CO) noun sub- set, and another on the POLLEX dataset. The language-specific models are trained on each re- spective language pair, using the unsupervised heuristic approach described in Section 3.2. <ref type="table" target="#tab_2">Table 2</ref> shows the results on each language pair. K-2004 denotes the results reported in <ref type="bibr" target="#b15">Kondrak (2004)</ref>. The increase in the average 11-point pre- cision on the five test sets (except Cree-Ojibwa) from 66.1% to 80.3% represents an error reduc- tion of 42%. This improvement demonstrates the superiority of a machine learning approach with a rich feature set over a categorical approach with manually-tuned parameters. When our classifier is trained instead on cognate data from an unre- lated Polynesian language family, the average 11- point precision on the test sets drops only slightly to 80.0%, which confirms its generality.</p><p>The correspondence-based specific models con- tribute towards the high accuracy of our system. Without them, the average results on the test sets decrease by 0.9% to 79.4% for the CO-trained model, and by 3.0% to 77.0% for the POLLEX- trained model. We conjecture that the language- specific models are less helpful in the former case because the general model already incorporates much of the information that is particular to the Algonquian family.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Metrics for Clustering</head><p>The choice of evaluation metrics for multilingual cognate clustering, which is our main task, re- quires careful consideration. Pairwise F-score works well for pairwise cognate classification, but in the context of clustering, the number of word pairs grows quadratically with the size of a set, which creates a bias against smaller sets. For ex- ample, a set containing 10 words may contribute as much to the pairwise recall as 45 two-word sets.</p><p>For the task of clustering words with identi- cal definitions, <ref type="bibr" target="#b12">Hauer and Kondrak (2011)</ref> pro- pose to use B-Cubed F-score ( <ref type="bibr" target="#b0">Bagga and Baldwin, 1998)</ref>. However, we found that B-Cubed F-score assigns counter-intuitive scores to clusterings in- volving datasets of dictionary size, in which many words are outside of any cognate set in the refer- ence annotation. For example, on the Algonquian dataset, a trivial strategy of placing each word into its own cluster (MaxPrecision) would achieve a B- Cubed F-Score of 89.6%.</p><p>In search for a better metric, we considered MUC ( <ref type="bibr">Vilain et al., 1995)</ref>, which is designed to score co-reference algorithms. MUC assigns pre- cision, recall and F-Score based on the number of missing links in the proposed clusters. However, as pointed out by <ref type="bibr" target="#b0">Bagga and Baldwin (1998)</ref>, when penalizing incorrectly placed elements, MUC is insensitive to the size of the cluster in question. For example, a completely useless clustering of all Algonquian words into one giant set (MaxRecall) yields a higher MUC F-Score than most of the rea- sonably effective approaches.</p><p>We believe that an appropriate measure of re- call for a cognate clustering system is the total number of found sets. A set that exists in the gold annotation is considered found if any of the words that belong to the set are clustered together by the system. We report both partially and com- pletely found sets. Arguably, the number of par- tially found sets may be more important, as it is easier for a linguist to extend a found set to other languages than to discover the set in the first place. In fact, a discovery of a single pair of cross-lingual cognates implies the existence of a correspond- ing proto-word in their ancestor language, which is likely to have reflexes in the other languages of the family.</p><p>As a corresponding measure of precision, we report cluster purity, which has previously been used to evaluate cognate clusterings by <ref type="bibr" target="#b11">Klein (2011) and</ref><ref type="bibr" target="#b3">Bouchard-Côté et al. (2013)</ref>. In order to calculate purity, each output set is first matched to a gold set with which it has the most words in common. Then purity is calculated as the fraction of total words that are matched to the correct gold set. More formally, let G = {G 1 , G 2 , ..., G n } be a gold clustering and C = {C 1 , C 2 , ..., C m } be a proposed clustering. Then</p><formula xml:id="formula_0">purity(C, G) = 1 N m i=1 max j |G j ∩ C i |</formula><p>where N is the total number of words. The trade- off between the number of found sets and clus- ter purity gives a good idea of the performance of a cognate clustering. For example, both of the MaxRecall and MaxPrecision strategies men- tioned above would obtain 100% scores according to one of the measures, but close to 0% according to the other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Cognate Clustering Results</head><p>In our main experiment, we apply our system to the task of creating cognate sets from the Algo- nquian dataset. The general classification model is trained on the POLLEX dataset, as described in Section 4.2, while the language-specific mod- els are derived following the procedure described in Section 3.2. The scores from both models are then used to guide the clustering process. Only one word from each language is allowed per clus- ter.</p><p>Since most work done in the area of cognate clustering starts from semantically aligned word lists, it is difficult to make a direct comparison. We report the results obtained with LEXSTAT (List and Moran, 2013). <ref type="bibr">4</ref> The system has no capability to consider the degree of semantic similarity be- tween words, so we first group together the words that have identical definitions and provide these as its input. As a baseline, we adopt the heuristic described in Section 3.2, which creates sets from words that have identical definitions and start with the same letter. <ref type="table">Table 3</ref> shows the results. LEXSTAT performs slightly better than the heuristic baseline, but both are limited by their inability to relate words that have non-identical definitions. In fact, only 21.4% of all gold cognate sets in the Algonquian dataset contain at least two words with the same defi- nition, which establishes an upper bound on the 4 http://lingpy.org</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>Found Sets Purity Heuristic Baseline 18.9 (9.9) 96.4 LEXSTAT 19.6 (10.5) 97.1 SemaPhoR 63.1 (48.2) 70.3 <ref type="table">Table 3</ref>: Cognate clustering results on the Algo- nquian dataset (in %). The absolute percentage of fully found sets is given in parentheses.</p><p>number of found sets for systems that are designed to operate on word lists, rather than dictionaries. For example, most of the cognates in <ref type="figure" target="#fig_0">Figure 1</ref> can- not be captured by such systems.</p><p>Our system, SemaPhoR, finds approximately three times as many cognate sets as LEXSTAT, and over 75% of those sets are complete with respect to the gold annotation. In practical terms, our sys- tem is able to provide concrete evidence for the existence of most of the proto-words that have re- flexes in the recorded languages, and identifies the majority of those reflexes in the process. The pu- rity of the produced clusters indicates that there are many more hits than misses in the system out- put. In addition, the clusters can be sorted accord- ing to their confidence scores, in order to facilitate the analysis of the results by an expert linguist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In this section, we interpret the results of our feature ablation experiments, and analyze several types of errors made by our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Feature Ablation</head><p>In order to determine the relative effect of the fea- tures described in Section 3.1, we test four vari- ants of the general model, which employ increas- ingly complex subsets of features. The simplest variant uses only the phonetic features that are de- fined on the word forms. The next variant adds the features that consider surface definition resem- blance. The third variant also includes WordNet- based semantic features. The final variant is the full system configuration that incorporates the fea- tures defined on word vector representations, but without language-specific models.  <ref type="table" target="#tab_3">Table 4</ref>: Cognate clustering results on the Algo- nquian dataset (in %) with subsets of features. the phonetic-only variant, with only a 5% drop in cluster purity.</p><p>In comparison with our full system, which in- corporates the language-specific models, the fi- nal variant finds a greater number of the cognate sets, but with a trade-off in overall precision (c.f. SemaPhoR in <ref type="table">Table 3</ref>). This shows that our sys- tem is able to exploit regular sound correspon- dences to filter out a substantial number of false cognates, such as lexical borrowings or chance re- semblances. However, the overall contribution of the specific models is relatively small. One possi- ble explanation is that the Algonquian languages are relatively closely related, which enables the general model to discern most of the cognate re- lationships on the basis of phonetic and semantic similarity. For example, many of the regular corre- spondences detected by the specific models, such as s:s and hk:kk, involve identical phonemes. The impact of the specific models could be greater for a more distantly-related language family.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Error Analysis</head><p>A number of omission errors can be traced to the imperfect heuristic that constrains the positive training instances for the language-specific mod- els to begin with the same letter. Indeed, 88.1% of Algonquian cognate sets are composed of words that share the initial phoneme. While this con- straint yields high-precision training sets that sat- isfy the transitivity condition, it also introduces a bias against cognates that differ in the first letter.</p><p>The second type of errors made by our system are caused by semantic drift that has altered the meaning of the original proto-word. For exam- ple, "sickness" is difficult for our general model to associate with "bitterness, pain." On the other hand, there are many instances where our system is successful in identifying non-obvious semantic similarity, often thanks to the word vector features of our model. <ref type="table">Table 5</ref> provides examples of cog- nates found by our system that would have been C ma:ya:ˇ cite:he:w he is angry M miana:ˇ cetaehae:w he is nauseated C pi:sisiw he is in bits O pi:ssisi he is ground up C ayiwiskawe:w he is taller than someone else O aniwiškaw precede, surpass someone C si:ka:wiw he is in mourning M se:kawew she is widowed <ref type="table">Table 5</ref>: Examples of cognates found with the as- sistance of word vector features.</p><p>very difficult to identify without word vector tech- nology. A substantial number of apparent errors made by our system are due to the complex polysyn- thetic morphology of Algonquian, in which a single Algonquian word can express a meaning of several English words. A number of dis- tinct cognate sets are highly similar in their def- initions and phonetic forms. For example, our system erroneously places the Menominee word a:kuaqtae:hsen into a cluster with two similar Cree and Ojibwa words, instead of associating it with the Ojibwa word a:kawa:tte:ˇ sšin <ref type="table">(Table 6</ref>). Al- though it could be argued that such closely-related forms are all cognate, we refrain from modifying any gold annotations, even if this negatively im- pacts the overall accuracy of our system. C a:kawa:ste:simo:w he lies down in the shade O a:kawa:tte:ˇ sšimo:n be in the shadow M a:kuaqtae:hsen he is in the shade O a:kawa:tte:ˇ sšin make shadow <ref type="table">Table 6</ref>: A clustering error due to morphology.</p><p>Finally, some apparent errors made by our sys- tem may not be errors at all, but rather reflect the incompleteness of the gold annotation. For exam- ple, consider the two false positive pairs in <ref type="table">Table  7</ref>. Even though they are not listed in <ref type="bibr" target="#b13">Hewson's (1993)</ref> etymological dictionary, the exact defini- tion match, coupled with striking phonetic simi- larity and the presence of regular sound correspon- dences strongly suggest that they are actually cog- nates.</p><p>M pekuač growing wild O pekwači growing wild C niso:te:w twin O ni:ˇ so:te:nq twin <ref type="table">Table 7</ref>: Examples of proposed cognate sets that are not found in the gold data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2526</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented a comprehensive system for the novel task of identifying cognate sets directly from dictionaries of related languages by leverag- ing both word forms and word definitions. To the best of our knowledge, it is the first system to use word vector representations for cognate identifi- cation. The main insight from our work is that a cognate classification model can be trained on one language family, and achieve impressive re- sults when classifying a completely unrelated lan- guage family. This allows cognate information from a high-resource language family to guide cognate identification between languages that lit- tle is known about.</p><p>There are aspects of cognate identification that can only be detected by human experts, such as cognates that have undergone extensive phonetic and semantic changes, or large-scale lexical bor- rowing between languages. However, we believe that our system represents a step towards auto- mated cognate identification, and will prove a use- ful tool for historical linguists.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of multilingual cognate set identification across four Algonquian dictionaries: Cree (C), Fox (F), Menominee (M) and Ojibwa (O). Cognate set numbers are shown on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Family</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>11-Point interpolated precision on the Al-
gonquian noun dataset. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 shows</head><label>4</label><figDesc>the results. The phonetic fea- tures alone are sufficient to detect just over half of the cognate sets. Each successive variant sub- stantially improves the recall at a cost of slightly lower precision. The full feature set yields a 27% relative increase in the number of found sets over</figDesc><table>Features 

Found Sets Purity 
Phonetic only 
52.0 (36.3) 70.2 
+ Definitions 
57.4 (41.7) 68.4 
+ WordNet 
61.9 (46.9) 68.1 
+ Word Vectors 66.2 (51.3) 66.5 

</table></figure>

			<note place="foot" n="2"> https://code.google.com/archive/p/word2vec 3 http://crscardellino.me/SBWCE</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the following students that contributed to our cognate-related projects over the last few years (in alphabetical order): Matthew Darling, Jacob Denson, Philip Dilts, Bradley Hauer, Mil-dred Lau, Tyler Lazar, Garrett Nicolai, Dylan Stankievech, Nicholas Tam, and Cindy Xiao. This research was partially funded by the Natu-ral Sciences and Engineering Research Council of Canada.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Algorithms for scoring coreference chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Breck</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First International Conference on Language Resources and Evaluation Workshop on Linguistics Coreference</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Alignment-based discriminative string similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Algonquian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Bloomfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linguistic Structures of Native America</title>
		<editor>Harry Hoijer et al.</editor>
		<imprint>
			<publisher>Viking Fund Publications in Anthropology</publisher>
			<date type="published" when="1946" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Automated reconstruction of ancient languages using probabilistic models of sound change</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Bouchard-Côté</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>PNAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automated classification of the world&apos;s languages: A description of the method and preliminary results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cecil</forename><forename type="middle">H</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">W</forename><surname>Holman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soren</forename><surname>Wichmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Typology and Universals</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">61</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Spanish billion words corpus and embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Cardellino</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A dictionary-based approach for evaluating orthographic methods in cognates identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aline</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Ciobanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liviu</forename><forename type="middle">P</forename><surname>Dinu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Recent Advances in Natural Language Processing</title>
		<meeting>Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>RANLP</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An Indoeuropean classification: A lexicostatistical experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isidore</forename><surname>Dyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Joseph B Kruskal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the American Philosophical society</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">82</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">WordNet: An Eletronic Lexical Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pollexonline: The Polynesian lexicon project online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Greenhill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Oceanic Linguistics</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">50</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Finding cognate groups using phylogenies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Large-scale cognate recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Clustering semantically equivalent words into cognate sets in multilinguial lists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradely</forename><surname>Hauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Joint Conference on Natural Language Processing</title>
		<meeting>the 5th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>IJCNLP</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A computer-generated dictionary of proto-Algonquian. Canadian Museum of Civilization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hewson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<pubPlace>Hull, Quebec</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Making large-scale SVM learning practical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Kernel Methods-Support Vector Learning</title>
		<editor>B. Schölkopf, C. Burges, and A. Smola</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Combining evidence in cognate identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Canadian Conference on Artificial Intelligence</title>
		<meeting>the Seventeenth Canadian Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Identification of cognates and recurrent sound correspondences in word lists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Traitement automatique des langues et langues anciennes</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="201" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Word similarity, cognation, and translational equivalence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Approaches to Measuring Linguistic Differences</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="375" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Gruyter Mouton</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Creating a comparative dictionary of TotonacTepehua</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Dilts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Computing and Historical Phonology (9th Meeting of SIGMORPHON)</title>
		<meeting>the ACL Workshop on Computing and Historical Phonology (9th Meeting of SIGMORPHON)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="134" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using sequence similarity networks to identify partial cognates in multilingual wordlists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bapteste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An open source toolkit for quantitative historical linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Moran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2013 System Demonstrations</title>
		<meeting>the ACL 2013 System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Introduction to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabhakar</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Combining word-level and character-level models for machine translation between closely-related languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automatic cognate identification with gap-weighted string subsequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taraka</forename><surname>Rama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Software framework for topic modelling with large corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Radimřehůřekradimˇradimřehůřek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sojka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC Workshop on New Challenges for NLP Frameworks</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A statistical method for evaluating systematic relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">D</forename><surname>Sokal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In University of Kansas Science Bulletin</title>
		<imprint>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A pipeline for computational historical linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lydia</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cysouw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Dynamics and Change</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Historical Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Trask</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>St Martin&apos;s Press, Inc</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Analyzing genetic connections between languages by matching consonant classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Turchin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilia</forename><surname>Peiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Gell-Mann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Journal of Language Relationship</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dennis Connolly, and Lynette Hirschman. 1995. A modeltheoretic coreference scoring scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Vilain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Aberdeen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Message Understanding</title>
		<meeting>the 6th Conference on Message Understanding</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multilingual lexical resources to detect cognates in nonaligned texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurianne</forename><surname>Sitbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Twelfth Annual Workshop of the Australasia Language Technology Association</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
