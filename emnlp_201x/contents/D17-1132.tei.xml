<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting Word Association Strengths</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cattle</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering Clear Water Bay</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering Clear Water Bay</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Kong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering Clear Water Bay</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting Word Association Strengths</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1283" to="1288"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper looks at the task of predicting word association strengths across three datasets; WordNet Evocation (Boyd-Graber et al., 2006), University of Southern Florida Free Association norms (Nel-son et al., 2004), and Edinburgh Associa-tive Thesaurus (Kiss et al., 1973). We achieve results of r = 0.357 and ρ = 0.379, r = 0.344 and ρ = 0.300, an ρ = 0.292 and ρ = 0.363, respectively. We find Word2Vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) cosine similarities, as well as vector offsets, to be the highest performing features. Furthermore , we examine the usefulness of Gaussian embeddings (Vilnis and McCal-lum, 2014) for predicting word association strength, the first work to do so.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Word embeddings such as <ref type="bibr">Word2Vec (Mikolov et al., 2013</ref>) or GloVe ( <ref type="bibr">Pennington et al., 2014</ref>) have received increasing attention in the world of natural language processing and computational linguistics. Under such embeddings, the seman- tic relatedness of two words is generally taken to be the cosine similarity of their word vectors. Al- though this approach performs well for variety of applications, it is not without its limitations. First, it defines "relatedness" quite narrowly as the ex- tent to which the two words appear in similar con- texts. Second, it fails to capture how humans in- ternally represent words <ref type="bibr" target="#b6">(De Deyne et al., 2016b)</ref>.</p><p>Word associations offer a more flexible view of semantic relatedness by leveraging "lexical knowledge acquired through world experience" ( <ref type="bibr">Nelson et al., 2004</ref>). While word embeddings capture distributional relationships, word associ- ations are able to capture more nuanced relation- ships "which are based on human perception and experiences <ref type="bibr">[and]</ref> are not reflected in common lan- guage usage." <ref type="bibr">(Ma, 2013</ref>) For example, "yellow" is so closely associated with "banana" that many people would only specify a banana's colour if it is not yellow. This is backed up by De Deyne et al. (2016b) which found word associations performed better than word embeddings across a variety of semantic relatedness tasks.</p><p>Furthermore, word associations, unlike cosine similarities, are asymmetric; when presented with the word "beer", many people think of the word "glass" but when presented with the word "glass", few people think of the word "beer" <ref type="bibr">(Ma, 2013)</ref>. This directionality allows for more fine-grained exploration of semantic links, with applications in word similarity <ref type="bibr" target="#b9">(Jabeen et al., 2013</ref>) and computa- tional humour <ref type="bibr" target="#b3">(Cattle and Ma, 2016)</ref>.</p><p>Although several word association datasets ex- ist, such as the Edinburgh Associative Thesaurus (EAT, <ref type="bibr">Kiss et al., 1973)</ref>, the University of South Florida Free Association Norms (USF, <ref type="bibr">Nelson et al., 2004</ref>), or WordNet Evocation <ref type="bibr">(Evocation, Boyd-Graber et al., 2006</ref>), their reliance on human annotations mean they all suffer from coverage is- sues relating to limited vocabularies or sparse con- nectivity <ref type="bibr" target="#b3">(Cattle and Ma, 2016;</ref><ref type="bibr" target="#b6">De Deyne et al., 2016b)</ref>. Although these issues would be some- what alleviated by the creation of larger datasets, collecting human judgments for all possible word pairs is impractical. Therefore, the ability to pre- dict association strengths between arbitrary word pairs represents the best solution to these coverage issues <ref type="bibr" target="#b2">(Boyd-Graber et al., 2006</ref>).</p><p>Although the prediction of Evocation ratings has attracted some attention <ref type="bibr" target="#b2">(Boyd-Graber et al., 2006;</ref><ref type="bibr" target="#b8">Hayashi, 2016)</ref>, to the best of our knowl- edge this is the first work to focus on the prediction of USF or EAT strengths. As described in Sec-tion 2, USF and EAT have several advantages over Evocation, such as the ability to work with am- biguous words instead of WordNet synsets. <ref type="bibr">Following Hayashi (2016)</ref>'s work on Evocation pre- diction, we frame word association prediction as a supervised regression task and introduce several new and modified features, including the first use of Gaussian embeddings <ref type="bibr">(Vilnis and McCallum, 2014</ref>) to better capture the asymmetric nature of word associations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Work</head><p>Word association has been used in psychologi- cal and psycholinguistic experiments for well over 100 years <ref type="bibr" target="#b2">(Boyd-Graber et al., 2006;</ref><ref type="bibr" target="#b7">De Deyne and Storms, 2008)</ref>. Word association datasets such as USF or EAT have typically framed word asso- ciation as "a task that requires participants to pro- duce the first word to come to mind that is related in a specified way to a presented cue" ( <ref type="bibr">Nelson et al., 2000</ref>). These datasets use forward strengths, the proportion of participants who produce a spe- cific response, to "index the relative accessibility of related words in memory [for a given cue]" <ref type="bibr">(Nelson et al., 2004</ref>).</p><p>This cue/response framework has several draw- backs. First, since forward strengths are relative, comparing strengths across different cue words is difficult. Second, both cues and responses are ambiguous, with each participant's responses be- ing greatly influenced by how they chose to inter- pret a given cue. For example, someone respond- ing to the cue "brother" with "monk" is consid- ering a different sense of "brother" than someone who responds "sister" <ref type="bibr">(Ma, 2013)</ref>. As such, for- ward strengths are biased toward responses which presume more readily apparent cue word senses. Third, limiting participants to a single response can lead to weaker associations being underre- ported or omitted entirely.</p><p>Evocation solves the ambiguity issue by fo- cusing on associations between WordNet synsets. Boyd- <ref type="bibr" target="#b2">Graber et al. (2006)</ref> presented participants with randomly selected synset pairs and asked them to score how much the first synset evoked (i.e. brought to mind) the second. Unlike forward strengths, these Evocation ratings are absolute, meaning they can be directly compared across dif- ferent cues. While randomly selecting synset pairs ensured that weaker associations would not be un- derreported, it did have the disadvantage that 67% of pairs were unanimously rated as having no con- nection <ref type="bibr" target="#b2">(Boyd-Graber et al., 2006</ref>).</p><p>Despite attempts to address this spareness issue by expanding Evocation with data gathered from Amazon Mechanical Turk 1 ( <ref type="bibr">Nikolova et al., 2009)</ref> or word-sense disambiguated USF cue/response pairs <ref type="bibr">(Ma, 2013)</ref>, obtaining human judgments for all possible synset pairs is impractical. As such, the prediction of Evocation ratings presents the most promising solution to this coverage is- sue. Boyd-Graber et al. <ref type="formula">(2006)</ref> detailed a sim- ple Evocation estimator which used a combina- tion of WordNet structure-based features, Word- Net definition-based features, and corpus-based word co-occurrence features. However, this ap- proach is somewhat limited in that it frames Evo- cation prediction as a classification task, consider- ing only five Evocation levels.</p><p>The main drawback of Evocation prediction as a classification task is that it is too coarse-grained to deal with very weak associations, such as those in remote triads <ref type="bibr" target="#b4">(De Deyne et al., 2016a</ref>), or very slight variations in association strength, such as those useful for computational humour <ref type="bibr" target="#b3">(Cattle and Ma, 2016)</ref>. To this end, Hayashi (2016) framed Evocation prediction as a supervised regression task. They employed a combination of WordNet structure-based features, word embedding-based features, and lexical features and found that vector offsets, i.e. the mathematical difference between vectors, were a strong indicator of Evocation rat- ings.</p><p>While Evocation's use of unambiguous synsets is useful for many applications, it is not without its own drawbacks. First, it requires texts to be word sense disambiguated; a non-trivial task. Second, since humans do not conceptualize words as a dis- crete set of independent word senses, Evocation is unable to capture natural associations owing to ho- mography, homophony, or polysemy <ref type="bibr">(Ma, 2013)</ref>. As such, despite their drawbacks, word associa- tions may provide a more flexible, more holistic view of mental semantics.</p><p>By allowing participants to record more than one response, De Deyne and Storms <ref type="bibr">(2008)</ref>, and their derivative works De <ref type="bibr" target="#b5">Deyne et al. (2013) and</ref><ref type="bibr" target="#b6">De Deyne et al. (2016b)</ref>, were able to better rep- resent weaker associations. However, this intro- duced its own set of problems as great care had to be taken to avoid chaining, i.e. responding to a previous response instead of the cue, and retrieval inhibition. De Deyne and Storms (2008) frames word association collection as a continuous task, meaning not only that the vocabulary is ever grow- ing but also that changes in associations over time can be observed and tracked. But despite the steps taken to improve the size and quality of their asso- ciation dataset, practicality dictates that coverage issues cannot be completely eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Definition</head><p>Our word association prediction system extends the method in Hayashi (2016) with several mod- ifications to make it better suited to the USF and EAT datasets.</p><p>First, we modify Hayashi (2016)'s lexVector. Hayashi (2016) represent each word's part-of- speech (POS) using a one-hot encoded five dimen- sional vector (one of each POS in WordNet). Sim- ilarly, they represent each word's lexical category using a one-hot encoded 45 dimensional vector (one for each WordNet lexicographer file). This results in a 100 dimensional vector representing the POS and lexical categories of both the cue and the response. Since words in USF and EAT can be associated with multiple synsets and we want to be able to capture associations related to polysemy, instead using a one-hot encoding we employ count vectors specifying the number of synsets from each POS/lexical category each word belongs to.</p><p>Second, instead of computing Wu-Palmer sim- ilarity (WUP, <ref type="bibr">Wu and Palmer, 1994)</ref> between a single synset pair, we compute it for all cue synset/response synset pairs and record the maxi- mum and average values. Following <ref type="bibr" target="#b2">Boyd-Graber et al. (2006)</ref> and <ref type="bibr">Ma (2013)</ref>, we also explored the use of path and Leacock-Chodorow ( <ref type="bibr">Leacock and Chodorow, 1998</ref>) similarities but found they did not add any advantage over WUP alone. We take a similar approach for adapting load and between- ness centralities <ref type="bibr" target="#b0">(Barthelemy, 2004</ref>) as well as Au- toExtend <ref type="bibr">(AutoEx, Rothe and Schütze, 2015</ref>) sim- ilarity.</p><p>Third, we extend the notion of dirRel, intro- duced in <ref type="bibr" target="#b8">Hayashi (2016)</ref> to leverage the seman- tic network structure of WordNet. Given a graph where nodes represent synsets and arcs represent WordNet relations such as hypernym/hyponym and holonym/meronym, dirRel(s,t,k) is the propor- tion of k-step neighbours of s that are also k-step neighbours of t. In the original formula, s and t are nodes representing a single synset. We in- stead consider a set of nodes S and a set of nodes T representing the set of synsets associated with the cue and response words, respectively, as shown in Equation 1. This may increase the probability that |nb(S, k)∩nb(T, k)| &gt; 0, a shortcoming of the original dirRel due to WordNet's "relatively sparse connective structure" <ref type="bibr" target="#b8">(Hayashi, 2016)</ref>.</p><formula xml:id="formula_0">dirRel(S, T, k) = |nb(S, k) ∩ nb(T, k)| |nb(S, k)|<label>(1)</label></formula><p>Fourth, in addition to the Word2Vec (w2v) co- sine similarity between cue/response pairs calcu- lated using Google's pre-trained 300 dimension Word2Vec embeddings 2 . We also examine the ef- fectiveness of Stanford's pre-trained 300 dimen- sion GloVe embeddings 3 .</p><p>Fifth, in order to better capture asymmetric word associations, we propose using Gaussian em- beddings. Gaussian embeddings <ref type="bibr">(Vilnis and McCallum, 2014</ref>) represent words not as a fixed point in vector space but as "potential functions", con- tinuous densities in latent space; therefore, they are more suitable for capturing asymmetric rela- tionships. More specifically, for each cue/response pair, we calculate both the KL-divergence and cosine similarities of their Gaussian embeddings. The embeddings have a dimensionality of 300 and are trained on English Wikipedia using the Word2Gauss 4 (w2g) and the hyperparameters re- ported by the developer <ref type="bibr">5</ref> Sixth, since cue and response words are not associated with a single synset, the AutoEx em- beddings employed in Hayashi (2016) to compute vector offsets are not well suited for our task. In- stead, we experiment with offsets calculated using w2v, GloVe, and w2g embeddings.</p><p>Finally, our 300 topic LDA model ( <ref type="bibr" target="#b1">Blei et al., 2003</ref>) was trained using Gensim 6 on full En- glish Wikipedia instead of the subset of English Wikipedia used in <ref type="bibr" target="#b8">Hayashi (2016)</ref>.</p><p>Using the above features, we trained a multi- layer perceptron for each of our three datasets; Evocation, USF, and EAT. In the case of Evo- cation, we discarded any synset information and   <ref type="table">Table 1</ref>: Individual feature performance after 50 epochs simply use each synset's headword (e.g. given the sysnet entity.n.01, we only considered the word entity). Following the setup used in Hayashi (2016), all neural networks are trained using the Chainer <ref type="bibr">7</ref> Python library with rectified linear units, dropout, and two hidden layers, each with 50% of the number of units in the input layer. All were trained on 80% of their respective dataset, with 20% held out for testing. Mean squared error was used as a loss function and optimization was per- formed using Adam algorithm <ref type="bibr">(Kingma and Ba, 2014)</ref>. To act as a baseline, we also reimple- mented the system described in <ref type="bibr" target="#b8">Hayashi (2016)</ref> and trained it on the same 80/20 split of Evocation as our system. In addition to the reported results, we also performed feature selection experiments using 20% of the training sets as validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>The performance of individual features are re- ported in <ref type="table">Table 1</ref> while the results of our ablation experiments are reported in <ref type="table" target="#tab_2">Table 2</ref>. For all ex- periments we report both the Pearson correlation coefficient (as r) and Spearman's rank correlation coefficient (as ρ).</p><p>The best performing single feature on Evocation and USF is w2v cosine similarity. However, its re- moval in the ablation test had little effect. This is likely due to redundancy between w2v and GloVe; not only does GloVe perform similarly to <ref type="bibr">w2v</ref>    <ref type="bibr">and Mikolov, 2014</ref>) would be more appropriate. However, if this were indeed the issue, one would expect vector offsets to perform equally poorly. This is not the case, with GloVe offsets being the best performing single feature on EAT and the re- moval of w2v offsets causing the greatest drop in performance in the EAT ablation tests.</p><note type="other">-LDA cos sim 0.357 0.377 0.340 0.299 0.291 0.361 -AutoEx cos sim (max) 0.362 0.382 0.347 0.299 0.280 0.358 -AutoEx cos sim (avg) 0.358 0.377 0.346 0.305 0.278 0.357 -w2v cos sim 0.352 0.377 0.331 0.294 0.280 0.345 -GloVe cos sim 0.352 0.367 0.332 0.292 0.284 0.360 -w2v and GloVe sims 0.329 0.342 0.284 0.255 0.261 0.353 -w2g cos sim 0.358 0.378 0.348 0.304 0.284 0.357 -w2g KL-divergence 0.351 0.356 0.344 0.299 0.286 0.348 -w2v offsets 0.361 0.386 0.303 0.280 0.239 0.271</note><p>The results of our Hayashi (2016) implementa- tion are roughly comparable to those reported in the original paper (r = 0.374, ρ = 0.401 com- pared to r = 0.439, ρ = 0.400). Our slightly lower Pearson's R may be due to differences in way we split our training and test data as well as due to randomness in the training process itself.</p><p>On Evocation, our system does not perform as well as <ref type="bibr" target="#b8">Hayashi (2016)</ref>. This is expected as we ex- plicitly ignore any synset information and instead attempt to predict association strengths between word-sense ambiguous words. Despite this, our performance is not appreciably lower, indicating the fitness of our system.</p><p>The fact that we perform better on Evocation than either USF or EAT is quite interesting consid- ering our system was designed with USF and EAT in mind. There are several possible explanations for this. First, as mentioned in Section 2, 67% of cue/response pairs in Evocation have a strength of zero. This uniformity in Evocation strengths may make them easier to predict. Second, due to the way USF and EAT were collected, there are no true zeros in the datasets. This lack of grounding may skew the predictions. Third, this may be an indication that predicting associations in a word- sense ambiguous context is a harder task than pre- dicting them in a word-sense disambiguated one. <ref type="bibr" target="#b2">Boyd-Graber et al. (2006)</ref> explicitly told annota- tors to ignore associations based on polysemy or rhyme. It could be the case that these effects are more difficult to identify.</p><p>Another possible explanation for this relatively lower performance is a lack of bespoke features. For example, we heavily rely on WordNet-based features which make sense in a word-sense disam- biguated context but are less suited for ambiguous contexts. In fact, removal of several of these fea- tures, such as betweenness or AutoEx similarity, seem to slightly improve performance. One expla- nation is that, despite noting in Section2 that word association strengths are influenced by word-sense frequencies, our system instead implicitly assumes all synsets are equally likely.</p><p>The most surprising finding was the poor per- formance of Gaussian embeddings overall, and KL-divergence in particular. Given the asymmet- ric nature of word associations, KL-divergence seemed to be a natural fit. However, it is vastly outperformed by even cosine similarity on the same set of embeddings. Despite this, the usefulness of Gaussian embeddings cannot be ruled out. While we used pre-trained em- beddings for Word2Vec and GloVe, we had to train our own Gaussian embedding model. Not only were Word2Vec and GloVe trained on much larger corpora than Gaussian embedding's English Wikipedia, but the pre-trained embeddings likely underwent a greater degree of hyperparameter tun- ing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Works</head><p>In this paper we explored the effectiveness of various features for predicting Evocation, USF, and EAT association strengths, finding GloVe and Word2Vec cosine similarities as well as vector off- sets to be the most useful features. We also exam- ined the effectiveness of Gaussian embeddings for capturing the asymmetric nature of word embed- dings but found it to be less effective than tradi- tional word embeddings.</p><p>Although we report a lower performance than that in <ref type="bibr" target="#b8">Hayashi (2016)</ref>, potentially indicating that predicting association strengths in word-sense am- biguous contexts is a harder task, we believe our results are a promising start. Training Gaussian embeddings on a larger corpus may lead to im- proved effectiveness. Future works should also consider incorporating word-sense frequencies or developing word-sense agnostic features, with a particular focus on asymmetric features. relatedness computation by asymmetric word asso- ciations. In WISE (1). pages 92-101.</p><p>Diederik <ref type="bibr">Kingma and Jimmy Ba. 2014</ref> Zhibiao <ref type="bibr">Wu and Martha Palmer. 1994</ref>. Verbs semantics and lexical selection. In Proceedings of the 32nd an- nual meeting on Association for Computational Lin- guistics. Association for Computational Linguistics, pages 133-138.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Feature</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>but removing both features at the same time produced the largest drop in performance. It is unclear why word embedding cosine similarities in gen- 7 http://chainer.org/</figDesc><table>Feature 
Evocation 
USF 
EAT 
r 
ρ 
r 
ρ 
r 
ρ 
All (w/ w2v offsets) 
0.357 
0.379 
0.344 
0.300 
0.292 
0.363 
-betweenness (max) 
0.360 
0.383 
0.341 
0.301 
0.270 
0.360 
-betweenness (avg) 
0.357 
0.376 
0.331 
0.298 
0.284 
0.353 
-load (max) 
0.358 
0.382 
0.339 
0.299 
0.290 
0.375 
-load (avg) 
0.360 
0.381 
0.340 
0.304 
0.279 
0.353 
-WUP sim (max) 
0.367 
0.376 
0.333 
0.294 
0.283 
0.367 
-WUP sim (avg) 
0.355 
0.374 
0.335 
0.296 
0.291 
0.364 
-lexVector 
0.351 
0.365 
0.336 
0.300 
0.275 
0.339 
-dirRel 
0.356 
0.375 
0.334 
0.293 
0.283 
0.362 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Ablation performance after 50 epochs 

eral performed relatively poorly on EAT. While 
the USF and EAT datasets are very similar, EAT 
does seem to contain a greater number of multi-
word cues/responses which would not be in the 
word embedding vocabularies. In such cases, per-
haps a multi-word embedding like Doc2Vec (Le 
</table></figure>

			<note place="foot" n="1"> https://mturk.com/</note>

			<note place="foot" n="2"> https://code.google.com/archive/p/word2vec/ 3 https://nlp.stanford.edu/projects/glove/ 4 https://github.com/seomoz/word2gauss 5 https://github.com/seomoz/word2gauss/issues/18#issuecomment286203006 6 https://radimrehurek.com/gensim/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Betweenness centrality in large complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Barthelemy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The European Physical Journal B-Condensed Matter and Complex Systems</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="168" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adding dense, weighted connections to wordnet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third global wordnet meeting</title>
		<meeting>the third global wordnet meeting<address><addrLine>jeju island, korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-01" />
		</imprint>
	</monogr>
	<note>Daniel Osherson, and Robert Schapire</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Effects of semantic relatedness between setups and punchlines in twitter hashtag games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cattle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">70</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Structure at every scale: A semantic network account of the similarities between unrelated concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simon De Deyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gert</forename><surname>Perfors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Storms</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">1228</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Better explanations of lexical and semantic cognition using networks derived from continued rather than single-word associations. Behavior Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simon De Deyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gert</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Storms</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="480" to="498" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Predicting human similarity judgments with distributional models: The value of word associations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Simon De Deyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Daniel</forename><surname>Perfors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Navarro</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/C16-1175" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. The COLING 2016 Organizing Committee</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. The COLING 2016 Organizing Committee</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1861" to="1870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Word associations: Norms for 1,424 dutch words in a continuous task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gert</forename><surname>Simon De Deyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Storms</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="198" to="205" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Predicting the evocation relation between lexicalized concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshihiko</forename><surname>Hayashi</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/C16-1156" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. The COLING 2016 Organizing Committee</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. The COLING 2016 Organizing Committee<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1657" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Directional context helps: Guiding semantic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoying</forename><surname>Shahida Jabeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andreae</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
