<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Event Role Extraction using Domain-Relevant Word Representations</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuela</forename><surname>BorosÂ¸</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIST, Vision and Content Engineering Laboratory</orgName>
								<orgName type="institution">CEA</orgName>
								<address>
									<postCode>F-91191</postCode>
									<settlement>Gif-sur-Yvette</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">LIMSI</orgName>
								<address>
									<addrLine>rue John von Neumann, Campus Universitaire d&apos;Orsay</addrLine>
									<postCode>F-91405</postCode>
									<settlement>Orsay</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Event Role Extraction using Domain-Relevant Word Representations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1852" to="1857"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The efficiency of Information Extraction systems is known to be heavily influenced by domain-specific knowledge but the cost of developing such systems is considerably high. In this article, we consider the problem of event extraction and show that learning word representations from unla-beled domain-specific data and using them for representing event roles enable to out-perform previous state-of-the-art event extraction models on the MUC-4 data set.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the Information Extraction (IE) field, event ex- traction constitutes a challenging task. An event is described by a set of participants (i.e. at- tributes or roles) whose values are text excerpts. The event extraction task is related to several sub- tasks: event mention detection, candidate role- filler extraction, relation extraction and event tem- plate filling. The problem we address here is the detection of role-filler candidates and their associ- ation with specific roles in event templates. For this task, IE systems adopt various ways of ex- tracting patterns or generating rules based on the surrounding context, local context and global con- text ( <ref type="bibr" target="#b24">Patwardhan and Riloff, 2009)</ref>. Current ap- proaches for learning such patterns include boot- strapping techniques <ref type="bibr" target="#b13">(Huang and Riloff, 2012a</ref>; <ref type="bibr" target="#b34">Yangarber et al., 2000</ref>), weakly supervised learn- ing algorithms ( <ref type="bibr" target="#b12">Huang and Riloff, 2011;</ref><ref type="bibr" target="#b31">Sudo et al., 2003;</ref><ref type="bibr" target="#b32">Surdeanu et al., 2006</ref>), fully supervised learning approaches ( <ref type="bibr" target="#b5">Chieu et al., 2003;</ref><ref type="bibr" target="#b9">Freitag, 1998;</ref><ref type="bibr" target="#b4">Bunescu and Mooney, 2004;</ref><ref type="bibr" target="#b24">Patwardhan and Riloff, 2009</ref>) and other variations. All these methods rely on substantial amounts of manually annotated corpora and use a large body of lin- guistic knowledge. The performance of these ap- proaches is related to the amount of knowledge engineering deployed and a good choice of fea- tures and classifiers. Furthermore, the efficiency of the system relies on the a priori knowledge of the applicative domain (the nature of the events) and it is generally difficult to apply a system on a different domain with less annotated data with- out reconsidering the design of the features used. An important step forwards is TIER light <ref type="bibr" target="#b13">(Huang and Riloff, 2012a</ref>) that targeted the minimization of human supervision with a bootstrapping tech- nique for event roles detection. Also, PIPER <ref type="bibr" target="#b23">(Patwardhan and Riloff, 2007;</ref><ref type="bibr" target="#b25">Patwardhan, 2010)</ref> dis- tinguishes between relevant and irrelevant regions and learns domain-relevant extraction patterns us- ing a semantic affinity measure. Another possi- ble approach for dealing with this problem is to combine the use a restricted set of manually anno- tated data with a much larger set of data extracted in an unsupervised way from a corpus. This ap- proach was experimented for relations in the con- text of Open Information Extraction ( <ref type="bibr" target="#b30">Soderland et al., 2010)</ref> but not for extracting events and their participants to our knowledge.</p><p>In this paper, we propose to approach the task of labeling text spans with event roles by auto- matically learning relevant features that requires limited prior knowledge, using a neural model to induce semantic word representations (commonly referred as word embeddings) in an unsupervised fashion, as in ( <ref type="bibr" target="#b1">Bengio et al., 2006;</ref><ref type="bibr" target="#b6">Collobert and Weston, 2008)</ref>. We exploit these word embed- dings as features for a supervised event role (mul- ticlass) classifier. This type of approach has been proved efficient for numerous tasks in natural lan- guage processing, including named entity recog- nition ( <ref type="bibr" target="#b33">Turian et al., 2010)</ref>, semantic role label- ing ), machine translation ( <ref type="bibr" target="#b28">Schwenk and Koehn, 2008;</ref><ref type="bibr" target="#b15">Lambert et al., 2012)</ref>, word sense disambiguation ( <ref type="bibr" target="#b3">Bordes et al., 2012</ref>) or sentiment analysis <ref type="bibr" target="#b11">(Glorot et al., 2011;</ref><ref type="bibr" target="#b29">Socher et al., 2011</ref>) but has never been used, to our knowl-edge, for an event extraction task. Our goal is two- fold: (1) to prove that using as only features word vector representations makes the approach com- petitive in the event extraction task; (2) to show that these word representations are scalable and robust when varying the size of the training data. Focusing on the data provided in MUC-4 ( <ref type="bibr" target="#b17">Lehnert et al., 1992)</ref>, we prove the relevance of our ap- proach by outperforming state-of-the-art methods, in the same evaluation environment as in previous works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>In this work, we approach the event extraction task by learning word representations from a domain- specific data set and by using these representa- tions to identify the event roles. This idea relies on the assumption that the different words used for a given event role in the text share some se- mantic properties, related to their context of use and that these similarities can be captured by spe- cific representations that can be automatically in- duced from the text, in an unsupervised way. We then propose to rely only on these word repre- sentations to detect the event roles whereas, in most works <ref type="bibr" target="#b27">(Riloff, 1996;</ref><ref type="bibr" target="#b23">Patwardhan and Riloff, 2007;</ref><ref type="bibr" target="#b13">Huang and Riloff, 2012a;</ref><ref type="bibr" target="#b14">Huang and Riloff, 2012b)</ref>, the role fillers are represented by a set of different features (raw words, their parts-of- speech, syntactic or semantic roles in the sen- tence).</p><p>Furthermore, we propose two additional contri- butions to the construction of the word representa- tions. The first one is to exploit limited knowledge about the event types (seed words) to improve the learning procedure by better selecting the dictio- nary. The second one is to use a max operation 1 on the word vector representations in order to build noun phrase representations (since slot fillers are generally noun phrases), which represents a better way of aggregating the semantic information born by the word representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Inducing Domain-Relevant Word Representations</head><p>In order to induce the domain-specific word rep- resentations, we project the words into a 50- dimensional word space. We chose a single layer neural network (NN) architecture that avoids strongly engineered features, assumes little prior knowledge about the task, but is powerful enough to capture relevant domain information. Follow- ing (Collobert et al., 2011), we use an NN which learns to predict whether a given text sequence (short word window) exists naturally in the consid- ered domain. We represent an input sequence of n words as w i = w iâ(n/2) . . . , w i , . . . w i+(n/2) .</p><p>The main idea is that each sequence of words in the training set should receive a higher score than a sequence in which one word is replaced with a random one. We call the sequence with a ran- dom word corrupted ( Â¯ w i ) and denote as correct (w i ) all the sequences of words from the data set. The goal of the training step is then to min- imize the following loss function for a word w i in the dictionary D:</p><formula xml:id="formula_0">C w i = w i âD max(0, 1 â g(w i )+g( Â¯ w i )), where g(Â·)</formula><p>is the scoring func- tion given by the neural network. Further details and evaluations of these embeddings can be found in ( <ref type="bibr" target="#b0">Bengio et al., 2003;</ref><ref type="bibr" target="#b1">Bengio et al., 2006;</ref><ref type="bibr" target="#b6">Collobert and Weston, 2008;</ref><ref type="bibr" target="#b33">Turian et al., 2010</ref>). For efficiency, words are fed to our architecture as in- dices taken from a finite dictionary. Obviously, a simple index does not carry much useful infor- mation about the word. So, the first layer of our network maps each of these word indices into a feature vector, by a lookup table operation. Our first contribution intervenes in the process of the choosing the proper dictionary. <ref type="bibr" target="#b2">(Bengio, 2009)</ref> has shown that the order of the words in the dic- tionary of the neural network is not indifferent to the quality of the achieved representations: he pro- posed to order the dictionary by frequency and se- lect the words for the corrupted sequence accord- ing to this order. In our case, the most frequent words are not always the most relevant for the task of event role detection. Since we want to have a training more focused to the domain specific task, we chose to order the dictionary by word relevance to the domain. We accomplish this by considering a limited number of seed words for each event type that needs to be discovered in text (e.g. attack, bombing, kidnapping, arson). We then rate with higher values the words that are more similar to the event types words, according to a given semantic similarity, and we rank them accordingly. We use the "Leacock Chodorow" similarity from Word- net 3.0 ( <ref type="bibr" target="#b16">Leacock and Chodorow, 1998)</ref>. Initial ex- perimental results proved that using this domain-oriented order leads to better performance for the task than the order by frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Using Word Representations to Identify Event Roles</head><p>After having generated for each word their vec- tor representation, we use them as features for the annotated data to classify event roles. However, event role fillers are not generally single words but noun phrases that can be, in some cases, identi- fied as named entities. For identifying the event roles, we therefore apply a two-step strategy. First, we extract the noun chunks using SENNA 2 parser (Collobert et al., 2011; Collobert, 2011) and we build a representation for these chunks defined as the maximum, per column, of the vector represen- tations of the words it contains. Second, we use a statistical classifier to recognize the slot fillers, using this representation as features. We chose the extra-trees ensemble classifier ( <ref type="bibr" target="#b10">Geurts et al., 2006</ref>), which is a meta estimator that fits a num- ber of randomized decision trees (extra-trees) on various sub-samples of the data set and use averag- ing to improve the predictive accuracy and control over-fitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Description</head><p>We conducted the experiments on the official MUC-4 training corpus that consists of 1,700 doc- uments and instantiated templates for each doc- ument. The task consists in extracting informa- tion about terrorist events in Latin America from news articles. We classically considered the fol- lowing 4 types of events: attack, bombing, kid- napping and arson. These are represented by tem- plates containing various slots for each piece of information that should be extracted from the doc- ument (perpetrators, human targets, physical tar- gets, etc). Following previous works (Huang and Riloff, 2011; Huang and Riloff, 2012a), we only consider the "String Slots" in this work (other slots need different treatments) and we group certain slots to finally consider the five slot types PerpInd (individual perpetrator), PerpOrg (organizational perpetrator), Target (physical target), Victim (hu- man target name or description) and Weapon (in- strument id or type). We used 1,300 documents (DEV) for training, 200 documents (TST1+TST2) for tuning, and 200 documents (TST3+TST4) as the blind test set. To compare with similar works, we do not evaluate the template construction and only focus on the identification of the slot fillers: for each answer key in a reference template, we check if we find it correctly with our extraction method, using head noun matching (e.g., the vic- tim her mother Martha Lopez Orozco de Lopez is considered to match Matha Lopez), and merging duplicate extractions (so that different extracted slot fillers sharing the same head noun are counted only once). We also took into account the answer keys with multiple values in the reference, deal- ing with conjunctions (when several victims are named, we need to find all of them) and disjunc- tions (when several names for the same organiza- tion are possible, we need to find any of them).</p><p>Our results are reported as Precision/Recall/F1- score for each event role separately and averaged on all roles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments</head><p>In all the experiments involving our model, we es- tablished the following stable choices of parame- ters: 50-dimensional vectors obtained by training on sequences of 5 words, which is consistent with previous studies <ref type="bibr" target="#b33">(Turian et al., 2010;</ref><ref type="bibr" target="#b6">Collobert and Weston, 2008)</ref>. All the hyper-parameters of our model (e.g. learning rate, size of the hidden layer, size of the word vectors) have been chosen by finetuning our event extraction system on the TST1+TST2 data set. For DRVR-50 and W2V-50, the embeddings were built from the whole training corpus (1,300 documents) and the dictionary was made of all the words of this corpus under their inflected form. We used the extra-trees ensemble classifier im- plemented in <ref type="bibr" target="#b26">(Pedregosa et al., 2011</ref>), with hyper- parameters optimized on the validation data: for- est of 500 trees and the maximum number of features to consider when looking for the best split is â number f eatures. We present a 3- fold evaluation: first, we compare our system with state-of-the-art systems on the same task, then we compare our domain-relevant vector representa- tions (DRVR-50) to more generic word embed- dings (C&amp;W50, HLBL-50) <ref type="bibr">3</ref> and finally to another</p><p>State-of-the-art systems PerpInd PerpOrg Target Victim Weapon Average ( <ref type="bibr" target="#b27">Riloff, 1996)</ref> 33/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>49/40 53/33/41 54/59/56 49/54/51 38/44/41 45/48/46 (Patwardhan and Riloff, 2007) 39/48/43 55/31/40 37/60/46 44/46/45 47/47/47 44/36/40 (Patwardhan and Riloff, 2009) 51/58/54 34/45/38 43/72/53 55/58/56 57/53/55 48/57/52</head><p>( <ref type="bibr" target="#b12">Huang and Riloff, 2011)</ref> 48/57/52 46/53/50 51/73/60 56/60/58 53/64/58 51/62/56 <ref type="bibr" target="#b13">(Huang and Riloff, 2012a)</ref> 47/51/47 60/39/47 37/65/47 39/53/45 53/55/54 47/53/50 ( <ref type="bibr" target="#b14">Huang and Riloff, 2012b)</ref> 54 word representation construction on the domain- specific data (W2V-50) 4 .</p><p>Figure 1: F1-score results for event role labeling on MUC-4 data, for different size of training data, of "String Slots" on the TST3+TST4 with differ- ent parameters, compared to the learning curve of TIER ( <ref type="bibr" target="#b13">Huang and Riloff, 2012a</ref>). The grey points represent the performances of other IE systems. <ref type="figure">Figure 1</ref> presents the average F1-score results, computed over the slots PerpInd, PerpOrg, Tar- get, Victim and Weapon. We observe that mod- els relying on word embeddings globally outper- form the state-of-the-art results, which demon- strates that the word embeddings capture enough semantic information to perform the task of event newswire corpus 4 W2V-50 are the embeddings induced from the MUC4 data set using the negative sampling training algorithm ( <ref type="bibr" target="#b19">Mikolov et al., 2013a;</ref><ref type="bibr" target="#b20">Mikolov et al., 2013b;</ref><ref type="bibr" target="#b21">Mikolov et al., 2013c</ref>), available at https://code.google.com/ p/word2vec/ role labeling on "String Slots" without using any additional hand-engineered features. Moreover, our representations (DRVR-50) clearly surpass the models based on generic embeddings (C&amp;W-50 and HLBL-50) and obtain better results than W2V- 50, based the competitive model of <ref type="bibr" target="#b19">(Mikolov et al., 2013a</ref>), even if the difference is small. We can also note that the performance of our model is good even with a small amount of training data, which makes it a good candidate to easily develop an event extraction system on a new domain. <ref type="table">Table 1</ref> provides a more detailed analysis of the comparative results. We can see in this table that our results surpass those of previous systems (0.73 vs. 0.59) with, particularly, a consistently higher precision on all roles, whereas recall is smaller for certain roles (Target and Weapon). To further ex- plore the impact of these representations, we com- pared our word embeddings with other word em- beddings (C&amp;W-50, HLBL-50) and report the re- sults in <ref type="figure">Figure 1</ref> and <ref type="table">Table 1</ref>. The results show that our model also outperforms the models using others word embeddings (F1-score of 0.73 against 0.65, 0.66). This proves that a model learned on a domain-specific data set does indeed pro- vide better results, even if its size is much smaller (whereas it is usually considered that neural mod- els require often important training data). Finally, we also achieve slightly better results than W2V-50 with other word representations built on the same corpus, which shows that the choices made for the word representation construction, such as the use of domain information for word ordering, tend to have a positive impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Perspectives</head><p>We presented in this paper a new approach for event extraction by reducing the features to only use unsupervised word representations and a small set of seed words. The word embeddings induced from a domain-specific corpus bring improvement over state-of-art models on the standard MUC- 4 corpus and demonstrate a good scalability on different sizes of training data sets. Therefore, our proposal offers a promising path towards eas- ier and faster domain adaptation. We also prove that using a domain-specific corpus leads to bet- ter word vector representations for this task than using other publicly-available word embeddings (even if they are induced from a larger corpus).</p><p>As future work, we will reconsider the archi- tecture of the neural network and we will refo- cus on creating a deep learning model while tak- ing advantage of a larger set of types of infor- mation such as syntactic information, following <ref type="bibr" target="#b18">(Levy and Goldberg, 2014)</ref>, or semantic informa- tion, following <ref type="bibr" target="#b35">(Yu and Dredze, 2014</ref>).</p></div>
			<note place="foot" n="1"> This max operation consists in taking, for each component of the vector, the max value of this component for each word vector representation.</note>

			<note place="foot" n="2"> Code and resources can be found at http://ml. nec-labs.com/senna/</note>

			<note place="foot" n="3"> C&amp;W-50 are described in (Collobert and Weston, 2008), HLBL-50 are the Hierarchical log-bilinear embeddings (Mnih and Hinton, 2007), provided by (Turian et al., 2010), available at http://metaoptimize.com/ projects/wordreprs induced from the Reuters-RCV1</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rejean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural probabilistic language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-SÃ©bastian</forename><surname>SenÃ©cal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">FrÃ©deric</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Luc</forename><surname>Gauvain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovations in Machine Learning</title>
		<editor>DawnE. Holmes and LakhmiC. Jain</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="138" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Learning deep architectures for AI. Foundations and trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Joint learning of words and meaning representations for open-text semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2012)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="127" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Collective information extraction with relational markov networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">42nd Annual Meeting on Association for Computational Linguistics (ACL-04)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="438" to="445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Closing the gap: Learning-based information extraction rivaling knowledge-engineering methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Leong Chieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoong Keok</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">41st international Annual Meeting on Association for Computational Linguistics (ACL-2003)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="216" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th International Conference of Machine learning (ICML08)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">LÃ©on</forename><surname>Battou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep learning for efficient discriminative parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>AISTATS</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Information extraction from HTML: Application of a general machine learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayne</forename><surname>Freitag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;98</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="517" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Extremely randomized trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Geurts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis</forename><surname>Wehenkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="42" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domain adaptation for large-scale sentiment classification: A deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th International Conference on Machine Learning (ICML-11)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Peeling back the layers: Detecting event role fillers in secondary contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2011</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1137" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bootstrapped training of event extraction classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2012)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="286" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modeling textual cohesion for event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">26th Conference on Artificial Intelligence (AAAI</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic translation of scientific documents in the hal archive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrik</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">FrÃ©dÃ©ric</forename><surname>Blain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC 2012</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3933" to="3936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Combining local context and Wordnet similarity for word sense identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Leacock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Christiane Fellbaum, editor</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
	<note>WordNet: An electronic lexical database</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">University of Massachusetts: MUC-4 test results and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><surname>Lehnert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th Conference on Message understanding</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dependencybased word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014), Short Papers</title>
		<meeting><address><addrLine>Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR 20013), workshop track</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26 (NIPS 2013)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT 2013</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Three new graphical models for statistical modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th International Conference of Machine learning (ICML 2007)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="641" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Effective information extraction with semantic affinity patterns and relevant regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="717" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A unified model of phrasal and sentential evidence for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Widening the field of view of information extraction through sentential event recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>University of Utah</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automatically generating extraction patterns from untagged text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;96</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1044" to="1049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Large and diverse language models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP 2008</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="661" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Parsing natural scenes and natural language with recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th International Conference on Machine Learning (ICML-11)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adapting open information extraction to domain-specific relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Roof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><forename type="middle">Etzioni</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="93" to="102" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An improved extraction pattern representation model for automatic ie pattern acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoshi</forename><surname>Sudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">41st Annual Meeting on Association for Computational Linguistics (ACL-03)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="224" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A hybrid approach for the acquisition of information extraction patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Turmo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Ageno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL-2006 Workshop on Adaptive Text Extraction and Mining (ATEM 2006)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Word representations: a simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">48th international Annual Meeting on Association for Computational Linguistics (ACL 2010)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic acquisition of domain knowledge for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Yangarber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasi</forename><surname>Tapanainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silja</forename><surname>Huttunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th Internation Conference on Computational Linguistics (COLING 2000)</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="940" to="946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Improving lexical embeddings with semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014), Short Papers</title>
		<meeting><address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="545" to="550" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
