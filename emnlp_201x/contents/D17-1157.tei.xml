<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Source-Side Left-to-Right or Target-Side Left-to-Right? An Empirical Comparison of Two Phrase-Based Decoding Algorithms</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin-Wen</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Research</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">New</forename><surname>York</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
							<email>mjcollins@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Source-Side Left-to-Right or Target-Side Left-to-Right? An Empirical Comparison of Two Phrase-Based Decoding Algorithms</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1495" to="1499"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper describes an empirical study of the phrase-based decoding algorithm proposed by Chang and Collins (2017). The algorithm produces a translation by processing the source-language sentence in strictly left-to-right order, differing from commonly used approaches that build the target-language sentence in left-to-right order. Our results show that the new algorithm is competitive with Moses (Koehn et al., 2007) in terms of both speed and BLEU scores.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Phrase-based models ( <ref type="bibr" target="#b8">Koehn et al., 2003;</ref><ref type="bibr" target="#b9">Och and Ney, 2004</ref>) have until recently been a state- of-the-art method for statistical machine transla- tion, and Moses ( <ref type="bibr" target="#b7">Koehn et al., 2007</ref>) is one of the most used phrase-based translation systems. Moses uses a beam search decoder based on a dy- namic programming algorithm that constructs the target-language sentence from left to right <ref type="bibr" target="#b8">(Koehn et al., 2003)</ref>. Neural machine translation systems <ref type="bibr" target="#b5">(Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b2">Cho et al., 2014;</ref><ref type="bibr" target="#b10">Sutskever et al., 2014</ref>), which have given impressive improvements over phrase-based sys- tems, also typically use models and decoders that construct the target-language string in strictly left- to-right order.</p><p>Recently, <ref type="bibr" target="#b1">Chang and Collins (2017)</ref> proposed a phrase-based decoding algorithm that processes the source-language string in strictly left-to-right order. Reordering is implemented by maintaining multiple sub-strings in the target-language, with phrases being used to extend these sub-strings by various operations (see Section 2 for a full descrip- tion). With a fixed distortion limit on reordering, * On leave from Columbia University. the time complexity of the algorithm is linear in terms of sentence length, and is polynomial time in other factors. <ref type="bibr" target="#b1">Chang and Collins (2017)</ref> present the algorithm and give a proof of its time complexity, but do not describe experiments, leaving an open question of whether the algorithm is useful in practice. This paper complements the original paper by studying the algorithm empirically. In addition to an exact dynamic programming implementation, we study the use of beam search with the algorithm, and an- other pruning method that restricts the maximum number of target-language strings maintained at any point. The experiments show that the algo- rithm is competitive with Moses in terms of both speed and translation quality (BLEU score).</p><p>The new decoding algorithm is of interest for a few reasons. While the experiments in this pa- per are with phrase-based translation systems, the method could potentially be extended to neural translation, for example with an attention-based model that is in some sense monotonic (left-to- right). The decoder may be relevant to work on si- multaneous translation <ref type="bibr" target="#b4">(He et al., 2016</ref>). The ideas may be applicable to string-to-string transduction problems other than machine translation. <ref type="bibr" target="#b1">Chang and Collins (2017)</ref> This section gives a sketch of the decoding algo- rithm of <ref type="bibr" target="#b1">Chang and Collins (2017)</ref>. We first define the phrase-based decoding problem, and then de- scribe the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Sketch of the Decoding Algorithm of</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Phrase-based Decoding Problem</head><p>Throughout this paper we will consider the follow- ing decoding problem. Given a source sentence x 1 . . . x n for n ≥ 1, a phrase p = (s, t, e) speci- fies a possible translation from x s . . . x t to a string Sub-derivation</p><formula xml:id="formula_0">State 1, 1, &lt;s&gt; 1, 1, &lt;s&gt;, 1, &lt;s&gt; p = 2, 3</formula><p>, we must , operation = replace π1 by CONCAT(π1, p)</p><p>1, 1, &lt;s&gt; 2, 3, we must 3, 1, &lt;s&gt;, 3, must p = 4, 4, also , operation = replace π1 by CONCAT(π1, p)</p><p>1, 1, &lt;s&gt; 2, 3, we must 4, 4, also 4, 1, &lt;s&gt;, 4, also p = 5, 6, these criticisms , operation = add a new sequence π2 = p 1, 1, &lt;s&gt; 2, 3, we must 4, 4, also , 5, 6, these criticisms 6, 1, &lt;s&gt;, 4, also , 5, these, 6, criticisms p = 7, 7, seriously , operation = replace π2 by CONCAT(π2, p)</p><p>1, 1, &lt;s&gt; 2, 3, we must 4, 4, also , 5, 6, these criticisms 7, 7, seriously 7, 1, &lt;s&gt;, 4, also , 5, these, 7, seriously p = 8, 8, take , operation = replace π1, π2 by CONCAT(π1, p, π2)</p><p>1, 1, &lt;s&gt; 2, 3, we must 4, 4, also 8, 8, take 5, 6, these criticisms 7, 7, seriously 8, 1, &lt;s&gt;, 7, seriously p = 9, 9, &lt;/s&gt; , operation = replace π1 by CONCAT(π1, p)</p><p>1, 1, &lt;s&gt; 2, 3, we must 4, 4, also 8, 8, take 5, 6, these criticisms 7, 7, seriously 9, 9, &lt;/s&gt; 9, 1, &lt;s&gt;, 9, &lt;/s&gt; <ref type="figure">Figure 1</ref>: Illustrations of how the new algorithm produces the output translation. We note each phrase that is being added and the operation it takes to generate the next segments of phrase sequence.</p><p>of target-language words e = e 1 . . . e m . We use s(p), t(p), and e(p) to refer to the three elements of a phrase p. A derivation is a sequence of</p><formula xml:id="formula_1">L phrases, p 1 . . . p L .</formula><p>The derivation gives a transla- tion by concatenating the target-language strings</p><formula xml:id="formula_2">e(p 1 ) . . . e(p L ).</formula><p>We will always assume that x 1 = &lt;s&gt;, the start-of-sentence symbol, and x n = &lt;/s&gt;, the end-of-sentence symbol. The only phrases covering positions 1 and n are (1, 1, &lt;s&gt;) and (n, n, &lt;/s&gt;).</p><p>A derivation p 1 . . . p L is valid if each word in the source sentence is translated exactly once, and</p><formula xml:id="formula_3">if for i = 2 . . . L we have |t(p i−1 )+1−s(p i )| ≤ d, where d is the distortion limit.</formula><p>The score for any derivation is</p><formula xml:id="formula_4">f (p 1 . . . p L ) = λ(e(p 1 ) . . . e(p L )) + L i=1 κ(p i ) + L i=2 η × |t(p i−1 ) + 1 − s(p i )|</formula><p>where the parameter η is the distortion penalty, λ(e) is a language model score for the word se- quence e, and κ(p) is the score for phrase p un- der the phrase-based model. For example under a bigram language model, we have λ(e 1 . . . e m ) = m i=2 λ(e i |e i−1 ). where λ(v|u) is the score for bi- gram (u, v).</p><p>The phrase-based decoding problem is to find arg max</p><formula xml:id="formula_5">p 1 ...p L ∈P f (p 1 . . . p L )</formula><p>where P is the set of all valid derivations for the input sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Decoding Algorithm</head><p>At a high level, the decoding algorithm of Chang and Collins (2017) differs from the commonly- used approach of <ref type="bibr" target="#b8">Koehn et al. (2003)</ref> in two im- portant respects:</p><p>1. The decoding algorithm proceeds in strictly left-to-right order in the source sentence.</p><p>2. Each sub-derivation (item) in the beam con- sists of multiple sequences of phrases, instead of a single sequence.</p><p>To be more precise, each sub-derivation in the decoding algorithm consists of:</p><p>1. An integer j specifying the length of the derivation (i.e., that words x 1 . . . x j have been translated).</p><p>2. A set of segments {π 1 , π 2 , . . . , π r } where r ≥ 1. Each segment π is a sequence of phrases. The segment π 1 always has (1, 1, &lt;s&gt;) as its first element. Each word x 1 . . . x j is translated exactly once in these segments.</p><p>As one example, the sub-derivation (1, {{(1, 1, &lt;s&gt;)}) is always the initial sub- derivation, with only the first word x 1 be- ing translated, and with a single segment π 1 = <ref type="figure">(1, 1, &lt;s&gt;)</ref>. A more complex sub- derivation is (7, {{(1, 1, &lt;s&gt;)(2, 3, we must)(4, 4, also), (5, 6, these criticisms)(7, 7, seriously)}) (1) which translates words x 1 . . . x 7 , and has two seg- ments, π 1 =(1, 1, &lt;s&gt;)(2, 3, we must)(4, 4, also) π 2 =(5, 6, these criticisms)(7, 7, seriously)</p><p>We now describe how sub-derivations can be built as the source sentence is processed in left- to-right order. A derivation (j, {π 1 . . . π r }) can be extended as follows:</p><formula xml:id="formula_6">1. First select some phrase p = (j + 1, t, e)</formula><p>where the phrase-based lexicon specifies that words x j+1 . . . x t can be translated as the En- glish sequence e = e 1 . . . e m .</p><p>2. Second, extend the derivation using one of the following operations (we use CONCAT to denote an operation that concatenates two or more phrase sequences):  <ref type="figure">Figure 1</ref> shows the sequence of steps, and the resulting sequence of sub-derivations, in the trans- lation of a German sentence.</p><p>A few remarks: Remark 1. The score for each of the operations (a)-(d) described above is easily calculated using a combination of phrase, language model, and dis- tortion scores.</p><p>Remark 2. The distortion limit can be used to rule out some of the operations (a)-(d) above, de- pending on the phrase p and the start/end points of each of the segments π 1 . . . π r .</p><p>Remark 3. Dynamic programming can be used with this algorithm. Under a bigram language model, the dynamic programming state for a sub- derivation (j, {π 1 . . . π r }) records the words and positions at the start and end of each segment π 1 . . . π r . For example under a bigram language  model the sub-derivation (7, . . .) in Eq. 1 would be mapped to the dynamic-programming state (7, {(1, &lt;s&gt;, 4, also), (5, these, 7, seriously)}). See Chang and Collins (2017) for more details.</p><p>Remark 4. It is simple to use beam search in conjunction with the algorithm. Different deriva- tions of the same length j are compared in the beam. A heuristic-typically a lower-order lan- guage model-can be used to score the first n − 1 words in each segment π 1 · · · π r : this can be used as the "future score" for each item in the beam. This is arguably simpler than the future scores used in ( <ref type="bibr" target="#b8">Koehn et al., 2003)</ref>, which have to take into account the fact that different items in the beam correspond to translations of different sub- sets of words in the source sentence. In our ap- proach different derivations of the same length j have translated the same set of words x 1 · · · x j . For example in the sub-derivation (7, . . .) given above (Eq. 1), and given a trigram language model, the initial bigram these criticisms in π 2 is scored as p u (these) × p b (criticisms|these) where p u and p b are unigram and bigram language mod- els.  section describes experiments comparing beam search under the new algorithm to the method of <ref type="bibr" target="#b8">Koehn et al. (2003)</ref>. Throughout this section we refer to the algorithm of <ref type="bibr" target="#b1">Chang and Collins (2017)</ref> as the "new" decoding algorithm.</p><note type="other">it-en 4 28.44 4m26s 28.44 3m57s 28.41 3m36s nl-en 8 24.96 7m53s 25.13 5m20s 25.16 5m56s pt-en 4 31.06 4m28s 31.05 4m00s 31.05 3m31s sv-en 4 31.33 3m58s 31.35 3m30s 31.34 3m02s vi-en 8 20.48 2 3m39s 20.96 2m08s 20.95 2m40s</note><p>Data. We use the Europarl parallel corpus (Ver- sion 7) 3 <ref type="bibr" target="#b6">(Koehn, 2005</ref>) for all language pairs ex- cept for Vietnamese-English (vi-en). For Czech- English (cs-en), we use the Newstest2015 as the development set and Newstest2016 as the test set. For European languages other than Czech, we use the development and test set released for the Shared Task of WPT 2005 4 . For vi-en, we use the IWSLT'15 data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Search Space with a Bigram Model</head><p>We first analyze the properties of the algorithm by running the exact decoding algorithm with a bi- gram language model and a fixed distortion limit of four, with no pruning. In <ref type="figure" target="#fig_2">Figure 2</ref>, we plot the number of transitions computed versus sentence length for translation of 2,000 German sentences to English. The figure confirms that the search space grows linearly with the number of words in the source sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Beam Search under the New Algorithm</head><p>Even though the exact algorithm is linear time in the input sentence length, other factors (the depen-  dence on d, l, and h, as described above) make the exact algorithm too costly to be useful in practice.</p><p>We experiment with beam search under the new algorithm, 5 both with and without further pruning or restriction.</p><p>We experimented with a segment constraint on the new algorithm: more specifically, we describe experiments with a hard limit r ≤ 2 on the number of segments π 1 . . . π r used in any translation. <ref type="figure" target="#fig_3">Figure 3</ref> shows results using a trigram language model for the new algorithm with beam search (SegmentD), the new algorithm with beam search and a hard limit r ≤ 2 on the number of segments (Segment2), and Moses. A beam size of 100 is used with all the algorithms. For each language pair, we pick the distortion limit that maximizes the BLEU score for Moses. Moses was used to train all the translation models. It can be seen that the Segment2 algorithm gives very similar perfor- mance to Moses, while SegmentD has inferior per- formance for languges which require a larger dis- tortion limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experiments on the Number of Segments</head><p>Required for German-to-English Translation Finally, we investigate empirically how many seg- ments (the maximum value of r) are required for translation from German to English. In a first ex- periment, we use the system of Chang and Collins (2011) to give exact search for German-to-English translation under a trigram language model with a distortion limit d = 4, and then look at the maxi- mum value for r for each optimal translation. Out of 1,821 sentences, 34.9% have a maximum value of r = 1, 62.4% have r = 2, and 2.69% have r = 3 <ref type="table">(Table 4a)</ref>. No optimal translations require a value of r greater than 3. It can be seen that very few translations require more than 2 segments. In a second experiment, we take the reordering system of <ref type="bibr" target="#b3">Collins et al. (2005)</ref> and test the maxi- mum value for r on each sentence to capture the reordering rules. <ref type="table">Table 4b</ref> gives the results. It can be seen that over 99% of sentences require a value of r = 3 or less, again suggesting that for at least this language pair, a choice of r = 3 or r = 4 is large enough to capture the majority of reorderings (assuming that the rules of <ref type="bibr" target="#b3">Collins et al. (2005)</ref> are comprehensive).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The goal of this paper was to understand the em- pirical performance of a newly proposed decoding algorithm that operates from left to right on the source side. We compare our implementation of the new algorithm with the Moses decoder. The experimental results demonstrate that the new al- gorithm combined with beam search and segment- based pruning is competitive with the Moses de- coder. Future work should consider integration of the method with more recent models, in particular neural translation models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(a)</head><label></label><figDesc>Replace π i for some i ∈ 1 . . . r by CONCAT(π i , p). (b) Replace π i for some i ∈ 2 . . . r by CONCAT(p, π i ). (c) Replace π i , π i for integers i = i by CONCAT(π i , p, π i ) (d) Create a new segment π r+1 = p.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The total number of dynamic programming transitions and the sentence length.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparison of beam search under the new decoding algorithm and the Moses decoder. We show the BLEU score and the decoding time of three beam search based decoding methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The number of segments required for German-to-English translation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>d SegmentD Segment2 Moses BLEU time BLEU time BLEU time cs-en 8 13.67 1 5m31s 17.42 2m49s 17.56 3m32s de-en 12 25.89 9m02s 26.69 5m25s 26.69 7m37s es-en 4 32.02 4m27s 32.01 3m58s 32.03 4m01s fi-en 8 23.02 5m03s 23.66 3m09s 23.73 3m37s fr-en 4 31.42 4m58s 31.43 4m23s 31.45 4m20s</figDesc><table></table></figure>

			<note place="foot" n="3"> Experiments The original motivation for Chang and Collins (2017) was to develop a dynamic-programming algorithm for phrase-based decoding that for a fixed distortion limit d was polynomial time in other factors: the resulting dynamic programming algorithm is O(nd!lh d+1 ) time, where d is the distortion limit, l is a bound on the number of phrases starting at any position, and h is related to the maximum number of different target translations for any source position. However an open question is whether the algorithm is useful in practice when used in conjunction with beam search. This</note>

			<note place="foot" n="1"> Unable to produce translations for 36 sentences. 2 Unable to produce translations for one sentence. 3 http://www.statmt.org/europarl/ 4 ACL 2005 Workshop on Building and Using Parallel Texts.</note>

			<note place="foot" n="5"> See Section 5.1 in Chang and Collins (2017)</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Exact decoding of phrase-based translation models through Lagrangian relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin-Wen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="26" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A polynomial-time dynamic programming algorithm for phrase-based decoding with a fixed distortion limit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin-Wen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="59" to="71" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Clause restructuring for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivona</forename><surname>Kučerová</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd annual meeting on association for computational linguistics. Association for Computational Linguistics</title>
		<meeting>the 43rd annual meeting on association for computational linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="531" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Interpretese vs. translationese: The uniqueness of human strategies in simultaneous interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recurrent continuous translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1700" to="1709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MT summit</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th annual meeting of the ACL on interactive poster and demonstration sessions</title>
		<meeting>the 45th annual meeting of the ACL on interactive poster and demonstration sessions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The alignment template approach to statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="417" to="449" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
