<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Why are You Taking this Stance? Identifying and Classifying Reasons in Ideological Debates</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazi</forename><forename type="middle">Saidul</forename><surname>Hasan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Human Language Technology Research Institute University of Texas at Dallas Richardson</orgName>
								<address>
									<postCode>75083-0688</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Human Language Technology Research Institute University of Texas at Dallas Richardson</orgName>
								<address>
									<postCode>75083-0688</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Why are You Taking this Stance? Identifying and Classifying Reasons in Ideological Debates</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="751" to="762"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent years have seen a surge of interest in stance classification in online debates. Oftentimes, however, it is important to determine not only the stance expressed by an author in her debate posts, but also the reasons behind her supporting or opposing the issue under debate. We therefore examine the new task of reason classification in this paper. Given the close interplay between stance classification and reason classification, we design computational models for examining how automatically computed stance information can be profitably exploited for reason classification. Experiments on our reason-annotated corpus of ideological debate posts from four domains demonstrate that sophisticated models of stances and reasons can indeed yield more accurate reason and stance classification results than their simpler counterparts.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, researchers have begun exploring new opinion mining tasks. One such task is debate stance classification (SC): given a post written for a two-sided topic discussed in an online debate fo- rum, determine which of the two sides (i.e., for or against) its author is taking ( <ref type="bibr" target="#b0">Agrawal et al., 2003;</ref><ref type="bibr" target="#b28">Thomas et al., 2006</ref>; <ref type="bibr" target="#b3">Bansal et al., 2008;</ref><ref type="bibr" target="#b23">Somasundaran and Wiebe, 2009;</ref><ref type="bibr" target="#b7">Burfoot et al., 2011;</ref><ref type="bibr" target="#b13">Hasan and Ng, 2013b</ref>). For example, the author of the post shown in <ref type="figure" target="#fig_0">Figure 1</ref> is pro-abortion.</p><p>Oftentimes, however, it is important to deter- mine not only the author's stance expressed in her debate posts, but also the reasons why she supports or opposes the issue under debate. Intuitively, given a debate topic such as "Should abortion be banned?" or "Do you support Obamacare?", it [I feel that abortion should remain legal, or rather, parents should have the power to make the decision themselves and not face any legal hindrance of any form.] 1 Let us take a look from the social perspective. [If parents cannot afford to provide for the child, or if the family is facing financial constraints, it is understandable that abortion can remain as one of the options.] 2</p><p>Reason 1: Woman's right to abort Reason 2: Unwanted babies are threat to their parents' fu- ture should not be difficult for us to come up with a set of reasons people typically use to back up their stances. Given a set of reasons associated with each stance in an online debate, the goal of post- level reason classification is to identify those rea- son(s) an author uses to back up her stance in her debate post. A more challenging version of this task is sentence-level reason classification, where the goal is to identify not only the reason(s) an au- thor uses in her post, but also the sentence(s) in the post that the author uses to describe each of her reasons. For example, the author of the post shown in <ref type="figure" target="#fig_0">Figure 1</ref> mentions two reasons why she supports abortion, namely it's a woman's right to abort and unwanted babies are threat to their par- ents' future, which are mentioned in the first and third sentences in the post respectively.</p><p>Our goal in this paper is to examine post-and sentence-level reason classification (RC) in ideo- logical debates. Many online debaters use emo- tional languages, which may involve sarcasm and insults, to express their points, thereby making RC and SC in ideological debates potentially more challenging than that in other debate settings such as congressional debates and company-internal discussions ( <ref type="bibr" target="#b32">Walker et al., 2012)</ref>.</p><p>Besides examining the new task of RC in ide- ological debates, we believe that our work makes three contributions. First, we propose to address post-level RC by means of sentence-level RC by (1) determining the reason(s) associated with each of its sentences (if any), and then (2) taking the union of the set of reasons associated with all of its sentences to be the set of reasons associated with the post. We hypothesize that this sentence-based approach, which exploits a training set in which each sentence in a post is labeled with its reason, would achieve better performance than a multi- label text classification approach to post-level RC, which learns to determine the subset of reasons a post contains directly from a training set in which each post is labeled with the corresponding set of reasons. In other words, we hypothesize that we could achieve better results for post-level RC by learning from sentence-level than from post-level reason annotations, as sentence-level reason anno- tations can enable a learning algorithm to accu- rately attribute an annotated reason to a particular portion of a post.</p><p>Second, we propose stance-supported RC sys- tems, hypothesizing that automatically computed stance information can be profitably exploited for RC. Since we are exploiting automatically com- puted (and thus potentially noisy) stance informa- tion, we hypothesize that the effectiveness of such information would depend in part on the way it is exploited in RC systems. As a result, we introduce a set of stance-supported models for RC, start- ing with simple pipeline models and then mov- ing on to joint models with increasing sophisti- cation. Note that exploiting stance information by no means guarantees that RC performance will improve, as an incorrect determination of stance could lead to an incorrect identification of rea- sons. Hence, one of our goals is to examine how to model stances and reasons so that RC can benefit from stance information.</p><p>Finally, since progress on RC is hindered in part by the lack of an annotated corpus, we make our reason-annotated dataset publicly available. 1 To our knowledge, this will be the first publicly avail- able corpus for sentence-and post-level RC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Corpus and Annotation</head><p>We collected debate posts from four popular domains, Abortion (ABO), Gay Rights (GAY), Obama (OBA), and Marijuana (MAR), from an online debate forum 2 . All debates are two-sided, so each post receives one of two stance labels, for or against, depending on whether the author of the post supports or opposes abortion, gay rights, Obama, or the legalization of marijuana respec- tively. A post's stance label is given by its author.</p><p>Note that each post belongs to a thread, which is a tree with one or more nodes such that (1) each node corresponds to a debate post, and (2) a post y i is the parent of another post y j if y j is a reply to y i . Given a thread, we generate post sequences, each of which is a path from the root of the thread to one of its leaves. Hence, a post sequence is an ordered set of posts such that each post is a reply to its immediately preceding post in the sequence. <ref type="table" target="#tab_2">Table 2a</ref> shows the statistics of the four stance- labeled datasets.</p><p>While the debate posts contain the stance labels given by their authors, they are not annotated with reasons. As part of our study of RC, we annotate each post with the reasons it gives for its stance. Our annotation procedure is composed of three steps. First, two human annotators independently examined each post and identified the reasons au- thors present to support their stances (i.e., for and against) in each domain. Second, they discussed and agreed on the reasons identified for each do- main. Third, they independently annotated the text of each post with reason labels from the post's do- main. To do this, they labeled each sentence of a post with the set of reasons the author expressed in that sentence. Any sentence that does not belong to any reason class was assigned the NONE class.</p><p>After the annotators completed the aforemen- tioned steps, they were asked to collapse all the reason classes that occur in less than 2% of the sentences annotated with non-NONE classes into the OTHER class. In other words, all the sentences that were originally annotated with one of these infrequent reason classes will now be labeled as OTHER. Our decision to merge infrequent classes is motivated by two observations. First, from a practical point of view, infrequent reasons do not carry much weight. Second, from a modeling per- spective, it is often not worth increasing model complexity by handling infrequent classes. The resulting set of reason classes for each domain is shown in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>A closer examination of the resulting annota- tions reveals that approximately 3% of the sen- tences received multiple reason labels. Again, to avoid the complexity of modeling multi-labeled    sentences given their rarity, we asked each annota- tor to pick the reason that was highlighted the most in each multi-labeled sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F1] Abortion is a woman's right (26%); [F2] Rape victims need it to be legal (7%); [F3] A fetus is not human (38%); [F4] Mother's life in danger (5%); [F5] Unwanted babies are ill-treated by parents (8%); [F6] Birth control fails at times (3%); [F7] Abortion is not murder (3%); [F8] Mother is not healthy/financially solvent (4%); [F9] Others (6%) against [A1] Put baby up for adoption (9%); [A2] Abortion kills a life (29%); [A3] An unborn baby is a human and has the right to live (40%); [A4] Be willing to have the baby if you have sex (14%); [A5] Abortion is harmful for women (5%); [A6] Others</head><p>Inter-annotator agreement scores at the sentence level and the post level, expressed in terms of Co- hen's Kappa <ref type="bibr" target="#b9">(Carletta, 1996)</ref>, are shown in Ta- ble 2b. Given that the majority of sentences were labeled as NONE, we avoid inflating agreement by not considering the sentences labeled with NONE by both annotators when computing Kappa. As we can see, we achieved substantial post-level agree- ment and high sentence-level agreement.</p><p>The major source of inter-annotator disagree- ment for all four datasets stems from the fact that in many cases, the annotators, while agreeing on the reason class, differ on how long the text span for a reason should be. This hurts sentence-level agreement but not post-level agreement, since the latter only concerns whether a reason was men- tioned in a post, and explains why the sentence- level agreement scores are lower than the corre- sponding post-level scores. Minor sources of dis- agreement arise from the facts that (1) the anno- tators selected different reason labels for some of the multi-labeled sentences, and (2) they tend to disagree in some cases where authors use sarcasm  to present a reason. Each case of disagreement is resolved through discussion among the annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Baseline RC System</head><p>Our baseline system uses a maximum entropy (MaxEnt) classifier to determine whether a reason is expressed in a post and/or its sentence(s). We create one training instance for each sentence in each post in the training set, using the reason label as its class label. We represent each instance using five types of features, as described below.</p><p>N-gram features. We encode each unigram and bigram collected from the training sentences as a binary feature indicating the n-gram's presence or absence in a given sentence.</p><p>Dependency-based features. To capture the inter-word relationships that n-grams may not, we employ the dependency-based features previ- ously used for stance classification in <ref type="bibr" target="#b1">Anand et al. (2011)</ref>. These features have three variants. In the first variant, the pair of arguments involved in each dependency relation extracted by a depen- dency parser is used as a feature. The second vari- ant is the same as the first except that the head (i.e., the first argument in a relation) is replaced by its part-of-speech tag. The features in the third vari- ant, the topic-opinion features, are created by re- placing each sentiment-bearing word in features of the first two types with its corresponding polarity label (i.e., + or −).</p><p>Frame-semantic features. While dependency- based features capture the syntactic dependencies, frame-semantic features encode the semantic rep- resentation of the concepts in a sentence. Fol- lowing our previous work on stance classification (Hasan and Ng, 2013c), we employ three types of features computed based on the frame-semantic parse of each sentence in a post obtained from SE- MAFOR ( <ref type="bibr" target="#b10">Das et al., 2010)</ref>. Frame-word interac- tion features encode whether two words appear in different elements of the same frame. Hence, each frame-word interaction feature consists of (1) the name of the frame f from which it is created, and (2) an unordered word pair in which the words are taken from two frame elements of f . A frame-pair feature is represented as a word pair corresponding to the names of two frames and encodes whether the target word of the first frame appears within an element of the second frame. Finally, frame n- gram features are a variant of word n-grams. For each word n-gram in the sentence, a frame n-gram feature is created by replacing one or more words in the word n-gram with the name of the frame or the frame element in which the word appears. A detailed description of these features can be found in Hasan and Ng (2013c).</p><p>Quotation features. We employ two quotation features. IsQuote is a binary feature that indicates whether a sentence is a quote or not (i.e., whether it appeared in its parent post in the post sequence).</p><p>Note that if an instance is a quote from a previ- ous post, it is unlikely that it represents a reason the author is presenting to support her argument. Instead, the author may have quoted this before stating her counter-argument. FollowsQuote is a binary feature that indicates whether a sentence follows a sentence for which the IsQuote feature value is true. Intuitively, a sentence following a quote is likely to present a counter-argument.</p><p>Positional feature. We split each post into four parts (such that each part contains roughly the same number of sentences) and create one posi- tional feature that encodes which part of the post contains a given sentence. This feature is moti- vated by our observations on the training data that (1) reasons are more likely to appear in the second half of a post and (2) on average more than one- third of the reasons appear in the last quarter of a post.</p><p>After training, we can apply the resulting RC system to classify the test instances, which are generated in the same way as the training in- stances. Once the sentences of a test post are clas- sified, we simply assume its post-level reason la- bels to be the set of reason labels assigned by the classifier to its sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Stance-Supported RC Systems</head><p>In this section, we propose a set of systems for RC. Unlike the baseline RC system, these RC systems are stance-supported, enabling us to ex- plore how different ways of modeling automati- cally computed stances and reasons can improve RC classification. Below we present our systems in increasing order of modeling sophistication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pipeline Systems</head><p>We examine two pipeline systems, P1 and P2. Given a set of test posts, both systems first de- termine the stance of each post and then apply a stance-specific reason classifier to each of them.</p><p>More specifically, both P1 and P2 employ two stance-specific reason classifiers: one is trained on all the posts labeled as for and the other is trained on all the posts labeled as against. Each stance- specific reason classifier is trained using MaxEnt on the same feature set as that of the Baseline RC system. It computes for a particular stance s the probability P (r|s, t), where r is a reason label and t is a sentence in a test post p.</p><p>P1 and P2 differ only with respect to the SC model used to stance-label each post. In P1, the stance s of a post p is determined by applying to p a stance classifier that computes P (s|p). To train the classifier, we employ MaxEnt. Each train-ing instance corresponds to a training post and is represented by all but the quotation and posi- tional features used to train the Baseline RC sys- tem, since these two feature types are sentence- based rather than post-based. After training, the resulting classifier can be used to stance-label a post independently of the other posts.</p><p>In P2, on the other hand, we recast SC as a se- quence labeling task. In other words, we train a SC model that assumes as input a post sequence and outputs a stance sequence, with one stance la- bel for each post in the input post sequence. This choice is motivated by an observation we made previously ( <ref type="bibr" target="#b12">Hasan and Ng, 2013a)</ref>: since each post in a sequence is a reply to the preceding post, we could exploit their dependencies by determining their stance labels together. <ref type="bibr">3</ref> As our sequence learner, we employ a maxi- mum entropy Markov model (MEMM) <ref type="bibr" target="#b16">(McCallum et al., 2000</ref>). Given an input post sequence P S = (p 1 , p 2 , . . . , p n ), the MEMM finds the most probable stance sequence S = (s 1 , s 2 , . . . , s n ) by computing P (S|P S ), where:</p><formula xml:id="formula_0">P (S|P S ) = n k=1 P (s k |s k−1 , p k )<label>(1)</label></formula><p>This probability can be computed efficiently via dynamic programming (DP), using a modified ver- sion of the Viterbi algorithm <ref type="bibr" target="#b31">(Viterbi, 1967)</ref>.</p><p>There is a caveat, however. Recall that the post sequences are generated from a thread. Since a test post may appear in more than one sequence, different occurrences of it may be assigned differ- ent stance labels by the MEMM. To determine the final stance label for the post, we average the prob- abilities assigned to the for stance over all its oc- currences; if the average is ≥ 0.5, then its final label is for; otherwise, its label is against.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">System based on Joint Inference</head><p>One weakness of the pipeline systems is that errors may propagate from the SC system to the RC sys- tem. If the stance of a post is incorrectly labeled, its reasons will also be incorrectly labeled.</p><p>To avoid this problem, we employ joint infer- ence. Specifically, we first train a SC system and a RC system independently of each other. We em- ploy the Baseline as our RC system, since this is the only RC system that is not stance-specific. For the SC system, we employ P2.</p><p>Since the SC system and the RC system are trained independently of each other, their outputs may not be consistent. For instance, an inconsis- tency arises if a post is labeled as for but one or more of its reasons are associated with the oppos- ing stance. In fact, an inconsistency can arise in the output of the RC system alone: reasons associ- ated with both stances may be assigned by the RC systems to different sentences of a given post.</p><p>To enforce consistency, we apply integer lin- ear programming (ILP) ( <ref type="bibr" target="#b22">Roth and Yih, 2004</ref></p><note type="other">). We formulate one ILP program for each debate post. Each ILP program contains two post-stance vari- ables (x f or and x against ) and |T | * |L R | reason variables (i.e., one indicator variable z t,r for each reason class r and each sentence t), where |T | is the number of sentences in the post and |L R | is the number of reason labels. Our objective is to maxi- mize the linear combination of these variables and their corresponding probabilities assigned by their respective classifiers (see (2)</note><p>below) subject to two types of constraints, the integrity constraints and the post-reason constraints. The integrity con- straints ensure that each post is assigned exactly one stance and each sentence in a post is assigned exactly one reason class (see the two equality con- straints in (3)). The post-reason constraints ensure consistency between the predictions made by the SC and the RC systems. Specifically, (1) if there is at least one reason supporting the for stance, the post must be assigned a for label; and (2) a for post must have at least one for reason. These con- straints are defined for the against label as well (see the constraints in (4)).</p><p>Maximize:</p><formula xml:id="formula_1">s∈L S a s x s + 1 |T | |T | t=1 r∈L R b t,r z t,r<label>(2)</label></formula><p>subject to:</p><formula xml:id="formula_2">s∈L S x s = 1, ∀ t r∈L R z t,r = 1, x s ∈ {0, 1}, z t,r ∈ {0, 1}<label>(3)</label></formula><formula xml:id="formula_3">∀ t x s ≥ z t,r , |T | t=1 z t,r ≥ x s<label>(4)</label></formula><p>Note that (1) a s and b t,r are two sets of probabil- ities assigned by the SC and RC systems respec- tively; (2) L S and L R denote the set of stance labels and reason labels respectively; and (3) the fraction 1 |T | ensures that both classifiers are con- tributing equally to the objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Systems based on Joint Learning</head><p>Another way to avoid the error propagation prob- lem in pipeline systems is to perform joint learn- ing. In joint learning, the two tasks, SC and RC, are learned jointly. Below we propose three joint models in increasing level of sophistication.</p><p>J1 is a joint model that, given a test post p, finds the stance label s and the reason label for each of the sentences that together maximize the probabil- ity P (R p , s|p), where R p = (r 1 , r 2 , . . . , r n ) is the sequence of reason labels with r i (1 ≤ i ≤ n) being the reason label assigned to t i , the i-th sen- tence in p. Using Chain Rule,</p><formula xml:id="formula_4">P (R p , s|p) = P (s|p)P (R p |s, p) = P (s|p) n i=1 P (r i |s, t i )<label>(5)</label></formula><p>Hence, P (R p , s|p) can be computed by using the stance-specific RC classifier and the SC classi- fier employed in P1.</p><p>The second joint model, J2, is the same as J1, except that we recast SC as a sequence la- beling task. As before, we employ MEMM to learn how to predict stance sequences. Given a post sequence P S = (p 1 , p 2 , . . . , p n ), J2 finds the stance sequence S = (s 1 , s 2 , . . . , s n ) and rea- sons R = (R 1 , R 2 , . . . , R n ) that jointly maximize P (R, S|P S ). Note that R i is the sequence of rea- son labels assigned to the sentences in post i.</p><p>The R and S that jointly maximize P (R, S|P S ) can be found efficiently via DP, using a modified version of the Viterbi algorithm. Unlike in P2, in J2 the decoding process is slightly more compli- cated because we have to take into account R i . Be- low we show the recursive definitions used to com- pute the entries in the DP table, where v k (h) is the (k,h)-th entry of the table; P (h|p) is provided by the MaxEnt stance classifier used in P1; P (h|j, p) is provided by the MEMM stance classifier used in P2; P (r max i |h, t i ) is provided by the stance- specific reason classifier used in the pipeline sys- tems; and r max i is the reason label for sentence t i that has the highest probability according to the reason classifier.</p><p>Base case:</p><formula xml:id="formula_5">v 1 (h) = P (h|p) n i=1 P (r max i |h, t i )<label>(6)</label></formula><p>Recursive definition:</p><formula xml:id="formula_6">v k (h) = max j v k−1 (j)P (h|j, p) n i=1 P (r max i |h, t i )<label>(7)</label></formula><p>To motivate our third joint model, J3, we make the following observation. Recall that a post in a post sequence is a reply to its preceding post. An inspection of the training data reveals that in many cases, a reply is a rebuttal to the preced- ing post, where an author attempts to argue why the points or reasons raised in the preceding post are wrong and then provides her reasons for the opposing stance. Motivated by this observation, we hypothesize that the reasons mentioned in the preceding post could be useful for predicting the reasons in the current post. However, none of the models we have presented so far makes use of the reasons predicted for the preceding post.</p><p>This motivates the design of J3, which we build on top of J2. Specifically, to incorporate the reason labels predicted for the preceding post in a post se- quence, we augment the feature set of the stance- specific reason classifiers with a set of reason fea- tures, with one binary feature for each reason. The value of a reason feature is 1 if and only if the cor- responding reason is predicted to be present in the preceding post. Hence, in J3, we can apply the same DP equations we used in J2 except that the set of features used by the reason classifier is aug- mented with the reason features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>While our primary goal is to evaluate the RC sys- tems introduced in the previous section, we are also interested in whether SC performance can im- prove when SC is jointly modeled with RC. More specifically, our evaluation is driven by the follow- ing question: will RC performance and SC perfor- mance improve as we employ more sophisticated methods for modeling reasons and stances? Be- fore showing the results, we describe the metrics for evaluating RC and SC systems.   <ref type="table">Table 3</ref>: SC accuracies and RC F-scores for our five-fold cross-validation experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>We express SC results in terms of accuracy (i.e., the percentage of test posts labeled with the cor- rect stance) and RC results in terms of F-score micro-averaged over all reason classes except the NONE class. For each RC system, we report its sentence-level RC score and post-level RC score, which are computed over sentences and posts re- spectively. As mentioned at the end of Section 3, the set of post-level reason labels of a given post is automatically obtained by taking the union of the set of reason labels assigned to each of its sen- tences. Hence, a reason classifier will be rewarded as long as it can predict, for any sentence in a test post, a reason label that the annotators assigned to some sentence in the same post. We obtain these scores via five-fold cross- validation experiments. During fold partition, all posts that are in the same post sequence are as- signed to the same fold. All reason and stance classifiers are domain-specific, meaning that each of them is trained on sentences/posts from ex- actly one domain and is applied to classify sen- tences/posts from the same domain. We use the Stanford maximum entropy classifier 4 for classifi- cation and solve ILP programs using lpsolve 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and Discussion</head><p>Results are shown in <ref type="table">Table 3</ref>. Each row corre- sponds to one of our seven RC systems, showing its SC accuracy as well as its sentence-and post- level RC F-scores for each domain.</p><p>Let us begin by discussing the RC results. First, P1 and P2 significantly beat the Baseline on all four domains by an average of 1.4 and 3.1 points at the sentence level and by an average of 2.3 and 3.8 points at the post level respectively. <ref type="bibr">6</ref> These re- sults show that stance information can indeed be profitably used for RC even if it is incorporated into RC systems in a simple manner. Second, improving SC through sequence learning can im- prove RC: the systems in which SC is recast as se- quence labeling (P2 and J2) perform significantly better than the corresponding systems that do not (P1 and J1). Third, ILP significantly beats P2 on two domains (ABO and GAY) and achieves the same level of performance as P2 on the remain- ing domains. These results suggest that joint infer- ence is no worse (and sometimes even better) than pipeline learning as far as exploiting stance infor- mation for RC is concerned. Fourth, the systems trained via joint learning (J1 and J2) beat their cor- responding pipeline counterparts (P1 and P2) on all four domains, significantly so by an average of 2.3 and 2.5 points at the sentence level and by an average of 2.0 and 2.6 points at the post level re- spectively, suggesting that joint learning is indeed a better way to incorporate stance information than pipeline learning. Finally, J3, the joint system that exploits reasons predicted for the previous post, significantly beats J2, the system on which it is built, by 1.6 and 1.8 points at the sentence level and by 1.7 and 1.3 points at the post level for ABO and GAY respectively. It also yields small, statis- tically insignificant, improvements (0.6 points at the sentence level and 0.6-0.9 points at the post level) for the remaining two domains. These re- sults suggest that the reasons predicted for the pre- vious post indeed provide useful information for predicting the current post's reasons.</p><p>Overall, these results are consistent with our hy-pothesis that the usefulness of stance information depends in part on the way it is exploited, and that RC performance increases as we employ more sophisticated methods for modeling reasons and stances. Our best system, J3, significantly beats the Baseline by an average of 6.7 and 7.5 points at the sentence and post levels respectively. As mentioned earlier, a secondary goal of this work is to determine whether joint modeling can improve SC as well. For that reason, we com- pare the performances of the best pipeline model (P2) and the best joint model (J3) on each domain. We find that in terms of SC accuracy, J3 is signifi- cantly better than P2 on ABO and GAY, and yields slightly, though insignificantly, better performance on the remaining two domains. In other words, our results suggest that joint modeling of SC and RC has a positive impact on SC performance on all domains, and the impact can sometimes be large enough to yield significantly better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Further Comparison</head><p>We hypothesized in the introduction that the sentence-based approach to post-level RC would yield better performance than the multi-label text classification approach. In Section 5.2, we pre- sented results of the sentence-based approach to RC. So, to test this hypothesis, we next evaluate the multi-label text classification approach to RC.</p><p>Recall that the multi-label text classification ap- proach assumes the following setup. Given a set of training posts where each post is multi-labeled with the set of reasons it contains, the goal is to train a system to determine the set of reasons a test post contains. Hence, unlike in the sentence- based approach, in this approach no sentence-level reason annotations are exploited during training.</p><p>We implement this approach by recasting multi- label text classification as n binary text classifica- tion tasks, where n is the number of reason classes for a domain. In the binary classification task for predicting reason i, we train a binary classifier c i using the one-versus-all training scheme. Specif- ically, to train c i , we create one training instance for each post p in the training set, labeling it as positive if and only if p contains reason i. Note that if i is a minority reason, the class distribution of the resulting training set will be highly skewed towards the negatives, which will in turn cause the resulting MaxEnt classifier to be biased towards predicting a test instance as negative.</p><p>To address this problem, we adjust the classifi- cation thresholds associated with the binary classi- fiers. Recall that a test instance is classified as pos- itive by a binary classifier if and only if its prob- ability of belonging to the positive class is above the classification threshold used. Hence, adjusting the threshold amounts to adjusting the number of test instances classified as positive, thus address- ing the bias problem mentioned above. Specifi- cally, we adjust the thresholds of the classifiers as follows. We train the binary classifiers to optimize the overall F-score by jointly tuning their classifi- cation thresholds on 25% of the training data re- served for development purposes. Since comput- ing the exact solution to this optimization prob- lem is computationally expensive, we employ a lo- cal search algorithm that changes the value of one threshold at a time to optimize F-score while keep- ing the remaining thresholds fixed. During testing, classifier c i will classify a test instance as positive if its probability of belonging to the positive class is above the corresponding threshold.</p><p>We apply this multi-label text classification ap- proach to obtain post-level RC scores for the Base- line, P1 and P2. Note that since P1 and P2 are pipeline systems, the binary classifiers they use to predict a test post's reasons depend on the post's predicted stance. Specifically, if a test post is pre- dicted to have a positive (negative) stance, then only the reason classifiers associated with the pos- itive (negative) stance will be used to predict the reasons it contains. On the other hand, this ap- proach cannot be used in combination with ILP or the joint models to produce post-level RC scores: they all require a reason classifier trained on reason-annotated sentences, which are not avail- able in the multi-label text classification approach.</p><p>Post-level RC results of the Baseline and the two pipeline systems, P1 and P2, obtained via this multi-label text classification approach are shown in <ref type="table">Table 4</ref>. These scores are significantly lower than the corresponding scores in <ref type="table">Table 3</ref> by 3.2, 2.9, and 3.1 points for the Baseline, P1, and P2 re- spectively, when averaged over the four domains. They confirm our hypothesis that the sentence- based approach to post-level RC is indeed better than its multi-class text classification counterpart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Error Analysis</head><p>To get a better understanding of our best- performing RC system (J3), we examine its major System ABO GAY OBA MAR Baseline 39.8 37.9 30.1 40.8 P1 41.5 41.0 31.7 44.7 P2</p><p>43.3 42.6 32.0 46.3 <ref type="table">Table 4</ref>: Post-level RC F-scores obtained via the multi-class text classification approach.</p><p>sources of error in this subsection. For the four domains, 75-83% of the errors can be attributed to the system's inability to de- cide whether a sentence describes a reason or not. Specifically, in 51-54% of the erroneous cases, a reason sentence is misclassified as NONE. On the other hand, 23-30% of the cases are concerned with assigning a reason label to a NONE sentence. The remaining 17-25% of the errors concern mis- labeling a reason sentence with the wrong reason.</p><p>A closer examination of the errors reveals that they resulted primarily from (1) the lack of access to background knowledge, (2) the failure to pro- cess complex discourse structures, and (3) the fail- ure to process sarcastic statements and rhetorical questions. We present two examples for each of these three major sources of error from the ABO and OBA domains in <ref type="table" target="#tab_5">Table 5</ref>. In each example, we show their predicted (P) and gold (G) labels.</p><p>Lack of access to background knowledge. Consider the first example for ABO in <ref type="table" target="#tab_5">Table 5</ref>. Our system misclassifies this sentence in part be- cause it lacks the background knowledge that "ge- netic code" is one of the characteristics of life and a fetus having it means a fetus has life (A3). Sim- ilarly, the system cannot determine the reason for the first OBA example without the knowledge that "deficit spending" is a term related to the econ- omy and that increasing it is bad (A1). We believe some of these relations can be extracted from lex- ical knowledge bases such as YAGO2 ( <ref type="bibr" target="#b24">Suchanek et al., 2007)</ref>, <ref type="bibr">Freebase (Bollacker et al., 2008)</ref>, and BabelNet ( <ref type="bibr" target="#b18">Navigli and Ponzetto, 2012</ref>).</p><p>Failure to process complex discourse struc- tures. Our system misclassifies the second ex- ample for ABO in part because the first part of the sentence (i.e., Sure, the fetus has the potential to one day be a person) expresses a meaning that is completely inverted by the second part. Such complex discourse structures often lead to classi- fication errors even for sentences whose interpre- tation requires no background knowledge. We be- lieve that this problem can be addressed in part by a better understanding of the structure of a dis- course, particularly the relation between two dis- course segments, using a discourse parser. Failure to process sarcastic statements and rhetorical questions. Owing to the nature of our dataset (i.e., debate posts), many errors arise from sentences containing sarcasm and/or rhetori- cal questions. This is especially a problem in long post sequences, where authors frequently restate their opponents' positions, sometimes ironically. A first step towards handling these errors would therefore be to identify sentences containing sar- casm and/or rhetorical questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>In this section, we discuss related work in the areas of document-level RC, argument recognition, tex- tual entailment in online debates, argumentation mining, and sentiment analysis. Document-level reason classification. <ref type="bibr" target="#b21">Persing and Ng (2009)</ref> apply a multi-label text classifi- cation approach to document-level RC of aviation safety incident reports. Given a set of pre-defined reasons, their RC system seeks to identify the rea- sons that can explain why the incident described in a given report occurred. Their work is dif- ferent from ours in at least two respects. First, while our posts occur in post sequences (which can be profitably exploited in RC, for example, as in J3), their incident reports were written indepen- dently of each other. Second, they do not perform sentence-level RC, as the lack of sentence-level reason annotations in their dataset prevented them from training a sentence-level reason classifier. Argument recognition. Boltuži´Boltuži´c andŠnajderandˇandŠnajder (2014) propose a multi-class classification task called argument recognition in online discussions. Given a post and a reason for a particular domain, the task is to predict the extent to which the au- thor of the post supports or opposes the reason as measured on a five-point ordinal scale rang- ing from "explicitly supports" to "explicitly op- poses". Hence, unlike RC, argument recognition focuses on the magnitude rather than the exis- tence of a post-reason relationship. In addition, Boltuži´Boltuži´c andŠnajderandˇandŠnajder focus on post-level (rather than sentence-level) classification and employ per- fect (rather than predicted) stance information. Textual entailment in online debates. Given the title of a debate and a post written in re- sponse to it, this task seeks to detect arguments in <ref type="table">Domain   Background knowledge  Complex discourse structure  Sarcasm/rhetorical questions  Example  P  G  Example  P  G  Example  P  G  ABO Science does agree that  the fetus has an individ- ual genetic code and fits  into the biological defi- nition of life.</ref> NONE A3 Sure, the fetus has the potential to one day be a person, but right now it is not.  the post that entail or contradict the title <ref type="bibr" target="#b8">(Cabrio and Villata, 2012</ref>). Hence, this task is concerned with identifying text segments that correspond to rationales without a predefined set of rationales, whereas RC is concerned with both identifying text segments and classifying them based on a given set of reasons. Argumentation mining. The goal of this task is to extract the argumentative structure of a docu- ment. Researchers have proposed approaches to mine the structure of scientific papers <ref type="bibr" target="#b25">(Teufel and Moens, 2000;</ref><ref type="bibr" target="#b27">Teufel, 2001</ref>), product reviews <ref type="bibr" target="#b30">(Villalba and Saint-Dizier, 2012;</ref><ref type="bibr" target="#b35">Wyner et al., 2012)</ref>, newspaper articles ( <ref type="bibr" target="#b11">Feng and Hirst, 2011)</ref>, and le- gal documents <ref type="bibr" target="#b6">(Brüninghaus and Ashley, 2005;</ref><ref type="bibr" target="#b34">Wyner et al., 2010;</ref><ref type="bibr" target="#b19">Palau and Moens, 2011;</ref><ref type="bibr" target="#b2">Ashley and Walker, 2013)</ref>. A major difference be- tween this task and RC is that the argument types refer to generic structural cues, textual patterns etc., whereas our reason classes refer to the spe- cific reasons an author may mention to support her stance in a domain. For instance, in the case of a scientific article, the argument types correspond to general background, description of the paper's or some other papers' approach, objective, con- trastive and/or comparative comments, etc. <ref type="bibr" target="#b25">(Teufel and Moens, 2000</ref>). The argument types for legal documents refer to legal factors which are either pro-plaintiff or pro-defendant <ref type="bibr" target="#b6">(Brüninghaus and Ashley, 2005</ref>). For instance, for trade secret law cases, factors such as Waiver-of-Confidentiality and Disclosure-in-Public-Forum refer to certain facts strengthening the claim of one of the sides participating in a case. Sentiment analysis. RC resembles certain tasks in sentiment analysis. One such task is pro and con reason classification in reviews ( <ref type="bibr" target="#b15">Kim and Hovy, 2006</ref>), where sentences containing opinions as well as reasons justifying the opinions are to be extracted and classified as PRO, CON, or NONE.</p><p>Hence, this task focuses on categorizing sentences into coarse-grained, high-level groups (e.g., PRO vs. CON, POSITIVE vs. NEGATIVE), but does not attempt to subcategorize the PRO and CON classes into fine-grained reason classes, unlike RC. Some- what similar to the PRO and CON sentence classifi- cation task is the task of determining the relevance of a sentence in a review for polarity classifica- tion. <ref type="bibr" target="#b37">Zaidan et al. (2007)</ref> coined the term ratio- nale to refer to any subjective textual content that contains evidence supporting the author's opinion or stance. These rationales, however, may not al- ways contain reasons. For instance, a sentence that mentions that the author likes a product is a ra- tionale, but it does not contain any reason for her liking it. Methods have been proposed for auto- matically identifying rationales (e.g., <ref type="bibr" target="#b36">Yessenalina et al. (2010)</ref>, <ref type="bibr" target="#b29">Trivedi and Eisenstein (2013)</ref>) and distinguishing subjective from objective materials in a review (e.g., <ref type="bibr" target="#b20">Pang and Lee (2004)</ref>, <ref type="bibr" target="#b33">Wiebe and Riloff (2005)</ref>, <ref type="bibr" target="#b17">McDonald et al. (2007)</ref>, <ref type="bibr" target="#b38">Zhao et al. (2008)</ref>). Note that in all these attempts, the end goal is not to classify sentences, but to employ the results of sentence classification to improve a higher-level task, such as sentiment classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We examined the new task of reason classification. We exploited stance information for reason classi- fication, proposing systems of varying complexity for modeling stances and reasons. Experiments on our reason-annotated corpus of ideological debate posts from four domains demonstrate that sophis- ticated models of stances and reasons can indeed yield more accurate reason and stance classifica- tion results than their simpler counterparts. Nev- ertheless, reason classification remains a challeng- ing task: the best post-level F-scores are in the low 50s. By making our corpus publicly available, we hope to stimulate further research on this task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A sample post on abortion annotated with reasons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>(</head><label></label><figDesc>b) Statistics of reason-labeled posts</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>System</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Reason classes and their percentages in the corresponding stance for each domain.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Stance and reason annotation statistics.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Examples of the major sources of error. P and G stand for predicted tag and gold tag respectively. 

</table></figure>

			<note place="foot" n="1"> http://www.hlt.utdallas.edu/ ˜ saidul/ stance/ 2 http://www.createdebate.com/</note>

			<note place="foot" n="3"> While we could similarly recast the problem of assigning reasons to the sentences in a post as a sequence learning task, we did not pursue this idea further because preliminary experiments indicated that sequence learning for RC was ineffective: there is little, if any, dependency between the reason labels in consecutive sentences.</note>

			<note place="foot" n="4"> http://nlp.stanford.edu/software/ classifier.shtml 5 http://sourceforge.net/projects/ lpsolve/</note>

			<note place="foot" n="6"> All significance tests are paired t-tests (p &lt; 0.05).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the three anonymous reviewers for their detailed and insightful comments on an earlier draft of this paper. This work was supported in part by NSF Grants IIS-1147644 and IIS-1219142. Any opinions, findings, conclusions or recommen-dations expressed in this paper are those of the au-thors and do not necessarily reflect the views or of-ficial policies, either expressed or implied, of NSF.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mining newsgroups using networks arising from social behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakesh</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishnan</forename><surname>Sridhar Rajagopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yirong</forename><surname>Srikant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on World Wide Web</title>
		<meeting>the 12th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="529" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cats rule and dogs drool!: Classifying stance in online debate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">E</forename><surname>Fox Tree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robeson</forename><surname>Bowmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Minor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis</title>
		<meeting>the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">From information retrieval (IR) to argument retrieval (AR) for legal cases: Report on a baseline study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vern</forename><forename type="middle">R</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Legal Knowledge and Information System</title>
		<meeting>the 26th International Conference on Legal Knowledge and Information System</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The power of negative thinking: Exploiting label disagreement in the min-cut classification framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2008: Companion volume: Posters</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="15" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2008 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Back up your stance: Recognizing arguments in online discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Boltuži´boltuži´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Snajder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="49" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reasoning with textual cases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Brüninghaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Ashley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Case-Based Reasoning</title>
		<meeting>the 6th International Conference on Case-Based Reasoning</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="137" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Collective classification of congressional floor-debate transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clinton</forename><surname>Burfoot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1506" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Natural language arguments: A combined approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th European Conference on Artificial Intelligence</title>
		<meeting>the 20th European Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="205" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Assessing agreement on classification tasks: The Kappa statistic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Carletta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="254" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">SEMAFOR 1.0: A probabilistic frame-semantic parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno>CMU-LTI-10-001</idno>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Classifying arguments by scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Vanessa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="987" to="996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Extralinguistic constraints on stance recognition in ideological debates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saidul</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="816" to="821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Frame semantics for stance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saidul</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Computational Natural Language Learning</title>
		<meeting>the Seventeenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="124" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Stance classification of ideological debates: Data, models, features, and constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saidul</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Joint Conference on Natural Language Processing</title>
		<meeting>the Sixth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1348" to="1356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic identification of pro and con reasons in online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Soo-</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL Main Conference Poster Sessions</title>
		<meeting>the COLING/ACL Main Conference Poster Sessions</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="483" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Maximum entropy Markov models for information extraction and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayne</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Machine Learning</title>
		<meeting>the 17th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="591" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Structured models for fine-to-coarse sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kerry</forename><surname>Hannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Neylon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Reynar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="432" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="217" to="250" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Argumentation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><forename type="middle">Mochales</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semi-supervised cause identification from aviation safety reports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Persing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="843" to="851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A linear programming formulation for global inference in natural language tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Conference on Computational Natural Language Learning</title>
		<meeting>the Eighth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recognizing stances in online debates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swapna</forename><surname>Somasundaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="226" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">YAGO: A core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International World Wide Web Conference</title>
		<meeting>the 16th International World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">What&apos;s yours and what&apos;s mine: Determining intellectual attribution in scientific text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<title level="m">Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora</title>
		<imprint>
			<biblScope unit="page" from="9" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Task-based evaluation of summary quality: Describing relationships between scientific papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Workshop on Automatic Summarization</title>
		<meeting>the NAACL Workshop on Automatic Summarization</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="12" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Get out the vote: Determining support or opposition from congressional floor-debate transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="327" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Discourse connectors for latent subjectivity in sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakshit</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="808" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Some facets of argument mining for opinion analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Paz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garcia</forename><surname>Villalba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Saint-Dizier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Computational Models of Argument</title>
		<meeting>the Fourth International Conference on Computational Models of Argument</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="23" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Error bounds for convolutional codes and an asymptotically optimum decoding algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Viterbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="260" to="269" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Stance classification using dialogic properties of persuasion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><surname>Grant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="592" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Creating subjective and objective sentence classifiers from unannotated texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Computational Linguistics and Intelligent Text Processing</title>
		<meeting>the 6th International Conference on Computational Linguistics and Intelligent Text Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="486" to="497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Approaches to text mining arguments from legal cases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Wyner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Mochales-Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Milward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic Processing of Legal Texts: Where the Language of Law Meets the Law of Language</title>
		<editor>Enrico Francesconi, Simonetta Montemagni, Wim Peters, and Daniela Tiscornia</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="60" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Semi-automated argumentative analysis of online product reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Wyner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jodi</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Computational Models of Argument</title>
		<meeting>the Fourth International Conference on Computational Models of Argument</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
	<note>Bench-Capon</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Automatically generating annotator rationales to improve sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ainur</forename><surname>Yessenalina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010 Conference Short Papers</title>
		<meeting>the ACL 2010 Conference Short Papers</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="336" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Using &quot;annotator rationales&quot; to improve machine learning for text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Zaidan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Piatko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies 2007: The Conference of the North American Chapter</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="260" to="267" />
		</imprint>
	</monogr>
	<note>Proceedings of the Main Conference</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Adding redundant features for crfs-based sentence sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gen</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
