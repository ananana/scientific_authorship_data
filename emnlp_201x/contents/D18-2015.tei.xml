<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sisyphus, a Workflow Manager Designed for Machine Translation and Automatic Speech Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Thorsten</forename><surname>Peter</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">RWTH-Aachen University Templergraben 55</orgName>
								<address>
									<postCode>52062</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Beck</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">RWTH-Aachen University Templergraben 55</orgName>
								<address>
									<postCode>52062</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">RWTH-Aachen University Templergraben 55</orgName>
								<address>
									<postCode>52062</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sisyphus, a Workflow Manager Designed for Machine Translation and Automatic Speech Recognition</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations)</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations) <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="84" to="89"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>84</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Training and testing many possible parameters or model architectures of state-of-the-art machine translation or automatic speech recognition system is a cumbersome task. They usually require a long pipeline of commands reaching from pre-processing the training data to post-processing and evaluating the output. This paper introduces Sisyphus, a tool that aims at managing scientific experiments in an efficient way. After defining the workflow for a given task, Sisyphus runs all required steps and ensures that all commands finish successfully. It avoids unnecessary computations by reusing tasks that are needed for multiple parts of the workflow and saves the user time by determining the order in which the tasks are to be performed. Since the program and work-flow are written in Python they can be easily extended to contain arbitrary code. This makes it possible to use the rich collection of Python tools for editing, debugging, and documentation. It only has few requirements on the underlying server or cluster, and has been successfully tested in many large scale setups and can handle thousands of tasks inside the work-flow.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Building competitive machine learning systems requires the correct execution of many different commands and components.</p><p>For example, a machine translation system needs to pre-process the data, train a neural net- work, and its performance evaluated. Each of these steps can contain a large number of separate steps. Running and later replicating all steps by hand is cumbersome and error-prone.</p><p>A common approach to reduce these problems is to create ad-hoc scripts for each given task. Al- though this can be a solution for some parts of the process, it is inflexible when changing workflows as often as required in research. Additionally, er- rors are easily overlooked when running a large number of scripts in parallel.</p><p>Sisyphus is written to ensure that tasks can be easily repeated and offers an overview of large ex- periment setups with a vast number of steps. Or- ganizing the work this way also allows the user to easily reconfigure experiment and reuse tested sub-tasks in other workflows. It is designed to han- dle large and complicated workflows, containing ten thousands of tasks in practice.</p><p>Finding a good naming scheme for multiple related experiments is also hard, since initially good choices often turn out to grow into strange constructs as new experiments are added over time resulting in names like "ExperimentA-withB- withoutC-D=6-version3". Sisyphus maps all jobs to a unique path and can create links bearing de- scriptive names. This allows the user to rename everything without violating any dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Basic Assumption</head><p>In Sisyphus, workflows are broken down into sub- tasks called "Jobs". A job performs a specific function, e.g. evaluating a translation, it often re- quires an external script or program. Sisyphus is built on one main assumption: Any job only re- lies on a given list of parameters. e.g. evaluating a translation depends on the hypothesis, the refer- ence, and optionally a script.</p><p>This property is used to avoid multiple compu- tations of the same job. Randomness is best mod- eled using seeds that are given via the job param- eters to allow for reliable reproducible results. If this is not possible, e.g. for asynchronous neural network training, Sisyphus still works, but cannot be guaranteed to to reproduce the exact same re- sult.</p><p>This means that the automatic handling of changing input files is beyond the scope of Sisy- phus. If an input file changes, it is necessary to manually tell Sisyphus to invalidate all jobs that depend on it. Since a reliable test, e.g. hashing, would be too costly to run for each startup, since it can take a long time on large files like the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Design Goals</head><p>The design of Sisyphus is mainly guided by the problems that we encounter while building sta- tistical machine translation and automatic speech recognition systems. Sisyphus aims to address the following problems:</p><p>• Separation of the workflow description of an experiment and the place where the experi- ment is run: This allows the user to store the small description on an expensive but safe file server with backups, while the outputs of an experiment are stored on a larger, but less re- liable file system (Section 4.1 and 4.3).</p><p>• Reusability of jobs: Once a job is defined, it should be easy to use at a different position within the workflow.</p><p>• Minimal requirements on the underlying server structure: Sisyphus only requires Python 3 1 with a few basic packages and a Unix-type operating system.</p><p>• Work definition independent of underlying queuing engine: Moving it to a different en- gine should be easy, e.g. testing the workflow on a local computer before moving it to a grid engine.</p><p>• Avoid redundant computations to save time and disk space by grouping jobs with the same input arguments.</p><p>• Start all needed jobs automatically in the cor- rect order and, if no blocking dependencies are found, in parallel.</p><p>• Automatically check for errors and, if possi- ble, recover. Errors that occur silently some- where in the pipeline can cause strange re- sults and are hard to find. (Section 3.3)</p><p>• Be as general as possible and easy to extend:</p><p>The whole workflow definition is written in standard conforming Python. This allows for a lot of flexibility in defining a workflow and to use external tools written for Python e.g. to check and edit the workflow.</p><p>• The ability to integrate any external tool that has a command line interface into a job.</p><p>1 https://www.python.org/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A large variety of heavyweight workflow manage- ment systems exist, e.g. <ref type="bibr">Pegasus (Deelman et al., 2015)</ref>, <ref type="bibr">Taverna (Wolstencroft et al., 2013)</ref>, and <ref type="bibr">Kepler (Ludäscher et al., 2006</ref>). They can cover a large variety of use-cases ( <ref type="bibr" target="#b2">Liew et al., 2016</ref>), but their use is hindered by strict requirements on the users computing nodes. The toolkit that seems to be most similar to our approach is Ducttape 2 , the successor of LonnyBin <ref type="bibr" target="#b0">(Clark and Lavie, 2010)</ref>. It is well designed and covers many useful points. However, we miss a more flexible configuration of the workflow e.g. workflows that adjust to the outputs of finished jobs are not supported. This does not allow to trig- ger parts of the workflow only if current computa- tions show that they are required.</p><p>Ducttape uses branch points to distinguish be- tween different experiment settings. This creates a fairly intuitive directory structure, but does not depend on the true value given to each parameter. If a parameter of a step is changed, it still maps to the same directory. Additionally, long names collapse to a hash value, losing the benefit of in- tuitively named directories. Interruptions of Duct- tape automatically stop all current computations, which makes it problematic to add additional ex- periments to a running workflow.</p><p>Sisyphus contains an experimental script to convert Ducttape workflows into Sisyphus recipes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Basic Elements</head><p>Every workflow can be modeled as a series of jobs. The output of a job can be either files or param- eters (parameters can be seen as special case of files). This can be mapped to a directed acyclic graph where each node is a job and each edge is a file or parameter. The latter are either passed on to another job or returned as result of the workflow.</p><p>The user can request the necessary files and Sisyphus executes all jobs that are needed to com- pute them. All jobs that are part of the graph but are not required for the desired output are ignored. This graph structure, as shown in <ref type="figure">Figure 1</ref>, is sim- ilar to the approach followed by <ref type="bibr" target="#b0">(Clark and Lavie, 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Jobs</head><p>Jobs are the core element of Sisyphus, and are rep- resented by the nodes in the dependency graph. Every Job has specified inputs and outputs. When <ref type="figure">Figure 1</ref>: Example of a workflow as it is drawn by the web interface. Jobs can be grouped to blocks for a bet- ter visualization as it is done here with the stage data block and the pre-processing blocks. If a Job finishes successfully it is marked dark-green, running Jobs are marked in green-yellow, Jobs that are runnable but not running yet are marked blue, Jobs that have to wait for other Jobs to finish are marked yellow, and Jobs that failed are marked red. A block takes always the status of the most problematic Job, e.g. if one Job failed it is red, if all Jobs are finished it is green. Files that are shared between Jobs are colored aquamarine.</p><p>an instance of a Job is created all inputs need to be specified. However, they can be the output of another Job. Once a Job is completed, all of its outputs are guaranteed to be available for future computations.</p><p>After a Job is created, a hash value is computed based on the given input parameters. This hash is used to ensure that only one node is used to repre- sent the same computation. Additionally, it is used as part of the path inside the work directory (Sec- tion 4.3) associated with the Job. This directory contains log files, status files, the work directory and the output directory. All commands will be run in the work directory, which is initially empty.</p><p>A Job is executed as soon as all inputs are ready, meaning all Jobs that compute inputs are finished. Before its execution, a Job has the opportunity to request additional inputs. This can happen as a re- sponse to the content of the previously specified inputs, e.g. to implement an automatic parame- ter optimization. If the Job does not specify addi- tional inputs, it is scheduled for execution in the configured queueing system. An example Job definition is shown in <ref type="figure">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tasks</head><p>Each Job must have one or more Tasks in which the actual command is specified. All Tasks that belong to the same Job share the same work direc- tory, and are executed in a fixed linear order.</p><p>A Task object is the combination of a method of the Job class, a set of requirements, and option- ally a set of parameters that will be passed to the method when executed. It is submitted to the grid engine and once it is scheduled Sisyphus executes the given method. It is also possible to create ar- rays of Jobs by providing a list of parameter-sets. These are executed in parallel (to the extent sup- ported by the queue). A common approach is to have a setup Task using one worker, a Task with multiple parallel running instances, and finally a Task to collect the outputs of all parallel Tasks and to write them into the Jobs output file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Error Handling</head><p>Sisyphus uses strict error checking to avoid errors in which a step causes problems down the line. This makes it easier to track down the problem that caused the error. By default, a Job switches into an error state if:</p><p>• a shell command returns a non-zero value, which is also true for any command inside a pipeline,</p><p>• an uninitialized variable is called, or</p><p>• the Python code throws an exception, which can be used in combination with assertions.</p><p>This means the execution of this Job is stopped to give the user a chance to fix the problem. After- wards, the user can either delete or move the Job directory by himself, or let Sisyphus do it for him. If a Task is known to fail spontaneously, it can be set to retry multiple times.</p><p>If a Task is interrupted before it is finished ex- ecuting all commands, it switches into the inter- rupted state. The Task can be marked as resume- able, if executing the same code multiple times results in the same outputs. In this case, Sisy- phus automatically tries to determine if the Task got interrupted due to a time or memory limit. It increases the requested requirements automat- ically and resubmits the Task. Resuming is not performed automatically by default, since some programs behave differently if they find files from previous runs in their work directory. If a Job can be resumed, meaning restarting the script will al- ways result in the same output, the user can mark 1 from sisyphus import * # import all Sisyphus related classes, mainly job and task 2 3 class ParallelPipeline(Job): 4 #Example how to distibute a slow pipeline command to multiple machines 5 def __init__(self, text, command, parallel_processe=8): 6 self.text = text # Text that will be split and piped though command 7 self.command = command # The actuall command 8 self.parallel_processe = parallel_processe # Split into that many parallel processes 9</p><p>self.out = self.output_path('out.gz') # Name of the output path 10 11 def split(self): 12 #Count lines, capture_output gives stdout of command back as string 13 lines = int(self.sh('zcat -f {text} | wc -l', capture_output=True)) 14</p><p>self.batch_size = (lines // self.parallel_processe) + 1 # compute batch size 15 self.sh('zcat -f {text} | split -d -l {batch_size}') # Split file 16 17 def run(self, pos): # pos will be given by task 18 self.sh('cat x%02i | {command} &gt; tmp.%02i' % (pos, pos)) # Run the command for each batch 19 20 def collect(self): 21 self.sh('cat tmp. * | gzip &gt; {out}') # collect all outputs 22 # Additional manual sanity check 23 output_lines = int(self.sh('zcat {out} | wc -l', capture_output=True)) 24 print("Number of output lines: %i" % output_lines) 25 assert output_lines &gt; 0, "No output created" 26 27 def tasks(self): 28 yield Task('split', rqmt={'cpu': 1, 'mem': 1}) # Run split task first 29 # Continue with the main task and starting a worker for each element in args list 30 yield Task('run', rqmt={'cpu': 2, 'mem': 4}, args=list(range(self.parallel_processe))) 31</p><p>yield Task('collect', rqmt={'cpu': 1, 'mem': 1}) # Finish with the collect task <ref type="figure">Figure 2</ref>: Example of a job containing multiple task and running the one task on multiple computers it as such. If not it stops executing further steps and waits for a manual fix by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Paths and Variables</head><p>Jobs are connected by Path and Variable objects, representing the edges in the dependency graph. A Variable is a subclass of the Path object which can store arbitrary pickleable Python objects to be passed between Jobs. A Job checks all Path objects that are given as inputs and start a Job only once all inputs are avail- able. There are multiple ways for a Path to become available. If it is created as an output of a Job, it is available either once the Job is finished or it is marked as available by the Job earlier. This can be used for example if a neural network training cre- ates save points of the current training state which can be evaluated before the whole training is fin- ished. If a Path object is used to add an input file to the graph, Sisyphus marks it as available if the file exists and alerts the user otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Engine</head><p>An engine defines how to execute and schedule the given tasks. Currently supported engines are the Son Grid Engine (SGE) with its closely related forks, Platform Load Sharing Facility (LSF), and a local engine running on the same node as Sisy- phus. It is also possible to combine different en- gines. A common setup is to have a local engine for small Jobs, e.g. counting the number of lines in a file, and a cluster-based engine for everything else. The choice which engine to use can be given via the requirement argument of a Task. Currently all engine implementations require that all nodes have access to a shared file system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Directory Structure</head><p>A Sisyphus experiment directory usually consists of:</p><p>• a recipe directory, containing the source code for the Jobs (Section 4.1),</p><p>• a config directory, which defines the Jobs to run and the order of their execution (Section 4.2),</p><p>• a work directory, each Job will create a direc- tory here to run its code, store its output, and save log files (Section 4.3),</p><p>• a output directory containing links the fin- ished outputs (Section 4.4),</p><p>• an aliases directory, containing links to run- ning Jobs with given aliases (Section 4.4), and</p><p>• a settings files, that holds global settings, e.g. which engines are available (Section 4.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Recipe Directory</head><p>The recipes are a collection of files that contain the code describing the Jobs that can be executed to run an experiment. Recipe files are valid Python files and can be imported similarly to any other Python modules. This allows the users to manage their experiments like a regular Python project, creating dependencies between different Jobs sim- ilar to Python module imports. The only thing that separates the recipe directory from a regular mod- ule directory is that it can contain Jobs descrip- tions. Beside placing Jobs in the recipe directory, it is also common to place functions encapsulating re- occurring workflows here. Any valid Python code can be placed here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Config Directory</head><p>The configuration directory is used to actually cre- ate the graph and select which outputs has to be computed. Similar to the recipe directory, it con- tains regular Python files that can be imported like any other Python module. It has to import the needed modules from the recipe directory and create the appropriate Jobs. When starting Sisy- phus the user selects which configuration should be loaded to construct the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Work Directory</head><p>The work directory stores the realization of the graph. Each Job gets its own directory. Its path is constructed from the recipe module, the Job name and the hash value of the given in- puts. This yields a compromise between struc- tured file names, brevity and the individuality of these names. The work directory can be linked to a different file system with sufficient disk space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Output and Aliases Directory</head><p>Outputs that are computed by Sisyphus are linked to the output directory. Similarly, it is possible to give important Jobs one or more meaningful aliases to make it trivial to find them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Settings File</head><p>The settings file is used for global parameters. This is the place to define which engine should be used, if and how the requirements of interrupted Jobs are changed, if the Job directory is cleaned automatically after it finishes, what the default en- vironment of an executed shell command should looks like, and various delays to allow networked file systems to synchronize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Helpers</head><p>Sisyphus provides a few tools to help with reoc- curring tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Web Server</head><p>The web server provides a list with all Jobs and their current states. Alternatively, it is also possi- ble to show all Jobs in a graph structure, as shown in <ref type="figure">Figure 1</ref>. Each Job can be selected to show more detailed information about its status, dependencies and possible error messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Console</head><p>It is possible to start an interactive Python shell to analyze the graph or test different functions di- rectly. It also serves to call the team import (Sec- tion 5.3) and clean up helper (Section 5.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Team Import</head><p>If multiple people work on the same task, it is helpful to avoid rerunning computations that have been already carried out by others. Sisyphus can automatically check other work directories and import finished Jobs. This saves one from manu- ally linking finished computations, as it is usually the case when using scripts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Virtual File System</head><p>An alternative way to have a structured access to all Job work directories and attributes is the virtual file system using fuse. This allows one to use any console or script to navigate the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Clean Up</head><p>After the experiments are finished it is time to clean up. Sisyphus supports a few options to do this depending how harsh the clean up has to be. This is mainly a trade-off between how much space is used on disk vs. how many steps are needed to re-run the experiments.</p><p>The least invasive method is to delete the work directory of each Job to remove temporary data created during the execution of the Job and to pack all log files into a tar archive. This can be set to run automatically in the background after a Job has finished successfully.</p><p>The second method is to remove lost Job direc- tories from Jobs that are not in the final graph. This usually happens if the workflow changed over time and some steps had to be re-run due to changed inputs. The now obsolete directories re- main on disk until they are removed. A alterna- tive source for lost data in the work directories are Jobs that have been restarted after an error which causes Sisyphus to move the old directory aside in case later debugging is necessary. This step keeps all the data used in the current workflow.</p><p>A more invasive option to free space is the clean-up of the current graph by removing Jobs that are not needed for further computations of the workflow anymore. This only keeps Jobs which produce outputs that are marked as targets or Jobs that are still needed to reach unfinished targets. In addition Jobs can be saved from deletion by defining a score, Jobs with a score higher than the chosen threshold will be kept. These are typi- cally Jobs that are expensive to recompute, e.g. the training of a neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Real-World Usage</head><p>Sisyphus is extensively used by the machine trans- lation and the automatic speech recognition teams at the RWTH Aachen University. All WMT and IWSLT submissions by the RWTH Aachen Uni- versity since 2015 until now have been created using Sisyphus <ref type="bibr">(Peter et al., 2015b,a)</ref>. It was used for speech recognition in <ref type="bibr" target="#b7">Zeyer et al. (2017)</ref>. AppTek 3 also uses Sisyphus internally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented overview of our novel workflow manager Sisyphus. Features like automatic er- ror detection, efficient usage of computational re- sources, scalability, easy of reproducibility, abil- ity to share work with others have been proven to be extremely helpful for our research. The large collection of tools for Python can be used with- out modification for editing, debugging, and docu- menting the workflow, since it is written in Python. It is freely available online 4 under the Mozilla License v2.0 to encourage the adoption by other groups.</p></div>
			<note place="foot" n="2"> https://github.com/jhclark/ducttape</note>

			<note place="foot" n="3"> http://www.apptek.com/ 4 https://github.com/rwth-i6/sisyphus</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work has received fund-ing from the European Research Council (ERC) (under the Euro-pean Union's Horizon 2020 re-search and innovation programme, grant agreement No 694537, project "SEQ-CLAS") and the Deutsche Forschungsgemein-schaft (DFG; grant agreement NE 572/8-1, project "CoreTec"). The GPU computing cluster was supported by DFG (Deutsche Forschungsgemein-schaft) under grant INST 222/1168-1 FUGG. The work reflects only the authors' views and none of the funding agencies is responsible for any use that may be made of the information it contains.</p><p>We want to thank explicitly Wilfried Michel, Nick Rossenbach, Arne Nix, Jan Rosendahl, Weiyue Wang, Henrik Rosendahl, and Julian Schamper for using and testing Sisyphus early on. We also really appreciate the detailed feedback from our reviewers.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">LoonyBin: Keeping Language Technologists Sane through Automated Management of Experimental (Hyper)Workflows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Language Resources and Evaluation, LREC 2010</title>
		<meeting>the International Conference on Language Resources and Evaluation, LREC 2010<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05" />
			<biblScope unit="page" from="17" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pegasus, a Workflow Management System for Science Automation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewa</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Vahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gideon</forename><surname>Juve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mats</forename><surname>Rynge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">J</forename><surname>Maechling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajiv</forename><surname>Mayani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Ferreira Da</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miron</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kent</forename><surname>Livny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wenger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">C</biblScope>
			<biblScope unit="page" from="17" to="35" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scientific Workflows: Moving Across Paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chee Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malcolm</forename><forename type="middle">P</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tan</forename><forename type="middle">Fong</forename><surname>Galea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Ang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jano</forename><forename type="middle">I</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Hemert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scientific Workflow Management and the Kepler System: Research Articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertram</forename><surname>Ludäscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilkay</forename><surname>Altintas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chad</forename><surname>Berkley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efrat</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurr. Comput. : Pract. Exper</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1039" to="1065" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The RWTH Aachen German to English MT System for IWSLT 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Thorsten</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farzad</forename><surname>Toutounchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Peitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parnia</forename><surname>Bahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Guta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Spoken Language Translation</title>
		<meeting><address><addrLine>Da Nang, Vietnam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The RWTH Aachen German-English Machine Translation System for WMT 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Thorsten</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farzad</forename><surname>Toutounchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joern</forename><surname>Wuebker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP 2015 Tenth Workshop on Statistical Machine Translation</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">158163</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Taverna workflow suite: designing and executing workflows of Web Services on the desktop, web or in the cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Wolstencroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Haines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donal</forename><surname>Fellows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Withers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Owen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stian</forename><surname>Soiland-Reyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Dunlop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Nenadic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiten</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Finn</forename><surname>Bacall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Hardisty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Nieva De La Hidalga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">P Balcazar</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoaib</forename><surname>Sufi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carole</forename><surname>Goble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">W1</biblScope>
			<biblScope unit="page" from="557" to="561" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CTC in the Context of Generalized FullSum HMM Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<meeting><address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="944" to="948" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
