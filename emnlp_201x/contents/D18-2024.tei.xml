<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:20+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OpenKE: An Open Toolkit for Knowledge Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">State Key Lab on Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shulin</forename><surname>Cao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">State Key Lab on Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Knowledge Engineering Laboratory</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">College of Information Science and Technology</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lv</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Knowledge Engineering Laboratory</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">State Key Lab on Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">State Key Lab on Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">State Key Lab on Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Knowledge Engineering Laboratory</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">OpenKE: An Open Toolkit for Knowledge Embedding</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations)</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations) <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="139" to="144"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>139</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We release an open toolkit for knowledge embedding (OpenKE), which provides a unified framework and various fundamental models to embed knowledge graphs into a continuous low-dimensional space. OpenKE prioritizes operational efficiency to support quick model validation and large-scale knowledge representation learning. Meanwhile, OpenKE maintains sufficient modularity and extensibil-ity to easily incorporate new models into the framework. Besides the toolkit, the embed-dings of some existing large-scale knowledge graphs pre-trained by OpenKE are also available , which can be directly applied for many applications including information retrieval, personalized recommendation and question answering. The toolkit, documentation, and pre-trained embeddings are all released on http://openke.thunlp.org/.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>People construct various large-scale knowledge graphs (KGs) to organize structured knowledge about the world, such as WordNet <ref type="bibr" target="#b11">(Miller, 1995)</ref>, <ref type="bibr">Freebase (Bollacker et al., 2008)</ref> and Wikidata <ref type="bibr" target="#b19">(Vrandeči´Vrandeči´c and Krötzsch, 2014</ref>). Most KGs are typically organized in the form of triples (h, r, t), with h and t indicating head and tail entities, and r indicating the relation between h and t, e.g., <ref type="bibr">(Mark Twain, PlaceOfBirth, Florida)</ref>. Abun- dant structured information in KGs is widely used to enhance various knowledge-driven NLP appli- cations (e.g., information retrieval, question an- swering and dialogue system) with the ongoing ef- fective construction of KGs.</p><p>Limited by the scale and sparsity of KGs, we have to represent KGs with corresponding dis- tributed representations. Therefore, a variety of * indicates equal contribution † Corresponding author: Z.Liu(liuzy@tsinghua.edu.cn) knowledge embedding (KE) approaches have been proposed to embed both entities and relations in KGs into a continuous low-dimensional space, such as linear models <ref type="bibr" target="#b5">(Bordes et al., 2011</ref><ref type="bibr" target="#b3">(Bordes et al., , 2014</ref>, latent factor models ( <ref type="bibr" target="#b17">Sutskever et al., 2009;</ref><ref type="bibr" target="#b7">Jenatton et al., 2012;</ref><ref type="bibr" target="#b10">Liu et al., 2017</ref>), neural models ( <ref type="bibr" target="#b16">Socher et al., 2013;</ref><ref type="bibr" target="#b6">Dong et al., 2014)</ref>, matrix factorization models <ref type="bibr" target="#b13">(Nickel et al., 2011</ref><ref type="bibr" target="#b14">(Nickel et al., , 2012</ref><ref type="bibr" target="#b12">(Nickel et al., , 2016</ref><ref type="bibr" target="#b18">Trouillon et al., 2016)</ref>, and translation models ( <ref type="bibr" target="#b4">Bordes et al., 2013;</ref><ref type="bibr" target="#b20">Wang et al., 2014;</ref><ref type="bibr" target="#b9">Lin et al., 2015;</ref><ref type="bibr" target="#b8">Ji et al., 2015</ref>). These models have achieved great performance on benchmark datasets. However, there exist two main issues which may lead to difficulty in full utilization and further development. On the one hand, the existing implementations are scattered and unsystematic to some extent. For example, the interfaces of these model implementations are inconsistent with each other. On the other hand, these model implementations mainly focus on model validation and are often time-consuming, which makes it difficult to apply them for real- world applications. Hence, it becomes urgent to develop an efficient and effective open toolkit for KE, which will definitely benefit both the commu- nities in academia and industry. For this purpose, we develop an open KE toolkit named "OpenKE". The toolkit provides a flexible framework and uni- fied interfaces for developing KE models. While taking in some training and computing optimiza- tion methods, OpenKE makes KE models efficient and capable of embedding large-scale KGs. The features of OpenKE are threefold:</p><p>(1) At the data and memory level, the unified framework of OpenKE manages data and mem- ory for KE models. Model developments based on OpenKE no longer require complicated data pro- cessing and memory allocation.</p><p>(2) At the algorithm level, OpenKE unifies the mathematical forms of various specific models to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Scoring Function Parameters Loss Function</p><formula xml:id="formula_0">RESCAL (Nickel et al., 2011) h Mrt Mr ∈ R k×k , h ∈ R k , t ∈ R k margin-based loss TransE (Bordes et al., 2013) −−h + r − tL 1 /L2 r ∈ R k , h ∈ R k , t ∈ R k margin-based loss</formula><p>TransH ( <ref type="bibr" target="#b20">Wang et al., 2014</ref>)  <ref type="bibr" target="#b0">Abadi et al., 2016)</ref> and Py- Torch ( <ref type="bibr" target="#b15">Paszke et al., 2017</ref>) to build a convenient platform to run models on GPUs.</p><formula xml:id="formula_1">−−(h − w r hwr) + r − (t − w r twr)L1/L2 wr ∈ R k , r ∈ R k , h ∈ R k , t ∈ R k margin-based loss TransR (Lin et al., 2015) −−Mrh + r − MrtL 1/L2 Mr ∈ R kr ×ke , r ∈ R kr , h ∈ R ke , t ∈ R ke margin-based loss TransD (Ji et al., 2015) −−(rph p + I)h + r − (rpt p + I)tL1/L2 rp ∈ R kr , hp ∈ R ke , tp ∈ R ke , I ∈ R kr ×ke , r ∈ R kr , h ∈ R ke , t ∈ R ke margin-based loss DistMult (Yang et al., 2015) &lt; h, r, t &gt; r ∈ R k , h ∈ R k , t ∈ R k logistic loss HolE (Nickel et al., 2016) r F −1 F(h) F (t) r ∈ R k , h ∈ R k , t ∈ R k logistic loss ComplEx (Trouillon et al., 2016) (&lt; h, r, t &gt;) r ∈ C k , h ∈ C k , t ∈ C k logistic loss</formula><p>Besides the toolkit, we also provide the pre- trained embeddings of several well-known large- scale KGs, which can be used directly for other relevant works without repeatedly spending much time for embedding KGs. In this paper, we mainly present the architecture design and implementa- tion of OpenKE, as well as the benchmark eval- uation results of some typical KE models im- plemented with OpenKE. Other related resources and details can be found on http://openke. thunlp.org/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>For a typical KG G, it expresses data as a directed graph G = {E, R, T }, where E, R and T indicate the sets of entities, relations and facts respectively. Each triple (h, r, t) ∈ T indicates there is a re- lation r ∈ R between h ∈ E and t ∈ E. For the entities h, t ∈ E and the relation r ∈ R, we use the bold face h, t, r to indicate their low-dimensional vectors respectively.</p><p>For any entity pair (h, t) ∈ E × E and any re- lation r ∈ R, we can determine whether there is a fact (h, r, t) ∈ T via their low-dimensional em- beddings learned by KE models. These embed- dings greatly facilitate understanding and mining knowledge in KGs. In practice, the KE models define a scoring function S(h, r, t) for each triple (h, r, t). In most cases, there are only true triples in KGs and non-existing triples can be either false or missing. Local closed world assumption ( <ref type="bibr" target="#b6">Dong et al., 2014</ref>) has been proposed to solve this prob- lem, which requires existing triples to have higher scores than those non-existing ones. Hence, the scoring function S(h, r, t) returns a higher score if (h, r, t) is true, vice versa.</p><p>Based on the above-mentioned scoring func- tions, some KE models formalize a margin-based loss as the training objective to learn embeddings of the entities and relations:</p><formula xml:id="formula_2">L = t∈T t ∈T γ + S(t ) − S(t) + .</formula><p>(1)</p><p>Here [x] + indicates keeping the positive part of x and γ &gt; 0 is a margin. T denotes the set of non- existing triples, which is constructed by corrupting entities and relations in existing triples,</p><formula xml:id="formula_3">T = E × R × E − T .<label>(2)</label></formula><p>Some other KE models cast the training objec- tive as a classification task. The embeddings of the entities and relations can be learned by minimizing the regularized logistic loss,</p><formula xml:id="formula_4">L = t∈T log(1 + exp(−S(t))) + t ∈T log(1 + exp(S(t ))). (3)</formula><p>The main difference among various KE models is scoring functions. Hence, we briefly introduce several typical models and their scoring functions in <ref type="table" target="#tab_0">Table 1</ref>. These models are state-of-the-art and widely introduced in many works. We systemati- cally incorporate all of them into our OpenKE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Design Goals</head><p>Before introducing the concrete toolkit implemen- tations, we report the design goals and features of OpenKE, including system encapsulation, opera- tional efficiency, and model extensibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Encapsulation</head><p>Developers tend to maximize the reuse of code to avoid unnecessary redundant development in prac- tice. For KE, its task is fixed, and its experimen- tal settings and model parameters are also sim- ilar. However, previous model implementations are scattered and lack of necessary interface en- capsulation. Thus, developers have to spend extra time reading obscure open-source code and writ- ing glue code for data processing when they con- struct models. In view of this issue, we build a uni- fied underlying platform in OpenKE and encap- sulate various data and memory processing which is independent of model implementations. As is shown in <ref type="figure" target="#fig_0">Figure 1</ref>, the system encapsulation makes it easy to train and test KE models. Thus, we just need to set hyperparameters via interfaces of the platform to construct KE models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Efficiency</head><p>Previous model implementations focus on model validation and enhancing experimental results rather than improving time and space efficiency. In fact, as real-world KGs can be very large, train- ing efficiency is an important concern. Hence, OpenKE integrates efficient computing power, training methods, and various acceleration strate- gies to support KE models. We adopt TensorFlow and PyTorch to implement the model training and test modules based on the interfaces of underly- ing platform. These machine learning frameworks enable models to be run on GPU, with just few minutes needed for training and testing models on benchmark datasets. In order to train existing large-scale KGs, we also implement lightweight C/C++ versions for quick deployment and multi- threading acceleration of KE models, in which some models (e.g. TransE) can embed more than 100M triples in a few hours on ordinary devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Extensibility</head><p>Since different KE models have different design solutions, we make OpenKE fully extensible to future variants. For the underlying platform, we encapsulate data processing and memory manage- import config, Models, os os.environ['CUDA_VISIBLE_DEVICES']='0' con = config.Config() con.set_in_path('./FB15K/') con.set_work_threads(8) con.set_train_times(1000) con.set_alpha(0.001) con.set_margin(1.0) con.set_dimension(100) con.set_opt_method('SGD') con.init() con.set_model(models.TransE) con.run()  ment, and then provide various data sampling in- terfaces. For the training modules, we provide enough interfaces for possible training methods. For the construction of KE models, we unify their mathematical forms and encapsulate them into a base class. These framework designs can greatly meet the needs of current and future models, and customized interfaces to meet individual require- ments are also available in OpenKE. As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, all specific models are implemented by inheriting the base class with designing their own scoring functions and loss functions. In addition, models in OpenKE can be placed into the frame- work of TensorFlow and PyTorch to interact with other machine learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Parallel Learning</head><p>Require: Entity and relation sets E and R, training triples T = {(h, r, t)}. 1: Initialize all model embeddings and parameters. 2: for i ← 1 to epoches do 3:</p><p>In each thread: 4:</p><p>for j ← 1 to batches/threads do 5:</p><p>Sample a positive triple (h, r, t) 6:</p><p>Sample a corrupted triple (h , r , t ) 7:</p><p>Compute the loss function L 8:</p><p>Update the gradient L 9:</p><p>end for 10: end for 11: Return all embeddings and parameters</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">GPU Learning</head><p>GPUs are widely used in machine learning tasks to speed up model training in recent years. In order to accelerate KE models, we integrate GPU learn- ing mechanisms into OpenKE. We build the GPU learning platform based on TensorFlow (branch master) and PyTorch (branch OpenKE-PyTorch). Both TensorFlow and PyTorch are machine learn- ing libraries, providing effective hardware opti- mizations and abundant arithmetic operators for convenient model constructions, especially the stable environments for GPU learning. The auto- grad packages also bring additional convenience. TensorFlow and PyTorch enable us to coustruct models without manual back propagation imple- mentations, further reducing the programming complexity for GPU Learning. We develop nec- essary encapsulation modules aligning to Tensor- Flow and PyTorch so that the development and de- ployment of KE models can be faster and further convenient. Models can be deployed easily on a variety of devices without implementing compli- cated device setting code, even for multiple GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parallel Learning</head><p>Abundant computing resources (e.g Servers with multiple GPUs) do not exist all the time. In fact, we often rely on simple personal computers for model validation. Hence, we enable OpenKE to adapt models for parallel learning on CPU 2 be- sides employing GPU learning, which allow users to make full use of all available computing re- sources. The parallel learning method is shown in Algorithm 1. The main idea of parallel learning method is based on data parallelism mechanism, which divides training triples into several parts and trains each part of triples with a corresponding  thread. In parallel learning, there are two strate- gies implemented to update gradients. One of the methods is the lock-free strategy, which means all threads share the unified embedding space and update embeddings directly without synchronized operations. We also implement a central syn- chronized method, where each thread calculates its own gradient and results will be updated after summing up the gradients from all threads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Offset-based Negative Sampling</head><p>All KE models learn their parameters by minimiz- ing the margin-based loss function Eq. <ref type="formula">(1)</ref> or the regularized logistic loss Eq. (3). Both of these loss functions need to construct non-existing triples as negative samples. We have empirically found that the corrupted triples have great influence on final performance. Randomly replacing entities or rela- tions with any other ones may make the negative triple set T contain some positive triples in T , which would weaken the performance of KE mod- els. The original sampling algorithm will spend much time checking whether generated triples are in T and filtering them out. In OpenKE, we pro- pose an offset-based negative sampling algorithm to generate negative triples. As shown in <ref type="figure" target="#fig_3">Figure 3</ref>, we renumber all entities with new serial numbers. Each entity's new number is obtained by adding an offset to its original ID, and the offset is the total number of positive entities which have lower IDs. Our algorithm first randomly sample a new num- ber and then map the new number back to its corre- sponding entity. This algorithm can directly gen- erate negative triples without any checking. Since the relation set is very small, we still directly re- place positive relations for relation corruption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluations</head><p>Link prediction has been widely used for evalu- ating KE models, which needs to predict the tail entity when given a triple (h, r, ?) or predict the <ref type="table" target="#tab_0">Dataset  Rel  Ent  Train  Valid  Test   FB15K 1,345 14,951 483,142 50,000 59,071  WN18  18  40,943 141,442</ref> 5,000 5,000  <ref type="table">Table 3</ref>: Experimental results of link prediction on FB15K (%).</p><p>head entity when given a triple (?, r, t). In order to evaluate OpenKE, we implement various KE mod- els with OpenKE, and compare their performance with previous works on link prediction task. Some datasets are usually used as benchmarks for link prediction, such as FB15K and WN18. FB15K is the relatively dense subgraph of Free- base; WN18 is the subset of WordNet. These pub- lic datasets are available online <ref type="bibr">3</ref> . Following pre- vious works, We adopt them in our experiments. The statistics of FB15K and WN18 are listed in <ref type="table" target="#tab_1">Table 2</ref>, including the number of entities, rela- tions, and facts.</p><p>As mentioned above, OpenKE supports mod- els with efficient learning on both CPU and GPU. For CPU, the benchmarks are run on an Intel(R) Core(TM) i7-6700K @ 3.70GHz, with 4 cores and 8 threads. For GPU, the models in both TensorFlow and PyTorch versions are trained by GeForce GTX 1070 (Pascal), with CUDA v.8.0 (driver 384.111) and cuDNN v.6.5. To compare with the previous works, we simply follow the pa- rameter settings used before and traverse all train- ing triples for 1000 rounds. Other detailed pa- rameters and training strategies are shown in our source code. We show these results in <ref type="table" target="#tab_3">Table 3 and  Table 4</ref>. In these tables, the difference between our implementations and the paper reported results are listed in the parentheses. To demonstrate the efficiency of OpenKE, we select TransE as a rep- resentative and implement it with both OpenKE and KB2E 4 , and then compare their training time. KB2E is a widely-used toolkit for KE models on GitHub. These results can be found in   From the results in <ref type="table">Table 3</ref>, <ref type="table" target="#tab_3">Table 4</ref> and <ref type="table" target="#tab_2">Table  5</ref>, we observe that: (1) Models implemented with OpenKE have the comparable accuracies com- pared to the values reported in the original pa- pers. These results are compatible with our ex- pectations. For some models, their accuracies are slightly higher due to OpenKE. These results in- dicate our toolkit is effecive. (2) OpenKE signifi- cantly accelerates the training process of the mod- els trained both on CPU and GPU. As compared to the model implemented with KB2E, all models in OpenKE achieve more than 10× speedup. These results show that our toolkit is efficient.</p><p>The evaluation results indicate that our toolkit significantly handles the time-consuming problem and can support existing models to learn large- scale KGs. In fact, TransE based on OpenKE only spends about 18 hours training the whole Wiki- data for 10000 rounds and gets stable embeddings. There are more than 40M entities and 100M facts in Wikidata. We also evaluate the embeddings learned on the whole Wikidata on the link pre- diction task. Because the whole Wikidata is quite huge, we emphasize link prediction of Wikidata more on ranking a set of candidate entities rather than requiring one best answer. Hence, we re- port the proportion of correct entities in top-N ranked entities (Hits@10, Hits@20, Hits@50 and Hits@100) in <ref type="table">Table 6</ref>. To our best knowledge, this is the first time that adopting KE models to embed an existing large-scale KG. The results shown in <ref type="table">Table 6</ref> indicate that OpenKE enables models to effectively and efficiently embed large-scale KGs.  <ref type="table">Table 6</ref>: Experimental results of link prediction on the whole Wikidata.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We propose an efficient open toolkit OpenKE for knowledge embedding. OpenKE builds a unified underlying platform to organize data and memory. It also applies GPU learning and parallel learning to speed up training. We also unify mathematical forms for specific models and encapsulate them to maintain enough modularity and extensibility. Ex- perimental results demonstrate that the models im- plemented by OpenKE are efficient and effective.</p><p>In the future, we will incorporate more knowledge embedding models and maintain the stable embed- dings of some large-scale knowledge graphs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example for training a KE model (TransE) via OpenKE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example for implementing a KE model (TransE) via OpenKE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example for the offset-based negative sampling algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>The brief introduction of some typical KE models. For most models, k is the dimension of both 
entities and relations. For some other models, K e is the dimension of entities and k r is the dimension of 
relations. F denotes the Fourier transform. denotes the element-wise product. &lt; a, b, c &gt; denotes the 
element-wise multi-linear dot product. 

implement them under the unified framework. We 
also propose a novel negative sampling strategy 
for further acceleration. 
(3) At the computation level, OpenKE can sep-
arate a large-scale KG into several parts and adapt 
KE models for parallel training. Based on the 
underlying management of data and memory, we 
also adopt TensorFlow (</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 : Statistics of FB15K and WN18.</head><label>2</label><figDesc></figDesc><table>Datasets 
FB15K 
Models 
TF 
PT 
MT 

TransE 
75.6(+28.5) 75.4(+28.3) 74.3(+27.2) 
TransH 
72.8(+14.3) 72.7(+14.2) 74.8(+16.3) 
TransR 
74.9(+6.2) 
75.7(+7.0) 
75.6(+6.9) 
TransD 
74.3(+0.1) 
74.2(+0.0) 
75.2(+1.0) 
RESCAL 49.1(+5.0) 
57.2(+13.1) 
-
DistMult 
73.4(+15.7) 75.4(+17.4) 
-
HolE 
70.4(−3.5) 
-
-
ComplEx 72.3(−11.7) 80.5(−3.5) 
-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table>Datasets 
WN18 
Models 
TF 
PT 
MT 

TransE 
90.5(+1.3) 
90.0(+0.8) 
83.3(−5.9) 
TransH 
94.6(+7.9) 
94.4(+7.7) 
92.5(+5.8) 
TransR 
93.8(+1.8) 
94.4(+2.4) 
94.6(+2.9) 
TransD 
94.2(+1.7) 
94.3(+1.8) 
91.9(−0.3) 
RESCAL 80.2(+27.4) 80.2(+27.4) 
-
DistMult 
93.6(−0.6) 
93.6(−0.6) 
-
HolE 
94.4(−0.5) 
-
-
ComplEx 94.0(−0.7) 
94.0(−0.7) 
-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Experimental results of link prediction on 
WN18 (%). 

Models 
Time (s) 

TransE (KB2E, CPU) 
7124 
TransE (OpenKE, CPU, 1-Thread) 
386 
TransE (OpenKE, CPU, 2-Thread ) 
206 
TransE (OpenKE, CPU, 4-Thread) 
118 
TransE (OpenKE, CPU, 8-Thread) 
76 
TransE (OpenKE, GPU, TensorFlow) 
178 
TransE (OpenKE, GPU, PyTorch) 
266 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Training time of different implementa-
tions of TransE on FB15K. 

</table></figure>

			<note place="foot" n="4"> Implementations In this section, we mainly present the implementations of acceleration modules and special sampling algorithm in OpenKE. OpenKE has been available to the public on GitHub 1 and is opensource under the MIT license. 1 http://github.com/thunlp/OpenKE</note>

			<note place="foot" n="2"> https://github.com/thunlp/Fast-TransX</note>

			<note place="foot" n="3"> https://everest.hds.utc.fr/doku.php? id=en:transe 4 https://github.com/thunlp/KB2E</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported by the 973 Program (No. 2014CB340501) and the National Natural Sci-ence Foundation of China (NSFC No. 61572273, 61661146007) and Tsinghua University Initiative Scientific Research <ref type="bibr">Program (20151080406)</ref>. This research is part of the NExT++ project, supported by the National Research Foundation, Prime Min-isters Office, Singapore under its IRC@Singapore Funding Initiative.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of OSDI</title>
		<meeting>OSDI</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Joint learning of words and meaning representations for open-text semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AISTATS</title>
		<meeting>AISTATS</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A semantic matching energy function for learning with multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ML</title>
		<meeting>ML</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning structured embeddings of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geremy</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilko</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A latent factor model for highly multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodolphe</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><forename type="middle">L</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume R</forename><surname>Obozinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding via dynamic mapping matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Analogical inference for multi-relational embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Holographic embeddings of knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Factorizing yago: scalable machine learning for linked data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Farabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Melvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnny</forename><surname>Mariethoz</surname></persName>
		</author>
		<title level="m">Pytorch: Tensors and dynamic neural networks in python with strong gpu acceleration</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modelling relational data using bayesian clustered tensor factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Théo</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wikidata: a free collaborative knowledgebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Vrandeči´vrandeči´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Krötzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
