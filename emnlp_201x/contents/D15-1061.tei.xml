<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Entity-centric Approach for Overcoming Knowledge Graph Sparsity</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Hegde</surname></persName>
							<email>manjunath@ssl.serc.iisc.in</email>
							<affiliation key="aff0">
								<orgName type="department">Indian Institute of Science</orgName>
								<orgName type="institution">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Indian Institute of Science</orgName>
								<orgName type="institution">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Entity-centric Approach for Overcoming Knowledge Graph Sparsity</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Automatic construction of knowledge graphs (KGs) from unstructured text has received considerable attention in recent research, resulting in the construction of several KGs with millions of entities (nodes) and facts (edges) among them. Unfortunately, such KGs tend to be severely sparse in terms of number of facts known for a given entity , i.e., have low knowledge density. For example, the NELL KG consists of only 1.34 facts per entity. Unfortunately , such low knowledge density makes it challenging to use such KGs in real-world applications. In contrast to best-effort extraction paradigms followed in the construction of such KGs, in this paper we argue in favor of ENTIty Centric Expansion (ENTICE), an entity-centric KG population framework , to alleviate the low knowledge density problem in existing KGs. By using ENTICE, we are able to increase NELL&apos;s knowledge density by a factor of 7.7 at 75.5% accuracy. Additionally, we are also able to extend the ontology discovering new relations and entities.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the last few years, automatic construc- tion of knowledge graphs (KGs) from web- scale text data has received considerable at- tention, resulting in the construction of sev- eral large KGs such as NELL ( <ref type="bibr" target="#b7">Mitchell et al., 2015</ref>), Google's Knowledge Vault ( <ref type="bibr" target="#b0">Dong et al., 2014</ref>). These KGs consist of millions of en- tities and facts involving them. While mea- suring size of the KGs in terms of number of entities and facts is helpful, they don't read- ily capture the volume of knowledge needed in  <ref type="table">Table 1</ref>: Any new fact involving a source en- tity from a Knowledge Graph (i.e., facts of the form entity1-relation-entity2 where entity1 is already in the KG) can be classified into one of the four extraction classes shown above. Most KG population techniques tend to focus on ex- tracting facts of the KR-KE class. ENTICE, the entity-centric approach proposed in this paper, is able to extract facts of all four classes.</p><p>real-world applications. When such a KG is used in an application, one is often interested in known facts for a given entity, and not nec- essarily the overall size of the KG. In particu- lar, knowing the average number of facts per entity is quite informative. We shall refer to this as the knowledge density of the KG. Low knowledge density (or high sparsity) in automatically constructed KGs has been rec- ognized in recent research <ref type="bibr" target="#b10">(West et al., 2014</ref>). For example, NELL KG has a knowledge den- sity of 1.34. Such low knowledge density puts significant limitations on the utility of these KGs. Construction of such KGs tend to follow a batch paradigm: the knowledge extraction system makes a full pass over the text corpus extracting whatever knowledge it finds, and fi- nally aggregating all extractions into a graph. Clearly, such best-effort extraction paradigm has proved to be inadequate to address the low knowledge density issue mentioned above. We refer to such paradigm as best-effort since its attention is divided equally among all possible entities.</p><p>Recently, a few entity-centric methods have been proposed to increase knowledge density in KGs ( <ref type="bibr" target="#b3">Gardner et al., 2013;</ref><ref type="bibr" target="#b4">Gardner et al., 2014</ref>). In contrast to the best-effort ap- proaches mentioned above, these entity-centric approaches aim at increasing knowledge den- sity for a given entity. A new fact involving the given entity can belong to one of the four types shown in <ref type="table">Table 1</ref>. Unfortunately, these densifying techniques only aim at identifying instances of known relations among entities al- ready present in the KG, i.e., they fall in the KR-KE type of <ref type="table">Table 1</ref>. In this paper we propose ENTIty Centric Expansion (ENTICE), an entity-centric knowledge densifying framework which, given an entity, is capable of extracting facts be- longing to all the four types shown in <ref type="table">Table 1</ref>. By using ENTICE, we are able to increase NELL's knowledge density by a factor of 7.7 1 , while achieving 75.4% accuracy. Our goal here is to draw attention to the effectiveness of entity-centric approaches with bigger scope (i.e., covering all four extraction classes in <ref type="table">Table 1</ref>) towards improving knowledge den- sity, and that even relatively straightforward techniques can go a long way in alleviating low knowledge density in existing state-of- the-art KGs. ENTICE code is available at:</p><p>https://github.com/malllabiisc/entity-centric- kb-pop</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Open Information Extraction (OIE) systems <ref type="bibr" target="#b11">(Yates et al., 2007;</ref><ref type="bibr" target="#b1">Fader et al., 2011;</ref><ref type="bibr" target="#b8">Schmitz et al., 2012</ref>) aim at extracting textual triples of the form noun phrase-predicate-noun phrase. While such systems aim for extraction cover- age, and because they operate in an ontology- free setting, they don't directly address the problem of improving knowledge density in on- tological KGs such as NELL. However, OIE extractions provide a suitable starting point which is exploited by ENTICE.</p><p>( <ref type="bibr" target="#b2">Gal√°rraga et al., 2014</ref>) addresses the prob- lem of normalizing (or canonicalizing) OIE ex- tractions which can be considered as one of the components of ENTICE (see Section 3.3).</p><p>As previously mentioned, recent proposals for improving density of KGs such as those re- ported in ( <ref type="bibr" target="#b3">Gardner et al., 2013;</ref><ref type="bibr" target="#b4">Gardner et al., 2014</ref>) focus on extracting facts of one of the four extraction classes mentioned in <ref type="table">Table 1</ref>, viz., KR-KE. The KBP challenge (Surdeanu, 2013) also focuses on extracting facts while keeping the relation set fixed, i.e., it addresses the KR-KE and KR-NE extraction classes.</p><p>A method to improve knowledge density in KGs by using search engine query logs and a question answering system is presented in <ref type="bibr" target="#b10">(West et al., 2014</ref>). The proprietary nature of datasets and tools used in this approach limits its applicability in our setting.</p><p>ENTICE aims to improve knowledge den- sity by extracting facts from all four extrac- tion classes, i.e., for a given entity, it extracts facts involving known relations, identifies po- tentially new relations that might be relevant for this entity, establishes such relations be- tween the given entity and other known as well as new entities -all in a single system. While various parts of this problem have been studied in isolation in the past, ENTICE is the first system to the best of our knowledge that addresses the complete problem as a sin- gle framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ENTIty Centric Expansion (ENTICE)</head><p>Overall architecture and dataflow within EN- TICE is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. We describe each of the components in the sections below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Preprocessing</head><p>Given the source entity, documents relevant to it are downloaded by issues queries against Google. In order to make the query specific, especially in case of ambiguous entities, a few keywords are also added to the query. For the experiments in this paper, the category is used as the keyword. For example, for the entity Al- bert Einstein from the scientist category, the query will be "Albert Einstein scientist". Top 20 documents returned by the search engine are downloaded and processed further. Text is extracted from the raw downloaded docu- ments using regex patters, HTML tag match- ing, and by using the Boilerpipe tool 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Triple Extraction</head><p>Text of each document obtained in the pre- vious step is processed through the Stanford CoreNLP toolkit ( <ref type="bibr" target="#b5">Manning et al., 2014</ref>) for tokenization, coreference resolution, and de- pendency parsing. Tokenized and coreference- resolved sentences are then passes through OpenIEv4 system 3 to extract (noun phrase, predicate, noun phrase) triples. Multiple and overlapping triples from the sentence was per- mitted. Length filter is applied on the noun phrase and the predicate of the triple ex- tracted. This eliminates triples whose predi- cate is more than 6 tokens and noun phrase more than 7 tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Noun and Relation Phrase Normalization</head><p>Noun phrases (NPs) and relation phrases ob- tained from the previous step are normalized (or canonicalized) in this step. Canopy clus- tering technique as proposed in ( <ref type="bibr" target="#b2">Gal√°rraga et al., 2014</ref>) was used for noun phrase as well re- lation phrase clustering. Initial clustering is done over the unlinked noun phrases in the triples. Please note that since we are working in an entity-centric manner, one of the two NPs present in the triple is already connected to the knowledge graph, and hence is consid- ered linked. To cluster noun phrases, we first construct canopies corresponding to each word in the noun phrase. For example, for noun phrase Albert Einstein, we create two canopies, viz., a canopy for Albert and another canopy for Einstein, and add Albert Einstein to both canopies. Grouping of noun phrases inside the canopy is the next step of clustering phase. Noun phrase similarity is calculated based on similarity of words in the noun phrases. Word similarity is either direct string matching or Gensim similarity score 4 , which internally uses word2vec embeddings ( <ref type="bibr" target="#b6">Mikolov et al., 2013)</ref>. After calculating pairwise similarity of noun phrases, hierarchical clustering is carried out to group noun phrases inside each canopy. A threshold score is used to stop hierarchical clustering. At the end of this process, we have canopies and groups of noun phrases inside them. A noun phrase can be in more than one canopy, hence those groups across canopies are merged if the similarity is greater than certain threshold. After this, each group will contain facts which have similar noun phrases and dif- ferent (or same) relation phrase. Again the facts are clustered based on the similarity of the relation phrase. Relation phrase similar- ity calculation step resembles the one used for noun phrases as described above.</p><p>After this triple clustering step, the best representative triple from each cluster is se- lected based on a few rules. We consider the structure of POS tags in noun phrases of a triple as one of the criteria. Secondly, if both noun phrases in the triple are linked to the knowledge graph, then it makes the triple more likely to become a representative tuple of the cluster. Also, if the NPs present in the triple are frequent in the cluster, then it makes the corresponding triple more like to become a representative.     <ref type="table">Table 4</ref>: Accuracy breakdown over ENTICE extractions for each of the four extraction classes in <ref type="table">Table 1</ref>. For each category, approximately 200 extractions were evaluated using Mechanical Turk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Integrating with Knowledge Graph</head><p>The set of normalized triples from the pre- vious step are linked with the Knowledge Graph, whenever possible, in this step. For a given normalized triple, following steps are performed as part of linking. First, category of each noun phrase in the triple is obtained based on string matching. In case of no match, refinements like dropping of adjectives, con- sidering only noun phrases are done to for re- matching. Now, the relation phrase is mapped to an existing predicate in the KG based on the extraction patterns in the metadata of the target relation (e.g., NELL and many other KGs have such metadata available). Can- didate predicates are chosen from the above mapped predicates based on category signa- ture of the two noun phrases (i.e. entity1 and entity2). This is possible since the all the pred- icates in NELL have the type signature defined in the metadata. Frequency of the relation phrase in the metadata is used as a criteria to select a candidate from multiple predicates. If such category-signature based mapping is not possible, then the predicate is listed as a new relation, and the corresponding triple marked to belong to either NR-KE or NE-NE extrac- tion class, depending on whether the target entity is already present in the KG or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In order to evaluate effectiveness of ENTICE, we apply it to increase knowledge density for 100 randomly selected entities from each of the following five NELL categories: Scientist, Uni- versities, Books, Birds, and Cars. For each category, a random subset of extractions in that category was evaluated using Mechanical Turk. To get a better accuracy of the eval- uation, each fact was evaluated by 3 workers. Workers were made to classify each fact as cor- rect, incorrect or can't say. Only those facts classified as correct by 2 or more evaluators were considered as correct facts.</p><p>Main Result: Experimental results com- paring knowledge densities in NELL and after application of ENTICE, along with the accu- racy of extractions, are presented in <ref type="table" target="#tab_2">Table 2</ref>. From this, we observe that ENTICE is able to improve knowledge density in NELL by a fac- tor of 7.7 while maintaining 75.5% accuracy. Sample extraction examples and accuracy per- extraction class are presented in <ref type="table" target="#tab_3">Table 3 and  Table 4</ref>, respectively.</p><p>Noun and Relation Phrase Normaliza- tion: We didn't perform any intrinsic eval- uation of the entity and relation normaliza- tion step. However, in this section, we pro- vide a few anecdotal examples to give a sense of the output quality from this step. We ob- serve that the canopy clustering algorithm for entity and normalization is able to cluster to- gether facts with somewhat different surface representations. For example, the algorithm came up with the following cluster with two facts: {(J. Willard Milnor, was awarded, 2011 Abel Prize); (John Milnor, received, Abel Prize)}. It is encouraging to see that the sys- tem is able to put J. Willard Milnor and John Milnor together, even though they have some- what different surface forms (only one word overlap). Similarly, the relation phrases was awarded and received are also considered to be equivalent in the context of these beliefs.</p><p>Integrating with Knowledge Graph: Based on evaluation over a random-sampling, we find that entity linking in ENTICE is 92% accurate, while relation linking is about 70% accurate.</p><p>In the entity linking stage, adjectives present in a noun phrase (NP) were ignored while matching the noun phrase to entities in the knowledge graph (NELL KB in this case). In case the whole NP didn't find any match, part of the NP was used to retrieve its cat- egory, if any. For example, in (Georg Walde- mar Cantor, was born in, 1854), the NP Georg Waldemar Cantor was mapped to category person using his last name and 1854 to cat- egory date. The relation phrase "was born in" maps to many predicates in NELL rela- tional metadata. NELL predicate AtDate was selected based on the rule that category sig- nature of the predicate matches the category of the noun phrases present in the triple. It also has the highest frequency count for the relational phrase in the metadata.</p><p>We observed that relation mapping has lesser accuracy due to two reasons. Firstly, error in determining right categories of NPs present in a triple; and secondly, due to higher ambiguity involving relation phrases in general, i.e., a single relation phrase usually matches many relation predicates in the on- tology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper presents ENTICE, a simple but effective entity-centric framework for increas- ing knowledge densities in automatically con- structed knowledge graphs. We find that EN- TICE is able to significantly increase NELL's knowledge density by a factor of 7.7 at 75.5% accuracy. In addition to extracting new facts, ENTICE is also able to extend the ontol- ogy. Our goal in this paper is twofold: (1) to draw attention to the effectiveness of entity- centric approaches with bigger scope (i.e., cov- ering all four extraction classes in <ref type="table">Table 1</ref>) to- wards improving knowledge density; and <ref type="formula">(2)</ref> to demonstrate that even relatively straight- forward techniques can go a long way in allevi- ating low knowledge density in existing state- of-the-art KGs. While these initial results are encouraging, we hope to apply ENTICE on other knowledge graphs, and also experiment with other normalization and entity linking al- gorithms as part of future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Dataflow and architecture and of ENTICE. See Section 3 for details.</figDesc><graphic url="image-1.png" coords="2,72.00,62.81,447.84,146.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Category</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Knowledge densities of five categories in NELL and after application of ENTICE, along 
with resulting accuracy. We observe that overall, ENTICE is able to increase knowledge density 
by a factor of 7.7 at 75.5% accuracy. This is our main result. 

Entity Name 
All facts in NELL 
Sample facts extracted by EN-
TICE 
Extraction 
Class 
George 
Paget 
Thomson 
(George Paget Thomson, isIn-
stanceOf, scientist) 
(Sir George Thomson, isFellowOf, 
Royal Society) 
NR-KE 

(George Thomson, hasSpouse, Kath-
leen Buchanan Smith) 
KR-NE 

(George Paget Thomson, diedOn, 
September 10) 
KR-KE 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 :</head><label>3</label><figDesc>Facts corresponding to an entity from the scientists domain in NELL as well as those extracted by ENTICE. While NELL contained only one fact for this entity, ENTICE was able to extract 15 facts for this entity, only 3 of which are shown above.</figDesc><table>Category 
KR -KE 
KR -NE 
NR -KE 
NR -NE 
correct 
facts 
wrong 
facts 
acc. 
correct 
facts 
wrong 
facts 
acc. 
correct 
facts 
wrong 
facts 
acc. 
correct 
facts 
wrong 
facts 
acc. 

Scientists 
57 
10 
85.07 61 
8 
88.40 14 
3 
82.35 9 
2 
81.81 
Cars 
68 
35 
66.01 58 
21 
73.41 9 
5 
64.28 5 
0 
100 
Universities 52 
30 
63.41 68 
20 
77.27 9 
2 
81.81 12 
4 
75 
Books 
78 
24 
76.47 79 
12 
86.81 2 
0 
100 
6 
1 
85.71 
Birds 
67 
29 
69.79 46 
19 
70.76 15 
4 
78.94 8 
6 
57.14 

Overall 
322 
128 
71.55 312 
80 
79.59 49 
14 
77.77 40 
13 
75.47 

</table></figure>

			<note place="foot" n="1"> Measured with respect to the five categories experimented with in the paper. See Section 4 for details.</note>

			<note place="foot" n="2"> Boilerpipe: http://code.google.com/p/boilerpipe 3 OpenIEv4: http://knowitall.github.io/openie/</note>

			<note place="foot" n="4"> https://github.com/piskvorky/gensim/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work is supported in part by a gift from Google. Thanks to Uday Saini for carefully reading a draft of the paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geremy</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilko</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Canonicalizing open knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Gal√°rraga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geremy</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian M</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management</title>
		<meeting>the 23rd ACM International Conference on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1679" to="1688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Improving learning and inference in a large knowledge-base using latent syntactic cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">Pratim</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Incorporating vector space similarity in random walk inference over knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">Pratim</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neverending learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Betteridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Open language learning for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Overview of the tac2013 knowledge base population evaluation: English slot filling and temporal slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Text Analysis Conference</title>
		<meeting>the Sixth Text Analysis Conference</meeting>
		<imprint>
			<publisher>TAC</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Knowledge base completion via searchbased question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on World wide web</title>
		<meeting>the 23rd international conference on World wide web</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Textrunner: open information extraction on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Broadhead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<meeting>Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="25" to="26" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
