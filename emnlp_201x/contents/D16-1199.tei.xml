<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Answer Questions from Wikipedia Infoboxes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Morales</surname></persName>
							<email>alvarom@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">CSAIL MIT</orgName>
								<orgName type="department" key="dep3">CSAIL MIT</orgName>
								<orgName type="department" key="dep4">CSAIL MIT</orgName>
								<orgName type="institution">CSAIL MIT</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varot</forename><surname>Premtoon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">CSAIL MIT</orgName>
								<orgName type="department" key="dep3">CSAIL MIT</orgName>
								<orgName type="department" key="dep4">CSAIL MIT</orgName>
								<orgName type="institution">CSAIL MIT</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Avery</surname></persName>
							<email>cavery@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">CSAIL MIT</orgName>
								<orgName type="department" key="dep3">CSAIL MIT</orgName>
								<orgName type="department" key="dep4">CSAIL MIT</orgName>
								<orgName type="institution">CSAIL MIT</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sue</forename><surname>Felshin</surname></persName>
							<email>sfelshin@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">CSAIL MIT</orgName>
								<orgName type="department" key="dep3">CSAIL MIT</orgName>
								<orgName type="department" key="dep4">CSAIL MIT</orgName>
								<orgName type="institution">CSAIL MIT</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Katz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">CSAIL MIT</orgName>
								<orgName type="department" key="dep3">CSAIL MIT</orgName>
								<orgName type="department" key="dep4">CSAIL MIT</orgName>
								<orgName type="institution">CSAIL MIT</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Answer Questions from Wikipedia Infoboxes</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1930" to="1935"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A natural language interface to answers on the Web can help us access information more efficiently. We start with an interesting source of information-infoboxes in Wikipedia that summarize factoid knowledge-and develop a comprehensive approach to answering questions with high precision. We first build a system to access data in infoboxes in a struc-tured manner. We use our system to construct a crowdsourced dataset of over 15,000 high-quality, diverse questions. With these questions , we train a convolutional neural network model that outperforms models that achieve top results in similar answer selection tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of open-domain question answering is to provide high-precision access to information. With many sources of knowledge on the Web, selecting the right answer to a user's question remains chal- lenging. Wikipedia contains over five million arti- cles in its English version. Providing a natural lan- guage interface to answers in Wikipedia is an impor- tant step towards more effective information access.</p><p>Many Wikipedia articles have an infobox, a table that summarizes key information in the article in the form of attribute-value pairs like "Narrated by: Fred Astaire". This data source is appealing for question answering because it covers a broad range of facts that are inherently relevant: a human editor manually highlighted this information in the infobox.</p><p>Although many infoboxes appear to be similar, they are only semi-structured-few attributes have consistent value types across articles, infobox tem- plates do not mandate which attributes must be included, and editors are allowed to add article- specific attributes. Infobox-like tables are very com- mon on the Web. Since it is infeasible to incorporate every such source into structured knowledge bases like Freebase ( <ref type="bibr" target="#b3">Bollacker et al., 2008)</ref>, we need tech- niques that do not rely on ontology or value type information.</p><p>We focus on the answer selection problem, where the goal is to select the best answer out of a given candidate set of attribute-value pairs from infoboxes corresponding to a named entity in the question. Ta- ble 1 illustrates how questions from users may have little lexical overlap with the correct attribute-value pair. Answer selection is an important subtask in building an end-to-end question answering system.</p><p>Our work has two main contributions: (1) We compiled the INFOBOXQA dataset, a crowdsourced corpus of over 15,000 questions with answers from infoboxes in 150 articles in Wikipedia. Unlike ex- isting answer selection datasets with answers from knowledge bases or long-form text, INFOBOXQA targets tabular data that is not augmented with value types or linked to an ontology. (2) We built a multi- channel convolutional neural network (CNN) model that achieves the best results on INFOBOXQA com- pared to other neural network models in the answer selection task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The INFOBOXQA dataset</head><p>Infoboxes are designed to be human-readable, not machine-interpretable. This allowed us to devise a crowdsourced assignment where we ask participants to generate questions from infoboxes. With little to no training, humans can form coherent questions out of terse, potentially ambiguous attribute-value pairs.</p><p>Wikipedia does not provide a way to access spe- cific information segments; its API returns the entire article. We first worked on the data access problem and developed a system called WikipediaBase to ro- bustly extract attribute-value pairs from infoboxes. Inspired by Omnibase ( <ref type="bibr" target="#b10">Katz et al., 2002</ref>), we or- ganize infoboxes in an object-attribute-value data model, where an object (Lake Titicaca) has an at- tribute ("Surface area") with a value (8,372 km 2 ). Attributes are grouped by infobox class (for in- stance, the film class contains attributes like "Di- rected by" and "Cinematography"). The data model allowed us to extend WikipediaBase to information outside of infoboxes. We implemented methods for accessing images, categories, and article sections.</p><p>We then created a question-writing assignment where participants see infoboxes constructed using data from WikipediaBase. These infoboxes visually resembled the original ones in Wikipedia but were designed to control for variables. To prevent parti- cipants from only generating questions for attributes at the top of the table, the order of attributes was randomly shuffled. To ensure that the task could be completed in a reasonable amount of time, in- foboxes were partitioned into assignments with up to ten attributes. A major goal of this data collec- tion was to gather question paraphrases. For each attribute, we asked participants to write two ques- tions. It is likely that at least one of the questions will use words from the attribute, but requiring an  additional question encouraged them to think of al- ternative phrasings. Every infobox in the experiment included a pic- ture to help disambiguate the article. For instance, the cover image for "Grand Theft Auto III" (in con- cert with the values in the infobox) makes it reason- ably clear that the assignment is about a video game and not a type of crime. We asked participants to include an explicit referent to the article title in each question (e.g., "Where was Albert Einstein born?" instead of "Where was he born?").</p><p>We analyzed the occurrences of infobox attributes in Wikipedia and found that they fit a rapidly- decaying exponential distribution with a long tail of attributes that occur in few articles. This distribution means that with a carefully chosen subset of articles we can achieve a large coverage of frequently ap- pearing attributes. We developed a greedy approx- imation algorithm that selects a subset of infobox classes, picks a random sample of articles in the class, and chooses three representative articles that contain the largest quantity of attributes. 150 articles from 50 classes were selected, covering roughly half of common attributes found in Wikipedia.</p><p>The dataset contains example questions q i , with an attribute-value pair (a i , v i ) that answers the ques- tion. To generate negative examples for the an- swer selection task, we picked every other tuple (a j , v j ); 8j 6 = i from the infobox that contains the correct answer. If we know that a question asks about a specific entity, we must consider ev- ery attribute in the entity's infobox as a possible an- swer. In INFOBOXQA, candidate answers are just attribute-value pairs with no type information. Be- cause of this, every attribute in the infobox is indis- tinguishable a priori, and is thus in the candidate set. Not having type information makes the task harder but also more realistic. <ref type="table" target="#tab_2">Table 2</ref> shows statistics of INFOBOXQA. The dataset is available online. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model description</head><p>Deep learning models for answer selection assume that there is a high similarity between question and answer representations ( <ref type="bibr" target="#b20">Yu et al., 2014</ref>). Instead of comparing them directly, the main intuition in our</p><note type="other">model is to use the attribute as an explicit bridge to facilitate the match between question and an- swer. Consider the question "Who replaced Dwight D. Eisenhower?", with answer "Succeeded by: John F. Kennedy". Clearly, the attribute "Succeeded by" plays a crucial role in indicating the match between the question and the answer. If the question and at- tribute have certain semantic similarities, and those similarities match the similarities of the answer and the attribute, then the answer must be a good match for the question.</note><p>We propose an architecture with three weight- sharing CNNs, each one processing either the ques- tion, the attribute, or the answer. We then use an element-wise product merge layer to compute simi- larities between the question and attribute, and be- tween the attribute and answer. We refer to this model as Tri-CNN. Tri-CNN has five types of layers: an input layer, a convolution layer, a max-pooling layer, a merge layer, and a final multi-layer percep- tron (MLP) scoring layer that solves the answer se- lection task. We now describe each layer.</p><p>Input layer. Let s q be a matrix 2 R |sq|⇥d , where row i is a d-dimensional word embedding of the i-th word in the question. Similarly, let s attr and s ans be word embedding matrices for the attribute and answer, respectively. s q , s attr , and s ans are zero- padded to have the same length. We use pre-trained GloVe 2 embeddings with d = 300 <ref type="bibr" target="#b12">(Pennington et al., 2014</ref>), which we keep adaptable during training.</p><p>Convolution layer. We use the multi-channel CNN architecture of <ref type="bibr" target="#b11">(Kim, 2014</ref>) with three weight- sharing CNNs, one each for s q , s attr , and s ans . Dif- ferent lengths of token substrings (e.g., unigrams or bigrams) are used as channels. The CNNs share weights among the three inputs in a Siamese archi- tecture ( <ref type="bibr" target="#b5">Bromley et al., 1993)</ref>. Weight-sharing al- lows the model to compute the representation of one input influenced by the other inputs; i.e., the repre- sentation of the question is influenced by the repre- sentations of the attribute and answer. </p><p>and b 2 R d is the bias. We use wide convolution to ensure that terminal and non-terminal words are considered equally when applying the filter w ( ). Max-pooling layer. Pooling is used to extract meaningful features from the output of convolution ( <ref type="bibr" target="#b19">Yin et al., 2015</ref>). We apply a max-pooling layer to the output of each channel h. The result is a vector c h 2 R d where</p><formula xml:id="formula_1">c h [i] = max{C[:, i]}<label>(2)</label></formula><p>Max-pooling is applied to all M channels. The re- sulting vectors c h for h 2 [1...M ] are concatenated into a single vector c. Merge layer. Our goal is to model the semantic similarities between the question and the attribute, and between the answer and the attribute. We com- pute the element-wise product of the feature vectors generated by convolution and max-pooling as fol- lows:</p><formula xml:id="formula_2">d q,attr = c q c attr (3) d ans,attr = c ans c attr (4)</formula><p>where is the element-wise product operator, such that d ij is a vector. Each element in d ij encodes a similarity in a single semantic aspect between two feature representations. MLP scoring layer. We wish to compute a real- valued similarity between the distance vectors from the merge layer. Instead of directly computing this using, e.g., cosine similarity, we follow (Baudiš andŠediv`y andˇandŠediv`andŠediv`y, 2016) and first project the two distance vec- tors into a shared embedding space. We compute element-wise sums and products of the embeddings, which are then input to a two-layer perceptron.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We implemented Tri-CNN in the dataset-sts 3 framework for semantic text similarity, built on top of the Keras deep learning library <ref type="bibr" target="#b8">(Chollet, 2015)</ref>. The framework aims to unify various sentence matching tasks, including answer selection, and provides implementations for variants of sentence- matching models that achieve state-of-the-art results on the TREC answer selection dataset ( <ref type="bibr" target="#b17">Wang et al., 2007)</ref>. We evaluated the performance of various models in dataset-sts against INFOBOXQA for the task of answer selection. We report the average and the standard deviation for mean average preci- sion (MAP) and mean reciprocal rank (MRR) from five-fold cross validation. We used 10% of the train- ing set for validation.</p><p>In answer selection, a model learns a function to score candidate answers; the set of candidate an- swers is already given. Entity linking is needed to generate candidate answers and is often treated as a separate module. For INFOBOXQA, we asked hu- mans to generate questions from pre-specified in- foboxes. Given this setup, we already know which entity the question refers to; we also know that the question is answerable by the infobox. Entity link- ing was therefore out of scope in our experiments. By effectively asking humans to identify the named entity, our evaluation results are not affected by noise caused by a faulty entity linking strategy.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Benchmarks</head><p>We compare against TF-IDF and BM25 ( <ref type="bibr" target="#b13">Robertson et al., 1995</ref>), two models from the information re- trieval literature that calculate weighted measures of word co-occurrence between the question and an- swer. We also experiment with various neural net- work sentence matching models. AVG is a baseline model that computes averages of unigram word em- beddings. CNN is the model most similar to Tri- CNN, with two CNNs in a Siamese architecture, one for the question and one for the answer. Max- pooling is computed on the output of convolution, and then fed to the output layer directly. RNN com- putes summary embeddings of the question and an- swer using bidirectional GRUs ( <ref type="bibr" target="#b7">Cho et al., 2014</ref>). ATTN1511 feeds the outputs of the bi-GRU into the convolution layer. It implements an asymmetric at- tention mechanism as in ( <ref type="bibr" target="#b15">Tan et al., 2015)</ref>, where the output of convolution and max-pooling of the ques- tion is used to re-weight the input to convolution of the answer. The convolution weights are not shared. For these neural architectures, we use the same MLP scoring layer used in Tri-CNN as the output layer and train using bipartite RankNet loss ( <ref type="bibr" target="#b6">Burges et al., 2005</ref>). slightly worse than the CNN model with weight- sharing. The Siamese architecture allows an input's representation to be influenced by the other inputs. The convolution feature maps are thus encoded in a comparable scheme that is more amenable to a matching task. Our Tri-CNN model built on top of this weight-sharing architecture achieves the best performance. Tri-CNN computes the match by com- paring the similarities between question-attribute and answer-attribute, which leads to improved re- sults over models that compare the question and an- swer directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>Deep learning approaches to answer selection have been successful on the standard TREC dataset and the more recent WIKIQA corpus ( <ref type="bibr" target="#b18">Yang et al., 2015)</ref>. Models like <ref type="bibr" target="#b9">(Feng et al., 2015)</ref> and ( <ref type="bibr" target="#b16">Wang and Nyberg, 2015</ref>) generate feature representations of ques- tions and answers using neural networks, comput- ing the similarity of these representations to select an answer. Recently, attention mechanisms to influ- ence the calculation of the representation ( <ref type="bibr" target="#b15">Tan et al., 2015</ref>) or to re-weight feature maps before matching ( <ref type="bibr" target="#b14">Santos et al., 2016</ref>) have achieved good results. Our work differs from past approaches in that we use the attribute as an additional input to the matching task. Other approaches to question answering over struc- tured knowledge bases focus on mapping questions into executable database queries ( <ref type="bibr" target="#b1">Berant et al., 2013)</ref> or traversing embedded sub-graphs in vector space ( <ref type="bibr" target="#b4">Bordes et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented an approach to answering questions from infoboxes in Wikipedia. We first compiled the INFOBOXQA dataset, a large and varied corpus of interesting questions from infoboxes. We then trained a convolutional neural network model on this dataset that uses the infobox attribute as a bridge in matching the question to the answer. Our Tri-CNN model achieved the best results when compared to recent CNN and RNN-based architectures. We plan to test our model's ability to generalize to other types of infobox-like tables on the Web. We expect our methods to achieve good results for sources such as product descriptions on shopping websites.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2Figure 1 :</head><label>1</label><figDesc>Figure 1: A schematic of the Tri-CNN model.</figDesc><graphic url="image-1.png" coords="3,314.28,57.82,224.64,236.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3</head><label></label><figDesc>https://github.com/brmson/dataset-sts</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Statistics of the INFOBOXQA dataset.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results of five-fold cross validation. Our Tri-CNN 

model achieves the best results in MAP and MRR. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 summarizes</head><label>3</label><figDesc></figDesc><table>the results of experiments on 
INFOBOXQA. The performance of the baselines 
indicates that unigram bag-of-words models are 
not sufficiently expressive for matching; Tri-CNN 
makes use of larger semantic units through its mul-
tiple channels. The attention mechanism and the 
combination of an RNN and CNN in ATTN1511 
achieves better results than RNN, but still performs </table></figure>

			<note place="foot" n="1"> http://groups.csail.mit.edu/infolab/infoboxqa/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Andrei Barbu and Yevgeni Berzak for helpful discussions and insightful comments on this paper. We also thank Ayesha Bose, Michael Sil-ver, and the anonymous reviewers for their valu-able feedback. Federico Mora, Kevin Ellis, Chris Perivolaropoulos, Cheuk Hang Lee, Michael Silver, and Mengjiao Yang also made contributions to the early iterations and current version of Wikipedia-Base.</p><p>The work described in this paper has been supported in part by AFRL contract No. FA8750-15-C-0010 and in part through funding pro-vided by the Center for Brains, Minds, and Ma-chines (CBMM), funded by NSF STC award CCF-1231216.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Sediv`y. 2016. Sentence pair scoring: Towards unified framework for text comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Baudiš</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Sediv</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06127</idno>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2008 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.3676</idno>
		<title level="m">Question answering with subgraph embeddings</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Signature verification using a &quot;Siamese&quot; time delay neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">W</forename><surname>Bentz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Säckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roopak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to rank using gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Deeds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicole</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Hullender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Machine Learning</title>
		<meeting>the 22nd International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the properties of neural machine translation: encoder-decoder approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST-8)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://github.com/fchollet/keras" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Applying deep learning to answer selection: A study and an open task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidan</forename><surname>Michael R Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01585</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Omnibase: Uniform access to heterogeneous data for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sue</forename><surname>Felshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alton</forename><forename type="middle">Jerome</forename><surname>Mcfarland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baris</forename><surname>Temelkuran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Processing and Information Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="230" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Okapi at TREC-3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Stephen E Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micheline</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIST Special Publication SP</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page">109</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.03609</idno>
		<title level="m">Attentive pooling networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">LSTMbased deep learning models for non-factoid answer selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.04108</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A long short-term memory model for answer sentence selection in question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">What is the Jeopardy model? A quasisynchronous grammar for QA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">WikiQA: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2013" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">ABCNN: Attention-based convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Wenpeng Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.05193</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep Learning for Answer Sentence Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Pulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
