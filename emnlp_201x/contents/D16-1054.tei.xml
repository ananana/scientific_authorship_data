<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Generating Characteristic-rich Question Sets for QA Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>November 1-5, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>Santa Barbara</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Ohio State University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Sadler</surname></persName>
							<email>brian.m.sadler6.civ@mail.mil, msrivats@us.ibm.com</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Army Research Lab</orgName>
								<orgName type="institution">U.S</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mudhakar</forename><surname>Srivatsa</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">IBM Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Izzeddin</forename><forename type="middle">G ¨</forename><surname>Ur</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>Santa Barbara</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zenghui</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>Santa Barbara</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>Santa Barbara</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Generating Characteristic-rich Question Sets for QA Evaluation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="562" to="572"/>
							<date type="published">November 1-5, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a semi-automated framework for constructing factoid question answering (QA) datasets, where an array of question characteristics are formalized, including structure complexity , function, commonness, answer cardi-nality, and paraphrasing. Instead of collecting questions and manually characterizing them, we employ a reverse procedure, first generating a kind of graph-structured logical forms from a knowledge base, and then converting them into questions. Our work is the first to generate questions with explicitly specified characteristics for QA evaluation. We construct a new QA dataset with over 5,000 logical form-question pairs, associated with answers from the knowledge base, and show that datasets constructed in this way enable fine-grained analyses of QA systems. The dataset can be found in https://github.com/ ysu1989/GraphQuestions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Factoid question answering (QA) has gained great attention recently, owing to the fast growth of large knowledge bases (KBs) such as DBpedia ( <ref type="bibr" target="#b16">Lehmann et al., 2014</ref>) and Freebase ( <ref type="bibr" target="#b6">Bollacker et al., 2008)</ref>, which avail QA systems of comprehensive and pre- cise knowledge of encyclopedic scope ( <ref type="bibr" target="#b25">Yahya et al., 2012;</ref><ref type="bibr" target="#b5">Berant et al., 2013;</ref><ref type="bibr" target="#b9">Cai and Yates, 2013;</ref><ref type="bibr" target="#b15">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b3">Berant and Liang, 2014;</ref><ref type="bibr" target="#b12">Fader et al., 2014;</ref><ref type="bibr" target="#b19">Reddy et al., 2014;</ref><ref type="bibr" target="#b1">Bao et al., 2014;</ref><ref type="bibr" target="#b31">Zou et al., 2014;</ref><ref type="bibr" target="#b21">Sun et al., 2015;</ref><ref type="bibr" target="#b10">Dong et al., 2015;</ref><ref type="bibr" target="#b28">Yao, 2015;</ref>. With the blos- soming of QA systems, evaluation is becoming an increasingly important problem. QA datasets, con- sisting of a set of questions with ground-truth an- swers, are critical for both comparing existing sys- tems and gaining insights to develop new systems.</p><p>Questions have rich characteristics, constituting dimensions along which question difficulty varies. Some questions are difficult due to their com- plex semantic structure ("Who was the coach when Michael Jordan stopped playing for the Chicago Bulls?"), while some others may be difficult because they require a precise quantitative analysis over the answer space ("What is the best-selling smartphone in 2015?"). Many other characteristics shall be con- sidered too, e.g., what topic a question is about (questions about common topics may be easier to answer) and how many answers there are (it is harder to achieve a high recall in case of multiple answers). Worse still, due to the flexibility of natural language, different people often describe the same question in different ways, i.e., paraphrasing. It is important for a QA system to be robust to paraphrasing.</p><p>A QA dataset explicitly specifying such ques- tion characteristics allows for fine-grained inspec- tion of system performance. However, to the best of our knowledge, none of the existing QA datasets <ref type="bibr" target="#b22">(Voorhees and Tice, 2000;</ref><ref type="bibr" target="#b5">Berant et al., 2013;</ref><ref type="bibr" target="#b9">Cai and Yates, 2013;</ref><ref type="bibr" target="#b18">Lopez et al., 2013;</ref><ref type="bibr" target="#b7">Bordes et al., 2015;</ref><ref type="bibr" target="#b20">Serban et al., 2016</ref>) provides ques- tion characteristics. In this work, we make the first attempt to generate questions with explicitly speci- fied characteristics, and examine the impact of vari- ous question characteristics in QA.</p><p>We present a semi-automated framework <ref type="bibr">(Figure 1)</ref> to construct QA datasets with characteristic specification from a knowledge base. The frame- work revolves around an intermediate graph query representation, which helps to formalize question characteristics and collect answers. We first auto- matically generate graph queries from a knowledge base, and then employ human annotators to convert graph queries into questions.</p><p>Automating graph query generation brings with it the challenge of assessing the quality of graph queries and filtering out bad ones. Our framework tackles the challenge by combining structured infor- mation in the knowledge base and statistical infor- mation from the Web. First, we identify redundant components in a graph query and develop techniques to remove them. Furthermore, based on the fre- quency of entities, classes, and relations mined from the Web, we quantify the commonness of a graph query and filter out too rare ones.</p><p>We employ a semi-automated approach for the conversion from graph query to natural language question, which provides two levels of paraphras- ing: Common lexical forms of an entity (e.g., "Queen Elizabeth" and "Her Majesty the Queen" for ElizabethII) mined from the Web are used as entity paraphrases, and the remaining parts of a question are paraphrased by annotators. As a result, dozens of paraphrased questions can be produced for a single graph query.</p><p>To demonstrate the usefulness of question char- acteristics in QA evaluation, we construct a new dataset with over 5,000 questions based on Freebase using the proposed framework, and extensively eval- uate several QA systems. A couple of new find- ings about system performance and question diffi- culty are discussed. For example, different from the results based on previous QA datasets ( ), we find that semantic parsing in gen- eral works better than information extraction on our dataset. Information extraction based QA systems have trouble dealing with questions requiring aggre- gation or with multiple answers. A holistic under- standing of the whole question is often needed for hard questions. The experiments point out an array of issues that future QA systems may need to solve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Early QA research has extensively studied problems like question taxonomy, answer type, and knowl- edge sources <ref type="bibr" target="#b8">(Burger et al., 2001;</ref><ref type="bibr" target="#b14">Hirschman and Gaizauskas, 2001;</ref><ref type="bibr" target="#b22">Voorhees and Tice, 2000</ref>). This work mainly targets factoid questions with one or more answers that are guaranteed to exist in a KB.</p><p>A few KB-based QA datasets have been pro- posed recently. QALD ( <ref type="bibr" target="#b18">Lopez et al., 2013</ref>) and FREE917 <ref type="bibr" target="#b9">(Cai and Yates, 2013</ref>) contain hundreds of hand-crafted questions. QALD also indicates whether a question requires aggregation. Both based on single Freebase triples, SIMPLEQUES- TIONS ( <ref type="bibr" target="#b7">Bordes et al., 2015</ref>) employ human an- notators to formulate questions, while <ref type="bibr" target="#b20">Serban et al. (2016)</ref> use a recurrent neural network to auto- matically formulate questions. They are featured by a large size, but the questions only concern sin- gle triples, while our framework can generate ques-tions involving multiple triples and various func- tions. <ref type="bibr" target="#b23">Wang et al. (2015)</ref> generate question-answer pairs for closed domains like basketball. They also first generate logical forms (λ-DCS formu- lae ( <ref type="bibr" target="#b17">Liang, 2013</ref>) in their case), and then convert log- ical forms into questions via crowdsourcing. Logi- cal forms are first converted into canonical questions to help crowdsourcing workers. Different from pre- vious works, we put a particular focus on generating questions with diversified characteristics in a sys- tematic way, and examining the impact of different question characteristics in QA.</p><p>Another attractive way for QA dataset construc- tion is to collect questions from search engine logs <ref type="bibr" target="#b2">(Bendersky and Croft, 2009</ref>). For exam- ple, WEBQUESTIONS <ref type="bibr" target="#b5">(Berant et al., 2013</ref>) contains thousands of popular questions from Google search, and <ref type="bibr" target="#b30">Yih et al. (2016)</ref> have manually annotated these questions with logical forms. However, automatic characterization of questions is hard, while man- ual characterization is costly and requires exper- tise. Moreover, users' search behavior is shaped by search engines <ref type="bibr" target="#b0">(Aula et al., 2010)</ref>. Due to the inade- quacy of current search engines to answer advanced questions, users may adapt themselves accordingly and mostly ask simple questions. Thus questions collected in this way, to some extent, may still not well reflect the true distribution of user information needs, nor does it fully exploit the potential of KB- based QA. Collecting answers is yet another chal- lenge for this approach. <ref type="bibr" target="#b30">Yih et al. (2016)</ref> show that only 66% of the WEBQUESTIONS answers, which were collected via crowdsourcing, are completely correct. On the other hand, although questions gen- erated from a KB may not follow the distribution of user information needs, it has the advantage of ex- plicit question characteristics, and enables program- matic configuration of question generation. Also, answer collecting is automated without involving human labor and errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Knowledge Base</head><p>In this work, we mainly concern knowledge bases storing knowledge about entities and relations in the form of triples (simply knowledge bases hereafter). Suppose E is a set of entities, L a set of literals (I = E ∪ L is also called individuals), C a set of classes, and R a set of directed relations, a knowledge base K consists of two parts: an ontology O ⊆ C × R × C and a model M ⊆ E × R × (C ∪ E ∪ L). In other words, an ontology specifies classes and relations between classes, and a model consists of facts about individuals. Such knowledge bases can be naturally represented as a directed graph, e.g., <ref type="figure" target="#fig_0">Figure 1(a)</ref>. Literal classes such as Datetime are represented as diamonds, and other classes are rounded rectangles. Individuals are shaded. We assume relations are typed, i.e., each relation is associated with a set of domain and range classes. Facts of a relation must be compatible with its domain and range constraints. Without loss of generality, we use Freebase (June 2013 version) in this work for compatibility with the to-be-tested QA systems. It has 24K classes, 65K relations, 41M entities, and 596M facts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph Query</head><p>Motivated by the graph-structured nature of knowl- edge bases, we adopt a graph-centric approach. We hinge on a formal representation named graph query (e.g., <ref type="figure" target="#fig_0">Figure 1</ref> ∧ dateOfDeath(x, z)∧ &lt; (z, 1960).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>564</head><p>The answer of a graph query q, denoted as q K , can be easily obtained from K. For example, if K is stored in a RDF triplestore, then q can be au- tomatically converted into a SPARQL query and run against K to get the answer. Compared with , graph queries are not constrained to be tree-structured, which grants us a higher ex- pressivity. For example, linguistic phenomena like anaphora (e.g., <ref type="figure" target="#fig_0">Figure 1(d)</ref>) become easier to model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Automatic Graph Query Generation</head><p>Our framework proceeds as follows: <ref type="formula" target="#formula_0">(1)</ref> Generate query templates from a knowledge base, ground the templates to generate graph queries, and col- lect answers (this section). (2) Refine graph queries to retain high-quality ones (Section 5). (3) Con- vert graph queries into questions via crowdsourcing (Section 6).</p><p>We now describe an algorithm to generate the query template shown in <ref type="figure" target="#fig_0">Figure 1</ref>(b) (excluding the function for now). For simplicity, we will focus on the case of a single question node. Nevertheless, the proposed framework can be extended to generate graph queries with multiple question nodes. The al- gorithm takes as input an ontology <ref type="figure" target="#fig_0">(Figure 1(a)</ref>) and the desired number of edges. All the operations are conducted in a random manner to avoid systematic biases in query generation. The DeceasedPerson class is first selected as the question node. We then iteratively grow it by adding neighboring nodes and edges in the ontology. In each iteration, an exist- ing node is selected, and a new edge, which might introduce a new node, is appended to it. For exam- ple, the relation causeOfDeath, whose domain in- cludes DeceasedPerson, is first appended to the question node, and then one of its range classes, CauseOfDeath, is added as a new node. When a node with the class CauseOfDeath already exists, it is possible to add an edge without introducing a new node. The same relation or class can be added multiple times, e.g., "parent of parent".</p><p>Topic entities like LungCancer play an impor- tant role in a question. A query template contains some template nodes that can be grounded with different topic entities to generate different graph queries. We randomly choose a few nodes as tem- plate. It may cause problems. For example, ground- ing one node may make some others redundant. We conduct a formal study on this in Section 5.1.</p><p>Functions such as counting and comparatives are pervasive in real-life questions, e.g., "how many", "the most recent", and "people older than", but are scarce in existing QA datasets. We incorpo- rate functions as an important question characteris- tic, and consider nine common functions, grouped into three categories: counting (count), superlative (max, min, argmax, argmin), and comparative (&gt;, ≥, &lt;, ≤). More functions can be incorporated in the future. See Appendix A for examples. We ran- domly add functions to compatible nodes in query templates. In the running example, the &lt; function imposes the constraint that only people who passed away before a certain date should be considered. Each query will have at most one function.</p><p>We then ground the template nodes with indi- viduals to generate graph queries. A grounding is valid if the individuals conform with the class of the corresponding template nodes, and the resulted answer is not empty. For example, by grounding CauseOfDeath with LungCancer and Datetime with 1960, we get the graph query in <ref type="figure" target="#fig_0">Figure 1</ref>(c). A query template can render multiple groundings.</p><p>Finally, we convert a graph query into a SPARQL query and execute it using Virtuoso Open-Source 7 to collect answers. We further impose mutual exclu- sivity in SPARQL queries, that is, the entities on any two nodes in a graph query should be different. Con- sider the example in <ref type="figure" target="#fig_2">Figure 2</ref>, which is asking for the siblings of Natasha Obama. Wihout mutual ex- clusivity, however, Natash Obama herself will also be included as an answer, which is not desired.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Query Redundancy and Minimization</head><p>Some components (nodes and edges) in a graph query may not effectively impose any constraint on the answer. The query in <ref type="figure" target="#fig_3">Figure 3</ref>(a) is to "find the US president whose child is Natasha Obama, and Natasha Obama was born on 2001-06-10". Intuitively, the bold-faced clause does not change the answer of the question. Correspondingly, the dateOfBirth edge and the date node are redun- dant. As a comparison, removing any component from the query in <ref type="figure" target="#fig_3">Figures 3(b)</ref> will change the an- swer. Formally, given a knowledge base K, a com- ponent in a graph query q is redundant iff. removing it does not change the answer q K .</p><p>Redundancy can be desired or not. In a question, redundant information may be inserted to reduce ambiguity. In <ref type="figure" target="#fig_3">Figure 3</ref>(a), if one uses "Natasha" to refer to NatashaObama, there comes ambiguity since it may be matched with many other entities. The additional information "who was born on 2001- 06-10" then helps. Next we describe an algorithm to remove redundancy from queries. One can choose to either only generate queries with no redundant com- ponent, or intentionally generate redundant queries and test QA systems in presence of redundancy.</p><p>We manage to generate minimal queries, for which there exists no sub-query having the same an- swer. An important theorem, as we prove in Ap- pendix B, is the equivalency of minimality and non- redundancy: A query is minimal iff. it has no redun- dant component. This renders a simple algorithm for query minimization, which directly detects and removes the redundant components in a query. We first examine every edge (in an arbitrary order), and remove an edge if it is redundant. Redundant nodes will then become disconnected to the question node and are thus eliminated. It is easy to prove that the produced query (e.g., <ref type="figure" target="#fig_3">Figure 3(b)</ref>) is minimal, and has the same answer as the original query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Commonness Checking</head><p>We now quantify the commonness of graph queries. The benefits of this study are two-fold. First, it pro- vides a refinement mechanism to reduce too rare queries. Second, commonness is itself an important question characteristic. It is interesting to examine its impact on question difficulty. Consider the ex- ample in <ref type="figure" target="#fig_4">Figure 4</ref>, which asks for "the great-great- grandparents of Ernest Solvay". It is minimal and logically plausible. Few users, however, are likely to come up with it. Ernest Solvay is famous for the Solvay Conferences, but few people outside the sci- ence community may know him. Although Person and parents are common, asking for the great- great-grandparents is quite uncommon.</p><p>A query is more common if users would more likely come up with it. We define the commonness of a query q as its probability p(q) of being picked among all possible queries from a knowledge base. The problem then boils down to estimating p(q). It is hard, if not impossible, to exhaust the whole query space. We thus make the following simplifica- tion. We break down query commonness by compo- nents, assuming mutual independence between com- ponents, and omit functions:</p><formula xml:id="formula_0">p(q) = i∈Iq p(i) × c∈Cq p(c) × r∈Rq p(r),<label>(1)</label></formula><p>where I q , C q , R q are the multi-set of the individuals, classes, and relations in q, respectively. Repeating components are thus accumulated (c.f. <ref type="figure" target="#fig_4">Figure 4)</ref>.</p><p>We propose a data-driven method, using statisti- cal information from the Web, to estimate p(i), p(c), and p(r). Other methods like domain-knowledge based estimation are also applicable if available. We start with entity probability p(e) (excluding literals for now). If users mention an entity more frequently, its probability of being observed in a question should be higher. We use a large entity linking dataset, FACC1 ( <ref type="bibr" target="#b13">Gabrilovich et al., 2013)</ref>, which identifies around 10 billion mentions of Freebase entities in over 1 billion web documents. The estimated link- ing precision and recall are 80-85% and 70-85%, re- c ∈C e∈c n(e) . Estimating p(r) re- quires relation extraction from texts, which is hard. We make the following simplification: If (e 1 , r, e 2 ) is a fact in the knowledge base, we increase n(r) by 1 if e 1 and e 2 co-occur in a document. This suffices to distinguish common relations from uncommon ones. We then define p(r) = n(r) r ∈R n(r ) . Finally, we use frequency information from the knowledge base to smooth the probabilities, e.g., to avoid zero probabilities. The probability of literals are solely determined by the frequency information from the knowledge base. Refer to Appendix C for the re- sulted probability distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Natural Language Conversion</head><p>In order to ensure naturalness and diversity, we em- ploy human annotators to manually convert graph queries into natural language questions. We man- age to provide two levels of paraphrasing <ref type="figure" target="#fig_5">(Fig- ure 5)</ref>. Each query is sent to multiple annotators for sentence-level paraphrasing. In addition, we use dif- ferent lexical forms of an entity mined from FACC1 for entity-level paraphrasing. We provide a ranked list of common lexical forms and the corresponding frequency for each topic entity. For example, the lexical form list for UnitedStatesOfAmerica is "us" (108M), "united states" (44M), "usa" (22M), etc. Finally, graph queries are automatically trans- lated into SPARQL queries to collect answers.</p><p>Natural language generation (NLG) <ref type="bibr" target="#b20">Serban et al., 2016;</ref><ref type="bibr" target="#b11">Dušek and Jurčíček, 2015)</ref> would be a good complement to our framework, the combination of which can lead to a fully-automated pipeline to generate QA datasets. For example, <ref type="bibr" target="#b20">Serban et al. (2016)</ref> automatically convert Free- base triples into questions with a neural network. More sophisticated NLG techniques able to handle graph queries involving multiple relations and vari- ous functions are an interesting future direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head><p>We have constructed a new QA dataset, named GRAPHQUESTIONS, using the proposed frame- work, and tested several QA systems to show that it enables fine-grained inspection of QA systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Dataset Construction</head><p>We first randomly generated a set of minimal graph queries, and removed the ones whose common- ness is below a certain threshold. The remaining graph queries were then screened by graduate stu- dents, and a canonical question was generated for each query, with each being verified by at least two students. We recruited 160 crowdsourcing work- ers from Amazon MTurk to generate sentence-level paraphrases of the canonical questions. Trivial para- phrases (e.g., "which city" vs. "what city") were manually removed to retain a high diversity in para- phrasing. At most 3 entity-level paraphrases were used for each sentence-level paraphrase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Dataset Analysis</head><p>GRAPHQUESTIONS contains 500 graph queries, 2,460 sentence-level paraphrases, and 5,166 ques- tions 2 . The dataset presents a high diversity and covers a wide range of domains including People, Astronomy, Medicine, etc. Specifically, it con- tains 148, 506, 596, 376 and 3,026 distinct domains, classes, relations, topic entities, and words, respec- tively. We evenly split GRAPHQUESTIONS into a training set and a testing set. All the paraphrases of the same graph query are in the same set.</p><p>While there are other question characteristics derivable from graph query, we will focus on the following ones: structure complexity, function, com- monness, paraphrasing, and answer cardinality. We  log 10 (p(q)) |A| 1 2 3 none count super. comp.</p><p>[</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>−40, 30) [−30, 20) [−20, 10) [−10, 0)</head><p>1 &gt; <ref type="table" target="#tab_1">1  # of graph queries 321  144  35  350  61  42  47  60  135  283  22  332  168   # of questions  3094 1648 424 3855  710  332  269  653  1477  2766  270  3487</ref>    use the number of edges to quantify structure com- plexity, and limit it to at most 3. Commonness is limited to log 10 (p(q)) ≥ −40 (c.f. Eq. 1). As shown in Section 7.4.2, such questions are already very hard for existing QA systems. Nevertheless, the proposed framework can be used to generate questions with different characteristic distributions. Some statistics are shown in <ref type="table" target="#tab_1">Table 1</ref> and more fine- grained statistics can be found in Appendix D. Several example questions are shown in Ta- ble 2. Sentence-level paraphrasing requires to han- dle both commands (the first example) and "Wh" questions, light verbs ("Who did nine eleven?"), and changes of syntactic structure ("The Septem- ber 11 attacks were carried out with the involve- ment of what terrorist organizations?"). Entity- level paraphrasing tests the capability of QA systems on abbreviation ("NYC" for New York City), world knowledge ("Her Majesty the Queen" for ElizabethII), or even common typos ("Shaks- peare" for WilliamShakespeare). Numbers and dates are also common, e.g., "Which computer oper- ating system was released on Sept. the 20th, 2008?"</p><p>We compare several QA datasets constructed from Freebase, shown in <ref type="table" target="#tab_4">Table 3</ref>. Datasets focus- ing on single-relation questions are of a larger scale, but are also of a significant lack in question charac- teristics. Overall GRAPHQUESTIONS presents the highest diversity in question characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Setup</head><p>We evaluate three QA systems whose source code is publicly available: SEMPRE (Berant et al., 2013), PARASEMPRE <ref type="bibr" target="#b3">(Berant and Liang, 2014)</ref>, and JA- CANA ( ). SEMPRE and PARASEMPRE follow the semantic parsing paradigm. SEMPRE conducts a bottom-up beam- based parsing on questions to find the best logical form. PARASEMPRE, in a reverse manner, enumer- ates a set of logical forms, generates a canonical utterance for each logical form, and ranks logical forms according to how well the canonical utter- ance paraphrases the input question. In contrast, JA- CANA follows the information extraction paradigm, and builds a classifier to directly predict whether an individual is the answer. They all use Freebase.</p><p>The main metric for answer quality is the aver- age F1 score, following <ref type="bibr" target="#b3">Berant and Liang (2014)</ref>. Because a question can have more than one an- swer, individual precision, recall, and F1 scores are first computed on each question and then averaged. When a system generates no response for a question,   precision is 1, recall is 0, and F1 is 0. Average run- time is used for efficiency. Results are shown in per- centage. Systems are trained on the training set us- ing the suggested configurations (Appendix E). We use student's t test at p = 0.05 for significance test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.1">Overall Evaluation</head><p>Compared with the scores on WEBQUESTIONS (30%-40%), the scores on GRAPHQUESTIONS are lower <ref type="table" target="#tab_5">(Table 4)</ref>. This is because GRAPHQUES- TIONS contains questions over a broader range of difficulty levels. For example, it is more diverse in topics (Appendix D); also the scores become much closer when excluding paraphrasing (Section 7.4.2).</p><p>JACANA achieves a comparable F1 score with SEMPRE and PARASEMPRE on WEBQUES- TIONS ( ). On GRAPHQUESTIONS, however, SEMPRE and PARASEMPRE significantly outperform JACANA (both p &lt; 0.0001). The following experiments will give more insights about where the performance difference comes from. On the other hand, JACANA is much faster, showing an advantage of information extraction. The semantic parsing systems spend a lot of time on executing SPARQL queries. Bypassing SPARQL and directly working on the knowledge base may be a promising way to speed up semantic parsing on large knowledge bases ( ).</p><p>2 WEBQUESTIONSSP is WEBQUESTIONS with manually annotated logical forms. Only those with a full logical form are included (4737 / 5810).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.2">Fine-grained Evaluation</head><p>With explicitly specified question characteristics, we are able to further inspect QA systems.</p><p>Structure Complexity. We first break down system performance by structure. Answer quality is in gen- eral sensitive to the complexity of question struc- ture: As the number of edges increases, F1 score decreases ( <ref type="figure" target="#fig_8">Figure 6(a)</ref>). The tested systems often fail to take into account auxiliary constraints in a question. For example, for "How many children of Ned Stark were born in Winterfell?" SEMPRE fails to identify the constraint "born in Winterfell", so it also considers Ned Stark's bastard son, Jon Snow, as an answer, who was not born in Winter- fell. Answering questions involving multiple rela- tions using large knowledge bases remain an open problem. The large size of knowledge bases pro- hibits exhaustive search, so smarter algorithms are needed to efficiently prune the answer space. Be- rant and Liang (2015) point out an interesting direc- tion, leveraging agenda-based parsing with imitation learning for efficient search in the answer space.</p><p>Function. In terms of functions, while SEMPRE and PARASEMPRE perform well on count questions, all the tested systems perform poorly on questions with superlatives or comparatives ( <ref type="figure" target="#fig_8">Figure 6(b)</ref>). JACANA has trouble dealing with functions because it does not conduct quantitative analysis over the answer space. SEMPRE and PARASEMPRE do not generate logical forms with superlatives and comparatives, so they cannot answer such questions well.</p><p>Commonness. Not surprisingly, more common questions are in general easier to answer <ref type="figure" target="#fig_8">(Fig- ure 6(c)</ref>). An interesting observation is that SEM- PRE's performance gets worse on the most common questions. The cause is likely rooted in how the QA systems construct their candidate answer sets. PARASEMPRE and JACANA exhaustively construct candidate sets, while SEMPRE employs a bottom-up beam search, making it more sensitive to the size of  the candidate answer space. Common entities like UnitedStatesOfAmerica are often featured by a high degree in knowledge bases (e.g., 1 million neighboring entities), which dramatically increases the size of the candidate answer space. During SEM- PRE's iterative beam search, many correct logical forms may have fallen off beam before getting into the final candidate set. We checked the percentage of questions for which the correct logical form is in the final candidate set, and found that it decreased from 19.8% to 16.7% when commonness increased from -15 to -5, providing an evidence for the intuition.</p><p>Paraphrasing. It is critical for a system to toler- ate the wording varieties of users. We make the first effort to evaluate QA systems on paraphras- ing. For each system, we rank, in descending or- der, all the paraphrases derived from the same graph query by their F1 score achieved by the system, and then compute the average F1 score of each rank. In <ref type="figure" target="#fig_8">Figure 6</ref>(d), the decreasing rate of a curve thus de- scribes a system's robustness to paraphrasing; the higher, the less robust. All the systems achieve a reasonable score on the top-1 paraphrases, i.e., when a system can choose the paraphrase it can best an- swer. The F1 scores drop quickly in general. On the fourth-ranked paraphrases, the F1 score of SEM- PRE, PARASEMPRE, and JACANA are respectively only 37.65%, 53.2%, and 36.2% of their score on the top-1 paraphrases. Leveraging paraphrasing in its model, PARASEMPRE does seem to be more ro- bust. The results show that how to handle para- phrased questions is still a challenging problem.</p><p>Answer Cardinality. SEMPRE and JACANA get a significantly lower F1 score (both p &lt; 0.0001) on multi-answer questions <ref type="table" target="#tab_8">(Table 5)</ref>, mainly com- ing from a decrease on recall. The decrease of PARASEMPRE is not significant (p=0.29). The par- ticularly significant decrease of JACANA demon-  strates the difficulty of training a classifier that can predict all of the answers correctly; semantic pars- ing is more robust in this case. The precision of SEMPRE is high because it generates no response for many questions. Note that under the current defini- tion, the average F1 score is not the harmonic mean of the average precision and recall (c.f. Section 7.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We proposed a framework to generate characteristic- rich questions for question answering (QA) evalua- tion. Using the proposed framework, we constructed a new and challenging QA dataset, and extensively evaluated several QA systems. The findings point out an array of issues that future QA research may need to solve.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Running example of our framework. Graph queries are first generated from a knowledge base. After refinement (not shown), graph queries are sent to human annotators and converted into natural language questions. Answers are collected from the knowledge base.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(c)), developed on the basis of Yih et al. (2015) and influenced by λ-DCS (Liang, 2013). Syntax. A graph query q is a connected directed graph built on a given knowledge base K. It com- prises three kinds of nodes: (1) Question node (dou- ble rounded rectangle), a free variable. (2) Un- grounded node (rounded rectangle or diamond), an existentially quantified variable. (3) Grounded node (shaded rounded rectangle or diamond), an individ- ual. In addition, there are functions (shaded circle) such as &lt; and count applied on a node. Nodes are typed, each associated with a class. Nodes are con- nected by directed edges representing relations. En- tities on the grounded nodes are called topic entities. Semantics. Graph query is a strict subset of λ- calculus. For example, the graph query in Fig- ure 1(c) can be written in λ-calculus (an existentially quantified variable is imposed by &lt;): λx.∃y.∃z.type(x, DeceasedPerson) ∧ type(y, DeceasedPerson) ∧ type(z, Datetime) ∧ parents(x, y) ∧ causeOfDeath(x, LungCancer) ∧ causeOfDeath(y, LungCancer)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Mutual exclusivity example. Entities on different nodes should be different.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Query minimization example: (a) Graph query with redundant components. (b) Graph query after minimization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Uncommon query example. It is uncommon to ask for somebody's great-great-grandparents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Question generation and paraphrasing. spectively. Suppose entity e has n(e) mentions, then p(e) =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Function</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Performance breakdown by (a) structure complexity, (b) function, (c) commonness, and (d) paraphrase. Note that in (c) x = −5 indicates the commonness range −10 ≤ log 10 (p(q)) &lt; 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>1679</head><label>1679</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Characteristic statistics. |A| is answer cardinality. Refer to Appendix D for paraphrase and other fine-grained distributions.</head><label>1</label><figDesc></figDesc><table>Question 
Domain 
Answer 
# of edges Function log 10 (p(q)) |A| 

Find terrorist organizations involved in 
September 11 attacks. 

The September 11 attacks were carried out with 
the involvement of what terrorist organizations? 
Terrorism 
alQaeda 
1 
none 
-16.67 
1 

Who did nine eleven? 

How many children of Eddard Stark were born 
in Winterfell? 

Winterfell is the home of how many of Eddard 
Stark's children? 
Fictional 
Universe 
3 
2 
count 
-23.34 
1 

What's the number of Ned Stark's children 
whose birthplace is Winterfell? 

In which month does the average rainfall of New 
York City exceed 86 mm? 

Rainfall averages more than 86 mm in New York 
City during which months? 
Travel 
March, August 
. . . 
3 
comp. 
-37.84 
7 

List the calendar months when NYC averages in 
excess of 86 millimeters of rain? 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Example questions and characteristics. Three sentence-level paraphrases are shown for each graph query, with the last 

one also involving entity-level paraphrasing. Topic entities are bold-faced. More examples can be found in Appendix D. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Dataset # of Questions # of Multi-relation Function (count/super./comp.) Commonness Paraphrase Multi-answer</head><label></label><figDesc></figDesc><table>GRAPHQUESTIONS (this work) 
5166 
2072 
710 / 332 / 269 
+ 
+ 
+ 

WEBQUESTIONSSP (Yih et al., 2016) 1 
4737 
2075 
2 / 168 / 334 
-
-
+ 

FREE917 (Cai and Yates, 2013) 
917 
229 
185 / 0 / 0 
-
-
+ 

Serban et al. (2016) 
30M 
0 
0 / 0 / 0 
-
-
-

SIMPLEQUESTIONS (Bordes et al., 2015) 
108K 
0 
0 / 0 / 0 
-
-
-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 3 : Comparison of QA datasets constructed from Freebase. GRAPHQUESTIONS is the richest in question characteristics.</head><label>3</label><figDesc></figDesc><table>System 
F1 
Time/s 

SEMPRE 
10.80 
56.19 

PARASEMPRE 12.79 
18.43 

JACANA 
5.08 
2.01 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 : Overall performance on GRAPHQUESTIONS.</head><label>4</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 : Performance breakdown by answer cardinality |A|.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="5"> Query Refinement Since graph queries are randomly generated, some of them may not correspond to an interesting question. Next we study two query characteristics, redundancy and commonness, based on which we provide mechanisms for automatic query refinement.</note>

			<note place="foot" n="2"> For each query template, we only generate one graph query, but one can also generate multiple graph queries, and easily get the corresponding questions by replacing the topic entities. This will significantly increase the total number of questions, and can be helpful in training.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Acknowledgements</head><p>This research was sponsored in part by the Army Research Laboratory under cooperative agreements W911NF09-2-0053, NSF IIS 0954125, and NSF IIS 1528175. The views and conclusions contained herein are those of the authors and should not be in-terpreted as representing the official policies, either expressed or implied, of the Army Research Lab-oratory or the U.S. Government. The U.S. Gov-ernment is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notice herein.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How does search behavior change as search becomes more difficult?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Aula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rehan</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Knowledge-based question answering as machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Analysis of long queries in a large scale search log</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 workshop on Web Search Click Data</title>
		<meeting>the 2009 workshop on Web Search Click Data</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Imitation learning of agenda-based semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="545" to="558" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGMOD</title>
		<meeting>SIGMOD</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02075</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Issues, tasks and program structures to roadmap research in question &amp; answering (q&amp;a)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinay</forename><surname>Chaudhri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Israel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Jacquemin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Maiorano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Understanding Conferences Roadmapping Documents</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing via schema matching and lexicon extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Question answering over Freebase with multi-column convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Training a natural language generator from unaligned data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Dušek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Jurčíček</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Open question answering over curated and extracted knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">FACC1: Freebase annotation of ClueWeb corpora, version 1 (release date 2013-0626</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<ptr target="http://lemurproject.org/clueweb09/andhttp://lemurproject.org/clueweb12/" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>format version 1, correction level 0</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Natural language question answering: the view from here</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynette</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">natural language engineering</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="275" to="300" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with onthe-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">DBpedia-a large-scale, multilingual knowledge base extracted from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Morsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Van Kleef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="195" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Lambda dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4408</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evaluating question answering over linked data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Cimiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Motta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics: Science, Services and Agents on the World Wide Web</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing without question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="377" to="392" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generating factoid questions with recurrent neural networks: The 30m factoid question-answer corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>García-Durán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Open domain question answering via semantic enrichment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Building a question answering test collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Building a semantic parser overnight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semantically conditioned LSTM-based natural language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep answers for naturally asked questions on the web of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shady</forename><surname>Elbassuoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Information extraction over structured data: Question answering with Freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Freebase QA: Information extraction or semantic parsing?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Lean question answering over Freebase from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semantic parsing via staged query graph generation: Question answering with knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The value of semantic parse labeling for knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jina</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Natural language question answering over rdf: a graph data driven approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruizhe</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haixun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">Xu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqiang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGMOD</title>
		<meeting>SIGMOD</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
