<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lessons from Natural Language Inference in the Clinical Domain</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Romanov</surname></persName>
							<email>aromanov@cs.uml.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">IBM Almaden Research Center</orgName>
								<orgName type="institution">University of Massachusetts Lowell * Lowell</orgName>
								<address>
									<addrLine>650 Harry Road San Jose</addrLine>
									<postCode>01854, 95120</postCode>
									<region>MA, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Shivade</surname></persName>
							<email>cshivade@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">IBM Almaden Research Center</orgName>
								<orgName type="institution">University of Massachusetts Lowell * Lowell</orgName>
								<address>
									<addrLine>650 Harry Road San Jose</addrLine>
									<postCode>01854, 95120</postCode>
									<region>MA, CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Lessons from Natural Language Inference in the Clinical Domain</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1586" to="1596"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1586</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>State of the art models using deep neural networks have become very good in learning an accurate mapping from inputs to outputs. However, they still lack generalization capabilities in conditions that differ from the ones encountered during training. This is even more challenging in specialized, and knowledge intensive domains, where training data is limited. To address this gap, we introduce MedNLI 1-a dataset annotated by doctors, performing a natural language inference task (NLI), grounded in the medical history of patients. We present strategies to: 1) leverage transfer learning using datasets from the open domain, (e.g. SNLI) and 2) incorporate domain knowledge from external data and lexical sources (e.g. medical terminologies). Our results demonstrate performance gains using both strategies.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural language inference (NLI) is the task of determining whether a given hypothesis can be inferred from a given premise. This task, for- merly known as recognizing textual entailment (RTE) ( <ref type="bibr" target="#b11">Dagan et al., 2006</ref>) has long been a popular task among researchers. Moreover, contribution of datasets from past shared tasks ( <ref type="bibr" target="#b10">Dagan et al., 2009)</ref>, and recent research ( <ref type="bibr" target="#b5">Bowman et al., 2015;</ref><ref type="bibr">Williams et al., 2018</ref>) have pushed the boundaries for this seemingly simple, but challenging prob- lem.</p><p>The Stanford Natural Language Inference (SNLI) dataset <ref type="bibr" target="#b5">(Bowman et al., 2015</ref>) is a large, high quality dataset and serves as a benchmark to evaluate NLI systems. However, it is restricted to a single text genre (Flickr image captions) and mostly consists of short and simple sentences. The MultiNLI corpus <ref type="bibr">(Williams et al., 2018</ref>) which in- troduced NLI corpora from multiple genres (e.g. fiction, travel) was a welcome step towards ad- dressing these limitations. MultiNLI offers diver- sity in linguistic phenomena, which makes it more challenging.</p><p>Following these efforts, we explore the prob- lem of NLI in the clinical domain. Language in- ference in specialized domains such as medicine is extremely complex and remains unexplored by the machine learning community. Moreover, since this domain has a distinct sublanguage <ref type="bibr" target="#b14">(Friedman et al., 2002</ref>), clinical text also presents unique challenges (abbreviations, inconsistent punctua- tion, misspellings, etc.) that differentiate it from open-domain data <ref type="bibr" target="#b24">(Meystre et al., 2008)</ref>.</p><p>In this paper, we address these gaps and make the following contributions:</p><p>• Introduce MedNLI -a new, publicly avail- able, expert annotated dataset for NLI in the clinical domain.</p><p>• A systematic comparison of several state-of- the-art open domain models on MedNLI.</p><p>• A study of transfer learning techniques from the open domain to the clinical domain.</p><p>• Techniques for incorporating domain- specific knowledge from knowledge bases (KB) and domain specific data into neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The MedNLI dataset</head><p>Let us recall the procedure followed for creating the SNLI dataset: annotators were presented with captions for a Flickr photo (the premise) without the photos themselves. They were asked to write three sentences (hypotheses): 1) A clearly true de- scription of the photo, 2) A clearly false descrip- tion, and 3) A description that might be true or false. This procedure produces three training pairs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head># Premise Hypothesis Label</head><p>1 ALT , AST , and lactate were elevated as noted above patient has abnormal lfts entailment 2 Chest x-ray showed mild congestive heart failure The patient complains of cough neutral 3 During hospitalization , patient became progres- sively more dyspnic requiring BiPAP and then a NRB</p><p>The patient is on room air contradiction 4 She was not able to speak , but appeared to com- prehend well Patient had aphasia entailment 5 T1DM : x 7yrs , h/o DKA x 6 attributed to poor medication compliance , last A1c [ ** 3-23 ** ] : 13.3 % 2</p><p>The patient maintains strict glucose control contradiction 6 Had an ultimately negative esophagogastroduo- denoscopy and colonoscopy Patient has no pain neutral 7 Aorta is mildly tortuous and calcified . the aorta is normal contradiction <ref type="table">Table 1</ref>: Examples from the development set of MedNLI of sentences for each premise with three differ- ent labels: entailment, contradiction, and neutral, respectively. In order to produce a comparable dataset, we used the same approach adjusted for the clinical domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Premise sampling and hypothesis generation</head><p>As the source of premise sentences, we used the MIMIC-III v1.3 (Johnson et al., 2016) database. With de-identified records of 38,597 patients, it is the largest repository of publicly available clini- cal data. Along with medications, lab values, vital signs, etc. MIMIC-III contains 2,078,705 clinical notes written by healthcare professionals in En- glish. The hypothesis sentences were generated by clinicians. Clinical notes are typically organized into sections such as Chief Complaint, Past Medical History, Physical Exam, Impression, etc. These sections can be easily identified since the formatting for associated section headers often resembles capital letters, followed by a colon. The clinicians in our team suggested Past Medical History to be the most informative section of a clinical note, from which critical inferences can be drawn about the patient.</p><p>Therefore, we segmented these notes into sec- tions using a simple rule based program capturing the formatting of these section headers. We ex- tracted the Past Medical History section and used a sentence splitter trained on biomedical articles <ref type="bibr">(Lingpipe, 2008)</ref> to get a pool of candi- date premises. We then randomly sampled a sub- set from these candidates and presented them to You will be shown a sentence from the Past Medical History section of a de-identified clinical note. Using only this sentence, your knowledge about the field of medicine, and common sense:</p><p>• Write one alternate sentence that is definitely a true description of the patient. Example, for the sentence "Patient has type II diabetes" you could write "Patient suffers from a chronic condition"</p><p>• Write one alternate sentence that might be a true description of the patient. Example, for the sen- tence "Patient has type II diabetes" you could write "Patient has hypertension"</p><p>• Write one sentence that is definitely a false de- scription of the patient. Example, for the sentence "Patient has type II diabetes" you could write "The patient's insulin levels are normal without any medications." <ref type="figure">Figure 1</ref>: Annotation prompt shown to clinicians the clinicians for annotation. <ref type="figure">Figure 1</ref> shows the exact prompt shown to the clinicians for the anno- tation task. SNLI annotations are grounded since they are associated with captions of the same im- age. We seek to achieve the same goal by ground- ing the annotations against the medical history of the same patient. As discussed earlier, examples shown in <ref type="table">Table 1</ref> depict unique challenges that involve reasoning over domain-specific knowledge. For instance, the first three examples require the knowledge about clinical terminology. The fourth example requires awareness of medications and the last example elicits knowledge about radiology images. We make the MedNLI dataset available 2 through the MIMIC-III derived data repository. Thus, any in- dividual certified to access MIMIC-III can also ac- cess MedNLI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Annotation collection</head><p>Conclusions in the clinical domain are known to be context dependent and a source of multiple un- certainties <ref type="bibr" target="#b17">(Han et al., 2011</ref>). We had to ensure that such subjective interpretations do not result in annotation conflicts affecting the quality of the dataset. To ensure agreement, we worked with clinicians and generated annotation guidelines for a pilot study. Two board certified radiologists worked on the annotation task, and were presented with the 100 unique premises each.</p><p>Some premises, often marred by de- identification artifacts, did not contain any information from which useful inferences could be drawn, e.g. This was at the end of [ ** Month (only) 1702 ** ] of this year. Such sentences were deemed as invalid for the task and discarded based on clinician judgment. The MIMIC-III dataset contains many de-identification artifacts associated with dates and names (persons and places) which also makes MedNLI more challenging.</p><p>After discarding 16 premises, the result of hy- pothesis generation was a set of 552 pairs. To calculate agreement, we presented pairs generated by one clinician, and sought annotations from the other clinician, determining if the inference was "Definitely true", "Maybe true", or "Definitely false" <ref type="bibr" target="#b5">(Bowman et al., 2015)</ref>. Comparison of these annotations resulted in a Cohen's kappa of κ = 0.78. While this is substantial if not perfect agreement by itself <ref type="bibr" target="#b23">(McHugh, 2012)</ref>, it is particu- larly good given the challenging nature of NLI and the complexity of the domain. <ref type="bibr">3</ref> On reviewing the annotations, we found that la- beling differences between "Definitely true" and "Maybe true" were the major source of disagree- ment. This was primarily because one clinician would think of a scenario that is generally true, while the other would think of assumptions (e.g. patient might be lying, or patient might be preg- nant) when it would not.</p><p>A discussion with clinicians concluded that the annotation guideline was clear and any person with a formal background of medicine should be able to complete the task successfully. To generate the final dataset, we recruited two additional clin- icians, both board certified medical students pur- suing their residency programs. Unlike SNLI, we did not collect multiple annotations per sentence pair because of the time and funding constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Dataset statistics</head><p>Together, the four clinicians worked on a total of 4,683 premises over a period of six weeks. The re- sulting dataset consists of 14,049 unique sentence pairs. Following Bowman et al. <ref type="formula">(2015)</ref>  <ref type="table">Table 2</ref>: Key statistics of the dataset the dataset into training, development, and testing subsets and ensured that no premise was overlap- ping between the three subsets. <ref type="table">Table 2</ref> presents key statistics of MedNLI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Models</head><p>To establish a baseline performance on MedNLI, we experimented with a feature-based system. To further explore the performance of modern neural networks-based systems, we experimented several models of various degrees of complexity: Bag of Words (BOW), InferSent (Conneau et al., 2017) and ESIM ( <ref type="bibr" target="#b7">Chen et al., 2017)</ref>. Note that our goal here is not to outperform existing models, but to explore the relative gain of the proposed methods, and compare them to a baseline. We used the same set of hyperparameters in all models to ensure that any difference in performance is exclusively due to the algorithms.</p><p>Feature-based system We used a gradient boosting classifier incorporating a variety of hand crafted features. Apart from standard NLP fea- tures, we also infused clinical knowledge from the Unified Medical Language System (UMLS) <ref type="bibr" target="#b3">(Bodenreider, 2004</ref>). Each terminology in the UMLS can be viewed as a graph where nodes represent medical concepts, and edges represent relations between them. These are canonical relationships found in ontologies such as IS A and SYNONYMY. For instance, diabetes IS A disorder of the en- docrine system. The domain specific features we added to the model represent similarity between UMLS concepts from the premise and the hypoth- esis, based how close they appear in the UMLS graph <ref type="bibr" target="#b27">(Pedersen et al., 2007)</ref>. Following <ref type="bibr" target="#b32">(Shivade et al., 2015;</ref><ref type="bibr" target="#b27">Pedersen et al., 2007)</ref> we used the SNOMED-CT terminology in our experiments. The groups below summarize the feature sets used in our model (35 features in total):  <ref type="bibr" target="#b15">(Glorot et al., 2011</ref>). In order to rep- resent an input sentence as a single vector, this architecture simply sums up the vectors of indi- vidual tokens. The premise and hypothesis vec- tors are then concatenated and passed through a multi-layer neural network. Recent work shows that even this straightforward approach encodes a non-trivial amount of information about the sen- tence ( <ref type="bibr" target="#b0">Adi et al., 2017</ref>).</p><p>InferSent InferSent ( <ref type="bibr" target="#b9">Conneau et al., 2017</ref>) is a model for sentence representation that demon- strated close to state-of-the-art performance across a number of tasks in NLP (including NLI) and computer vision. The main differences from the BOW model are as follows:</p><p>• A bidirectional LSTM encoder of input sen- tences and a max-pooling operation over timesteps are used to get a vector for the premise (p) and for the hypothesis (h); • A more complex scheme of interaction be- tween the vectors p and h to get a single vec- tor z that contains all the information needed to produce a decision about the relationship between the input sentences:</p><formula xml:id="formula_0">z = [p, h, |p − h|, p * h].</formula><p>ESIM The ESIM model, developed by <ref type="bibr" target="#b7">Chen et al. (2017)</ref>, is shown in <ref type="figure" target="#fig_0">Figure 2</ref>. It is a fairly complex model that makes use of two bidirec- tional LSTM networks. The basic idea of ESIM is as follows:</p><p>• The first LSTM produces a sequence of hid- den states.</p><p>• Pairwise attention matrix e is computed be- tween all tokens in the premise and the hy- pothesis to produce new sequences of "at- tended" hidden states, which are then fed into the second LSTM.</p><p>• Max and average pooling are performed over the output of the LSTMs.</p><p>• The output of the pooling operations is com- bined in a way similar to the InferSent model. The three aforementioned models exemplify the architectures that are, perhaps, the most widely used for NLI task, spanning from simple bag-of- words approaches to complicated models with Bi- LSTM and inter-sentence attention. We addition- ally experimented with a plain Bi-LSTM model as well as GRU <ref type="figure" target="#fig_0">(Cho et al., 2014</ref>), but since their per- formance was not remarkable (in the same range as BOW) we do not report it here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Transfer learning</head><p>Given the existence of larger general-domain NLI datasets such as SNLI and MultiNLI, it stands to reason to try to leverage them to improve the per- formance in the clinical domain. Transfer learning has been shown to improve performance on vari- ety of tasks such as: machine translation on low- resource languages ( <ref type="bibr">Zoph et al., 2016</ref>) and also some tasks from the bio-medical domain in par- ticular ( <ref type="bibr" target="#b31">Sahu and Anand, 2017;</ref><ref type="bibr" target="#b20">Lee et al., 2018)</ref>. To see if a corresponding boost would be possi- ble for the NLI task, we investigated three com- mon transfer learning techniques on the MedNLI dataset using SNLI and five different genres from MultiNLI.</p><p>Direct transfer is the simplest method of trans- fer learning. After training a model on a large source domain dataset, the model is directly tested on the target domain dataset. If the source and the target domains are similar to some extent, one can achieve a reasonable accuracy by simply applying a model pre-trained on the source domain to the target domain. In our case the source domain is general domain in SNLI and the various genres in MultiNLI, and the target domain is clinical.</p><p>Sequential transfer is the most widely used technique. After pre-training the model on a large source domain, the model is further fine-tuned us- ing the smaller training data of the target domain.</p><p>The assumption is that while the model would learn domain-specific features, it would also learn some domain-independent features that will be useful for the target domain. Furthermore, the fine-tuning process would affect the learned fea- tures from the source domain and make them more suitable for the target domain.</p><p>Multi-target transfer is a more complex method involving separation of the model into three components (or layers):</p><p>• The shared component is trained on both the source and target domains;</p><p>• The source domain component is trained only during the pre-training phase and does not participate in the prediction of the target do- main; • The target domain component is trained dur- ing the fine-tuning stage and it produces the predictions together with the shared compo- nent.</p><p>The motivation for multi-target transfer is that performance should be improved by splitting deeper layers of the model into domain-specific parts and having a shared block early in the network, where it presumably learns domain- independent features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Word embeddings</head><p>Another way to improve the accuracy on the tar- get domain is to use domain-specific word embed- dings instead of, or, in addition to, open-domain ones. For example, <ref type="bibr" target="#b33">Stanovsky et al. (2017)</ref> achieved state of the art results on the task of recognizing Adverse Drug Reaction using graph- based embeddings trained on the "Drugs" and "Diseases" categories from DBpedia ( <ref type="bibr" target="#b21">Lehmann et al., 2015)</ref>, as well as embeddings trained on web-pages categorized as "medical domain".</p><p>We experimented with the following publicly available general-domain word embeddings:</p><p>• GloVe <ref type="bibr">[CC]</ref> : GloVe embeddings ( <ref type="bibr" target="#b28">Pennington et al., 2014</ref>), trained on Common Crawl 4 .</p><p>• fastText <ref type="bibr">[Wiki]</ref> : fastText embeddings ( <ref type="bibr" target="#b4">Bojanowski et al., 2017)</ref>, trained on Wikipedia.</p><p>• fastText <ref type="bibr">[CC]</ref> : fastText embeddings, trained on Common Crawl.</p><p>Furthermore, we trained fastText embeddings on the following domain-specific corpora:</p><p>• fastText <ref type="bibr">[BioASQ]</ref> :A collection of PubMed abstracts from the BioASQ challenge data ( <ref type="bibr">Tsatsaronis et al., 2015)</ref>. This data includes abstracts from 12,834,585 scientific articles from the biomedical domain.</p><p>• fastText <ref type="bibr">[MIMIC-III]</ref> : Clinical notes for pa- tients from the MIMIC-III database (Johnson et al., 2016): 2,078,705 notes with 320 tokens in each on average.</p><p>Finally, we experimented with initializing word embeddings with pre-trained vectors from general domain and further training on a domain-specific corpus:</p><p>• GloVe <ref type="bibr">[CC]</ref> → fastText <ref type="bibr">[BioASQ]</ref> : GloVe embed- dings for initialization, and the BioASQ data for fine-tuning.</p><p>• GloVe <ref type="bibr">[CC]</ref> → fastText <ref type="bibr">[BioASQ]</ref> → fastText <ref type="bibr">[MIMIC-III]</ref> : GloVe embeddings for initialization, and two consequent fine- tuning using the BioASQ and MIMIC-III data.</p><p>• fastText <ref type="bibr">[Wiki]</ref> → fastText <ref type="bibr">[MIMIC-III]</ref> : fastText Wikipedia embeddings for initialization, and the MIMIC-III data for fine-tuning.</p><p>Experiments using other approaches to word embeddings, such as word2vec ( <ref type="bibr" target="#b25">Mikolov et al., 2013</ref>) and CoVe ( <ref type="bibr" target="#b22">McCann et al., 2017</ref>) did not show any gains. All the above trained embeddings are available for download.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Knowledge integration</head><p>Since understanding medical texts requires domain-specific knowledge, we experimented with different ways of incorporating such knowl- edge into the systems. First, we can modify the input to the system so it carries a portion of clinical information. Second, we can modify the model itself, integrating domain knowledge directly into it.</p><p>The UMLS is the largest, publicly available, and regularly updated database of medical ter- minologies, concepts, and relationships between them. It can be viewed as a graph where clini- cal concepts are nodes, connected by edges rep- resenting relations, such as synonymy, parent- child, etc. Following past work, we restricted to the SNOMED-CT terminology in UMLS and ex- perimented with two techniques for incorporating knowledge: retrofitting and attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Retrofitting</head><p>Retrofitting ( <ref type="bibr" target="#b12">Faruqui et al., 2015</ref>) modifies pre- trained word embeddings based on an ontology. The basic idea is to try to bring the representations of the concepts that are connected in the ontology closer to one another in vector space. The authors showed that retrofitting using WordNet <ref type="bibr" target="#b13">(Fellbaum, 1998</ref>) synsets improves accuracy on several word- level tasks, as well as sentiment analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Knowledge-directed attention</head><p>Attention proved to be a useful technique for many NLP tasks, starting from machine transla- tion ( <ref type="bibr" target="#b2">Bahdanau et al., 2015</ref>) to parsing <ref type="bibr" target="#b35">(Vinyals et al., 2015)</ref> and NLI itself ( <ref type="bibr" target="#b26">Parikh et al., 2016;</ref><ref type="bibr" target="#b30">Rocktäschel et al., 2016)</ref>. In most models (includ- ing the ESIM model that we use in our experi- ments) attention is learned in an end-to-end fash- ion. However, if we have knowledge about rela- tionships between concepts, we could leverage it to explicitly tell the model to attend to specific concepts during the processing of the input sen- tence.</p><p>For example, there is an edge in SNOMED-CT from the concept Lung consolidation to Pneumo- nia. Using this information, during the processing of a sentence pair</p><p>• Premise The patient has pneumonia.</p><p>• Hypothesis The patient has a lung disease. the model could attend to the token lung while pro- cessing pneumonia.</p><p>We propose to integrate this knowledge in a way similar to how attention is used in the ESIM model. Specifically, we calculate the attention ma- trix e ∈ R n×m between all pairs of tokens a i and b j in the inputs sentences, where n is the length of the hypothesis and m is the length of the premise. The value in each cell reflects the length of the shortest path l ij between the corre- sponding concepts of the premise and the hypoth- esis in SNOMED-CT (the shorter is the path, the higher is the value).</p><p>This process could be informally described as follows: each tokeñ a i of the premise is a weighted sum of relevant tokens b j of the hypothesis, ac- cording to the medical ontology, and vice versa. This enables the medical domain knowledge to be integrated directly into the system.</p><p>We used the original tokens a i as well as the attendedãattended˜attendedã i inside the model for both InferSent and ESIM. For InferSent, we simply concatenate them across the time dimension:</p><formula xml:id="formula_1">ˆ a = [a 1 , a 2 , . . . , a n , ˜ a 1 , ˜ a 2 , . . . , ˜ a n ]</formula><p>where n is the length of the inputs sequence. For the ESIM model, we concatenate a i andãand˜andã i before passing them to the composition layer (see <ref type="figure" target="#fig_0">Fig- ure 2</ref> and Section 3.3 in the original paper <ref type="bibr" target="#b7">(Chen et al., 2017)</ref>). This enables the model to learn the relative importance of both the token and the knowledge directed attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Set Features BOW InferSent ESIM</head><p>Dev 51.9 71.9 76.0 74.4 Test 51.9 70.2 73.5 73.1 <ref type="table">Table 3</ref>: Baseline accuracy on the development and the test set of MedNLI for different models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and discussion</head><p>We implemented all models using PyTorch <ref type="bibr">5</ref> and trained them with the Adam optimizer ( <ref type="bibr" target="#b19">Kingma and Ba, 2015</ref>) until the validation loss showed no improvement for 5 epochs. The epoch with the lowest loss on the validation set was selected for testing. We used the GloVe word embed- dings ( <ref type="bibr" target="#b28">Pennington et al., 2014</ref>) in all experiments, except for subsection 5.3. In all experiments we report the average result of 6 different runs, with the same hyperparameters and different random seeds. Medical concepts in SNOMED-CT were identified in the premise and hypothesis sentences using Metamap <ref type="bibr" target="#b1">(Aronson and Lang, 2010)</ref>. The code for all experiments is publicly available. 6 <ref type="table">Table 3</ref> shows the baseline results: the perfor- mance of a model when trained and tested on the MedNLI dataset. The feature-based system performed the worst. As for neural networks- based systems, the BOW model showed the low- est performance on the both development and test sets. The InferSent model, in contrast, achieved the highest accuracy, despite ESIM outperform- ing it on SNLI. This could be attributed to the fact that ESIM has twice as many parameters as InferSent, and so InferSent overfits less to the smaller MedNLI dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baselines</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Transfer learning</head><p>As expected, <ref type="table">Table 4</ref> shows that direct transfer is worse than the baseline but is still better than a random baseline of 33.3%. Sequential and multi- target transfer learning, in contrast, yields a con- siderable gain for all the models. The maximum gain is 2.4%, 0.9%, and 0.3% for the BOW, In- ferSent, and ESIM models correspondingly. Second, note that the biggest SNLI domain gave the most boost in only two out of six cases, imply- ing that the size of the domain should not be the most important factor in choosing the source do- main for transfer learning. The best accuracy for all the models was obtained with the "slate" do- main from MultiNLI corpus with sequential trans- fer (note, however, that the accuracy of ESIM is actually lower than the baseline accuracy). This is consistent with observations of <ref type="bibr">Williams et al. (2018)</ref>. Finally, although some domains are better for particular transfer learning methods with par- ticular models, there is no single combination that works for all cases. <ref type="table">Table 5</ref> shows that simply using of the embed- dings trained on the MIMIC-III notes significantly increases the accuracy for all the models. Fur- thermore, the InferSent models achieves a 3.1% boost with the fastText Wikipedia embeddings, fine-tuned on the MIMIC-III data. Note that the results fastText <ref type="bibr">[Wiki]</ref> are worse than the baseline GloVe <ref type="bibr">[CC]</ref> for all models, which could be due to the source corpus size. However, the results on BioASQ are worse than on MIMIC-III, despite the significantly larger corpus of the BioASQ embed- dings. Overall, our experiments show the bene- fit of domain-specific rather than general-domain word embeddings. <ref type="table" target="#tab_3">Table 6</ref> shows that retrofitting only hurts the per- formance. This is in contrast with the results of the original study, where retrofitting was bene- ficial not only for word-level tasks but also for tasks such as sentiment analysis <ref type="bibr" target="#b12">(Faruqui et al., 2015)</ref>. We hypothesize that although WordNet and UMLS are structurally similar, significant dif- ferences in the content <ref type="bibr" target="#b6">(Burgun and Bodenreider, 2001</ref>) might be the reason for these results. Retrofitting should be more useful when it is used on a WordNet-like database where the main rela- tion is synonymy, and tested on tasks such as word similarity tests or sentiment analysis. The UMLS semantic network is more complex and contains relations that may not be suitable for retrofitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Word embeddings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Knowledge integration</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Retrofitting</head><p>Moreover, retrofitting works only on directly related concepts in a knowledge graph (although it might affect, to some extent, indirectly related concepts by transitivity). However, as <ref type="figure" target="#fig_2">Figure 3</ref> shows, UMLS contains few training pairs that have such concepts (namely, pairs with a path of   <ref type="table">Table 4</ref>: Absolute gain in accuracy with respect to the baseline (see <ref type="table">Table 3</ref>) on the MedNLI test set for different transfer learning modes. Bold indicates the best source domain for each model and transfer. <ref type="bibr">[BioASQ]</ref> 0.2 0.7 1.4 GloVe <ref type="bibr">[CC]</ref> → fastText <ref type="bibr">[BioASQ]</ref> → fastText <ref type="bibr">[MIMIC-III]</ref> 0.9 2.7 1.8 fastText <ref type="bibr">[Wiki]</ref> → fastText <ref type="bibr">[MIMIC-III]</ref> 0.1 3.1 1.7 <ref type="table">Table 5</ref>: Absolute gain in accuracy with respect to the baseline (GloVe <ref type="bibr">[CC]</ref> ) for different word embed- dings (the number in parentheses reflects the num- ber of tokens in the corresponding training cor- pora).</p><formula xml:id="formula_2">Embeddings BOW InferSent ESIM fastText [Wiki] -3.5 -3.5 -4.4 fastText [CC] (600B) -0.6 1.3 -0.3 fastText [BioASQ] (2.3B) 0.5 0.6 0.2 fastText [MIMIC-III] (0.8B) 1.1 2.3 1.2 GloVe [CC] → fastText</formula><p>length 1). In contrast, the lengths of the shortest path in SNLI using WordNet fall close to 1. This suggests that the medical inferences represented in MedNLI requires more complex reasoning, typi- cally involving multiple steps.</p><p>As a sanity check, we applied retrofitting to the GloVe embeddings and tested the InferSent model on the "fiction" domain from the MultiNLI corpus. We used the code and lexicons pro- vided by <ref type="bibr" target="#b12">Faruqui et al. (2015)</ref> and confirmed that retrofitting hurts the performance in that case as well.</p><p>BOW InferSent ESIM -1.7 -2.0 -2.7 Absolute gain in accuracy using retrofitting for MedNLI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Knowledge-directed attention</head><p>To evaluate the potential of knowledge-directed attention, let us consider its effect on a base- line embedding (GloVe <ref type="bibr">[CC]</ref> ) and a fastText em- bedding trained on MIMIC-III (fastText <ref type="bibr">[MIMIC-III]</ref> ) that showed good performance in section 5.3.</p><p>Knowledge-directed attention showed positive effect with the InferSent model on GloVe <ref type="bibr">[CC]</ref>  Shortest path length gain), and was not detrimental to ESIM. How- ever, in case of the fastText <ref type="bibr">[MIMIC-III]</ref> embeddings knowledge-directed attention was beneficial to both models, as shown in <ref type="table" target="#tab_5">Table 7</ref>. Note that while retrofitting can use only direct relations during the training process, our method incorporates infor- mation about relationships of any length, which is a necessity (as evident from <ref type="figure" target="#fig_2">Figure 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Embedding</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>InferSent ESIM</head><p>GloVe <ref type="bibr">[CC]</ref> 0.3 0.0 fastText <ref type="bibr">[MIMIC-III]</ref> 0.2 0.3 Absolute gain in accuracy using knowledge-directed attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Error analysis</head><p>The neutral class is the hardest to recognize for all models. Majority errors stem from confusion between entailment and the neutral class. Use of domain-specific embeddings trained on MIMIC-  III result in gains which are equally distributed across all three classes. Interestingly, gains from knowledge-directed attention stem mostly (60%) from the neutral class. Moreover, 87% of these neutral predictions were predicted as entailment before adding the knowledge directed attention.</p><p>We categorized the errors made by all the mod- els in four broad categories. <ref type="table" target="#tab_7">Table 8</ref> outlines rep- resentative errors made by most models in these categories. Numerical reasoning such as abnor- mal lab value → disease or abnormal vital sign → finding are very hard for a model to learn un- less it has seen multiple instances of the same nu- merical value. <ref type="bibr">7</ref> The first step is to learn what val- ues are abnormal and the next is to actually per- form the inference. Many inferences require world knowledge that could be deemed close to open do- main NLI. While these are very subtle, some are quite domain specific (e.g. emergency admission planned visit). Abbreviations are ubiquitously found in clinical text. While some are standard and therefore frequent, clinicians tend to use non standard abbreviations making inference harder. Finally, many inferences are at the core of rea- soning with clinical knowledge. While training on large datasets maybe a natural but impractical solution, this is an open research problem for re- searchers in the community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Limitations</head><p>Unlike SNLI and MultiNLI, each example in the MedNLI dataset was single annotated. However, this was the best we could do in the limited time and resources available. Very recently Gururan- gan et al. (2018) discovered annotation artifacts in NLI datasets. Since we followed the exact same process, we found them to be present in MedNLI as well. The premise-oblivious text-classifier that <ref type="bibr">7</ref> The symbol → represents entailment relationship achieves 67.0 F1 on SNLI, and 53.9 on Multi-NLI achieves 61.9 on MedNLI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We have presented MedNLI, an expert annotated, public dataset for natural language inference in the clinical domain. To the best of our knowledge, MedNLI is the first dataset of its kind. Our ex- periments with several state-of-the-art models pro- vide a strong baseline for this dataset. Our work compliments the current efforts in NLI by present- ing thorough experiments for the specialized and knowledge intensive field of medicine. We also demonstrated that a simple use of domain-specific word embeddings provides a performance boost. Finally, we also presented a method for integrat- ing domain ontologies into the training regime of models. We hope the released code and dataset with clear benchmarks help advance research in clinical NLP and the NLI task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: ESIM model. Dashed blocks illustrate the knowledge-directed attention matrix and the corresponding vectors (see Section 4.2.2 for details).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Source</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Lengths of the shortest paths between concepts in the premise and the hypothesis. 0 indicates that they contain the same concept.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>, we split</head><label>we</label><figDesc></figDesc><table>Dataset size 
Training pairs 
11232 
Development pairs 
1395 
Test pairs 
1422 

Average sentence length in tokens 
Premise 
20.0 
Hypothesis 
5.8 

Maximum sentence length in tokens 
Premise 
202 
Hypothesis 
20 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Representative errors made by different models 

</table></figure>

			<note place="foot" n="2"> https://jgc128.github.io/mednli/</note>

			<note place="foot" n="3"> Rajpurkar et al. (2017) report F1 &lt; 0.45 for four radiologists when compared among themselves</note>

			<note place="foot" n="4"> http://commoncrawl.org/</note>

			<note place="foot" n="5"> https://pytorch.org/ 6 https://jgc128.github.io/mednli/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work would not have been possible with-out Adam Coy, Andrew Colucci, Chanida Tham-machart, and Hassan Ahmad-the clinicians in our team who helped us in creating the dataset. We are grateful to Vandana Mukherjee and Tan-veer Syeda-Mahmood for supporting the project. We would also like to thank Anna Rumshisky and Anna Rogers for their help in this work. Most importantly, we would like to thank Leo Anthony Celi and Alistair Johnson from the MIMIC team for helping us in making MedNLI publicly avail-able.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fine-grained analysis of sentence embeddings using auxiliary prediction tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Adi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Einat</forename><surname>Kermany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Lavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An overview of metamap: historical perspective and recent advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Alan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François-Michel</forename><surname>Aronson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="229" to="236" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Unified Medical Language System (UMLS): Integrating biomedical terminology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="267" to="270" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>suppl</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Comparing terms, concepts and semantic classes in WordNet and the Unified Medical Language System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anita</forename><surname>Burgun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Workshop: WordNet and other lexical resources: Applications, extensions and customizations</title>
		<meeting>the NAACL Workshop: WordNet and other lexical resources: Applications, extensions and customizations</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="77" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Enhanced lstm for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Procedings of ACL</title>
		<meeting>edings of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the properties of neural machine translation: Encoder-decoder approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</title>
		<meeting>SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recognizing textual entailment: Rational, evaluation and approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="i" to="xvii" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Retrofitting word vectors to semantic lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sujay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Jauhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Bradford Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Two biomedical sublanguages: a description based on the theories of Zellig Harris</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carol</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pauline</forename><surname>Kra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Rzhetsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="222" to="235" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Annotation artifacts in natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Suchin Gururangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Varieties of uncertainty in health care: a conceptual taxonomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neeraj K</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Decision Making</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="828" to="838" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Alistair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liwei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengling</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><forename type="middle">Anthony</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger G</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Transfer learning for named-entity recognition with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><forename type="middle">Young</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franck</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dbpedia-a large-scale, multilingual knowledge base extracted from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Morsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Van Kleef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="195" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learned in translation: Contextualized word vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Interrater reliability: the kappa statistic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mchugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biochemia medica</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="276" to="282" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Extracting information from textual documents in the electronic health record: a review of recent research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephane</forename><forename type="middle">M</forename><surname>Meystre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guergana</forename><forename type="middle">K</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><forename type="middle">C</forename><surname>Kipper-Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">F</forename><surname>Hurdle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Yearbook of Medical Informatics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="128" to="172" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A decomposable attention model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ankur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Measures of semantic similarity and relatedness in the biomedical domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Serguei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Pakhomov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher G</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chute</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="288" to="299" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaylie</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hershel</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisy</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aarti</forename><surname>Bagul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Curtis</forename><surname>Langlotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Shpanskaya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05225</idno>
		<title level="m">Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Reasoning about entailment with neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočisk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Kočisk`y, and Phil Blunsom</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">What matters in a transferable neural network model for relation classification in the biomedical domain?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kumar</forename><surname>Sunil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anand</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.03446</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Textual inference for eligibility criteria resolution in clinical trials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Shivade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcelo</forename><surname>Lopetegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Fosler-Lussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert M</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="211" to="218" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Recognizing mentions of adverse drug reaction in social media using knowledge-infused recurrent models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gruhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sergios Petridis, Dimitris Polychronopoulos, et al. 2015. An overview of the bioasq large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Michael R Alvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krithara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">138</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2773" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
