<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ParlAI: A Dialog Research Software Platform</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ParlAI: A Dialog Research Software Platform</title>
					</analytic>
					<monogr>
						<title level="j" type="main">EMNLP System Demonstrations</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="79" to="84"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce ParlAI (pronounced &quot;par-lay&quot;), an open-source software platform for dialog research implemented in Python, available at http://parl.ai. Its goal is to provide a unified framework for sharing, training and testing dialog models; integration of Amazon Mechanical Turk for data collection, human evaluation, and online/reinforcement learning; and a repository of machine learning models for comparing with others&apos; models, and improving upon existing architectures. Over 20 tasks are supported in the first release, including popular datasets such as SQuAD, bAbI tasks, MCTest, WikiQA, QACNN, QADaily-Mail, CBT, bAbI Dialog, Ubuntu, OpenSubti-tles and VQA. Several models are integrated, including neural models such as memory networks , seq2seq and attentive LSTMs.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The purpose of language is to accomplish communi- cation goals, which typically involve a dialog between two or more communicators <ref type="bibr" target="#b4">(Crystal, 2004)</ref>. Hence, trying to solve dialog is a fundamental goal for re- searchers in the NLP community. From a machine learning perspective, building a learning agent capa- ble of dialog is also fundamental for various reasons, chiefly that the solution involves achieving most of the subgoals of the field, and in many cases those subtasks are directly impactful to the task.</p><p>On the one hand dialog can be seen as a single task (learning how to talk) and on the other hand as thou- sands of related tasks that require different skills, all us- ing the same input and output format. The task of book- ing a restaurant, chatting about sports or the news, or answering factual or perceptually-grounded questions all fall under dialog. Hence, methods that perform task transfer appear crucial for the end-goal. Memory, log- ical and commonsense reasoning, planning, learning from interaction, learning compositionality and other AI subgoals also have clear roles in dialog.</p><p>However, to pursue these research goals, we require software tools that unify the different dialog sub-tasks  and the agents that can learn from them. Working on individual datasets can lead to siloed research, where the overfitting to specific qualities of a dataset do not generalize to solving other tasks. For example, meth- ods that do not generalize beyond WebQuestions (Be- rant et al., 2013) because they specialize on knowledge bases only, <ref type="bibr">SQuAD (Rajpurkar et al., 2016</ref>) because they predict start and end context indices (see Sec. 7), or bAbI ( ) because they use support- ing facts or make use of its simulated nature.</p><p>In this paper we present a software platform, Par- lAI (pronounced "par-lay"), that provides researchers a unified framework for training and testing dialog models, especially multitask training or evaluation over many tasks at once, as well as seamless integration with Amazon Mechanical Turk. Over 20 tasks are supported in the first release, including many popular datasets, see <ref type="figure" target="#fig_0">Fig. 1</ref>. Included are examples of training neural mod- els with PyTorch and Lua Torch 1 . Using Theano 2 or Tensorflow 3 instead is also straightforward.</p><p>The overarching goal of ParlAI is to build a community-based platform for easy access to both tasks and learning algorithms that perform well on them, in order to push the field forward. This pa- per describes our goals in detail, and gives a technical overview of the platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Goals</head><p>The goals of ParlAI are as follows: A unified framework for development of dialog models. ParlAI aims to unify dialog dataset input for- mats fed to machine learning agents to a single format, and to standardize evaluation frameworks and metrics as much as possible. Researchers can submit their new tasks and their agent training code to the repository to share with others in order to aid reproducibility, and to better enable follow-on research. General dialog involving many different skills. ParlAI contains a seamless combination of real and simulated language datasets, and encourages multitask model development &amp; evaluation by making multitask models as easy to build as single task ones. This should reduce overfitting of model design to specific datasets and encourage models that perform task transfer, an im- portant prerequisite for a general dialog agent. Real dialog with people. ParlAI allows collecting, training and evaluating on live dialog with humans via Amazon Mechanical Turk by making it easy to connect Turkers with a dialog agent, see <ref type="figure" target="#fig_1">Fig. 2</ref>. This also en- ables comparison of Turk experiments across different research groups, which has been historically difficult. Towards a common general dialog model. Our aim is to motivate the building of new tasks and agents that move the field towards a working dialog model. Hence, each new task that goes into the repository should build towards that common goal, rather than be- ing seen solely as a piece of independent research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">General Properties of ParlAI</head><p>ParlAI consists of a number of tasks and agents that can be used to solve them. All the tasks in ParlAI have a single format (API) which makes applying any agent to any task, or multiple tasks at once, simple. The tasks include both fixed supervised/imitation learn- ing datasets (i.e. conversation logs) and interactive (on- line or reinforcement learning) tasks, as well as both real language and simulated tasks, which can all be 1 http://pytorch.org/ and http://torch.ch/ 2 http://deeplearning.net/software/theano/ 3 https://www.tensorflow.org/ teacher = SquadTeacher(opt) agent = MyAgent(opt) world = World(opt, <ref type="bibr">[teacher, agent]</ref>) for i in range(num_exs):</p><p>world.parley() print seamlessly trained on. ParlAI also supports other me- dia, e.g. images as well as text for visual question an- swering ( <ref type="bibr" target="#b0">Antol et al., 2015</ref>) or visually grounded dia- log ( <ref type="bibr" target="#b5">Das et al., 2017)</ref>. ParlAI automatically downloads tasks and datasets the first time they are used. One or more Mechanical Turkers can be embedded inside an environment (task) to collect data, train or evaluate learning agents. Examples are included in the first release of train- ing with PyTorch and Lua Torch. ParlAI uses ZeroMQ to talk to languages other than Python (such as Lua Torch). Both batch training and hogwild training of models are supported and built into the code. An ex- ample main for training an agent is given in <ref type="figure" target="#fig_2">Fig. 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Worlds, Agents and Teachers</head><p>The main concepts (classes) in ParlAI are worlds, agents and teachers:</p><p>• world -the environment. This can vary from be- ing very simple, e.g. just two agents conversing, to much more complex, e.g. multiple agents in an interactive environment.</p><p>• agent -an agent that can act (especially, speak) in the world. An agent is either a learner (i.e. a ma- chine learned system), a hard-coded bot such as one designed to interact with learners, or a human (e.g. a Turker).</p><p>• teacher -a type of agent that talks to the learner in order to teach it, e.g. implements one of the tasks in <ref type="figure" target="#fig_0">Fig. 1</ref>. After defining a world and the agents in it, a main loop can be run for training, testing or displaying, which calls the function world.parley() to run one time step of the world. Example code to display data is given in <ref type="figure" target="#fig_2">Fig. 3</ref>, and the output of running it is in <ref type="figure">Fig. 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Actions and Observations</head><p>All agents (including teachers) speak to each other in a single common format -the observation/action ob- ject (a python dict), see <ref type="figure" target="#fig_4">Fig. 5</ref>. It is used to pass text, labels and rewards between agents. The same object type is used for both talking (acting) and listening (ob- serving), but with different values in the fields. Hence, python examples/display_data.py -t babi [babi:Task1k:4]: The office is north of the kitchen. The bathroom is north of the office. What is north of the kitchen? <ref type="bibr">[cands: office|garden|hallway|bedroom|kitchen|bathroom]</ref> [RepeatLabelAgent]: office --------------------- ˜˜[ ˜˜[babi:Task1k:2]: Daniel went to the kitchen. Daniel grabbed the football there. Mary took the milk there. Mary journeyed to the office. Where is the milk? <ref type="bibr">[cands: office|garden|hallway|bedroom|kitchen|bathroom]</ref> [RepeatLabelAgent]: office <ref type="figure">Figure 4</ref>: Example output to display data of a given task (see <ref type="figure" target="#fig_2">Fig. 3</ref> for corresponding code).</p><p>the object is returned from agent.act() and passed in to agent.observe(), see <ref type="figure" target="#fig_2">Fig. 3</ref>. The fields of the message are as follows:</p><p>• text: a speech act.</p><p>• id: the speaker's identity.</p><p>• reward: a real-valued reward assigned to the re- ceiver of the message.</p><p>• episode done: indicating the end of a dialog. For supervised datasets, there are some additional fields that can be used:</p><p>• label: a set of answers the speaker is expecting to receive in reply, e.g. for QA datasets the right answers to a question.</p><p>• label candidates: a set of possible ways to re- spond supplied by a teacher, e.g. for multiple choice datasets or ranking tasks.</p><p>• text candidates: ranked candidate predictions from a learner. Used to evaluate ranking metrics, rather than just evaluate the single response in the text field.</p><p>• metrics: A teacher can communicate to a learning agent metrics on its performance. Finally other media can also be supported with addi- tional fields:</p><p>• image: an image, e.g. for Visual Question An- swering or Visual Dialog datasets. As the dict is extensible, we can add more fields over time, e.g. for audio and other sensory data, as well as actions other than speech acts.</p><p>Each of these fields are technically optional, depend- ing on the dataset, though the text field will most likely be used in nearly all exchanges. A typical exchange from a ParlAI training set is shown in <ref type="figure" target="#fig_6">Fig. 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Code Structure</head><p>The ParlAI codebase has five main directories:</p><p>• core: the primary code for the platform.</p><p>• agents: contains agents which can interact with the worlds/tasks (e.g. learning models).</p><p>• examples: contains examples of different mains (display data, training and evaluation).   • tasks: contains code for the different tasks avail- able from within ParlAI.</p><p>• mturk: contains code for setting up Mechanical Turk and sample MTurk tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Core</head><p>The core library contains the following files:</p><p>• agents.py: defines the Agent base class for all agents, which implements the observe() and act() methods, the Teacher class which also reports metrics, and MultiTaskTeacher for multitask train- ing.</p><p>• dialog teacher.py: the base teacher class for doing dialog with fixed chat logs.</p><p>• worlds.py: defines the base World class, Di- alogPartnerWorld for two speakers, MultiAgent- DialogWorld for more than two, and two contain- ers that can wrap a chosen environment: Batch- World for batch training, and HogwildWorld for training across multiple threads.   • remote agent: basic class for any agent connect- ing over ZeroMQ.</p><formula xml:id="formula_0">• dict</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Teacher: { 'text': 'Sam went to the kitchen.\n Pat gave Sam the milk.\nWhere is the milk?',\\ 'labels': ['kitchen'], 'label_candidates': ['hallway', 'kitchen', 'bathroom'], 'episode_done': False</head><p>• seq2seq: basic GRU sequence to sequence model (Sutskever et al., 2014) • ir baseline: information retrieval (IR) base- line that scores responses with TFIDF-weighted matching ( <ref type="bibr" target="#b12">Ritter et al., 2011</ref>).</p><p>• repeat label: basic class for merely repeating all data sent to it (e.g. for debugging).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Examples</head><p>This directory contains examples of different mains:.</p><p>• display data: display data from a particular task provided on the command-line.</p><p>• display model: show the predictions of a pro- vided model. • eval model: compute evaluation metrics for a given model on a given task.</p><p>• train model: execute a standard training proce- dure with a given task and model, including log- ging and possibly alternating between training and validation.</p><p>For example, one can display 10 random examples from the bAbI tasks (  python display data.py -t babi -n 10</p><p>Display multitasking bAbI and SQuAD <ref type="bibr" target="#b11">(Rajpurkar et al., 2016)</ref> at the same time:</p><p>python display data.py -t babi,squad</p><p>Evaluate an IR baseline model on the Movies Subred- dit:</p><p>python eval model.py -m ir baseline -t '#moviedd-reddit <ref type="bibr">' -dt valid</ref> Train an attentive LSTM model on the SQuAD dataset with a batch size of 32 examples: python train model.py -m drqa -t squad -b 32</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Tasks</head><p>Over 20 tasks are supported in the first release, includ- ing popular datasets such as SQuAD ( <ref type="bibr" target="#b11">Rajpurkar et al., 2016)</ref>, bAbI tasks ( , QACNN and QADailyMail ( <ref type="bibr" target="#b7">Hermann et al., 2015</ref>), CBT ( <ref type="bibr" target="#b8">Hill et al., 2015)</ref>, bAbI Dialog tasks <ref type="bibr" target="#b2">(Bordes and Weston, 2016)</ref>, <ref type="bibr">Ubuntu (Lowe et al., 2015</ref>) and VQA ( <ref type="bibr" target="#b0">Antol et al., 2015)</ref>. All the datasets in the first release are shown in <ref type="figure" target="#fig_0">Fig. 1 4</ref> .</p><p>The tasks are separated into five categories:</p><p>• Question answering (QA): one of the simplest forms of dialog, with only 1 turn per speaker. Any intelligent dialog agent should be capable of an- swering questions, and there are many kinds of questions (and hence datasets) that one can build, providing a set of very important tests. Question answering is particularly useful in that the evalu- ation is simpler than other forms of dialog if the dataset is labeled with QA pairs and the questions are mostly unambiguous.</p><p>• Sentence Completion (Cloze Tests): the agent has to fill in a missing word in the next utterance in a dialog. Again, this is specialized dialog task, but it has the advantage that the datasets are cheap to make and evaluation is simple, which is why the community has built several such datasets.</p><p>• Goal-Oriented Dialog: a more realistic class of tasks is where there is a goal to be achieved by the end of the dialog. For example, a customer and a travel agent discussing a flight, one speaker recommending another a movie to watch, and so on.</p><p>• Chit-Chat: dialog tasks where there may not be an explicit goal, but more of a discussion -for example two speakers discussing sports, movies or a mutual interest.</p><p>• Visual Dialog: dialog is often grounded in physi- cal objects in the world, so we also include dialog tasks with images as well as text. Choosing a task in ParlAI is as easy as specifying it on the command line, as shown in the dataset dis- play utility, <ref type="figure">Fig. 4</ref>. If the dataset has not been used before, ParlAI will automatically download it. As all datasets are treated in the same way in ParlAI (with a single dialog API, see Sec. 5), a dialog agent can switch training and testing between any of them. Im- portantly, one can specify many tasks at once (multi- tasking) by simply providing a comma-separated list, e.g. the command line arguments -t babi,squad, to use those two datasets, or even all the QA datasets at once (-t #qa) or indeed every task in ParlAI at once (-t #all). The aim is to make it easy to build and evaluate very rich dialog models.</p><p>Each task is contained in a folder with the following standardized files:</p><p>• build.py: file for setting up data for the task, including downloading the data the first time it is requested.</p><p>• agents.py: contains teacher class(es), agents that live in the world of the task.</p><p>• worlds.py: optionally added for tasks that need to define new/complex environments. To add a new task, one must implement build.py to download any required data, and agents.py for the teacher. If the data consist of fixed logs/dialog scripts such as in many supervised datasets (SQuAD, Ubuntu, etc.) there is very little code to write. For more com- plex setups where an environment with interaction has to be defined, new worlds and/or teachers can be im- plemented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Mechanical Turk</head><p>An important part of ParlAI is seamless integration with Mechanical Turk for data collection, training or evaluation. Human Turkers are also viewed as agents in ParlAI and hence human-human, human-bot, or mul- tiple humans and bots in group chat can all converse within the standard framework, switching out the roles as desired with no code changes to the agents. This is because Turkers also receive and send via the same in- terface: using the fields of the observation/action dict. We provide two examples in the first release:</p><p>(i) qa collector: an agent that talks to Turkers to col- lect question-answer pairs given a context para- graph to build a QA dataset, see <ref type="figure" target="#fig_1">Fig. 2</ref>. (ii) model evaluator: an agent which collects ratings from Turkers on the performance of a bot on a given task. Running a new MTurk task involves implementing and running a main file (like run.py) and defining sev- eral task specific parameters for the world and agent(s) you wish humans to talk to. For data collection tasks the agent should pose the problem and ask the Turker for e.g. the answers to questions, see <ref type="figure" target="#fig_1">Fig. 2</ref>. Other pa- rameters include the task description, the role of the Turker in the task, keywords to describe the task, the number of hits and the rewards for the Turkers. One can run in a sandbox mode before launching the real task where Turkers are paid.</p><p>For online training or evaluation, the Turker can talk to your machine learning agent, e.g. LSTM, memory network or other implemented technique. New tasks can be checked into the repository so researchers can share data collection and data evaluation procedures and reproduce experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Demonstrative Experiment</head><p>To demonstrate ParlAI in action, we give results in Ta- ble 1 of DrQA, an attentive LSTM architecture with single task and multitask training on the SQuAD and bAbI tasks, a combination not shown before with any method, to our knowledge. This experiment simultaneously shows the power of ParlAI -how easy it is to set up this experiment -and the limitations of current methods. Almost all methods working well on SQuAD have been designed to predict a phrase from the given context (they are given labeled start and end indices in training). Hence, those models cannot be applied to all dialog datasets, e.g. some of the bAbI tasks include yes/no questions, where yes and no do not appear in the context. This highlights that re- searchers should not focus models on a single dataset. ParlAI does not provide start and end label indices as its API is dialog only, see <ref type="figure" target="#fig_4">Fig. 5</ref>. This is a deliberate choice that discourages such dataset overfitting/ spe- cialization. However, this also results in a slight drop in performance because less information is given <ref type="bibr">5 (66.4 EM vs. 69.5 EM, see (Chen et al., 2017)</ref>, which is still in the range of many existing well-performing meth- ods, see https://stanford-qa.com).</p><p>Overall, while DrQA can solve some of the bAbI tasks and performs well on SQuAD, it does not match the best performing methods on bAbI ( <ref type="bibr" target="#b13">Seo et al., 2016;</ref><ref type="bibr" target="#b6">Henaff et al., 2016)</ref>, and multitasking does not help. Hence, ParlAI lays out the challenge to the commu- nity to find learning algorithms that are generally ap- plicable and that benefit from training over many dialog datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related Software</head><p>There are many existing independent dialog datasets, and training code for individual models that work on some of them. Many are framed in slightly different ways (different formats, with different types of super- vision), and ParlAI attempts to unify this fragmented landscape.</p><p>There are some existing software platforms that are related in their scope, but not in their specialization. OpenAI's Gym and Universe 6 are toolkits for devel- oping and comparing reinforcement learning (RL) al- gorithms. Gym is for games like Pong or Go, and Uni- verse is for online games and websites. Neither focuses on dialog or covers the case of supervised datasets as we do.</p><p>CommAI 7 is a framework that uses textual commu- nication for the goal of developing artificial general in- telligence through incremental tasks that test increas- ingly more complex skills, as described in . CommAI is in a RL setting, and con- tains only synthetic datasets, rather than real natural language datasets as we do here. In that regard it has a different focus to ParlAI, which emphasizes the more immediate task of real dialog, rather than directly on evaluation of machine intelligence. <ref type="table">Task   Single Multitask  bAbI 10k 1: Single Supporting Fact  100</ref>   <ref type="table">Table 1</ref>: Test Accuracy of DrQA on bAbI 10k and SQuAD (Exact Match metric) using ParlAI. The subset of bAbI tasks for which the answer is exactly contained in the text is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion and Outlook</head><p>ParlAI is a framework allowing the research commu- nity to share existing and new tasks for dialog as well as agents that learn on them, and to collect and evaluate conversations between agents and humans via Mechan- ical Turk. We hope this tool enables systematic devel- opment and evaluation of dialog agents, helps push the state of the art in dialog further, and benefits the field as a whole.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The tasks in the first release of ParlAI.</figDesc><graphic url="image-1.png" coords="1,306.71,234.30,213.33,132.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: MTurk Live Chat for collecting QA datasets in ParlAI.</figDesc><graphic url="image-2.png" coords="1,314.80,390.61,187.73,156.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: ParlAI main for displaying data (top) and the code for the world.parley call (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Observation</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The observation/action dict is the central message passing object in ParlAI: agents send this message to speak, and receive a message of this form to observe other speakers and the environment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: A typical exchange from a ParlAI training set involves messages passed using the observation/action dict (the test set would not include labels). Shown here is the bAbI dataset.</figDesc></figure>

			<note place="foot" n="4"> All dataset descriptions and references are at http:// parl.ai in the README.md and task list.py.</note>

			<note place="foot" n="5"> As we now do not know the location of the true answer, we randomly pick the start and end indices of any context phrase matching the given training set answer, in some cases this is unique. 6 https://gym.openai.com/ and https://universe.openai.com/ 7 https://github.com/facebookresearch/CommAI-env</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">VQA: Visual Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2425" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from questionanswer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Learning end-to-end goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07683</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00051</idno>
		<title level="m">Reading wikipedia to answer open-domain questions</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The Cambridge encyclopedia of the English language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crystal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Ernst Klett Sprachen</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning cooperative visual dialog agents with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satwik</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06585</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Tracking the world state with recurrent entity networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.03969</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>Antoine Bordes, and Yann LeCun</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1693" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The goldilocks principle: Reading children&apos;s books with explicit memory representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02301</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nissan</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.08909</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.08130</idno>
		<title level="m">A roadmap towards machine intelligence</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Datadriven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Query-reduction networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04582</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.05698</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
