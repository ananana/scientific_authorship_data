<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:10+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Consistency-Aware Search for Word Alignment</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Jiangsu Collaborative Innovation Center for Language Competence</orgName>
								<address>
									<settlement>Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Jiangsu Collaborative Innovation Center for Language Competence</orgName>
								<address>
									<settlement>Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems Tsinghua National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Consistency-Aware Search for Word Alignment</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>As conventional word alignment search algorithms usually ignore the consistency constraint in translation rule extraction, improving alignment accuracy does not necessarily increase translation quality. We propose to use coverage, which reflects how well extracted phrases can recover the training data, to enable word alignment to model consistency and correlate better with machine translation. This can be done by introducing an objective that maximizes both alignment model score and coverage. We introduce an efficient algorithm to calculate coverage on the fly during search. Experiments show that our consistency-aware search algorithm significantly outperforms both generative and discriminative alignment approaches across various languages and translation models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Word alignment, which aims to identify the correspondence between words in two languages, plays an important role in statistical machine translation <ref type="bibr" target="#b1">(Brown et al., 1993)</ref>. Word alignment and translation rule extraction often constitute two consecutive steps in the training pipeline. Word- aligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models ( <ref type="bibr" target="#b17">Koehn et al., 2003;</ref><ref type="bibr" target="#b26">Och and Ney, 2004</ref>), but also for syntax-based models <ref type="bibr" target="#b4">(Chiang, 2005;</ref><ref type="bibr" target="#b11">Galley et al., 2006</ref>). Dividing alignment and extraction into two separate steps significantly improves the efficiency and scala- bility of parameter estimation as compared with directly learning translation models from bilingual * Corresponding author: Yang Liu. corpora ( <ref type="bibr" target="#b24">Marcu and Wong, 2002;</ref><ref type="bibr" target="#b7">DeNero and Klein, 2008;</ref><ref type="bibr" target="#b6">Cohn and Blunsom, 2009)</ref>.</p><p>However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word align- ment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU <ref type="bibr" target="#b2">(Callison-Burch et al., 2004;</ref><ref type="bibr" target="#b13">Goutte et al., 2004;</ref><ref type="bibr" target="#b15">Ittycheriah and Roukos, 2005</ref>). <ref type="bibr" target="#b0">Ayan and Dorr (2006)</ref> find that precision-oriented alignments result in better translation performance than recall-oriented alignments. <ref type="bibr" target="#b10">Fraser and Marcu (2007)</ref> show that using AER and balanced F-measure can only partially explain the effect of alignment quality on BLEU for several language pairs.</p><p>We believe that the correlation problem arises from the discrepancy between word alignment and translation rule extraction. On one hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constraints. Consequently, sensible translation rules may not be extracted because they violate consistency constraints required by translation rule extraction ( <ref type="bibr" target="#b26">Och and Ney, 2004</ref>). <ref type="bibr" target="#b30">Wang et al. (2010)</ref> find that the standard alignment tools are not optimal for training syntax-based models. As a result, they have to resort to re- aligning. On the other hand, the consistency constraint used in most translation rule extraction algorithms tolerate wrong links within consistent phrase pairs. <ref type="bibr" target="#b5">Chiang (2007)</ref> uses the union of two unidirectional alignments, which usually has a low precision, for extracting hierarchical phrases. Therefore, it is important to include both alignment model score and the consistency constraint in the optimization objective of word alignment.</p><p>In this work, we propose to use coverage, which measures how well extracted phrases can <ref type="figure">Figure 1</ref>: (a) An alignment resulting in a set of bilingual phrases (highlighted by shading) that can recover the training example, and (b) an alignment resulting in a set of bilingual phrases that fails to fully recover the training example. We assume the maximum phrase length w = 3. Our approach aims to avoid adding links that both have low posterior probabilities and hurt the recovery (e.g., the link between "huiwu" and "hold").</p><p>recover the training data, to bridge word alignment and (hierarchical) phrase-based translation. We introduce a new alignment search algorithm with an objective that maximizes both alignment model score and coverage while keeping the training algorithm unchanged. The coverage of an align- ment is calculated on the fly during search using a local phrase extraction algorithm. Experiments show that our approach achieves significant im- provements over state-of-the-art baselines across various languages and translation models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>We begin by introducing the preliminaries of word alignment and phrase-based translation.</p><p>Definition 1 Given a source-language sentence f = f J 1 = f 1 . . . f J and a target-language sentence e = e I 1 = e 1 . . . e I , an alignment a is a subset of the Cartesian product of the word positions of two sentences: a ⊆ {(j, i) : j = 1, . . . , J; i = 1, . . . , I}.</p><p>Figure 1(a) shows an alignment for a Chinese sentence "oumeng he eluosi shounao huiwu zai mosike juxing" and an English sentence "EU and Russia hold summit in Moscow". We use black circles to denote links. The link <ref type="bibr">(1,</ref><ref type="bibr">1)</ref> indicates that the first Chinese word "oumeng" and the first English word "EU" are translations of each other.</p><p>Definition 2 Given a training example f , e, a, a bilingual phrase B is a pair of source and target phrases:</p><formula xml:id="formula_0">B = (f j 2 j 1 , e i 2 i 1 ) such that 1 ≤ j 1 ≤ j 2 ≤ J ∧ 1 ≤ i 1 ≤ i 2 ≤ I.</formula><p>For example, ("zai mosike", "in Moscow") in <ref type="figure">Figure 1</ref> can be denoted as a bilingual phrase B = (f 7 6 , e 7 6 ). For convenience, We use B.j 1 and B.j 2 to denote the beginning and ending positions of the source phrase in B, respectively. B.i 1 and B.i 2 are defined likewise for the target side.</p><formula xml:id="formula_1">Definition 3 A bilingual phrase B = (f j 2 j 1 , e i 2 i 1</formula><p>) is said to be tight if and only if all boundary words (i.e., f j 1 , f j 2 , e i 1 , and e i 2 ) are aligned. Otherwise, it is a loose bilingual phrase.</p><p>For example, in <ref type="figure">Figure 1</ref>, while (f 3 1 , e 3 1 ) is a tight bilingual phrase, (f 4 1 , e 4 1 ) is a loose bilingual phrase.</p><p>Definition 4 ( <ref type="bibr" target="#b26">Och and Ney, 2004</ref>) Given a train- ing example f , e, a, a bilingual phrase</p><formula xml:id="formula_2">B = (f j 2 j 1 , e i 2 i 1</formula><p>) is said to be consistent with the word alignment a if and only if:</p><p>1. No words in the source phrase are aligned with words outside the target phrase and vice versa:</p><formula xml:id="formula_3">∀(j, i) ∈ a : j 1 ≤ j ≤ j 2 ↔ i 1 ≤ i ≤ i 2 ,</formula><p>2. At least one word in the source phrase is aligned with at least one word in the target</p><formula xml:id="formula_4">phrase: ∃(j, i) ∈ a : j 1 ≤ j ≤ j 2 ∧ i 1 ≤ i ≤ i 2 .</formula><p>Alignment consistency forms the basis of trans- lation rule extraction in modern SMT systems <ref type="bibr" target="#b16">(Koehn and Hoang, 2007;</ref><ref type="bibr" target="#b5">Chiang, 2007;</ref><ref type="bibr" target="#b11">Galley et al., 2006</ref>; <ref type="bibr" target="#b21">Liu et al., 2006</ref>). In <ref type="figure">Figure 1</ref>, (f 3 1 , e 3 1 ) is consistent with the alignment because all words in "oumeng he eluosi" are aligned with all words in "EU and Russia". In contrast, in <ref type="figure">Figure 1</ref>(b), "huiwu shounao" and "hold summit" are not consistent with the alignment because "hold" is also aligned to a word "juxing" outside.</p><p>However, alignment consistency only defines a loose relationship between alignment and trans- lation. A phrase pair consistent with alignment tolerates wrong inside links. For example, even if "oumeng" is aligned with "Russia", (f 3 1 , e 3 1 ) is still consistent. This is one possible reason that maximizing alignment accuracy does not neces- sarily lead to improved translation performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Modeling Consistency in Word Alignment</head><p>Our intuition is that including the consistency constraint in word alignment can hopefully reduce the discrepancy between alignment and transla- tion. While this idea has been suggested by a number of authors (e.g., <ref type="bibr" target="#b9">(Deng and Zhou, 2009;</ref><ref type="bibr" target="#b8">DeNero and Klein, 2010)</ref>), our goal is to optimize arbitrary alignment models with respect to end-to- end translation in the search phase without labeled data (see Related Work for detailed comparison). A natural way is to include consistency in the optimization objective as a regularization term. However, as consistency is only defined at the phrase level (see Definition 4), we need a sentence-level measure to reflect how well an alignment conforms to the consistency constraint. A straightforward measure is the number of bilin- gual phrases consistent with the alignment (phrase count for short), which is easy and efficient to calculate during search <ref type="bibr" target="#b9">(Deng and Zhou, 2009)</ref>. Unfortunately, optimizing with respect to phrase count is prone to yield alignments with very few links in a biased way, which result in a large number of bilingual phrases extracted from a small fraction of the training data. Another alternative is reachability ( <ref type="bibr" target="#b18">Liang et al., 2006a;</ref><ref type="bibr" target="#b32">Yu et al., 2013</ref>) that indicates whether there exists a full derivation to recover the training data. However, calculating reachability faces a major problem: a large portion of training data cannot be fully recovered due to noisy alignments and the distortion limit ( <ref type="bibr" target="#b32">Yu et al., 2013)</ref>.</p><p>In this work, we propose coverage, which reflects how well extracted phrases can recover the training data, to measure the sentence-level consistency. In the following, we will introduce a number of definitions to facilitate the exposition.</p><p>Definition 5 A source word f j is said to be covered by a bilingual phrase B = (f j 2</p><formula xml:id="formula_5">j 1 , e i 2 i 1 ) if and only if j 1 ≤ j ≤ j 2 : cov(f j , B) = j 1 ≤ j ≤ j 2 . Similarly, a target word e i is covered by B if and only if i 1 ≤ i ≤ i 2 .</formula><p>The indicator function expr returns 1 if the boolean expression expr is true and returns 0 otherwise. For example, in <ref type="figure">Figure 1</ref>(a), "oumeng" and "EU" are covered by the bilingual phrase B = (f 3 1 , e 3 1 ). Definition 6 Given a set of bilingual phrases B = {B (k) } K k=1 , a source word f j is said to be covered by the bilingual phrase set B if and only if it is covered by at least one phrase in B :</p><formula xml:id="formula_6">cov(f j , B) = K k=1 cov(f j , B (k) ) &gt; 0. The definition for a target word is similar.</formula><p>For example, in <ref type="figure">Figure 1</ref>(a), all source and target words are covered by the bilingual phrase set. In <ref type="figure">Figure 1</ref>(b), the source words "shounao", "huiwu", "juxing" and the target words "hold" and "summit" are not covered.</p><p>Definition 7 Given a sentence pair f , e and a phrase length limit w 1 , the hard coverage of an alignment a is defined as a boolean value:</p><formula xml:id="formula_7">C h (f , e, a, w) = δ J j=1 cov(f j , B), J ∧ δ I i=1 cov(e i , B), I (1)</formula><p>where B = EXTRACT(f , e, a, 1, J, 1, I, w) is the set of consistent bilingual phrases extracted from the sentence pair using a standard phrase extraction algorithm ( <ref type="bibr" target="#b26">Och and Ney, 2004</ref>). The function δ returns true if the two parameters are same and returns false otherwise.</p><p>Algorithm 1 A consistency-aware search algorithm for word alignment.</p><formula xml:id="formula_8">1: procedure ALIGN(f , e, θ, w, β, b, n) 2: open ← ∅ 3: N ← ∅ 4: a, B ← ∅, ∅∅ 5: ADD(open, a, B, β, b) 6:</formula><p>while open = ∅ do 7:</p><p>closed ← ∅ 8:</p><p>for all a, B ∈ open do 9:</p><p>for all l ∈ J × I − a do 10:</p><p>a ← a ∪ {l} 11:</p><p>B ← UPDATE(f , e, a, l, B, w) 12:</p><p>if GAIN(f , e, a, a , w, θ) &gt; 0 then 13:</p><formula xml:id="formula_9">ADD(closed, a , B , β, b) 14: end if 15: ADD(N , a , B , β, n) 16:</formula><p>end for 17:</p><p>end for 18:</p><p>open ← closed 19:</p><p>end while 20:</p><p>return N 21: end procedure</p><p>Depending on the tightness of extracted phrases (see Definition 3), we further distinguish between C h+t (f , e, a, w) and C h+l (f , e, a, w), which denote hard coverage calculated with tight and loose phrases, respectively.</p><p>Hard coverage denotes whether extracted phrases can fully recover the training data. For example, the values of hard coverage for Figures 1(a) and 1(b) are 1 and 0, respectively. As most training examples can hardly be fully recovered, we introduce soft coverage to better account for partially recoverable training data.</p><p>Definition 8 Given a sentence pair f , e and a phrase length limit w, the soft coverage of an alignment a is defined as</p><formula xml:id="formula_10">C s (f , e, a, w) = J j=1 cov(f j , B) + I i=1 cov(e i , B) J + I<label>(2)</label></formula><p>Similarly, we also distinguish between C s+t and C s+l depending on the tightness of extracted phrases.</p><p>Definition 9 Given a word-aligned bilingual cor- pus D = {{f (s) , e (s) , a (s) } S s=1 and a phrase length limit w, the corpus-level soft coverage is defined as</p><formula xml:id="formula_11">C s (D, w) = |f (s) | j=1 cov(f (s) j , B (s) ) S s=1 |f (s) | + |e (s) | + |e (s) | i=1 cov(e (s) i , B (s) ) S s=1 |f (s) | + |e (s) | (3)</formula><p>Algorithm 2 Updating the set of extracted bilingual phrases after adding a link.</p><p>1: procedure UPDATE(f , e, a, l, B, w) 2:</p><formula xml:id="formula_12">B ← B 3: for all B ∈ B do 4: if B.j1 ≤ l.j ≤ B.j2 ∨ B.i1 ≤ l.i ≤ B.i2 then 5: B ← B − {B} 6: end if 7:</formula><p>end for 8:</p><formula xml:id="formula_13">j1 ← l.j − w + 1 9: j2 ← l.j + w − 1 10: i1 ← l.i − w + 1 11: i2 ← l.i + w − 1 12: a ← a ∪ {l} 13: B ← EXTRACT(f , e, a , j1, j2, i1, i2, w) 14: B ← B ∪ B 15:</formula><p>return B 16: end procedure</p><p>The corpus-level hard coverage is defined like- wise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Consistency-Aware Search</head><p>While Deng and Zhou (2009) focus on intro- ducing an effectiveness function such as phrase count into alignment symmetrization, we are inter- ested in guiding the search algorithms of arbitrary alignment models using coverage. Therefore, the objective of our search algorithm is defined as score(f , e, a, w, θ)</p><formula xml:id="formula_14">= M (f , e, a, θ) + λC(f , e, a, w)<label>(4)</label></formula><p>where M (f , e, a, θ) is alignment model score, θ is a set of model parameters, C(f , e, a, w) is coverage (either hard or soft), and λ is a hyper- parameter that controls the preference between alignment model score and coverage. 2 Therefore, the decision rule is given byâ</p><formula xml:id="formula_15">byˆbyâ = argmax a∈A(f ,e) score(f , e, a, w, θ)<label>(5)</label></formula><p>where A(f , e) is a set of all possible alignments for the sentence pair. Algorithm 1 shows the consistency-aware search algorithm for word alignment. The input of the algorithm includes a source sentence f , a target sentence e, a set of model parameters θ, phrase length limit w, pruning parameters β and b, and the number of most likely alignments to be retaind n (line 1). Inspired by <ref type="bibr" target="#b22">Liu et al. (2010)</ref>, the algorithm starts with an empty alignment a together with an empty phrase set B. We use open to store active alignments during search and N to store top-n alignments after search (lines 2-4). The procedure ADD(open, a, B, β, b) adds a, B to open and discards any alignment that has a score worse than β multiplied by the best score in the list or the score of the b-th best alignment (line 5). For each iteration (line 6), we use a list closed to store promising alignments that have higher scores than the current alignment (line 8). For every possible link l (line 9), the algorithm produces a new alignment a and updates the phrase set by calling a procedure UPDATE(f , e, a, l, B, w) (lines 10-11). Then, the algorithm calls a <ref type="figure">procedure GAIN(f , e, a, a , w, θ)</ref> to calculate the difference of model score after adding the link l:</p><formula xml:id="formula_16">score(f , e, a , w, θ) − score(f , e, a, w, θ)</formula><p>If a has a higher score, it is added to closed (line 13). We also update N to retain the top n alignment explored during the search (line 15). This process iterates until the model score does not increase.</p><p>Algorithm 2 describes how to update the set of extracted bilingual phrases after adding a link. Our idea is to only update the phrases near the added link l and keep other phrases unchanged. This strategy improves the efficiency by avoiding extracting phrases from the entire sentence pair. The algorithm first removes bilingual phrases that are either in the same row or in the same column with l (lines 2-7). For example, in <ref type="figure">Figure 1</ref>, the following bilingual phrases are removed after adding the link between "huiwu" and "hold" because the link breaks the consistency:</p><p>("shounao huiwu", "summit") ("juxing", "hold")</p><p>Other phrases out of the reach of the added link remain unchanged.</p><p>Then, the algorithm extracts bilingual phrases near l by calling the procedure EXTRACT. Note that the phrase extraction is restricted to a local region (j 1 , j 2 , i 1 , i 2 ) by the phrase length limit w. We use l.i and l.j to denote the source and target positions of the link, respectively.  <ref type="table">Table 1</ref>: Comparison of different settings of coverage on the Chinese-English dataset using Moses. "h" denotes "hard", "s" denotes "soft", "l" denotes "loose", and "t" denotes "tight". The BLEU scores were calculated on the development set. For quick validation, we used a small fraction of the training data to train the phrase-based model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Languages and Datasets</head><p>We evaluated our approach in terms of alignment and translation quality on five language pairs: Chinese-English (ZH-EN), Czech-English (CS- EN), German-English (DE-EN), Spanish-English (ES-EN), and French-English (FR-EN). The eval- uation metrics for alignment and translation are alignment error rate (AER) <ref type="bibr" target="#b25">(Och and Ney, 2003)</ref> and case-insensitive BLEU ( <ref type="bibr" target="#b27">Papineni et al., 2002</ref>), respectively. For Chinese-English, the training data consists of 1.2M pairs of sentences with 30.9M Chinese words and 35.5M English words. We used the SRILM toolkit <ref type="bibr" target="#b29">(Stolcke, 2002</ref>) to train a 4- gram language model on the Xinhua portion of the English GIGAWORD corpus, which contains 398.6M words. For alignment evaluation, we used the Tsinghua Chinese-English word alignment evaluation data set ( <ref type="bibr" target="#b20">Liu and Sun, 2015)</ref>. <ref type="bibr">3</ref> For translation evaluation, we used the NIST 2006 dataset as the development set and the <ref type="bibr">NIST 2002</ref><ref type="bibr">NIST , 2003</ref><ref type="bibr">NIST , 2004</ref><ref type="bibr">NIST , 2005</ref> and 2008 datasets as the test sets.</p><p>For other languages, the training data is Euro- parl v7. The English language model trained on the Xinhua portion of the English GIGA- WORD corpus was also used for translation from European languages to English. For translation evaluation, we used the "news-test2012" dataset that contains 3,003 sentences as the development set and the "news-test2013" dataset that contains 3,000 sentences as the test set.   <ref type="table">Table 2</ref>: Comparison of different alignment methods on the Chinese-English dataset. "GDF" denotes the grow-diag-final heuristic. "phrase count" denotes optimizing with respect to maximizing the number of extracted tight phrases. We used Moses to extract loose phrases from word-aligned training data for all methods. "# bp" denotes the number of extracted bilingual phrases, "# sp" denotes the number of source phrases, "# tp" denotes the number of target phrases, "# sw" denotes the source vocabulary size, "# tw" denotes the target vocabulary size.  <ref type="table">Table 3</ref>: Translation evaluation on different alignment models. We apply our approach to both generative and discriminative alignment models. "generative" denotes applying the grow-diag-final heuristic to the alignments produced by IBM Model 4 in two directions. "discriminative" denotes the log-linear alignment model ( <ref type="bibr" target="#b22">Liu et al., 2010)</ref>. Adding coverage leads to significant improvements. We use "**" to denote that the difference is statistically significant at p &lt; 0.01 level.</p><note type="other"># bp # sp # tp # sw # tw C s+t C s+l AER BLEU C → E</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Alignment Models</head><p>We apply our approach to both generative and discriminative alignment models. For generative models, we used GIZA++ ( <ref type="bibr" target="#b25">Och and Ney, 2003</ref>) to train IBM Model 4 in two directions. To calculate a model score for symmetrized alignments, we fol- low <ref type="bibr" target="#b19">Liang et al. (2006b)</ref> to leverage link posterior marginal probabilities. For discriminative models, we used the open-source toolkit TsinghuaAligner ( <ref type="bibr" target="#b20">Liu and Sun, 2015</ref>) that implements the log-linear alignment model as described in ( <ref type="bibr" target="#b22">Liu et al., 2010</ref>). The model score for the log-linear model is also defined using link posteriors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Translation Models</head><p>Two kinds of translation models, phrase-based ( <ref type="bibr" target="#b17">Koehn et al., 2003</ref>) and hierarchical phrase-based <ref type="bibr" target="#b5">(Chiang, 2007)</ref>, are used to evaluate whether our approach improves the correlation between alignment and translation. For the phrase-based model, we used the open-source toolkit Moses ( <ref type="bibr" target="#b16">Koehn and Hoang, 2007)</ref>. For the hierarchical phrase-based model, we used an in-house re- implementation on par with state-of-the-art open- source decoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Comparison of Different Settings</head><p>We first investigate the optimal setting for coverage (hard vs. soft, tight vs. loose) on the Chinese-English dataset. For quick validation, we used a subset of the training data to train the phrase-based model using Moses. We used the development set to optimize the scaling factor λ (see Eq. <ref type="formula" target="#formula_14">(4)</ref>) and set it to 0.3 in our experiments. <ref type="table">Table 1</ref> compares C h+l , C h+t , C s+l , and C s+t . We find that the "soft + tight" combination (i.e., C s+t ) yields the highest BLEU score on the development set. One possible reason is that tight phrases are usually of high quality and soft coverage allows for taking full advantage of the training data. On the contrary, C h+t yields the lowest BLEU score because hard coverage fails to distinguish between partially recoverable training examples as it assigns zero to all partially recoverable data.</p><p>Then, we investigate the effect of the phrase length limit w in Algorithm 1 on translation quality. We find w = 7 achieves the best result, which is consistent with the default setting in Moses. As a result, we used C s+t and set w = 7 in the following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparison of Different Alignment Methods</head><p>We compare our approach with a number of alignment methods in terms of AER and BLEU, including IBM Model 4 in two directions (C → E and E → C), symmetrization heuristics (Inter- section, Union, grow-diag-final), and consistency- aware models (tight phrase count and coverage).</p><p>We used Moses to extract loose bilingual phrases from word-aligned bilingual corpora from all methods. Note that our approach uses C s+t for finding alignments, from which Moses extracts loose phrases. <ref type="table">Table 2</ref> lists the numbers of extracted bilingual phrases ("# bp"), source phrases ("# sp"), target phrases ("# tp"), source vocabulary size ("# sw"), and target vocabulary size ("# tw"). We find that a very large number of loose phrases can be extracted from the Intersection alignments, which also have the highest vocabulary sizes. However, a large portion of words in these phrases are actually unaligned, resulting in low translation quality.</p><p>We observe that adding consistency, either in terms of phrase count or coverage, significantly improves alignment accuracy by a large margin, suggesting that imposing structural constraint helps to reduce alignment errors. Our approach outperforms all methods in terms of BLEU significantly. Note that the coverage itself does not correlate well with BLEU. It is important to achieve a balance between model score and coverage. As mentioned in Section 5.2, we set λ = 0.3 in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Translation Evaluation on Different Alignment Models</head><p>We apply our approach to both generative ( <ref type="bibr" target="#b1">Brown et al., 1993</ref>) and discriminative ( <ref type="bibr" target="#b22">Liu et al., 2010)</ref> alignment models. As shown in <ref type="table">Table 3</ref>, we find that adding coverage to the optimization objective significantly improves the BLEU scores. All differences are statistically significant at p &lt; 0.01 level. This finding suggests that our approach generalizes well to various alignment models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Translation Evaluation on Different Translation Models</head><p>We also evaluated our approach on both phrase- based and hierarchical phrase-based models. As shown in <ref type="table">Table 4</ref>, adding coverage to generative models leads to significant improvements for both models. All the differences are statistically significant at p &lt; 0.01 level. Although coverage is designed for extracting phrases, using coverage is still beneficial to hier- archical phrase-based models because hierarchical phrases are derived from phrases consistent with word alignment. 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Translation Evaluation on Different Language Pairs</head><p>Finally, we report BLEU scores across five language pairs in <ref type="table">Table 5</ref>: Chinese-English (ZH- EN), Czech-English (CS-EN), German-English (DE-EN), Spanish-English (ES-EN), and French- English (FR-EN). ZH-EN uses four references and other language pairs only use single references. We find that our approach outperforms the baseline statistically significantly at p &lt; 0.01 for four language pairs and p &lt; 0.05 for one language pair. Therefore, using coverage to bridge word alignment and machine translation can hopefully benefit more languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Our work is inspired by three lines of research: (1) reachability in discriminative training of translation models, (2) structural constraints for alignment, and (3) learning with constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Reachability in Discriminative Training of Translation Models</head><p>Discriminative training algorithms for statistical machine translation often need reachable training examples to find full derivations for updating model parameters ( <ref type="bibr" target="#b18">Liang et al., 2006a;</ref><ref type="bibr" target="#b32">Yu et al., 2013</ref>  <ref type="table">Table 4</ref>: Translation evaluation on different translation models. For translation, We used both phrase- based and hierarchical phrase-based models. For alignment, we used the generative model. "generative" denotes applying the grow-diag-final heuristic to the alignments produced by IBM Model 4 in two directions. Adding coverage leads to significant improvements. We use "**" to denote that the difference is statistically significant at p &lt; 0.01 level.  <ref type="table">Table 5</ref>: Translation evaluation on five language pairs. "generative" denotes applying the grow-diag-final heuristic to the alignments produced by IBM Model 4 in two directions. We use "*" and"**" to denote that the difference is statistically significant at p &lt; 0.05 and p &lt; 0.01, respectively. Note that ZH-EN uses four references and other language pairs only use single references. due to noisy alignments and distortion limit. They find that most reachable sentences are short and generally literal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>alignment ZH-EN CS-EN DE-EN ES-EN</head><p>We borrow the idea of measuring the degree of recovering training data from reachability but ignore the dependency between bilingual phrases for efficiency. To calculate reachability, one needs to figure out a full derivation, in which the bilingual phrases cover the training data and do not intersect with each other. <ref type="bibr" target="#b32">Yu et al. (2013)</ref> indicate that using forced decoding to select reachable sentences with an unlimited distortion limit runs in O(2 n n 3 ) time. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Structural Constraints for Alignment</head><p>Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase align- ment ( <ref type="bibr" target="#b24">Marcu and Wong, 2002;</ref><ref type="bibr" target="#b7">DeNero and Klein, 2008;</ref><ref type="bibr" target="#b6">Cohn and Blunsom, 2009)</ref> or inter- secting synchronous grammars with alignment <ref type="bibr" target="#b31">(Wu, 1997;</ref><ref type="bibr" target="#b33">Zhang and Gildea, 2005;</ref><ref type="bibr" target="#b14">Haghighi et al., 2009)</ref>.</p><p>Our work is in spirit most close to <ref type="bibr" target="#b9">(Deng and Zhou, 2009)</ref> and <ref type="bibr" target="#b8">(DeNero and Klein, 2010)</ref>. <ref type="bibr" target="#b9">Deng and Bowen (2009)</ref> cast combining IBM Model 4 alignments in two directions as an optimization problem driven by an effectiveness function. They evaluate the impact of adding or removing a link with respect to phrase extraction using the effectiveness function of phrase count. The major difference is that we generalize their idea to arbitrary alignment models in the search phase rather than bidirectional alignment combination in the post-processing phase. In addition, we find that using coverage instead of phrase count results in better translation performance (see <ref type="table">Table 2</ref>).</p><p>DeNero and Klein (2010) develop a discrimi- native model of extraction sets and optimize an extraction-based loss function with respect to translation. Their model is capable of predicting the extracted phrase set. While their approach relies on annotated data for training the discrimi- native model, our method only needs to tune the scaling factor λ on the development set. In addition, our approach is very general and can easily apply to arbitrary alignment models by appending a term to the optimization objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Learning with Constraints</head><p>Our work is also related to learning with con- straints such as constraint-driven learning <ref type="bibr" target="#b3">(Chang et al., 2007</ref>) and posterior regularization ( <ref type="bibr" target="#b12">Ganchev et al., 2010)</ref>.</p><p>The basic idea is to inject prior knowledge to the model as a regularization term. The major difference is that our coverage regularizer is independent of model parameters. As a result, alignment models can still be trained independently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we have presented a general frame- work for optimizing word alignment with respect to machine translation. We introduce coverage to measure how well extracted bilingual phrases can recover the training data. We develop a consistency-aware search algorithm that calculates coverage on the fly during search efficiently. Experiments show the our approach is effective in both alignment and translation tasks across various alignment models, translation models, and language pairs.</p><p>In the future, we plan to apply our approach to syntax-based models ( <ref type="bibr" target="#b11">Galley et al., 2006</ref>; <ref type="bibr" target="#b21">Liu et al., 2006;</ref><ref type="bibr" target="#b28">Shen et al., 2008)</ref> and include the con- stituency constraint in the optimization objective. It is also interesting to develop consistency-aware training algorithms for word alignment.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>method</head><label></label><figDesc></figDesc></figure>

			<note place="foot" n="1"> The phrase length limit w is essential in defining coverage, restricting that the sentence pair must be covered by bilingual phrases no longer than w words. Otherwise, a very long bilingual phrase (e.g., the entire sentence pair) can achieve full coverage in a biased way.</note>

			<note place="foot" n="2"> Note that training algorithms are unchanged. We only introduce a new search algorithm that takes coverage into consideration. We leave consistency-aware training algorithms for arbitrary alignment models for future work.</note>

			<note place="foot" n="3"> http://nlp.csai.tsinghua.edu.cn/˜ly/systems/TsinghuaAlig ner/TsinghuaAligner.html</note>

			<note place="foot" n="4"> We also tested our approach on syntax-based models (Galley et al., 2006; Liu et al., 2006) but failed to achieve significant improvements. The reason is that extracting syntactic translation rules often imposes an additional constraint: a phrase must be a constituent that is subsumed by a subtree. We believe that appending such constraint to the optimization objective will hopefully benefit syntax-based translation models. We leave this for future work.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Yang Liu and Maosong Sun are supported by the 863 Program (2015AA011808) and the Na-tional Natural Science Foundation of China <ref type="bibr">(No. 61331013 and No. 61432013)</ref>. Huanbo Luan is supported by the National Natural Science Foundation of China (No. 61303075). This research is also supported by the Singapore Na-tional Research Foundation under its International Research Centre@Singapore Funding Initiative and administered by the IDM Programme. Many thanks go to Chunyang Liu and Meng Zhang for their discussions. We also thank the anonymous reviewers for their valuable feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Going beyond aer: An extensive analysis of word alignments and their impact on mt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Necip Fazil Ayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLINGACL 2006</title>
		<meeting>COLINGACL 2006<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">A Della</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Statistical machine translation with word-and sentence aligned parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Talbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>and Miles Osborne</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Guiding semi-supervision with constraint-driven learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A hierarchical phrasebased model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2005</title>
		<meeting>ACL 2005<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="228" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A bayesian model of syntax-directed tree to string grammar induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The complexity of phrase alignment problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discriminative modeling of extraction sets for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klein</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2010</title>
		<meeting>ACL 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Optimizing word alignment combination for phrase table training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonggang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measuring word alignment quality for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics, Squibs and Discussions</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="293" to="303" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Scalable inference and training of context-rich syntactic translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Graehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Deneefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Thayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-ACL 2006</title>
		<meeting>COLING-ACL 2006<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07" />
			<biblScope unit="page" from="961" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Posterior regularization for structured latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzmann</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Graça</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Gillenwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Aligning words using matrix factorisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Better word alignments with supervised itg models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A maximum entropy word aligner for arabic-english machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2005</title>
		<meeting>EMNLP 2005</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Factored translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLPCoNLL</title>
		<meeting>EMNLPCoNLL<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="868" to="876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL 2003</title>
		<meeting>HLT-NAACL 2003<address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-05" />
			<biblScope unit="page" from="127" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An end-to-end discriminative approach to machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Bouchard-Cote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Alignment by agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLTNAACL 2006</title>
		<meeting>HLTNAACL 2006<address><addrLine>New York City, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06" />
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Contrastive unsupervised word alignment with non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI 2015</title>
		<meeting>AAAI 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Treeto-string alignment template for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING/ACL</title>
		<meeting>COLING/ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Discriminaitve word alignment by linear modeling</title>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="303" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A phrasebased, joint probability model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The alignment template approach to statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="417" to="449" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bleu: a methof for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A new string-to-dependency machine translation algorithm with a target dependency language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Srilm-an extensible language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICSLP</title>
		<meeting>ICSLP</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Re-structuring, re-labeling, and re-aligning for syntax-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Stochastic inversion transaction grammars and bilingual parsing of parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="377" to="404" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Max-violation perceptron and forced decoding for scalable mt training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2013</title>
		<meeting>EMNLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stochastic lexicalized inversion transduction grammars for alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danieal</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2005</title>
		<meeting>ACL 2005</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
