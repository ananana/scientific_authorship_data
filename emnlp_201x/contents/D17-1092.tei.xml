<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Temporal Information Extraction for Question Answering Using Syntactic Dependencies in an LSTM-based Architecture</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanliang</forename><surname>Meng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Lowell Lowell</orgName>
								<address>
									<postCode>01854</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Lowell Lowell</orgName>
								<address>
									<postCode>01854</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Romanov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Lowell Lowell</orgName>
								<address>
									<postCode>01854</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Temporal Information Extraction for Question Answering Using Syntactic Dependencies in an LSTM-based Architecture</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="887" to="896"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we propose to use a set of simple, uniform in architecture LSTM-based models to recover different kinds of temporal relations from text. Using the shortest dependency path between entities as input, the same architecture is implemented to extract intra-sentence, cross-sentence, and document creation time relations. A &quot;double-checking&quot; technique reverses entity pairs in classification, boosting the recall of positive cases and reducing misclassifications between opposite classes. An efficient pruning algorithm resolves conflicts globally. Evaluated on QA-TempEval (SemEval2015 Task 5), our proposed technique outperforms state-of-the-art methods by a large margin. We also conduct intrinsic evaluation and post state-of-the-art results on Timebank-Dense.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recovering temporal information from text is es- sential to many text processing tasks that require deep language understanding, such as answering questions about the timeline of events or auto- matically producing text summaries. This work presents intermediate results of an effort to build a temporal reasoning framework with contemporary deep learning techniques.</p><p>Until recently, there has been remarkably few attempts to evaluate temporal information extrac- tion (TemporalIE) methods in context of down- stream applications that require reasoning over the temporal representation. One recent effort to conduct such evaluation was SemEval2015 Task 5, a.k.a. QA-TempEval ( <ref type="bibr" target="#b5">Llorens et al., 2015a)</ref>, which used question answering (QA) as the tar- get application. QA-TempEval evaluated systems producing TimeML ( <ref type="bibr" target="#b12">Pustejovsky et al., 2003</ref>) an- notation based on how well their output could be used in QA. We believe that application-based evaluation of TemporalIE should eventually com- pletely replace the intrinsic evaluation if we are to make progress, and therefore we evaluated our techniques mainly using QA-TempEval setup.</p><p>Despite the recent advances produced by multi- layer neural network architectures in a variety of areas, the research community is still struggling to make neural architectures work for linguistic tasks that require long-distance dependencies (such as discourse parsing or coreference resolution). Our goal was to see if a relatively simple architecture with minimal capacity for retaining information was able to incorporate the information required to identify temporal relations in text.</p><p>Specifically, we use several simple LSTM- based components to recover ordering relations between temporally relevant entities (events and temporal expressions). These components are fairly uniform in their architecture, relying on de- pendency relations recovered with a very small number of mature, widely available processing tools, and require minimal engineering otherwise. To our knowledge, this is the first attempt to apply such simplified techniques to the TemporalIE task, and we demonstrate this streamlined architecture is able to outperform state-of-the-art results on a temporal QA task with a large margin.</p><p>In order to demonstrate generalizability of our proposed architecture, we also evaluate it intrin- sically using TimeBank-Dense 1 ( <ref type="bibr" target="#b2">Chambers et al., 2014</ref>). TimeBank-Dense annotation aims to ap- proximate a complete temporal relation graph by including all intra-sentential relations, all relations between adjacent sentences, and all relations with document creation time. Although our system was not optimized for such a paradigm, and this data is quite different in terms of both the annota- tion scheme and the evaluation method, we obtain state-of-the-art results on this corpus as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A multitude of TemporalIE systems have been de- veloped over the past decade both in response to the series of shared tasks organized by the com- munity ( <ref type="bibr" target="#b18">Verhagen et al., , 2010</ref><ref type="bibr" target="#b16">UzZaman et al., 2012;</ref><ref type="bibr" target="#b15">Sun et al., 2013;</ref><ref type="bibr" target="#b1">Bethard et al., 2015;</ref><ref type="bibr" target="#b6">Llorens et al., 2015b;</ref> and in standalone efforts ( <ref type="bibr" target="#b2">Chambers et al., 2014;</ref><ref type="bibr" target="#b10">Mirza, 2016)</ref>.</p><p>The best methods used by TemporalIE systems to date tend to rely on highly engineered task- specific models using traditional statistical learn- ing, typically used in succession ( <ref type="bibr" target="#b15">Sun et al., 2013;</ref><ref type="bibr" target="#b2">Chambers et al., 2014</ref>). For example, in a recent QA-TempEval shared task, the participants rou- tinely used a series of classifiers (such as support vector machine (SVM) or hidden Markov chain SVM) or hybrid methods combining hand crafted rules and SVM, as was used by the top system in that challenge ( <ref type="bibr" target="#b11">Mirza and Minard, 2015)</ref>. While our method also relies on decomposing the tem- poral relation extraction task into subtasks, we use essentially the same simple LSTM-based archi- tecture for different components, that consume a highly simplified representation of the input.</p><p>Although there has not been much work ap- plying deep learning techniques to TemporalIE, some relevant work has been done on a similar (but typically more local) task of relation extrac- tion. Convolutional neural networks ( <ref type="bibr" target="#b21">Zeng et al., 2014</ref>) and recurrent neural networks both have been used for argument relation classification and similar tasks ( <ref type="bibr" target="#b22">Zhang and Wang, 2015;</ref><ref type="bibr" target="#b20">Xu et al., 2015;</ref><ref type="bibr" target="#b19">Vu et al., 2016)</ref>. We take inspiration from some of this work, including specifically the ap- proach proposed by <ref type="bibr" target="#b20">Xu et al. (2015)</ref> which uses syntactic dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset</head><p>We used QA-TempEval (SemEval 2015 Task 5) 2 data and evaluation methods in our experiments. The training set contains 276 annotated TimeML files, mostly news articles from major agencies or Wikinews from late 1990s to early 2000s. This data contains annotations for events, temporal ex- pressions (referred to as TIMEXes), and temporal relations (referred to as TLINKs). The test set con- tains unannotated files in three genres: 10 news articles composed in 2014, 10 Wikipedia articles about world history, and 8 blogs entries from early 2000s.</p><p>In QA-TempEval, evaluation is done via a QA toolkit which contains yes/no questions about tem- poral relations between two events or an event and a temporal expression. QA evaluation is not avail- able for most of the training data except for 25 files, for which 79 questions are available. We used used this subset of the training data for vali- dation. The test set contains unannotated files, so QA is the only way to measure the performance. The total of 294 questions is available for the test data, see <ref type="table" target="#tab_8">Table 6</ref>.</p><p>We also use TimeBank-Dense dataset, which contains a subset of the documents in QA- TempEval. In TimeBank-Dense, all entity pairs in the same sentence or in consecutive sentences are labeled. If there is no information about the rela- tion between two entities, it is labeled as "vague". We follow the experimental setup in <ref type="bibr" target="#b2">(Chambers et al., 2014)</ref>, which splits the corpus into train- ing/validation/test sets of 22, 5, and 9 documents, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">TIMEX and Event Extraction</head><p>The first task in our TemporalIE pipeline (TEA) is to identify time expressions (TIMEXes) and events in text. We utilized the HeidelTime package <ref type="bibr" target="#b13">(Strötgen and Gertz, 2013</ref>) to identify TIMEXes. We trained a neural network model to identify event mentions. Contrary to common practice in TemporalIE, our models do not rely on event at- tributes, and thus we did not attempt to identify them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature</head><p>Explanation is main verb whether the token is the main verb of a sentence is predicate whether the token is the predicate of a phrase is verb whether the token is a verb is noun whether the token is a noun We perform tokenization, part-of-speech tag- ging, and dependency parsing using NewsReader ( <ref type="bibr" target="#b0">Agerri et al., 2014</ref>). Every token is represented with a set of features derived from preprocess- ing. Syntactic dependencies are not used for event extraction, but are used later in the pipeline for   <ref type="figure">Figure 1</ref>: System overview for our temporal extraction annotator (TEA) system TLINK classification. The features used to identify events are listed in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>The event extraction model uses long short-term memory (LSTM) <ref type="bibr" target="#b3">(Hochreiter and Schmidhuber, 1997)</ref>, an RNN architecture well-suited for se- quential data. The extraction model has two com- ponents, as shown on the right of <ref type="figure" target="#fig_1">Figure 2</ref>. One component is an LSTM layer which takes word embeddings as input. The other component takes 4 token-level features as input. These components produce hidden representations which are concate- nated, and fed into an output layer which performs binary classification. For each token, we use four tokens on each side to represent the surrounding context. The resulting sequence of nine word em- beddings is then used as input to an LSTM layer. If a word is near the edge of a sentence, zero padding is applied. We only use the token-level features of the target token, and ignore those from the context words. The 4 features are all binary, as shown in <ref type="table" target="#tab_0">Table 1</ref>. Since the vast majority of event mentions in the training data are single words, we only mark single words as event mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">TLINK Classification</head><p>Our temporal relation (TLINK) classifier con- sists of four components: an LSTM-based model for intra-sentence entity relations, an LSTM- based model for cross-sentence relations, another LSTM-based model for relations with document creation time, and a rule-based component for TIMEX pairs. The four models perform TLINK classifications independently, and the combined results are fed into a pruning module to remove the conflicting TLINKs. The three LSTM-based components use the same streamlined architecture over token sequences recovered from shortest de- pendency paths between entity pairs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Intra-Sentence Model</head><p>A TLINK extraction model should be able to learn the patterns that correspond to specific temporal relations, such as specific temporal prepositional phrases and clauses with temporal conjunctions. This suggests such models may benefit from en- coding syntactic relations, rather than linear se- quences of lexical items.</p><p>We use the shortest path between entities in a dependency tree to capture the essential context. Using the NewsReader pipeline, we identify the shortest path, and use the word embeddings for all tokens in the path as input to a neural net- work. Similar to previous work in relation extrac- tion ( <ref type="bibr" target="#b20">Xu et al., 2015)</ref>, we use two branches, where the left branch processes the path from the source entity to the least common ancestor (LCA), and the right branch processes the path from the target entity to the LCA. However, our TLINK extrac- tion model uses only word embeddings as input, not POS tags, grammatical relations themselves, or WordNet hypernyms.</p><p>For example, for the sentence "Their marriage ended before the war", given an event pair (mar- riage, war), the left branch of the model will re- ceive the sequence (marriage, ended), while the right branch will receive (war, before, ended). The LSTM layer processes the appropriate sequence of word embeddings in each branch. This is followed by a separate max pooling layer for each branch, so for each LSTM unit, the maximum value over the time steps is used, not the final step value. During the early stages of model design, we ob- served that this max pooling approach (also used in <ref type="bibr" target="#b20">Xu et al. (2015)</ref>) resulted in a slight improve- ment in performance. Finally, the results from the max pooling layers of both branches are con- catenated and fed to a hidden layer, followed by a softmax to yield a probability distribution over the classes. The model architecture is shown in <ref type="figure" target="#fig_1">Figure 2</ref> (left). We also augment the training data by flipping every pair, i.e. if (e 1 , e 2 ) → BEFORE, (e 2 , e 1 ) → AFTER is also included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Cross-Sentence Model</head><p>TLINKs between the entities in consecutive sen- tences can often be identified without any external context or prior knowledge. For example, the or- der of events may be indicated by discourse con- nectives, or the events may follow natural order, potentially encoded in their word embeddings.</p><p>To recover such relations, we use a model sim- ilar to the one used for intra-sentence relations, as described in Section5.1. Since there is no common root between entities in different sentences, we use the path between an entity and the sentence root to construct input data. A sentence root is often the main verb, or a conjunction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Relations to DCT</head><p>The document creation time (DCT) naturally serves as the "current time". In this section, we discuss how to identify temporal relations between an event and DCT. The assumption here is that an event mention and its local context can often suf- fice for DCT TLINKs. For example, English has inflected verbs for tense in finite clauses, and uses auxiliaries to express aspects.</p><p>The model we use is again similar to the one in Section5.2. Although one branch would suffice in this case, we use two branches in our implementa- tion. One branch processes the path from a given entity to the sentence root, and the other branch processes the same path in reverse, from the root to the entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Relations between TIMEXes</head><p>Time expressions explicitly signify a time point or an interval of time. Without the TIMEX entities serving as "hubs", many events would be isolated from each other. We use rule-based techniques to identify temporal relations between TIMEX pairs that have been identified and normalized by Hei- delTime. The relation between the DCT and other time expressions is just a special case of TIMEX- to-TIMEX TLINK and is handled with rules as well.  In the present implementation, we focus on the DATE class of TIMEX tags, which is prevalent in the newswire text. The TIME class tags which con- tain more information are converted to DATE. Ev- ery DATE value is mapped to a tuple of real val- ues (start, end). The "value" attribute of TIMEX tags follows the ISO-8601 standard, so the map- ping is straightforward. <ref type="table" target="#tab_2">Table 2</ref> provides some examples. We set the minimum time interval to be a day. Practically, such a treatment suffices for our data. After mapping DATE values to tu- ples of real numbers, we can define 5 relations between TIMEX entities T 1 = (start 1 , end 1 ) and T 2 = (start 2 , end 2 ) as follows:</p><formula xml:id="formula_0">T 1 × T 2 →                                BEFORE if end 1 &lt; start 2 AFTER if start 1 &gt; end 2 INCLUDES if start 1 &lt; start 2 and end 1 &gt; end 2 IS INCLUDED if start 1 &gt; start 2 and end 1 &lt; end 2 SIMULTANEOUS if start 1 = start 2 and end 1 = end 2 (1)</formula><p>The TLINKs from training data contain more types of relations than the five described in Equa- tion 1. However relations such as IBEFORE ("im- mediately before"), IAFTER("immediately after") and IDENTITY are only used on event pairs, not TIMEX pairs. The QA system also does not tar- get questions on TIMEX pairs. The purpose here is to use the TIMEX relations to link the otherwise isolated events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>890</head><p>6 Double-checking A major difficulty we have is that the TLINKs for intra-sentence, cross-sentence, and DCT relations in the training data are not comprehensive. Of- ten, the temporal relation between two entities is clear, but the training data provides no TLINK an- notation. We downsampled the NO-LINK class in training in order to address both the class imbal- ance and the fact that TimeML-style annotation is de-facto sparse, with only a fraction of positive in- stances annotated.</p><p>In addition to that, we introduce a technique to boost the recall of positive classes (not <ref type="bibr">NO-LINK)</ref> and to reduce the misclassification between the op- posite classes. Since entity pairs are always classi- fied in both orders, if both orders produce a TLINK relation, rather than NO-LINK, we adopt the label with a higher probability score, as assigned by the softmax classifier. We call this technique "double- checking". It serves to reduce the errors that are fundamentally harmful (e.g. BEFORE misclassi- fied as AFTER, and vice versa). We also allow a positive class to have the "veto power" against NO-LINK class. For instance, if our model pre- dicts (e 1 , e 2 ) → AFTER but NO-LINK reversely, we adopt the former.   <ref type="table" target="#tab_4">Table 3</ref> shows the effects of double-checking and downsampling the NO-LINK cases on the intra-sentence model. Double-checking technique not only further boosts recall, but also reduces the misclassification between the opposite classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Pruning TLINKs</head><p>The four TLINK classification models in Section 5 deal with different kinds of TLINKs, so their output does not overlap. Nevertheless temporal relations are transitive in nature, so the deduced relations from given TLINKs can be in conflict.</p><p>Most conflicts arise from two types of relations, namely BEFORE/AFTER and IN- CLUDES/IS INCLUDED.</p><p>Naturally, we can convert TLINKs of opposite relations and put them all together. If we use a directed graph to repre- sent the BEFORE relations between all entities, it should be acyclic. <ref type="bibr" target="#b14">Sun (2014)</ref> proposed a strategy that "prefers the edges that can be inferred by other edges in the graph and remove the ones that are least so". Another strategy is to use the results from separate classifiers or "sieves" to rank TLINKs according to their confidence ( <ref type="bibr" target="#b7">Mani et al., 2007;</ref><ref type="bibr" target="#b2">Chambers et al., 2014</ref>). High-ranking results overwrite low-ranking ones.</p><p>We follow the same idea of purging the weak TLINKs. Given a directed graph, our approach is to remove the edges to break cycles, so that the sum of weights from the removed edges is minimal. This problem is actually an extension of the minimum feedback arc set problem and is NP-hard <ref type="bibr" target="#b4">(Karp, 1972)</ref>. We therefore adopt a heuristic-based approach, applied separately to the graphs induced by BEFORE/AFTER and IN- CLUDES/IS INCLUDED relations. <ref type="bibr">3</ref> The softmax layer provides a probability score for each re- lation class, which represents the strength of a link. TLINKs between TIMEX pairs are gener- ated by rules, so we assume them to be reli- able and assign them a score of 1. Although IN- CLUDES/IS INCLUDED edges can generate con- flicts in a BEFORE/AFTER graph as well, we cur- rently do not resolve such conflicts because they are relatively rare. We also do not use SIMULTA- NEOUS/IDENTITY relations to merge nodes, be- cause we found that it leads to very unstable re- sults.</p><p>For a given relation (e.g., BEFORE), we incre- mentally build a directed graph with all edges rep- resenting that relation. We first initialize the graph with TIMEX-to-TIMEX relations. Event vertices are then added to this graph in a random order. For each event, we add all edges associated with it. If this creates a cycle, the edges are removed one by one until there is no cycle, keeping track of the sum of the scores associated with removed edges. We choose the order in which the edges are removed to minimize that value. <ref type="bibr">4</ref> The algorithm is shown above.</p><p>In practice, the vertices do not have a high de- gree for a given relation, so permuting the candi- dates N × (N − 1) times (i.e., not fully), where N is the number of candidates, produces only a negligible slowdown. We also make sure to try the greedy approach, dropping the edges with the smallest weights first.</p><formula xml:id="formula_1">X ← EVENTS; V ← TIMEXes; E ← TIMEX pairs; Initialize G ←&lt; V, E &gt;; for x∈ X do V ← V + {x}; C ← {(x, v) ∪ (v, x)|v ∈ V } ; E ← E ∪ C ; G ←&lt; V , E &gt; ; if cycle exists(G') then for Ci ∈ π(C) do scorei = 0; while Ci = φ &amp; cycle exists(G ∪ Ci) do c ← Ci.pop(); scorei+ = weight(c); end end end G ← G ∪ Ci s.t. i = argmin(</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Model Settings</head><p>In this section, we describe the model settings used in our experiments. All models requiring word embeddings use 300-dimensional word2vec vec- tors trained on Google News corpus (3 billion run- ning words). <ref type="bibr">5</ref> Our models are written in Keras on top of Theano.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TIMEX and Event Annotation</head><p>The LSTM layer of the event extraction model contains 128 LSTM units. The hidden layer on top of that has 30 neurons. The input layer corresponding to the 4 token features is connected with a hidden layer with 3 neurons. The combined hidden layer is then connected with a single-neuron output layer. We set a dropout rate 0.5 on input layer, and another drop out rate 0.5 on the hidden layer before output.</p><p>As mentioned earlier, we do not attempt to tag event attributes. Since the vast majority of tokens are outside of event mention boundaries, we set higher weights for the positive class. In order to answer questions about temporal relations, it is not particularly harmful to introduce spurious events, but missing an event makes it impossible to an- swer any question related to it. Therefore we in- tentionally boost the recall while sacrificing preci- sion. <ref type="table" target="#tab_5">Table 4</ref> shows the performance of our event extraction, as well as the performance of Heidel- Time TIMEX tagging. For events, partial overlap of mention boundaries is considered an error.  We set a dropout rate 0.6 on input layer, and an- other drop out rate 0.5 on the hidden layer before output.</p><p>Cross-Sentence Model The training and evalu- ation procedures are very similar to what we did for intra-sentence models, and the hyperparame- ters for the neural networks are the same. Now the vast majority of entity pairs have no TLINKs ex- plicitly marked in training data. Unlike the intra- sentence scenario, however, a NO-LINK label is truly adequate in most cases. We found that down- sampling NO-LINK instances to match the number of all positive instances (ratio=1) yields desirable results. Since positive instances are very sparse in both the training and validation data, the ratio should not be too low, so as not to risk overfitting.</p><p>DCT Model We use the same hyperparameters for the DCT model as for the intra-sentence and cross-sentence models. Again, the training files do not sufficiently annotate TLINKs with DCT even if the relations are clear, so there are many false neg- atives. We downsample the NO-LINK instances so that they are 4 times the number of positive in- stances.</p><p>system coverage prec rec f1 human-fold1-original 0.43 0.91 0.38 0.54 human-fold1-timlinks 0.52 0.93 0.47 0.62 TIPSem-fold1-original 0.35 0.57 0.22 0.32 TIPSem-fold1-timex 0.53 0.69 0.38 0.50 orig. validation data 0.37 0.93 0.34 0.50 orig. tags TEA tlinks 0.81 0.58 0.47 0.52 TEA-initial 0.78 0.60 0.47 0.52 TEA-double-check 0.89 0.60 0.53 0.56 TEA-prune 0.82 0.58 0.48 0.53 TEA-flat 0.81 0.44 0.35 0.39 TEA-Dense 0.68 0.70 0.48 0.57 TEA-final 0.84 0.64 0.53 0.58 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Experiments</head><p>In this section, we first describe the model se- lection experiments on QA-TempEval validation data, selectively highlighting results of interest.</p><p>We then present the results obtained with the op- timized model on the QA-TempEval task and on TimeBank-Dense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Model Selection Experiments</head><p>As mentioned before, "gold" TLINKs are sparse, so we cannot merely rely on the F1 scores on val- idation data to do model selection. Instead, we used the QA toolkit. The toolkit contains 79 yes- no questions about temporal relations between en- tities in the validation data. Originally, only 6 questions have "no" as the correct answer, and 1 question is listed as "unknown". After investigat- ing the questions and answers, however, we found some errors and typos 6 . After fixing the errors, there are 7 no-questions and 72 yes-questions in total. All evaluations are performed on the fixed data.</p><p>The evaluation tool draws answers from the an- notations only. If an entity (event or TIMEX) in- volved in a question is not annotated, or the TLINK cannot be found, the question will then be counted as not answered. There is no way for partici- pants to give an answer directly, other than de- 6 Question 24 from XIE19980821.0077.tml should be answered with "yes", but the answer key contains a typo "is". Question 34 from APW19980219.0476.tml has BE- FORE that should be replaced with AFTER. Question 29 from XIE19980821.0077.tml has "unknown" in the answer key, but after reading the article, we believe the correct answer is "no". livering the annotations. The program generates Timegraphs to infer relations from the annotated TLINKs. As a result, relations without explicit TLINK labels can still be used if they can be in- ferred from the annotations. The QA toolkit uses the following evaluation measures:  <ref type="table" target="#tab_6">Table 5</ref> shows the results produced by different models on the validation data. The results of the four systems above the first horizontal line are pro- vided by the task organizer. Among them, the top two use annotations provided by human experts. As we can see, the precision is very high, both above 0.90. Our models cannot reach that preci- sion. In spite of the lower precision, automated systems can have much higher coverages i.e. an- swer a lot more questions.</p><p>As a starting point, we evaluated the valida- tion files in their original form, and the results are shown as "orig. validation data" of <ref type="table" target="#tab_6">Table 5</ref>. The precision was good, but with very low coverage. This supports our claim that the TLINKs provided by the training/validation files are not complete. We also tried using the event and TIMEX tags from the validation data, but performing TLINK classifi- cation with our system. As shown with "orig. tags TEA tlinks" in the table, now the coverage rises to 64 (or 0.81), and the overall F1 score reaches 0.52. The TEA-initial system uses our own annotators. The performance is similar, with a slight improve- ment in precision. This result shows our event and TIMEX tags work well, and are not inferior to the ones provided by the training data.</p><p>The double-checking technique boosts the cov- erage a lot, probably because we allow positive results to veto NO-LINKs. Combining double- checking with the pruning technique yields the best results, with F1 score 0.58, answering 42 out of 79 questions correctly.</p><p>In order to validate the choice of the depen- dency path-based context, we also experimented with a conventional flat context window, using the same hyperparameters. Every entity is represented by a 11-word window, with the entity mention in the middle. If two entities are near each other, their windows are cut short before reaching the other entity. Using the flat context instead of depen- dency paths yields a much weaker performance. This confirms our hypothesis that syntactic depen- dencies represent temporal relations better than word windows. However, it should be noted that we did not separately optimize the models for the flat context setting. The large performance drop we saw from switching to flat context did not war- rant performing a separate parameter search.</p><p>We also wanted to check whether a comprehen- sive annotation of TLINKs in the training data can improve model performance on the QA task. We therefore trained our model on TimeBank-Dense data and evaluated it with QA (see the TEA-Dense line in <ref type="table" target="#tab_6">Table 5</ref>). Interestingly, the performance is nearly as good as our top model, although TimeBank-Dense only uses five major classes of relations. For one thing, it shows that our sys- tem may perform equally after being trained on sparsely labeled data and on densely labeled data, judged from the QA evaluation tool. If this is true, excessively annotated data may not be necessary in some tasks.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">QA-TempEval Experiments</head><p>We use the QA toolkit provided by the QA- TempEval organizers to evaluate our system on the test data. The documents in test data are not an- notated at all, so the event tags, TIMEX tags, and TLINKs are all created by our system. <ref type="table" target="#tab_8">Table 6</ref> shows the the statistics of test data. As we can see, the vast majority of the questions in the test set should be answered with yes. Gener- ally speaking, it is much more difficult to validate a specific relation (answer yes) than to reject it (answer no) when we have as many as 12 types of relations in addition to the vague NO-LINK class. dist-means questions involving entities that are in the same sentence or in consecutive sentences. dist+ means the entities are farther away.</p><p>The QA-TempEval task organizers used two evaluation methods. The first method is exactly the same as the one we used on validation data. The second method used a so-called Time Expres- sion Reasoner (TREFL) to add relations between TIMEXes, and evaluated the augmented results.</p><p>The goal of such an extra run is to "analyze how a general time expression reasoner could improve results". Our model already includes a component to handle TIMEX relations, so we will compare our results with other systems' in both methods.</p><p>News Genre (99 questions) system prec rec f1 % answd # correct hlt-fbk-ev1-trel1 0.59 0.17 0. <ref type="bibr">27</ref>   The results are shown in <ref type="table" target="#tab_10">Table 7</ref>. We give the results for the hlt-fbk systems that were submitted by the top team. Among them, hlt-fbk-ev2-trel2 was the overall winner of TempEval task in 2015. ClearTK, CAEVO, TIPSEMB and TIPSem were some off-the-shelf systems provided by the task organizers for reference. These systems were not optimized for the task ( <ref type="bibr" target="#b5">Llorens et al., 2015a</ref>).</p><p>For news and Wikipedia genres, our system out- performs all other systems by a large margin. For blogs genre, however, the advantage of our sys- tem is unclear. Recall that our training set con- tains news articles only. While the trained model works well on Wikipedia dataset too, blog dataset is fundamentally different in the following ways: (1) each blog article is very short, (2) the style of writing in blogs is much more informal, with non- standard spelling and punctuation, and (3) blogs All Genres (294 questions) system prec rec f1 % awd # corr hlt-fbk-ev2-trel2 0.49 0.30 0.37 62 89 hlt-fbk-ev2-trel2-TREFL 0.51 0. <ref type="bibr">34</ref>   are written in first person, and the content is usu- ally personal stories and feelings. Interestingly, the comparison between differ- ent hlt-fbk submissions suggests that resolving event coreference (implemented by hlt-fbk-ev2- trel2) substantially improves system performance for the news and Wikipedia genres. However, although our system does not attempt to handle event coreference explicitly, it easily outperforms the hlt-fbk-ev2-trel2 system in the genres where coreference seems to matter the most.</p><p>Evaluation with TREFL The extra evaluation with TREFL has a post-processing step that adds TLINKs between TIMEX entities. Our model already employs such a strategy, so this post- processing does not help. In fact, it drags down the scores a little. <ref type="table" target="#tab_12">Table 8</ref> summarizes the results over all genres before and after applying TREFL. For comparison, we include the top 2015 system, hlt-fbk-ev2-trel2. As we can see, TEA generally shows substantially higher scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">TimeBank-Dense Experiments</head><p>We trained and evaluated the same system on TimeBank-Dense to see how it performs on a sim- ilar task with a different set of labels and another method of evaluation. In this experiment, we used the event and TIMEX tags from test data, as <ref type="bibr" target="#b9">Mirza and Tonelli (2016)</ref>.</p><p>Since all the NO-LINK (vague) relations are la- beled, downsampling was not necessary. We did use double-checking in the final conflict resolu- tion, but without giving positive cases the veto power over NO-LINK. Because NO-LINK relations dominate, especially for cross-sentence pairs, we set class weights to be inversely proportional to the class frequencies during training. We also reduced input batch size to counteract class imbalance.</p><p>We ran two sets of experiments. One used the uniform configurations for all the neural net- work models, similar to our experiments with QA- TempEval. The other tuned the hyperparameters for each component model (number of neurons, dropout rates, and early stop) separately. system ClearTK NavyT CAEVO CATENA TEA-Dense uniform tuned F1 0.447 0.453 0.507 0.511 0.505 0.519 <ref type="table">Table 9</ref>: TEA results on TimeBank-Dense. ClearTK, NavyT, and CAEVO are systems from <ref type="bibr" target="#b2">Chambers et al. (2014)</ref>. CATENA is from <ref type="bibr" target="#b9">Mirza and Tonelli (2016)</ref> The results from TimeBank-Dense are shown in Talble 9. Even though TimeBank-Dense has a very different methodology for both annotation and evaluation, our "out-of-the-box" model which uses uniform configurations across different com- ponents obtains F1 0.505, compared to the best F1 of 0.511 in previous work. Our best result of 0.519 is obtained by tuning hyperparameters on intra- sentence, cross-sentence, and DCT models inde- pendently.</p><p>For the QA-TempEval task, we intentionally tagged a lot of events, and let the pruning algo- rithm resolve potential conflicts. In the TimeBank- Dense experiment, however, we only used the pro- vided event tags, which are sparser than what we have in QA-TempEval. The system may have lost some leverage that way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>We have proposed a new method for extraction of temporal relations which takes a relatively sim- ple LSTM-based architecture, using shortest de- pendency paths as input, and re-deploys it in a set of subtasks needed for extraction of temporal relations from text. We also introduce two tech- niques that leverage confidence scores produced by different system components to substantially improve the results of TLINK classification: (1) a "double-checking" technique which reverses pairs in classification, thus boosting the recall of posi- tives and reducing misclassifications among oppo- site classes and (2) an efficient pruning algorithm to resolve TLINK conflicts. In a QA-based evalu- ation, our proposed method outperforms state-of- the-art methods by a large margin. We also obtain state-of-the art results in an intrinsic evaluation on a very different TimeBank-Dense dataset, proving generalizability of the proposed model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Plain</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model architecture. Left: intra-sentence and crosssentence model. Right: Event extraction model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>scorei); end Algorithm 1: Algorithm to prune edges. π(C) denotes some permutations of C, where C is a list of weighted edges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>coverage = #answered #questions , precision = #correct #answered recall = #correct #questions , f1 = 2×precision×recall precision+recall</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Token features for event extraction</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Examples of DATE values and their tuple represen- tations</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Effects of downsampling and double-checking on 
intra-sentence results. 0.5 NO-LINK ratio means that NO-
LINKs are downsampled to a half of the number of all positive 
instances combined. BEFORE as AFTER shows the fraction of 
BEFORE misclassified as AFTER, and vice versa. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 4 : TIMEX and event evaluation on validation set.</head><label>4</label><figDesc></figDesc><table>Intra-Sentence Model We identify 12 classes 
of temporal relations, plus a NO-LINK class. For 
training, we downsampled NO-LINK class to 10% 
of the number of positive instances. Our system 
does not attempt to resolve coreference. For the 
purpose of identifying temporal relations, SIMUL-
TANEOUS and IDENTITY links capture the same 
relation of simultaneity, which allowed us to com-
bine them. The LSTM layer of the intra-sentence 
model contains 256 LSTM units on each branch. 
The hidden layer on top of that has 100 neurons. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>QA results on validation data. There are 79 ques-
tions in total. The 4 systems on the top of the table are pro-
vided with the toolkit. The systems starting with "human-
" are annotated by human experts. TEA-final utilizes both 
double-check and pruning. TEA-flat uses the flat context. 
TEA-Dense is trained on TimeBank-Dense. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Test data statistics. Adapted from Table 1 in Llorens 
et al. (2015a). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 7 : QA evaluation on test data without TREFL</head><label>7</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 8 : Test results over all genres.</head><label>8</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> https://www.usna.edu/Users/cs/ nchamber/caevo/#corpus</note>

			<note place="foot" n="2"> http://alt.qcri.org/semeval2015/ task5/</note>

			<note place="foot" n="3"> We found that ENDS and BEGINS TLINKs are too infrequent to warrant a separate treatment. 4 By removing an edge, we mean resetting the relation to NO-LINK. Another possibility may be to set the relation associated with the edge to the one with the second highest probability score, however this may create additional cycles.</note>

			<note place="foot" n="5"> https://github.com/mmihaltz/ word2vec-GoogleNews-vectors</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This project is funded in part by an NSF CAREER Award to A. Rumshisky (IIS-1652742). We would like to thank Connor Cooper and Kevin Wacome for their contributions to the early stages of this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ixa pipeline: Efficient and ready to use multilingual nlp tools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Agerri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josu</forename><surname>Bermudez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Rigau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 9th Language Resources and Evaluation Conference (LREC2014)</title>
		<meeting>of the 9th Language Resources and Evaluation Conference (LREC2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="26" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 6: Clinical tempeval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>of the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dense event ordering with a multi-pass architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Mcdowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="273" to="284" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reducibility among combinatorial problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Karp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Complexity of Computer Computations, Proc. Sympos</title>
		<imprint>
			<date type="published" when="1972" />
			<biblScope unit="page" from="85" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 5: Qa tempeval-evaluating temporal information understanding with question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Llorens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>of the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 5: Qa tempeval-evaluating temporal information understanding with question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Llorens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Workshop on Semantic Evaluation</title>
		<meeting>of the International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>SemEval-2015</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Three approaches to learning tlinks in timeml</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inderjeet</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Wellner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<idno>CS-07- 268</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>Computer Science Department</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Timeline: Cross-document event ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne-Lyse</forename><surname>Minard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuela</forename><surname>Speranza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itziar</forename><surname>Aldabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marieke</forename><surname>Van Erp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rubén</forename><surname>Urizar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fondazione Bruno</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Workshop on Semantic Evaluation</title>
		<meeting>of the International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
	<note>Semeval-2015 task. SemEval-2015</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Catena: Causal and temporal relation extraction from natural language texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tonelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 26th International Conference on Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="64" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Extracting temporal and causal relations between events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paramita</forename><surname>Mirza</surname></persName>
		</author>
		<idno>abs/1604.08120</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hlt-fbk: a complete temporal processing system for qa tempeval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paramita</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne-Lyse</forename><surname>Minard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>of the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="801" to="805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">TimeML: Robust specification of event and temporal expressions in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Castaño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ingria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Saur`saur`ı</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Setzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Workshop on Computational Semantics</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>IWCS-5</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Multilingual and cross-domain temporal tagging. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jannik</forename><surname>Strötgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gertz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="269" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Time Well Tell: Temporal Reasoning in Clinical Narratives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyi</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>University at Albany, SUNY</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD dissertation. Department of Informatics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evaluating temporal relations in clinical text: 2012 i2b2 challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozlem</forename><surname>Uzuner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="806" to="813" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Llorens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.5333</idno>
		<title level="m">Tempeval-3: Evaluating events, time expressions, and temporal relations</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semeval-2007 task 15: Tempeval temporal relation identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Schilder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hepple</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 4th International Workshop on Semantic Evaluations</title>
		<meeting>of the 4th International Workshop on Semantic Evaluations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semeval-2010 task 13: Tempeval-2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Sauri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 5th international workshop on semantic evaluation</title>
		<meeting>of the 5th international workshop on semantic evaluation</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="57" to="62" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Combining recurrent and convolutional neural networks for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno>abs/1605.07333</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Classifying relations via long short term memory networks along shortest dependency paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP 2015</title>
		<meeting>of EMNLP 2015</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1785" to="1794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING 2014</title>
		<meeting>of COLING 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Relation classification via recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1508.01006</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
