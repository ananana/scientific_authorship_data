<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:34+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BrainBench: A Brain-Image Test Suite for Distributional Semantic Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyan</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Murphy</surname></persName>
							<email>brian.murphy@qub.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alona</forename><surname>Fyshe</surname></persName>
							<email>afyshe@uvic.ca *</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Queen&apos;s University Belfast Belfast</orgName>
								<orgName type="institution">University of Victoria Victoria</orgName>
								<address>
									<region>BC, Northern Ireland</region>
									<country>Canada, UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Victoria Victoria</orgName>
								<address>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BrainBench: A Brain-Image Test Suite for Distributional Semantic Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2017" to="2021"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The brain is the locus of our language ability , and so brain images can be used to ground linguistic theories. Here we introduce Brain-Bench, a lightweight system for testing dis-tributional models of word semantics. We compare the performance of several models, and show that the performance on brain-image tasks differs from the performance on behav-ioral tasks. We release our benchmark test as part of a web service.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There is active debate over how we should test se- mantic models. In fact, in 2016 there was an en- tire workshop dedicated to the testing of semantic representations <ref type="bibr" target="#b8">(RepEval, 2016)</ref>. Several before us have argued for the usage of brain data to test se- mantic models <ref type="bibr" target="#b1">(Anderson et al., 2013;</ref><ref type="bibr">Murphy et al., 2012;</ref><ref type="bibr" target="#b1">Anderson et al., 2015)</ref>, as a brain image repre- sents a snapshot of one person's own semantic rep- resentation. Still, testing semantic models against brain imaging data is rarely done by those not in- timately involved in psycholinguistics or neurolin- guistics. This may be due to a lack of familiarity with neuroimaging methods and publicly available datasets.</p><p>We present the first iteration of BrainBench, a new system that makes it easy to test seman- tic models using brain imaging data (Available at http://www.langlearnlab.cs.uvic. ca/brainbench/). Our system has methodology that is similar to popular tests based on behavioral * Corresponding Author data (see Section 2.2), and has the additional benefit of being fast enough to offer as a web service.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Tasks</head><p>Here we outline the set of tasks we used to evaluate several popular Distributional Semantic (DS) mod- els.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Brain Image Data</head><p>For BrainBench we use two brain image datasets collected while participants viewed 60 concrete nouns with line drawings ( <ref type="bibr" target="#b7">Mitchell et al., 2008;</ref><ref type="bibr" target="#b9">Sudre et al., 2012)</ref>. One dataset was collected us- ing fMRI (Functional Magnetic Resonance Imag- ing) and one with MEG (Magnetoencephalography). Each dataset has 9 participants, but the participants sets are disjoint, thus there are 18 unique partici- pants in all. Though the stimuli is shared across the two experiments, as we will see, MEG and fMRI are very different recording modalities and thus the data are not redundant.</p><p>fMRI measures the change in blood oxygen levels in the brain, which varies according to the amount of work being done by a particular brain area. An fMRI image is a 3D volume of the brain where each point in the volume (called a voxel) represents brain activity at a particular place in the brain. In the fMRI dataset used here, each voxel represents a 3mm x 3mm x 5mm area of the brain. Each of the 60 words was presented 6 times in random order, for a total of 360 brain images. The number of voxels depends on the size and shape of a person's brain, but there are around 20,000 voxels per participant in this dataset.</p><p>MEG measures the magnetic field caused by many neurons firing in the same direction at the same time. This signal is very weak, and so must be measured in a magnetically shielded room. The MEG machine is essentially a large helmet with 306 sensors that measure aspects of the magnetic fields at different locations in the brain. A MEG brain im- age is the time signals recorded from each of these sensors. Here, the sampling rate is 200 Hz. For each word, the MEG recording is 800ms long resulting in 306 Ã— 160 data points. Each of the words was pre- sented 20 times (in random order) for a total of 1200 brain images. For simplicity we will use the term "brain image feature" to refer to both fMRI voxels and MEG sensor/time points. A non-trivial portion of our participants' brain ac- tivity may be driven by the low-level visual proper- ties of the word/line-drawing stimulus, rather than by semantics. As there is a possibility of confound- ing visual properties with semantic properties, we have attempted to remove the activity attributable to visual properties from the brain images. In total we have 11 visual features which include things like the length of the word, the number of white pixels, and features of the line drawing ( <ref type="bibr" target="#b9">Sudre et al., 2012</ref>). To remove the visual stimulus' contribution to the sig- nal, we train a regression model that predicts the sig- nal in each brain image feature as a function of the 11 visual features. We then subtract the predicted value from the observed value of the brain image feature. This process is known as "partialling out" an effect. Thus, the signal that remains in the brain image will not be correlated with the visual stimuli, and should only be related to the semantics of the word itself (or noise).</p><p>Brain images are quite noisy, so we used the methodology from <ref type="bibr" target="#b7">Mitchell et al. (2008)</ref> to select the most stable brain image features for each of the 18 participants. The stability metric assigns a high score to features that show strong self-correlation over presentations of the same word. We noticed that tuning the number of features to keep made lit- tle or no difference in the absolute ordering of the different DS models. Thus, we use the optimal num- ber of features averaged over all 6 DS models de- scribed in Section 3: the top 13% of MEG sen- sor/time points, and 3% of fMRI voxels. Finally, we average all brain images corresponding to repe- titions of the same word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Behavioral Tasks</head><p>We include, for comparison, four popular word vec- tor evaluation benchmarks.</p><p>MEN This dataset contains 3,000 word pairs, such that each word appears frequently in two separate corpora. Human participants were presented with two word pairs and asked to choose the word pair that was more related, resulting in a ranking of re- latedness amongst word pairs <ref type="bibr" target="#b1">(Bruni and Baroni, 2013)</ref>.</p><p>SimLex-999 A word pairing task meant to specifi- cally target similarity rather than the more broad "re- latedness" ( <ref type="bibr">Hill et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WS-353-[SIM|REL]</head><p>A set of 353 word pairs with relatedness ratings ( <ref type="bibr" target="#b3">Finkelstein et al., 2002</ref>). This dataset was subsequently split into sets where the pairs denote similarity and relatedness, named WS- 353-SIM and WS-353-REL, respectively (Agirre et al., 2009).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Distributional Models</head><p>We test six semantic models against both the fMRI and behavioral datasets. The six models are:</p><p>Skip-gram: A neural network trained to predict the words before and after the current word, given the current word. We selected a model with 300 dimensions trained on the Google news corpus ( <ref type="bibr" target="#b6">Mikolov et al., 2013)</ref>.</p><p>Glove: A regression-based model that combines global context information (term-document cooc- currence) with local information (small windows of word-word cooccurrence) ( <ref type="bibr" target="#b7">Pennington et al., 2014</ref>). This 300-dimensional model was trained on the Wikipedia and Gigaword 5 corpora combined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RNN:</head><p>A recurrent neural network with 640- dimensional hidden vectors. These models are trained to predict the next word in a sequence and have the ability to encode (theoretically) in- finitely distant contextual information <ref type="bibr">(Mikolov et al., 2011</ref>). The model was trained on broadcast news transcriptions.</p><p>Global: A neural network model that incorporates global and local information, like that of the Glove model ( <ref type="bibr" target="#b4">Huang et al., 2012)</ref>. This model is our smallest, with dimension 50, and was trained on Wikipedia.</p><p>Cross-lingual: A tool that projects distributional representations from multiple language into a shared representational space <ref type="bibr">(Faruqui and Dyer, 2014</ref>). Here we use the German-English model (512 dimen- sions), trained on the WMT-2011 corpus.</p><p>Non-distributional: This model is based solely on hand-crafted linguistic resources <ref type="bibr" target="#b2">(Faruqui and Dyer, 2015)</ref>. Several resources like WordNet <ref type="bibr" target="#b3">(Fellbaum, 1998</ref>) and FrameNet ( <ref type="bibr" target="#b1">Baker et al., 1998</ref>) are combined to make very sparse word vector repre- sentations. Due to their sparsity, these vectors are of very high dimension <ref type="bibr">(171,</ref><ref type="bibr">839)</ref>. This is a particu- larly interesting model because it is not built from a corpus (unlike every other model in this list).</p><p>Note that we are not aiming to compare the good- ness of any of these distributional models, as they are trained on different corpora with different algo- rithms. Instead, we wish to compare the patterns of performance on behavioral benchmarks to that of a brain-image based task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>Each of the behavioral tasks included here assigns a similarity score to word pairs. For each DS model we calculate the correlation between the vectors for every pair of words in the behavioral datasets. We then calculate the correlation between the DS vector correlations and the behavioral scores.</p><p>We follow a very similar methodology for the brain image datasets. Let us represent each DS model with a matrix X âˆˆ R wÃ—p where w is the num- ber of words for which we have brain images (here w = 60), and p is the number of dimensions in a particular DS model. From X we calculate the cor- relation between each pair of word vectors, resulting in a matrix C DS âˆˆ R wÃ—w .</p><p>Let us represent each participant's brain images with a matrix Y âˆˆ R wÃ—v where v is the number of selected brain image features. From this matrix we calculate the correlation between each pair of brain images, resulting in a matrix C BI âˆˆ R wÃ—w (BI for brain image). This final representation is similar to the behavioral tasks above, but now we have a simi- larity measure for every pair of words in our dataset.</p><p>Here is where the evaluation for brain imaging tasks differs from the behavioral tasks. Instead of measuring the correlation between C BI and C DS , as is done in Representational Similarity Analysis (RSA) ( <ref type="bibr">Kriegeskorte et al., 2008)</ref>, we use the test- ing methodology from <ref type="bibr" target="#b7">Mitchell et al. (2008)</ref>, which we will refer to as the 2 vs. 2 test. The 2 vs. 2 test was developed to help detect statistically significant predictions on brain imaging data, and, compared to RSA, can better differentiate the performance of a model from chance. We perform a 2 vs. 2 test for all pairs of C DS and C BI (that is, for every pair of DS model and fMRI/MEG participant).</p><p>For each 2 vs. 2 test we select the same two words (rows) w 1 , w 2 from C DS and C BI . We omit the columns which correspond to the correlation to w 1 and w 2 , as they contain a perfect signal for the 2 vs. 2 test. We now have four vectors, C DS (w 1 ), C DS (w 2 ), C BI (w 1 ) and C BI (w 2 ), all of length w âˆ’ 2. We compute the correlation (corr) between vectors derived from C DS and C BI to see if:</p><formula xml:id="formula_0">corr(C DS (w 1 ), C BI (w 1 )) + corr(C DS (w 2 ), C BI (w 2 ))</formula><p>(the correlation of correctly matched rows: w 1 to w 1 and w 2 to w 2 ) is greater than:</p><formula xml:id="formula_1">corr(C DS (w 1 ), C BI (w 2 )) + corr(C DS (w 2 ), C BI (w 1 ))</formula><p>(the correlation of incorrectly matched rows). If the correctly matched rows are more similar than incor- rectly matched rows, then the 2 vs. 2 test is consid- ered correct. We perform the 2 vs. 2 test for all pos- sible pairs of words, for 1770 tests in total. The 2 vs. 2 accuracy is the percentage of 2 vs. 2 tests correct. Chance is 50%.</p><p>Our process of computing 2 vs. 2 accuracy over rows of a correlation matrix is different than the original methodology for these datasets <ref type="bibr" target="#b7">(Mitchell et al., 2008;</ref><ref type="bibr" target="#b9">Sudre et al., 2012</ref>). Previous work trained regression models that took brain images as input and predicted the dimensions of a DS model as out- put. Training these regression models for all 1770 pairs of words takes hours to complete, whereas the test we suggest here is much faster, and the correla- tion matrices C BI can be computed ahead of time. This makes the tests fast enough to offer as a web service. We hope our web offering will remove bar- riers to the wider adoption of brain-based tests from within the computational linguistics community.   <ref type="figure" target="#fig_0">Figure 1</ref> shows the results for each of the DS mod- els against the fMRI and MEG datasets. On aver- age, the Skip-gram, Glove and Cross-lingual mod- els perform quite well, whereas the multi-layer NNs (RNN, Global) perform less well. The one DS model to be built from hand-crafted resources (Non- distributional) performs poorly on both brain image tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>As previously mentioned, we are not claiming to show that any one of the DS models is better than any other. Indeed, that would be comparing apples to oranges, as each DS model is trained with a differ- ent algorithm on a different corpus. Instead, notice that the pattern of performance for the fMRI task is remarkably similar to the pattern on the MEN behav- ioral task. This is interesting given that our dataset contains only 60 words and the MEN dataset con- tains &gt; 700. On the MEG data, the Cross-lingual model performs best, and its performance pattern is unlike any of the behavioral tasks in <ref type="figure" target="#fig_1">Figure 2</ref>. The averaged BrainBench results are most similar to the results for WS-353-REL. However, averaging the re- sults together may be misleading, as the fMRI and MEG result patterns are different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>There are some caveats about the analyses herein. Firstly, the brain-based tests include only 60 con- crete nouns, so they will necessarily favor distri- butional models with good noun representations, regardless of the representations of other parts of speech. We are currently working with various re- search groups to expand the number of brain-image datasets included in this benchmark to have a more diverse test base. The behavioral benchmarks were not reduced to include only the 60 words for which we have brain data, because this would have ren- dered the benchmarks essentially useless, as very rarely are a pair of the 60 words from the brain im- age data scored as a pair in the behavioral bench- marks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have presented our new system, BrainBench, which is a fast and lightweight alternative to pre- vious methods for comparing DS models to brain images. Our proposed methodology is more similar to well-known behavioral tasks, as BrainBench also uses the similarity of words as a proxy for mean- ing. We hope that this contribution will bring brain imaging tests "to the masses" and encourage discus- sion around the testing of DS models against brain imaging data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Performance of Distributional Semantic models on the brain-image datasets.</figDesc><graphic url="image-1.png" coords="4,75.23,54.62,236.06,124.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Performance of Distributional Semantic models on several benchmark behavioral tasks.</figDesc><graphic url="image-2.png" coords="4,319.96,57.97,215.28,120.86" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Kravalova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
	<note>Marius Pas, and Aitor Soroa</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reading visually embodied meaning from the brain: Visually grounded computational models decode visual-object mental imagery induced by written text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anderson</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th annual meeting on Association for Computational Linguistics</title>
		<meeting>the 36th annual meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="462" to="471" />
		</imprint>
	</monogr>
	<note>NeuroImage. Faruqui and Dyer2014] Manaal Faruqui and Chris Dyer. 2014. Improving vector space word representations using multilingual correlation. Proceedings of the European Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dyer</surname></persName>
		</author>
		<title level="m">Non-distributional Word Vector Representations. Acl-2015</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="464" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Placing search in context: the concept revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">. ; Lev</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zach</forename><surname>Solan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gadi</forename><surname>Wolfman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SimLex-999: Evaluating Semantic Models with (Genuine) Similarity Estimation. Computational Linguistics</title>
		<editor>Hill et al.2015] Felix Hill, Roi Reichart, and Anna Korhonen</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="665" to="695" />
		</imprint>
	</monogr>
	<note>WordNet: An Electronic Lexical Database</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Representational similarity analysis-connecting the branches of systems neuroscience. Frontiers in systems neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<editor>Kriegeskorte et al.2008] Nikolaus Kriegeskorte, Marieke Mur, and Peter Bandettini</editor>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers<address><addrLine>Stefan Kombrink</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-11" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="873" to="882" />
		</imprint>
	</monogr>
	<note>Anoop Deoras, LukÃ¡Å¡ Burget, and JaÅˆ CernockÂ´yCernockÂ´y</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<title level="m">Proceedings of Automatic Speech Recognition and Understanding (ASRU)</title>
		<meeting>Automatic Speech Recognition and Understanding (ASRU)</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
	<note>RNNLM-Recurrent Neural Network Language Modeling Toolkit</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
	<note>ICLR 2013</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Predicting human brain activity associated with the meanings of nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Joint Conference on Lexical and Computational Semantics (*SEM)</title>
		<editor>Murphy et al.2012] Brian Murphy, Partha Talukdar, and Tom Mitchell</editor>
		<meeting><address><addrLine>New York, N.Y.; Montreal, Quebec, Canada; Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-05" />
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="page" from="114" to="123" />
		</imprint>
	</monogr>
	<note>Conference on Empirical Methods in Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">RepEval workshop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Repeval</surname></persName>
		</author>
		<ptr target="https://sites.google.com/site/repevalacl16/" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tracking Neural Coding of Perceptual and Semantic Features of Concrete Nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Sudre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leila</forename><surname>Wehbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alona</forename><surname>Fyshe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riitta</forename><surname>Salmelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="463" to="451" />
			<date type="published" when="2012-05" />
		</imprint>
	</monogr>
	<note>Sudre et al.2012</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
