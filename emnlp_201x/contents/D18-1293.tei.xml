<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Incremental Computation of Infix Probabilities for Probabilistic Finite Automata</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cognetta</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yo-Sub</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soon</forename><forename type="middle">Chan</forename><surname>Kwon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Incremental Computation of Infix Probabilities for Probabilistic Finite Automata</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2732" to="2741"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2732</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In natural language processing, a common task is to compute the probability of a given phrase appearing or to calculate the probability of all phrases matching a given pattern. For instance , one computes affix (prefix, suffix, in-fix, etc.) probabilities of a string or a set of strings with respect to a probability distribution of patterns. The problem of computing infix probabilities of strings when the pattern distribution is given by a probabilistic context-free grammar or by a probabilistic finite automaton is already solved, yet it was open to compute the infix probabilities in an incremental manner. The incremental computation is crucial when a new query is built from a previous query. We tackle this problem and suggest a method that computes infix probabilities incrementally for probabilistic finite automata by representing all the probabilities of matching strings as a series of transition matrix calculations. We show that the proposed approach is theoretically faster than the previous method and, using real world data, demonstrate that our approach has vastly better performance in practice .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Probabilistic grammars and finite automata are commonly used to model distributions in natural language processing. Among language models, probabilistic finite automata (PFAs) provide a sim- ple, yet powerful and well-understood representa- tion of many probabilistic language phenomena. Numerous speech processing tasks rely on PFAs in practice ( <ref type="bibr" target="#b6">Gyawali et al., 2013;</ref><ref type="bibr" target="#b10">Mohri et al., 2002;</ref><ref type="bibr" target="#b18">Wilson and Raaijmakers, 2008;</ref><ref type="bibr" target="#b13">Ng et al., 2000</ref>).</p><p>An important problem regarding PFAs is to cal- culate the probability of some affix <ref type="bibr">(prefix, suffix, infix, etc.</ref>) of a string with respect to a given dis- tribution. That is, given a PFA P and a string w, one might ask the probability of w appearing as a prefix, suffix, or infix in the distribution mod- eled by P-in other words, the sum of the prob- abilities of all strings in the form of wx, xw, or xwy with respect to P, for some strings x and y. A more general problem is to compute the sum of the probabilities of all strings in a regu- lar language with respect to a PFA. Computing af- fix probabilities in probabilistic models is an im- portant problem in natural language processing. For probabilistic context-free grammars (PCFGs) and PFAs, the problem of calculating the prefix or suffix probability of a string can be efficiently solved <ref type="bibr" target="#b4">(Fred, 2000;</ref><ref type="bibr" target="#b3">Corazza et al., 1991)</ref>. How- ever, calculating the infix probability of a string or the weight of a regular language is not as straightforward ( <ref type="bibr" target="#b3">Corazza et al., 1991)</ref>. Addition- ally, computing affix probabilities for more gen- eral probabilistic language models has proven to be quite difficult. Nevertheless, there are some ap- proaches for computing the exact affix probabil- ities over a variety of models. Lattice posterior probabilities for n-grams, which are a restricted form of PFA ( <ref type="bibr" target="#b17">Vidal et al., 2005b</ref>), have a vari- ety of uses in speech processing and can be com- puted efficiently (de <ref type="bibr" target="#b5">Gispert et al., 2013;</ref><ref type="bibr" target="#b2">Can and Narayanan, 2015)</ref>. For several affixes, <ref type="bibr" target="#b3">Corazza et al. (1991)</ref> described algorithms to determine the probability of a string appearing as that affix in a PCFG. They made an important note that, un- like computing prefix or suffix probabilities, infix probability calculations are prone to double count- ing in the event of the infix appearing multiple times in a string. Then, they provided an algorithm for computing the infix probability of a string in restricted cases. Stolcke (1995) described a series of recurrences that can be used to compute affix probabilities and variations of the most probable parse of a string for PCFGs. For the general class of linear context-free rewriting systems, a method to compute prefix probabilities is known <ref type="bibr" target="#b12">(Nederhof and Satta, 2011b</ref>). Fred (2000) also consid- ered these problems and described a method to compute the infix probabilities under the condi- tion that the infix appears at most once in any non- zero probability string when the language model is a stochastic regular grammar, which is equivalent in power to a PFA. These assumptions are rather strict and led researchers to consider a more gen- eral problem. Nederhof and Satta (2011a) solved the general infix probability problem for PCFGs. In fact, their method can be used to compute the weight of any regular language with respect to a PCFG. They also proposed an open problem of incrementally computing the infix probability of a string-using the numerical result of one infix computation to speed up the evaluation of another.</p><p>We design a new method for solving the in- fix probability problem for PFAs incrementally. Unlike the previous methods involving recur- rence calculations or intersection constructions, our method is based on evaluating a series of ma- trices formed from regular expressions. Addition- ally, our method has no constraints on the input string. We show that our method is both theoreti- cally and practically more performant than the pre- vious algorithms. Our experimental results show a greater than 80% performance improvement. In Section 2, we review PFAs and other necessary formalisms. We recall how to obtain unambigu- ous regular expressions in Section 3, and introduce a matrix representation for computing the weight of a regular language in Section 4. In Section 5, we propose an algorithm to incrementally com- pute the infix probability of a given string. We val- idate the practical performance of the incremental method using a test set of PFAs obtained from real life data in Section 6 and conclude with a discus- sion and some open problems in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Finite Automata and PFAs</head><p>Following standard notation in automata theory, we let Σ be a set of characters and Σ * be the set of all strings. For a string w = w 1 w 2 . . . w n ∈ Σ * , we write |w| = n as its length. The empty string is written as λ.</p><p>A deterministic finite automaton (DFA) is a 5- tuple D = (Q, Σ, δ, s, F ), where Q is a finite set of states, Σ is a finite alphabet, δ : Q × Σ → Q is the transition function, s ∈ Q is the initial state, and F ⊂ Q is the set of final states. A language is a set of strings, and D recognizes a regular language denoted by L(D). For a summary of automata theory (including regular expressions and formal language theory), we direct the reader to <ref type="bibr" target="#b7">Hopcroft and Ullman (1979)</ref>.</p><p>A PFA is a weighted finite automaton that com- putes a function P : Σ * → <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. We abuse function notation and write P(w) or P(π) to de- note the weight of a word or a path, respectively. These values are defined later. A PFA P is spec- ified by a 5-tuple P = (Q, Σ, δ, I, F ), where Q is a finite set of states, Σ is a finite alphabet,</p><formula xml:id="formula_0">δ : Q × Σ × Q → [0, 1] is the transition func- tion, I : Q → [0, 1] and F : Q → [0, 1]</formula><p>are the initial and final functions, respectively. The tran- sition function is assumed to have a default value of 0, in other words, if a transition does not exist it can be considered as having weight 0. A PFA has three additional requirements:</p><formula xml:id="formula_1">1. q∈Q I(q) = 1 2. ∀q ∈ Q, F (q) + q ∈Q,c∈Σ δ(q, c, q ) = 1</formula><p>3. All states are both accessible and co- accessible 1 .</p><p>If these conditions hold, then for all strings w, 0 ≤ P(w) ≤ 1 and w∈Σ * P(w) = 1. A PFA can be represented in the form of transition matrices, which simplifies several computations. We denote the matrix formulation of a PFA by P = (Q, Σ, {M(c)} c∈Σ , I, F) where {M(c)} c∈Σ is a set of |Q| × |Q| transition matrices with M(c) i,j = δ(q i , c, q j ). Likewise, I and F are 1 × |Q| and |Q| × 1 vectors with I i = I(q i ) and</p><formula xml:id="formula_2">F j = F (q j ).</formula><p>Consider a string w = w 1 w 2 · · · w n ∈ Σ * and a corresponding labeled path π = (q 0 , w 1 , q 1 ), (q 1 , w 2 , q 2 ), . . . , (q n−1 , w n , q n ) in P. Then the probability of a path π in P is</p><formula xml:id="formula_3">P(π) = I(q 0 ) n i=1 δ(q i−1 , w i , q i ) F (q n ).</formula><p>Let Φ w be the set of all labeled paths corre- sponding to w. The probability of w is now π∈Φw P(π). There exist two equivalent dy- namic programming methods-the forwards and backwards algorithms-to compute the probabil- ity of a given string ( <ref type="bibr" target="#b16">Vidal et al., 2005a</ref>). Using the matrix formulation, the probability of a string is given succinctly as</p><formula xml:id="formula_4">I |w| i=1 M(w i )F.</formula><p>For brevity, we write M(Σ) = c∈Σ M(c) and 0 and 1 for the zero and identity matrices when the dimensions are clear. Further, we compute</p><formula xml:id="formula_5">∞ i=0 M(Σ) i = (1 − M(Σ)) −1 ,</formula><p>which we denote M(Σ * ). We can compute the pre- fix and suffix probabilities of a string w as</p><formula xml:id="formula_6">P(wΣ * ) = I   |w| i=1 M(w i )   M(Σ * )F and P(Σ * w) = IM(Σ * )   |w| i=1 M(w i )   F,</formula><p>respectively. If an automaton M satisfies all of the requirements for a PFA except that q∈Q I(q) ≤ 1 or ∀ q ∈ Q, F (q) + q ∈Q,c∈Σ δ(q, c, q ) ≤ 1, then we call M a sub-PFA. These machines have the property that for any string w over Σ, 0 ≤ M(w) ≤ 1 and w∈Σ * M(w) ≤ 1. Since a sub-PFA M may not describe a probability distribution over strings, we call M(w) the weight of w instead of prob- ability. A stochastic language over an alphabet Σ is a set S ⊆ Σ * where each string in S has an associated probability, 0 ≤ P r S (w) ≤ 1, such that w∈Σ * P r S (w) = 1. Given a stochas- tic language S, if there exists a PFA P such that ∀w ∈ Σ * , P(w) = P r S (w), we call S a regular stochastic language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Unambiguous Regular Expressions</head><p>Regular expressions are a common representation of regular languages. A string that can be matched with a regular expression is said to be in the lan- guage of the regular expression. A match occurs when there is a valid assignment of symbols in the regular expression to the queried string. We de- note the set of all strings that match a regular ex- pression as L(R). An unambiguous regular ex- pression has only one valid assignment for any string in the language. For example, consider the regular expression (a ∪ b) * aa(a ∪ b) * , which ac- cepts the set of strings over Σ = {a, b} containing aa as an infix. We assign different subscripts to symbols that appear in more than one position to form</p><formula xml:id="formula_7">a , 0 . 2 | b , 0 . 2 a, 0.3 | b, 0.1 0.8 | 0.3 0.1 | 0.2 0.0 | 0.3 0.0 | 0.5 0.1 | 0.6 a, 0.5 | b, 0.2 b, 0.7 b, 0.2 a , 0 . 4 a, 0.1 b, 0.2</formula><formula xml:id="formula_8">(a 1 ∪ b 1 ) * a 2 a 3 (a 4 ∪ b 2 ) * .</formula><p>Given the string baaa, we find that b 1 a 1 a 2 a 3 and b 1 a 2 a 3 a 4 are both valid assignments, hence baaa is in the language. However, since there are two valid assignments, we say that this regular expression is ambigu- ous ( <ref type="bibr" target="#b1">Book et al., 1971</ref>). An unambiguous expres- sion for the same language is b * a(bb * a) * a(a ∪ b) * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Intersecting a DFA and a PFA</head><p>The standard method to compute the weight of a regular language with respect to a PFA is to in- tersect its DFA representation with the PFA. This construction was already discussed in ( <ref type="bibr" target="#b16">Vidal et al., 2005a</ref>). Nederhof and Satta (2011a) considered a similar construction for DFAs and PCFGs and solved the infix problem for that class of machine. The construction creates a new sub-PFA <ref type="bibr">[D ∩ P]</ref> such that:</p><formula xml:id="formula_9">[D ∩ P](w) = P(w), w ∈ L(D); 0, otherwise.</formula><p>It follows that</p><formula xml:id="formula_10">w∈Σ * [D ∩ P](w) = w∈L(D) P(w),</formula><p>as desired.</p><p>The intersection algorithm is similar to that of the cross product of two automata from clas- sical automata theory. Given a DFA D and a PFA P, we construct a new machine W with states Q W = Q D × Q P . For two states (x, y), (x , y ) and a character c ∈ Σ, δ W ((x, y), c, (x , y )) = δ P (y, c, y ) if δ D (x, c) = x and 0 otherwise. Likewise, I W ((p, q)) = I P (q) if p is the initial state of D and F W ((p , q )) = F P (q ) if p is a final state of D and are 0 otherwise.</p><p>Using Algorithm 1, we can now efficiently com- pute the sum of the weight of all strings in L(D) by evaluating</p><formula xml:id="formula_11">I [D ∩ P] (1 − M [D ∩ P] (Σ)) −1 F [D ∩ P] . Algorithm 1 DFA/PFA intersection 1: procedure INTERSECT(DFA D, PFA P) 2: Q = Q D × Q P 3: for (d, p) ∈ Q do 4: if d is q 0 then 5: I ((d, p)) = I(p) 6:</formula><p>else 7:</p><formula xml:id="formula_12">I ((d, p)) = 0 8: end if 9: if d ∈ F D then 10: F ((d, p)) = F (p) 11:</formula><p>else 12:</p><formula xml:id="formula_13">F ((d, p)) = 0 13: end if 14: for c ∈ Σ, (d , p ) ∈ Q do 15: if δ D (d, c) = d then 16: δ ((d, p), c, (d , p )) = δ P (p, c, p ) 17:</formula><p>else 18: </p><formula xml:id="formula_14">δ ((d, p), c, (d , p )) =</formula><formula xml:id="formula_15">return [D ∩ P] = (Q , Σ, δ , I , F ) 23: end procedure</formula><p>To find the infix probability of a given string w = w 1 w 2 · · · w n , we take D to be a DFA that recognizes the language of all strings containing w as an infix. The Knuth-Morris-Pratt (KMP) al- gorithm produces such a DFA (with O(n) states) in O(n) time ( <ref type="bibr" target="#b8">Knuth et al., 1977)</ref>. Thus, comput- ing the infix probabilities of each of w's prefixes takes O(n(n|Q P |) m ) time, where m is the matrix multiplication constant 2 , as at each step one needs to rebuild the entire intersection automaton for the current prefix and compute an inverse on its tran- sition matrices.</p><p>Nederhof and Satta (2011a) demonstrated that a similar method can be used to compute the infix probability of a given string in PCFGs. <ref type="bibr" target="#b1">Book et al. (1971)</ref> showed that, given a regular language (in the form of an automaton or regular expression), one can find an equivalent unambigu- ous regular expression by constructing an equiva- lent DFA and using state elimination on the result- ing DFA. Let D = (Q, Σ, δ, q 1 , F ) be a DFA with |Q| = n and the states being ordered from 1 to n. We add two new states, q 0 and q n+1 such that q 0 is the new start state and q n+1 is the only final state, and add the following transitions: δ(q 0 , λ) = q 1 and ∀q ∈ F, δ(q, λ) = q n+1 . We then dynamically eliminate states using the following recurrence:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Generating Unambiguous Regular Expressions</head><formula xml:id="formula_16">α k i,j = α k−1 i,j + α k−1 i,k (α k−1 k,k ) * α k−1 k,j</formula><p>with the base cases:</p><formula xml:id="formula_17">α 0 i,j =      λ, i = 0, j = 1; λ, q i ∈ F ∧ j = n + 1; {c | δ(q i , c) = q j }, otherwise.</formula><p>The equations follow the general concatenation, union, and Kleene star rules for regular expres- sions. In addition, we have:</p><formula xml:id="formula_18">• ∅ + c = c + ∅ = c, for c ∈ Σ • ∅c = c∅ = ∅, for c ∈ Σ • λc = cλ = c, for c ∈ Σ • ∅ * = λ.</formula><p>The term α k−1 i,j corresponds to the set of strings for which, starting from state q i , describe a path to q j where all intermediate states are of the form q , where &lt; k (the terminal state in the path has no such restriction). Similarly,</p><formula xml:id="formula_19">α k−1 i,k (α k−1 k,k ) * α k−1 k,j</formula><p>corresponds to all of the strings which, beginning at state q i , end at q j going through q k , where all intermediate states have label at most k (Mc- Naughton and Yamada, 1960). We extract α n 0,n+1 , which is an unambiguous regular expression for the language recognized by <ref type="bibr">D (Book et al., 1971)</ref>. Note that the requirement of an input automaton being deterministic is not strict. In fact, state elimination generates unam- biguous regular expressions from any unambigu- ous automaton.</p><p>From now on, we only consider unambiguous regular expressions for any regular languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Weight of a Regular Language</head><p>In Section 2.3, we reviewed the classical way of computing the weight of a regular language with respect to a PFA using an intersection construc- tion. Here, we present a new method based on unambiguous regular expressions. We describe a simple transformation to convert regular expres- sions into operations on transition matrices. Con- sider the following mapping from regular expres- sions to matrices:</p><formula xml:id="formula_20">• ∅ → 0 • λ → 1 • c ∈ Σ → M(c).</formula><p>Now, let R and S be regular expressions with M(R) and M(S) being their corresponding ma- trices:</p><formula xml:id="formula_21">• R ∪ S → M(R) + M(S) • RS → M(R)M(S) • R * → (1 − M(R)) −1 .</formula><p>Using these definitions, we can build a ma- trix calculation out of a given regular expression. We then obtain the weight of a regular expres- sion R with respect to some PFA P by evaluat- ing I P M P (R)F P . However, the straightforward application of this method is prone to overcount- ing when there are many ways for a string to be matched to the expression.</p><p>We present a simple example where an am- biguous expression overcounts whereas an unam- biguous expression returns the correct result when transformed into matrix calculations:</p><p>Let R = b * a(bb * a) * a(a ∪ b) * and S = (a ∪ b) * aa(a ∪ b) * , which are both regular expressions for all strings containing aa as an infix. Using the PFA in <ref type="figure" target="#fig_0">Figure 1</ref>, we have:</p><formula xml:id="formula_22">IM(b * a(bb * a) * a(a ∪ b) * )F ≈ 0.153, IM((a ∪ b) * aa(a ∪ b) * )F ≈ 0.198.</formula><p>This gap can be made arbitrarily large by adding ambiguity to the regular expression with- out changing the described language.</p><p>We now show that, given a PFA P and a DFA D, we can compute the weight of L(D) with respect to P. Lemma 1. Let P be a PFA, D be a DFA and R be an unambiguous regular expression for L(D) generated by state elimination. Then I P M P (R)F P = w∈L(D) P(w). Proof. Let D have n states, labeled q 1 to q n . We proceed as in <ref type="bibr" target="#b1">(Book et al., 1971</ref>) by adding two new states, q 0 and q n+1 . We fill out the base case table α 0 . We then construct a new table, β where</p><formula xml:id="formula_23">β k i,j = M P (α k i,j )</formula><p>. In other words, α holds the regular expressions generated during state elimi- nation while β holds the corresponding matrices. Since α 0 contains only unambiguous regular ex- pressions, M P (α 0 i,j ) is the matrix corresponding to the sum of M P (w) for all w that, starting from state q i travel to state q j without passing through any states with label greater than 0. We continue the elimination process until we reach α n and β n . The regular expression in α n 0,n+1 corresponds to the unambiguous regular expression containing all strings accepted by D. Thus, the matrix stored in β n 0,n+1 is the matrix such that</p><formula xml:id="formula_24">I P M P (α n 0,n+1 )F P = I P β n 0,n+1 F P = w∈L(D)</formula><p>P(w).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Incremental Infix Calculation</head><p>We now tackle the open problem of incrementally computing the infix probability of a string with re- spect to a PFA. Suppose we have computed the in- fix probability of a string w. We want to use the re- sult of that computation to compute the infix prob- ability of wa without simply starting the computa- tion again from scratch. Such a calculation is rel- atively easy for other affixes. For the prefix prob- ability of a string represented by the unambiguous regular expression wΣ * , one can simply compute IM(w)M(Σ * )F and save the vector IM(w). When the prefix is extended to wa, the saved vector can be multiplied by M(a)M(Σ * )F and obtain the re- sult (we can save the vector IM(w)M(a) to use in future incremental calculations). A similar pro- cess works for the incremental suffix probability of a string (Σ * w to Σ * aw). These incremental ap- proaches are due to the inherent unambiguity of regular expressions for strings appearing as a pre- fix or suffix. Unfortunately, the analogous method for infix probabilities is not as straightforward. We cannot simply append (or prepend) the desired character to a precomputed regular expression because the resulting expression may not be unambiguous or may represent the a different language. To tackle this problem, we first define the language F(w) to be the set of strings that end in the first occurrence of w. In other words,  Next, we find a regular language L such that F(wa) = F(w) · L for a character a ∈ Σ, which gives rise to an incremental computation using the previous result F(w). Given two languages R and S, we define the left quotient R\S to be:</p><formula xml:id="formula_25">R\S = {y | ∃x ∈ R such that xy ∈ S}.</formula><p>It is known that regular languages are closed under the left quotient operation <ref type="bibr" target="#b7">(Hopcroft and Ullman, 1979)</ref>. Corollary 2 follows from the definition of the left quotient and describes the desired L.</p><p>Corollary 2. Given F(w) and F(w)\F(wa), F(wa) = F(w) · F(w)\F(wa).</p><p>We use this characteristic and compute F(w)\F(wa) without explicitly computing F(wa) based on state elimination-the procedure is detailed later in this section. <ref type="figure">Figure 2</ref> is an annotated example of unambiguous regular expressions for F of a, aa, and aab.</p><p>Let D be the DFA for F(w 1 w 2 · · · w n ) gener- ated by the KMP algorithm ( <ref type="bibr" target="#b8">Knuth et al., 1977)</ref>. Two examples are depicted in <ref type="figure" target="#fig_3">Figure 3</ref>. D has n + 1 states, with state q n+1 being final and hav- ing no outgoing transitions. Furthermore, each</p><formula xml:id="formula_26">F(a) = b * a F(aa) = b * a · (bb * a) * a F(aab) = b * a(bb * a) * a · a * b F(a) F(a)\F(aa) F(aa) F(aa)\F(aab)</formula><p>Figure 2: An example of F for a, aa, aab. We anno- tate them to show how F can be built up incrementally using previously computed regular expressions.</p><p>state q i with i &lt; n + 1 has exactly one outgo- ing transition to state q i+1 and all other transitions are to states with labels at most i. Thus, removing state q n+1 and all incoming and outgoing transi- tions and making q n the only final state results in the DFA for F(w 1 w 2 · · · w n−1 ). This process can be repeated until the empty string is reached. This leads to the observation that, when constructing an unambiguous expression for F(w 1 w 2 · · · w n ), we can recover the expression for F(w 1 w 2 · · · w n−1 ) extracting the regular expression at α n−1 0,n . Simi- larly, the expression for F(w 1 w 2 · · · w k ) is stored at α k 0,k+1 . At stage k of the state elimination procedure on D, state q 0 is only connected to states up to label k − 1, thus α k−1 0,k+1 = ∅. Since</p><formula xml:id="formula_27">α k 0,k+1 = α k−1 0,k+1 + α k−1 0,k (α k−1 k,k ) * α k−1 k,k+1 ,</formula><p>we can simplify the expression as</p><formula xml:id="formula_28">α k 0,k+1 = α k−1 0,k (α k−1 k,k ) * α k−1 k,k+1 .</formula><p>In addition, we recall</p><formula xml:id="formula_29">α k−1 0,k = F(w 1 w 2 · · · w k−1 ).</formula><p>Therefore,</p><formula xml:id="formula_30">F(w 1 · · · w k ) = F(w 1 · · · w k−1 )(α k−1 k,k ) * α k−1 k,k+1</formula><p>and</p><formula xml:id="formula_31">(α k−1 k,k ) * α k−1 k,k+1 = F(w 1 · · · w k−1 )\F(w 1 · · · w k ).</formula><p>Algorithm 2 is for the offline setting-we know the entire string ahead of time and compute the in- fix probabilities of each of its prefixes incremen- tally. In Algorithm 2, following Section 3 and the relationship between the tables α and β in the proof of Lemma 1, we run the matrix eval- uations of each regular expression instead of the regular expressions directly. At any step k, we only consider tables α k and α k−1 and, thus, we can employ a standard sliding window technique for dynamic programming to reduce the required space complexity. In this scheme, instead of hold- ing all tables up to α k , we simply hold the two most previous ones, reducing the space complex- ity required by a factor of O(k). We call our two tables T and T and, to simplify the pseudocode, make elements of these two tables behave as both matrices and regular expressions. For example, (T i,j ) * simultaneously corresponds to the regular expression (α i,j ) * and the matrix M((</p><formula xml:id="formula_32">α i,j ) * ) = (1 − M(α i,j )) −1 . Algorithm 2 Offline Incremental Infix 1: procedure INFIX(w = w 1 w 2 · · · w n ∈ Σ * ) 2:</formula><p>D ← DFA accepting F(w)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>T ← (n + 3) × (n + 3) T 0,1 ← 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>T n+1,n+2 ← 1 6:</p><formula xml:id="formula_33">for i ∈ [1, n + 2]; j ∈ [1, n + 2]; c ∈ Σ do 7:</formula><p>if δ(q i , c) = q j then 8:</p><formula xml:id="formula_34">T i,j ← T i,j + M(c) 9:</formula><p>end if 10:</p><p>end for 11:</p><formula xml:id="formula_35">V ← I 12: for k ∈ [0, n + 1] do 13: V ← V(T k,k ) * T k,k+1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:</head><p>yield VM(Σ * )F</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15:</head><p>T ← (n + 3) × (n + 3) table <ref type="bibr">16</ref>:</p><formula xml:id="formula_36">for i ∈ [0, n + 2]; j ∈ [0, n + 2] do 17: T i,j ← T i,j + T i,k (T k,k ) * T k,j 18:</formula><p>end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>19:</head><p>T ← T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>20:</head><p>end for 21: end procedure Algorithm 2 begins by constructing DFA for F(w), which takes linear time in the length of w ( <ref type="bibr" target="#b8">Knuth et al., 1977)</ref> on Line 2. This DFA is modified to contain the new start and end state as described in Section 3 for a total of n + 3 states. We then begin to step through the state elimination algorithm. After constructing the ini- tial table based on the base cases described in Sec- tion 3 from Line 3 to 10, we prepare our vector V that will record results from the previous in- fix calculation. At the beginning, V should hold IM(F(λ)) = I. In the first step, we eliminate state q 1 of the automaton. Since state q 0 leads to state q 1 with a λ-transition, F at this step corresponds to F(λ) and F(λ) · Σ * = Σ * , which trivially has infix probability 1. At stage k of the for loop, we compute F(w 1 w 2 · · · w k−1 )\F(w 1 w 2 · · · w k ) on Line 13. We multiply this by V, which holds F(w 1 w 2 · · · w k−1 ), which makes V now store F(w 1 w 2 · · · w k ). On Line 14, we emit the infix probability of w 1 w 2 · · · w k by evaluat- ing VM P (Σ * )F P . From Line 15 to 18, we up- date our state elimination table. On Line 19, we use the sliding window technique and copy our updated table into T which allows for T to be safely overwritten in the next iteration. This pro- cess repeats until we have removed all states q i for 1 ≤ i ≤ n + 1, and therefore have computed the infix probability of each prefix of w. </p><formula xml:id="formula_37">| m ) compared to O(|w|(|w||Q P |) m ) = O(|w| m+1 |Q P | m ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Results</head><p>We verify the effectiveness of our method using real-world data. We present 3 n-grams 3 (two 2- grams and one 3-gram) and their 3 PFAs with 614, 1028, and 1455 states extracted from the Brown Corpus tagged with the Penn Tree Bank tagset us- ing the NLTK library ( <ref type="bibr" target="#b0">Bird and Loper, 2004</ref>). As a preprocessing step, we convert all punctuation to the PUNC tag for a total of 35 tags. The n-grams are built by computing the probability of reading a given tag under the condition that we have just seen a specific sequence of n tags. We then ran- domly select a sequence of 9 tags as our string across all experiments. For each of the n-grams, we calculate the infix probability of each prefix of our input string using the incremental regular ex- pression method and the intersection method. We record the average of 10 runs per infix calcula- tion. All experiments were written in Python 3.5 and the automata and matrices were implemented using NumPy. The experiments were run on an AMD Ryzen 7 1700 (3.0 GHz) 8-Core Processor <ref type="bibr">3</ref> We have a similar performance improvement for all other test cases that we extract from the dataset. with 16GB of RAM.</p><p>In the worst-case (the case when |Q| = 1028 in <ref type="table">Table 1</ref>), the cumulative time for the incremental shows an 556.77% speed-up. The largest individ- ual infix probability calculation is in the experi- ment with |Q| = 1455 when calculating the infix of length 9, where the incremental method obtains a 560.76% speed-up. These results show that the incremental method is not only theoretically faster, but also much faster in practice when compared to the intersection method.</p><p>The runtime gap is quite large compared to what is expected from the theoretical analysis of the two algorithms. Additionally, in theory, the time for each step of the incremental calculation should remain essentially constant, but the experimental results show that it grows at a slow rate. These are most likely implementation issues stemming from the large memory requirements involved in the calculations.</p><p>The experimental results show that the incre- mental infix method vastly outperforms the naive intersection method. The ability to memoize previous calculations allows the incremental ap- proach to calculate the next infix probability much faster than simply restarting the entire calculation. This empirically verifies the asymptotic analysis of the two approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We have presented a new method for solving the open problem of incrementally computing the in- fix probabilities of a given string with respect to a PFA. Our method utilizes unambiguous regular expressions and is distinguished from the previous methods in that it does not alter the structure of the PFA during the evaluation. Similarly to the al- gorithm presented in <ref type="bibr" target="#b11">(Nederhof and Satta, 2011a)</ref>, this method imposes no restrictions on the input string.</p><p>We have showed that our method is asymp- totically faster than the previously best-known method. Furthermore, we have experimentally evaluated the performance of our algorithm on a real life dataset and have observed that the pro- posed algorithm performs significantly better than the intersection method in all cases.</p><p>Future directions of this line of research are to determine a method for two sided incremental in- fix computation-that is, given a computation for the infix of w, compute the infix of wa or aw at will. Currently, it is only possible to do one sided incremental infix calculations. Computing the in- fix incrementally in an online fashion-in which we do not know the entire string ahead of time and receive new characters in a stream-would be an- other improvement. We believe that the current method can be modified to work in an online set- ting, possibly with an increase in runtime. Fur- thermore, finding new classes of problems that can benefit from a similar incremental calculation is also interesting. Finally, extending this method to work for PCFGs and more complex probabilistic models is an important open problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example PFA over Σ = {a, b}. Each state has an initial and final probability, separated by a bar. The edges hold a character and the probability of the corresponding transition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>F</head><label></label><figDesc>(w) = {x | w appears only as a suffix of x}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>It follows that F(w) · Σ * is exactly the set of strings containing w as an infix. Thus, given an unambiguous regular expression for F(w), we can build an unambiguous regular expression for the infix of w by concatenating with Σ * .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: DFAs generated by the KMP algorithm. DFA A) accepts F(aab) and B) accepts F(aabb). The automata below are the new finite automata after adding the new initial and final state for the state elimination procedure, as described in Section 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>table 4 :</head><label>4</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> Accessible states are states reachable from a state with non-zero initial weight and co-accessible states are those that can reach a state with non-zero final weight.</note>

			<note place="foot" n="2"> The matrix multiplication constant, m, is the order of the polynomial for the runtime of multiplying two n×n matrices together, i.e. a function in O(n m ). In practice, Strassen&apos;s algorithm is often used, yielding m ≈ 2.81 (Strassen, 1969).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors thank the reviewers for their detailed and constructive comments. This work was supported by the Institute for Information &amp; Communications Technology Pro-motion (IITP) grant funded by the Korea govern-ment (MSIP) <ref type="bibr">(2018-0-00247, 2018-0-00276)</ref>.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">NLTK: The natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2004 on Interactive Poster and Demonstration Sessions</title>
		<meeting>the ACL 2004 on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ambiguity in graphs and expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Book</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimon</forename><surname>Even</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheila</forename><surname>Greiback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gene</forename><surname>Ott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="149" to="153" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A dynamic programming algorithm for computing ngram posteriors from lattices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dogan</forename><surname>Can</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrikanth</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2388" to="2397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Computation of probabilities for an island-driven parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Corazza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renato</forename><forename type="middle">De</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Gretter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="936" to="950" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Computation of substring probabilities in stochastic grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">N</forename><surname>Ana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fred</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Grammatical Inference: Algorithms and Applications</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="103" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">N-gram posterior probability confidence measures for statistical machine translation: an empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Adrì A De Gispert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gonzalo</forename><surname>Blackwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="85" to="114" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Native language identification: a simple n-gram based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binod</forename><surname>Gyawali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriela</forename><surname>Ramírez-De-La-Rosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thamar</forename><surname>Solorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, BEA@NAACL-HLT</title>
		<meeting>the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, BEA@NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="224" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Introduction to Automata Theory, Languages, and Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">E</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Addison-Wesley Publishing Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast pattern matching in strings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">E</forename><surname>Knuth</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaughan</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="323" to="350" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Regular expressions and state graphs for automata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Mcnaughton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisao</forename><surname>Yamada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Transactions on Electronic Computers</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="39" to="47" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Weighted finite-state transducers in speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="88" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Computation of infix probabilities for probabilistic contextfree grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Mark-</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Nederhof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1213" to="1221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Prefix probabilities for linear context-free rewriting systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Mark-</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Nederhof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Parsing</title>
		<meeting>the 12th International Conference on Parsing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="151" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Experiments in spoken document retrieval using phoneme n-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="61" to="77" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An efficient probabilistic context-free parsing algorithm that computes prefix probabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="165" to="201" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gaussian elimination is not optimal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Volker Strassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="354" to="356" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Probabilistic finite-state machines-part I</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franck</forename><surname>Thollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Higuera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><forename type="middle">C</forename><surname>Casacuberta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carrasco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1013" to="1025" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Probabilistic finite-state machines-part II</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franck</forename><surname>Thollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Higuera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><forename type="middle">C</forename><surname>Casacuberta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carrasco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1026" to="1039" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Comparing word, character, and phoneme n-grams for subjective utterance recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Raaijmakers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH 2008, 9th Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1614" to="1617" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
