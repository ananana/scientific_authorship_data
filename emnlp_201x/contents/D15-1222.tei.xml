<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="1925">1925-1930. September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="1925">1925-1930. September 2015. 2015</date>
						</imprint>
					</monogr>
					<note>Better Summarization Evaluation with Word Embeddings for ROUGE Jun-Ping Ng Bloomberg L.P. New York, USA jng324@bloomberg.net Viktoria Abrecht Bloomberg L.P. New York, USA vkanchakousk@bloomberg.net</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>ROUGE is a widely adopted, automatic evaluation measure for text summariza-tion. While it has been shown to correlate well with human judgements, it is biased towards surface lexical similarities. This makes it unsuitable for the evaluation of abstractive summarization, or summaries with substantial paraphrasing. We study the effectiveness of word embed-dings to overcome this disadvantage of ROUGE. Specifically, instead of measuring lexical overlaps, word embeddings are used to compute the semantic similarity of the words used in summaries instead. Our experimental results show that our proposal is able to achieve better correlations with human judgements when measured with the Spearman and Kendall rank coefficients .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic text summarization is a rich field of re- search. For example, shared task evaluation work- shops for summarization were held for more than a decade in the Document Understanding Con- ference (DUC), and subsequently the Text Anal- ysis Conference (TAC). An important element of these shared tasks is the evaluation of participating systems. Initially, manual evaluation was carried out, where human judges were tasked to assess the quality of automatically generated summaries. However in an effort to make evaluation more scaleable, the automatic ROUGE 1 measure <ref type="bibr" target="#b8">(Lin, 2004b</ref>) was introduced in DUC-2004. ROUGE determines the quality of an automatic summary through comparing overlapping units such as n- grams, word sequences, and word pairs with hu- man written summaries. <ref type="bibr">1</ref> Recall-Oriented Understudy of Gisting Evaluation ROUGE is not perfect however. Two problems with ROUGE are that 1) it favors lexical simi- larities between generated summaries and model summaries, which makes it unsuitable to evaluate abstractive summarization, or summaries with a significant amount of paraphrasing, and 2) it does not make any provision to cater for the readability or fluency of the generated summaries.</p><p>There has been on-going efforts to improve on automatic summarization evaluation measures, such as the Automatically Evaluating Summaries of Peers (AESOP) task in TAC ( <ref type="bibr" target="#b1">Dang and Owczarzak, 2009;</ref><ref type="bibr" target="#b16">Owczarzak, 2010;</ref><ref type="bibr" target="#b15">Owczarzak and Dang, 2011)</ref>. However, ROUGE remains as one of the most popular metric of choice, as it has repeatedly been shown to correlate very well with human judgements <ref type="bibr" target="#b7">(Lin, 2004a;</ref><ref type="bibr" target="#b14">Over and Yen, 2004;</ref><ref type="bibr" target="#b15">Owczarzak and Dang, 2011)</ref>.</p><p>In this work, we describe our efforts to tackle the first problem of ROUGE that we have iden- tified above -its bias towards lexical similari- ties. We propose to do this by making use of word embeddings ( <ref type="bibr" target="#b0">Bengio et al., 2003)</ref>. Word embed- dings refer to the mapping of words into a multi- dimensional vector space. We can construct the mapping, such that the distance between two word projections in the vector space corresponds to the semantic similarity between the two words. By in- corporating these word embeddings into ROUGE, we can overcome its bias towards lexical similar- ities and instead make comparisons based on the semantics of words sequences. We believe that this will result in better correlations with human assessments, and avoid situations where two word sequences share similar meanings, but get unfairly penalized by ROUGE due to differences in lexico- graphic representations.</p><p>As an example, consider these two phrases: 1) It is raining heavily, and 2) It is pouring. If we are performing a lexical string match, as ROUGE does, there is nothing in common between the terms "raining", "heavily", and "pouring". How- ever, these two phrases mean the same thing. If one of the phrases was part of a human written summary, while the other was output by an auto- matic summarization system, we want to be able to reward the automatic system accordingly.</p><p>In our experiments, we show that word embed- dings indeed give us better correlations with hu- man judgements when measured with the Spear- man and Kendall rank coefficient. This is a signif- icant and exciting result. Beyond just improving the evaluation prowess of ROUGE, it has the po- tential to expand the applicability of ROUGE to abstractive summmarization as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>While ROUGE is widely-used, as we have noted earlier, there is a significant body of work study- ing the evaluation of automatic text summarization systems. A good survey of many of these mea- sures has been written by <ref type="bibr" target="#b19">Steinberger and Ježek (2012)</ref>. We will thus not attempt to go through every measure here, but rather highlight the more significant efforts in this area.</p><p>Besides ROUGE, Basic Elements (BE) <ref type="bibr" target="#b4">(Hovy et al., 2005</ref>) has also been used in the DUC/TAC shared task evaluations. It is an automatic method which evaluates the content completeness of a generated summary by breaking up sentences into smaller, more granular units of information (re- ferred to as "Basic Elements").</p><p>The pyramid method originally proposed by <ref type="bibr" target="#b17">Passonneau et al. (2005)</ref> is another staple in DUC/TAC. However it is a semi-automated method, where significant human intervention is required to identify units of information, called Summary Content Units (SCUs), and then to map content within generated summaries to these SCUs. Recently however, an automated variant of this method has been proposed ( <ref type="bibr" target="#b18">Passonneau et al., 2013)</ref>. In this variant, word embeddings are used, as we are proposing in this paper, to map text con- tent within generated summaries to SCUs. How- ever the SCUs still need to be manually identified, limiting this variant's scalability and applicability.</p><p>Many systems have also been proposed in the AESOP task in TAC from 2009 to 2011. For ex- ample, the top system reported in <ref type="bibr" target="#b15">Owczarzak and Dang (2011)</ref>, <ref type="bibr">AutoSummENG (Giannakopoulos and Karkaletsis, 2009)</ref>, is a graph-based system which scores summaries based on the similarity between the graph structures of the generated sum- maries and model summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>Let us now describe our proposal to integrate word embeddings into ROUGE in greater detail.</p><p>To start off, we will first describe the word em- beddings that we intend to adopt. A word embed- ding is really a function W , where W : w → R n , and w is a word or word sequence. For our pur- pose, we want W to map two words w 1 and w 2 such that their respective projections are closer to each other if the words are semantically sim- ilar, and further apart if they are not. <ref type="bibr" target="#b11">Mikolov et al. (2013b)</ref> describe one such variant, called word2vec, which gives us this desired property 2 . We will thus be making use of word2vec.</p><p>We will now explain how word embeddings can be incorporated into ROUGE. There are sev- eral variants of ROUGE, of which ROUGE-1, ROUGE-2, and ROUGE-SU4 have often been used. This is because they have been found to cor- relate well with human judgements <ref type="bibr" target="#b7">(Lin, 2004a;</ref><ref type="bibr" target="#b14">Over and Yen, 2004;</ref><ref type="bibr" target="#b15">Owczarzak and Dang, 2011</ref>). ROUGE-1 measures the amount of unigram over- lap between model summaries and automatic sum- maries, and ROUGE-2 measures the amount of bi- gram overlap. ROUGE-SU4 measures the amount of overlap of skip-bigrams, which are pairs of words in the same order as they appear in a sen- tence. In each of these variants, overlap is com- puted by matching the lexical form of the words within the target pieces of text. Formally, we can define this as a similarity function f R such that:</p><formula xml:id="formula_0">f R (w 1 , w 2 ) = 1, if w 1 = w 2 0, otherwise<label>(1)</label></formula><p>where w 1 and w 2 are the words (could be unigrams or n-grams) being compared. In our proposal 3 , which we will refer to as ROUGE-WE, we define a new similarity function f W E such that:</p><formula xml:id="formula_1">f W E (w 1 , w 2 ) = 0, if v 1 or v 2 are OOV v 1 · v 2 , otherwise<label>(2)</label></formula><p>where w 1 and w 2 are the words being compared, and v x = W (w x ). OOV here means a situation where we encounter a word w that our word em- bedding function W returns no vector for. For the purpose of this work, we make use of a set of 3 million pre-trained vector mappings 4 trained from part of Google's news dataset ( <ref type="bibr" target="#b10">Mikolov et al., 2013a</ref>) for W .</p><p>Reducing OOV terms for n-grams. With our formulation for f W E , we are able to compute variants of ROUGE-WE that correspond to those of ROUGE, including ROUGE-WE-1, ROUGE- WE-2, and ROUGE-WE-SU4. However, despite the large number of vector mappings that we have, there will still be a large number of OOV terms in the case of ROUGE-WE-2 and ROUGE-WE-SU4, where the basic units of comparison are bigrams.</p><p>To solve this problem, we can compose individ- ual word embeddings together. We follow the sim- ple multiplicative approach described by <ref type="bibr" target="#b12">Mitchell and Lapata (2008)</ref>, where individual vectors of constituent tokens are multiplied together to pro- duce the vector for a n-gram, i.e.,</p><formula xml:id="formula_2">W (w) = W (w 1 ) × . . . × W (w n )<label>(3)</label></formula><p>where w is a n-gram composed of individual word tokens, i.e., w = w 1 w 2 . . . w n . Multiplication be- tween two vectors W (w i ) = {v i1 , . . . , v ik } and W (w j ) = {v j1 , . . . , v jk } in this case is defined as:</p><formula xml:id="formula_3">{v i1 × v j1 , . . . , v ik × v jk }<label>(4)</label></formula><p>4 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset and Metrics</head><p>For our experiments, we make use of the dataset used in AESOP ( <ref type="bibr" target="#b15">Owczarzak and Dang, 2011)</ref>, and the corresponding correlation measures. For clarity, let us first describe the dataset used in the main TAC summarization task. The main summarization dataset consists of 44 topics, each of which is associated with a set of 10 docu- ments. There are also four human-curated model summaries for each of these topics. Each of the 51 participating systems generated a summary for each of these topics. These automatically gener- ated summaries, together with the human-curated model summaries, then form the basis of the dataset for AESOP.</p><p>To assess how effective an automatic evaluation system is, the system is first tasked to assign a score for each of the summaries generated by all of the 51 participating systems. Each of these sum- maries would also have been assessed by human judges using these three key metrics: Pyramid. As reviewed in Section 2, this is a semi- automated measure described in <ref type="bibr" target="#b17">Passonneau et al. (2005)</ref>. Responsiveness. Human judges are tasked to evaluate how well a summary adheres to the infor- mation requested, as well as the linguistic quality of the generated summary. Readability. Human judges give their judgement on how fluent and readable a summary is.</p><p>The evaluation system's scores are then tested to see how well they correlate with the human assess- ments. The correlation is evaluated with a set of three metrics, including 1) Pearson correlation (P), 2) Spearman rank coefficient (S), and 3) Kendall rank coefficient (K).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>We evaluate three different variants of our proposal, ROUGE-WE-1, ROUGE-WE-2, and ROUGE-WE-SU4, against their corresponding variants of ROUGE (i.e., ROUGE-1, ROUGE-2, ROUGE-SU4). It is worth noting here that in AE- SOP in 2011, ROUGE-SU4 was shown to corre- late very well with human judgements, especially for pyramid and responsiveness, and out-performs most of the participating systems. <ref type="table" target="#tab_0">Tables 1, 2, and 3</ref> show the correlation of the scores produced by each variant of ROUGE-WE with human assessed scores for pyramid, respon- siveness, and readability respectively. The tables also show the correlations achieved by ROUGE-1, ROUGE-2, and ROUGE-SU4. The best result for each column has been bolded for readability.  <ref type="table">Table 1</ref>: Correlation with pyramid scores, mea- sured with Pearson r (P), Spearman ρ (S), and Kendall τ (K) coefficients.</p><p>ROUGE-WE-1 is observed to correlate very well with the pyramid, responsiveness, and read-</p><formula xml:id="formula_4">Measure P S K ROUGE-WE-1</formula><p>0.9155 0.8192 0.6308 ROUGE-WE-2 0.9534 0.7974 0.6149 ROUGE-WE-SU4 0.9538 0.7872 0.5969 ROUGE-1 0.9349 0.8182 0.6334 ROUGE-2 0.9416 0.7897 0.6096 ROUGE-SU4 0.9545 0.7902 0.6017  <ref type="table">Table 3</ref>: Correlation with readability scores, mea- sured with Pearson r (P), Spearman ρ (S), and Kendall τ (K) coefficients.</p><p>ability scores when measured with the Spear- man and Kendall rank correlation. However, ROUGE-SU4 correlates better with human assess- ments for the Pearson correlation. The key differ- ence between the Pearson correlation and Spear- man/Kendall rank correlation, is that the former assumes that the variables being tested are nor- mally distributed. It also further assumes that the variables are linearly related to each other. The lat- ter two measures are however non-parametric and make no assumptions about the distribution of the variables being tested. We argue that the assump- tions made by the Pearson correlation may be too constraining, given that any two independent eval- uation systems may not exhibit linearity. Looking at the two bigram based variants, ROUGE-WE-2 and ROUGE-WE-SU4, we ob- serve that ROUGE-WE-2 improves on ROUGE-2 most of the time, regardless of the correlation met- ric used. This lends further support to our proposal to use word embeddings with ROUGE.</p><p>However ROUGE-WE-SU4 is only better than ROUGE-SU4 when evaluating readability. It does consistently worse than ROUGE-SU4 for pyramid and responsiveness. The reason for this is likely due to how we have chosen to compose unigram word vectors into bigram equivalents. The mul- tiplicative approach that we have taken worked better for ROUGE-WE-2 which looks at contigu- ous bigrams. These are easier to interpret seman- tically than skip-bigrams (the target of ROUGE- WE-SU4). The latter, by nature of their construc- tion, loses some of the semantic meaning attached to each word, and thus may not be as amenable to the linear composition of word vectors.</p><p>Owczarzak and Dang (2011) reports only the results of the top systems in AESOP in terms of Pearson's correlation. To get a more complete picture of the usefulness of our proposal, it will be instructive to also compare it against the other top systems in AESOP, when measured with the Spearman/Kendall correlations. We show in Ta- ble 4 the top three systems which correlate best with the pyramid score when measured with the Spearman rank coefficient. C S IIITH3 ( <ref type="bibr" target="#b5">Kumar et al., 2011</ref>) is a graph-based system which assess summaries based on differences in word co-locations between generated summaries and model summaries. BE-HM (baseline by the orga- nizers of the AESOP task) is the BE system ( <ref type="bibr" target="#b4">Hovy et al., 2005</ref>), where basic elements are identi- fied using a head-modifier criterion on parse re- sults from Minipar. Lastly, catolicasc1 (de Oliveira, 2011) is also a graph-based system which frames the summary evaluation problem as a max- imum bipartite graph matching problem.  We see that ROUGE-WE-1 displays better cor- relations with pyramid scores than the top system in AESOP 2011 (i.e., C S IIITH3) when mea- sured with the Spearman coefficient. The latter does slightly better however for the Kendall coef- ficient. This observation further validates that our proposal is an effective enhancement to ROUGE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We proposed an enhancement to the popu- lar ROUGE metric in this work, ROUGE-WE. ROUGE is biased towards identifying lexical sim- ilarity when assessing the quality of a generated summary. We improve on this by incorporat- ing the use of word embeddings. This enhance- ment allows us to go beyond surface lexicographic matches, and capture instead the semantic similar- ities between words used in a generated summary and a human-written model summary. Experi- menting on the TAC AESOP dataset, we show that this proposal exhibits very good correlations with human assessments, measured with the Spear- man and Kendall rank coefficients. In particular, ROUGE-WE-1 outperforms leading state-of-the- art systems consistently.</p><p>Looking ahead, we want to continue building on this work. One area to improve on is the use of a more inclusive evaluation dataset. The AE- SOP summaries that we have used in our experi- ments are drawn from systems participating in the TAC summarization task, where there is a strong exhibited bias towards extractive summarizers. It will be helpful to enlarge this set of summaries to include output from summarizers which carry out substantial paraphrasing ( <ref type="bibr" target="#b6">Li et al., 2013;</ref><ref type="bibr" target="#b13">Ng et al., 2014;</ref><ref type="bibr" target="#b9">Liu et al., 2015)</ref>.</p><p>Another immediate goal is to study the use of better compositional embedding models. The gen- eralization of unigram word embeddings into bi- grams (or phrases), is still an open problem <ref type="bibr" target="#b20">(Yin and Schütze, 2014;</ref><ref type="bibr" target="#b21">Yu et al., 2014)</ref>. A better com- positional embedding model than the one that we adopted in this work should help us improve the results achieved by bigram variants of ROUGE- WE, especially ROUGE-WE-SU4. This is im- portant because earlier works have demonstrated the value of using skip-bigrams for summarization evaluation.</p><p>An effective and accurate automatic evaluation measure will be a big boon to our quest for bet- ter text summarization systems. Word embeddings add a promising dimension to summarization eval- uation, and we hope to expand on the work we have shared to further realize its potential.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Correlation with responsiveness scores, 
measured with Pearson r (P), Spearman ρ (S), and 
Kendall τ (K) coefficients. 

Measure 
P 
S 
K 
ROUGE-WE-1 
0.7846 0.4312 0.3216 
ROUGE-WE-2 
0.7819 0.4141 0.3042 
ROUGE-WE-SU4 0.7931 0.4068 0.3020 
ROUGE-1 
0.7900 0.3914 0.2846 
ROUGE-2 
0.7524 0.3975 0.2925 
ROUGE-SU4 
0.7840 0.3953 0.2925 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Correlation with pyramid scores of 
top systems in AESOP 2011, measured with the 
Spearman ρ (S), and Kendall τ (K) coefficients. 

</table></figure>

			<note place="foot" n="2"> The effectiveness of the learnt mapping is such that we can now compute analogies such as king − man + woman = queen. 3 https://github.com/ng-j-p/rouge-we</note>

			<note place="foot" n="4"> https://drive.google.com/file/d/ 0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp= sharing</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Neural Probabilistic Language Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Janvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Overview of the TAC 2009 Summarization Track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trang</forename><surname>Hoa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Owczarzak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analysis Conference</title>
		<meeting>the Text Analysis Conference</meeting>
		<imprint>
			<publisher>TAC</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">CatolicaSC at TAC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Paulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analysis Conference</title>
		<meeting>the Text Analysis Conference</meeting>
		<imprint>
			<publisher>TAC</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">AutoSummENG and MeMoG in Evaluating Guided Summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Giannakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vangelis</forename><surname>Karkaletsis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analysis Conference</title>
		<meeting>the Text Analysis Conference</meeting>
		<imprint>
			<publisher>TAC</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluating DUC 2005 using Basic Elements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Document Understanding Conference (DUC)</title>
		<meeting>the Document Understanding Conference (DUC)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using Unsupervised System with Least Linguistic Features for TAC-AESOP Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niraj</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kannan</forename><surname>Srinathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analysis Conference</title>
		<meeting>the Text Analysis Conference</meeting>
		<imprint>
			<publisher>TAC</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Document Summarization via Guided Sentence Compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuliang</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="490" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Looking for a Few Good Metrics: ROUGE and its Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes of the 4th NTCIR Workshop Meeting</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ROUGE: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL-04 Workshop</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Toward Abstractive Summarization Using Semantic Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Sadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1077" to="1086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual Conference on Neural Information Processing Systems (NIPS)</title>
		<meeting>the 27th Annual Conference on Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Linguistic Regularities in Continuous Space Word Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Vector-based Models of Semantic Composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL)</title>
		<meeting>the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="236" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploiting Timelines to Enhance Multidocument Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Ping</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="923" to="933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An Introduction to DUC 2004 Intrinsic Evaluation of Generic New Text Summarization Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Over</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Document Understanding Conference (DUC)</title>
		<meeting>the Document Understanding Conference (DUC)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Overview of the TAC 2011 Summarization Track: Guided Task and AESOP Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analysis Conference</title>
		<meeting>the Text Analysis Conference</meeting>
		<imprint>
			<publisher>TAC</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Overview of the TAC 2010 Summarization Track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analysis Conference</title>
		<meeting>the Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Applying the Pyramid Method in DUC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rebecca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sigelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Document Understanding Conference (DUC)</title>
		<meeting>the Document Understanding Conference (DUC)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automated Pyramid Scoring of Summaries using Distributional Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rebecca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dolores</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Perin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="143" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Evaluation Measures for Text Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Ježek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing and Informatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="275" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An Exploration of Embeddings for Generalized Phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2014 Student Research Workshop</title>
		<meeting>the ACL 2014 Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="41" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Factor-based Compositional Embedding Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS 2014 Deep Learning and Representation Learning Workshop</title>
		<meeting>the NIPS 2014 Deep Learning and Representation Learning Workshop</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
