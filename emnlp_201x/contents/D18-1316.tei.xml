<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generating Natural Language Adversarial Examples</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018. 2890</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustafa</forename><surname>Alzantot</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles (UCLA)</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Sharma</surname></persName>
							<email>sharma2@cooper.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Cooper Union</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Elgohary</surname></persName>
							<email>elgohary@cs.umd.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-Jhang</forename><surname>Ho</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles (UCLA)</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mani</forename><forename type="middle">B</forename><surname>Srivastava</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles (UCLA)</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles (UCLA)</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Generating Natural Language Adversarial Examples</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2890" to="2896"/>
							<date type="published">October 31-November 4, 2018. 2018. 2890</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Deep neural networks (DNNs) are vulnerable to adversarial examples, perturbations to correctly classified examples which can cause the model to misclassify. In the image domain , these perturbations are often virtually indistinguishable to human perception, causing humans and state-of-the-art models to disagree. However, in the natural language domain , small perturbations are clearly perceptible , and the replacement of a single word can drastically alter the semantics of the document. Given these challenges, we use a black-box population-based optimization algorithm to generate semantically and syntactically similar adversarial examples that fool well-trained sentiment analysis and textual en-tailment models with success rates of 97% and 70%, respectively. We additionally demonstrate that 92.3% of the successful sentiment analysis adversarial examples are classified to their original label by 20 human annotators, and that the examples are perceptibly quite similar. Finally, we discuss an attempt to use adversarial training as a defense, but fail to yield improvement, demonstrating the strength and diversity of our adversarial examples. We hope our findings encourage researchers to pursue improving the robustness of DNNs in the natural language domain.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent research has found that deep neural net- works (DNNs) are vulnerable to adversarial ex- amples ( <ref type="bibr" target="#b10">Goodfellow et al., 2015;</ref><ref type="bibr">Szegedy et al., 2014</ref>). The existence of adversarial examples has been shown in image classification ( <ref type="bibr">Szegedy et al., 2014</ref>) and speech recognition <ref type="bibr" target="#b4">(Carlini and Wagner, 2018)</ref>. In this work, we demonstrate that adversarial examples can be constructed in the context of natural language. Using a black-box * Moustafa Alzantot and Yash Sharma contribute equally to this <ref type="bibr">work.</ref> population-based optimization algorithm, we suc- cessfully generate both semantically and syntac- tically similar adversarial examples against mod- els trained on both the IMDB ( <ref type="bibr" target="#b15">Maas et al., 2011</ref>) sentiment analysis task and the Stanford Natural Language Inference (SNLI) <ref type="bibr" target="#b2">(Bowman et al., 2015)</ref> textual entailment task. In addition, we validate that the examples are both correctly classified by human evaluators and similar to the original via a human study. Finally, we attempt to defend against said adversarial attack using adversarial training, but fail to yield any robustness, demon- strating the strength and diversity of the generated adversarial examples.</p><p>Our results show that by minimizing the seman- tic and syntactic dissimilarity, an attacker can per- turb examples such that humans correctly classify, but high-performing models misclassify. We are open-sourcing our attack 1 to encourage research in training DNNs robust to adversarial attacks in the natural language domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Natural Language Adversarial Examples</head><p>Adversarial examples have been explored primar- ily in the image recognition domain. Exam- ples have been generated through solving an op- timization problem, attempting to induce misclas- sification while minimizing the perceptual distor- tion ( <ref type="bibr">Szegedy et al., 2014;</ref><ref type="bibr" target="#b3">Carlini and Wagner, 2017;</ref>. Due to the computational cost of such approaches, fast methods were introduced which, either in one- step or iteratively, shift all pixels simultaneously until a distortion constraint is reached <ref type="bibr" target="#b10">(Goodfellow et al., 2015;</ref><ref type="bibr" target="#b14">Kurakin et al., 2017;</ref><ref type="bibr" target="#b16">Madry et al., 2018)</ref>. Nearly all popular methods are gradient- based.</p><p>Such methods, however, rely on the fact that adding small perturbations to many pixels in the image will not have a noticeable effect on a human viewer. This approach obviously does not transfer to the natural language domain, as all changes are perceptible. Furthermore, unlike continuous im- age pixel values, words in a sentence are discrete tokens. Therefore, it is not possible to compute the gradient of the network loss function with respect to the input words. A straightforward workaround is to project input sentences into a continuous space (e.g. word embeddings) and consider this as the model input. However, this approach also fails because it still assumes that replacing every word with words nearby in the embedding space will not be noticeable. Replacing words without account- ing for syntactic coherence will certainly lead to improperly constructed sentences which will look odd to the reader.</p><p>Relative to the image domain, little work has been pursued for generating natural language ad- versarial examples. Given the difficulty in gener- ating semantics-preserving perturbations, distract- ing sentences have been added to the input docu- ment in order to induce misclassification <ref type="bibr" target="#b12">(Jia and Liang, 2017)</ref>. In our work, we attempt to gener- ate semantically and syntactically similar adver- sarial examples, via word replacements, resolv- ing the aforementioned issues. Minimizing the number of word replacements necessary to in- duce misclassification has been studied in previ- ous work <ref type="bibr" target="#b19">(Papernot et al., 2016)</ref>, however with- out consideration given to semantics or syntactics, yielding incoherent generated examples. In recent work, there have been a few attempts at generat- ing adversarial examples for language tasks by us- ing back-translation ( <ref type="bibr" target="#b11">Iyyer et al., 2018)</ref>, exploit- ing machine-generated rules ( <ref type="bibr" target="#b22">Ribeiro et al., 2018)</ref>, and searching in underlying semantic space ( <ref type="bibr">Zhao et al., 2018)</ref>. In addition, while preparing our sub- mission, we became aware of recent work which target a similar contribution ( <ref type="bibr" target="#b13">Kuleshov et al., 2018;</ref><ref type="bibr" target="#b9">Ebrahimi et al., 2018)</ref>. We treat these con- tributions as parallel work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Attack Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Threat model</head><p>We assume the attacker has black-box access to the target model; the attacker is not aware of the model architecture, parameters, or training data, and is only capable of querying the target model with supplied inputs and obtaining the output pre- dictions and their confidence scores. This set- ting has been extensively studied in the image do- main ( <ref type="bibr" target="#b20">Papernot et al., 2017;</ref><ref type="bibr" target="#b7">Chen et al., 2017a;</ref><ref type="bibr" target="#b0">Alzantot et al., 2018)</ref>, but has yet to be explored in the context of natural language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Algorithm</head><p>To avoid the limitations of gradient-based attack methods, we design an algorithm for constructing adversarial examples with the following goals in mind. We aim to minimize the number of modified words between the original and adversarial exam- ples, but only perform modifications which retain semantic similarity with the original and syntactic coherence. To achieve these goals, instead of rely- ing on gradient-based optimization, we developed an attack algorithm that exploits population-based gradient-free optimization via genetic algorithms.</p><p>An added benefit of using gradient-free opti- mization is enabling use in the black-box case; gradient-reliant algorithms are inapplicable in this case, as they are dependent on the model being dif- ferentiable and the internals being accessible <ref type="bibr" target="#b19">(Papernot et al., 2016;</ref><ref type="bibr" target="#b9">Ebrahimi et al., 2018)</ref>.</p><p>Genetic algorithms are inspired by the process of natural selection, iteratively evolving a popu- lation of candidate solutions towards better solu- tions. The population of each iteration is a called a generation. In each generation, the quality of pop- ulation members is evaluated using a fitness func- tion. "Fitter" solutions are more likely to be se- lected for breeding the next generation. The next generation is generated through a combination of crossover and mutation. Crossover is the pro- cess of taking more than one parent solution and producing a child solution from them; it is anal- ogous to reproduction and biological crossover. Mutation is done in order to increase the diver- sity of population members and provide better ex- ploration of the search space. Genetic algorithms are known to perform well in solving combina- torial optimization problems <ref type="bibr" target="#b1">(Anderson and Ferris, 1994;</ref><ref type="bibr" target="#b18">Mühlenbein, 1989)</ref>, and due to employ- ing a population of candidate solutions, these al- gorithms can find successful adversarial examples with fewer modifications.</p><p>Perturb Subroutine: In order to explain our algorithm, we first introduce the subroutine Perturb. This subroutine accepts an input sen- tence x cur which can be either a modified sentence or the same as x orig . It randomly selects a word w in the sentence x cur and then selects a suitable re- placement word that has similar semantic mean- ing, fits within the surrounding context, and in- creases the target label prediction score. In order to select the best replacement word, Perturb applies the following steps:</p><p>• Computes the N nearest neighbors of the se- lected word according to the distance in the GloVe embedding space ( <ref type="bibr" target="#b21">Pennington et al., 2014</ref>). We used euclidean distance, as we did not see noticeable improvement using cosine. We filter out candidates with dis- tance to the selected word greater than δ.</p><p>We use the counter-fitting method presented in <ref type="bibr" target="#b17">(Mrkši´Mrkši´c et al., 2016</ref>) to post-process the adversary's GloVe vectors to ensure that the nearest neighbors are synonyms. The result- ing embedding is independent of the embed- dings used by victim models.</p><p>• Second, we use the Google 1 billion words language model ( <ref type="bibr" target="#b5">Chelba et al., 2013</ref>) to fil- ter out words that do not fit within the context surrounding the word w in x cur . We do so by ranking the candidate words based on their language model scores when fit within the re- placement context, and keeping only the top K words with the highest scores.</p><p>• From the remaining set of words, we pick the one that will maximize the target label pre- diction probability when it replaces the word w in x cur .</p><p>• Finally, the selected word is inserted in place of w, and Perturb returns the resulting sen- tence. The selection of which word to replace in the input sentence is done by random sampling with probabilities proportional to the number of neigh- bors each word has within Euclidean distance δ in the counter-fitted embedding space, encouraging the solution set to be large enough for the algo- rithm to make appropriate modifications. We ex- clude common articles and prepositions (e.g. a, to) from being selected for replacement.</p><p>Optimization Procedure: The optimization al- gorithm can be seen in Algorithm 1. The algo- rithm starts by creating the initial generation P 0 of size S by calling the Perturb subroutine S times to create a set of distinct modifications to the orig- inal sentence. Then, the fitness of each popula- tion member in the current generation is computed as the target label prediction probability, found by Algorithm 1 Finding adversarial examples for i = 1, ..., S in population do P 0 i ← Perturb(x orig , target) for g = 1, 2...G generations do for i = 1, ..., S in population do</p><formula xml:id="formula_0">F g−1 i = f (P g−1 i ) target x adv = P g−1 arg max j F g−1 j if arg max c f (x adv ) c == t then return x adv {Found successful attack} else P g 1 = {x adv } p = N ormalize(F g−1 ) for i = 2, ..</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>., S in population do</head><p>Sample parent 1 from P g−1 with probs p Sample parent 2 from P g−1 with probs p child = Crossover(parent 1 , parent 2 ) child mut = Perturb(child, target)</p><formula xml:id="formula_1">P g i = {child mut }</formula><p>querying the victim model function f . If a pop- ulation member's predicted label is equal to the target label, the optimization is complete. Other- wise, pairs of population members from the cur- rent generation are randomly sampled with prob- ability proportional to their fitness values. A new child sentence is then synthesized from a pair of parent sentences by independently sampling from the two using a uniform distribution. Finally, the Perturb subroutine is applied to the resulting children.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>To evaluate our attack method, we trained models for the sentiment analysis and textual entailment classification tasks. For both models, each word in the input sentence is first projected into a fixed 300-dimensional vector space using GloVe <ref type="bibr" target="#b21">(Pennington et al., 2014</ref>). Each of the models used are based on popular open-source benchmarks, and can be found in the following repositories <ref type="bibr">23</ref> . Model descriptions are given below. Sentiment Analysis: We trained a sentiment analysis model using the IMDB dataset of movie reviews <ref type="bibr" target="#b15">(Maas et al., 2011</ref>). The IMDB dataset consists of 25,000 training examples and 25,000 test examples. The LSTM model is composed of 128 units, and the outputs across all time steps are Original Text Prediction = Negative. (Confidence = 78.0%) This movie had terrible acting, terrible plot, and terrible choice of actors. (Leslie Nielsen ...come on!!!) the one part I considered slightly funny was the battling FBI/CIA agents, but because the audience was mainly kids they didn't understand that theme. Adversarial Text Prediction = Positive. (Confidence = 59.8%) This movie had horrific acting, horrific plot, and horrifying choice of actors. (Leslie Nielsen ...come on!!!) the one part I regarded slightly funny was the battling FBI/CIA agents, but because the audience was mainly youngsters they didn't understand that theme. <ref type="table">Table 1</ref>: Example of attack results for the sentiment analysis task. Modified words are highlighted in green and red for the original and adversarial texts, respectively.</p><p>Original Text Prediction: Entailment (Confidence = 86%) Premise: A runner wearing purple strives for the finish line. Hypothesis: A runner wants to head for the finish line. Adversarial Text Prediction: Contradiction (Confidence = 43%) Premise: A runner wearing purple strives for the finish line. Hypothesis: A racer wants to head for the finish line.  averaged and fed to the output layer. The test accu- racy of the model is 90%, which is relatively close to the state-of-the-art results on this dataset. Textual Entailment: We trained a textual en- tailment model using the Stanford Natural Lan- guage Inference (SNLI) corpus <ref type="bibr" target="#b2">(Bowman et al., 2015)</ref>. The model passes the input through a ReLU "translation" layer ( <ref type="bibr" target="#b2">Bowman et al., 2015)</ref>, which encodes the premise and hypothesis sen- tences by performing a summation over the word embeddings, concatenates the two sentence em- beddings, and finally passes the output through 3 600-dimensional ReLU layers before feeding it to a 3-way softmax. The model predicts whether the premise sentence entails, contradicts or is neutral to the hypothesis sentence. The test accuracy of the model is 83% which is also relatively close to the state-of-the-art ( <ref type="bibr" target="#b8">Chen et al., 2017b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Attack Evaluation Results</head><p>We randomly sampled 1000, and 500 correctly classified examples from the test sets of the two tasks to evaluate our algorithm. Correctly classi- fied examples were chosen to limit the accuracy levels of the victim models from confounding our results. For the sentiment analysis task, the at- tacker aims to divert the prediction result from positive to negative, and vice versa. For the tex- tual entailment task, the attacker is only allowed to modify the hypothesis, and aims to divert the prediction result from 'entailment' to 'contradic- tion', and vice versa. We limit the attacker to maximum G = 20 iterations, and fix the hyper- parameter values to S = 60, N = 8, K = 4, and δ = 0.5. We also fixed the maximum percentage of allowed changes to the document to be 20% and 25% for the two tasks, respectively. If increased, the success rate would increase but the mean qual- ity would decrease. If the attack does not succeed within the iterations limit or exceeds the specified threshold, it is counted as a failure.</p><p>Sample outputs produced by our attack are shown in <ref type="table" target="#tab_0">Tables 1 and 2</ref>. Additional outputs can be found in the supplementary material. <ref type="table" target="#tab_1">Table 3</ref> shows the attack success rate and mean percent- age of modified words on each task. We compare to the Perturb baseline, which greedily applies the Perturb subroutine, to validate the use of population-based optimization. As can be seen from our results, we are able to achieve high suc- cess rate with a limited number of modifications on both tasks. In addition, the genetic algorithm significantly outperformed the Perturb baseline in both success rate and percentage of words mod- ified, demonstrating the additional benefit yielded by using population-based optimization. Testing using a single TitanX GPU, for sentiment analy- sis and textual entailment, we measured average runtimes on success to be 43.5 and 5 seconds per example, respectively. The high success rate and reasonable runtimes demonstrate the practicality of our approach, even when scaling to long sen- tences, such as those found in the IMDB dataset.</p><p>Speaking of which, our success rate on textual entailment is lower due to the large disparity in sentence length. On average, hypothesis sentences in the SNLI corpus are 9 words long, which is very short compared to IMDB (229 words, lim- ited to 100 for experiments). With sentences that short, applying successful perturbations becomes much harder, however we were still able to achieve a success rate of 70%. For the same reason, we didn't apply the Perturb baseline on the textual entailment task, as the Perturb baseline fails to achieve any success under the limits of the maxi- mum allowed changes constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">User study</head><p>We performed a user study on the sentiment anal- ysis task with 20 volunteers to evaluate how per- ceptible our adversarial perturbations are. Note that the number of participating volunteers is sig- nificantly larger than used in previous studies <ref type="bibr" target="#b12">(Jia and Liang, 2017;</ref><ref type="bibr" target="#b9">Ebrahimi et al., 2018</ref>). The user study was composed of two parts. First, we pre- sented 100 adversarial examples to the participants and asked them to label the sentiment of the text (i.e., positive or negative.) 92.3% of the responses matched the original text sentiment, indicating that our modification did not significantly affect human judgment on the text sentiment. Second, we pre- pared 100 questions, each question includes the original example and the corresponding adversar- ial example in a pair. Participants were asked to judge the similarity of each pair on a scale from 1 (very similar) to 4 (very different). The average rating is 2.23 ± 0.25, which shows the perceived difference is also small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Adversarial Training</head><p>The results demonstrated in section 4.1 raise the following question: How can we defend against these attacks? We performed a preliminary exper- iment to see if adversarial training <ref type="bibr" target="#b16">(Madry et al., 2018)</ref>, the only effective defense in the image do- main, can be used to lower the attack success rate. We generated 1000 adversarial examples on the cleanly trained sentiment analysis model using the IMDB training set, appended them to the existing training set, and used the updated dataset to ad- versarially train a model from scratch. We found that adversarial training provided no additional ro- bustness benefit in our experiments using the test set, despite the fact that the model achieves near 100% accuracy classifying adversarial examples included in the training set. These results demon- strate the diversity in the perturbations generated by our attack algorithm, and illustrates the diffi- culty in defending against adversarial attacks. We hope these results inspire further work in increas- ing the robustness of natural language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We demonstrate that despite the difficulties in gen- erating imperceptible adversarial examples in the natural language domain, semantically and syntac- tically similar adversarial examples can be crafted using a black-box population-based optimization algorithm, yielding success on both the sentiment analysis and textual entailment tasks. Our human study validated that the generated examples were indeed adversarial and perceptibly quite similar. We hope our work encourages researchers to pur- sue improving the robustness of DNNs in the nat- ural language domain.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Example of attack results for the textual entailment task. Modified words are highlighted in green and red for the original and adversarial texts, respectively.</figDesc><table>Sentiment Analysis 
Textual Entailment 
% success % modified 
% success % modified 
Perturb baseline 
52% 
19% 
-
-
Genetic attack 
97% 
14.7% 
70% 
23% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Comparison between the attack success rate and mean percentage of modifications required by the genetic attack and perturb baseline for the two tasks.</figDesc><table></table></figure>

			<note place="foot" n="1"> https://github.com/nesl/nlp_ adversarial_examples</note>

			<note place="foot" n="2"> https://github.com/keras-team/keras/ blob/master/examples/imdb_lstm.py 3 https://github.com/Smerity/keras_ snli/blob/master/snli_rnn.py</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This research was supported in part by the U.S. Army Research Laboratory and the UK Ministry of Defence under Agreement Number W911NF-16-3-0001, the National Science Foundation under award # CNS-1705135, OAC-1640813, and IIS-1760523, and the NIH Center of Excellence for Mobile Sensor Data-to-Knowledge (MD2K) un-der award 1-U54EB020404-01. Ahmed Elgohary is funded by an IBM PhD Fellowship. Any find-ings in this material are those of the author(s) and do not reflect the views of any of the above fund-ing agencies. The U.S. and U.K. Governments are authorized to reproduce and distribute reprints for Government purposes notwithstanding any copy-right notation hereon.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Genattack: Practical black-box attacks with gradient-free optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustafa</forename><surname>Alzantot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Supriyo</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mani</forename><surname>Srivastava</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11090</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Genetic algorithms for combinatorial optimization: the assemble line balancing problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael C</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ferris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ORSA Journal on Computing</title>
		<imprint>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.04644</idno>
		<title level="m">Towards evaluating the robustness of neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Audio adversarial examples: Targeted attacks on speech-totext</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems: Deep Learning and Security Workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">One billion word benchmark for measuring progress in statistical language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciprian</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.3005</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>Thorsten Brants, Phillipp Koehn, and Tony Robinson</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">EAD: Elastic-net attacks to deep neural networks via adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Workshop on Artificial Intelligence and Security</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Enhanced lstm for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">HotFlip: White-box adversarial examples for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javid</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anyi</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejing</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adversarial example generation with syntactically controlled paraphrase networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adversarial examples for natural language classification problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Kuleshov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shantanu</forename><surname>Thakoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingfung</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02697</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adversarial machine learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning word vectors for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">E</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics: Human Language Technologies</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Counter-fitting word vectors to linguistic constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Diarmuid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Parallel genetic algorithms, population genetics and combinatorial optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinz</forename><surname>Mühlenbein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Parallel Processing: Logic, Organization, and Technology</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Crafting adversarial input sequences for recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Harang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.08275</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Practical black-box attacks against machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananthram</forename><surname>Berkay Celik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM on Asia Conference on Computer and Communications Security</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semantically equivalent adversarial rules for debugging nlp models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Marco Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Attacking the madry defense model with l1-based adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations: Workshops</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
