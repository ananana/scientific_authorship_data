<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Term Translation for Document-informed Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fandong</forename><surname>Meng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Intelligent Information Processing Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
							<email>dyxiong@suda.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Intelligent Information Processing Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Intelligent Information Processing Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Centre for Next Generation Localisation, Dublin City University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Term Translation for Document-informed Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="546" to="556"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Term translation is of great importance for statistical machine translation (SMT), especially document-informed SMT. In this paper, we investigate three issues of term translation in the context of document-informed SMT and propose three corresponding models: (a) a term translation disambiguation model which selects desirable translations for terms in the source language with domain information, (b) a term translation consistency model that encourages consistent translations for terms with a high strength of translation consistency throughout a document, and (c) a term bracketing model that rewards translation hypotheses where bracketable source terms are translated as a whole unit. We integrate the three models into hierarchical phrase-based SMT and evaluate their effectiveness on NIST Chinese-English translation tasks with large-scale training data. Experiment results show that all three models can achieve significant improvements over the baseline. Additionally, we can obtain a further improvement when combining the three models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A term is a linguistic expression that is used as the designation of a defined concept in a language <ref type="bibr">(ISO 1087)</ref>. As terms convey concepts of a text, term translation becomes crucial when the text is translated from its original language to another language. The translations of terms are often af- fected by the domain in which terms are used and the context that surrounds terms ( <ref type="bibr" target="#b28">Vasconcellos et al., 2001)</ref>. In this paper, we study domain-specific and context-sensitive term translation for SMT.</p><p>In order to achieve this goal, we focus on three issues of term translation: 1) translation ambigu- ity, 2) translation consistency and 3) bracketing. First, term translation ambiguity is related to trans- lations of the same term in different domains. A source language term may have different transla- tions when it occurs in different domains. Second, translation consistency is about consistent trans- lations for terms that occur in the same document. Usually, it is undesirable to translate the same term in different ways as it occurs in different parts of a document. Finally, bracketing concerns whether a multi-word term is bracketable during transla- tion. Normally, a multi-word term is translated as a whole unit into a contiguous target string.</p><p>We study these three issues in the context of document-informed SMT. We use document- informed information to disambiguate term trans- lations in different documents and maintain con- sistent translations for terms that occur in the same document. We propose three different models for term translation that attempt to address the three issues mentioned above. In particular,</p><p>• Term Translation Disambiguation Model: In this model, we condition the translations of terms in different documents on correspond- ing per-document topic distributions. In do- ing so, we enable the decoder to favor trans- lation hypotheses with domain-specific term translations.</p><p>• Term Translation Consistency Model: This model encourages the same terms with a high strength of translation consistency that occur in different parts of a document to be trans- lated in a consistent fashion. We calculate the translation consistency strength of a term based on the topic distribution of the docu- ments where the term occurs in this model.</p><p>• Term Bracketing Model: We use the brack- eting model to reward translation hypothe-ses where bracketable multi-word terms are translated as a whole unit.</p><p>We integrate the three models into hierarchical phrase-based SMT <ref type="bibr" target="#b2">(Chiang, 2007)</ref>. Large-scale experiment results show that they are all able to achieve significant improvements of up to 0.89 BLEU points over the baseline. When simulta- neously integrating the three models into SMT, we can gain a further improvement, which outper- forms the baseline by up to <ref type="bibr">1.16 BLEU points.</ref> In the remainder of this paper, we begin with a brief overview of related work in Section 2, and bilingual term extraction in Section 3. We then elaborate the proposed three models for term translation in Section 4. Next, we conduct experi- ments to validate the effectiveness of the proposed models in Section 5. Finally, we conclude and pro- vide directions for future work in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section, we briefly introduce related work and highlight the differences between our work and previous studies.</p><p>As we approach term translation disambigua- tion and consistency via topic modeling, our mod- els are related to previous work that explores the topic model ( <ref type="bibr" target="#b0">Blei et al., 2003</ref>) for machine trans- lation ( <ref type="bibr" target="#b36">Zhao and Xing, 2006;</ref><ref type="bibr" target="#b25">Su et al., 2012;</ref><ref type="bibr" target="#b31">Xiao et al., 2012;</ref><ref type="bibr" target="#b5">Eidelman et al., 2012)</ref>. <ref type="bibr" target="#b36">Zhao and Xing (2006)</ref> employ three models that enable word alignment process to leverage topical con- tents of document-pairs with topic model. <ref type="bibr" target="#b25">Su et al. (2012)</ref> establish the relationship between out-of- domain bilingual corpus and in-domain monolin- gual corpora via topic mapping and phrase-topic distribution probability estimation for translation model adaptation. <ref type="bibr" target="#b31">Xiao et al. (2012)</ref> propose a topic similarity model for rule selection. <ref type="bibr" target="#b5">Eidelman et al. (2012)</ref> use topic models to adapt lexical weighting probabilities dynamically during trans- lation. In these studies, the topic model is not used to address the issues of term translation mentioned in Section 1.</p><p>Our work is also related to document-level SMT in that we use document-informed informa- tion for term translation. <ref type="bibr" target="#b26">Tiedemann (2010)</ref> pro- pose cache-based language and translation mod- els, which are built on recently translated sen- tences. <ref type="bibr" target="#b8">Gong et al. (2011)</ref> extend this by further introducing two additional caches. They employ a static cache to store bilingual phrases extracted from documents in training data that are similar to the document being translated and a topic cache with target language topic words. Recently we have also witnessed efforts that model lexical co- hesion ( <ref type="bibr" target="#b10">Hardmeier et al., 2012;</ref><ref type="bibr" target="#b30">Wong and Kit, 2012;</ref><ref type="bibr" target="#b34">Xiong et al., 2013a;</ref><ref type="bibr" target="#b35">Xiong et al., 2013b)</ref> as well as coherence <ref type="bibr" target="#b32">(Xiong and Zhang, 2013)</ref> for document-level SMT. <ref type="bibr" target="#b11">Hasler et al. (2014a)</ref> use topic models to learn document-level transla- tion probabilities. <ref type="bibr" target="#b12">Hasler et al. (2014b)</ref> use topic- adapted model to improve lexical selection. The significant difference between our work and these studies is that term translation has not been inves- tigated in these document-level SMT models. <ref type="bibr" target="#b14">Itagaki and Aikawa (2008)</ref> employ bilingual term bank as a dictionary for machine-aided trans- lation. <ref type="bibr" target="#b23">Ren et al. (2009)</ref> propose a binary feature to indicate whether a bilingual phrase contains a term pair. <ref type="bibr" target="#b22">Pinis and Skadins (2012)</ref> investigate that bilingual terms are important for domain adapta- tion of machine translation. These studies do not focus on the three issues of term translation as discussed in Section 1. Furthermore, domain and document-informed information is not used to as- sist term translation. <ref type="bibr" target="#b15">Itagaki et al. (2007)</ref> propose a statistical method to calculate translation consistency for terms with explicit domain information. Partially inspired by their study, we introduce a term translation consistency metric with document-informed infor- mation. Furthermore, we integrate the proposed term translation consistency model into an actual SMT system, which has not been done by <ref type="bibr" target="#b15">Itagaki et al. (2007)</ref>. <ref type="bibr" target="#b27">Ture et al. (2012)</ref> use IR-inspired tf-idf scores to encourage consistent translation choice. <ref type="bibr" target="#b9">Guillou (2013)</ref> investigates what kind of words should be translated consistently. Term translation consistency has not been investigated in these studies.</p><p>Our term bracketing model is also related to <ref type="bibr" target="#b33">Xiong et al. (2009)</ref>'s syntax-driven bracket- ing model for phrase-based translation, which pre- dicts whether a phrase is bracketable or not using rich syntactic constraints. The difference is that we construct the model with automatically created bilingual term bank and do not depend on any syn- tactic knowledge. tending a bilingual term bank, which in turn can be used to improve other tasks such as information retrieval and machine translation. In this paper, we want to automatically build a bilingual term bank so that we can model term translation to improve translation quality of SMT. Our interest is to ex- tract multi-word terms.</p><p>Currently, there are mainly two strategies to conduct bilingual term extraction from parallel corpora. One of them is to extract term candi- dates separately for each language according to monolingual term metrics, such as C-value/NC- value ( <ref type="bibr" target="#b7">Frantzi et al., 1998;</ref><ref type="bibr" target="#b29">Vu et al., 2008)</ref>, or other common cooccurrence measures such as Log-Likelihood Ratio, Dice coefficient and Point- wise Mutual Information <ref type="bibr" target="#b4">(Daille, 1996;</ref><ref type="bibr" target="#b21">Piao et al., 2006</ref>). The extracted monolingual terms are then paired together <ref type="bibr" target="#b13">(Hjelm, 2007;</ref><ref type="bibr" target="#b6">Fan et al., 2009;</ref><ref type="bibr" target="#b23">Ren et al., 2009</ref>). The other strategy is to align words and word sequences that are transla- tion equivalents in parallel corpora and then clas- sify them into terms and non-terms ( <ref type="bibr" target="#b18">Merkel and Foo, 2007;</ref><ref type="bibr" target="#b17">Lefever et al., 2009;</ref><ref type="bibr" target="#b1">Bouamor et al., 2012)</ref>. In this paper, we adopt the first strategy. In particular, for each sentence pair, we collect all source phrases which are terms and find aligned target phrases for them via word alignments. If the target side is also a term, we store the source and target term as a term pair.</p><p>We conduct monolingual term extraction using the C-value/NC-value metric and Log-Likelihood Ratio (LLR) measure respectively. We then com- bine terms extracted according to the two metrics mentioned above. For the C-value/NC-value met- ric based term extraction, we implement it in the same way as described in <ref type="bibr" target="#b7">Frantzi et al. (1998)</ref>. This extraction method recognizes linguistic pat- terns (mainly noun phrases) listed as follows.</p><formula xml:id="formula_0">((Adj|N oun) + |((Adj|N oun) * (N ounP rep) ? )(Adj|N oun) * )N oun</formula><p>It captures the linguistic structures of terms. For the LLR metric based term extraction, we imple- ment it according to <ref type="bibr" target="#b4">Daille (1996)</ref>, who estimate the propensity of two words to appear together as a multi-word expression. We then adopt LLR-based hierarchical reducing algorithm proposed by <ref type="bibr" target="#b23">Ren et al. (2009)</ref> to extract terms with arbitrary lengths. Since the C-value/NC-value metric based extrac- tion method can obtain terms in strict linguistic patterns while the LLR measure based method ex- tracts more flexible terms, these two methods are complementary to each other. Therefore, we use these two methods to extract monolingual multi- word terms and then combine the extracted terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Models</head><p>This section presents the three models of term translation. They are the term translation dis- ambiguation model, term translation consistency model and term bracketing model respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Term Translation Disambiguation Model</head><p>The most straightforward way to disambiguate term translations in different domains is to cal- culate the conditional translation probability of a term given domain information. We use the topic distribution of a document obtained by a topic model to represent the domain information of the document. Since Latent Dirichlet Alloca- tion (LDA) ( <ref type="bibr" target="#b0">Blei et al., 2003</ref>) is the most widely- used topic model, we exploit it for inferring topic distributions of documents. <ref type="bibr" target="#b31">Xiao et al. (2012)</ref> proposed a topic similarity model for rule selec- tion. Different from their work, we take an eas- ier strategy that estimates topic-conditioned term translation probabilities rather than rule-topic dis- tributions. This makes our model easily scalable on large training data.</p><p>With the bilingual term bank created from the training data, we calculate the source-to-target term translation probability for each term pair con- ditioned on the topic distribution of the source document where the source term occurs. We main- tain a K-dimension (K is the number of topics) vector for each term pair. The k-th component p(t e |t f , z = k) measures the conditional transla- tion probability from source term t f to target term t e given the topic k.</p><p>We calculate p(t e |t f , z = k) via maximum likelihood estimation with counts from training data. When the source part of a bilingual term pair occurs in a document D with topic distribu- tion p(z|D) estimated via LDA tool, we collect an instance (t f , t e , p(z|D), c), where c is the frac- tion count of the instance as described in <ref type="bibr" target="#b2">Chiang (2007)</ref>. After collection, we get a set of instances I = {(t f , t e , p(z|D), c)} with different document- topic distributions for each bilingual term pair. Us- ing these instances, we calculate the probability p(t e |t f , z = k) as follows:</p><formula xml:id="formula_1">p(t e |t f , z = k) = i∈I,i.t f =t f ,i.te=te i.c * p(z = k|D) i∈I,i.t f =t f i.c * p(z = k|D)<label>(1)</label></formula><p>We associate each extracted term pair in our bilingual term bank with its corresponding topic- conditioned translation probabilities estimated in the Eq. (1). When translating sentences of docu- ment D , we first get the topic distribution of D using LDA tool. Given a sentence which contains T terms {t f i } T 1 in D , our term translation disam- biguation model T ermDis can be denoted as</p><formula xml:id="formula_2">T ermDis = T i=1 P d (t e i |t f i , D )<label>(2)</label></formula><p>where the conditional source-to-target term trans- lation probability</p><formula xml:id="formula_3">P d (t e i |t f i , D ) given the docu- ment D</formula><p>is formulated as follows:</p><formula xml:id="formula_4">P d (t e i |t f i , D ) = K k=1 p(t e i |t f i , z = k) * p(z = k|D )<label>(3)</label></formula><p>Whenever a source term t f i is translated into t e i , we check whether the pair of t f i and its translation t e i can be found in our bilingual term bank. If it can be found, we calculate the conditional transla- tion probability from t f i to t e i given the document D according to Eq. (3).</p><p>The term translation disambiguation model is integrated into the log-linear model of SMT as a feature. Its weight is tuned via minimum error rate training (MERT) <ref type="bibr" target="#b20">(Och, 2003)</ref>. Through the fea- ture, we can enable the decoder to favor translation hypotheses that contain target term translations ap- propriate for the domain represented by the topic distribution of the corresponding document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Term Translation Consistency Model</head><p>The term translation disambiguation model helps the decoder select appropriate translations for terms that are in accord with their domains. Yet another translation issue related to the domain- specific term translation is to what extent a term should be translated consistently given the domain where it occurs. Term translation consistency in- dicates the translation stability that a source term is translated into the same target term ( <ref type="bibr" target="#b15">Itagaki et al., 2007)</ref>. When translating a source term, if the translation consistency strength of the source term is high, we should take the corresponding target term as the translation for it. Otherwise, we may need to create a new translation for it according to its context. In particular, we want to enable the decoder to choose between: 1) translating a given source term into the extracted corresponding tar- get term or 2) translating it in another way accord- ing to the strength of its translation consistency. In doing so, we can encourage consistent transla- tions for terms with a high translation consistency strength throughout a document.</p><p>Our term translation consistency model can ex- actly measure the strength of term translation con- sistency in a document. Since the essential com- ponent of our term translation consistency model is the translation consistency strength of the source term estimated under the topic distribution, we de- scribe how to calculate it before introducing the whole model.</p><p>With the bilingual term bank created from training data, we first group each source term and all its corresponding target terms into a 2- tuple Gt f , Set(t e ), where t f is the source term and Set(t e ) is the set of t f 's corresponding tar- get terms. We maintain a K-dimension (K is the number of topics) vector for each 2-tuple Gt f , Set(t e ). The k-th component measures the translation consistency strength cons(t f , k) of the source term t f given the topic k.</p><p>We calculate cons(t f , k) for each Gt f , Set(t e ) with counts from training data as follows:</p><formula xml:id="formula_5">cons(t f , k) = M m=1 Nm n=1 ( q mn * p(k|m) Q k ) 2 (4) Q k = M m=1 Nm n=1 q mn * p(k|m) (5)</formula><p>where M is the number of documents in which the source term t f occurs, N m is the number of unique corresponding term translations of t f in the mth document, q mn is the frequency of the nth translation of t f in the mth document, p(k|m) is the conditional probability of the mth document over topic k, and Q k is the normalization factor. All translations of t f are from Set(t e ). We adapt <ref type="bibr" target="#b15">Itagaki et al. (2007)</ref>'s translation consistency met- ric for terms to our topic-based translation consis- tency measure in the Eq. (4). This equation cal- culates the translation consistency strength of the source term t f given the topic k according to the distribution of t f 's translations in each document where they occur. According to Eq. (4), the trans- lation consistency strength is a score between 0 and 1. If a source term only occurs in a document and all its translations are the same, the translation consistency strength of this term is 1. We reorganize our bilingual term bank into a list of 2-tuples Gt f , Set(t e</p><note type="other">)s, each of which is associated with a K-dimension vector storing the topic-conditioned translation consistency strength calculated in the Eq. (4). When translating sen- tences of document D, we first get the topic dis- tribution of D via LDA tool. Given a sentence which contains T terms {t f i } T 1 in D, our term translation consistency model T ermCons can be denoted as</note><formula xml:id="formula_6">T ermCons = T i=1 exp(S c (t f i |D))<label>(6)</label></formula><p>where the strength of translation consistency for t f i given the document D is formulated as fol- lows:</p><formula xml:id="formula_7">S c (t f i |D) = log( K k=1 cons(t f i , k) * p(k|D))<label>(7)</label></formula><p>During decoding, whenever a hypothesis just translates a source term t f i into t e , we check whether the translation t e can be found in Set(t e ) of t f i from the reorganized bilingual term bank. If it can be found, we calculate the strength of trans- lation consistency for t f i given the document D according to Eq. (7) and take it as a soft con- straint. If the S c (t f i |D) of t f i is high, the decoder should translate t f i into the extracted correspond- ing target terms. Otherwise, the decoder will se- lect translations from outside of Set(t e ) for t f i . In doing so, we encourage terms to be translated in a topic-dependent consistency pattern in the test data similar to that in the training data so that we can control the translation consistency of terms in the test data.</p><p>The term translation consistency model is also integrated into the log-linear model of SMT as a feature. Through the feature, we can enable the decoder to translate terms with a high translation consistency in a document into corresponding tar- get terms from our bilingual term bank rather than other translations in a consistent fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Term Bracketing Model</head><p>The term translation disambiguation model and consistency model concern the term translation ac- curacy with domain information. We further pro- pose a term bracketing model to guarantee the in- tegrality of term translation. <ref type="bibr" target="#b33">Xiong et al. (2009)</ref> proposed a syntax-driven bracketing model for phrase-based translation, which predicts whether a phrase is bracketable or not using rich syntac- tic constraints. If a source phrase remains con- tiguous after translation, they refer to this type of phrase as bracketable phrase, otherwise unbrack- etable phrase. For multi-word terms, it is also desirable to be bracketable since a source term should be translated as a whole unit and its trans- lation should be contiguous.</p><p>In this paper, we adapt <ref type="bibr" target="#b33">Xiong et al. (2009)</ref>'s bracketing approach to term translation and build a classifier to measure the probability that a source term should be translated in a bracketable man- ner. For all source parts of the extracted bilingual term bank, we find their target counterparts in the word-aligned training data. If the corresponding target counterpart remains contiguous, we take the source term as a bracketable instance, otherwise an unbracketable instance. With these bracketable and unbracketable instances, we train a maximum entropy binary classifier to predict bracketable (b) probability of a given source term t f within par- ticular contexts c(t f ). The binary classifier is for- mulated as follows:</p><formula xml:id="formula_8">P b (b|c(t f )) = exp( j θ j h j (b, c(t f ))) b exp( j θ j h j (b , c(t f )))<label>(8)</label></formula><p>where h j ∈ {0, 1} is a binary feature function and θ j is the weight of h j . We use the following fea- tures: 1) the word sequence of the source term, 2) the first word of the source term, 3) the last word of the source term, 4) the preceding word of the first word of the source term, 5) the succeeding word of the last word of the source term, and 6) the number of words in the source term. Given a source sentence which contains T terms {t f i } T 1 , our term bracketing model T ermBrack can be denoted as</p><formula xml:id="formula_9">T ermBrack = T i=1 P b (b|c(t f i ))<label>(9)</label></formula><p>Whenever a hypothesis just covers a source term t f i , we calculate the bracketable probability of t f i according to <ref type="bibr">Eq. (8)</ref>. The term bracketing model is integrated into the log-linear model of SMT as a feature. Through the feature, we want the decoder to translate source terms with a high bracketable probability as a whole unit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head><p>Target D M Fángyù X` ıtˇongıtˇong defence mechanisms Fángyù X` ıtˇongıtˇong defence systems Fángyù X` ıtˇongıtˇong defense programmes 470 56 Fángyù X` ıtˇongıtˇong prevention systems ... ... Zhànlù e DˇaodànDˇaodàn Fángyù X` ıtˇongıtˇong strategic missile defense system 7 0 <ref type="table">Table 1</ref>: Examples of bilingual terms extracted from the training data. "D" means the total number of documents in which the corresponding source term occurs and "M" denotes the number of documents in which the corresponding source term is translated into different target terms. The source side is Chinese Pinyin. To save space, we do not list all the 23 different translations of the source term "Fángyù X` ıtˇongıtˇong".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we conducted experiments to an- swer the following three questions.</p><p>1. Are our term translation disambiguation, consistency and bracketing models able to improve translation quality in BLEU?</p><p>2. Does the combination of the three models provide further improvements?</p><p>3. To what extent do the proposed models affect the translations of test sets?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Setup</head><p>Our  <ref type="bibr" target="#b19">(Och and Ney, 2003</ref>) on the corpora in both directions and using the "grow-diag-final- and" balance strategy ( <ref type="bibr" target="#b16">Koehn et al., 2003</ref> LDA tool GibbsLDA++ 2 with the default setting for training and inference. We performed 100 it- erations of the L-BFGS algorithm implemented in the MaxEnt toolkit 3 with both Gaussian prior and event cutoff set to 1 to train the term bracketing prediction model (Section 4.3).</p><p>We performed part-of-speech tagging for mono- lingual term extraction (C-value/NC-vaule method in Section 3) of the source and target languages with the Stanford NLP toolkit 4 . The bilingual term bank was extracted based on the following param- eter settings of term extraction methods. Empiri- cally, we set the maximum length of a term to 6 words 5 . For both the C-value/NC-value and LLR- based extraction methods, we set the context win- dow size to 5 words, which is a widely-used set- ting in previous work. And we set C-value/NC- value score threshold to 0 and LLR score threshold to 10 according to the training corpora.</p><p>We used the case-insensitive 4-gram BLEU 6 as our evaluation metric. In order to alleviate the im- pact of the instability of MERT <ref type="bibr" target="#b20">(Och, 2003)</ref>, we ran it three times for all our experiments and pre- sented the average BLEU scores on the three runs following the suggestion by <ref type="bibr" target="#b3">Clark et al. (2011)</ref>.</p><p>We used an in-house hierarchical phrase-based decoder to verify our proposed models. Although the decoder translates a document in a sentence- by-sentence fashion, it incorporates document- informed information for sentence translation via the proposed term translation models trained on documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zhǐyǒu Wěiyuánhuì Chéngyuán Cái Kě Cānjiā Wěiyuánhuì Shěnyì</head><p>Only members of the commission shall take part in the commission deliberations .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>He these proposals</head><p>Tā Jiāng Zhèxiē Jiànyì Jiāo Yóu Yī Gè Bùzhǎngjí Wěiyuánhuì Shěnyì submit for approval to a committee of ministers .</p><p>(a) (b) <ref type="figure">Figure 1</ref>: An example of unbracketable source term in the training data. In (a), Wěiyuánhù ı Shěny`Shěny`ı" is bracketable while in (b) it is unbracketable. The solid lines connect bilingual phrases. The source side is Chinese Pinyin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Bilingual Term Bank</head><p>Before reporting the results of the proposed mod- els, we provide some statistics of the bilingual term bank extracted from the training data. According to our statistics, about 1.29M bilin- gual terms are extracted from the training data. 65.07% of the sentence pairs contain bilingual terms in the training data. And on average, a source term has about 1.70 different translations. These statistics indicate that terms are frequently used in real-world data and that a source term can be translated into different target terms.</p><p>We also present some examples of bilingual terms extracted from the training data in <ref type="table">Table 1</ref>. Accordingly, we show the total number of doc- uments in which the corresponding source term occurs and the number of documents in which the corresponding source term is translated into different target terms. The source term "Fángyù X` ıtˇongıtˇong" has 23 different translations in total. They are distributed in 470 documents in the training data. In 414 documents, "Fángyù X` ıtˇongıtˇong" has only one single translation. However, in the other 56 documents it has different translations. This indicates that "Fángyù X` ıtˇongıtˇong" is not consistently translated in these 56 documents. Different from this, the source term Zhànlù e DˇaodànDˇaodàn Fángyù X` ıtˇongıtˇong" only has one translation. And it is trans- lated consistently in all 7 documents where it oc- curs. In fact, according to our statistics, there are about 5.19% source terms whose translations are not consistent even in the same document.</p><p>These examples and statistics suggest 1) that source terms have domain-specific translations and 2) that source terms are not necessarily trans- lated in a consistent manner even in the same doc- ument. These are exactly the reasons why we pro- pose the term translation disambiguation and con- sistency model based on domain information rep- resented by topic distributions.</p><p>Actually, 36.13% of the source terms are not necessarily translated into target strings as a whole unit. We show an example of such terms in Fig- ure 1. In <ref type="figure">Figure 1</ref>-(a), Wěiyuánhù ı Shěny`Shěny`ı" is a term, and is translated into "commission deliber- ations" as a whole unit. Therefore Wěiyuánhù ı Shěny`Shěny`ı" is bracketable in this sentence. How- ever, in <ref type="figure">Figure 1</ref>-(b), Wěiyuánhù ı" and "Shěny`Shěny`ı" are translated separately. Therefore Wěiyuánhù ı Shěny`Shěny`ı" is an unbracketable term in this sentence. This is the reason why we propose a bracketing model to predict whether a source term is brack- etable or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Effect of the Proposed Models</head><p>In this section, we validate the effectiveness of the proposed term translation disambiguation model, consistency model and bracketing model respec- tively. In addition to the traditional hiero <ref type="bibr" target="#b2">(Chiang, 2007</ref>) system, we also compare against the "CountFeat" method in <ref type="bibr" target="#b23">Ren et al. (2009)</ref> who use a binary feature to indicate whether a bilingual phrase contains a term pair. Although <ref type="bibr" target="#b23">Ren et al. (2009)</ref>'s experiments are conducted in a phrase- based system, the idea can be easily applied to a hierarchical phrase-based system.</p><p>We carried out experiments to investigate the ef- fect of the term translation disambiguation model (Dis-Model) and report the results in <ref type="table">Table 2</ref>. In order to find the topic number setting with which our model has the best performance, we ran exper- iments using the MT06 as the development test set. From <ref type="table">Table 2</ref>, we observe that the Dis-Model ob- tains steady improvements over the baseline and "CountFeat" method with the topic number K  <ref type="table">Table 2</ref>: BLEU-4 scores (%) of the term translation disambiguation model (Dis-Model), the term transla- tion consistency model (Cons-Model), the term bracketing model (Brack-Model), and the combination of the three models, on the development test set MT06 and the final test set MT08. K ∈ {50, 100, 150, 200} which is the number of topics for the Dis-Model and the Cons-Model. "Combined-Model" is the combi- nation of the three single modes with topic number 150 for the Dis-Model and the Cons-Model. "Base- line" is the traditional hierarchical phrase-based system. "CountFeat" is the method that adds a counting feature to reward translation hypotheses containing bilingual term pairs. The "*" and "+" denote that the results are significantly <ref type="bibr" target="#b3">(Clark et al., 2011</ref>) better than those of the baseline system and the CountFeat method respectively (p&lt;0.01).</p><p>ranging from 50 to 150. However, when we set K to 200, the performance drops. The highest BLEU scores 33.16 and 24.67 are obtained at the topic setting K = 150. In fact, our Dis-Model gains higher performance in BLEU than both the tradi- tional hiero baseline and the "CountFeat" method with all topic settings. The "CountFeat" method rewards translation hypotheses containing bilin- gual term pairs. However it does not explore any domain information. Our Dis-Model incorporates domain information to conduct translation disam- biguation and achieves higher performance. When the topic number is set to 150, we gain the high- est BLEU score, which is higher than that of the baseline by 0.73 and 0.53 BLEU points on MT06 and MT08, respectively. The final gain over the baseline is on average 0.63 BLEU points.</p><p>We conducted the second group of experiments to study whether the term translation consistency model (Cons-Model) is able to improve the per- formance in BLEU, as well as to investigate the impact of different topic numbers on the Cons- Model. Results are shown in <ref type="table">Table 2</ref>, from which we observe the similar phenomena to what we have found in the Dis-Model. Our Cons-Model gains higher BLEU scores than the baseline sys- tem and the "CountFeat" method with all topic settings. Setting topic number to 150 achieves the highest BLEU score, which is higher than base- line by 0.89 BLEU points and 0.70 BLEU points on MT06 and MT08 respectively, and on average 0.79 BLEU points.</p><p>We also conducted experiments to verify the ef- fectiveness of the term bracketing model (Brack- Model), which conducts bracketing prediction for source terms. Results in <ref type="table">Table 2</ref> show that our Brack-Model gains higher BLEU scores than those of the baseline system and the "CountFeat" method. The final gain of Brack-Model over the baseline is 0.66 BLEU points and 0.52 points on MT06 and MT08 respectively, and on average 0.59 BLEU points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Combination of the Three Models</head><p>As shown in the previous subsection, the term translation disambiguation model, consistency model and bracketing model substantially outper- form the baseline. Now, we investigate whether using these three models simultaneously can lead to further improvements. The last row in <ref type="table">Table 2</ref> shows that the combination of the three models (Combined-Model) achieves higher BLEU score than all single models, when we set the topic num- ber to 150 for the term translation disambigua- tion model and consistency model. The final gain  <ref type="table">Table 3</ref>: Percentage (%) of 1-best translations which are generated by the Combined-Model and the three single models with best settings on the development test set MT06 and the final test set MT08. The topic number is 150 for Best-Dis- Model and Best-Cons-Model.</p><p>of the Combined-Model over the baseline is 1.16 BLEU points and 0.85 points on MT06 and MT08 respectively, and on average 1.00 BLEU points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Analysis</head><p>In this section, we investigate to what extent the proposed models affect the translations of test sets. In <ref type="table">Table 3</ref>, we show the percentage of 1-best trans- lations affected by the Combined-Model and the three single models with best settings on test sets MT06 and MT08. For single models, if the corre- sponding feature (disambiguation, consistency or bracketing) is activated in the 1-best derivation, the corresponding model has impact on the 1-best translation. For the Combined-Model, if any of the corresponding features is activated in the 1- best derivation, the Combined-Model affects the 1-best translation.</p><p>From <ref type="table">Table 3</ref>, we can see that 1-best transla- tions of source sentences affected by any of the proposed models account for a high proportion (30%∼60%) on both MT06 and MT08. This in- dicates that all proposed models play an important role in the translation of both test sets. Among the three proposed models, the Brack-Model is the one that affects the largest number of 1-best trans- lations in both test sets. And the percentage is 60.46% and 55.78% on MT06 and MT08 respec- tively. The Brack-Model only considers source terms during decoding, while the Dis-Model and Cons-Model need to match both source and target terms. The Brack-Model is more likely to be acti- vated. Hence the percentage of 1-best translations affected by this model is higher than those of the other two models. Since we only investigate the 1-best translations generated by the Combined- Model and single models, the translations gener- ated by some single models (e.g., Brack-Model) may not be generated by the Combined-Model. Therefore it is hard to say that the numbers of 1- best translations affected by the Combined-Model must be greater than those of single models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>We have studied the three issues of term trans- lation and proposed three different term trans- lation models for document-informed SMT. The term translation disambiguation model enables the decoder to favor the most suitable domain- specific translations with domain information for source terms. The term translation consistency model encourages the decoder to translate source terms with a high domain translation consistency strength into target terms rather than other new strings. Finally, the term bracketing model re- wards hypotheses that translate bracketable terms into continuous target strings as a whole unit. We integrate the three models into a hierarchical phrase-based SMT system 7 and evaluate their ef- fectiveness on the NIST Chinese-English transla- tion task with large-scale training data. Experi- ment results show that all three models achieve significant improvements over the baseline. Ad- ditionally, combining the three models achieves a further improvement. For future work, we would like to evaluate our models on term translation across a range of different domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>). We adopted SRI Language Modeling Toolkit (Stol- cke and others, 2002) to train a 4-gram language model with modified Kneser-Ney smoothing on the Xinhua portion of the English Gigaword cor- pus. For the topic model, we used the open source</figDesc><table>1 The corpora include LDC2003E07, LDC2003E14, 
LDC2004T07, LDC2004E12, LDC2005E83, LDC2005T06, 
LDC2005T10, LDC2006E24, LDC2006E34, LDC2006E85, 
LDC2006E92, 
LDC2007E87, 
LDC2007E101, 
LDC2008E40, 
LDC2008E56, 
LDC2009E16 
and 
LDC2009E95. 

</table></figure>

			<note place="foot" n="3"> Bilingual Term Extraction Bilingual term extraction is to extract terms from two languages with the purpose of creating or ex</note>

			<note place="foot" n="2"> http://sourceforge.net/projects/gibbslda/ 3 http://homepages.inf.ed.ac.uk/lzhang10/maxent toolkit.html 4 http://nlp.stanford.edu/software/tagger.shtml 5 We determine the maximum length of a term by testing {5, 6, 7, 8} in our preliminary experiments. We find that length 6 produces a slightly better performance than other values. 6 ftp://jaguar.ncsl.nist.gov/mt/resources/mteval-v11b.pl</note>

			<note place="foot" n="7"> Our models are not limited to hierarchical phrase-based SMT. They can be easily applied to other SMT formalisms, such as phrase-and syntax-based SMT.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by National Key Tech-nology R&amp;D Program (No. 2012BAH39B03) and CAS Action Plan for the Development of Western China (No. KGZD-EW-501). Deyi Xiong's work was supported by Natural Science Foundation of Jiangsu Province (Grant No. BK20140355). Qun Liu's work was partially supported by Science Foundation Ireland (Grant No. 07/CE/I1142) as part of the CNGL at Dublin City University. Sin-cere thanks to the anonymous reviewers for their thorough reviewing and valuable suggestions. The corresponding author of this paper, according to the meaning given to this role by University of Chinese Academy of Sciences and Soochow Uni-versity, is Deyi Xiong.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Latent dirichlet allocation. the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Validation of sub-sentential paraphrases acquired from parallel monolingual corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houda</forename><surname>Bouamor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélien</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Vilnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="716" to="725" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="228" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Better hypothesis testing for statistical machine translation: Controlling for optimizer instability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="176" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Study and implementation of combined techniques for automatic extraction of terminology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Béatrice Daille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="49" to="66" />
		</imprint>
	</monogr>
	<note>Journal of The balancing act: Combining symbolic and statistical approaches to language</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Topic models for dynamic translation model adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Eidelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="115" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatic extraction of bilingual terms from a chinese-japanese parallel corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaorong</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuyuki</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Universal Communication Symposium</title>
		<meeting>the 3rd International Universal Communication Symposium</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The c-value/nc-value method of automatic recognition for multi-word terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Katerina T Frantzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junichi</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Research and Advanced Technology for Digital Libraries</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="585" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cache-based document-level statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengxian</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="909" to="919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analysing lexical consistency in translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liane</forename><surname>Guillou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Discourse in Machine Translation</title>
		<meeting>the Workshop on Discourse in Machine Translation</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Document-wide decoding for phrasebased statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Hardmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1179" to="1190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dynamic topic adaptation for phrase-based mt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hasler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter</title>
		<meeting>the 14th Conference of the European Chapter<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamic topic adaptation for smt using distributional profiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hasler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="445" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Identifying cross language term equivalents using statistical machine translation and distributional association measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 16th Nordic Conference of Computational Linguistics Nodalida</title>
		<meeting>16th Nordic Conference of Computational Linguistics Nodalida</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="97" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Post-mt term swapper: Supplementing a statistical machine translation system with a user dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaki</forename><surname>Itagaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takako</forename><surname>Aikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Automatic validation of terminology translation consistency with statistical method. Proceedings of MT summit XI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaki</forename><surname>Itagaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takako</forename><surname>Aikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="269" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Language-independent bilingual terminology extraction from a multilingual parallel corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Els</forename><surname>Lefever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lieve</forename><surname>Macken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronique</forename><surname>Hoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 12th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="496" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Terminology extraction and term ranking for standardizing term banks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magnus</forename><surname>Merkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jody</forename><surname>Foo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 16th Nordic Conference of Computational Linguistics Nodalida</title>
		<meeting>16th Nordic Conference of Computational Linguistics Nodalida</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="349" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic extraction of chinese multiword expressions with a statistical tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangfan</forename><surname>Scott Sl Piao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Rayson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Multi-word-expressions in a Multilingual Context held in conjunction with the 11th EACL</title>
		<meeting><address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mt adaptation for underresourced domains-what works and what not</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Skadins</forename><surname>Pinis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies-The Baltic Perspective: Proceedings of the Fifth International Conference Baltic HLT 2012</title>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">247</biblScope>
			<biblScope unit="page">176</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving statistical machine translation using domain bilingual multiword expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Zhixiang Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Lü</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Multiword Expressions: Identification, Interpretation, Disambiguation and Applications</title>
		<meeting>the Workshop on Multiword Expressions: Identification, Interpretation, Disambiguation and Applications</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="47" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Srilm-an extensible language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on spoken language processing</title>
		<meeting>the international conference on spoken language processing</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="901" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Translation model adaptation for statistical machine translation with monolingual topic information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yidong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huailin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="459" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Context adaptation in statistical machine translation using models with exponentially decaying cache</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Processing</title>
		<meeting>the 2010 Workshop on Domain Adaptation for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="8" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Encouraging consistent translation choices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferhan</forename><surname>Ture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Terminology and machine translation. Handbook of Terminology Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muriel</forename><surname>Vasconcellos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Avey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Gdaniec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurie</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjorie</forename><surname>León</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="697" to="723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Term extraction through unithood and termhood unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thuy</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ai</forename><forename type="middle">Ti</forename><surname>Aw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third international joint conference on natural language processing</title>
		<meeting>the third international joint conference on natural language processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Extending machine translation evaluation metrics with lexical cohesion to document level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Billy</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1060" to="1068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A topic similarity model for hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="750" to="758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A topic-based coherence model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence (AAAI-13)</title>
		<meeting>the Twenty-Seventh AAAI Conference on Artificial Intelligence (AAAI-13)<address><addrLine>Bellevue, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A syntax-driven bracketing model for phrasebased translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aiti</forename><surname>Aw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Modeling lexical cohesion for document-level machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lü</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third international joint conference on Artificial Intelligence</title>
		<meeting>the Twenty-Third international joint conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2183" to="2189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Lexical chain based cohesion models for document-level statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew Lim</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1563" to="1573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bitam: Bilingual topic admixture models for word alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL on Main conference poster sessions</title>
		<meeting>the COLING/ACL on Main conference poster sessions</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="969" to="976" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
