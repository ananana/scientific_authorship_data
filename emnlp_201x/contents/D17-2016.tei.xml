<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised, Knowledge-Free, and Interpretable Word Sense Disambiguation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Panchenko</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fide</forename><surname>Marten</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Ruppert</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Faralli</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ustalov</surname></persName>
							<email>dmitry.ustalov@urfu.ru</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Informatics</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="laboratory">Language Technology Group</orgName>
								<orgName type="institution">Universit채t Hamburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Natural Sciences and Mathematics</orgName>
								<orgName type="institution">Universit채t Mannheim</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Ural Federal University</orgName>
								<address>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised, Knowledge-Free, and Interpretable Word Sense Disambiguation</title>
					</analytic>
					<monogr>
						<title level="j" type="main">EMNLP System Demonstrations</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="91" to="96"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Interpretability of a predictive model is a powerful feature that gains the trust of users in the correctness of the predictions. In word sense disambiguation (WSD), knowledge-based systems tend to be much more interpretable than knowledge-free counterparts as they rely on the wealth of manually-encoded elements representing word senses, such as hypernyms, usage examples, and images. We present a WSD system that bridges the gap between these two so far disconnected groups of methods. Namely, our system, providing access to several state-of-the-art WSD models, aims to be interpretable as a knowledge-based system while it remains completely unsupervised and knowledge-free. The presented tool features a Web interface for all-word disambiguation of texts that makes the sense predictions human readable by providing interpretable word sense inventories, sense representations, and dis-ambiguation results. We provide a public API, enabling seamless integration.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The notion of word sense is central to computa- tional lexical semantics. Word senses can be either encoded manually in lexical resources or induced automatically from text. The former knowledge- based sense representations, such as those found in the BabelNet lexical semantic network <ref type="bibr" target="#b11">(Navigli and Ponzetto, 2012</ref>), are easily interpretable by humans due to the presence of definitions, us- age examples, taxonomic relations, related words, and images. The cost of such interpretability is that every element mentioned above is encoded manually in one of the underlying resources, such as Wikipedia. Unsupervised knowledge-free ap- proaches, e.g. <ref type="bibr" target="#b4">(Di Marco and Navigli, 2013;</ref><ref type="bibr" target="#b0">Bartunov et al., 2016)</ref>, require no manual labor, but the resulting sense representations lack the above- mentioned features enabling interpretability. For instance, systems based on sense embeddings are based on dense uninterpretable vectors. Therefore, the meaning of a sense can be interpreted only on the basis of a list of related senses.</p><p>We present a system that brings interpretability of the knowledge-based sense representations into the world of unsupervised knowledge-free WSD models. The contribution of this paper is the first system for word sense induction and disambigua- tion, which is unsupervised, knowledge-free, and interpretable at the same time. The system is based on the WSD approach of  and is designed to reach interpretability level of knowledge-based systems, such as Babelfy ( <ref type="bibr" target="#b10">Moro et al., 2014)</ref>, within an unsupervised knowledge- free framework. Implementation of the system is open source. 1 A live demo featuring several dis- ambiguation models is available online. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section, we list prominent WSD systems with openly available implementations.</p><p>Knowledge-Based and/or Supervised Systems IMS ( <ref type="bibr" target="#b17">Zhong and Ng, 2010</ref>) is a supervised all- words WSD system that allows users to integrate additional features and different classifiers. By de- fault, the system relies on the linear support vec- tor machines with multiple features. The <ref type="bibr">AutoExtend (Rothe and Sch체tze, 2015)</ref> approach can be used to learn embeddings for lexemes and synsets  of a lexical resource. These representations were successfully used to perform WSD using the IMS. DKPro WSD ( <ref type="bibr" target="#b9">Miller et al., 2013</ref>) is a modu- lar, extensible Java framework for word sense dis- ambiguation. It implements multiple WSD meth- ods and also provides an interface to evaluation datasets. PyWSD 3 project also provides imple- mentations of popular WSD methods, but these are implemented in the Python language.</p><p>Babelfy <ref type="bibr" target="#b10">(Moro et al., 2014</ref>) is a system based on the BabelNet that implements a multilingual graph-based approach to entity linking and WSD based on the identification of candidate meanings using the densest subgraph heuristic.  <ref type="bibr" target="#b0">Bartunov et al., 2016</ref>) is a system that learns sense embed- dings using a Bayesian extension of the Skip-gram model and provides WSD functionality based on the induced sense inventory. SenseGram <ref type="bibr" target="#b14">(Pelevina et al., 2016</ref>) is a system that transforms word embeddings to sense embeddings via graph clus- tering and uses them for WSD. Other methods to learn sense embeddings were proposed, but these do not feature open implementations for WSD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge-Free and Unsupervised Systems</head><p>Among all listed systems, only Babelfy imple- ments a user interface supporting interpretable vi- sualization of the disambiguation results. <ref type="figure" target="#fig_0">Figure 1</ref> presents architecture of the WSD sys- tem. As one may observe, no human labor is used to learn interpretable sense representa- tions and the corresponding disambiguation mod- els. Instead, these are induced from the input text corpus using the JoBimText approach ( <ref type="bibr" target="#b3">Biemann and Riedl, 2013</ref>) implemented using the Apache Spark framework 4 , enabling seamless processing of large text collections. Induction of a WSD model consists of several steps. First, a graph of semantically related words, i.e. a distributional thesaurus, is extracted. Second, word senses are induced by clustering of an ego-network of related words <ref type="bibr" target="#b1">(Biemann, 2006</ref>). Each discovered word sense is represented as a cluster of words. Next, the induced sense inventory is used as a pivot to generate sense representations by aggregation of the context clues of cluster words. To improve interpretability of the sense clusters they are la- beled with hypernyms, which are in turn extracted from the input corpus using Hearst (1992) pat- terns. Finally, the obtained WSD model is used to retrieve a list of sentences that characterize each sense. Sentences that mention a given word are disambiguated and then ranked by prediction con- fidence. Top sentences are used as sense usage ex- amples. For more details about the model induc- tion process refer to ( . Cur- rently, the following WSD models induced from a text corpus are available:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Induction of the WSD Models</head><p>Word senses based on cluster word features. This model uses the cluster words from the in- duced word sense inventory as sparse features that represent the sense.</p><p>Word senses based on context word features. This representation is based on a sum of word vec- tors of all cluster words in the induced sense inven- tory weighted by distributional similarity scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Super senses based on cluster word features.</head><p>To build this model, induced word senses are first globally clustered using the Chinese Whispers graph clustering algorithm <ref type="bibr" target="#b1">(Biemann, 2006</ref>). The edges in this sense graph are established by disam- biguation of the related words ( <ref type="bibr" target="#b6">Faralli et al., 2016;</ref><ref type="bibr" target="#b16">Ustalov et al., 2017)</ref>. The resulting clusters rep- resent semantic classes grouping words sharing a common hypernym, e.g. "animal". This set of se- mantic classes is used as an automatically learned inventory of super senses: There is only one global sense inventory shared among all words in contrast to the two previous traditional "per word" models. Each semantic class is labeled with hypernyms. This model uses words belonging to the semantic class as features.</p><p>Super senses based on context word features. This model relies on the same semantic classes as the previous one but, instead, sense represen- tations are obtained by averaging vectors of words sharing the same class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">WSD API</head><p>To enable fast access to the sense inventories and effective parallel predictions, the WSD models ob- tained at the previous step were indexed in a rela- tional database. <ref type="bibr">5</ref> In particular, each word sense is represented by its hypernyms, related words, and usage examples. Besides, for each sense, the database stores an aggregated context word rep- resentation in the form of a serialized object con- taining a sparse vector in the Breeze format. <ref type="bibr">6</ref> Dur- ing the disambiguation phrase, the input context is represented in the same sparse feature space and the classification is reduced to the computation of the cosine similarity between the context vector and the vectors of the candidate senses retrieved from the database. This back-end is implemented as a RESTful API using the Play framework. <ref type="bibr">7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">User Interface for Interpretable WSD</head><p>The graphical user interface of our system is im- plemented as a single page Web application using the React framework. <ref type="bibr">8</ref> The application performs disambiguation of a text entered by a user. In par- ticular, the Web application features two modes:</p><p>Single word disambiguation mode is illus- trated in <ref type="figure" target="#fig_2">Figure 2</ref>. In this mode, a user specifies an ambiguous word and its context. The output of the system is a ranked list of all word senses of the ambiguous word ordered by relevance to the input context. By default, only the best matching sense is displayed. The user can quickly understand the meaning of each induced sense by looking at the hypernym and the image representing the sense. <ref type="bibr" target="#b5">Faralli and Navigli (2012)</ref> showed that Web search engines can be used to acquire information about word senses. We assign an image to each word in the cluster by querying an image search API 9 us- ing a query composed of the ambiguous word and its hypernym, e.g. "jaguar animal". The first hit of this query is selected to represent the induced word sense. Interpretability of each sense is fur- ther ensured by providing to the user the list of related senses, the list of the most salient context clues, and the sense usage examples (cf. <ref type="figure" target="#fig_2">Figure 2</ref>). Note that all these elements are obtained without manual intervention. Finally, the system provides the reasons behind the sense predictions by displaying context words triggered the prediction. Each common feature is clickable, so a user is able to trace back sense clus- ter words containing this context feature.</p><p>All words disambiguation mode is illustrated in <ref type="figure" target="#fig_3">Figure 3</ref>. In this mode, the system performs dis- ambiguation of all nouns and entities in the input text. First, the text is processed with a part-of- speech and a named entity taggers. <ref type="bibr">10</ref> Next, each detected noun or entity is disambiguated in the same way as in the single word disambiguation mode described above, yet the disambiguation re- sults are represented as annotations of a running text. The best matching sense is represented by a hypernym and an image as depicted in <ref type="figure" target="#fig_3">Figure 3</ref>. This mode performs "semantification" of a text, which can, for instance, assist language learners with the understanding of a text in a foreign lan- guage: Meaning of unknown to the learner words can be deduced from hypernyms and images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>In our prior work ( , we per- formed a thorough evaluation of the method im- plemented in our system on two datasets showing the state-of-the-art performance of the approach as compared to other unsupervised knowledge-free   2,708 3.13 11,712 <ref type="table">Table 1</ref>: Evaluation dataset based on BabelNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head># Words # Senses Avg. Polysemy # Contexts</head><p>methods for WSD, including participants of the <ref type="bibr">SemEval 2013 Task 13 (Jurgens and</ref><ref type="bibr" target="#b8">Klapaftis, 2013</ref>) and two unsupervised knowledge-free WSD systems based on word sense embeddings ( <ref type="bibr" target="#b0">Bartunov et al., 2016;</ref><ref type="bibr" target="#b14">Pelevina et al., 2016</ref>). These evaluations were based on the "lexical sample" setting, where the system is expected to predict a sense identifier of the ambiguous word.</p><p>In this section, we perform an extra evalua- tion that assesses how well hypernyms of ambigu- ous words are assigned in context by our system. Namely, the task is to assign a correct hypernym of an ambiguous word, e.g. "animal" for the word "Jaguar" in the context "Jaguar is a large spotted predator of tropical America". This task does not depend on a fixed sense inventory and evaluates at the same time WSD performance and the quality of the hypernymy labels of the induced senses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>In this experiment, we gathered a dataset consist- ing of definitions of BabelNet 3.7 senses of 1,219 frequent nouns. 11 In total, we collected 56,003 sense definitions each labeled with gold hyper- nyms coming from the IsA relations of BabelNet.</p><p>The average polysemy of words in the gathered dataset was 15.50 senses per word as compared to 2.34 in the induced sense inventory. This huge discrepancy in granularities lead to the fact that some test sentences cannot be correctly predicted by definition: some (mostly rare) BabelNet senses simply have no corresponding sense in the induced inventory. To eliminate the influence of this id- iosyncrasy, we kept only sentences that contain at least one common hypernym with all hypernyms of all induced senses. The statistics of the result- ing dataset are presented in <ref type="table">Table 1</ref>, it is available in the project repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Metrics</head><p>WSD performance is measured using the accuracy with respect to the sentences labeled with the di- rect hypernyms (Hypers) or an extended set of hy- pernym including hypernyms of hypernyms (Hy- 11 Most of the nouns come from the TWSI (Biemann, 2012) dataset, while the remaining nouns were manually selected.  perHypers). A correct match occurs when the pre- dicted sense has at least one common hypernym with the gold hypernyms of the target word in a test sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WSD Model Accuracy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion of Results</head><p>Word Senses. All evaluated models outperform both random and most frequent sense baselines, see <ref type="table" target="#tab_2">Table 2</ref>. The latter picks the sense that cor- responds to the largest sense cluster ( ). In the case of the traditional "per word" inventories, the model based on the con- text features outperform the models based on clus- ter words. While sense representations based on the clusters of semantically related words contain highly accurate features, such representations are sparse as one sense contains at most 200 features. As the result, often the model based on the cluster words contain no common features with the fea- tures extracted from the input context. The sense representations based on the aggregated context clues are much less sparse, which explains their superior performance.</p><p>Super Senses. In the case of the super sense inventory, the model based solely on the cluster words yielded better results that the context-based model. Note here that (1) the clusters that rep- resent super senses are substantially larger than word sense clusters and thus less sparse, (2) words in the super sense clusters are unweighted in con- trast to word sense cluster, thus averaging of word vectors is more noise-prone. Besides, the perfor- mance scores of the models based on the super sense inventories are substantially lower compared to their counterparts based on the traditional "per word" inventories. Super sense models are able to perform classification for any unknown word missing in the training corpus, but their disam- biguation task is more complex (the models need to choose one of 712 classes as compared to an average of 2-3 classes for the "per word" invento- ries). This is illustrated by the near-zero scores of the random and the MFS baselines for this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We present the first openly available word sense disambiguation system that is unsupervised, knowledge-free, and interpretable at the same time. The system performs extraction of word and super sense inventories from a text corpus. The disambiguation models are learned in an unsuper- vised way for all words in the corpus on the ba- sis on the induced inventories. The user inter- face of the system provides efficient access to the produced WSD models via a RESTful API or via an interactive Web-based graphical user interface.</p><p>The system is available online and can be directly used from external applications. The code and the WSD models are open source. Besides, in-house deployments of the system are made easy due to the use of the Docker containers. 12 A prominent direction for future work is supporting more lan- guages and establishing cross-lingual sense links.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Software and functional architecture of the WSD system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Neelakantan et al. (2014) proposed a multi-sense extension of the Skip-gram model that features an open implementation. AdaGram (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Single word disambiguation mode: results of disambiguation of the word "Jaguar" (B) in the sentence "Jaguar is a large spotted predator of tropical America similar to the leopard." (A) using the WSD disambiguation model based on cluster word features (C). The predicted sense is summarized with a hypernym and an image (D) and further represented with usage examples, semantically related words, and typical context clues. Each of these elements is extracted automatically. The reasons of the predictions are provided in terms of common sparse features of the input sentence and a sense representation (E). The induced senses are linked to BabelNet using the method of Faralli et al. (2016) (F).</figDesc><graphic url="image-3.png" coords="4,72.00,67.04,453.54,318.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: All words disambiguation mode: results of disambiguation of all nouns in a sentence.</figDesc><graphic url="image-4.png" coords="4,72.00,514.34,453.54,213.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>863</head><label>863</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance of the hypernymy labeling 
in context on the BabelNet dataset. 

</table></figure>

			<note place="foot" n="1"> https://github.com/uhh-lt/wsd 2 http://jobimtext.org/wsd</note>

			<note place="foot" n="3"> Unsupervised Knowledge-Free Interpretable WSD This section describes (1) how WSD models are learned in an unsupervised way from text and (2) how the system uses these models to enable human interpretable disambiguation in context. 3 https://github.com/alvations/pywsd</note>

			<note place="foot" n="4"> http://spark.apache.org</note>

			<note place="foot" n="5"> https://www.postgresql.org 6 https://github.com/scalanlp/breeze 7 https://www.playframework.com 8 https://facebook.github.io/react</note>

			<note place="foot" n="9"> https://azure.microsoft.com/en-us/ services/cognitive-services/search 10 http://www.scalanlp.org</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We acknowledge the support of the DFG under the "JOIN-T" project, the RFBR under project no. 16-37-00354 mol a, Amazon via the "AWS Research Grants" and Microsoft via the "Azure for Research" programs. Finally, we also thank four anonymous reviewers for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Breaking Sticks and Ambiguities with Adaptive Skip-gram</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kondrashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osokin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vetrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AISTATS</title>
		<meeting>AISTATS<address><addrLine>Cadiz, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="130" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Chinese Whispers: An Efficient Graph Clustering Algorithm and Its Application to Natural Language Processing Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. TextGraphs</title>
		<meeting>TextGraphs<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Turk Bootstrap Word Sense Inventory 2.0: A Large-Scale Resource for Lexical Substitution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. LREC. Istanbul, Turkey</title>
		<meeting>LREC. Istanbul, Turkey</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="4038" to="4042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Text: now in 2D! A framework for lexical expansion with contextual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language Modelling</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="95" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Clustering and Diversifying Web Search Results with Graph-Based Word Sense Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Marco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="709" to="754" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A New MinimallySupervised Framework for Domain Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Faralli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1411" to="1422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Linked Disambiguated Distributional Semantic Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Faralli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISWC, Part II</title>
		<meeting>ISWC, Part II<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="56" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic Acquisition of Hyponyms from Large Text Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. COLING</title>
		<meeting>COLING<address><addrLine>Nantes, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="539" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SemEval-2013 Task 13: Word Sense Induction for Graded and NonGraded Senses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Klapaftis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SemEval</title>
		<meeting>SemEval<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="290" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">DKPro WSD: A Generalized UIMA-based Framework for Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL. Sofia</title>
		<meeting>ACL. Sofia<address><addrLine>Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Entity Linking meets Word Sense Disambiguation: A Unified Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raganato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="231" to="244" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="217" to="250" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP. Doha</title>
		<meeting>EMNLP. Doha<address><addrLine>Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1059" to="1069" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unsupervised Does Not Mean Uninterpretable: The Case for Word Sense Induction and Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ruppert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Faralli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EACL. Valencia</title>
		<meeting>EACL. Valencia<address><addrLine>Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="86" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Making Sense of Word Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pelevina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Arefiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. RepL4NLP. Berlin, Germany</title>
		<meeting>RepL4NLP. Berlin, Germany</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="174" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">AutoExtend: Extending Word Embeddings to Embeddings for Synsets and Lexemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sch체tze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL-IJCNLP</title>
		<meeting>ACL-IJCNLP<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1793" to="1803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Watset: Automatic Induction of Synsets from a Graph of Synonyms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ustalov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">It Makes Sense: A WideCoverage Word Sense Disambiguation System for Free Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL Demos</title>
		<meeting>ACL Demos<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
