<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Syntactically Constrained Bidirectional-Asynchronous Approach for Emotional Conversation Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyuan</forename><surname>Li</surname></persName>
							<email>lijingyuan@mail.hfut.edu.cn, sunx@hfut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Anhui Province Key Laboratory of Affective Computing and Advanced Intelligent Machine</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Anhui Province Key Laboratory of Affective Computing and Advanced Intelligent Machine</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Syntactically Constrained Bidirectional-Asynchronous Approach for Emotional Conversation Generation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="678" to="683"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>678</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Traditional neural language models tend to generate generic replies with poor logic and no emotion. In this paper, a syntactically constrained bidirectional-asynchronous approach for emotional conversation generation (E-SCBA) is proposed to address this issue. In our model, pre-generated emotion keywords and topic keywords are asynchronously introduced into the process of decoding. It is much different from most existing methods which generate replies from the first word to the last. Through experiments, the results indicate that our approach not only improves the diversity of replies, but gains a boost on both logic and emotion compared with baselines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, as artificial intelligence has de- veloped rapidly, researchers are pursuing tech- nologies with greater similarities to human intel- ligence. As a subjective factor, emotion performs an elemental difference between humans and ma- chines. In other words, machines that could under- stand emotion would be more responsive to human needs. For example, in education, positive emo- tions improve students' learning efficiency <ref type="bibr" target="#b4">(Kort et al., 2002</ref>). In healthcare, mood prediction can be used in mental health counseling to help an- ticipate and prevent suicide or depression ( . To make machine more intelligent, we must resolve the conundrum of emotional interactions.</p><p>There are tons of researches about conversa- tion, an important channel for communication be- tween humans. And lots of work has recently been carried out in open-domain conversation devoted to generating meaningful replies ( <ref type="bibr" target="#b13">Vinyals and Le, 2015;</ref><ref type="bibr" target="#b7">Li et al., 2016;</ref>. Unfor- tunately, the factors considered in these methods only concerns topic, like <ref type="bibr" target="#b14">(Xing et al., 2017)</ref>, where * The corresponding author of this paper. they failed to take emotion into account. Unlike the former, the work in (  first addressed the emotional factor in large-scale con- versation generation, and it showed that emotional replies obtain superior performances compared to the baselines that did not consider emotion. How- ever, two defects still manifest themselves in the aforementioned models. First, all methods above only adopted a single factor (i.e., topic or emo- tion), because of which the bias of information can not comprehensively summarize the human con- versations to achieve favorable results. Second, the way that generates replies from the first word to the last can lead to a decline in diversity, limited by the high-frequency generic words in the begin- ning (e.g., I and you), as argued in ( <ref type="bibr" target="#b7">Mou et al., 2016</ref>).</p><p>The deficiencies above inspire us to introduce a new approach called E-SCBA, studying both emotion and topic. Three main contributions are presented in this paper: (1) It conducts a study of compound information, which constitutes the syntactic constraint in the conversation generation. (2) Different from the work in ( <ref type="bibr" target="#b7">Mou et al., 2016)</ref>, a bidirectional-asynchronous decoder with multi- stage strategy is proposed to utilize the syntactic constraint. It ensures the unobstructed communi- cation between different information and allows a fine-grained control of the reply to address the problem of fluency and grammaticality as argued in ( <ref type="bibr" target="#b2">Ghosh et al., 2017;</ref>. <ref type="formula">(3)</ref> Our experiments show that E-SCBA work better on emotion, logic and diversity than the general seq2seq and other models that consider only a sin- gle factor during the generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head><p>The whole process of emotional conversation gen- eration consists of the following three steps:</p><p>Step I: Given a post, we first use two networks combined with category embeddings to re- spectively predict emotion keyword and topic keyword that should appear in the final reply (see Section 2.2).</p><p>Step II: After the prediction, a newly designed decoder is used to introduce both keywords into the content 1 , as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. It first produces a sequence of hidden states based on the emotion keyword (Step I), and then uses an emotional attention mechanism to affect the generation of middle sequence, which is based on the topic keyword (Step II). The remaining two sides are ultimately gen- erated by the combination of middle part and keywords (Step III). A detailed description is given in Section 2.3.</p><p>Step III: Finally, a direction selector is used to ar- range the generated reply in a logically cor- rect order by selecting the better one from forward and backward forms of the reply generated in the last step (see Section 2.4).</p><p>In this work, we default that the replies contain at least one emotion keyword and one topic key- word, which are expected to appear in the dictio- naries we used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Keyword Predictor</head><p>The keywords to be selected are pre-stored in the prepared dictionaries. The adopted emotion dic- tionary was proposed by ( <ref type="bibr" target="#b15">Xu et al., 2008)</ref>, which contains 27,466 emotion words divided into 7 cat- egories: Happy, Like, Surprise, Sad, Fear, Angry and Disgust. The adopted topic dictionary was ob- tained by the LDA model ( <ref type="bibr" target="#b1">Blei et al., 2003)</ref>, in- cluding 10 categories with 100 words for each cat- egory. And to avoid situations in which emotion and topic keywords are predicted to be the same word, all the overlapping words in these two dic- tionaries default to emotion keywords.</p><p>The prediction of emotion and topic keywords follows the similar path. We first derive topic cate- gory and emotion category from the post with two classifiers separately. To be more specific, the pre- trained LDA model is used for the topic category inference. And the work in ( <ref type="bibr" target="#b11">Sun et al., 2018</ref>) is ap- plied for emotion. The concrete model is an emo-tion transfer network. Given a specific external stimuli (e.g., a sentence), the network produce an emotional response, which is specifically an emo- tion category in this work. After this, combining the sum of hidden states˜hstates˜ states˜h = T i=1 h i from en- coder and the category embeddings k = {k et , k tp }, keywords are predicted as follows:</p><formula xml:id="formula_0">p(w k et |x, k et ) = sof tmax(W w et [ ˜ h; k et ]) (1) p(w k tp |x, k tp ) = sof tmax(W w tp [ ˜ h; k tp ]) (2)</formula><p>where w k et and w k tp separately represent the emo- tion keyword and topic keyword that are expected to appear in the reply.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Bidirectional-Asynchronous Decoder</head><p>Due to the decoder architecture shown in <ref type="figure" target="#fig_0">Figure  1</ref>, we suppose the reply in this section is y = (y ct , w k tp , y md , w k et , y ce ) 2 where y md is the mid- dle part between two keywords and y ct , y ce rep- resent the remaining sides connected to the topic keyword and emotion keyword. The generation of middle part y md = (y md 1 , ..., y md K ) can be de- scribed as follows:</p><formula xml:id="formula_1">c et j = f et att (s tp j−1 , {s et i } K i=1 ) (3) p(y md |x, w k ) = K j=1 p(y md j |y md j−1 , s tp j , c et j ) (4)</formula><p>where w k = &lt; w k et , w k tp &gt; represents the set of keywords, s et i and s tp j separately represent the de- coding state of the steps that introduce emotion keyword and topic keyword. c et j is the emotional constrain unit at time j, computing by the emotion control function f et att as follows:</p><formula xml:id="formula_2">c et j = K i=1 α et j,i s et i (5) α et j,i = exp(e et j,i ) K t=1 exp(e et j,t )<label>(6)</label></formula><formula xml:id="formula_3">e et j,i = (v md α ) T tanh(W md α s tp j−1 + U md α s et i ) (7)</formula><p>where e et j,i represents the impact scores of the emo- tion state s et i on the topic state s tp j−1 . After generating the middle part, we connect it with the keywords to form a new sequence. Two seq2seq models are used to encode the connected sequences and decode y ce = (y ce 1 , ..., y ce M ) and y ct = (y ct 1 , ..., y ct N ), as below:</p><formula xml:id="formula_4">p(y ce |w k , y md ) = p(y ce |[w k tp , y md,f , w k et ]) (8) p(y ct |w k , y md ) = p(y ct |[w k et , y md,b , w k tp ])<label>(9)</label></formula><p>where y md,f and y md,b are the forward and back- ward situations of the middle part, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Direction Selector</head><p>To make the samples meet the requirements of de- coder, by default we place the topic keyword as the first keyword on the left and the emotion keyword on the right in training. However, in real situa- tions, the topic keyword does not always appear before the emotion keyword, where we must de- termine correct direction by the machine. By connecting the results in the preceding sec- tion, we get y f = (y ct,b , w k tp , y md,f , w k et , y ce,f ) as the forward situation and y b means the backward situation. GRU networks are used as encoders to process sequences in different situations, which do not share parameters. And the direction is pre- dicted by:</p><formula xml:id="formula_5">p(d|y f , y b ) = sigmoid(W d [ ˜ h d,f , ˜ h d,b ]) (10) ˜ h d, * = T i=1 GRU(y * i )<label>(11)</label></formula><p>where * ∈ {f , b} means forward or backward. Af- ter the operation completes, one of the sequences y f and y b should conform to our expectations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head><p>We evaluated and trained E-SCBA on the emo- tional conversation dataset NLPCC2017. There are a total of 1,119,201 Chinese post-reply pairs in the set. The dictionaries mentioned in Sec- tion 2.2 were used to mark the conversation. The cases whose replies contain both emotion key- words and topic keywords account for 42.6% (476,121) of the total 3 , which are suitable data for the bidirectional-asynchronous decoder. We randomly sampled 8,000 for validation, 3,000 for testing and the rest for training. We also sampled another 60,000 pairs from the training set to train the LDA model 4 mentioned in Section 2.2. Be- sides, an error analysis is presented based on a Chinese movie subtitle dataset which is collected from the Internet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Metrics</head><p>To evaluate our approach, we use the metrics as below:</p><p>Embedding-based Metrics: We measure the similarity computed by cosine distance between a candidate reply and the target reply using sentence-level embedding, following the work in ( <ref type="bibr" target="#b6">Liu et al., 2016;</ref><ref type="bibr" target="#b10">Serban et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Overall    The results of automatic evaluation (G-E = Greedy Matching, E-A = Embedding Average, V-E = Vector Extrema).</p><formula xml:id="formula_6">Happy Like Surprise C L E C L E C L E C L E S2S</formula><p>Distinct Metrics: By computing the number of different unigrams (Distinct-1) and bigrams (Distinct-2), we measure information and diversity in the candidate replies, following the work in ( <ref type="bibr" target="#b7">Li et al., 2016;</ref><ref type="bibr" target="#b14">Xing et al., 2017)</ref>.</p><p>Human Annotations: We asked four annota- tors to evaluate the replies 5 generated from our ap- proach and baselines from Consistency, Logic and Emotion. Consistency measures fluency and gram- maticality of the reply on a three-point scale: 0, 1, 2; Logic measures the degree to which the post and the reply logically match on a three-point scale <ref type="bibr">6</ref> as above; Emotion judges whether the reply includes the right emotion. A score of 0 means the emotion is wrong or there is no emotion, and a score of 1 is the opposite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Baselines</head><p>In the experiments, E-SCBA is compared with the following baselines:</p><p>S2S: the general seq2seq model with attention method ( <ref type="bibr" target="#b0">Bahdanau et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S2S</head><p>-STW: the model uses a synchronous method that starts generating its reply solely and directly from the topic keyword.</p><p>S2S-SEW: the model uses a synchronous method that starts generating its reply solely and directly from the emotion keyword.</p><p>S2S-AW: the model uses an asynchronous method the same as ( <ref type="bibr" target="#b7">Mou et al., 2016)</ref>.</p><p>The synchronous method in S2S-STW and S2S- SEW was mentioned in ( <ref type="bibr" target="#b8">Mou et al., 2015)</ref>, acting as the contrast to the asynchronous models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results and Discussion</head><p>The results of automatic evaluation are shown in <ref type="table" target="#tab_2">Table 2</ref>. Compared with the best model (S2S-AW) that considers only a single factor, E-SCBA makes significant improvement on the distinct metrics (+0.056 and +0.165), which verifies the effective- ness of taking both emotion and topic information into account to improve the diversity. Likewise, our approach also respectively achieves 0.042, 0.068 and 0.043 gains on G-M, E-A and V-E, ben- efiting from the compound information that cap- tures the thrust of human conversation so that E- SCBA has a better ability to learn the goal dis- tribution. Furthermore, the grades of the asyn- chronous models are higher than the synchronous models on both kinds of metrics, showing that the asynchronous method is a more suitable way for content-introducing conversation generation. <ref type="table">Table 1</ref> depicts the human annotations (t-test: p &lt; 0.05 for C and L, p &lt; 0.01 for E). Overall, E- SCBA outperforms S2S-AW on all three metrics, where the compound information plays a positive role in the comprehensive promotion. However, in Surprise and Angry, the grades of Consistency and Logic are not satisfactory, since the data for them are much less than others (Surprise (1.2%)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post</head><p>Emotion Chinese English(translated) 受当局追捕，我们只能秘密活动。 Hunted by the authorities, we work in secret.</p><p>Disgust 有一种被嘲 嘲 嘲讽 讽 讽的感 感 感觉 觉 觉。 There is a sense of being mocked.  and Angry (0.7%)). Besides, the score of Emo- tion in Surprise has a big difference from others. We think the reason is that the characteristic of Surprise overlaps with other categories that have much more data, such as Happy, which interferes with the learning efficiency of the approach in Sur- prise. Meanwhile, it is harder for annotators to de- termine which one is the right emotion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>我一直在观察你们的制作过程。</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Case Study and Error Analysis</head><p>In this section, we sampled some typical cases from a Chinese movie subtitle dataset to do a fur- ther error analysis. The cases are shown in <ref type="table" target="#tab_4">Table 3</ref>. The post of weibo and movie subtitle are applied in different scenes to obey different distributions. The weaker correlation between training sets and test sets can present a more reliable study. The first three conversations are positive sam- ples and others are negative samples that have con- tent with flaws. For the reply in the antepenulti- mate line, its problem is the faint emotion. Since the emotion keyword in this sentence is a poly- semic word, and it expresses a meaning with no emotion here. Under diverse circumstances, a pol- ysemic word probably have different meanings, emotional or neutral. For example, the word "like" can be a generic word when it denotes similar, but it can also be an emotion word when it denotes enjoy. Same situation also occurs in Chinese. Be- sides, we notice that if the LDA model pick a meaningless topic keyword from the dictionary, our approach may have a difficulty in generating a diverse and long reply, as the reply in the penulti- mate line. The lack of information causes generic replies which are consisted of few words gener- ated from the networks. The last line presents another limitation. The emotion keyword hooli- gan corresponds to the post and the topic keyword looking forward to is meaningful, but the com- bination of them, looking forward to a hooligan, does not conform to the normal logic. This situ- ation is caused by the fact that two kinds of key- words are generated independently before decod- ing, and it may cause a mismatch. In the future, we will try to explore different network architectures to make keywords interact with each other during the generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we proposed a novel conversation generation approach (E-SCBA) to make a more comprehensive optimization for the quality of re- ply, which introduces both emotion and topic knowledge into the generation. The newly de- signed decoder makes use of syntactic knowledge to constrain generation and ensures fluency and grammaticality of reply. Experiments show that our approach can generate replies that have rich diversity and feature both emotion and logic.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The process of generating replies in the test. The middle part of the reply is generated in Steps I and II, and the remaining two sides are generated in Step III. The RNN networks used in the decoder do not share the parameters with each other.</figDesc><graphic url="image-1.png" coords="3,72.00,62.81,453.55,162.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Sampled conversations with a corresponding emotion from the Chinese movie subtitle data.</figDesc><table></table></figure>

			<note place="foot" n="1"> Syntactic constraint starts to work here, and can be intuitively interpreted as relative positions of emotion words and topic words, as well as different combinations between them.</note>

			<note place="foot" n="2"> For the training data in opposite direction, we reversed the target replies to meet the requirement.</note>

			<note place="foot" n="3"> Please note that we did not use the original labels of the dataset, but the emotion categories of the keywords as labels to avoid unnecessary bias. For cases that contain multiple topic keywords or emotion keywords, we chose the keywords that appear less frequently to reduce imbalances. 4 High frequency words and stop words, which have no benefit to the topics, were removed in advance.</note>

			<note place="foot" n="5"> 700 conservations in total, 100 for each emotion category, were sampled randomly from the test set. 6 If a reply is too short or turns up frequently, it would be annotated as either 0 or 1 (if the annotator thought the reply related to the post), like &quot;Me too&quot; and &quot;I think so&quot;.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Affect-lm: A neural language model for customizable affective text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sayan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Laksana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="634" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multimodal autoencoder: A deep learning approach to filling in missing sensor data and enabling better mood prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natasha</forename><surname>Jaques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akane</forename><surname>Sano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosalind</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Affective Computing and Intelligent Interaction (ACII)</title>
		<meeting>International Conference on Affective Computing and Intelligent Interaction (ACII)<address><addrLine>San Antonio, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An affective model of interplay between emotions and learning: reengineering educational pedagogy-building a learning companion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. IEEE International Conference on</title>
		<meeting>IEEE International Conference on</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="43" to="46" />
		</imprint>
	</monogr>
	<note>Advanced Learning Technologies</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Sequence to backward and forward sequences: A content-introducing approach to generative short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3349" to="3358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Backward and forward language modeling for constrained sentence generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.06612</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Detecting anomalous emotion through big data from social networks based on a deep learning method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqin</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimedia Tools and Applications</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Personalized multitask learning for predicting tomorrow&apos;s mood, stress, and health</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natasha</forename><surname>Sara Ann Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehimwenma</forename><surname>Jaques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akane</forename><surname>Nosakhare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosalind</forename><surname>Sano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Affective Computing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05869</idno>
		<title level="m">A neural conversational model</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Topic aware neural response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yalou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="3351" to="3357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Constructing the affective lexicon ontology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the China Society for Scientific &amp; Technical Information</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Emotional chatting machine: emotional conversation generation with internal and external memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01074</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
