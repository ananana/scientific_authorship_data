<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Context-Aware Representations for Knowledge Base Relation Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniil</forename><surname>Sorokin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab (UKP) Research Training Group AIPHES</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab (UKP) Research Training Group AIPHES</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Context-Aware Representations for Knowledge Base Relation Extraction</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1784" to="1789"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We demonstrate that for sentence-level relation extraction it is beneficial to consider other relations in the sentential context while predicting the target relation. Our architecture uses an LSTM-based encoder to jointly learn representations for all relations in a single sentence. We combine the context representations with an attention mechanism to make the final prediction. We use the Wikidata knowledge base to construct a dataset of multiple relations per sentence and to evaluate our approach. Compared to a baseline system, our method results in an average error reduction of 24% on a held-out set of relations. The code and the dataset to replicate the experiments are made available at https://github.com/ukplab.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The main goal of relation extraction is to determine a type of relation between two target entities that appear together in a text. In this paper, we consider the sentential relation extraction task: to each oc- currence of the target entity pair e 1 , e 2 in some sentence s one has to assign a relation type r from a given set R ( <ref type="bibr" target="#b2">Hoffmann et al., 2011)</ref>. A triple e 1 , r, e 2 is called a relation instance and we refer to the relation of the target entity pair as target re- lation. Relation extraction is a fundamental task that enables a wide range of semantic applications from question answering ( <ref type="bibr" target="#b17">Xu et al., 2016</ref>) to fact checking ( <ref type="bibr" target="#b15">Vlachos and Riedel, 2014</ref>).</p><p>For relation extraction, it is crucial to be able to extract relevant features from the sentential context ( <ref type="bibr" target="#b10">Riedel et al., 2010;</ref><ref type="bibr" target="#b18">Zeng et al., 2015)</ref>. Modern ap- proaches focus just on the relation between the tar- get entities and disregard other relations that might be present in the same sentence ( <ref type="bibr" target="#b18">Zeng et al., 2015;</ref><ref type="bibr" target="#b5">Lin et al., 2016)</ref>. For example, in order to correctly identify the relation type between the movie e 1 and the director e 2 in (1), it is important to separate out the INSTANCE OF relation between the movie and its type e 3 :</p><p>( We present a novel architecture that considers other relations in the sentence as a context for predicting the label of the target relation. We use the term context relations to refer to them throughout the pa- per. Our architecture uses an LSTM-based encoder to jointly learn representations for all relations in a single sentence. The representation of the target relation and representations of the context relations are combined to make the final prediction.</p><p>To facilitate the experiments we construct a dataset that contains multiple positive and nega- tive relation instances per sentence. We employ a fast growing community managed knowledge base (KB) Wikidata <ref type="bibr" target="#b16">(Vrandeči´Vrandeči´c and Krötzsch, 2014</ref>) to build the dataset.</p><p>Our main contribution is the new neural net- work architecture for extracting relations between an entity pair that takes into account other relations in the sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>We employ a neural network to automatically en- code the target relation and the sentential context into a fixed-size feature vector. <ref type="bibr" target="#b7">Mintz et al. (2009)</ref> and <ref type="bibr" target="#b10">Riedel et al. (2010)</ref> have used manually engi- neered features based on part-of-speech tags and dependency parses to represent the target relations. Recently, <ref type="bibr" target="#b18">Zeng et al. (2015)</ref> and  have shown that one can successfully apply convo-lutional neural networks to extract sentence-level features automatically.</p><p>Most of the methods ( <ref type="bibr" target="#b10">Riedel et al., 2010;</ref><ref type="bibr" target="#b18">Zeng et al., 2015;</ref><ref type="bibr" target="#b5">Lin et al., 2016</ref>) focus on predicting a single relation type based on the combined evi- dence from all of the occurrences of an entity pair. <ref type="bibr" target="#b2">Hoffmann et al. (2011)</ref> and <ref type="bibr" target="#b14">Surdeanu et al. (2012)</ref> assign multiple relation types to each entity pair, such that the predictions are tied to particular oc- currences of the entity pair. We regard the relation extraction task similarly and predict relation types on the sentence level.</p><p>We use a distant supervision approach <ref type="bibr" target="#b7">(Mintz et al., 2009</ref>) to construct the dataset. <ref type="bibr" target="#b7">Mintz et al. (2009)</ref> and <ref type="bibr" target="#b10">Riedel et al. (2010)</ref> have applied it to create relation extraction datasets for a large-scale KB. In contrast to our dataset, their data contains a single relation instance per sentence. That makes it incompatible with our method.</p><p>All of the aforementioned approaches consider just the relation between the target entities and dis- regard other relations that might be present in the same sentence. Our method uses context relations to predict the target relation. One can also use other types of structured information from the nearby context to improve relation extraction. <ref type="bibr" target="#b11">Roth and Yih (2004)</ref> have combined named entity recogni- tion and relation extraction in a structured predic- tion approach to improve both tasks. Later, <ref type="bibr" target="#b8">Miwa and Bansal (2016)</ref> have implemented an end-to-end neural network to construct a context representa- tion for joint entity and relation extraction. Finally, <ref type="bibr" target="#b4">Li et al. (2013)</ref> have designed global features and constraints to extract multiple events and their ar- guments from the same sentence.</p><p>We don't implement global constraints in our approach, since unlike events and arguments, there are no restrictions as to what relations can appear together. Instead we encode all relations in the same context into fixed-size vectors and use an attention mechanism to combine them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data generation with Wikidata</head><p>Wikidata is a collaboratively constructed KB that encodes common world knowledge in a form of binary relation instances (e.g. CAPITAL:P36 (Hawaii:Q782, Honolulu:Q18094)) <ref type="bibr">1</ref>  Columbia University → Q49088 For further processing, we filter out sentences that contain fewer than 3 annotated entities, since we need to have multiple relations per sentence for training (see Section 4).</p><p>We extract named entities and noun chunks from the input sentences with the Stanford CoreNLP toolkit ( ) to identify entities that are not covered by the Wikipedia annotations (e.g. Obama in the sentence above). We retrieve IDs for those entities by searching through entity labels in Wikidata. We use HeidelTime <ref type="bibr" target="#b13">(Strötgen and Gertz, 2013</ref>) to extract dates.</p><p>For each pair of entities, we query Wikidata for relation types that connect them. We discard an occurrence of an entity pair if the relation is am- biguous, i. e. multiple relation types were retrieved. For comparison, <ref type="bibr" target="#b14">Surdeanu et al. (2012)</ref> report that only 7.5% of entity pairs have more than one corre- sponding relation type in the distantly supervised dataset of <ref type="bibr" target="#b10">Riedel et al. (2010</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation Encoder</head><p>Figure 1: The architecture of the relation encoder it into train, validation and held-out sets, ensuring that there is no overlap in either sentences or rela- tion triples between the three sets. <ref type="table">Table 1</ref> summa- rizes the statistics about the dataset. We assessed the quality of the distant supervision set-up on 200 manually verified sentences from the training set: 79.5% of relations in those sentences were cor- rectly labeled with distant supervision (86.9 if one entity is linked, 74.7 if both are linked).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model architecture 4.1 Relation encoder</head><p>The relation encoder produces a fixed-size vector representation o s of a relation between two entities in a sentence (see <ref type="figure">Figure 1)</ref>. First, each token of the sentence x = {x 1 , x 2 . . . x n } is mapped to a k-dimensional embed- ding vector using a matrix W ∈ R |V |×k , where |V | is the size of the vocabulary. Throughout the exper- iments in this paper, we use 50-dimensional GloVe embeddings pre-trained on a 6 billion corpus <ref type="bibr" target="#b9">(Pennington et al., 2014</ref>).</p><p>Second, we mark each token in the sentence as either belonging to the first entity e 1 , the second entity e 2 or to neither of those. A marker embed- ding matrix P ∈ R 3×d is randomly initialized (d is the dimension of the position embedding and there are three marker types). For each token, we concatenate the marker embedding with the word embedding: (W n , P n ).</p><p>We apply a recurrent neural network (RNN) on the token embeddings. The length n naturally varies from sentence to sentence and an RNN pro- vides a way to accommodate inputs of various  <ref type="bibr">, 1997</ref>) that was successfully applied to information extraction be- fore (Miwa and Bansal, 2016).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model variants</head><p>LSTM baseline As the first model variant, we feed the output vector o s of the relation encoder to a softmax layer to predict the final relation type for the target entity (see the upper part of <ref type="figure">Figure 1</ref>):</p><formula xml:id="formula_0">p(r|e 1 , e 2 , x; θ ) = exp( f r ) ∑ n r i=1 exp( f i ) ,<label>(1)</label></formula><formula xml:id="formula_1">f i = y i · o s + b i ,</formula><p>where y i is a weight vector and b i is a bias. ContextSum We argue that for predicting a re- lation type for a target entity pair other context relations in the same sentence are relevant. Some relation types may tend to co-occur, such as DI- RECTED BY and PRODUCED BY, whereas others may be restrictive (e. g. one can only have a single PLACE OF BIRTH).</p><p>Therefore, in addition to the target entity pair, we take other entities from the same sentence that were extracted at the data generation step. We construct a set of context relations by taking each possible pair of entities. 3 Example (2) shows a target entity pair e 1 , e 2 and context entities highlighted in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(2) [Swag It Out] is the official [debut sin- gle] by [American singer] [e 1 Zendaya], known for starring in the series [e 2 Shake It Up].</head><p>We apply the same relation encoder on the target and context relations (see <ref type="figure">Figure 2)</ref>. </p><formula xml:id="formula_2">o c = m ∑ i=0 a i o i , a i = exp(g(o i , o s )) ∑ m j=0 exp(g(o j , o s )) ,<label>(2)</label></formula><p>where g i computes an attention score for a con- text relation with respect to the target relation: g(o i , o s ) = o i Ao s , and A is a weight matrix that is learned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Training the models</head><p>All models were trained using the Adam optimizer ( <ref type="bibr" target="#b3">Kingma and Ba, 2014</ref>) with categorical cross- entropy as the loss function. We use an early stop- ping criterion on the validation data to determine the number of training epochs. The learning rate is fixed to 0.01 and the rest of the optimization pa- rameters are set as recommended in <ref type="bibr" target="#b3">Kingma and Ba (2014)</ref>: β 1 = 0.9, β 2 = 0.999, ε = 1e − 08. The training is performed in batches of 128 instances.</p><p>We apply Dropout ( <ref type="bibr" target="#b12">Srivastava et al., 2014</ref>) on the penultimate layer as well as on the embeddings layer with a probability of 0.5. We choose the size of the layers (RNN layer size o = 256) and entity marker embeddings (d = 3) with a random search on the validation set.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Held-out evaluation</head><p>As an additional baseline, we re-implement a sentence-level model based on convolutional neu- ral networks (CNNs) described in <ref type="bibr" target="#b5">Lin et al. (2016)</ref>. This is a state-of-the-art model for fine-grained re- lation extraction that was previously tested on the single-relation dataset from <ref type="bibr" target="#b10">Riedel et al. (2010)</ref>. In addition to CNNs, their architecture uses a dif- ferent position encoding scheme: position markers encode a relative position of each word with respect to the target entities. <ref type="bibr">5</ref> We use the same GloVe word embeddings for this model and perform a hyper- parameter optimization on the validation set.</p><p>Our dataset lets us compare the baseline models and the models that use context relations on the same data. Following the previous work on rela-  <ref type="table">Table 2</ref>: Precision (P) and recall (R) for the top relations.</p><p>tion extraction, we report the aggregated precision- recall curves for each model on the held-out data <ref type="figure" target="#fig_1">(Figure 3</ref>). <ref type="bibr">6</ref> To compute the curves, we rank the predictions of each model by their confidence and traverse this list top to bottom measuring the preci- sion and recall at each step. The models that take the context into account perform similar to the baselines at the smallest re- call numbers, but start to positively deviate from them at higher recall rates. In particular, the ContextAtt model performs better than any other system in our study over the entire recall range. Compared to the competitive LSTM-baseline that uses the same relation encoder, the ContextAtt model achieves a 24% reduction of the average error: from 0.2096 ± 0.002 to 0.1590 ± 0.002. The difference between the models is statistically sig- nificant (p = 0.009). <ref type="bibr">7</ref> We also compute macro precision-recall curves that give equal weights to all relations in the dataset. <ref type="figure" target="#fig_3">Figure 4</ref> shows that the ContextAtt model performs best over all relation types. One can also see that the ContextSum doesn't universally outperforms the LSTM-baseline. It demonstrates again that us- ing attention is crucial to extract relevant informa- tion from the context relations.</p><p>On the relation-specific results <ref type="table">(Table 2</ref>) we ob- serve that the context-enabled model demonstrates the most improvement on precision and seems to be especially useful for taxonomy relations (see SUBCLASS OF, PART OF). <ref type="bibr">6</ref> We do not compare against the approach of <ref type="bibr" target="#b14">Surdeanu et al. (2012)</ref> that also performs sentence-level relation extraction, since the provided implementation does not feature the com- plete pipeline and is only applicable on a particular Freebase dataset. <ref type="bibr">7</ref> The average error and the standard deviation are estimated on 5 training iterations for each model. The statistical signifi- cance is computed using the Wilcoxon rank-sum test on the error rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We have introduced a neural network architecture for relation extraction on the sentence level that takes into account other relations from the same context. We have shown by comparison with com- petitive baselines that these context relations are beneficial for relation extraction with a large set of relation types.</p><p>Our approach can be easily applied to other types of relation extraction models as well. For instance, <ref type="bibr" target="#b5">Lin et al. (2016)</ref> extract sentence-level features and then combine features from multiple sentences with a selective attention mechanism. It would be possible to replace their sentence-level feature extractor with our model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>That ensures that representation for target and context relations are learned jointly. We sum the context relation representations: o c = ∑ m i=0 o i , where each element o i is a vector representation of a single context relation. The resulting context representation o c ∈ R o is concatenated with the vector representation of the target relation: o = [o s , o c ]. We feed the concatenated vector to the softmax layer in Eq. 1 to predict the final relation type for the target entity pair (see the upper part of Figure 2). ContextAtt In this variant, we use a weighted sum of the context relation representation at the penultimate step:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Aggregated precision-recall curves for the implemented models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Aggregated macro precision-recall curves for the implemented models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>. It contains more than 28 million entities and 160 million re-</figDesc><table>Train Validation Held-out 

# of relation triples 284,295 
113,852 
287,902 
# of relation inst. 
578,199 
190,160 
600,804 

Table 1: Statistics of the generated dataset. 

lation instances. 2 A broad community oversight, 
similar to Wikipedia, ensures a higher data quality 
compared to other KBs (Färber et al., 2015). 
We use the complete English Wikipedia corpus 
to generate training and evaluation data. Wikipedia 
and Wikidata are tightly integrated which enables 
us to employ manual wiki annotations to extract 
high quality data. From each sentence in a com-
plete article we extract link annotations and retrieve 
Wikidata entity IDs corresponding to the linked arti-
cles. There is an unambiguous one-to-one mapping 
between Wikidata entities and Wikipedia articles. 
For example: 

1: Input Born in [[Honolulu|Honolulu, 
Hawaii]], Obama is a graduate of 
[[Columbia University]]. 
2: Links to Wikidata Ids Honolulu → Q18094 
</table></figure>

			<note place="foot" n="1"> Unique IDs in Wikidata have a Q-prefix for entities and a P-prefix for relations.</note>

			<note place="foot" n="2"> https://www.wikidata.org/wiki/Special: Statistics</note>

			<note place="foot" n="3"> We limit the maximum number of relations in a sentence to 7 for computational reasons.</note>

			<note place="foot" n="4"> We test for the RNN layer size the values {64, 128, 256, 512}, for entity marker embeddings the values {1, 3, 5, 7} and for the Dropout rate the values in the range 0.0-0.75. 5 We have briefly experimented with such position markers for our models, but found no improvements.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been supported by the German Re-search Foundation as part of the Research Training Group Adaptive Preparation of Information from Heterogeneous Sources (AIPHES) under grant No. GRK 1994/1, and via the QA-EduInf project (grant GU 798/18-1 and grant RI 803/12-1). We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40 GPU used for this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Comparative Survey of DBpedia, Freebase, OpenCyc, Wikidata, and YAGO</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basil</forename><surname>Ell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Menne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achim</forename><surname>Rettinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web Journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT)</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT)<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Joint Event Extraction via Structured Prediction with Global Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural Relation Extraction with Selective Attention over Instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2124" to="2133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics (ACL): System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics (ACL): System Demonstrations<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP<address><addrLine>Singapore, Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">End-to-end Relation Extraction using LSTMs on Sequences and Tree Structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1105" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modeling Relations and Their Mentions without Labeled Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<meeting>the European Conference on Machine Learning and Knowledge Discovery in Databases<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A linear programming formulation for global inference in natural language tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 8th Conference on Computational Natural Language Learning (CoNLL)<address><addrLine>Boston, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Multilingual and cross-domain temporal tagging. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jannik</forename><surname>Strötgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gertz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="269" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiinstance Multi-label Learning for Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)<address><addrLine>Jeju, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fact Checking: Task definition and dataset construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Language Technologies and Computational Social Science</title>
		<meeting>the ACL Workshop on Language Technologies and Computational Social Science<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="18" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Wikidata: A Free Collaborative Knowledgebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Vrandeči´vrandeči´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Krötzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Question Answering on Freebase via Relation Extraction and Textual Evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2326" to="2336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1753" to="1762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Self-adaptive hierarchical sentence model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Poupart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>International Joint Conference on Artificial Intelligence (IJCAI)<address><addrLine>Buenos Aires, Argentina</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4069" to="4076" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
