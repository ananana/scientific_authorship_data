<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Swag: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">♠</forename><forename type="middle">♥ ♠</forename></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">G</forename><surname>Allen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Swag: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="93" to="104"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>93</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Given a partial description like &quot;she opened the hood of the car,&quot; humans can reason about the situation and anticipate what might come next (&quot;then, she examined the engine&quot;). In this paper, we introduce the task of grounded com-monsense inference, unifying natural language inference and commonsense reasoning. We present Swag, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation arti-facts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-the-art language models to massively oversam-ple a diverse set of potential counterfactuals. Empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88%), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>When we read a story, we bring to it a large body of implicit knowledge about the physical world. For instance, given the context "on stage, a woman takes a seat at the piano," shown in <ref type="table" target="#tab_0">Table 1</ref>, we can easily infer what the situation might look like: a woman is giving a piano performance, with a crowd watching her. We can furthermore infer her likely next action: she will most likely set her fin- gers on the piano keys and start playing.</p><p>This type of natural language inference requires commonsense reasoning, substantially broadening the scope of prior work that focused primarily on On stage, a woman takes a seat at the piano. She a) sits on a bench as her sister plays with the doll. b) smiles with someone as the music plays. c) is in the crowd, watching the dancers. d) nervously sets her fingers on the keys.</p><p>A girl is going across a set of monkey bars. She a) jumps up across the monkey bars. b) struggles onto the monkey bars to grab her head. c) gets to the end and stands on a wooden plank. d) jumps up and does a back flip.</p><p>The woman is now blow drying the dog. The dog a) is placed in the kennel next to a woman's feet. b) washes her face with the shampoo. c) walks into frame and walks towards the dog. d) tried to cut her face, so she is trying to do something very close to her face.  <ref type="bibr" target="#b5">Ginet, 2000</ref>). Whereas the dominant entailment paradigm asks if two natural language sentences (the 'premise' and the 'hypothesis') describe the same set of possible worlds ( <ref type="bibr" target="#b8">Dagan et al., 2006;</ref><ref type="bibr" target="#b1">Bowman et al., 2015</ref>), here we focus on whether a (multiple-choice) ending describes a possible (fu- ture) world that can be anticipated from the situa- tion described in the premise, even when it is not strictly entailed. Making such inference necessi- tates a rich understanding about everyday physical situations, including object affordances ( <ref type="bibr" target="#b12">Gibson, 1979)</ref> and frame semantics ( <ref type="bibr" target="#b0">Baker et al., 1998)</ref>. A first step toward grounded commonsense in- ference with today's deep learning machinery is to create a large-scale dataset. However, recent work has shown that human-written datasets are suscep- tible to annotation artifacts: unintended stylistic patterns that give out clues for the gold labels ( <ref type="bibr" target="#b15">Gururangan et al., 2018;</ref><ref type="bibr" target="#b37">Poliak et al., 2018)</ref>. As a result, models trained on such datasets with hu-man biases run the risk of over-estimating the ac- tual performance on the underlying task, and are vulnerable to adversarial or out-of-domain exam- ples ( <ref type="bibr" target="#b49">Wang et al., 2018;</ref><ref type="bibr" target="#b13">Glockner et al., 2018)</ref>.</p><p>In this paper, we introduce Adversarial Filtering (AF), a new method to automatically detect and reduce stylistic artifacts. We use this method to construct Swag: an adversarial dataset with 113k multiple-choice questions. We start with pairs of temporally adjacent video captions, each with a context and a follow-up event that we know is physically possible. We then use a state-of-the- art language model fine-tuned on this data to mas- sively oversample a diverse set of possible nega- tive sentence endings (or counterfactuals). Next, we filter these candidate endings aggressively and adversarially using a committee of trained mod- els to obtain a population of de-biased endings with similar stylistic features to the real ones. Fi- nally, these filtered counterfactuals are validated by crowd workers to further ensure data quality.</p><p>Extensive empirical results demonstrate unique contributions of our dataset, complementing exist- ing datasets for natural langauge inference (NLI) <ref type="bibr" target="#b1">(Bowman et al., 2015;</ref><ref type="bibr" target="#b50">Williams et al., 2018)</ref> and commonsense reasoning <ref type="bibr" target="#b38">(Roemmele et al., 2011;</ref><ref type="bibr" target="#b55">Zhang et al., 2017)</ref>. First, our dataset poses a new challenge of grounded commonsense inference that is easy for humans (88%) while hard for current state-of- the-art NLI models (&lt;60%). Second, our pro- posed adversarial filtering methodology allows for cost-effective construction of a large-scale dataset while substantially reducing known annotation ar- tifacts. The generality of adversarial filtering al- lows it to be applied to build future datasets, en- suring that they serve as reliable benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Swag: Our new dataset</head><p>We introduce a new dataset for studying physically grounded commonsense inference, called Swag. 1 Our task is to predict which event is most likely to occur next in a video. More formally, a model is given a context c = (s, n): a complete sentence s and a noun phrase n that begins a second sen- tence, as well as a list of possible verb phrase sen- tence endings V = {v 1 , . . . , v 4 }. See <ref type="figure" target="#fig_2">Figure 1</ref> for an example triple (s, n, v i ). The model must then select the most appropriate verb phrase v ˆ i ∈ V .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 v + h F B O f v F X t 3 4 t a 2 N D U v y 3 d j x g = " &gt; A A A C 3 X i c d V J L b 9 N A E N 6 Y V z G v F o 5 c L C I k x C G y E R J w q 6 C H X h C t R G i l J C r j z c R Z Z R / W 7 L h t a u X a C 4 g T i J / E b + D f s E l 9 w A m M t N p v v 3 n P b F 5 q 5 T l N f 3 e i a 9 d v 3 L y 1 d T u + c / f e / Q f b O w 8 / e V e R x L 5 0 2 t F x D h 6 1 s t h n x R q P S 0 I w u c a j f P Z u q T 8 6 R f L K 2 Y 8 8 L 3 F k o L B q o i R w o A 7 5 Z L u b 9 t K V J J s g a 0 B X N H J w s t P 5 N R w 7 W R m 0 L D V 4 P 8 j S k k c 1 E C u p c R E P K 4 8 l y B k U O A j Q g k E / q l e V L p K n g R k n E 0 f h W E 5 W 7 N 8 e N R j v 5 y Y P l g Z 4 6 t d 1 S / J f u k H F k 9 e j W t m y Y r T y K t G k 0 g m 7 Z N l 2 M l a E k v U 8 A J C k Q q 2 J n A K B 5 D C c V h Z T a V b k z l q d 1 B K 0 b D M F Q T l V 8 r z N E m q v L t p j + E 9 I c h y W Y I s 2 m 5 v 2 u y K 9 F s w R b q b I n Z s x 5 D 6 w e x j 2 Q v g + z O h D i Q T s 6 H k 9 B C o M n C / q 5 o 7 j O K w + W 1 / 0 J u i / 6 L 3 p Z Y c v u 7 t v m z + w J R 6 L J + K Z y M Q r s S v 2 x Y H o C y l Q f B H f x Y / o c 3 Q Z f Y 2 + X Z l G n c b n k W h J 9 P M P 9 U X t 7 A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 v + h F B O f v F X t 3 4 t a 2 N D U v y 3 d j x g = " &gt; A A A C 3 X i c d V J L b 9 N A E N 6 Y V z G v F o 5 c L C I k x C G y E R J w q 6 C H X h C t R G i l J C r j z c R Z Z R / W 7 L h t a u X a C 4 g T i J / E b + D f s E l 9 w A m M t N p v v 3 n P b F 5 q 5 T l N f 3 e i a 9 d v 3 L y 1 d T u + c / f e / Q f b O w 8 / e V e R x L 5 0 2 t F x D h 6 1 s t h n x R q P S 0 I w u c a j f P Z u q T 8 6 R f L K 2 Y 8 8 L 3 F k o L B q o i R w o A 7 5 Z L u b 9 t K V J J s g a 0 B X N H J w s t P 5 N R w 7 W R m 0 L D V 4 P 8 j S k k c 1 E C u p c R E P K 4 8 l y B k U O A j Q g k E / q l e V L p K n g R k n E 0 f h W E 5 W 7 N 8 e N R j v 5 y Y P l g Z 4 6 t d 1 S / J f u k H F k 9 e j W t m y Y r T y K t G k 0 g m 7 Z N l 2 M l a E k v U 8 A J C k Q q 2 J n A K B 5 D C c V h Z T a V b k z l q d 1 B K 0 b D M F Q T l V 8 r z N E m q v L t p j + E 9 I c h y W Y I s 2 m 5 v 2 u y K 9 F s w R b q b I n Z s x 5 D 6 w e x j 2 Q v g + z O h D i Q T s 6 H k 9 B C o M n C / q 5 o 7 j O K w + W 1 / 0 J u i / 6 L 3 p Z Y c v u 7 t v m z + w J R 6 L J + K Z y M Q r s S v 2 x Y H o C y l Q f B H f x Y / o c 3 Q Z f Y 2 + X Z l G n c b n k W h J 9 P M P 9 U X t 7 A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 v + h F B O f v F X t 3 4 t a 2 N D U v y 3 d j x g = " &gt; A A A C 3 X i c d V J L b 9 N A E N 6 Y V z G v F o 5 c L C I k x C G y E R J w q 6 C H X h C t R G i l J C r j z c R Z Z R / W 7 L h t a u X a C 4 g T i J / E b + D f s E l 9 w A m M t N p v v 3 n P b F 5 q 5 T l N f 3 e i a 9 d v 3 L y 1 d T u + c / f e / Q f b O w 8 / e V e R x L 5 0 2 t F x D h 6 1 s t h n x R q P S 0 I w u c a j f P Z u q T 8 6 R f L K 2 Y 8 8 L 3 F k o L B q o i R w o A 7 5 Z L u b 9 t K V J J s g a 0 B X N H J w s t P 5 N R w 7 W R m 0 L D V 4 P 8 j S k k c 1 E C u p c R E P K 4 8 l y B k U O A j Q g k E / q l e V L p K n g R k n E 0 f h W E 5 W 7 N 8 e N R j v 5 y Y P l g Z 4 6 t d 1 S / J f u k H F k 9 e j W t m y Y r T y K t G k 0 g m 7 Z N l 2 M l a E k v U 8 A J C k Q q 2 J n A K B 5 D C c V h Z T a V b k z l q d 1 B K 0 b D M F Q T l V 8 r z N E m q v L t p j + E 9 I c h y W Y I s 2 m 5 v 2 u y K 9 F s w R b q b I n Z s x 5 D 6 w e x j 2 Q v g + z O h D i Q T s 6 H k 9 B C o M n C / q 5 o 7 j O K w + W 1 / 0 J u i / 6 L 3 p Z Y c v u 7 t v m z + w J R 6 L J + K Z y M Q r s S v 2 x Y H o C y l Q f B H f x Y / o c 3 Q Z f Y 2 + X Z l G n c b n k W h J 9 P M P 9 U X t 7 A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 v + h F B O f v F X t 3 4 t a 2 N D U v y 3 d j x g = " &gt; A A A C 3 X i c d V J L b 9 N A E N 6 Y V z G v F o 5 c L C I k x C G y E R J w q 6 C H X h C t R G i l J C r j z c R Z Z R / W 7 L h t a u X a C 4 g T i J / E b + D f s E l 9 w A m M t N p v v 3 n P b F 5 q 5 T l N f 3 e i a 9 d v 3 L y 1 d T u + c / f e / Q f b O w 8 / e V e R x L 5 0 2 t F x D h 6 1 s t h n x R q P S 0 I w u c a j f P Z u q T 8 6 R f L K 2 Y 8 8 L 3 F k o L B q o i R w o A 7 5 Z L u b 9 t K V J J s g a 0 B X N H J w s t P 5 N R w 7 W R m 0 L D V 4 P 8 j S k k c 1 E C u p c R E P K 4 8 l y B k U O A j Q g k E / q l e V L p K n g R k n E 0 f h W E 5 W 7 N 8 e N R j v 5 y Y P l g Z 4 6 t d 1 S / J f u k H F k 9 e j W t m y Y r T y K t G k 0 g m 7 Z N l 2 M l a E k v U 8 A J C k Q q 2 J n A K B 5 D C c V h Z T a V b k z l q d 1 B K 0 b D M F Q T l V 8 r z N E m q v L t p j + E 9 I c h y W Y I s 2 m 5 v 2 u y K 9 F s w R b q b I n Z s x 5 D 6 w e x j 2 Q v g + z O h D i Q T s 6 H k 9 B C o M n C / q 5 o 7 j O K w + W 1 / 0 J u i / 6 L 3 p Z Y c v u 7 t v m z + w J R 6 L J + K Z y M Q r s S v 2 x Y H o C y l Q f B H f x Y / o c 3 Q Z f Y 2 + X Z l G n c b n k W h J 9 P M P 9 U X t 7 A = = &lt; / l a t e x i t &gt; t + 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F x Z l r q R S p Q 2 + c q d l v / 9 i y s H N v s c = " &gt; A A A C 3 3 i c d V J L b x M x E H a 2 P M r y a s u R y 4 o I C Y E U 7 S I k 6 K 2 C H r g g i i C 0 U h J V Y 2 e y s W K v V + P Z 0 r D K v R c Q J x C / i N / A v 8 F J 9 8 A m M J L l z 9 + 8 Z y x L o z 2 n 6 e 9 O t H X l 6 r X r 2 z f i m 7 d u 3 7 m 7 s 7 v 3 0 b u K F P a V M 4 5 O J H g 0 u s A + a z Z 4 U h K C l Q a P 5 e z V U n 9 8 h u S 1 K z 7 w v M S R h b z Q E 6 2 A A / W e n 2 S n O 9 2 0 l 6 4 k 2 Q R Z A 7 q i k a P T 3 c 6 v 4 d i p y m L B y o D 3 g y w t e V Q D s V Y G F / G w 8 l i C m k G O g w A L s O h H 9 a r W R f I w M O N k 4 i i c g p M V + 7 d H D d b 7 u Z X B 0 g J P / b p u S f 5 L N 6 h 4 8 m J U 6 6 K s G A t 1 m W h S m Y R d s m w 8 G W t C x W Y e A C j S o d Z E T Y F A c R h P K 4 u t D G t y n 1 q d 1 A q M a j M 5 Q T n V 6 r z N E h q v P 7 f H 8 J + Q 5 D i s o c j b r L T t d 0 V m L Z g j 3 E w h n Z s x S B / Y Q w x 7 I X w T Z v S 2 R A J 2 9 L g e A u U W z h d 1 c 8 d x H F a f r S 9 6 E / S f 9 v Z 7 2 b t n 3 Y O X z R / Y F v f F A / F I Z O K 5 O B C v x Z H o C y V y 8 U V 8 F z 8 i G V 1 E X 6 N v l 6 Z R p / G 5 J 1 o S / f w D J a b u X A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F x Z l r q R S p Q 2 + c q d l v / 9 i y s H N v s c = " &gt; A A A C 3 3 i c d V J L b x M x E H a 2 P M r y a s u R y 4 o I C Y E U 7 S I k 6 K 2 C H r g g i i C 0 U h J V Y 2 e y s W K v V + P Z 0 r D K v R c Q J x C / i N / A v 8 F J 9 8 A m M J L l z 9 + 8 Z y x L o z 2 n 6 e 9 O t H X l 6 r X r 2 z f i m 7 d u 3 7 m 7 s 7 v 3 0 b u K F P a V M 4 5 O J H g 0 u s A + a z Z 4 U h K C l Q a P 5 e z V U n 9 8 h u S 1 K z 7 w v M S R h b z Q E 6 2 A A / W e n 2 S n O 9 2 0 l 6 4 k 2 Q R Z A 7 q i k a P T 3 c 6 v 4 d i p y m L B y o D 3 g y w t e V Q D s V Y G F / G w 8 l i C m k G O g w A L s O h H 9 a r W R f I w M O N k 4 i i c g p M V + 7 d H D d b 7 u Z X B 0 g J P / b p u S f 5 L N 6 h 4 8 m J U 6 6 K s G A t 1 m W h S m Y R d s m w 8 G W t C x W Y e A C j S o d Z E T Y F A c R h P K 4 u t D G t y n 1 q d 1 A q M a j M 5 Q T n V 6 r z N E h q v P 7 f H 8 J + Q 5 D i s o c j b r L T t d 0 V m L Z g j 3 E w h n Z s x S B / Y Q w x 7 I X w T Z v S 2 R A J 2 9 L g e A u U W z h d 1 c 8 d x H F a f r S 9 6 E / S f 9 v Z 7 2 b t n 3 Y O X z R / Y F v f F A / F I Z O K 5 O B C v x Z H o C y V y 8 U V 8 F z 8 i G V 1 E X 6 N v l 6 Z R p / G 5 J 1 o S / f w D J a b u X A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F x Z l r q R S p Q 2 + c q d l v / 9 i y s H N v s c = " &gt; A A A C 3 3 i c d V J L b x M x E H a 2 P M r y a s u R y 4 o I C Y E U 7 S I k 6 K 2 C H r g g i i C 0 U h J V Y 2 e y s W K v V + P Z 0 r D K v R c Q J x C / i N / A v 8 F J 9 8 A m M J L l z 9 + 8 Z y x L o z 2 n 6 e 9 O t H X l 6 r X r 2 z f i m 7 d u 3 7 m 7 s 7 v 3 0 b u K F P a V M 4 5 O J H g 0 u s A + a z Z 4 U h K C l Q a P 5 e z V U n 9 8 h u S 1 K z 7 w v M S R h b z Q E 6 2 A A / W e n 2 S n O 9 2 0 l 6 4 k 2 Q R Z A 7 q i k a P T 3 c 6 v 4 d i p y m L B y o D 3 g y w t e V Q D s V Y G F / G w 8 l i C m k G O g w A L s O h H 9 a r W R f I w M O N k 4 i i c g p M V + 7 d H D d b 7 u Z X B 0 g J P / b p u S f 5 L N 6 h 4 8 m J U 6 6 K s G A t 1 m W h S m Y R d s m w 8 G W t C x W Y e A C j S o d Z E T Y F A c R h P K 4 u t D G t y n 1 q d 1 A q M a j M 5 Q T n V 6 r z N E h q v P 7 f H 8 J + Q 5 D i s o c j b r L T t d 0 V m L Z g j 3 E w h n Z s x S B / Y Q w x 7 I X w T Z v S 2 R A J 2 9 L g e A u U W z h d 1 c 8 d x H F a f r S 9 6 E / S f 9 v Z 7 2 b t n 3 Y O X z R / Y F v f F A / F I Z O K 5 O B C v x Z H o C y V y 8 U V 8 F z 8 i G V 1 E X 6 N v l 6 Z R p / G 5 J 1 o S / f w D J a b u X A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F x Z l r q R S p Q 2 + c q d l v / 9 i y s H N v s c = " &gt; A A A C 3 3 i c d V J L b x M x E H a 2 P M r y a s u R y 4 o I C Y E U 7 S I k 6 K 2 C H r g g i i C 0 U h J V Y 2 e y s W K v V + P Z 0 r D K v R c Q J x C / i N / A v 8 F J 9 8 A m M J L l z 9 + 8 Z y x L o z 2 n 6 e 9 O t H X l 6 r X r 2 z f i m 7 d u 3 7 m 7 s 7 v 3 0 b u K F P a V M 4 5 O J H g 0 u s A + a z Z 4 U h K C l Q a P 5 e z V U n 9 8 h u S 1 K z 7 w v M S R h b z Q E 6 2 A A / W e n 2 S n O 9 2 0 l 6 4 k 2 Q R Z A 7 q i k a P T 3 c 6 v 4 d i p y m L B y o D 3 g y w t e V Q D s V Y G F / G w 8 l i C m k G O g w A L s O h H 9 a r W R f I w M O N k 4 i i c g p M V + 7 d H D d b 7 u Z X B 0 g J P / b p u S f 5 L N 6 h 4 8 m J U 6 6 K s G A t 1 m W h S m Y R d s m w 8 G W t C x W Y e A C j S o d Z E T Y F A c R h P K 4 u t D G t y n 1 q d 1 A q M a j M 5 Q T n V 6 r z N E h q v P 7 f H 8 J + Q 5 D i s o c j b r L T t d 0 V m L Z g j 3 E w h n Z s x S B / Y Q w x 7 I X w T Z v S 2 R A J 2 9 L g e A u U W z h d 1 c 8 d x H F a f r S 9 6 E / S f 9 v Z 7 2 b t n 3 Y O X z R / Y F v f F A / F I Z O K 5 O B C v x Z H o C y V y 8 U V 8 F z 8 i G V 1 E X 6 N v l 6 Z R p / G 5 J 1 o S / f w D J a b u X A = = &lt; / l a t e x i t &gt;</head><p>(the videos are never used) <ref type="figure" target="#fig_2">Figure 1</ref>: Overview of the data collection process. For a pair of sequential video captions, the second caption is split into noun and verb phrases. A lan- guage model generates many negative endings, of which a difficult subset are human-annotated.</p><p>Overview Our corpus consists of 113k multi- ple choice questions (73k training, 20k valida- tion, 20k test) and is derived from pairs of con- secutive video captions from ActivityNet Cap- tions ( <ref type="bibr" target="#b23">Krishna et al., 2017;</ref><ref type="bibr" target="#b16">Heilbron et al., 2015)</ref> and the Large Scale Movie Description Chal- lenge (LSMDC; <ref type="bibr">Rohrbach et al., 2017)</ref>. The two datasets are slightly different in nature and allow us to achieve broader coverage: ActivityNet con- tains 20k YouTube clips containing one of 203 ac- tivity types (such as doing gymnastics or playing guitar); LSMDC consists of 128k movie captions (audio descriptions and scripts). For each pair of captions, we use a constituency parser ( <ref type="bibr" target="#b47">Stern et al., 2017</ref>) to split the second sentence into noun and verb phrases ( <ref type="figure" target="#fig_2">Figure 1</ref>). <ref type="bibr">2</ref> Each question has a human-verified gold ending and 3 distractors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A solution to annotation artifacts</head><p>In this section, we outline the construction of Swag. We seek dataset diversity while minimizing annotation artifacts, conditional stylistic patterns such as length and word-preference biases. For many NLI datasets, these biases have been shown to allow shallow models (e.g. bag-of-words) ob- tain artificially high performance.</p><p>To avoid introducing easily "gamed" patterns, we present Adversarial Filtering (AF), a generally- applicable treatment involving the iterative refine- ment of a set of assignments to increase the en- tropy under a chosen model family. We then dis- cuss how we generate counterfactual endings, and Algorithm 1 Adversarial filtering (AF) of negative sam- ples. During our experiments, we set N easy = 2 for refining a population of N − = 1023 negative examples to k = 9, and used a 80%/20% train/test split.</p><p>while convergence not reached do</p><p>• Split the dataset D randomly up into train- ing and testing portions D tr and D te .</p><p>• Optimize a model f θ on D tr . for index i in D te do • Identify easy indices:</p><formula xml:id="formula_0">A easy i = {j ∈ A i : f θ (x + i ) &gt; f θ (x − i,j )} • Replace N easy easy indices j ∈ A easy i with adversarial indices k ∈ A i satisfying f θ (x − i,k ) &gt; f θ (x − i,j )</formula><p>. end for end while finally, the models used for filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Formal definition</head><p>In this section, we formalize what it means for a dataset to be adversarial. Intuitively, we say that an adversarial dataset for a model f is one on which f will not generalize, even if evaluated on test data from the same distribution. More for- mally, let our input space be X and the label space be Y. Our trainable classifier f , taking parameters θ is defined as f θ : X → R |Y| . Let our dataset of size N be defined as D = {(x i , y i )} 1≤i≤N , and let the loss function over the dataset be L(f θ , D). We say that a dataset is adversarial with respect to f if we expect high empirical error I over all leave-one-out train/test splits <ref type="bibr" target="#b48">(Vapnik, 2000)</ref>:</p><formula xml:id="formula_1">I(D, f ) = 1 N N i=1 L(f θ i , {(x i , y i )}),<label>(1)</label></formula><p>where</p><formula xml:id="formula_2">θ i = argmin θ L(f θ , D \ {(x i , y i )}),<label>(2)</label></formula><p>with regularization terms omitted for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Adversarial filtering (AF) algorithm</head><p>In this section, we outline an approach for gen- erating an adversarial dataset D, effectively max- imizing empirical error I with respect to a fam- ily of trainable classifiers f . Without loss of generality, we consider the situation where we have N contexts, each associated with a single positive example (x + i , 1) ∈ X × Y, and a large population of context-specific negative examples (x − i,j , 0) ∈ X × Y, where 1≤j≤N − for each i. For instance, the negative examples could be incorrect relations in knowledge-base completion <ref type="bibr" target="#b45">(Socher et al., 2013)</ref>, or all words in a dictionary for a single-word cloze task ( <ref type="bibr" target="#b58">Zweig and Burges, 2011)</ref>.</p><p>Our goal will be to filter the population of neg- ative examples for each instance i to a size of kN − . This will be captured by returning a set of assignments A, where for each instance the as- signment will be a k-subset</p><formula xml:id="formula_3">A i = [1 . . . N − ] k .</formula><p>The filtered dataset will then be:</p><formula xml:id="formula_4">D AF = {(x i , 1), {(x − i,j , 0)} j∈A i } 1≤i≤N<label>(3)</label></formula><p>Unfortunately, optimizing I(D AF , f ) is difficult as A is global and non-differentiable. To address this, we present Algorithm 1. On each iteration, we split the data into dummy 'train' and 'test' splits. We train a model f on the training portion and obtain parameters θ, then use the remaining test portion to reassign the indices of A. For each context, we replace some number of 'easy' nega- tives in A that f θ classifies correctly with 'adver- sarial' negatives outside of A that f θ misclassifies. This process can be thought of as increasing the overall entropy of the dataset: given a strong model f θ that is compatible with a random subset of the data, we aim to ensure it cannot generalize to the held-out set. We repeat this for several it- erations to reduce the generalization ability of the model family f over arbitrary train/test splits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Generating candidate endings</head><p>To generate counterfactuals for Swag, we use an LSTM <ref type="bibr" target="#b17">(Hochreiter and Schmidhuber, 1997</ref>) lan- guage model (LM), conditioned on contexts from video captions. We first pretrain on BookCorpus ( , then finetune on the video cap- tion datasets. The architecture uses standard best practices and was validated on held-out perplex- ity of the video caption datasets; details are in the appendix. We use the LM to sample N − =1023 unique endings for a partial caption. <ref type="bibr">3</ref> Importantly, we greedily sample the endings, since beam search decoding biases the generated endings to be of lower perplexity (and thus easily distinguishable from found endings). We find this process gives good counterfactuals: the generated endings tend to use topical words, but often make little sense physically, making them perfect for our task. Further, the generated endings are marked as "gibberish" by humans only 9.1% of the time (Sec 3.5); in that case the ending is filtered out. </p><note type="other">0.5 0.6 Test accuracy Baseline (random) CNN BoW POStag LSTM MLP Ensemble</note><p>Figure 2: Test accuracy by AF iteration, under the negatives given by A. The accuracy drops from around 60% to close to random chance. For effi- ciency, the first 100 iterations only use the MLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Stylistic models for adversarial filtering</head><p>In creating Swag, we designed the model family f to pick up on low-level stylistic features that we posit should not be predictive of whether an event happens next in a video. These stylistic features are an obvious case of annotation artifacts <ref type="bibr" target="#b2">(Cai et al., 2017;</ref><ref type="bibr" target="#b43">Schwartz et al., 2017</ref>). <ref type="bibr">4</ref> Our final clas- sifier is an ensemble of four stylistic models: On every adversarial iteration, the ensemble is trained jointly to minimize cross-entropy. The accuracies of these models (at each itera- tion, evaluated on a 20% split of the test dataset before indices of A get remapped) are shown in <ref type="figure">Figure 2</ref>. Performance decreases from 60% to close to random chance; moreover, confusing the perplexity-based MLP is not sufficient to lower performance of the ensemble. Only once the other stylistic models are added does the ensemble ac- curacy drop substantially, suggesting that our ap- proach is effective at reducing stylistic artifacts. <ref type="bibr">4</ref> A broad definition of annotation artifacts might include aspects besides lexical/stylistic features: for instance, certain events are less likely semantically regardless of the context (e.g. riding a horse using a hose). For this work, we erred more conservatively and only filtered based on style.</p><p>Imagine that you are watching a video clip. The clip has a caption, but it is missing the final phrase. Please choose the best 2 caption endings, and classify each as:</p><p>• likely, if it completes the caption in a reasonable way;</p><p>• unlikely, if it sounds ridiculous or impossible;</p><p>• gibberish if it has such serious errors that it doesn't feel like a valid English sentence.</p><p>Example: Someone is shown sitting on a fence and talking to the camera while pointing out horses. Someone • stands in front of a podium. (likely, second best)</p><p>• rides a horse using a hose. (unlikely)</p><p>• is shown riding a horse. <ref type="figure">(likely, best)</ref> • , the horse in a plaza field. (gibberish) <ref type="figure">Figure 3</ref>: Mechanical Turk instructions (abridged).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Human verification</head><p>The final data-collection step is to have humans verify the data. Workers on Amazon Mechani- cal Turk were given the caption context, as well as six candidate endings: one found ending and five adversarially-sampled endings. The task was twofold: Turkers ranked the endings indepen- dently as likely, unlikely, or gibberish, and se- lected the best and second best endings <ref type="figure">(Fig 3)</ref>.</p><p>We obtained the correct answers to each con- text in two ways. If a Turker ranks the found end- ing as either best or second best (73.7% of the time), we add the found ending as a gold exam- ple, with negatives from the generations not la- belled best or gibberish. Further, if a Turker ranks a generated ending as best, and the found ending as second best, then we have reason to believe that the generation is good. This lets us add an addi- tional training example, consisting of the gener- ated best ending as the gold, and remaining gen- erations as negatives. <ref type="bibr">5</ref> Examples with ≤3 non- gibberish endings were filtered out. <ref type="bibr">6</ref> We found after 1000 examples that the annota- tors tended to have high agreement, also generally choosing found endings over generations (see <ref type="table">Ta- ble 2</ref>). Thus, we collected the remaining 112k ex- amples with one annotator each, periodically veri- fying that annotators preferred the found endings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we evaluate the performance of various NLI models on <ref type="bibr">Swag</ref>  <ref type="table">Table 2</ref>: Annotators tend to label the found ending as likely and within the top 2 (column 2), in other cases the example is filtered out. Both label groups have high inter-annotator agreement, in terms of Krippendorff's α and pairwise percent agreement.</p><p>for our dataset take the following form: given a sentence and a noun phrase as context c = (s, n), as well as a list of possible verb phrase endings V = {v 1 , . . . , v 4 }, a model f θ must select a verbî verbî that hopefully matches i gold :</p><formula xml:id="formula_5">ˆ i = argmax i f θ (s, n, v i )<label>(4)</label></formula><p>To study the amount of bias in our dataset, we also consider models that take as input just the ending verb phrase v i , or the entire second sen- tence (n, v i ). For our learned models, we train f by minimizing multi-class cross-entropy. We consider three different types of word representa- tions: 300d GloVe vectors from Common Crawl ( <ref type="bibr" target="#b34">Pennington et al., 2014</ref>), 300d Numberbatch vec- tors retrofitted using ConceptNet relations <ref type="bibr" target="#b46">(Speer et al., 2017)</ref>, and 1024d ELMo contextual repre- sentations that show improvement on a variety of NLP tasks, including standard NLI ( <ref type="bibr" target="#b35">Peters et al., 2018)</ref>. We follow the final dataset split (see Sec- tion 2) using two training approaches: training on the found data, and the found and highly-ranked generated data. See the appendix for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Unary models</head><p>The following models predict labels from a single span of text as input; this could be the ending only, the second sentence only, or the full passage. a. fastText <ref type="bibr" target="#b21">(Joulin et al., 2017)</ref>: This library mod- els a single span of text as a bag of n-grams, and tries to predict the probability of an ending being correct or incorrect independently. 7 b. Pretrained sentence encoders We consider two types of pretrained RNN sentence encoders, SkipThoughts ( ) and InferSent ( <ref type="bibr" target="#b6">Conneau et al., 2017</ref>). SkipThoughts was trained by predicting adjacent sentences in book data, whereas InferSent was trained on supervised NLI data. For each second sentence (or just the end- ing), we feed the encoding into an MLP. c. LSTM sentence encoder Given an arbitrary span of text, we run a two-layer BiLSTM over it. The final hidden states are then max-pooled to ob- tain a fixed-size representation, which is then used to predict the potential for that ending.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Binary models</head><p>The following models predict labels from two spans of text. We consider two possibilties for these models: using just the second sentence, where the two text spans are n, v i , or using the context and the second sentence, in which case the spans are s, (n, v i ). The latter case includes many models developed for the NLI task. d. Dual Bag-of-Words For this baseline, we treat each sentence as a bag-of-embeddings (c, v i ). We model the probability of picking an ending i using a bilinear model: softmax i (cWv T i ). 8 e. Dual pretrained sentence encoders Here, we obtain representations from SkipThoughts or In- ferSent for each span, and compute their pairwise compatibility using either 1) a bilinear model or 2) an MLP from their concatenated representations. f. SNLI inference Here, we consider two mod- els that do well on SNLI ( <ref type="bibr" target="#b1">Bowman et al., 2015)</ref>: Decomposable Attention ( ) and ESIM ( <ref type="bibr" target="#b4">Chen et al., 2017)</ref>. We use pretrained ver- sions of these models (with ELMo embeddings) on SNLI to obtain 3-way entailment, neutral, and contradiction probabilities for each example. We then train a log-linear model using these 3-way probabilities as features. g. SNLI models (retrained) Here, we train ESIM and Decomposable Attention on our dataset: we simply change the output layer size to 1 (the po- tential of an ending v i ) with a softmax over i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Other models</head><p>We also considered the following models: h. Length: Although length was used by the ad- versarial classifier, we want to verify that human validation didn't reintroduce a length bias. For this baseline, we always choose the shortest ending. i. ConceptNet As our task requires world knowl- edge, we tried a rule-based system on top of the  Performance of all models in accuracy (%). All models substantially underperform humans, although performance increases as more context is provided (left to right). We optionally train on found endings only, or found and human-validated generated endings (found+gen).</p><p>ConceptNet knowledge base ( <ref type="bibr" target="#b46">Speer et al., 2017)</ref>.</p><p>For an ending sentence, we use the spaCy depen- dency parser to extract the head verb and its de- pendent object. The ending score is given by the number of ConceptNet causal relations 9 between synonyms of the verb and synonyms of the object. j. Human performance To benchmark human performance, five Mechanical Turk workers were asked to answer 100 dataset questions, as did an 'expert' annotator (the first author of this paper). Predictions were combined using a majority vote.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>We present our results in <ref type="table" target="#tab_4">Table 3</ref>. The best model that only uses the ending is the LSTM sequence model with ELMo embeddings, which obtains 43.6%. This model, as with most models stud- ied, greatly improves with more context: by 3.1% when given the initial noun phrase, and by an ad-ditional 4% when also given the first sentence. Further improvement is gained from models that compute pairwise representations of the in- puts. While the simplest such model, Dual- BoW, obtains only 35.1% accuracy, combining In- ferSent sentence representations gives 40.5% ac- curacy (InferSent-Bilinear). The best results come from pairwise NLI models: when fully trained on Swag, ESIM+ELMo obtains 59.2% accuracy.</p><p>When comparing machine results to human re- sults, we see there exists a lot of headroom. Though there likely is some noise in the task, our results suggest that humans (even untrained) con- verge to a consensus. Our in-house "expert" an- notator is outperformed by an ensemble of 5 Turk workers (with 88% accuracy); thus, the effective upper bound on our dataset is likely even higher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Swag versus existing NLI datasets</head><p>The past few years have yielded great advances in NLI and representation learning, due to the avail- ability of large datasets like SNLI and MultiNLI Our dataset shows a greater variety of dynamic verbs, such as "move", as well as temporal verbs such as "start" and "come." "Continue" is cut off for SNLI (it has frequency 6 · 10 −5 ). Bottom: CDF for verbs in SNLI and Swag.</p><p>( <ref type="bibr" target="#b1">Bowman et al., 2015;</ref><ref type="bibr" target="#b50">Williams et al., 2018)</ref>. With the release of Swag, we hope to continue this trend, particularly as our dataset largely has the same input/output format as other NLI datasets. We observe three key differences between our dataset and others in this space: First, as noted in Section 1, Swag requires a unique type of temporal reasoning. A state-of-the- art NLI model such as ESIM, when bottlenecked through the SNLI notion of entailment (SNLI- ESIM), only obtains 36.1% accuracy. 10 This im- plies that these datasets necessitate different (and complementary) forms of reasoning.</p><p>Second, our use of videos results in wide cover- age of dynamic and temporal situations Compared with SNLI, with contexts from Flickr30K ( <ref type="bibr" target="#b36">Plummer et al., 2017</ref>) image captions, Swag has more active verbs like 'pull' and 'hit,' and fewer static verbs like 'sit' and 'wear' <ref type="figure" target="#fig_3">(Figure 4</ref>). <ref type="bibr">11</ref> Third, our dataset suffers from few lexical bi- ases. Whereas fastText, a bag of n-gram model, obtains 67.0% accuracy on SNLI versus a 34.3% baseline ( <ref type="bibr" target="#b15">Gururangan et al., 2018)</ref>, fastText ob- tains only 29.0% accuracy on Swag. <ref type="bibr">12</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Error analysis</head><p>We sought to quantify how human judgments dif- fer from the best studied model, ESIM+ELMo. We randomly sampled 100 validation questions <ref type="bibr">10</ref> The weights of SNLI-ESIM pick up primarily on entail- ment probability (0.59), as with neutral (0.46), while contra- diction is negatively correlated (-.42).</p><p>11 Video data has other language differences; notably, char- acter names in LSMDC were replaced by 'someone' <ref type="bibr">12</ref> The most predictive individual words on SWAG are in- frequent in number: 'dotted' with P(+|dotted) = 77% with 10.3 counts, and P(−|similar) = 81% with 16.3 counts. (Counts from negative endings were discounted 3x, as there are 3 times as many negative endings as positive endings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reason</head><p>Explanation Freq.</p><p>Situational The good ending is better in context. 53.7% Plausibility The bad ending is implausible regard- less of context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14.4%</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Novelty</head><p>The bad ending seems redundant; it is entailed by the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.8%</head><p>Weirdness The bad ending is semantically or grammatically malformed, e.g. 'the man is getting out of the horse.'</p><p>18.1%</p><p>Ambiguous Both endings seem equally likely. 12.0% <ref type="table">Table 4</ref>: Justifications for ranking the gold answer over a wrong answer chosen by ESIM+ELMo.</p><p>that ESIM+ELMo answered incorrectly, for each extracting both the gold ending and the model's preferred ending. We asked 5 Amazon Mechanical Turk workers to pick the better ending (of which they preferred the gold endings 94% of the time) and to select one (or more) multiple choice reasons explaining why the chosen answer was better. The options, and the frequencies, are outlined in <ref type="table">Table 4</ref>. The most common reason for the turkers preferring the correct answer is situational (52.3% of the time), followed by weirdness (17.5%) and plausibility (14.4%). This suggests that ESIM+ELMo already does a good job at filtering out weird and implausible answers, with the main bottleneck being grounded physical understand- ing. The ambiguous percentage is also relatively low (12.0%), implying significant headroom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Qualitative examples</head><p>Last, we show several qualitative examples in Ta- ble 5. Though models can do decently well by identifying complex alignment patterns between the two sentences (e.g. being "up a tree" im- plies that "tree" is the end phrase), the incorrect model predictions suggest this strategy is insuffi-A waiter brings a fork. The waiter a) starts to step away. (74.76%) b) adds spaghetti to the table. (21.57%) c) brings a bunch of pie to the food (2.67%) d) drinks from the mug in the bowl. (0.98%)</p><p>He is up a tree. Someone a) stands underneath the tree.  cient. For instance, answering "An old man rides a small bumper car" requires knowledge about bumper cars and how they differ from regular cars: bumper cars are tiny, don't drive on roads, and don't work in parking lots, eliminating the alterna- tives. However, this knowledge is difficult to ex- tract from existing corpora: for instance, the Con- ceptNet entry for Bumper Car has only a single relation: bumper cars are a type of vehicle. Other questions require intuitive physical reasoning: e.g, for "he pours the raw egg batter into the pan," about what happens next in making an omelet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Where to go next?</head><p>Our results suggest that Swag is a challenging testbed for NLI models. However, the adversarial models used to filter the dataset are purely stylis- tic and focus on the second sentence; thus, subtle artifacts still likely remain in our dataset. These patterns are ostensibly picked up by the NLI mod- els (particularly when using ELMo features), but the large gap between machine and human perfor- mance suggests that more is required to solve the dataset. As models are developed for common- sense inference, and more broadly as the field of NLP advances, we note that AF can be used again to create a more adversarial version of Swag using better language models and AF models. Commonsense NLI Several datasets have been introduced to study NLI beyond linguistic entail- ment: for inferring likely causes and endings given a sentence (COPA; Roemmele et al., 2011), for choosing the most sensible ending to a short story (RocStories; <ref type="bibr" target="#b44">Sharma et al., 2018)</ref>, and for predicting likelihood of a hy- pothesis by regressing to an ordinal label (JOCI; ( <ref type="bibr" target="#b55">Zhang et al., 2017)</ref>). These datasets are relatively small: 1k examples for COPA and 10k cloze ex- amples for RocStories. 13 JOCI increases the scale by generating the hypotheses using a knowledge graph or a neural model. In contrast to JOCI where the task was formulated as a regression task on the degree of plausibility of the hypothesis, we frame commonsense inference as a multiple choice ques- tion to reduce the potential ambiguity in the labels and to allow for direct comparison between ma- chines and humans. In addition, Swag's use of ad- versarial filtering increases diversity of situations and counterfactual generation quality. Last, another related task formulation is sen- tence completion or cloze, where the task is to pre- dict a single word that is removed from a given context ( <ref type="bibr" target="#b58">Zweig and Burges, 2011;</ref><ref type="bibr" target="#b30">Paperno et al., 2016)</ref>. <ref type="bibr">14</ref> Our work in contrast requires longer tex- tual descriptions to reason about.</p><p>Vision datasets Several resources have been in- troduced to study temporal inference in vision. The Visual Madlibs dataset has 20k image cap- tions about hypothetical next/previous events ( <ref type="bibr" target="#b51">Yu et al., 2015)</ref>; similar to our work, the test portion is multiple-choice, with counterfactual answers re- trieved from similar images and verified by hu- mans. The question of 'what will happen next?' has also been studied in photo albums <ref type="bibr" target="#b19">(Huang et al., 2016)</ref>, videos of team sports, <ref type="bibr" target="#b10">(Felsen et al., 2017)</ref> and egocentric dog videos ( <ref type="bibr" target="#b9">Ehsani et al., 2018)</ref>. Last, annotation artifacts are also a re- curring problem for vision datasets such as Vi- sual Genome ( <ref type="bibr" target="#b53">Zellers et al., 2018)</ref> and Visual QA ( <ref type="bibr" target="#b20">Jabri et al., 2016)</ref>; recent work was done to cre- ate a more challenging VQA dataset by annotating complementary image pairs ( <ref type="bibr" target="#b14">Goyal et al., 2016)</ref>.</p><p>Reducing gender/racial bias Prior work has sought to reduce demographic biases in word em- beddings ( <ref type="bibr" target="#b54">Zhang et al., 2018</ref>) as well as in image recognition models ( <ref type="bibr" target="#b56">Zhao et al., 2017)</ref>. Our work has focused on producing a dataset with minimal annotation artifacts, which in turn helps to avoid some gender and racial biases that stem from elic- itation ( <ref type="bibr" target="#b55">Rudinger et al., 2017)</ref>. However, it is not perfect in this regard, particularly due to biases in movies ( <ref type="bibr" target="#b42">Schofield and Mehr, 2016;</ref>. Our methodology could potentially be ex- tended to construct datasets free of (possibly inter- sectional) gender or racial bias.</p><p>Physical knowledge Prior work has studied learning grounded knowledge about objects and verbs: from knowledge bases ( <ref type="bibr" target="#b25">Li et al., 2016)</ref>, syn- tax parses <ref type="bibr" target="#b11">(Forbes and Choi, 2017)</ref>, word embed- dings ( <ref type="bibr" target="#b27">Lucy and Gauthier, 2017)</ref>, and images and dictionary definitions ( <ref type="bibr" target="#b52">Zellers and Choi, 2017</ref>). An alternate thread of work has been to learn scripts: high-level representations of event chains <ref type="bibr" target="#b41">(Schank and Abelson, 1975;</ref><ref type="bibr" target="#b3">Chambers and Jurafsky, 2009</ref>). Swag evaluates both of these strands. <ref type="bibr">14</ref> Prior work on sentence completion filtered negatives with heuristics based on LM perplexities. We initially tried something similar, but found the result to still be gameable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We propose a new challenge of physically situated commonsense inference that broadens the scope of natural language inference (NLI) with com- monsense reasoning. To support research toward commonsense NLI, we create a large-scale dataset Swag with 113k multiple-choice questions. Our dataset is constructed using Adversarial Filtering (AF), a new paradigm for robust and cost-effective dataset construction that allows datasets to be con- structed at scale while automatically reducing an- notation artifacts that can be easily detected by a committee of strong baseline models. Our adver- sarial filtering paradigm is general, allowing po- tential applications to other datasets that require human composition of question answer pairs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 .</head><label>1</label><figDesc>A multilayer perceptron (MLP) given LM per- plexity features and context/ending lengths. 2. A bag-of-words model that averages the word embeddings of the second sentence as features. 3. A one-layer CNN, with filter sizes ranging from 2-5, over the second sentence. 4. A bidirectional LSTM over the 100 most com- mon words in the second sentence; uncommon words are replaced by their POS tags. We ensemble the models by concatenating their fi- nal representations and passing it through an MLP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Top: Distribution of the 40 top verbs in the union of SNLI and Swag. Our dataset shows a greater variety of dynamic verbs, such as "move", as well as temporal verbs such as "start" and "come." "Continue" is cut off for SNLI (it has frequency 6 · 10 −5 ). Bottom: CDF for verbs in SNLI and Swag.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples from Swag; the correct an-
swer is bolded. Adversarial Filtering ensures that 
stylistic models find all options equally appealing. 

linguistic entailment (Chierchia and McConnell-
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>1 Short for Situations With Adversarial Generations.</head><label>1</label><figDesc></figDesc><table>is put on top of the 
vegetables. 
is putting vegetable fruits. 
is using a red sponge to add 
eggs and parsley. 

⋮ 

is placed in the oven. 

The mixer creams the butter. Sugar… 

Adversarially select 
generations 

Annotators filter endings 
to ensure agreement 

Oversample 
endings from 
context+NP 

Sugar is added to the mixing bowl. 
The mixer creams the butter. 

LSMDC 

NP 
VP 
context 

Using video captions from 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>. Recall that models</head><label></label><figDesc></figDesc><table>Label distribution by 
ending type 

Inter-annotator 
agreement 
Labels Found end Gen. end 
α 
ppa 
Best 
53.5% 
9.3% 
0.43 
72% 
Second Best 
20.2% 
15.9% 
Neither 
26.3% 
74.8% 
Likely 
80.3% 
33.3% 
0.39 
64% 
Unlikely 
19.0% 
57.5% 
Gibberish 
0.7% 
9.1% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>found+gen found only found+gen found only found+gen Model Val Test Val Test Val Test Val Test Val Test Val Test</head><label></label><figDesc></figDesc><table>Ending only 
2nd sentence only 
Context+2nd sentence 
found only misc 

Random 
25.0 25.0 25.0 25.0 25.0 25.0 25.0 25.0 25.0 25.0 25.0 25.0 
Length 
26.7 27.0 26.7 27.0 
ConceptNet 
26.0 26.0 26.0 26.0 

Unary models 

fastText 
27.5 26.9 29.9 29.0 29.2 27.8 29.8 29.0 29.4 28.0 30.3 29.8 
Sentence 
encoders 

SkipThoughts 
32.4 32.1 32.2 31.8 33.0 32.4 32.8 32.3 
InferSent 
30.6 30.2 32.0 31.9 33.2 32.0 34.0 32.6 
LSTM 
sequence 
model 

LSTM+GloVe 
31.9 31.8 32.9 32.4 32.7 32.4 34.3 33.5 43.1 43.6 45.6 45.7 
LSTM+Numberbatch 
32.4 32.6 32.3 31.9 31.9 31.9 34.1 32.8 39.9 40.2 41.2 40.5 
LSTM+ELMo 
43.6 42.9 43.3 42.3 47.4 46.7 46.3 46.0 51.4 50.6 51.3 50.4 

Binary models 

DualBoW 
DualBoW+GloVe 
31.3 31.3 31.9 31.2 34.5 34.7 32.9 33.1 
DualBoW+Numberbatch 
31.9 31.4 31.6 31.3 35.1 35.1 34.2 34.1 

Dual 
sentence 
encoders 

SkipThoughts-MLP 
34.6 33.9 36.2 35.5 33.4 32.3 37.4 36.4 
SkipThoughts-Bilinear 
36.0 35.7 34.7 34.5 36.5 35.6 35.3 34.9 
InferSent-MLP 
32.9 32.1 32.8 32.7 35.9 36.2 39.5 39.4 
InferSent-Bilinear 
32.0 31.3 31.6 31.3 40.5 40.3 39.0 38.4 
SNLI 
inference 

SNLI-ESIM 
36.4 36.1 36.2 36.0 
SNLI-DecompAttn 
35.8 35.8 35.8 35.7 

SNLI 
models 
(retrained) 

DecompAttn+GloVe 
29.8 30.3 31.1 31.7 47.4 47.6 48.5 48.6 
DecompAttn+Numberbatch 
32.4 31.7 32.5 31.9 47.4 48.0 48.0 48.3 
DecompAttn+ELMo 
43.4 43.4 40.6 40.3 47.7 47.3 46.0 45.4 
ESIM+GloVe 
34.8 35.1 36.3 36.7 51.9 52.7 52.5 52.5 
ESIM+Numberbatch 
33.1 32.6 33.0 32.4 46.5 46.4 44.0 44.6 
ESIM+ELMo 
46.0 45.7 45.9 44.8 59.1 59.2 58.7 58.5 

Human 

1 turker 
82.8 
3 turkers 
85.1 
5 turkers 
88.0 
Expert 
85.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Example questions answered by the best model, ESIM+Elmo, sorted by model probability. 
Correct model predictions are in blue, incorrect model predictions are red. The right answers are bolded. 

</table></figure>

			<note place="foot" n="2"> We filter out sentences with rare tokens (≤3 occurrences), that are short (l ≤ 5), or that lack a verb phrase.</note>

			<note place="foot" n="3"> To ensure that the LM generates unique endings, we split the data into five validation folds and train five separate LMs, one for each set of training folds. This means that each LM never sees the found endings during training.</note>

			<note place="foot" n="5"> These two examples share contexts. To prevent biasing the test and validation sets, we didn&apos;t perform this procedure on answers from the evaluation sets&apos; context. 6 To be data-efficient, we reannotated filtered-out examples by replacing gibberish endings, as well as generations that outranked the found ending, with candidates from A.</note>

			<note place="foot" n="7"> The fastText model is trained using binary cross-entropy; at test time we extract the prediction by selecting the ending with the highest positive likelihood under the model.</note>

			<note place="foot" n="8"> We also tried using an MLP, but got worse results.</note>

			<note place="foot" n="9"> We used the relations &apos;Causes&apos;, &apos;CapableOf&apos;, &apos;ReceivesAction&apos;, &apos;UsedFor&apos;, and &apos;HasSubevent&apos;. Though their coverage is low (30.4% of questions have an answer with ≥1 causal relation), the more frequent relations in ConceptNet, such as &apos;IsA&apos;, at best only indirectly relate to our task.</note>

			<note place="foot" n="13"> For RocStories, this was by design to encourage learning from the larger corpus of 98k sensible stories.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the anonymous reviewers, members of the ARK and xlab at the University of Wash-ington, researchers at the Allen Institute for AI, and Luke Zettlemoyer for their helpful feed-back. We also thank the Mechanical Turk work-ers for doing a fantastic job with the human val-idation. This work was supported by the Na-tional Science Foundation Graduate Research Fel-lowship (DGE-1256082), the NSF grant (IIS-1524371, 1703166), the DARPA CwC program through ARO (W911NF-15-1-0543), the IARPA DIVA program through D17PC00343, and gifts by Google and Facebook. The views and conclu-sions contained herein are those of the authors and should not be interpreted as representing endorse-ments of IARPA, DOI/IBC, or the U.S. Govern-ment.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The berkeley framenet project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Collin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John B</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th international conference on Computational linguistics</title>
		<meeting>the 17th international conference on Computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="86" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1721" />
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pay attention to the ending: Strong neural baselines for the roc story cloze task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="616" to="622" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Narrative Schemas and Their Participants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="602" to="610" />
		</imprint>
	</monogr>
	<note>ACL &apos;09</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Enhanced lstm for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1657" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Meaning and Grammar (2Nd Ed.): An Introduction to Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gennaro</forename><surname>Chierchia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sally</forename><surname>Mcconnell-Ginet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo¨ıclo¨ıc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="670" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A framework for computational semantics (fracas)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dick</forename><surname>Crouch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Eijckl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Genabith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Japars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Milward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poesio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
	<note>The FraCaS Consortium</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Who let the dogs out? modeling dog behavior from visual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiana</forename><surname>Ehsani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hessam</forename><surname>Bagherinezhad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roozbeh</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">What will happen next? forecasting player moves in sports videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panna</forename><surname>Felsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pulkit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3342" to="3351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Verb physics: Relative physical knowledge of actions and objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="266" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The ecological approach to visual perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Houghton Mifflin Comp</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Breaking nli systems with sentences that require simple lexical inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Glockner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="650" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Making the V in VQA matter: Elevating the role of image understanding in</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tejas</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Summers-Stay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.00837</idno>
	</analytic>
	<monogr>
		<title level="m">Visual Question Answering</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Annotation artifacts in natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Suchin Gururangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="107" to="112" />
		</imprint>
	</monogr>
	<note>Short Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Activitynet: A large-scale video benchmark for human activity understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Fabian Caba Heilbron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Escorcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Niebles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="961" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning to write with cooperative discriminators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Visual storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Hao Kenneth</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Ferraro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1233" to="1239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Revisiting visual question answering baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Jabri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="727" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bag of tricks for efficient text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter<address><addrLine>Short Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="427" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dense-Captioning Events in Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Natural language inference from multiple premises</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="100" to="109" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Commonsense knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aynaz</forename><surname>Taheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1445" to="1455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Types of common-sense knowledge needed for recognizing textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Lobue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="329" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Are distributional representations ready for the real world? evaluating word vectors for grounded perceptual meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Lucy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Gauthier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Language Grounding for Robotics</title>
		<meeting>the First Workshop on Language Grounding for Robotics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="76" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A sick cure for the evaluation of compositional distributional semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="14" to="1314" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA). ACL Anthology Identifier</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A corpus and evaluation framework for deeper understanding of commonsense stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiadong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The lambada dataset: Word prediction requiring a broad discourse context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Paperno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Quan</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><surname>Pezzelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Fernandez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1525" to="1534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A decomposable attention model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2249" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multitask video captioning with video and entailment generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakanth</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Vancouver</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1273" to="1283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multireward reinforced summarization with saliency and entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakanth</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="646" to="653" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Plummer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">C</forename><surname>Cervantes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Caicedo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="74" to="93" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Hypothesis Only Baselines in Natural Language Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aparajita</forename><surname>Haldar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on Lexical and Computational Semantics (StarSem)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Roemmele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew S</forename><surname>Cosmin Adrian Bejan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<title level="m">Workshop on Ethics in Natural Language Processing</title>
		<imprint>
			<biblScope unit="page" from="74" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Connotation frames of power and agency in modern films</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><forename type="middle">Cindy</forename><surname>Prasettio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2329" to="2334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Scripts, plans, and knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Schank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 4th International Joint Conference on Artificial Intelligence<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1975" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="151" to="157" />
		</imprint>
	</monogr>
	<note>IJCAI&apos;75</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Genderdistinguishing features in film dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Schofield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Mehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Workshop on Computational Linguistics for Literature</title>
		<meeting>the Fifth Workshop on Computational Linguistics for Literature</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="32" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The effect of different writing tasks on linguistic style: A case study of the ROC story cloze task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Tackling the story ending biases in the story cloze test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishi</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omid</forename><surname>Bakhshandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="752" to="757" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Conceptnet 5.5: An open multilingual graph of general knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4444" to="4451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A minimal span-based neural constituency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="818" to="827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Information Science and Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Nature of Statistical Learning Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>2 edition</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amapreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07461</idno>
		<title level="m">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1112" to="1122" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Licheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunbyung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
		<title level="m">Visual Madlibs: Fill in the blank Image Generation and Question Answering. ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Zero-shot activity recognition with verb attribute induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Neural motifs: Scene graph parsing with global context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Mitigating unwanted biases with adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Hu Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blake</forename><surname>Lemoine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>Ethics and Society</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Ordinal Common-sense Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="379" to="395" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Men also like shopping: Reducing gender bias amplification using corpus-level constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2979" to="2989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Aligning books and movies: Towards story-like visual explanations by watching movies and reading books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<idno type="arXiv">arXivpreprintarXiv:1506.06724</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">The microsoft research sentence completion challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burges</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
