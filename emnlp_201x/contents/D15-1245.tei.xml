<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Any-language frame-semantic parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Héctor</roleName><forename type="first">Anders</forename><surname>Johannsen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<addrLine>Denmark Njalsgade 140</addrLine>
									<postCode>DK-2300</postCode>
									<settlement>Copenhagen S</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martínez</forename><surname>Alonso</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<addrLine>Denmark Njalsgade 140</addrLine>
									<postCode>DK-2300</postCode>
									<settlement>Copenhagen S</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<addrLine>Denmark Njalsgade 140</addrLine>
									<postCode>DK-2300</postCode>
									<settlement>Copenhagen S</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Any-language frame-semantic parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a multilingual corpus of Wikipedia and Twitter texts annotated with FRAMENET 1.5 semantic frames in nine different languages, as well as a novel technique for weakly supervised cross-lingual frame-semantic parsing. Our approach only assumes the existence of linked, comparable source and target language corpora (e.g., Wikipedia) and a bilingual dictionary (e.g., Wiktionary or BABELNET). Our approach uses a truly interlingual representation, enabling us to use the same model across all nine languages. We present average error reductions over running a state-of-the-art parser on word-to-word translations of 46% for target identification, 37% for frame identification , and 14% for argument identification .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Frame-semantic parsing is the task of automati- cally finding semantically salient targets in text, disambiguating the targets by assigning a sense (frame) to them, identifying their arguments, and labeling these arguments with appropriate roles. The FRAMENET 1.5 lexicon 1 provides a fixed repository of semantic frames and roles, which we use in the experiments below.</p><p>Several learning and parsing algorithms have been developed for frame-semantic analysis <ref type="bibr" target="#b3">(Johansson and Nugues, 2007;</ref><ref type="bibr" target="#b8">Täckström et al., 2015)</ref>, and frame semantics has been successfully applied to question-answering <ref type="bibr" target="#b4">(Shen and Lapata, 2007)</ref>, information extraction <ref type="bibr" target="#b7">(Surdeanu et al., 2003</ref>) and knowledge extraction <ref type="bibr">(Søgaard et al., 2015b</ref>).</p><p>1 https://framenet.icsi.berkeley.edu/ In contrast to Propbank-style semantic-role la- beling ( <ref type="bibr" target="#b9">Titov and Klementiev, 2012)</ref>, only very limited frame-semantic resources exist for lan- guages other than English. We therefore fo- cus on multilingual or cross-language frame- semantic parsing, leveraging resources for English and other major languages to build any-language parsers. We stress that we learn frame-semantic parsing models that can be applied to any lan- guage, rather than cross-lingual transfer models for specific target languages. Our approach re- lies on inter-lingual word embeddings ( <ref type="bibr">Søgaard et al., 2015a</ref>), which are built from topic-aligned documents. Word embeddings have previously been used for monolingual frame-semantic pars- ing by <ref type="bibr" target="#b2">Hermann et al. (2014)</ref>.</p><p>Contributions This paper makes the following three contributions. We present a new multi- lingual frame-annotated corpus covering five top- ics, two domains (Wikipedia and Twitter), and nine languages. We implement a simplified ver- sion of the frame-semantic parser introduced in . Finally, we show how to modify this parser to learn any-language frame-semantic parsing models using inter-lingual word embed- dings ( <ref type="bibr">Søgaard et al., 2015a</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data annotation</head><p>Figure 1 depicts a FRAMENET 1.5 frame-semantic analysis of a German sentence from Wikipedia. The annotator marked two words, Idee and kam, as targets. In frame-semantic parsing, target iden- tification is the task of deciding which words (i.e. targets) trigger FRAMENET frames. Frame iden- tification is the problem of disambiguating targets by labeling them with frames, e.g., COGITATION or COMING_UP_WITH. Argument identification is the problem of identifying the arguments of frames, e.g., Idee for COMING_UP_WITH.</p><p>We had linguistically trained students anno- tate about 200 sentences from Wikipedia and 200 tweets each in their native language. The data was pre-annotated by obtaining all English trans- lation equivalents of the source language words through BABELNET 2 , finding associated frames in the FRAMENET 1.5 training data. We pre- sented annotators with all frames that could be triggered by any of the target word's transla- tions. Both data from Wikipedia and Twit- ter cover the same five topics: Google, An- gelina Jolie, Harry Potter, Women's Rights, and Christiano Ronaldo. The topics were chosen to guarantee coverage for all nine languages, both in Wikipedia and Twitter. Our corpus, which covers nine languages, is publicly avail- able at https://github.com/andersjo/ any-language-frames The languages we cover are Bulgarian (BG), Danish (DA), German (DE), Greek (EL), English (EN), Spanish (ES), French (FR), Italian (IT) and Swedish (SV). En- glish is included as a sanity check of our cross- lingual annotation setup. The English, Danish, and Spanish datasets were doubly-annotated in order to compute inter- annotator agreement (IAA). The overall target identification IAA was 82.4% F 1 for English, 81.6% for Danish, and 80.0% for Spanish. This is lower than a similar monolingual annotation experiment recently reporting target identification IAA at 95.3% ( <ref type="bibr">Søgaard et al., 2015b</ref>). The frame identification IAA scores were also higher in that study, at 84.5% and 78.1% F 1 . The drop in agreement seems mostly due to pre-tagging er- rors caused by erroneous or irrelevant word-to- word translations. The Spanish data has the lowest agreement score.</p><p>We compute test-retest reliability of our anno- tations as the correlation coefficient (Pearson's ρ) between the two annotations. In Cronbach's α in- ternal consistency table, the cut-off for acceptable reliability is 0.7. While there is certainly noise in our annotations, these are still consistently above the Cronbach cut-off. Also, we evaluate our mod- els across 18 datasets, covering nine different lan- guages with two domains each; although for read- ability, we combine the Wiktionary and Twitter datasets for each language below. The relatively low reliability compared to pre- vious annotation efforts is due to the cross-lingual pre-annotation step, which was necessary to make annotation feasible. All languages, including En- glish, have been pre-annotated using BABELNET. We expect annotators to only assign frames when meaningful frames can be assigned, so the main source of error is that the pre-annotation may ex- clude valid frames. Hence, we will not only re- port F 1 -scores in our evaluations, but also preci- sion, since recall may be misleading, penalizing for frames that could not be chosen by the annota- tors.</p><p>3 Frame semantic parsing</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Target identification</head><p>Following , we use part-of-speech heuristics to identify the words that evoke frames (target words). Frame-evoking words typically be- long to a narrow range of part of speech. There- fore, we only consider words as target candidates when tagged with one of the top k part-of-speech tags most commonly seen as targets in the train- ing set. The k parameter is optimized to maxi- mize F 1 on our development language, Spanish, where we found k = 7. 3 Surviving candidates are then translated into English by mapping the words into multi-lingual BABELNET synsets, which rep- resent sets of words with similar meaning across languages. All English words in the BABEL- NET synsets are considered possible translations. If any of the translations are potential targets in FRAMENET 1.5, the current word is identified as a frame-evoking word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Frame identification</head><p>A target word is, on average, ambiguous be- tween three frames. We use a multinomial log- linear classifier <ref type="bibr">4</ref> (with default parameters) to de- cide which of the possible frames evoked by the target word that fits the context best. Our feature representation replicates that of  as far as possible, considering the multilingual set- ting where lexical features cannot be directly used. To compensate for the lack of lexical features, we introduce two groups of language-independent features that rely on multilingual word embed- dings. One feature group uses the embedding of the target word directly, while the other is based on distance measures between the target word and the set of English words used as targets for a possible frame. We measure the minimum and mean dis- tance (in embedding space) from the target word to the set of English target words, as well as the distances to each word individually.</p><p>Several of the features in the original repre- sentation are built on top of automatic POS an- notation and syntactic parses. We use the Uni- versal Dependencies v1.1 treebanks for the lan- guages in our data to train part-of-speech taggers (TREETAGGER 5 ) and a dependency parser (TUR- BOPARSER 6 ) to generate the syntactic features. In contrast to , we use dependency subtrees instead of spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Argument identification</head><p>A frame contains a number of named arguments that may or may not be expressed in a given sen- tence. Argument identification is concerned with assigning frame arguments to spans of words in the sentence. While this task can benefit from in- formation on the joint assignment of arguments,  report only an improvement of less than 1% in F 1 using beam search to approxi- mate a global optimal configuration for argument identification. To simplify our system, we take all argument-identification decisions independently. We use a single classifier for argument identifica- tion, computing the most probable argument for each frame element. Each word index is associ- ated with a span by the transitive closure of its syn- tactic dependencies (i.e. subtree). Our greedy ap- proach to argument identification thus amounts to scoring the n + 1 possible realisations of an argu- ment for an n-length sentence (i.e. subtrees plus the empty argument), selecting the highest scor- ing subtree for each argument type allowed by the frame.</p><p>As the training data contains very few examples of each frame or role (e.g., Buyer in the frame COMMERCE_SCENARIO), we enable sharing of features for frame arguments that have the same name. The assumption is that arguments with identical names have similar semantic properties across frames; that is the argument Perpetrator, for example, is similar for the frames ARSON and THEFT.</p><p>The scores are the confidences of a binary clas- sifier trained on &lt;frame, argument, subtree&gt; tu- ples. Positive examples are the observed argu- ments. We use the remaining n incorrect subtrees for a given &lt;frame, argument&gt; pair to generate negative training examples . A single binary clas- sification model is trained for the whole data set.</p><p>As with frame identification, our features are similar to those of , with a few exceptions and additions. We use dependency sub- trees instead of spans and replace all lexical fea- tures (which do not transfer cross-lingually) with features based on the interlingual word embed- dings from <ref type="bibr">Søgaard et al. (2015a)</ref>. We use the embeddings to find the 20 most similar words in the training data and use these words to generate lexical features that matched the source-language training data. Each feature is weighted by its co- sine similarity with the target-language word.   Baseline Our approach to multi-lingual frame semantics parsing extends  to cross-lingual learning using the interlingual em- beddings from <ref type="bibr">Søgaard et al. (2015a)</ref>. Our base- line is a more direct application of the SEMAFOR system 7 ( ), translating target lan- guage text to English using word-to-word transla- tions and projecting annotation back. For word- to-word translation we use Wiktionary bilingual dictionaries <ref type="bibr">(Ács, 2014)</ref>, and we use frequency counts from UKWAC 8 to disambiguate words with multiple translations, preferring the most common one. The baseline and our system both use the training data supplied with FRAMENET for learn- ing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target identification</head><note type="other">BG DA DE EL EN ES FR IT SV Avg.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Consider first the target identification results in <ref type="table" target="#tab_0">Table 2</ref>. We observe that using BABELNET and our re-implementation of  per- forms considerably better than running SEMAFOR on Wiktionary word-by-word translations.</p><p>Our frame identification results are also pre-  <ref type="table" target="#tab_0">Table 2</ref>. Our system is better in six out of nine cases, whereas the most frequent sense base- line is best in two. It is unsurprising that English fares best in this setup, because it does not undergo the word-to-word translation of the other data sets. Argument identification is a harder task, and scores are generally lower; see the lower part of <ref type="table" target="#tab_0">Table 2</ref>. Also, note that errors percolate: If we do not identify a target, or mislabel a frame, we can no longer retrieve the correct arguments. Never- theless, we observe that we are better than running SEMAFOR on word-by-word translations in eight out of nine languages-all, except English.</p><p>Generally, we obtain error reductions over our baseline of 46% for target identification, 37% for frame identification, and 14% for argument iden- tification. For English, we are only 2% (absolute) below IAA for target identification, but about 40% below IAA for frame and argument identification. For Danish, the gap is smaller.</p><p>If we compare performance on Wikipedia and Twitter datasets, we see that target identifica- tion and frame identification scores are gener- ally higher for Wikipedia, while argument iden- tification scores are higher for Twitter. While Wikipedia is generally more similar to the newswire/balanced corpus in FRAMENET 1.5, the sentence length is shorter in tweets, making it eas- ier to identify the correct arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We presented a multi-lingual frame-annotated cor- pus covering nine languages in two domains. With this corpus we performed experiments to predict target, frame and argument identification, outperforming a word-to-word translated baseline running on SEMAFOR. Our approach is a de- lexicalized version of  with a sim- pler decoding strategy and, crucially, using multi- lingual word embeddings to achieve any-language frame-semantic parsing. Over a baseline of using SEMAFOR with word-to-word translations, we ob- tain error reductions of 46% for target identifica- tion, 37% for frame identification, and 14% for ar- gument identification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Frame semantic annotation from the German Wikipedia data (Women's Rights)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>2 http://babelnet.org/</head><label>2</label><figDesc></figDesc><table>Language 
EN 
DA 
ES 

Twitter and Wikipedia 
TARGET 
82.4 81.6 80.0 
FRAME 
73.5 72.3 60.8 
ARGUMENT 
70.7 55.0 83.5 
Test-retest reliability 
74.4 78.6 71.8 

Twitter 
TARGET 
79.1 80.7 80.5 
FRAME 
68.8 72.3 58.6 
ARGUMENT 
70.0 86.2 57.5 
Test-retest reliability 
71.0 78.7 73.1 

Table 1: Inter-annotator agreement (F 1 in %) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Frame semantic parsing results (precision and F 1 in %) 

</table></figure>

			<note place="foot" n="3"> The white-listed POS are nouns, verbs, adjectives, proper nouns, adverbs, and determiners. 4 http://hunch.net/~vw/ 5 http://www.cis.uni-muenchen.de/ ~schmid/tools/TreeTagger/ 6 http://www.cs.cmu.edu/~ark/ TurboParser/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pivot-based multilingual dictionary building using wiktionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judit</forename><surname>Ács</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Frame-semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="56" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic frame identification with distributed word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Extended constituent-to-dependency conversion for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NODALIDA</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using semantic roles to improve question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Inverted indexing for cross-lingual nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Željko</forename><surname>Agi´cagi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Héctor Martínez Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johannsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using frame semantics for knowledge extraction from twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector Martinez</forename><surname>Alonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using predicate-argument structures for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Aarseth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Efficient inference and structured learning for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Crosslingual induction of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
