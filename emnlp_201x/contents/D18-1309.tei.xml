<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Exhaustive Model for Nested Named Entity Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018. 2843</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Golam</forename><surname>Sohrab</surname></persName>
							<email>sohrab.mohammad@aist.go.jp, makoto-miwa@toyota-ti.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Research Center (AIRC)</orgName>
								<orgName type="institution">National Institute of Advanced Industrial Science and Technology (AIST)</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Research Center (AIRC)</orgName>
								<orgName type="institution">National Institute of Advanced Industrial Science and Technology (AIST)</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Toyota Technological Institute</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Exhaustive Model for Nested Named Entity Recognition</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2843" to="2849"/>
							<date type="published">October 31-November 4, 2018. 2018. 2843</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a simple deep neural model for nested named entity recognition (NER). Most NER models focused on flat entities and ignored nested entities, which failed to fully capture underlying semantic information in texts. The key idea of our model is to enumerate all possible regions or spans as potential entity mentions and classify them with deep neural networks. To reduce the computational costs and capture the information of the contexts around the regions, the model represents the regions using the outputs of shared underlying bidirectional long short-term memory. We evaluate our exhaustive model on the GENIA and JNLPBA corpora in biomedical domain, and the results show that our model outper-forms state-of-the-art models on nested and flat NER, achieving 77.1% and 78.4% respectively in terms of F-score, without any external knowledge resources.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named entity recognition (NER) is a task of find- ing entities with specific semantic types such as Protein, Cell, and RNA in text. NER is generally treated as a sequential labeling task, where each token is tagged with a label that corresponds to its surrounding entity. However, when entities over- lap or are nested within one another, treating the task as a sequential labeling task becomes diffi- cult because an individual token can be included in several entities and defining a label for each to- ken can be difficult. For example, in the following phrase from the GENIA corpus ( <ref type="bibr" target="#b11">Kim et al., 2004</ref>), four levels of nested entities occur and the token "IL-2" is a Protein on its own, and it is also a part of two other Proteins and one DNA.</p><p>[[[ <ref type="bibr">[IL-2]</ref> Protein receptor] Protein (IL-2R) alpha chain] Protein gene] DNA NER has drawn considerable attention as the first step towards many natural language pro- cessing (NLP) applications including relation ex- traction <ref type="bibr" target="#b17">(Miwa and Bansal, 2016)</ref>, event extrac- tion <ref type="bibr" target="#b4">(Feng et al., 2016)</ref>, co-reference resolu- tion <ref type="bibr" target="#b6">(Fragkou, 2017;</ref><ref type="bibr" target="#b21">Stone and Arora, 2017)</ref>, and entity linking ( <ref type="bibr" target="#b8">Gupta et al., 2017)</ref>. Much work on NER, however, has ignored nested entities and in- stead chosen to focus on the non-nested entities, which are also referred to as flat entities. Only a few studies target the nested named entity recog- nition ( <ref type="bibr" target="#b18">Muis and Lu, 2017;</ref><ref type="bibr" target="#b15">Lu and Roth, 2015;</ref><ref type="bibr" target="#b5">Finkel and Manning, 2009)</ref>.</p><p>Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several do- mains ( <ref type="bibr" target="#b14">Lample et al., 2016;</ref><ref type="bibr" target="#b16">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b7">Gridach, 2017;</ref><ref type="bibr" target="#b22">Strubell et al., 2017)</ref>. Such models achieve state-of-the-art results without requiring any hand crafted features or external knowledge resources. In contrast, fewer approaches have emphasized the nested entity recognition problem. Existing approaches to nested NER ( <ref type="bibr" target="#b19">Shen et al., 2003;</ref><ref type="bibr" target="#b0">Alex et al., 2007;</ref><ref type="bibr" target="#b5">Finkel and Manning, 2009;</ref><ref type="bibr" target="#b15">Lu and Roth, 2015;</ref><ref type="bibr" target="#b23">Xu et al., 2017;</ref><ref type="bibr" target="#b18">Muis and Lu, 2017)</ref> are mostly feature-based and thus suffer from heavy feature engineering. In this paper, we present a novel neural exhaustive model that reasons over all the regions within a specified maximum size. The model represents each region using the outputs of bidirectional long short-term memory (LSTM) by combining the boundary representation of a region and inside representation that simply treats all the tokens in a region equally by taking the average of LSTM outputs corresponding to tokens inside the region. It then classifies regions into their entity types or non-entity. Unlike the existing model that relies on token-level labels, our model directly employs an entity type as the label of a region. The model does not rely on any external knowledge resources or NLP tools like part-of-speech taggers. We evaluated our model on the GENIA and JNLPBA corpora in the biomedical domain and the model achieved 77.1% and 78.4% respectively in terms of F-score, which are the new state-of-the-art performances on the corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Neural Exhaustive Model</head><p>The proposed model exhaustively considers all possible regions in a sentence using a single neu- ral network; we thus call the model neural exhaus- tive model. Our model is built upon a shared bidi- rectional LSTM layer. The model enumerates all possible regions or spans that can include all the nested entities. It then represent the regions by us- ing the outputs of the LSTM layer and detect the entities from the regions. The number of possible regions depend on the predefined maximum size. In this section, we describe the architecture of our neural exhaustive model in detail, which is sum- marized in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Word Representation</head><p>We represent each word by concatenating word embeddings and character-based word representa- tions. Pre-trained word embeddings are used to initialize word embeddings ( <ref type="bibr" target="#b2">Chiu et al., 2016</ref>). For the character-based word representations, we en- code the character-level information of each word following the successes of <ref type="bibr" target="#b16">Ma and Hovy (2016)</ref> and <ref type="bibr" target="#b14">Lample et al. (2016)</ref> that utilized character embeddings for the flat NER task. The embedding of each character in a word is randomly initial- ized. We feed the sequence of character embed- dings comprising a word to a bidirectional LSTM layer and concatenate the forward and backward output representations to obtain the word repre- sentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Exhaustive Combination using LSTM</head><p>Given an input sentence sequence X = {x 1 , x 2 , ...x n }, where x i denotes the i-th word and n denotes the number of words in the sentence se- quence, the distributed embeddings of words and characters are fed into a bidirectional LSTM layer that computes the hidden vector sequence in for- ward</p><formula xml:id="formula_0">− → h = − → h 1 , − → h 2 , . . . , − → h n and backward ← − h = ← − h 1 , ← − h 2 , . . . , ← − h n manners.</formula><p>We concatenate the forward and backward outputs as</p><formula xml:id="formula_1">h i = − → h i ; ← − h i ,</formula><p>where [; ] denotes concatenation. With the LSTM output h i , our exhaustive model shares the underlying representations of all possi- ble regions by exhaustive combination. We gen- erate all possible regions with the sizes less than or equal to the maximum region size L. We use a region(i, j) to represent the region from i to j inclusive, where 1 ≤ i &lt; j ≤ n and j − i &lt; L.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Region Representation and Classification</head><p>We represent the region by separating the region into the boundary and inside representations. The boundary representation is important to capture the contexts surrounding the region. We sim- ply rely on the outputs of the bidirectional LSTM layer corresponding to the boundary words of a target region for this purpose. For the inside rep- resentation, we simply average the outputs of the bidirectional LSTM layer in the region to treat them equally. We include the outputs for the boundary words to guarantee that the inside rep- resentation has corresponding outputs. In sum- mary, we obtain the representation R(i, j) of the region(i, j) as follows:</p><formula xml:id="formula_2">R(i, j) = h i ; 1 j − i + 1 j k=i h k ; h j .<label>(1)</label></formula><p>We then feed the representation of each seg- mented region to a rectified linear unit (ReLU) as an activation function. Finally, the output of the activation layer is passed to a softmax output layer to classify the region into a specific entity type or non-entity.</p><p>The exhaustive model represents all possible re- gions based on maximum entity length and clas- sify all of them. The overall number of classifi- cations for each sentence in the exhaustive model is in O(lmn), where l is a total number of words in the sentence, m is the maximum entity length and n is the total number of possible entity types. <ref type="bibr" target="#b5">Finkel and Manning (2009)</ref> and <ref type="bibr" target="#b0">Alex et al. (2007)</ref> proposed featured-based approaches for handling nested NER. The time complexity of their mod- els are expensive, i.e., cubic in the number of the words in the sentence. The exhaustive approach is fast since we run the LSTM once and the classifi- cations can be performed in parallel on the combi- nations created from the LSTM outputs.</p><p>The exhaustive model classify each region inde- pendently unlike word-level taggers. This makes the model flexible so that it can incorporate <ref type="figure">Figure 1</ref>: Architecture of the proposed neural exhaustive model. The model considers all possible regions up to a maximum size, but we depict here only a small subset for brevity. "IL-2", "IL-2 receptor", "IL-2 receptor (IL-2R) alpha", and "IL-2 receptor (IL-2R) alpha chain gene" are nested entities.</p><p>phrase-level dictionary information directly and we can tune biases for each type unlike CRF. We leave this evaluation to our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Settings</head><p>We evaluated our exhaustive model on GE- NIA 1 ( <ref type="bibr" target="#b12">Kim et al., 2003)</ref> and JNLPBA 2 ( <ref type="bibr" target="#b11">Kim et al., 2004</ref>) datasets to provide empirical evidence for the effectiveness of our model both in nested and flat NER. <ref type="table">Table 1</ref> shows the statistics of GENIA dataset.</p><p>Our model was implemented in Chainer 3 deep learning framework. We employed pre-trained word embeddings that were trained on MEDLINE abstracts ( <ref type="bibr" target="#b2">Chiu et al., 2016)</ref>, which included 200- dimensional embeddings of 2,231,686 vocabulary. We used ADAM ( <ref type="bibr" target="#b13">Kingma and Ba., 2015)</ref> for learning with a mini-batch size of 100. We used the same hyper-parameters in all the experiments; we set the dimension of word embedding to 200, the dimension of character embedding to 25, the hidden layer size to 200, the gradient clipping to 5, and the ADAM hyper-parameters to its default values ( <ref type="bibr" target="#b13">Kingma and Ba., 2015</ref> To deeply understand the model parameters, we compared the models in different regions. We chose the maximum region size from 3, 6, 8 and 10. We also employed different region repre- sentation. We tried only the boundary represen- tation (boundary), only the inside representation (inside), and our region representation (bound- ary+inside).</p><p>We employed precision, recall, and F-score to   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model P(%) R(%) F(%) Exhaustive Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussions</head><p>4.1 Nested NER <ref type="table" target="#tab_2">Table 2</ref> shows the comparison of our model with several previous state-of-the nested NER models on the test dataset. Our model outperforms the state-of-the-art models in terms of F-score. Our results on <ref type="table" target="#tab_2">Table 2</ref> is based on bidirectional LSTM with character embeddings and the maximum re- gion size is 10. <ref type="table" target="#tab_3">Table 3</ref> describes the performances of our model on different entity levels on the test dataset. The model performs well on multi-token and top- level entities. This is interesting because they are often considered difficult for sequential labeling models. <ref type="table" target="#tab_4">Table 4</ref> shows the performances on the five entity types on the test dataset. We here show the performance by <ref type="bibr" target="#b5">Finkel and Manning (2009)</ref> (F&amp;M) for the reference. Our system performs better than their model except for the RNA type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Tests</head><p>We show the differences in the performance on the development dataset to compare the possible sce- narios of the proposed approach and to report the Label P(%) R(%) F(%) F&amp;M F(%) DNA 92.6 58.7 71.8 65.2 RNA 98.8 57.1 72.4 74.7 cell line 94.6 53.1 67.9 64.0 cell type 88.4 70.0 78.1 67.1 protein 94.1 70.8 80.8 73.8    importance of each component in our exhaustive model. <ref type="table" target="#tab_5">Table 5</ref> shows the coverage ratio and the per- formance with different maximum region sizes. Since the average entity mention length of GE- NIA dataset is less than 4, the system can cover almost all the entities for the maximum sizes of 6 or more. The longer maximum region size is desirable to cover all the mentions, but it requires more computational costs. Fortunately, the per- formance did not degrade with the long maximum region size, despite the fact that it introduces more out-of-entity regions.</p><p>Ablations on character embeddings in <ref type="table" target="#tab_6">Table 6</ref> also show the importance of character embed- dings. It also shows that both the boundary infor- mation and the inside information, i.e., average of the embeddings in a region, are necessary to im- prove the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Flat NER</head><p>We evaluated our model on JNLPBA as a flat dataset, where nested and discontinuous entities are removed. <ref type="table" target="#tab_7">Table 7</ref> shows the performances of our model on JNLPBA dataset. We compared our result with the state-of-the-art result of Gridach (2017) which achieved 75.8% in F-score, where our model obtained 78.4% in terms of F-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Interests in nested NER detection have increased in recent years, but it is still the case that NER models deals with only one flat level at a time. <ref type="bibr" target="#b24">Zhou et al. (2004)</ref> detected nested entities in a bottom-up way. They detected the innermost flat entities and then found other NEs containing the flat entities as substrings using rules derived from the detected entities. The authors reported an improvement of around 3% in the F-score un- der certain conditions on the GENIA corpus <ref type="bibr" target="#b3">(Collier et al., 1999</ref>). <ref type="bibr" target="#b10">Katiyar and Cardie (2018)</ref> pro- posed a neural network-based approach that learns hypergraph representation for nested entities us- ing features extracted from a recurrent neural net- work (RNN). The authors reported that the model outperformed the existing state-of-the-art feature- based approaches.</p><p>Recent studies show that the conditional ran- dom fields (CRFs) can significantly produce higher tagging accuracy in flat ( <ref type="bibr" target="#b1">Athavale et al., 2016)</ref> or nested (stacking flat NER to nested rep- resentation) (Son and Minh, 2017) NERs. <ref type="bibr" target="#b9">Ju et al. (2018)</ref> proposed a novel neural model to ad- dress nested entities by dynamically stacking flat NER layers until no outer entities are extracted. A cascaded CRF layer is used after the LSTM output in each flat layer. The authors reported that the model outperforms state-of-the-art results by achieving 74.5% in terms of F-score. <ref type="bibr" target="#b5">Finkel and Manning (2009)</ref> proposed a tree-based rep- resentation to represent each sentence as a con- stituency tree of nested entities. All entities were treated as phrases and represented as subtrees fol- lowing the whole tree structure and used a CRF- based approach driven by entity-level features to detect nested entities. We demonstrate that the performance can be improved significantly with- out CRFs, by training an exhaustive neural model that learns which regions are entity mentions and how to best classify the regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper presented a neural exhaustive model that considers all possible regions exhaustively for nested NER. The model obtains the representation of each region from an underlying shared LSTM layer, and it represents the region by concatenat- ing boundary representations of the region and in- side representation that averages embeddings of words in the region. It then classifies the region into its entity type or non-entity. The model does not depend on any external NLP tools. In the ex- periment, we show that our model learns to detect nested named entities from the generated mention candidates of all possible regions. Our exhaustive model outperformed existing models with a sig- nificant margin in terms of F-score in both flat and nested NER.</p><p>For future work, we would like to investigate the use of region-level information. We also consider modeling the dependencies between regions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>Item 
Train 
Dev 
Test 
Documents 
1,599 
189 
212 
Sentences 
15,022 1,669 1,855 
Split(%) 
81 
9 
10 
DNA 
7,921 
1061 1,283 
RNA 
730 
140 
117-
protein 
29,032 2,338 3,098 
cell line 
3,149 
340 
460 
cell type 
6,021 
563 
617 
outermost entity 
42,462 4,020 4,942 
nested level 
4 
3 
3 
entity avg. length 
2.87 
3.13 
2.93 
multi-token entity 
33951 3554 4203 
overall nested entity 8301 
803 
1202 
overall entity 
46,853 4,442 5,575 

Table 1: Statistics of GENIA 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance comparison of the state-of-
the-art nested NER models on the test dataset. 

Entity Level P(%) R(%) F(%) 
Single-token 91.6 58.4 
69.9 
Multi-token 95.9 65.8 
77.9 
Top Level 
92.7 69.8 
79.3 
Nested 
94.3 59.3 
72.7 
All entities 
93.2 64.0 
77.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Performances of our model on different 
entity level on the test dataset. 

evaluate our model. We also compared the perfor-
mances for single-token v.s. multi-token entities 
and top-level v.s. nested entities. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Categorical performances on the GENIA 
test dataset. 

Region 
Ratio(%) P(%) R(%) F(%) 
size = 3 
89.6 
92.9 69.8 
79.5 
size = 6 
98.9 
93.6 66.7 
77.5 
size = 8 
99.4 
93.7 66.5 
77.6 
size = 10 100 
93.5 67.6 
78.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Performance of our model with differ-
ent maximum region sizes on the development 
dataset. Ratio refers to the coverage ratio of en-
tity mentions. 

Setting 
P(%) R(%) F(%) 
Bi-LSTM 
94.1 65.7 
77.1 
Bi-LSTM + Character 93.5 67.6 
78.2 
Boundary 
94.1 54.3 
68.5 
Inside 
93.2 46.4 
61.2 
Boundary+Inside 
93.5 67.6 
78.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Performance of our model with different 
model architectures on the development dataset. 
indicates results using character embeddings. 

Label 
P(%) R(%) F(%) 
DNA 
95.2 56.8 
71.4 
RNA 
96.1 61.4 
75.2 
cell line 86.2 44.1 
58.8 
cell type 96.7 61.5 
75.3 
protein 
97.1 72.2 
82.6 
overall 
96.4 66.8 
78.4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Categorical and overall performances of 
the JNLPBA test dataset. 

</table></figure>

			<note place="foot" n="1"> http://www.geniaproject.org/ genia-corpus/term-corpus 2 http://www.nactem.ac.uk/tsujii/GENIA/ ERtask/report.html 3 https://chainer.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their valu-able comments. This paper is based on results ob-tained from a project commissioned by the New Energy and Industrial Technology Development Organization (NEDO).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recognising Nested Named Entities in Biomedical Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing</title>
		<meeting>the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing<address><addrLine>Stroudsburg, PA, USA. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Towards Deep Learning in Hindi NER: An approach to tackle the Labelled Data Scarcity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreenivas</forename><surname>Vinayak Athavale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monik</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameya</forename><surname>Pamecha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shrivastava</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
		<respStmt>
			<orgName>Cornell University Library</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">How to Train good Word Embeddings for Biomedical NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Billy</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gamal</forename><surname>Crichton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Workshop on Biomedical Natural Language Processing</title>
		<meeting>the 15th Workshop on Biomedical Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="166" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The GENIA Project: Corpusbased Knowledge Acquisition and Information Extraction from Genome Research Papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Collier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Nobata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sekimizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Imai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ibushi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="171" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A LanguageIndependent Neural Network for Event Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the ACL</title>
		<meeting>the 54th Annual Meeting of the ACL<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nested Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manning</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Applying named entity recognition and co-reference resolution for segmenting english texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavlina</forename><surname>Fragkou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progress in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="325" to="346" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Character-level neural network for biomedical named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mourad</forename><surname>Gridach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="85" to="91" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Entity Linking via Joint Encoding of Types, Descriptions, and Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2671" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Neural Layered Model for Nested Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meizhi</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana. ACL</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1446" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Nested Named Entity Recognition Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="861" to="871" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Introduction to the Bio-Entity Recognition Task at JNLPBA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international joint workshop on natural language processing in biomedicine and its applications</title>
		<meeting>the international joint workshop on natural language processing in biomedicine and its applications</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="70" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">GENIA corpus-a semantically annotated corpus for bio-textmining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tateisi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="180" to="182" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>suppl. 1</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural Architectures for Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the ACL: Human Language Technologies. ACL</title>
		<meeting>the 2016 Conference of the North American Chapter of the ACL: Human Language Technologies. ACL<address><addrLine>San Diego, California. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Joint Mention Extraction and Classification with Mention Hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="857" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">End-to-end Sequence Labeling via Bi-directional LSTM-CNNsCRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the ACL</title>
		<meeting>the 54th Annual Meeting of the ACL<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1105" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Labeling Gaps Between Words: Recognizing Overlapping Mentions with Mention Separators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldrian</forename><surname>Obaja Muis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2598" to="2608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Effective Adaptation of a Hidden Markov Model-based Named Entity Recognizer for Biomedical Domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew-Lim</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2003 workshop on Natural language processing in biomedicine</title>
		<meeting>the ACL 2003 workshop on Natural language processing in biomedicine</meeting>
		<imprint>
			<publisher>Japan. ACL</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
	<note>Sapporo</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Nested Named Entity Recognition Using Multilayer Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><surname>Nguyen Truong Son And Nguyen Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of PACLING 2017</title>
		<meeting>PACLING 2017<address><addrLine>Sedona Hotel, Yangon, Myanmar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="16" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Identifying nominals with no head match co-references using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arora</surname></persName>
		</author>
		<idno>CoRR abs/1710.00936</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast and Accurate Entity Recognition with Iterated Dilated Convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2670" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Local Detection Approach for Named Entity Recognition and Mention Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingbin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sedtawut</forename><surname>Watcharawittayakul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the ACL</title>
		<meeting>the 55th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1237" to="1247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recognizing Names in Biomedical Texts: a</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chewlim</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Approach. Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1178" to="1190" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
