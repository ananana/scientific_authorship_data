<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Cross-Lingual Named Entity Recognition with Minimal Resources</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiateng</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
							<email>nasmith@cs.washington.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Cross-Lingual Named Entity Recognition with Minimal Resources</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="369" to="379"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>369</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>For languages with no annotated resources, unsupervised transfer of natural language processing models such as named-entity recognition (NER) from resource-rich languages would be an appealing capability. However, differences in words and word order across languages make it a challenging problem. To improve mapping of lexical items across languages , we propose a method that finds translations based on bilingual word embeddings. To improve robustness to word order differences , we propose to use self-attention, which allows for a degree of flexibility with respect to word order. We demonstrate that these methods achieve state-of-the-art or competitive NER performance on commonly tested languages under a cross-lingual setting, with much lower resource requirements than past approaches. We also evaluate the challenges of applying these methods to Uyghur, a low-resource language. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named entity recognition (NER), the task of de- tecting and classifying named entities from text into a few predefined categories such as people, lo- cations or organizations, has seen the state-of-the- art greatly advanced by the introduction of neu- ral architectures <ref type="bibr" target="#b8">(Collobert et al., 2011;</ref><ref type="bibr" target="#b19">Huang et al., 2015;</ref><ref type="bibr" target="#b7">Chiu and Nichols, 2016;</ref><ref type="bibr" target="#b22">Lample et al., 2016;</ref><ref type="bibr" target="#b46">Yang et al., 2016;</ref><ref type="bibr" target="#b27">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b35">Peters et al., 2017;</ref><ref type="bibr" target="#b26">Liu et al., 2018;</ref><ref type="bibr" target="#b36">Peters et al., 2018</ref>). However, the success of these methods is highly dependent on a reasonably large amount of annotated training data, and thus it remains a chal- lenge to apply these models to languages with lim- ited amounts of labeled data. Cross-lingual NER attempts to address this challenge by transferring knowledge from a high-resource source language with abundant entity labels to a low-resource tar- get language with few or no labels. Specifically, in this paper we attempt to tackle the extreme sce- nario of unsupervised transfer, where no labeled data is available in the target language. Within this paradigm, there are two major challenges to tackle: how to effectively perform lexical mapping between the languages, and how to address word order differences.</p><p>To cope with the first challenge of lexical map- ping, a number of methods use parallel corpora to project annotations between languages through word alignment ( <ref type="bibr" target="#b12">Ehrmann et al., 2011;</ref><ref type="bibr" target="#b21">Kim et al., 2012</ref>; <ref type="bibr" target="#b45">Wang and Manning, 2014;</ref><ref type="bibr" target="#b32">Ni et al., 2017</ref>). Since parallel corpora may not be always avail- able, <ref type="bibr" target="#b28">Mayhew et al. (2017)</ref> proposed a "cheap translation" approach that uses a bilingual dictio- nary to perform word-level translation. The above approaches provide a reasonable proxy for the actual labeled training data, largely because the words that participate in entities can be translated relatively reliably given extensive parallel dictio- naries or corpora (e.g., with 1 million word pairs or sentences). Additionally, as a side benefit of having explicitly translated words, models can di- rectly exploit features extracted from the surface forms (e.g. through character-level neural feature extractors), which has proven essential for high accuracy in the monolingual scenario <ref type="bibr" target="#b27">(Ma and Hovy, 2016)</ref>. However, these methods are largely predicated on the availability of large-scale paral- lel resources, and thus, their applicability to low- resource languages is limited.</p><p>In contrast, it is also possible to learn lex- ical mappings through bilingual word embed- dings (BWE). These bilingual embeddings can be obtained by using a small dictionary to project two sets of embeddings into a consistent space ( <ref type="bibr" target="#b30">Mikolov et al., 2013a;</ref><ref type="bibr" target="#b15">Faruqui and Dyer, 2014;</ref><ref type="bibr" target="#b2">Artetxe et al., 2016;</ref><ref type="bibr" target="#b38">Smith et al., 2017)</ref>, or even in an entirely unsupervised manner using adversarial training or identical character strings ( <ref type="bibr" target="#b49">Zhang et al., 2017;</ref><ref type="bibr" target="#b3">Artetxe et al., 2017;</ref><ref type="bibr" target="#b23">Lample et al., 2018</ref>). Many approaches in the past have leveraged the shared embedding space for cross-lingual applications ( <ref type="bibr" target="#b17">Guo et al., 2015;</ref><ref type="bibr" target="#b1">Ammar et al., 2016b;</ref><ref type="bibr" target="#b50">Zhang et al., 2016;</ref><ref type="bibr" target="#b14">Fang and Cohn, 2017)</ref>, including NER ( <ref type="bibr" target="#b4">Bharadwaj et al., 2016;</ref><ref type="bibr" target="#b32">Ni et al., 2017)</ref>. The minimal dependency on parallel resources makes the embedding-based method much more suitable for low-resource lan- guages. However, since different languages have different linguistic properties, it is hard, if not im- possible, to align the two embedding spaces per- fectly (see <ref type="figure">Figure 1)</ref>. Meanwhile, because sur- face forms are not available, character-level fea- tures cannot be used, resulting in reduced tagging accuracy (as demonstrated in our experiments).</p><p>To address the above issues, we propose a new lexical mapping approach that combines the ad- vantages of both discrete dictionary-based meth- ods and continuous embedding-based methods. Specifically, we first project embeddings of dif- ferent languages into the shared BWE space, then learn discrete word translations by looking for nearest neighbors in this projected space, and fi- nally train a model on the translated data. This allows our method to inherit the benefits of both embedding-based and dictionary-based methods: its resource requirements are low as in the former, but it suffers less from misalignment of the em- bedding spaces and has access to character-level information like the latter.</p><p>Turning to differences in word ordering, to our knowledge there are no methods that explic- itly deal with this problem in unsupervised cross- lingual transfer for NER. Our second contribu- tion is a method to alleviate this issue by incor- porating an order-invariant self-attention mech- anism ( <ref type="bibr" target="#b44">Vaswani et al., 2017;</ref><ref type="bibr" target="#b25">Lin et al., 2017)</ref> into our neural architecture. Self-attention al- lows re-ordering of information within a partic- ular encoded sequence, which makes it possible to account for word order differences between the source and the target languages.</p><p>In our experiments, we start with models trained in English as the source language on the CoNLL 2002 and 2003 datasets and transfer them into Spanish, Dutch, and German as the target lan- guages. Our approach obtains new state-of-the- art cross-lingual results in Spanish and Dutch, and competitive results in German, even without a dictionary, completely removing the need for re- sources such as Wikipedia and parallel corpora. Next, we transfer English using the same approach into Uyghur, a truly low-resource language. With significantly fewer cross-lingual resources, our ap- proach can still perform competitively with previ- ous best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>We establish our problem setting ( §2.1), then present our methods in detail ( §2.2), and provide some additional motivation ( §2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Setting</head><p>NER takes a sentence as the input and outputs a se- quence of labels corresponding to the named entity categories of the words in the sentence, such as lo- cation, organization, person, or none. In standard supervised NER, we are provided with a labeled corpus of sentences in the target language along with tags indicating which spans correspond to en- tities of each type.</p><p>As noted in the introduction, we study the prob- lem of unsupervised cross-lingual NER: given la- beled training data only in a separate source lan- guage, we aim to learn a model that is able to per- form NER in the target language. This transfer can be performed using a variety of resources, in- cluding parallel corpora <ref type="bibr" target="#b40">(Täckström et al., 2012;</ref><ref type="bibr" target="#b32">Ni et al., 2017)</ref>, <ref type="bibr">Wikipedia (Nothman et al., 2013)</ref>, and large dictionaries ( <ref type="bibr" target="#b32">Ni et al., 2017;</ref><ref type="bibr" target="#b28">Mayhew et al., 2017)</ref>. In this work, we limit ourselves to a setting where we have the following resources, making us comparable to other methods such as <ref type="bibr" target="#b28">Mayhew et al. (2017)</ref> and <ref type="bibr" target="#b32">Ni et al. (2017)</ref>:</p><p>• Labeled training data in the source language.</p><p>• Monolingual corpora in both source and target languages.</p><p>• A dictionary, either a small pre-existing one, or one induced by unsupervised methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Method</head><p>Our method follows the process below:</p><p>1. Train separate word embeddings using mono- lingual corpora using standard embedding train- ing methods ( §2.2.1).</p><p>2. Project word embeddings in the two languages into a shared embedding space by optimizing <ref type="figure">Figure 1</ref>: Example of the result of our approach on Spanish-English words not included in the dictionary (em- beddings are reduced to 2 dimensions for visual clarity). We first project word embeddings into a shared space, and then use the nearest neighbors for word translation. Notice that the word pairs are not perfectly aligned in the shared embedding space, but after word translation we obtain correct alignments.</p><p>the word embedding alignment using the given dictionary ( §2.2.2).</p><p>3. For each word in the source language training data, translate it by finding its nearest neighbor in the shared embedding space ( §2.2.3).</p><p>4</p><p>. Train an NER model using the translated words along with the named entity tags from the En- glish corpus ( §2.2.4).</p><p>We consider each in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Learning Monolingual Embeddings</head><p>Given text in the source and target language, we first independently learn word embedding matri- ces X and Y in the source and target languages respectively. These embeddings can be learned on monolingual text in both languages with any of the myriad of word embedding methods ( <ref type="bibr" target="#b31">Mikolov et al., 2013b;</ref><ref type="bibr" target="#b34">Pennington et al., 2014;</ref><ref type="bibr" target="#b5">Bojanowski et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Learning Bilingual Embeddings</head><p>Next, we learn a cross-lingual projection of X and Y into a shared space. Assume we are given a dictionary</p><formula xml:id="formula_0">{x i , y i } D i=1</formula><p>, where x i and y i denote the embeddings of a word pair. Let </p><formula xml:id="formula_1">X D = [x 1 , x 2 , · · · , x D ] and Y D = [y 1 , y 2 , · · · , y D ] denote</formula><formula xml:id="formula_2">min W d i=1 W x i − y i 2 s.t. W W = I,</formula><p>where W is a square parameter matrix. This ob- jective can be further simplified as</p><formula xml:id="formula_3">max W Tr(X D W Y D ) s.t. W W = I.</formula><p>Here, the transformation matrix W is constrained to be orthogonal so that the dot product similarity of words is invariant with respect to the transfor- mation both within and across languages. To optimize the above objective (the Procrustes problem), we decompose the matrix</p><formula xml:id="formula_4">Y D X D us- ing singular value decomposition. Let the results be Y D X D = U V , then W = U V</formula><p>gives the exact solution. We define the similarity ma- trix between X and Y to be S = Y W X = Y U (XV ) , where each column contains the co- sine similarity between source word x i and all tar- get words y i . We can then define X = XV and Y = Y U , which are X and Y transformed into a shared embedding space.</p><p>To refine the alignment in this shared space fur- ther, we iteratively perform a self-learning refine- ment step k 2 times by:</p><p>1. Using the aligned embeddings to generate a new dictionary that consists of mutual nearest neigh- bors obtained using the same metric as intro- duced below.</p><p>2. Solving the Procrustes problem based on the newly generated dictionary to get a new set of bilingual embeddings.</p><p>The bilingual embeddings at the end of the kth step, X k and Y k , will be used to perform trans- lation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Learning Word Translations</head><p>To learn actual word translations, we next pro- ceed to perform nearest-neighbor search in the common space. Instead of using a common dis- tance metric such as cosine similarity, we adopt the cross-domain similarity local scaling (CSLS) metric ( <ref type="bibr" target="#b23">Lample et al., 2018)</ref>, which is designed to address the hubness problem common to the shared embedding space ( <ref type="bibr" target="#b11">Dinu and Baroni, 2014)</ref>. Specifically,</p><formula xml:id="formula_5">CSLS(x i , y j ) = 2 cos(x i , y j ) − r T (x i ) − r S (y j ) where r T (x i ) = 1 K yt∈N T (x i )</formula><p>cos(x i , y t ) de- notes the mean cosine similarity between x i and its K neighbors y t . Using this metric, we find translations for each source word s by selecting target wordˆtwordˆ wordˆt s wherê t s = arg max t CSLS(x s , y t ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Training the NER Model</head><p>Finally, we translate the entire English NER train- ing data into the target language by taking English sentences S = s 1 , s 2 , ..., s n and translating them into target sentencesˆTsentencesˆ sentencesˆT = ˆ t 1 , ˆ t 2 , ..., ˆ t n . The la- bel of each English word is copied to be the la- bel of the target word. We can then train an NER model directly using the translated data. Notably, because the model has access to the surface forms of the target sentences, it can use the character se- quences of the target language as part of its input.</p><p>During learning, all word embeddings are nor- malized to lie on the unit ball, allowing every training pair an equal contribution to the objective and improving word translation accuracy ( <ref type="bibr" target="#b2">Artetxe et al., 2016)</ref>. When training the NER model, how- ever, we do not normalize the word embeddings, because preliminary experiments showed the orig- inal unnormalized embeddings gave superior re- sults. We suspect this is due to frequency infor- mation conveyed by vector length, an important signal for NER. (Named entities appear less fre- quently in the monolingual corpus.) <ref type="figure">Figure 1</ref> shows an example of the embeddings and translations learned with our approach trained on Spanish and English data from the experiments (see §4 for more details). As shown in the figure, there is usually a noticeable difference between the word embeddings of a word pair in different languages, which is inevitable because different languages have distinct traits and different mono- lingual data, and as a result it is intrinsically hard to learn a perfect alignment. This indicates that models trained directly on data using the source Instead of directly modeling the shared embed- ding space ( <ref type="bibr" target="#b17">Guo et al., 2015;</ref><ref type="bibr" target="#b50">Zhang et al., 2016;</ref><ref type="bibr" target="#b14">Fang and Cohn, 2017;</ref><ref type="bibr" target="#b32">Ni et al., 2017)</ref>, we lever- age the shared embedding space for word transla- tion. As shown in <ref type="figure">Figure 1</ref>, unaligned word pairs can still be translated correctly with our method, as the embeddings are still closer to the correct trans- lations than the closest incorrect one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">NER Model Architecture</head><p>We describe the model we use to perform NER. We will first describe the basic hierarchical neural CRF tagging model ( <ref type="bibr" target="#b22">Lample et al., 2016;</ref><ref type="bibr" target="#b27">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b46">Yang et al., 2016)</ref>, and introduce the self-attention mechanism that we propose to deal with divergence of word order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Hierarchical Neural CRF</head><p>The hierarchical CRF model consists of three components: a character-level neural network, ei- ther an RNN or a CNN, that allows the model to capture subword information, such as morpholog- ical variations and capitalization patterns; a word- level neural network, usually an RNN, that con- sumes word representations and produces context sensitive hidden representations for each word; and a linear-chain CRF layer that models the de- pendency between labels and performs inference.</p><p>In this paper, we closely follow the architecture proposed by <ref type="bibr" target="#b22">Lample et al. (2016)</ref>, and use bi- directional LSTMs for both the character level and word level neural networks. Specifically, given an input sequence of words (w 1 , w 2 , ..., w n ), and each word's corresponding character sequence, the model first produces a representation for each word, x i , by concatenating its character rep- resentation with its word embedding. Subse- quently, the word representations of the input se- quence (x 1 , x 2 , · · · , x n ) are fed into a word level Bi-LSTM, which models the contextual depen- dency within each sentence and outputs a se- quence of context sensitive hidden representations (h 1 , h 2 , · · · , h n ). A CRF layer is then applied on top of the word level LSTM and takes in as its input the sequence of hidden representations (h 1 , h 2 , · · · , h n ), and defines the joint distribution of all possible output label sequences. The Viterbi algorithm is used during decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Self-Attention</head><p>The training-time inputs to our model are in essence corrupted sentences from the target lan- guage (e.g., Spanish), which have a different or- der from natural target sentences. We propose to alleviate this problem by adding a self-attention layer ( <ref type="bibr" target="#b44">Vaswani et al., 2017</ref>) on top of the word- level Bi-LSTM. Self-attention provides each word with a context feature vector based on all the words of a sentence. As the context vectors are obtained irrespective of the words' positions in a sentence, at test time, the model is more likely to see vectors similar to those seen at training time, which we posit introduces a level of flexibility with respect to the word order, and thus may al- low for better generalization.</p><p>Let H = [h 1 , h 2 , · · · , h n ] be a sequence of word-level hidden representations. We apply a single layer MLP on H to obtain the queries Q and keys K = tanh(HW + b), where W ∈ R d×d is a parameter matrix and b ∈ R d is a bias term, with d being the hidden state size. The output of attention layer is defined as:</p><formula xml:id="formula_6">H a = softmax(QK ) (E − I)H = [h a 1 , h a 2 , ..., h a 3 ]</formula><p>where I is an identity matrix and E is an all-one matrix. The term (E − I) serves as an atten- tion mask that prevents the weights from center- ing on the word itself, as we would like to provide each word with sentence level context. The out- puts from the self-attention layer are then concate- nated with the original hidden representations to form the final inputs to the CRF layer, which are</p><formula xml:id="formula_7">([h 1 , h a 1 ], [h 2 , h a 2 ], ..., [h 3 , h a 3 ]).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>To examine the effectiveness of both of our pro- posed methods, we conduct four sets of experi- ments. First, we evaluate our model both with and without provided dictionaries on a benchmark NER dataset and compare with previous state-of- the-art results. Second, we compare our meth- ods against a recently proposed dictionary-based translation baseline ( <ref type="bibr" target="#b28">Mayhew et al., 2017</ref>) by di- rectly applying our model on their translated data. <ref type="bibr">3</ref> Subsequently, we conduct an ablation study to fur- ther understand our proposed methods. Lastly, we apply our methods to a truly low-resource lan- guage, Uyghur.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>We evaluate our proposed methods on the bench- mark <ref type="bibr">CoNLL 2002</ref><ref type="bibr" target="#b42">and 2003</ref><ref type="bibr">NER datasets (Tjong Kim Sang, 2002</ref><ref type="bibr" target="#b42">Tjong Kim Sang and De Meulder, 2003)</ref>, which contain 4 European lan- guages, English, German, Dutch and Spanish. For all experiments, we use English as the source lan- guage and translate its training data into the target language. We train a model on the translated data, and test it on the target language. For each exper- iment, we run our models 5 times using different seeds and report the mean and standard deviation, as suggested by <ref type="bibr" target="#b37">Reimers and Gurevych (2017)</ref>. Word Embeddings For all languages, we use two different embedding methods, fastText <ref type="bibr" target="#b5">(Bojanowski et al., 2017</ref>) and GloVe ( <ref type="bibr" target="#b34">Pennington et al., 2014</ref>), to perform word-embedding based translations and train the NER model, respectively. For fastText, we use the publicly available em- beddings trained on Wikipedia for all languages. For GloVe, we use the publicly available embed- dings pre-trained on Gigaword and Wikipedia for English. For Spanish, German and Dutch, we use Spanish Gigaword and Wikipedia, German WMT News Crawl data and Wikipedia, and Dutch Wikipedia, respectively, to train the GloVe word embeddings. We use a vocabulary size of 100,000 for both embedding methods.</p><p>Dictionary We consider three different settings to obtain the seed dictionary, including two meth- ods that do not use parallel resources:</p><p>1. Use identical character strings shared between the two vocabularies as the seed dictionary.</p><p>2. <ref type="bibr" target="#b23">Lample et al. (2018)</ref>'s method of using adver- sarial learning to induce a mapping that aligns the two embedding spaces, and the mutual near- est neighbors in the shared space will be used as a dictionary. The learning procedure is formu- lated as a two player game, where a discrim- inator is trained to distinguish words from the two embedding spaces, and a linear mapping is trained to align the two embedding spaces and thus fool the discriminator.</p><p>3. Use a provided dictionary. In our experiments, we use the ones provided by <ref type="bibr" target="#b23">Lample et al. (2018)</ref>, <ref type="bibr">4</ref> each of which contain 5,000 source words and about 10,000 entries.</p><p>Translation We follow the general procedure described in Section 2, and replace each word from the English training data with its correspond- ing word in the target language. For out-of- vocabulary (OOV) words, we simply keep them as-is. We capitalize the resulting sentences fol- lowing the pattern of the original English words. Note that for German, simply following the En- glish capitalization pattern does not work, because all nouns in German are capitalized. To handle this problem, we count the number of times each word is capitalized in Wikipedia, and capitalize the word if the probability is greater than 0.6.</p><p>Network Parameters For our experiments, we set the character embedding size to be 25, char- acter level LSTM hidden size to be 50, and word level LSTM hidden size to be 200. For OOV words, we initialize an unknown embedding by uniformly sampling from range [−</p><formula xml:id="formula_8">3 emb , + 3 emb ],</formula><p>where emb is the size of embedding, 100 in our case. We replace each number with 0 when used as input to the character level Bi-LSTM.</p><p>Network Training We use SGD with momen- tum to train the NER model for 30 epochs, and select the best model on the target language de- velopment set. We choose the initial learning rate to be η 0 = 0.015, and update it using a learning decay mechanism after each epoch, η t = η 0 1+ρt , where t is the number of completed epoch and ρ = 0.05 is the decay rate. We use a batch size of 10 and evaluate the model per 150 batches within each epoch. We apply dropout on the in- puts to the word-level Bi-LSTM, the outputs of the word-level Bi-LSTM, and the outputs of the self-attention layer to prevent overfitting. The self- attention dropout rate is set to 0.5 when using our translated data, and 0.2 when using cheap- translation data. We use 0.5 for all other dropouts. The word embeddings are not fine-tuned during training. <ref type="table">Table 1</ref> presents our results on transferring from English to three other languages, alongside results from previous studies. Here "BWET" (bilingual word embedding translation) denotes using the hi- erarchical neural CRF model trained on data trans- lated from English. As can be seen from the ta- ble, our methods outperform previous state-of-the- art results on Spanish and Dutch by a large mar- gin and perform competitively on German even without using any parallel resources. We achieve similar results using different seed dictionaries, and produce the best results when adding the self- attention mechanism to our model. Despite the good performance on Spanish and Dutch, our model does not outperform the previ- ous best result on German, and we speculate that there are a few reasons. First, German has rich morphology and contains many compound words, making the word embeddings less reliable. Our supervised result on German indicates the same problem, as it is about 8 F 1 points worse than Spanish and Dutch. Second, these difficulties be- come more pronounced in the cross-lingual set- ting, leading to a noisier embedding space align- ment, which lowers the quality of BWE-based translation. We believe that this is a problem with all methods using word embeddings. In such cases, more resource-intensive methods may be necessary. <ref type="table">Table 1</ref> also presents results of a comparison be- tween our proposed BWE translation method and the "cheap translation" baseline of ( <ref type="bibr" target="#b28">Mayhew et al., 2017)</ref>. The size of the dictionaries used by both  <ref type="table">Table 1</ref>: NER F 1 scores. * Approaches that use more resources than ours ("Wikipedia" means Wikipedia is used not as a monolingual corpus, but to provide external knowledge). † Approaches that use multiple languages for transfer. "Only Eng. data" is the model used in <ref type="bibr" target="#b28">Mayhew et al. (2017)</ref> trained on their data translated from English without using Wikipedia and other languages. The "data from <ref type="bibr" target="#b28">Mayhew et al. (2017)</ref>" is the same data translated from only English they used. "Id.c." indicates using identical character strings between the two languages as the seed dictionary. "Adv." indicates using adversarial training and mutual nearest neighbors to induce a seed dictionary. Our supervised results are obtained using models trained on annotated corpus from CoNLL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Comparison with Dictionary-Based Translation</head><p>approaches are given in the right-most column.</p><p>Using our model on their translated data from En- glish outperforms the baseline scores produced by their models over all languages, a testament to the strength of our neural CRF baseline. The results produced by our model on their data indicate that our approach is effective, as we manage to outper- form their approaches on all three languages using much smaller dictionaries and even without dictio- naries. Also, we see that self-attention is effective when applied on their data, which also does not carry the correct word order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Why Does Translation Work Better?</head><p>In this section, we study the effects of differ- ent ways of using bilingual word embeddings and the resulting induced translations. As we pointed out previously, finding translations has two advan- tages: (1) the model can be trained on the exact points from the target embedding space, and (2) the model has access to the target language's orig- inal character sequences. Here, we conduct abla- tion studies over these two variables. Specifically, we consider the following three variants. 5</p><p>• Common space This is the most common set- ting for using bilingual word embeddings, and has recently been applied in NER ( <ref type="bibr" target="#b32">Ni et al., 2017)</ref>. In short, the source and target word em- beddings are cast into a common space, namely X = XV and Y = Y U , and the model is trained with the source side embedding and the source character sequence, and directly applied on the target side.</p><p>• Replace In this setting, we replace each original word embedding x i with its nearest neighbor y i in the common space but do not perform trans- lation. This way, the model will be trained with target word embeddings and source-side char- acter sequences.</p><p>• Translation This is our proposed approach, where the model is trained on both exact points in the target space and target language character sequences.</p><p>The three variants are compared in <ref type="table" target="#tab_2">Table 2</ref>. The "common space" variant performs the worst by a large margin, confirming our hypothesis that discrepancy between the two embedding spaces harms the model's ability to generalize. From the comparison between the "replace" and "transla- tion," we observe that having access to the target language's character sequence helps performance, especially for German, perhaps due in part to its capitalization patterns, which differ from English. In this case, we have to lower-case all the words for character inputs in order to prevent the model from overfitting the English capitalization pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Spanish Dutch German Common space 65.40 ± 1.22 66.15 ± 1.62 43.73 ± 0.94 Replace 68.21 ± 1.22 69.37 ± 1.33 48.59 ± 1.21 Translation 69.21 ± 0.95 69.39 ± 1.21 53.94 ± 0.66  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Case Study: Uyghur</head><p>In this section, we directly apply our approach to Uyghur, a truly low-resource language with very limited monolingual and parallel resources. We test our model on 199 annotated evaluation documents from the DARPA LORELEI program (the "unsequestered set") and compare with previ- ously reported results in the cross-lingual setting by <ref type="bibr" target="#b28">Mayhew et al. (2017)</ref>. Similar to our previous experiments, we transfer from English, use fast- Text embeddings trained on Common Crawl and Wikipedia 6 and a provided dictionary to perform translation, and use GloVe trained on a monolin- gual corpus that has 30 million tokens to perform NER. Results are presented in <ref type="table" target="#tab_3">Table 3</ref>. Our method performs competitively, consid- ering that we use a much smaller dictionary than <ref type="bibr" target="#b28">Mayhew et al. (2017)</ref> and no knowledge from Wikipedia in Uyghur. Our best results come from a combined approach: using word embeddings to translate words that are not covered by <ref type="bibr" target="#b28">Mayhew et al. (2017)</ref>'s dictionary (last line of <ref type="table" target="#tab_3">Table 3</ref>). Note that for the CoNLL languages, <ref type="bibr" target="#b28">Mayhew et al. (2017)</ref> used Wikipedia for the Wikifier fea- tures ( <ref type="bibr" target="#b43">Tsai et al., 2016)</ref>, while for Uyghur they used it for translating named entities, which is cru- cial for low-resource languages when some named entities are not covered by the dictionary or the translation is not reliable. We suspect that the un- reliable translation of named entities is the ma-jor reason why our method alone performs worse but performs better when combined with their data that has access to higher quality translations of named entities.</p><p>The table omits results using adversarial learn- ing and identical character strings, as both failed (F 1 scores around 10). We attribute these failures to the low quality of Uyghur word embeddings and the fact that the two languages are distant. Also, Uyghur is mainly written in Arabic script, mak- ing the identical character method inappropriate. Overall, this reveals a practical challenge for mul- tilingual embedding methods, where the underly- ing distributions of the text in the two languages are divergent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Cross-Lingual Learning Cross-lingual learning approaches can be loosely classified into two categories: annotation projection and language- independent transfer.</p><p>Annotation projection methods create training data by using parallel corpora to project annota- tions from the source to the target language. Such approaches have been applied to many tasks un- der the cross-lingual setting, such as POS tag- ging ( <ref type="bibr" target="#b48">Yarowsky et al., 2001;</ref><ref type="bibr" target="#b10">Das and Petrov, 2011;</ref><ref type="bibr" target="#b39">Täckström et al., 2013;</ref><ref type="bibr" target="#b13">Fang and Cohn, 2016)</ref>, mention detection ( <ref type="bibr" target="#b52">Zitouni and Florian, 2008</ref>) and parsing ( <ref type="bibr" target="#b20">Hwa et al., 2005;</ref><ref type="bibr" target="#b29">McDonald et al., 2011</ref>).</p><p>Language independent transfer-based ap- proaches build models using language indepen- dent and delexicalized features. For instance, <ref type="bibr" target="#b51">Zirikly and Hagiwara (2015)</ref> transfers word cluster and gazetteer features through the use of comparable copora. <ref type="bibr" target="#b43">Tsai et al. (2016)</ref> links words to Wikipedia entries and uses the entry category as features to train language independent NER models. Recently, <ref type="bibr" target="#b32">Ni et al. (2017)</ref> propose to project word embeddings into a common space as language independent features. These approaches utilize such features by training a model on the source language and directly applying it to the target language.</p><p>Another way of performing language indepen- dent transfer resorts to multi-task learning, where a model is trained jointly across different lan- guages by sharing parameters to allow for knowl- edge transfer <ref type="bibr" target="#b0">(Ammar et al., 2016a;</ref><ref type="bibr" target="#b9">Cotterell and Duh, 2017;</ref><ref type="bibr" target="#b24">Lin et al., 2018)</ref>. However, such approaches usually require some amounts of training data in the target language for bootstrapping, which is different from our un- supervised approach that requires no labeled re- sources in the target language.</p><p>Bilingual Word Embeddings There have been two general paradigms in obtaining bilingual word vectors besides using dictionaries: through paral- lel corpora and through joint training. Approaches based on parallel corpora usually learn bilingual word embeddings that can produce similar repre- sentations for aligned sentences <ref type="bibr">(Hermann and Blunsom, 2014;</ref><ref type="bibr" target="#b6">Chandar et al., 2014</ref>). Jointly- trained models combine the common monolin- gual training objective with a cross-lingual train- ing objective that often comes from parallel corpus ( <ref type="bibr" target="#b53">Zou et al., 2013;</ref><ref type="bibr" target="#b16">Gouws et al., 2015)</ref>. Recently, unsupervised approaches also have been used to align two sets of word embeddings by learning a mapping through adversarial learning or self- learning ( <ref type="bibr" target="#b49">Zhang et al., 2017;</ref><ref type="bibr" target="#b3">Artetxe et al., 2017;</ref><ref type="bibr" target="#b23">Lample et al., 2018</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose two methods to tackle the cross-lingual NER problem under the unsuper- vised transfer setting. To address the challenge of lexical mapping, we find translations of words in a shared embedding space built from a seed lex- icon. To alleviate word order divergence across languages, we add a self-attention mechanism to our neural architecture. With these methods com- bined, we are able to achieve state-of-the-art or competitive results on commonly tested languages under a cross-lingual setting, with lower resource requirements than past approaches. We also eval- uate the challenges of applying these methods to an extremely low-resource language, Uyghur.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Self-attentive Bi-LSTM-CRF Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Comparison of different ways of using bilingual word embeddings, within our method (NER F 1 ).</head><label>2</label><figDesc></figDesc><table>Model 
Uyghur Unsequestered Set Extra Resources 

 *  † 

Mayhew et al. (2017) 
51.32 
Wikipedia, 100K dict. 

 *  

Mayhew et al. (2017) (only Eng. data) 
27.20 
Wikipedia, 100K dict. 
BWET 
25.73 ± 0.89 
5K dict. 
BWET + self-att. 
26.38 ± 0.34 
5K dict. 

 *  

BWET on data from Mayhew et al. (2017) 
30.20 ± 0.98 
Wikipedia, 100K dict. 

 *  

BWET + self-att. on data from Mayhew et al. (2017) 30.68 ± 0.45 
Wikipedia, 100K dict. 

 *  

Combined (see text) 
31.61 ± 0.46 
Wikipedia, 100K dict., 5K dict. 

 *  

Combined + self-att. 
32.09 ± 0.61 
Wikipedia, 100K dict., 5K dict. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>NER F 1 scores on Uyghur.  *  Approaches using language-specific features and resources ("Wikipedia" 
means Wikipedia is used not as a monolingual corpus, but to provide external knowledge).  † Approaches that 
transfer from multiple languages and use language-specific techniques. 

</table></figure>

			<note place="foot" n="1"> The source code is available at https://github. com/thespectrewithin/cross-lingual_NER</note>

			<note place="foot" n="2"> We use k = 3 in this paper.</note>

			<note place="foot" n="3"> We thank the authors of Mayhew et al. (2017) for sharing their data.</note>

			<note place="foot" n="4"> https://github.com/facebookresearch/ MUSE</note>

			<note place="foot" n="5"> In this study, we use GloVe for learning bilingual embeddings and word translations instead of fastText.</note>

			<note place="foot" n="6"> https://github.com/facebookresearch/ fastText/blob/master/docs/crawl-vectors. md</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Stephen Mayhew for sharing the data, and Zihang Dai for meaningful discussion. This research was sponsored by Defense Ad-vanced Research Projects Agency Information In-novation Office (I2O) under the Low Resource Languages for Emergent Incidents (LORELEI) program, issued by DARPA/I2O under Contract No. HR0011-15-C0114. The views and conclu-sions contained in this document are those of the authors and should not be interpreted as repre-senting the official policies, either expressed or implied, of the U.S. government. The U.S. gov-ernment is authorized to reproduce and distribute reprints for government purposes notwithstanding any copyright notation here on.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Many languages, one parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="431" to="444" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Massively multilingual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://arxiv.org/pdf/1602.01925" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning principled bilingual mappings of word embeddings while preserving monolingual invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gorka</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2289" to="2294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning bilingual word embeddings with (almost) no bilingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gorka</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Phonologically aware neural model for named entity recognition in low resource transfer settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akash</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mortensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1462" to="1472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An autoencoder approach to learning bilingual word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Lauly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitesh</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaraman</forename><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vikas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrita</forename><surname>Raykar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1853" to="1861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Named entity recognition with bidirectional lstm-cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nichols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="357" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lowresource named entity recognition with crosslingual, character-level neural conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="91" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unsupervised part-of-speech tagging with bilingual graph-based projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="600" to="609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Improving zero-shot learning by mitigating the hubness problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<idno>abs/1412.6568</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Building a multilingual named entityannotated corpus using annotation projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maud</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Steinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RANLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="118" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning when to trust distant supervision: An application to lowresource POS tagging using cross-lingual projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Model transfer for tagging low-resource languages using a bilingual dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="587" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving vector space word representations using multilingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="462" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bilbowa: Fast bilingual distributed representations without word alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="748" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cross-lingual dependency parsing based on distributed representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1234" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multilingual models for compositional distributed semantics</title>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<editor>Karl Moritz Hermann and Phil Blunsom</editor>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="58" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Bidirectional LSTM-CRF models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bootstrapping parsers via syntactic projection across parallel texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Weinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Cabezas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okan</forename><surname>Kolak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural language engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="311" to="325" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multilingual named entity recognition using parallel data and metadata from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungchul</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="694" to="702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Word translation without parallel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jgou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A multi-lingual multi-task architecture for low-resource sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="799" to="809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cicero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Empower sequence labeling with taskaware neural language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cheap translation for cross-lingual named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2526" to="2535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-source transfer of delexicalized dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="62" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno>abs/1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Weakly supervised cross-lingual named entity recognition via effective annotation and representation projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1470" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning multilingual named entity recognition from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicky</forename><surname>Ringland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence tagging with bidirectional language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1756" to="1765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<title level="m">Deep contextualized word representations. In NAACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Reporting score distributions makes a difference: Performance study of lstm-networks for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="338" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Offline bilingual word vectors, orthogonal transformations and the inverted softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Turban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><forename type="middle">Y</forename><surname>Hamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hammerla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Token and type constraints for cross-lingual part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Cross-lingual word clusters for direct transfer of linguistic structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="477" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik F Tjong Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien De</forename><surname>Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Cross-lingual named entity recognition via wikification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="219" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Cross-lingual projected expectation regularization for weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Multi-task cross-lingual sequence tagging from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno>abs/1603.06270</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Transfer learning for sequence tagging with hierarchical recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Inducing multilingual text analysis tools via robust projection across aligned corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wicentowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Adversarial training for unsupervised bilingual lexicon induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1959" to="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Ten pairs to tag-multilingual POS tagging via coarse mapping between embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gaddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1307" to="1317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Crosslingual transfer of named entity recognizers without parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayah</forename><surname>Zirikly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masato</forename><surname>Hagiwara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="390" to="396" />
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Mention detection crossing the language barrier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imed</forename><surname>Zitouni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="600" to="609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Bilingual word embeddings for phrase-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Will</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1393" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
