<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Flexible Domain Adaptation for Automated Essay Scoring Using Correlated Linear Regression</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Phandi</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><forename type="middle">A</forename><surname>Kian</surname></persName>
							<email>ckianmin@dso.org.sg</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chai</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">DSO National Laboratories</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Flexible Domain Adaptation for Automated Essay Scoring Using Correlated Linear Regression</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Most of the current automated essay scoring (AES) systems are trained using manually graded essays from a specific prompt. These systems experience a drop in accuracy when used to grade an essay from a different prompt. Obtaining a large number of manually graded essays each time a new prompt is introduced is costly and not viable. We propose domain adaptation as a solution to adapt an AES system from an initial prompt to a new prompt. We also propose a novel domain adaptation technique that uses Bayesian linear ridge regression. We evaluate our domain adaptation technique on the publicly available Automated Student Assessment Prize (ASAP) dataset and show that our proposed technique is a competitive default domain adaptation algorithm for the AES task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Essay writing is a common task evaluated in schools and universities. In this task, students are typically given a prompt or essay topic to write about. Essay writing is included in high-stakes as- sessments, such as Test of English as a Foreign Language (TOEFL) and Graduate Record Exami- nation (GRE). Manually grading all essays takes a lot of time and effort for the graders. This is what Automated Essay Scoring (AES) systems are try- ing to alleviate.</p><p>Automated Essay Scoring uses computer soft- ware to automatically evaluate an essay written in an educational setting by giving it a score. Work related to essay scoring can be traced back to 1966 when Ellis Page created a computer grading software called Project Essay Grade (PEG). Re- search on AES has continued through the years.</p><p>The recent Automated Student Assessment Prize (ASAP) Competition 1 sponsored by the Hewlett Foundation in 2012 has renewed interest on this topic. The agreement between the scores assigned by state-of-the-art AES systems and the scores as- signed by human raters has been shown to be rel- atively high. See <ref type="bibr">Shermis and Burstein (2013)</ref> for a recent overview of AES.</p><p>AES is usually treated as a supervised machine learning problem, either as a classification, regres- sion, or rank preference task. Using this approach, a training set in the form of human graded essays is needed. However, human graded essays are not readily available. This is perhaps why research in this area was mostly done by commercial organi- zations. After the ASAP competition, research in- terest in this area has been rekindled because of the released dataset.</p><p>Most of the recent AES related work is prompt- specific. That is, an AES system is trained using essays from a specific prompt and tested against essays from the same prompt. These AES systems will not work as well when tested against a differ- ent prompt. Furthermore, generating the training data each time a new prompt is introduced will be costly and time consuming.</p><p>In this paper, we propose domain adaptation as a solution to this problem. Instead of hiring peo- ple to grade new essays each time a new prompt is introduced, domain adaptation can be used to adapt the old prompt-specific system to suit the new prompt. This way, a smaller number of train- ing essays from the new prompt is needed. In this paper, we propose a novel domain adaptation tech- nique based on Bayesian linear ridge regression.</p><p>The rest of this paper is organized as follows. In Section 2, we give an overview of related work on AES and domain adaptation. Section 3 describes the AES task and the features used. Section 4 presents our novel domain adaptation algorithm.</p><p>Section 5 describes our data, experimental setup, and evaluation metric. Section 6 presents and dis- cusses the results. We conclude in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>We first introduce related work on automated es- say scoring, followed by domain adaptation in the context of natural language processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Automated Essay Scoring</head><p>Since the first AES system, Project Essay Grade, was created in 1966, a number of commercial sys- tems have been deployed. One such system, e- rater ( <ref type="bibr" target="#b0">Attali and Burstein, 2004</ref>), is even used as a replacement for the second human grader in the Test of English as a Foreign Language (TOEFL) and Graduate Record Examination (GRE). Other AES commercial systems also exist, such as Intel- liMetric 2 and Intelligent Essay Assessor ( <ref type="bibr" target="#b8">Foltz et al., 1999)</ref>.</p><p>AES is generally considered as a machine learn- ing problem. Some work, such as PEG <ref type="bibr" target="#b15">(Page, 1994)</ref> and e-rater, considers it as a regression prob- lem. PEG uses a large number of features with re- gression to predict the human score. e-rater uses natural language processing (NLP) techniques to extract a smaller number of complex features, such as grammatical error and lexical complexity, and uses them with stepwise linear regression <ref type="bibr" target="#b0">(Attali and Burstein, 2004</ref>). Others like <ref type="bibr" target="#b13">(Larkey, 1998</ref>) take the classification approach. <ref type="bibr" target="#b18">(Rudner and Liang, 2002</ref>) uses Bayesian models for clas- sification and treats AES as a text classification problem. Intelligent Essay Assessor uses Latent Semantic Analysis (LSA) ( <ref type="bibr" target="#b12">Landauer et al., 1998)</ref> as a measure of semantic similarity between es- says. Other recent work uses the preference rank- ing based approach <ref type="bibr" target="#b20">(Yannakoudakis et al., 2011;</ref><ref type="bibr" target="#b4">Chen and He, 2013)</ref>.</p><p>In this paper, we also treat AES as a regression problem, following PEG and e-rater. We use re- gression because the range of scores of the essays could be very large and a classification approach does not work well in this case. It also allows us to model essay scores as continuous values and scale them easily in the case of different score ranges between the source essay prompt and the target es- say prompt.</p><p>The features used differ among the systems, ranging from simple features (e.g., word length, essay length, etc) to more complex features (e.g., grammatical errors). Some of these features are generic in the sense that they could apply to all kinds of prompts. Such features include the num- ber of spelling errors, grammatical errors, lexical complexity, etc. Others are prompt-specific fea- tures such as bag of words features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Domain Adaptation</head><p>The knowledge learned from a single domain might not be directly applicable to another do- main. For example, a named entity recognition system trained on labeled news data might not per- form as well on biomedical texts <ref type="bibr" target="#b11">(Jiang and Zhai, 2007)</ref>. We can solve this problem either by getting labeled data from the other domain, which might not be available, or by performing domain adapta- tion.</p><p>Domain adaptation is the task of adapting knowledge learned in a source domain to a target domain. Various approaches to this task have been proposed and used in the context of NLP. Some commonly used approaches include EasyAdapt <ref type="bibr" target="#b5">(Daumé III, 2007)</ref>, instance weighting (IW) <ref type="bibr" target="#b11">(Jiang and Zhai, 2007)</ref>, and structural correspondence learning (SCL) <ref type="bibr" target="#b3">(Blitzer et al., 2006</ref>).</p><p>We can divide the approaches of domain adapta- tion into two categories based on the availability of labeled target data. The case where a small num- ber of labeled target data is available is usually re- ferred to as supervised domain adaptation (such as EasyAdapt and IW). The case where no la- beled target domain data is available is usually re- ferred to as unsupervised domain adaptation (such as SCL). In our work, we focus on supervised do- main adaptation.</p><p>Daumé III (2007) described a domain adapta- tion scheme called EasyAdapt which makes use of feature augmentation. Suppose we have a feature vector x in the original feature space. This scheme will map this instance using the mapping functions Φ s (x) and Φ t (x) for the source and target domain respectively, where</p><formula xml:id="formula_0">Φ s (x) = x, x, 0 Φ t (x) = x, 0, x,</formula><p>and 0 is a zero vector of length |x|. This adapta- tion scheme is attractive because of its simplicity and ease of use as a pre-processing step, and also because it performs quite well despite its simplic- ity. It has been used in various NLP tasks such as word segmentation <ref type="bibr" target="#b14">(Monroe et al., 2014</ref>), ma- chine translation ( ), word sense disambiguation ( <ref type="bibr" target="#b21">Zhong et al., 2008)</ref>, and short an- swer scoring <ref type="bibr" target="#b10">(Heilman and Madnani, 2013)</ref>. Our work is an extension of this scheme in the sense that our work is a generalization of EasyAdapt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Automated Essay Scoring</head><p>This section describes the Automated Essay Scor- ing (AES) task and the features we use for the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Description</head><p>In AES, the input to the system is a student es- say, and the output is the score assigned to the es- say. The score assigned by the AES system will be compared against the human assigned score to measure their agreement. Common agree- ment measures used include Pearson's correlation, Spearman's correlation, and quadratic weighted Kappa (QWK). We use QWK in this paper, which is also the evaluation metric in the ASAP compe- tition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features and Learning Algorithm</head><p>We model the AES task as a regression problem and use Bayesian linear ridge regression (BLRR) as our learning algorithm. We choose BLRR as our learning algorithm so as to use the correlated BLRR approach which will be explained in Sec- tion 4. We use an open source essay scoring sys- tem, EASE (Enhanced AI Scoring Engine) <ref type="bibr">3</ref> , to ex- tract the features. EASE is created by one of the winners of the ASAP competition so the features they use have been proven to be robust. <ref type="table">Table 1</ref> gives the features used by EASE.</p><p>Useful n-grams are defined as n-grams that sep- arate good scoring essays and bad scoring es- says, determined using the Fisher test <ref type="bibr" target="#b7">(Fisher, 1922)</ref>. Good scoring essays are essays with a score greater than or equal to the average score, and the remainder are considered as bad scoring essays. The top 201 n-grams with the highest Fisher values are then chosen as the bag features. We perform the calculation of useful n-grams sep- arately for source and target domain essays, and join them together using set union during the do- main adaptation experiment. This is done to pre- vent the system from choosing only n-grams from the source domain as the useful n-grams, since the 3 https://github.com/edx/ease number of source domain essays is much larger than the target domain essays.</p><p>EASE uses NLTK ( <ref type="bibr" target="#b2">Bird et al., 2009</ref>) for POS tagging and stemming, aspell for spellchecking, and WordNet <ref type="bibr">(Fellbaum, 1998)</ref> to get the syn- onyms. Correct POS tags are generated using a grammatically correct text (provided by EASE). The POS tag sequences not included in the correct POS tags are considered as bad POS. EASE uses scikit-learn (Pedregosa et al., 2011) for extracting unigram and bigram features. For linear regres- sion, a constant feature of value one is appended for the bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Correlated Bayesian Linear Ridge Regression</head><p>First, consider the single-task setting. Let x ∈ R p be the feature vector of an essay. p represents the number of features in x. The generative model for an observed real-valued score y is</p><formula xml:id="formula_1">α ∼ Γ(α 1 , α 2 ), λ ∼ Γ(λ 1 , λ 2 ), w ∼ N (0, λ −1 I), f (x) def = x T w, y ∼ N (f (x i ), α −1 ).</formula><p>Here, α and λ are Gamma distributed hyper- parameters of the model; w ∈ R p is the Normal distributed weight vector of the model; f is the latent function that returns the "true" score of an essay represented by x by linear combination; and y is the noisy observed score of x. Now, consider the two-task setting, where we indicate the source task and the target task by su- perscripts s and t. Given an essay with feature vector x, we consider its observed scores y s and y t when evaluated in task s and task t separately. We have scale hyper-parameters α and λ sampled as before. In addition, we have the correlation ρ between the two tasks. The generative model re- lating the two tasks is</p><formula xml:id="formula_2">ρ ∼ p ρ , w t , w s ∼ N (0, λ −1 I), f t (x) def = x T w t , f s (x) def = ρx T w t + (1 − ρ 2 ) 1/2 x T w s , y t ∼ N (f t (x), α −1 ), y s ∼ N (f s (x), α −1 ),</formula><p>where p ρ is a chosen distribution over the correla- tion; and w t and w s are the weight vectors of the  target and the source tasks respectively, and they are identically distributed but independent. In this setting, it can be shown that the correlation be- tween latent scoring functions for the target and the source tasks is ρ. That is,</p><formula xml:id="formula_3">E(f t (x)f s (x )) = λ −1 ρx T x .<label>(1)</label></formula><p>This, in fact, is a generalization of the EasyAdapt scheme, for which the correlation ρ is fixed at 0.5 <ref type="bibr" target="#b5">[(Daumé III, 2007)</ref>, see eq. 3]. Two other common values for ρ are 1 and 0; the former corresponds to a straightforward concatenation of the source and target data, while the latter is the shared-hyper- parameter setting which shares α and λ between the source and target domain. Through adjust- ing ρ, the model traverses smoothly between these three regimes of domain adaptation. EasyAdapt is attractive because of its (frustrat- ingly) ease of use via encoding the correlation within an expanded feature representation scheme. In the same way, the current setup can be achieved readily by the expanded feature representation</p><formula xml:id="formula_4">Φ t (x) = x, 0 p , Φ s (x) = ρx, (1 − ρ 2 ) 1/2 x<label>(2)</label></formula><p>in R 2p for the target and the source tasks. Asso- ciated with this expanded feature representation is the weight vector w def = (w t , w s ) also in R 2p . As we shall see in Section 4.1, such a representation eases the estimation of the parameters.</p><p>The above model is related to the multi-task Gaussian Process model that has been used for joint emotion analysis <ref type="bibr" target="#b1">(Beck et al., 2014</ref>). There, the intrinsic coregionalisation model (ICM) has been used with squared-exponential covariance function. Here, we use the simpler linear covari- ance function <ref type="bibr" target="#b17">(Rasmussen and Williams, 2006)</ref>, and this leads to Bayesian linear ridge regression. There are two reasons for this choice. The first is that linear combination of carefully chosen fea- tures, especially lexical ones, usually gives good performance in NLP tasks. The second is in the preceding paragraph: an intuitive feature expan- sion representation of the domain adaptation pro- cess that allows ease of parameter estimation.</p><p>The above model is derived from the Cholesky decomposition 1 ρ</p><formula xml:id="formula_5">ρ 1 = 1 0 ρ (1 − ρ 2 ) 1/2 1 ρ 0 (1 − ρ 2 ) 1/2</formula><p>of the desired correlation matrix that will eventu- ally lead to equation (1). Other choices are possi- ble, as long as equation <ref type="formula" target="#formula_3">(1)</ref> is satisfied. However, the current choice has the desired property that the w t portion of the combined weight vector is di-rectly interpretable as the weights for the features in the target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Maximum Likelihood Estimation</head><p>We estimate the parameters (α, λ, ρ) of the model using penalized maximum likelihood. For α and λ, the gamma distributions are used. For ρ, we impose a distribution with density p ρ (ρ) = 1 + a − 2aρ, a ∈ [−1, 1]. This distribution is sup- ported only in <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>; negative ρs are not supported because we think that negative transfer of informa- tion from source to target domain prompts in this essay scoring task is improbable. In our applica- tion, we slightly bias the correlations towards zero with a = 1/10 in order to ameliorate spurious cor- relations.</p><p>For the training data, let there be n t examples in the target domain and n s in the source domain. Let X t (resp. X s ) be the n t -by-p (resp. n s -by-p) de- sign matrix for the training data in the target (resp. source) domain. Let y t and y s be the correspond- ing observed essay scores. The expanded feature matrix due to equation <ref type="formula" target="#formula_4">(2)</ref> is</p><formula xml:id="formula_6">X def = X t 0 ρX s (1 − ρ 2 ) 1/2 X s .</formula><p>Similarly, let y be the stacking of y t and y s . Let K def = λ −1 XX T + α −1 I, which is also known as the Gramian for the observations. The log marginal likelihood of the training data is <ref type="bibr" target="#b17">(Rasmussen and Williams, 2006</ref>)</p><formula xml:id="formula_7">L = − 1 2 y T K −1 y − 1 2 log |K| − n t + n s 2 log 2π.</formula><p>This is penalized to give L p by adding</p><formula xml:id="formula_8">(α 1 − 1) log(α) − α 2 α + α 1 log α 2 − log Γ(α 1 ) +(λ 1 − 1) log(λ) − λ 2 λ + λ 1 log λ 2 − log Γ(λ 1 ) + log(1 + a − 2aρ).</formula><p>The estimation of these parameters is then done by optimising L p . In our implementation, we use scikit-learn for estimating α and λ in an inner loop, and we use gradient descent for estimating ρ in the outer loop using</p><formula xml:id="formula_9">∂L p ∂ρ = 1 2 tr γγ T − K −1 ∂K ∂ρ − 2a 1 + a − 2aρ , where γ def = K −1 y and ∂K ∂ρ = λ −1 0 X t (X s ) T X s (X t ) T 0 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Prediction</head><p>We report the mean prediction as the score of an essay. This uses the mean weight vector ¯ w = λ −1 X T K −1 y ∈ R 2p , which may be parti- tioned into two vectors ¯ w t and ¯ w s , each in R p . The prediction of a new essay represented by x * in the target domain is then given by x T * ¯ w t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we will give a brief description of the dataset we use, describe our experimental setup, and explain the evaluation metric we use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data</head><p>We use the ASAP dataset 4 for our domain adapta- tion experiments. This dataset contains 8 prompts of different genres. The average length of the es- says differs for each prompt, ranging from 150 to 650 words. The essays were written by students ranging in grade 7 to grade 10. All the essays were graded by at least 2 human graders. The genres include narrative, argumentative, or response. The prompts also have different score ranges, as shown in <ref type="table">Table 2</ref>.</p><p>We pick four pairs of essay prompts to perform our experiments. In each experiment, one of the essay prompts from the pair will be the source do- main and the other essay prompt will be the target domain. The essay set pairs we choose are 1 → 2, 3 → 4, 5 → 6, and 7 → 8, where the pair 1 → 2 denotes using prompt 1 as the source domain and prompt 2 as the target domain, for example. These pairs are chosen based on the similarities in their genres, score ranges, and median scores. The aim is to have similar source and target domains for effective domain adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Setup</head><p>We use 5-fold cross validation on the ASAP train- ing data for evaluation. This is because the of- ficial test data of the competition is not released to the public. We divide the target domain data randomly into 5 folds. One fold is used as the test data, while the remaining four folds are col- lected together and then sub-sampled to obtain the target-domain training data. The sizes of the sub- sampled target-domain training data are 10, 25, 50 and 100, with the larger sets containing the smaller sets. All essays from the source domain are used.  <ref type="table">Genre Avg len Range Median   1  1,783 ARG  350  2-12  8  2  1,800 ARG  350  1-6  3  3  1,726  RES  150  0-3  1  4  1,772  RES  150  0-3  1  5  1,805  RES  150  0-4  2  6  1,800  RES  150  0-4  2  7  1,569  NAR  250  0-30  16  8</ref> 723 NAR 650 0-60 36 <ref type="table">Table 2</ref>: Selected details of the ASAP data. For the genre column, ARG denotes argumentative es- says, RES denotes response essays, and NAR de- notes narrative essays.</p><p>Our evaluation considers the following four ways in which we train the AES model:</p><p>SourceOnly Using essays from the source do- main only;</p><p>TargetOnly Using 10, 25, 50, and 100 sampled essays from the target domain only;</p><p>SharedHyper Using correlated Bayesian linear ridge regression (BLRR) with ρ fixed to 0 on source domain essays and sampled essays from the target domain.</p><p>EasyAdapt As SharedHyper, but with ρ = 0.5;</p><p>Concat As SharedHyper, but with ρ fixed to 1.0;</p><p>ML-ρ Using correlated BLRR with ρ maximizing the likelihood of the data.</p><p>Since the source and target domain may have different score ranges, we scale the scores linearly to range from −1 to 1. When predicting on the test essays, the predicted scores of our system will be linearly scaled back to the target domain score range and rounded to the nearest integer.</p><p>We build upon scikit-learn's implementation of BLRR for our learning algorithm. To ameliorate the effects of different scales of features, we nor- malize the features: length, POS, and prompt fea- tures are linearly scaled to range from 0 to 1 ac- cording to the training data; and the feature values for bag-of-words features are log(1 + count) in- stead of the actual counts.</p><p>We use scikit-learn version 0.15.2, NLTK ver- sion 2.0b7, and aspell version 0.60.6.1 in this ex- periment. The BLRR code (bayes.py) in scikit- learn is modified to obtain valid likelihoods for use in the outer loop for estimating ρ. We use scikit- learn's default value for the parameters α 1 , α 2 , λ 1 , and λ 2 which is 10 −6 .  <ref type="table">Table 3</ref>: In-domain experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QWK scores</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation Metric</head><p>Quadratic weighted Kappa (QWK) is used to mea- sure the agreement between the human rater and the system. We choose to use this evaluation met- ric since it is the official evaluation metric of the ASAP competition. Other work such as <ref type="bibr" target="#b4">(Chen and He, 2013</ref>) that uses the ASAP dataset also uses this evaluation metric. QWK is calculated using</p><formula xml:id="formula_10">κ = 1 − i,j w i,j O i,j i,j w i,j E i,j ,</formula><p>where matrices O, (w i,j ), and E are the matrices of observed scores, weights, and expected scores respectively. Matrix O i,j corresponds to the num- ber of essays that receive a score i by the first rater and a score j by the second rater. The weight en- tries are w i,j = (i − j) 2 /(N − 1) 2 , where N is the number of possible ratings. Matrix E is calculated by taking the outer product between the score vec- tors of the two raters, which are then normalized to have the same sum as O.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head><p>In-domain results for comparison First, we determine indicative upper bounds on the QWK scores using Bayesian linear ridge regression (BLRR). To this end, we perform 5-fold cross vali- dation by training and testing within each domain. This is also done with linear support vector ma- chine (SVM) regression to confirm that BLRR is a competitive method for this task. In addition, since the ASAP data has at least 2 human annota- tors for each essay, we also calculate the human agreement score. The results are shown in Ta- ble 3. We see that the BLRR scores are close to the the human agreement scores for prompt 1 and   <ref type="table">Table 4</ref>: QWK scores of the six methods on four domain adaptation experiments, ranging from us- ing 10 target-domain essays (second column) to 100 target-domain essays (fifth column). The scores are the averages over 5 folds. Setting a → b means the AES system is trained on essay set a and tested on essay set b. For each set of six results comparing the methods, the best score is bold- faced and the second-best score is underlined.</p><p>prompts 5 to 8, but fall short by 10% to 20% for prompts 2 to 4. We also see that BLRR is com- parable to linear SVM regression, giving almost the same performance for prompts 4 to 7; slightly poorer performance for prompts 1 to 3; and much better performance for prompt 8. The subsequent discussion in this section will refer to the BLRR scores in <ref type="table">Table 3</ref> for in-domain scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Importance of domain adaptation</head><p>The results of the domain adaptation experiments are tabu- lated in <ref type="table">Table 4</ref>, where the best scores are bold- faced and the second-best scores are underlined.</p><p>As expected, for pairs 1 → 2, 3 → 4, and 5 → 6, all the scores are below their corresponding up- per bounds from the in-domain setting in <ref type="table">Table 3</ref>. However, for pair 7 → 8, the QWK score for domain adaptation with 100 target essays outper- forms that of the in-domain, albeit only by 0.4%. This can be explained by the small number of es- says in prompt 8 that can be used in both the in- domain and domain adaptation settings, and that domain adaptation additionally involves prompt 7 which has more than twice the number of essays; see column two in <ref type="table">Table 2</ref>. Hence, domain adap- tation is effective in the context of small number of target essays with large number of source es- says. This can also be seen in <ref type="table">Table 4</ref> where we have simulated small number of target essays with sizes 10, 25, 50, and 100. When we compare the scores of TargetOnly against the best scores and second-best scores, we find that domain adapta- tion is effective and important in improving the QWK scores. By the above argument alone, one might have thought that an overwhelming large number of source domain essays was sufficient for the tar- get domain. However, this is not true. When we compare the scores of SourceOnly against the best scores and second-best scores, we find that do- main adaptation again improves the QWK scores. In fact, with just 10 additional target domain es- says, effective domain adaptation can improve over SourceOnly for all target domains 2, 4, 6, and 8 respectively. This is the first time where the effects of domain adaptation are shown in the AES task. In addi- tion, the large improvement with a small number of additional target domain essays in 5 → 6 and 7 → 8 suggests the high domain-dependence na- ture of the task: learning on one essay prompt and testing on another should be strongly discouraged.</p><p>Contributions by target-domain essays It is instructive to understand why domain adaptation is important for AES. To this end, we estimate the contribution of bag-of-words features to the over- all prediction by computing the ratio i over bag-of-words features w 2 i i over all features w 2 i using weights learned in the in-domain setting; see <ref type="table">Table 1</ref> for the complete list of features. For do- mains 2, 4, 6, and 8, which are the target domains in the domain adaptation experiments, these ra- tios are 0.37, 0.73, 0.69, and 0.93. The ratios for the other four domains are similarly high. This shows that bag-of-words features play a signifi- cant role in the prediction of the essay scores. We examine the number of bag-of-words features that 100 additional target domain essays would add to SourceOnly; that is, we compare the bag-of-words features for SourceOnly with those of SharedHy- per, EasyAdapt, Concat, and ML-ρ for n t = 100. The numbers of these additional features, aver- aged over the five folds, are 269, 351, 377, and 291 for target domains 2, 4, 6, and 8 respectively. In terms of percentages, these are 67%, 87%, 94%, and 72% more features over SourceOnly. Such a large number of additional bag-of-words features contributed by target-domain essays, together with the fact that these features are given high weights, means that target-domain essays are important.</p><p>Comparing domain adaptation methods We now compare the four domain adaptation meth- ods: SharedHyper, EasyAdapt, Concat, and ML-ρ. We recall that the first three are constrained cases of the last by fixing ρ to 0, 0.5, and 1 respec- tively. First, we see that SharedHyper is a rather poor domain adaptation method for AES, because it gives the lowest QWK score, except for the case of using 25, 50, and 100 target essays in adapt- ing from prompt 7 to prompt 8, where it is better than Concat. In fact, its scores are generally close to the TargetOnly scores. This is unsurprising, since in SharedHyper the weights are effectively not shared between the target and source training examples: only the hyper-parameters α and λ are shared. This is a weak form of information sharing between the target and source domains. Hence, we expect this to perform suboptimally when the target and source domains bear more than spuri- ous relationship, which is indeed the case here be- cause we have chosen the source and target do- main pairs based on their similarities, as described in Section 5.1.</p><p>We now focus on EasyAdapt, Concat, and ML-ρ, which are the better domain adaptation methods from our results. We see that ML-ρ ei- ther gives the best or second-best scores, except for the one case of 5 → 6 with 10 target essays. In comparison, although Concat performs consis- tently well for 1 → 2, 3 → 4, and 5 → 6, its QWK scores for 7 → 8 are quite poor and even lower than those of TargetOnly for 25 or more target es- says. In contrast to Concat, EasyAdapt performs well for 7 → 8 but not so well for the other three domain pairs. Let us examine the reason for contrasting re- sults between EasyAdapt and Concat to appreci- ate the flexibility afforded by ML-ρ. The ρ es- timated by ML-ρ for the pairs 1 → 2, 3 → 4, 5 → 6, and 7 → 8 with 100 target essays are 0.81, 0.97, 0.76, and 0.63 averaged over five folds. The lower estimated correlation ρ for 7 → 8 means that prompt 7 and prompt 8 are not as similar as the other pairs are. In such a case as this, Concat, which in effect considers the target domain to be exactly the same as the source domain, can per- form very poorly. For the other three pairs which are more similar, the correlation of 0.5 assumed by EasyAdapt is not strong enough to fully exploit the similarities between the domains. Unlike Concat and EasyAdapt, ML-ρ has the flexibility to allow it to traverse effectively between the different de- grees of domain similarity or relatedness based on the source domain and target domain training data. In view of this, we consider ML-ρ to be a compet- itive default domain adaptation algorithm for the AES task.</p><p>In retrospect of our present results, it can be obvious why prompts 7 and 8 are not as simi- lar as we would have hoped for more effective domain adaptation. Both prompts ask for narra- tive essays, and these by nature are very prompt- specific and require words and phrases relating di- rectly to the prompts. In fact, referring to a pre- vious discussion on the contributions by target- domain essays, we see that weights for the bag- of-words features for prompt 8 contribute a high of 93% of the total. When we examine the bag- of-words features, we see that prompt 7 (which is to write about patience) contributes only 19% to the bag-of-words features of prompt 8 (which is to write about laughter) in the in-domain experiment. This means that 81% of the bag-of-words features, which are important to narrative essays, must be contributed by the target-domain essays relating to prompt 8. Future work on domain adaptation for AES can explore chosing the prior p ρ on ρ to better reflect the nature of the essays involved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we investigate the effectiveness of us- ing domain adaptation when we only have a small number of target domain essays. We have shown that domain adaptation can achieve better results compared to using just the small number of target domain data or just using a large amount of data from a different domain. As such, our research will help reduce the amount of annotation work needed to be done by human graders to introduce a new prompt.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Feature</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Type</head><label></label><figDesc></figDesc><table>Feature Description 

Length 
Number of characters 
Number of words 
Number of commas 
Number of apostrophes 
Number of sentence ending punctuation symbols ( ".", "?", or "!") 
Average word length 

Part of speech (POS) Number of bad POS n-grams 
Number of bad POS n-grams divided by the total number of words in the essay 

Prompt 
Number of words in the essay that appears in the prompt 
Number of words in the essay that appears in the prompt divided by the total 
number of words in the essay 
Number of words in the essay which is a word or a synonym of a word that 
appears in the prompt 
Number of words in the essay which is a word or a synonym of a word that 
appears in the prompt divided by the total number of words in the essay 

Bag of words 
Count of useful unigrams and bigrams (unstemmed) 
Count of stemmed and spell corrected useful unigrams and bigrams 

Table 1: Description of the features used by EASE. 

</table></figure>

			<note place="foot" n="1"> http://www.kaggle.com/c/asap-aes</note>

			<note place="foot" n="2"> http://www.vantagelearning.com/products/intellimetric/</note>

			<note place="foot" n="4"> https://www.kaggle.com/c/asap-aes/data</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is supported by Singapore Ministry of Education Academic Research Fund Tier 2 grant MOE2013-T2-1-150.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automated essay scoring with e-rater R v. 2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yigal</forename><surname>Attali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational Testing Service</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Joint emotion analysis via multi-task Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Natural Language Processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain adaptation with structural correspondence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automated essay scoring by maximizing human-machine agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<editor>Christiane Fellbaum</editor>
		<imprint>
			<date type="published" when="1998" />
			<pubPlace>Bradford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the interpretation of χ 2 from contingency tables, and the calculation of p</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society</title>
		<imprint>
			<date type="published" when="1922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The intelligent essay assessor: Applications to educational technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename><surname>Peter W Foltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas K</forename><surname>Laham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Landauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interactive Multimedia Electronic Journal of Computer-Enhanced Learning</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An empirical comparison of features and tuning for phrase-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ets: domain adaptation and stacking for short answer scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Workshop on Semantic Evaluation</title>
		<meeting>the Seventh International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Instance weighting for domain adaptation in NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An introduction to latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thomas K Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename><surname>Foltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Discourse Processes</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatic essay grading using text categorization techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leah S Larkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 21st International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Word segmentation of informal Arabic with domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Computer grading of student prose, using modern concepts and software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Page</forename><surname>Ellis Batten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Experimental Education</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Gaussian Processes for Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><forename type="middle">Edward</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automated essay scoring using Bayes&apos; theorem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahung</forename><surname>Rudner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Technology, Learning and Assessment</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Handbook of Automated Essay Evaluation: Current Applications and New Directions</title>
		<editor>Mark D. Shermis and Jill Burstein</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A new dataset and method for automatically grading ESOL texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Medlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Word sense disambiguation using OntoNotes: An empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Seng</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
