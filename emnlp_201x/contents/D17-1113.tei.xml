<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:56+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Speaking, Seeing, Understanding: Correlating semantic models with conceptual representation in the brain</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luana</forename><surname>Bulat</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Computer Laboratory University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Computer Laboratory University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Computer Laboratory University of Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Speaking, Seeing, Understanding: Correlating semantic models with conceptual representation in the brain</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1081" to="1091"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Research in computational semantics is increasingly guided by our understanding of human semantic processing. However, semantic models are typically studied in the context of natural language processing system performance. In this paper, we present a systematic evaluation and comparison of a range of widely-used, state-of-the-art semantic models in their ability to predict patterns of conceptual representation in the human brain. Our results provide new insights both for the design of computational semantic models and for further research in cognitive neuroscience.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent years have witnessed many breakthroughs in data-driven semantic modelling: from the log- linear skip-gram model of <ref type="bibr" target="#b29">Mikolov et al. (2013a)</ref> to multi-modal meaning representations ( <ref type="bibr" target="#b7">Bruni et al., 2012;</ref><ref type="bibr" target="#b21">Kiela and Bottou, 2014;</ref><ref type="bibr" target="#b23">Kiela and Clark, 2015;</ref><ref type="bibr" target="#b22">Kiela et al., 2015a</ref>). These models boast of a higher performance accuracy in numer- ous semantic tasks, including modeling seman- tic similarity and relatedness <ref type="bibr" target="#b38">(Silberer and Lapata, 2012</ref>), lexical entailment ( <ref type="bibr" target="#b24">Kiela et al., 2015b</ref>), analogy ( <ref type="bibr" target="#b30">Mikolov et al., 2013b</ref>) and metaphor ( <ref type="bibr" target="#b37">Shutova et al., 2016)</ref>. However, less is known about the extent to which such models correlate with and reflect human conceptual representation.</p><p>Much research in the cognitive neuroscience community has been concerned with uncovering how the brain represents conceptual knowledge, by leveraging brain activation data associated with the meanings of concepts obtained during func- tional magnetic resonance imaging (fMRI) exper- iments. In the computational linguistics commu- nity, the availability of such fMRI data provides researchers with a benchmark for evaluating se- mantic model performance in terms of their abil- ity to represent human semantic memory. <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> were the first to demonstrate that distributional semantic models encode some of the patterns found in the fMRI data. Other re- searchers followed in their steps, evaluating tra- ditional count-based distributional models <ref type="bibr" target="#b15">(Devereux et al., 2010;</ref><ref type="bibr" target="#b33">Murphy et al., 2012</ref>), topic model-based semantic features ( <ref type="bibr" target="#b36">Pereira et al., 2013</ref>), psycholinguistic and behavioural features ( <ref type="bibr" target="#b35">Palatucci et al., 2009;</ref><ref type="bibr" target="#b9">Chang et al., 2010;</ref><ref type="bibr" target="#b16">Fernandino et al., 2015</ref>) and visual representations ( <ref type="bibr" target="#b0">Anderson et al., 2013</ref><ref type="bibr" target="#b2">Anderson et al., , 2017</ref>. While all of these studies report correlation between the investigated semantic models and patterns found in the brain imaging data, their focus on individual models and the use of different datasets and prediction meth- ods make their results difficult to compare and to integrate into a coherent evaluation landscape. The work of <ref type="bibr" target="#b33">Murphy et al. (2012)</ref> is an exception, in that the authors systematically compare several distributional models with a range of parameters on the same brain imaging dataset. However, they focus on the traditional count-based distributional models only.</p><p>We take inspiration from the works of <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> and <ref type="bibr" target="#b33">Murphy et al. (2012)</ref>; however, we conduct a more extensive study of the ability of different types of semantic models to predict the patterns of brain activity associated with con- ceptual representation. We evaluate and compare several kinds of semantic models, using different modalities and data sources: (1) traditional count- based distributional models (with word window- based and dependency-based contexts) learnt from text; (2) log-linear skip-gram models (with word window-based and dependency-based contexts); (3) behavioural models based on the free associ- ation task; (4) word representations learnt from visual data; and (5) multi-modal word repre- sentations combining linguistic and visual infor- mation. Unlike previous studies, where evalu- ations were typically conducted using a single technique, we evaluate our models using several methods: ridge regression ( <ref type="bibr" target="#b18">Hoerl and Kennard, 1970)</ref>, similarity-based encoding and similarity- based decoding <ref type="bibr" target="#b3">(Anderson et al., 2016)</ref>. Such an experimental setup allows for a comprehensive evaluation and comparison of the models.</p><p>To the best of our knowledge the dependency- based skip-gram model and the free association- based model, as well as their multimodal coun- terparts, have not been previously evaluated on the brain activity prediction task. Other mod- els have been evaluated individually and have not yet been systematically compared within a sin- gle evaluation framework. Providing such a com- parison, our experiments and results demonstrate that (1) visual information is a stronger predic- tor of brain activity than the linguistic informa- tion for concrete nouns; (2) sparse text-based mod- els, whether dependency-based or built using lin- ear bag-of-words context, tend to predict neu- ral activity more accurately than dense models; (3) cognitively-motivated association-based mod- els perform on par with or better than other lin- guistic models, which suggests that they provide an interesting avenue in computational semantics research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The seminal work of <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> in- troduced a new semantic model able to predict brain activation data associated with the meanings of concrete nouns from their corpus-harvested se- mantic representations. They chose a set of 25 verbs to act as semantic features in their distri- butional model, inspired by the importance of sensory-motor features in neural representations of concepts <ref type="bibr" target="#b11">(Cree and McRae, 2003)</ref>.</p><p>Since then, various studies have shown that dis- tributional semantic models encode and are able to predict neural activation patterns associated with concepts <ref type="bibr" target="#b15">(Devereux et al., 2010;</ref><ref type="bibr" target="#b33">Murphy et al., 2012;</ref><ref type="bibr" target="#b36">Pereira et al., 2013)</ref>. <ref type="bibr" target="#b15">Devereux et al. (2010)</ref> build on the work of <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> and show that automatically acquired feature-norm like semantic representations can make equally powerful predictions about brain activity associ- ated with the presentation of words. <ref type="bibr" target="#b36">Pereira et al. (2013)</ref> use semantic features learnt from topic models on Wikipedia to predict neural activation patterns for unseen concepts.</p><p>Several other studies have demonstrated the fit of semantic models built from human behavioural data with regard to predicting neural activation patterns ( <ref type="bibr" target="#b35">Palatucci et al., 2009;</ref><ref type="bibr" target="#b9">Chang et al., 2010;</ref><ref type="bibr" target="#b16">Fernandino et al., 2015)</ref>. <ref type="bibr" target="#b9">Chang et al. (2010)</ref> use brain region encodings as well as detailed taxo- nomic encodings of <ref type="bibr" target="#b28">McRae et al. (2005)</ref> feature norms to predict brain activation patterns using a linear regression model. They demonstrate that learned brain activity patterns can be used to de- code mental states. <ref type="bibr" target="#b16">Fernandino et al. (2015)</ref> use human elicited attribute salience scores based on five sensory-motor attributes (sound, color, visual motion, shape and manipulation) to derive fMRI brain activation patterns for concrete words, but are unsuccessful at modeling neural activation pat- terns for abstract words.</p><p>Recent advances in multi-modal semantics have shown that grounding semantic models in sen- sory modalities improves performance on a variety of tasks <ref type="bibr" target="#b38">(Silberer and Lapata, 2012;</ref><ref type="bibr" target="#b7">Bruni et al., 2012;</ref><ref type="bibr" target="#b21">Kiela and Bottou, 2014;</ref><ref type="bibr" target="#b8">Bulat et al., 2016)</ref>. <ref type="bibr" target="#b0">Anderson et al. (2013)</ref> show that semantic models built from visual data correlate highly with fMRI- based brain activation patterns. <ref type="bibr" target="#b1">Anderson et al. (2015)</ref> find that similarity in activity in the brain areas related to linguistic processing can be bet- ter predicted from text-based semantic representa- tions, whilst image-based representations perform better at predicting similarity in the visual process- ing areas of the brain. In line with the dual coding theory, <ref type="bibr" target="#b2">Anderson et al. (2017)</ref> demonstrate an ad- vantage in decoding brain activity patterns of ab- stract words for text-based semantic models over the image-based ones. Contrary to previous find- ings, <ref type="bibr" target="#b2">Anderson et al. (2017)</ref> find no advantage in decoding neural activity patterns associated with concrete words for image-based models. <ref type="bibr" target="#b33">Murphy et al. (2012)</ref> present the first study sys- tematically comparing several text-based seman- tic models on the brain activity prediction task. They focus on the traditional count-based distri- butional models and achieve the best performance using dependency-based features. Our study is more extensive than that of <ref type="bibr" target="#b33">Murphy et al. (2012)</ref>, as we evaluate both the count-based models and the more recent skip-gram word embeddings, as well as comparing them to free association-based, visual and multi-modal semantic representations. While Murphy and colleagues evaluate the mod- els using one method only -linear regression, we compare predicted neural activation patterns obtained using both regression and the similarity- based encoding and decoding methods proposed by <ref type="bibr" target="#b3">Anderson et al. (2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Brain imaging data</head><p>We use the dataset of fMRI neural activation pat- terns associated with the meanings of nouns, cre- ated by <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> as described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">fMRI experiment</head><p>Nine right-handed adults between the age of 18 and 32 (five female) participated in the study. They were presented with line drawings and noun labels for 60 concrete nouns from 12 semantic classes -animals, body parts, buildings, building parts, clothing, furniture, insects, kitchen items, tools, vegetables, vehicles and man-made objects -with five exemplars per class. The task for the participants during the scanning was to think about the properties of the noun stimuli they were pre- sented with. The entire set of 60 stimulus words was presented six times to every participant, in a different order for each presentation.</p><p>The fMRI images were acquired on a Siemens Allegra 3.0T scanner. The initial data was cor- rected for slice timing, motion and linear trend; spatially normalised and resampled to 3x3x6mm 3 voxels. Only those voxels overlapping with the cortex were selected (approximately 20000 for ev- ery participant).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Voxel selection</head><p>We employ the same voxel selection procedure as <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> for evaluating the sim- ilarity between actual fMRI images and model- predicted fMRI images. Similarity is computed by only taking into account 500 voxels with the most stable activation profile across words -with pro- files compared across the six presentations. The evaluation is performed using leave-two-out cross validation. Voxel selection was performed inde- pendently for each of the cross validation folds, at training time. A voxel's stability score across the six presentations was approximated as the mean pairwise Pearson correlation between its activation profiles over the 58 training words in the cross- validation fold. The 500 voxels with the highest stability score were chosen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Brain activity vectors</head><p>We evaluate our models on the data of each par- ticipant independently. Following <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref>, we obtain a single fMRI image per con- cept (a representative image) by first computing the mean fMRI response over its six presentations, and then subtracting the mean of all 60 of these representative images from each. In the rest of this paper we will refer to these representations as brain activity vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Semantic models</head><p>MITCHELL As a benchmark for all other seman- tic models, we use the publicly available 1 co- occurrence based semantic vectors developed in the <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> study. The features of this semantic space are 25 sensory-motor verbs. Co-occurrence statistics were collected using a window size of 5 words either side of the tar- get word, on a trillion-word corpus provided by Google.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Text-based semantic models</head><p>We train a variety 2 of context-counting and context-predicting text-based semantic models on the January 2016 dump of Wikipedia, which was tokenised using the Stanford NLP tools 3 , lemma- tised with the Morpha lemmatiser ( <ref type="bibr" target="#b31">Minnen et al., 2001</ref>), and parsed with the C&amp;C parser <ref type="bibr" target="#b10">(Clark and Curran, 2007)</ref>. DISTRIB We obtain count-based distributional se- mantic models, using the top 10K most frequent lemmatised words in the corpus (excluding stop- words) as contexts. The context window is de- fined as sentence boundaries. Counts are re- weighted using positive pointwise mutual infor- mation (PPMI) and vectors are L2-normalised. <ref type="bibr">SVD300</ref> We also construct 300-dimensional dense semantic representations by applying singular value decomposition (SVD) <ref type="bibr" target="#b14">(Deerwester et al., 1990</ref>) to DISTRIB.</p><p>DEPS Following <ref type="bibr" target="#b33">Murphy et al. (2012)</ref>, who find that dependency-based semantic vectors perform best on a neurosemantic decoding task, we also include such a semantic space in our compari- son. Vector representations are created by leverag- ing the dependency relations output by the C&amp;C parser <ref type="bibr" target="#b10">(Clark and Curran, 2007)</ref> as features. We use both the incoming and outgoing dependency relations as features; for example, given the de- pendency relation <ref type="figure">(RUN, DOBJ, MARATHON)</ref> we extract the tuple (DOBJ, MARATHON) as a fea- ture for RUN and (!DOBJ, RUN) as a feature for MARATHON. The top 10K most frequent depen- dency features are used as contexts and counts are re-weighted using PPMI.</p><p>DEPS-SVD300 We also obtain 300-dimensional dense dependency-based semantic representations by applying SVD to DEPS.</p><p>EMBED-BOW We train 300-dimensional embed- dings using the standard log-linear skipgram model with negative sampling of <ref type="bibr" target="#b29">Mikolov et al. (2013a)</ref>. The embeddings were trained using lin- ear bag-of-words contexts, with the window de- fined as k = 2 (EMBED-BOW2) or k = 5 (EMBED-BOW5) words either side of the target word. We use 10 negative samples per word- context pair and 15 iterations over the corpus.</p><p>EMBED-DEPS In addition to the embeddings trained with linear bag-of-words contexts, we also obtain 300-dimensional dependency-based word embeddings using the <ref type="bibr" target="#b27">Levy and Goldberg (2014)</ref> implementation of the generalised skip-gram with arbitrary contexts model. Using both incoming and outgoing dependency relations output by the C&amp;C parser, we create word-context pairs using all words and contexts occurring more than 400 times in the corpus. This resulted in a vocabulary of about 92,000 words, with over 250,000 distinct syntactic contexts. We use 10 negative samples per word-context pair and 15 iterations over the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Association-based semantic model</head><p>Free word association datasets ( <ref type="bibr" target="#b13">De Deyne et al., 2016</ref>) represent a rich source of semantic information and have been suc- cessfully used in NLP, including research on se- mantic memory ( <ref type="bibr" target="#b39">Steyvers et al., 2004</ref>) and multi- modal semantics <ref type="bibr" target="#b17">(Hill and Korhonen, 2014)</ref>. Re- cent studies have shown the superiority of se- mantic models built using data collected from multiple-response free association tasks -where subjects are asked to list multiple associative cues for every target word rather than a sin- gle association -over the models built from single-response ones <ref type="bibr" target="#b12">(De Deyne et al., 2013)</ref>. Moreover, such association-based semantic mod- els have been shown to outperform current state- of-the-art text-based language models on concept relatedness and similarity judgments <ref type="bibr" target="#b13">(De Deyne et al., 2016)</ref>.</p><p>We make use of the word association dataset collected as part of the Small World of Words 4 project, where more than 100K fluent English speakers were asked to list three associations for each target word. The dataset contains multiple- response association data for over 10K words. We use a subset of this dataset, where all target words have at least 50 primary, 50 secondary and 50 ter- tiary responses and all responses also appear as normed target words 5 .</p><p>ASSOC We construct a count-based semantic model of word associations (henceforth ASSOC) similarly to a count-based distributional model: the responses are treated as semantic features, and counts are replaced by the sum of primary, sec- ondary and tertiary association frequencies be- tween the target word and the responses. Counts are re-weighted using PPMI and vectors are L2- normalised. The association-based representa- tions obtained for the 60 target words in the <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> dataset under this model are 9854-dimensional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Image-based semantic model</head><p>We also build state-of-the-art deep visual seman- tic representations (henceforth VISUAL) for the 60 concepts in the <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> dataset. Fol- lowing previous work in multi-modal semantics ( <ref type="bibr" target="#b6">Bergsma and Goebel, 2011;</ref><ref type="bibr" target="#b21">Kiela and Bottou, 2014)</ref> and the findings of a recent study of sys- tem architectures and data sources for construct- ing visual representations ( , we retrieve 10 images per concept from Google Im- ages. We use the MMFeat toolkit 6 <ref type="bibr" target="#b20">(Kiela, 2016)</ref> to build our image representations. We extract the 4096-dimensional pre-softmax layer from a for-ward pass through a convolutional neural network ( <ref type="bibr" target="#b26">Krizhevsky et al., 2012)</ref>, which has been pre- trained on the ImageNet classification task using Caffe ( <ref type="bibr" target="#b19">Jia et al., 2014</ref>). We obtain the visual rep- resentation for a given concept by taking the mean of the 10 resulting image representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Multi-modal semantic models</head><p>We also included multi-modal semantic spaces in our analysis, as these are currently widely used in NLP and have been previously shown to achieve the best performance at predicting con- ceptual encodings in the brain ( <ref type="bibr" target="#b1">Anderson et al., 2015)</ref>. Multi-modal semantic spaces are con- structed by combining the visual (VISUAL) and respective linguistic (e.g. MITCHELL, DISTRIB, DEPS) or association-based (ASSOC) representa- tions into a multi-modal representation by con- catenating their respective L2-normalized vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Methods</head><p>In this study, we use two different ways of analysing the correlation between the semantic models described in Section 4 and the fMRI brain activation patterns used as a proxy for human con- ceptual representation. First, we compare these se- mantic models in their predictive power, by look- ing at how well they can synthesise, i.e. predict, brain activation patterns for unseen concepts (Sec- tion 5.1). Secondly, we look at how well they are able to decode neural activation patterns by measuring their success at predicting the stimulus that produced an unlabeled (unseen) fMRI pattern (Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Predicting brain activity patterns</head><p>The brain activity prediction task has been used in previous NLP research as a method of evaluating different semantic models in their ability to model conceptual representation. Most of these studies learn a mapping function between the semantic model of choice and the fMRI neural activity pat- terns using regression techniques ( <ref type="bibr" target="#b32">Mitchell et al., 2008;</ref><ref type="bibr" target="#b15">Devereux et al., 2010;</ref><ref type="bibr" target="#b33">Murphy et al., 2012)</ref>. Recent work by <ref type="bibr" target="#b3">Anderson et al. (2016)</ref> introduce a new method for synthesising fMRI activity pat- terns through similarity-based encoding that does not require model fitting. We compare the predic- tion performance of the semantic models detailed in Section 4 by implementing both a regression- based model and the similarity-based encoding al- gorithm of <ref type="bibr" target="#b3">Anderson et al. (2016)</ref>.</p><p>Regression-based learning Following previous work ( <ref type="bibr" target="#b32">Mitchell et al., 2008;</ref><ref type="bibr" target="#b15">Devereux et al., 2010;</ref><ref type="bibr" target="#b33">Murphy et al., 2012)</ref>, for every participant, we learn a mapping function between semantic model features and brain activation vectors using lin- ear regression. The learned weights are used to make predictions about brain activation vectors as- sociated with concepts that were not seen during training. We implement Ridge regression <ref type="bibr" target="#b18">(Hoerl and Kennard, 1970)</ref>, a multiple linear regression model that uses a least squares loss function and L2 regularisation.</p><p>Similarity-based encoding We implement the similarity-based encoding method introduced by <ref type="bibr" target="#b3">Anderson et al. (2016)</ref>. This method predicts the brain activity vector for an unseen concept by ex- ploiting its similarity (with respect to a particular semantic model) to words for which we have ob- served brain activity vectors.</p><p>The first step in predicting a brain activity vec- tor for an unseen concept is to compute its se- mantic model similarity code. This is a N - dimensional <ref type="bibr">7</ref> vector of similarity scores -com- puted using Pearson's correlation -between the unseen concept and the N words for which we have brain activation vectors 8 . The predicted brain activity vector for the unseen concept is then "syn- thesised" by using its semantic model similarity code to weight a superposition of brain activity vectors:</p><formula xml:id="formula_0">b = 1 C N i=1 b i · corr( v i , v N +1 )<label>(1)</label></formula><p>Assuming the unseen word is indexed N +1 and v j is the semantic model representation of word j, C is a normalisation constant defined as the sum of absolute values of elements in the semantic model similarity code:</p><formula xml:id="formula_1">C = | N i=1 corr( v i , v N +1 )|<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Decoding neural activity patterns</head><p>We then evaluate our semantic models in terms of their ability to decode unseen fMRI activation pat- terns. The analysis in this case does not involve synthesising brain activation vectors for new con- cepts, but predicting the correct label (stimulus) associated with a given fMRI pattern. We implement the similarity-based decoding procedure as detailed in <ref type="bibr" target="#b3">Anderson et al. (2016)</ref>. The first step is to obtain the semantic model simi- larity matrix -by computing the semantic model similarity codes for each of the 60 concepts in the <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> dataset (as described above) -and the brain activity similarity matrix -by computing brain activity similarity codes.</p><p>At test time, two of the N words are chosen for decoding, together with their respective semantic model similarity codes ( s i , s j ) and brain activity similarity codes ( a i , a j ). Next, s i , s j , a i and a j are obtained by removing the i-th and j-th elements in s i , s j , a i and a j respectively, because entries in the similarity vectors corresponding to the test words would reveal the correct answer in the matching task. We will refer to s i and s j as reduced seman- tic model similarity codes, and by analogy to a </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>All semantic spaces presented in Section 4 have full coverage on the <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref> dataset. All experiments detailed in this section were per- formed separately for every participant and evalu- ated using leave-two-out cross validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Regression experiments</head><p>We repeatedly train a regression model to fit brain activation vectors for each of the semantic spaces described in Section 4, using only 58 of the 60 available concept representations (leave-two-out cross validation). This resulted in 1770 cross- validation folds. <ref type="bibr">9</ref> The only hyperparameter in the regression is λ, which controls the degree of regularisation. The λ hyperparameter was opti- mised when training each cross-validation fold, by choosing from the range 0.0001 to 100 through generalised cross validation (i.e. λ was optimised by only looking at the training items during each cross-validation fold).</p><p>During each testing round, we used the learned mapping function to construct predicted brain acti- vation vectors for the two held out words.We eval- uated each of the semantic models by computing its accuracy of matching the two predicted brain activation vectors with the two observed ones. A matching score was computed by analysing the cosine similarity between the predicted and the observed brain activation vectors. If the sum of similarities for the correct pairing was higher than the one for the incorrect pairing the match- ing accuracy was set to 1 for this cross-validation fold, and otherwise it was set to 0. If the model was choosing the match at random, the expected accuracy is 0.50. The similarity between two brain activation vectors was computed by only taking into account the 500 most stable voxels (during each cross-validation fold) as detailed in Section 3.2. The cross-validated accuracies for each of our semantic models are presented in Ta- ble 1, with selected results also shown in <ref type="figure">Figure 1</ref>. We only report results on two multi-modal mod- els (VISUAL+MITCHELL and VISUAL+ASSOC), as there was no significant difference in performance between any pair of multi-modal models.</p><p>All semantic models learn to predict neu- ral activation patterns for unseen words signif- icantly above chance level. Association-based semantic models (ASSOC) significantly <ref type="bibr">10</ref> outper- form all dense semantic representations (whether embedding-based or SVD-reduced), with p &lt; 0.05. Sparse text-based representations with linear context (DISTRIB and DEPS) significantly outper- form some dense semantic representations. How- ever, no dense semantic models significantly out- perform DISTRIB and DEPS. There is no signif- icant difference between the performance of AS- SOC, DISTRIB and DEPS. Contrary to the findings of Murphy et al. <ref type="formula" target="#formula_0">(2012)</ref>, we do not find any advan- tage in predicting brain activation patterns from dependency-based text models.</p><p>Both VISUAL and multi-modal models signifi- cantly outperform text-based models overall (p &lt; 0.05), excepting MITCHELL with p &lt; 0.11 when comparing to VISUAL and p &lt; 0.09 when compar- ing against multi-modal semantic models. These results support previous findings regarding the im- portance of grounding semantic models in percep- tual input. These grounded semantic models per-</p><formula xml:id="formula_2">MODEL P1 P2 P3 P4 P5 P6 P7 P8 P9 mean MITCHELL 0</formula><p>.78 0.72 0.71 0.75 0.76 0.56 0.71 0.63 0.63 0.70 DISTRIB 0.85 0.67 0.73 0.84 0.72 0.55 0.70 0.54 0.69 0.70 SVD300 0.85 0.65 0.68 0.77 0.67 0.53 0.66 0.52 0.  <ref type="table">Table 1</ref>: Regression results. Cross-validated accuracies for models trained on participants P1 through P9, together with mean over participants.</p><p>form as well as models that encode mental repre- sentations through associations (ASSOC). There is no significant advantage for multi-modal models over VISUAL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Similarity-based encoding experiments</head><p>We also compare performance of the semantic models when the predicted brain activation vec- tor is computed using the <ref type="bibr" target="#b3">Anderson et al. (2016)</ref> similarity based encoding method. We use a leave-two-out cross validation strategy, to match previous work and our experiments detailed in Section 6.1. The similarity-based encoding ap- proach does not require any mapping function to be learned, hence is a robust and fast way to ob- tain synthesised brain activation vectors for un- seen words. During each cross-validation fold, semantic model similarity codes of the two test words were computed using the procedure outlined in Sec- tion 5.1. Predicted brain activation vectors were then synthesised for the two test words by weight- ing a superposition of brain activity vectors using their semantic model similarity codes. The match- ing score for each of the cross-validation folds was computed in the same way as in the case of the regression model (Section 6.1). The only differ- ence was that we measured the similarity between the two brain activation vectors using Pearson's correlation coefficient, following <ref type="bibr" target="#b3">Anderson et al. (2016)</ref>. As in the previous experiment, the ex- pected chance performance of this method is 0.5. The cross-validated accuracies for each of our se- mantic models are shown in <ref type="table" target="#tab_2">Table 2</ref>, with selected results also shown in <ref type="figure">Figure 1</ref>.</p><p>All semantic models perform significantly above chance level. As in the case of the re- gression experiments, there is a clear advantage in synthesising brain activation vectors for visu- ally grounded models (VISUAL and multi-modal models) over the language-based ones (this time including MITCHELL), as well as ASSOC. When looking at the performance of the text-based mod- els in general, there is no difference in perfor- mance when comparing context-predicting mod- els to count-based ones, or sparse semantic models to dense ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Brain activation pattern decoding</head><p>In the similarity-based decoding experiments, we assess the ability of semantic models to iden- tify the correct stimulus for a given brain activa- tion pattern, using the same leave-two-out cross- validation strategy. At test time, we obtain the re- duced semantic model similarity codes and the re- duced neural similarity codes for the two test items as described in Section 5.2. It is important to note that these similarity code vectors do not contain any information about the true labeling, since en- tries corresponding to the test items were removed. Decoding is considered successful if the matching score (computed as the sum of Pearson's correla- tions) is higher for the congruent pair than for the incorrect one. Again, the expected performance for a model decoding at random is 0.50. <ref type="table" target="#tab_3">Table 3</ref> shows the performance of our semantic models, with selected results also shown in <ref type="figure">Figure 1</ref>.</p><p>The performance of all semantic models in the decoding task is significantly above chance level. Grounded semantic models (visual and multi-modal) prove once again to have a signif- icant advantage in decoding brain activation pat- terns over the text-based models and association- based model (p &lt; 0.05). There is no signifi- 0.89 0.72 0.79 0.90 0.79 0.74 0.78 0.56 0.    cant difference in performance between any of the multi-modal models and VISUAL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Discriminating between words in the same semantic class</head><p>Following <ref type="bibr" target="#b32">Mitchell et al. (2008)</ref>, we also compare the models in their ability to make accurate pre- dictions when the two test words are exemplars of the same semantic category <ref type="bibr">11</ref> . This formulation of the task is more difficult, since items in the same semantic class (e.g. dog and cat) are more simi- lar than items from different semantic classes (e.g. eye and desk).</p><p>In order to measure the performance of our models in this task, we recompute the cross- validated accuracies for all three experiments (regression-based learning, encoding and decod- ing) by only taking into account the performance on the 120 cross-validation folds where the test items share the same semantic class. The results across models and experiments show very simi- lar trends as the ones computed using all 1770 <ref type="bibr">11</ref> The 60 concepts are exemplars of 12 semantic classes. cross-validation folds. The majority of the mod- els still perform above chance level, but as ex- pected they perform worse than when evaluated using the entire dataset. Visually-grounded mod- els still perform the best in all three experiments (mean performance across participants for multi- modal models in all three tasks is in the [0.61- 0.63] range).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and future work</head><p>We presented the first systematic comparison of a range of widely-used, state-of-the-art seman- tic models in their ability to predict patterns of conceptual representation in the human brain. Firstly, we demonstrated that visual information is a stronger predictor of brain activity than linguis- tic information for concrete nouns. These findings provide further support to the existing hypotheses about the interplay of linguistic, conceptual and perceptual systems in the human brain . These results also resonate with the success of the rapidly growing field of multimodal seman- tics (   <ref type="figure">Figure 1</ref>: (TOP) Comparison of individual and mean model performance for five selected models (MITCHELL, DEPS, ASSOC, VISUAL, VISUAL+ASSOC), using results in <ref type="table">Table 1</ref> (Ridge regression), <ref type="table" target="#tab_2">Table  2</ref> (Similarity-based encoding) and <ref type="table" target="#tab_3">Table 3</ref> (Similarity-based decoding). (BOTTOM) Mean±SE accuracy of participants for all models.</p><p>Secondly, our results suggest that sparse text- based models, whether dependency-based or built using linear bag-of-words context, predict neural activity more accurately than dense models. We also show that the structure of the text-based se- mantic model (sparse vs. dense) has more influ- ence on the performance than the type of informa- tion used to construct the context (linear bag-of- words vs. dependency-based).</p><p>Finally, we found that cognitively-motivated association-based models perform on par with or better than other linguistic models. These re- sults are in line with the previous findings of be- havioural research suggesting that humans repre- sent the meanings of concepts through association with other concepts (  which in turn endorses the association-based semantic models as a promising direction in computational semantics research.</p><p>An interesting avenue for future work would be to investigate the variance of results amongst in- dividual participants <ref type="figure">(Figure 1)</ref>. Previous stud- ies that use fMRI data always report variation across participants <ref type="bibr" target="#b15">(Devereux et al., 2010;</ref><ref type="bibr" target="#b2">Anderson et al., 2017</ref>) and most often attribute it to head motion. However, understanding how individual variations in participants can impact modeling de- cisions would be of great value to the computa- tional semantics community.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Similarity based encoding results: Cross-validated accuracies for models trained on 
participants P1 through P9, together with mean over participants. 

MODEL 
P1 
P2 
P3 
P4 
P5 
P6 
P7 
P8 
P9 
mean 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Similarity based decoding results: Cross-validated accuracies for models trained on 
participants P1 through P9, together with mean over participants. 

</table></figure>

			<note place="foot" n="1"> https://www.cs.cmu.edu/afs/cs/ project/theo-73/www/science2008/data. html 2 We have experimented with different parameter settings for each type of language-based semantic space (e.g. size of the vectors, number of iterations when learning the embeddings etc.) and found that the reported vectors with &quot;standard&apos; settings perform the best (or do not get significantly outperformed). 3 https://nlp.stanford.edu/software/ index.shtml</note>

			<note place="foot" n="4"> https://smallworldofwords.org/ 5 Total of 9854 words (appearing as both target and responses) and 1092251 association pairs 6 https://github.com/douwekiela/mmfeat</note>

			<note place="foot" n="7"> Assuming that we have N words for which we have both semantic model representations (e.g. DISTRIB vectors) and observed brain activation vectors. 8 The similarities are measured w.r.t. the semantic model we use as &quot;predictor&quot;, e.g. DISTRIB, SVD300 or VISUAL</note>

			<note place="foot" n="9"> There are (60 choose 2) ways to choose two test items from the 60 Mitchell et al. (2008) concepts.</note>

			<note place="foot" n="10"> We used (pairwise) paired t-tests to judge the statistical significance of the difference in performance between any two models within the same experiment.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Luana Bulat is supported by an EPSRC Doctoral Training Grant and ERC Proof of Concept Grant GroundForce (693579). Stephen Clark is sup-ported by ERC Starting Grant <ref type="bibr">DisCoTex (306920)</ref> and ERC Proof of Concept Grant GroundForce (693579). Ekaterina Shutova is supported by the Leverhulme Trust Early Career Fellowship. We thank the anonymous reviewers for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Of words, eyes and brains: Correlating image-based distributional semantic models with neural representations of concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Andrew J Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulisse</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Bordignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="page" from="1960" to="1970" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reading visually embodied meaning from the brain: Visually grounded computational models decode visualobject mental imagery induced by written text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Andrew J Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Lopopolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="309" to="322" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visually grounded and textual semantic models differentially decode brain activity associated with concrete and abstract nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Andrew J Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="17" to="30" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Representational similarity encoding for fMRI: Pattern-based synthesis to predict brain activity using stimulus-model-similarities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew J Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev Ds</forename><surname>Zinszer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raizada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="44" to="53" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Grounded cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barsalou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Psychol</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="617" to="645" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Language and simulation in conceptual processing. Symbols, embodiment, and meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ava</forename><surname>Lawrence W Barsalou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine D</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="245" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using visual information to predict lexical preference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randy</forename><surname>Goebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RANLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="399" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Distributional semantics in technicolor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namkhanh</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="136" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vision and feature norms: Improving automatic feature norm learning through cross-modal maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luana</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="579" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Quantitative modeling of the neural representation of objects: How semantic feature norms can account for fMRI activation. Neuroimage: Special Issue on Multi-variate Deciding and Brain Reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Min Kevin</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><forename type="middle">Adam</forename><surname>Just</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="716" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Widecoverage efficient statistical parsing with ccg and log-linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>James R Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="493" to="552" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Analyzing the factors underlying the structure and computation of the meaning of chipmunk, cherry, chisel, cheese, and cello (and many other such concrete nouns)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Cree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcrae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">163</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Better explanations of lexical and semantic cognition using networks derived from continued rather than single-word associations. Behavior Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simon De Deyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gert</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Storms</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="480" to="498" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predicting human similarity judgments with distributional models: The value of word associations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Simon De Deyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel J</forename><surname>Perfors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 26th International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Indexing by latent semantic analysis. Journal of the American society for information science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Susan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">W</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">K</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harshman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using fMRI activation to conceptual stimuli to evaluate methods for extracting conceptual representations from corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Devereux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 First Workshop on Computational Neurolinguistics</title>
		<meeting>the NAACL HLT 2010 First Workshop on Computational Neurolinguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="70" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Predicting brain activation patterns associated with individual lexical concepts based on five sensory-motor attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Fernandino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">J</forename><surname>Humphries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seidenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">L</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey R</forename><surname>Conant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Binder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="17" to="26" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning abstract concept embeddings from multi-modal data: Since you probably can&apos;t see what I mean</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ridge regression: Biased estimation for nonorthogonal problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert W</forename><surname>Hoerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kennard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="67" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia</title>
		<meeting>the ACM International Conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MMFEAT: A toolkit for extracting multi-modal features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning image embeddings using convolutional neural networks for improved multi-modal semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Grounding semantics in olfactory perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luana</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="231" to="236" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-and cross-modal semantics beyond vision: Grounding in auditory perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2461" to="2470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploiting image generality for lexical entailment detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Comparing Data Sources and Architectures for Deep Visual Representation Learning in Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anita</forename><forename type="middle">L</forename><surname>Ver˝</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dependencybased word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (2)</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semantic feature production norms for a large set of living and nonliving things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Mcrae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George S Cree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Seidenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcnorgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior research methods</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="547" to="559" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Applied morphological processing of english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Minnen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darren</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">03</biblScope>
			<biblScope unit="page" from="207" to="223" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Predicting human brain activity associated with the meanings of nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><forename type="middle">V</forename><surname>Tom M Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Shinkareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Min</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><forename type="middle">Adam</forename><surname>Robert A Mason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Just</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="issue">5880</biblScope>
			<biblScope unit="page" from="1191" to="1195" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Selecting corpus-semantic models for neurolinguistic decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="114" to="123" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The University of South Florida free association, rhyme, and word fragment norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cathy</forename><forename type="middle">L</forename><surname>Douglas L Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas A</forename><surname>Mcevoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schreiber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="402" to="407" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Zero-shot learning with semantic output codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1410" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Using wikipedia to learn semantic feature representations of concrete concepts in neuroimaging experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Detre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="240" to="252" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Black holes and white rabbits: Metaphor identification with visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Maillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting><address><addrLine>San Diego California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-12" />
			<biblScope unit="page" from="160" to="170" />
		</imprint>
	</monogr>
	<note>NAACL HLT 2016</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Grounded models of semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1423" to="1433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Word association spaces for predicting semantic similarity effects in episodic memory. Experimental cognitive psychology and its applications: Festschrift in honor of Lyle Bourne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas L</forename><surname>Richard M Shiffrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nelson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Walter Kintsch, and Thomas Landauer</publisher>
			<biblScope unit="page" from="237" to="249" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
