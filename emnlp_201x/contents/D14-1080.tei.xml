<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Opinion Mining with Deep Recurrent Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Ozan ˙ Irsoy</roleName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
							<email>oirsoy, cardie@cs.cornell.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<postCode>14853</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Opinion Mining with Deep Recurrent Neural Networks</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="720" to="728"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recurrent neural networks (RNNs) are con-nectionist models of sequential data that are naturally applicable to the analysis of natural language. Recently, &quot;depth in space&quot;-as an orthogonal notion to &quot;depth in time&quot;-in RNNs has been investigated by stacking multiple layers of RNNs and shown empirically to bring a temporal hierarchy to the architecture. In this work we apply these deep RNNs to the task of opinion expression extraction formulated as a token-level sequence-labeling task. Experimental results show that deep, narrow RNNs outperform traditional shallow, wide RNNs with the same number of parameters. Furthermore, our approach outperforms previous CRF-based baselines, including the state-of-the-art semi-Markov CRF model, and does so without access to the powerful opinion lexicons and syntactic features relied upon by the semi-CRF, as well as without the standard layer-by-layer pre-training typically required of RNN architectures.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Fine-grained opinion analysis aims to detect the sub- jective expressions in a text (e.g. "hate") and to char- acterize their intensity (e.g. strong) and sentiment (e.g. negative) as well as to identify the opinion holder (the entity expressing the opinion) and the target, or topic, of the opinion (i.e. what the opinion is about) ( ). Fine-grained opinion analysis is important for a variety of NLP tasks including opinion-oriented question answering and opinion summarization. As a result, it has been studied extensively in recent years.</p><p>In this work, we focus on the detection of opinion ex- pressions -both direct subjective expressions (DSEs) and expressive subjective expressions (ESEs) as de- fined in . DSEs consist of explicit mentions of private states or speech events expressing private states; and ESEs consist of expressions that in- dicate sentiment, emotion, etc., without explicitly con- veying them. An example sentence shown in <ref type="table">Table 1</ref> in which the DSE "has refused to make any statements" explicitly expresses an opinion holder's attitude and the  <ref type="table">Table 1</ref>: An example sentence with labels ESE "as usual" indirectly expresses the attitude of the writer.</p><p>Opinion extraction has often been tackled as a se- quence labeling problem in previous work (e.g. <ref type="bibr" target="#b3">Choi et al. (2005)</ref>). This approach views a sentence as a sequence of tokens labeled using the conventional BIO tagging scheme: B indicates the beginning of an opinion-related expression, I is used for tokens inside the opinion-related expression, and O indicates tokens outside any opinion-related class. The example sen- tence in <ref type="table">Table 1</ref> shows the appropriate tags in the BIO scheme. For instance, the ESE "as usual" results in the tags B ESE for "as" and I ESE for "usual".</p><p>Variants of conditional random field (CRF) ap- proaches have been successfully applied to opinion ex- pression extraction using this token-based view <ref type="bibr" target="#b3">(Choi et al., 2005;</ref><ref type="bibr" target="#b1">Breck et al., 2007)</ref>: the state-of-the-art approach is the semiCRF, which relaxes the Marko- vian assumption inherent to CRFs and operates at the phrase level rather than the token level, allowing the in- corporation of phrase-level features <ref type="bibr" target="#b28">(Yang and Cardie, 2012)</ref>. The success of the CRF-and semiCRF-based approaches, however, hinges critically on access to an appropriate feature set, typically based on constituent and dependency parse trees, manually crafted opinion lexicons, named entity taggers and other preprocessing components (see <ref type="bibr" target="#b28">Yang and Cardie (2012)</ref> for an up-to- date list).</p><p>Distributed representation learners provide a differ- ent approach to learning in which latent features are modeled as distributed dense vectors of hidden lay- ers. A recurrent neural network (RNN) is one such learner that can operate on sequential data of variable length, which means it can also be applied as a se- quence labeler. Moreover, bidirectional RNNs incor- porate information from preceding as well as follow- ing tokens <ref type="bibr" target="#b23">(Schuster and Paliwal, 1997</ref>) while recent advances in word embedding induction <ref type="bibr" target="#b4">(Collobert and Weston, 2008;</ref><ref type="bibr" target="#b19">Mnih and Hinton, 2007;</ref><ref type="bibr" target="#b18">Mikolov et al., 2013;</ref><ref type="bibr" target="#b24">Turian et al., 2010</ref>) have enabled more ef- fective training of RNNs by allowing a lower dimen- sional dense input representation and hence, more com- pact networks <ref type="bibr" target="#b16">(Mikolov et al., 2010;</ref><ref type="bibr" target="#b15">Mesnil et al., 2013)</ref>. Finally, deep recurrent networks, a type of RNN with multiple stacked hidden layers, are shown to naturally employ a temporal hierarchy with multi- ple layers operating at different time scales <ref type="bibr" target="#b10">(Hermans and Schrauwen, 2013)</ref>: lower levels capture short term interactions among words; higher layers reflect inter- pretations aggregated over longer spans of text. When applied to natural language sentences, such hierarchies might better model the multi-scale language effects that are emblematic of natural languages, as suggested by previous results <ref type="bibr" target="#b10">(Hermans and Schrauwen, 2013)</ref>. Motivated by the recent success of deep architectures in general and deep recurrent networks in particular, we explore an application of deep bidirectional RNNs - henceforth deep RNNs -to the task of opinion ex- pression extraction. For both DSE and ESE detection, we show that such models outperform conventional, shallow (uni-and bidirectional) RNNs as well as previ- ous CRF-based state-of-the-art baselines, including the semiCRF model.</p><p>In the rest of the paper we discuss related work (Section 2) and describe the architecture and training methods for recurrent neural networks (RNNs), bidi- rectional RNNs, and deep (bidirectional) RNNs (Sec- tion 3). We present experiments using a standard cor- pus for fine-grained opinion extraction in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Opinion extraction. Early work on fine-grained opinion extraction focused on recognizing subjective phrases ( <ref type="bibr" target="#b20">Munson et al., 2005</ref>). <ref type="bibr" target="#b1">Breck et al. (2007)</ref>, for example, formulated the prob- lem as a token-level sequence-labeling problem and ap- ply a CRF-based approach, which significantly outper- formed previous baselines. <ref type="bibr" target="#b3">Choi et al. (2005)</ref> extended the sequential prediction approach to jointly identify opinion holders; <ref type="bibr" target="#b2">Choi and Cardie (2010)</ref> jointly de- tected polarity and intensity along with the opinion ex- pression. Reranking approaches have also been ex- plored to improve the performance of a single sequence labeler <ref type="bibr" target="#b12">(Johansson and Moschitti, 2010;</ref><ref type="bibr" target="#b13">Johansson and Moschitti, 2011</ref>). More recent work relaxes the Marko- vian assumption of CRFs to capture phrase-level inter- actions, significantly improving upon the token-level labeling approach <ref type="bibr" target="#b28">(Yang and Cardie, 2012)</ref>. In par- ticular, <ref type="bibr" target="#b29">Yang and Cardie (2013)</ref> propose a joint infer- ence model to jointly detect opinion expressions, opin- ion holders and targets, as well as the relations among them, outperforming previous pipelined approaches.</p><p>Deep learning. Recurrent neural networks <ref type="bibr" target="#b8">(Elman, 1990)</ref> constitute one important class of naturally deep architecture that has been applied to many sequential prediction tasks. In the context of NLP, recurrent neu- ral networks view a sentence as a sequence of tokens and have been successfully applied to tasks such as lan- guage modeling <ref type="bibr" target="#b17">(Mikolov et al., 2011</ref>) and spoken lan- guage understanding <ref type="bibr" target="#b15">(Mesnil et al., 2013)</ref>. Since clas- sical recurrent neural networks only incorporate infor- mation from the past (i.e. preceding tokens), bidirec- tional variants have been proposed to incorporate in- formation from both the past and the future (i.e. sub- sequent tokens) <ref type="bibr" target="#b23">(Schuster and Paliwal, 1997)</ref>. Bidirec- tionality is especially useful for NLP tasks, since infor- mation provided by the following tokens is generally helpful (and sometimes essential) when making a deci- sion on the current token.</p><p>Stacked recurrent neural networks have been pro- posed as a way of constructing deep RNNs ( <ref type="bibr" target="#b22">Schmidhuber, 1992;</ref><ref type="bibr" target="#b7">El Hihi and Bengio, 1995)</ref>. Careful empir- ical investigation of this architecture showed that mul- tiple layers in the stack can operate at different time scales <ref type="bibr" target="#b10">(Hermans and Schrauwen, 2013)</ref>. <ref type="bibr" target="#b21">Pascanu et al. (2013)</ref> explore other ways of constructing deep RNNs that are orthogonal to the concept of stacking layers on top of each other. In this work, we focus on the stacking notion of depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>This section describes the architecture and training methods for the deep bidirectional recurrent networks that we propose for the task of opinion expression min- ing. Recurrent neural networks are presented in 3.1, bidirectionality is introduced in 3.2, and deep bidirec- tional RNNs, in 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Recurrent Neural Networks</head><p>A recurrent neural network <ref type="bibr" target="#b8">(Elman, 1990</ref>) is a class of neural network that has recurrent connections, which allow a form of memory. This makes them applica- ble for sequential prediction tasks with arbitrary spatio- temporal dimensions. Thus, their structure fits many NLP tasks, when the interpretation of a single sentence is viewed as analyzing a sequence of tokens. In this work, we focus our attention on only Elman-type net- works <ref type="bibr" target="#b8">(Elman, 1990)</ref>.</p><p>In an Elman-type network, the hidden layer h t at time step t is computed from a nonlinear transforma- tion of the current input layer x t and the previous hid- den layer h t−1 . Then, the final output y t is computed using the hidden layer h t . One can interpret h t as an in- termediate representation summarizing the past, which is used to make a final decision on the current input.</p><p>More formally, given a sequence of vectors {x t } t=1..T , an Elman-type RNN operates by comput- ing the following memory and output sequences:</p><formula xml:id="formula_0">h t = f (W x t + V h t−1 + b)<label>(1)</label></formula><formula xml:id="formula_1">y t = g(U h t + c) (2)</formula><p>where f is a nonlinear function, such as the sigmoid function and g is the output nonlinearity, such as the softmax function. W and V are weight matrices be- tween the input and hidden layer, and among the hidden units themselves (connecting the previous intermediate representation to the current one), respectively, while U is the output weight matrix. b and c are bias vec- tors connected to hidden and output units, respectively. As a base case for the recursion in Equation 1, h 0 is assumed to be 0. Training an RNN can be done by optimizing a dis- criminative objective (e.g. the cross entropy for classifi- cation tasks) with a gradient-based method. Backprop- agation through time can be used to efficiently com- pute the gradients <ref type="bibr" target="#b25">(Werbos, 1990)</ref>. This method is es- sentially equivalent to unfolding the network in time and using backpropagation as in feedforward neural networks, while sharing the connection weights across different time steps. The Elman-style RNN is shown in <ref type="figure" target="#fig_0">Figure 1</ref>, top left.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bidirectionality</head><p>Observe that with the above definition of RNNs, we have information only about the past, when making a decision on x t . This is limiting for most NLP tasks. As a simple example, consider the two sentences: "I did not accept his suggestion" and "I did not go to the rodeo". The first has a DSE phrase ("did not ac- cept") and the second does not. However, any such RNN will assign the same labels for the words "did" and "not" in both sentences, since the preceding se- quences (past) are the same: the Elman-style unidirec- tional RNNs lack the representational power to model this task. A simple way to work around this problem is to include a fixed-size future context around a single input vector (token). However, this approach requires tuning the context size, and ignores future information from outside of the context window. Another way to incorporate information about the future is to add bidi- rectionality to the architecture, referred as the bidirec- tional RNN <ref type="bibr" target="#b23">(Schuster and Paliwal, 1997)</ref>:</p><formula xml:id="formula_2">− → h t = f ( − → W x t + − → V − → h t−1 + − → b ) (3) ← − h t = f ( ← − W x t + ← − V ← − h t+1 + ← − b )<label>(4)</label></formula><formula xml:id="formula_3">y t = g(U → − → h t + U ← ← − h t + c)<label>(5)</label></formula><p>where</p><formula xml:id="formula_4">− → W , − → V and − → b</formula><p>are the forward weight matri- ces and bias vector as before;</p><p>← − W , ← − V and ← − b are their backward counterparts; U → , U ← are the output ma- trices; and c is the output bias. 1 Again, we assume</p><formula xml:id="formula_5">− → h 0 = ← − h T +1 = 0.</formula><p>In this setting − → h t and ← − h t can be interpreted as a summary of the past, and the future, respectively, around the time step t. When we make a decision on an input vector, we employ the two in- termediate representations − → h t and ← − h t of the past and the future. (See <ref type="figure" target="#fig_0">Figure 1</ref>, top right.) Therefore in the bidirectional case, we have perfect information about the sequence (ignoring the practical difficulties about capturing long term dependencies, caused by vanishing gradients), whereas the classical Elman-type network uses only partial information as described above.</p><p>Note that the forward and backward parts of the net- work are independent of each other until the output layer when they are combined. This means that during training, after backpropagating the error terms from the output layer to the forward and backward hidden lay- ers, the two parts can be thought of as separate, and each trained with the classical backpropagation through time <ref type="bibr" target="#b25">(Werbos, 1990</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Depth in Space</head><p>Recurrent neural networks are often characterized as having depth in time: when unfolded, they are equiv- alent to feedforward neural networks with as many hidden layers as the number tokens in the input se- quence (with shared connections across multiple layers of time). However, this notion of depth likely does not involve hierarchical processing of the data: across dif- ferent time steps, we repeatedly apply the same trans- formation to compute the memory contribution of the input (W ), to compute the response value from the cur- rent memory (U ) and to compute the next memory vec- tor from the previous one (V ). Therefore, assuming the input vectors {x t } together lie in the same representa- tion space, as do the output vectors {y t }, hidden rep- resentations {h t } lie in the same space as well. As a result, they do not necessarily become more and more abstract, hierarchical representations of one another as we traverse in time. However in the more conventional, stacked deep learners (e.g. deep feedforward nets), an important benefit of depth is the hierarchy among hid- den representations: every hidden layer conceptually lies in a different representation space, and constitutes a more abstract and higher-level representation of the input <ref type="bibr" target="#b0">(Bengio, 2009)</ref>.</p><p>In order to address these concerns, we investi- gate deep RNNs, which are constructed by stacking Elman-type RNNs on top of each other <ref type="bibr" target="#b10">(Hermans and Schrauwen, 2013)</ref>. Intuitively, every layer of the deep RNN treats the memory sequence of the previous layer as the input sequence, and computes its own memory representation.</p><p>More formally, we have:</p><formula xml:id="formula_6">− → h (i) t = f ( − → W (i) → − → h (i−1) t + − → W (i) ← ← − h (i−1) t + − → V (i) − → h (i) t−1 + − → b (i) ) (6) ← − h (i) t = f ( ← − W (i) → − → h (i−1) t + ← − W (i) ← ← − h (i−1) t + ← − V (i) ← − h (i) t+1 + ← − b (i) )<label>(7)</label></formula><p>when i &gt; 1 and</p><formula xml:id="formula_7">− → h (1) t = f ( − → W (1) x t + − → V (1) − → h<label>(1)</label></formula><formula xml:id="formula_8">t−1 + − → b (1) ) (8) ← − h (1) t = f ( ← − W (1) x t + ← − V (1) ← − h<label>(1)</label></formula><formula xml:id="formula_9">t+1 + ← − b (1) )<label>(9)</label></formula><p>Importantly, note that both forward and backward rep- resentations are employed when computing the forward and backward memory of the next layer. Two alternatives for the output layer computations are to employ all memory layers or only the last. In this work we adopt the second approach:</p><formula xml:id="formula_10">y t = g(U → − → h (L) t + U ← ← − h (L) t + c)<label>(10)</label></formula><p>where L is the number of layers. Intuitively, connecting the output layer to only the last hidden layer forces the architecture to capture enough high-level information at the final layer for producing the appropriate output- layer decision.</p><p>Training a deep RNN can be conceptualized as in- terleaved applications of the conventional backprop- agation across multiple layers, and backpropagation through time within a single layer.</p><p>The unidirectional and bidirectional deep RNNs are depicted in the bottom half of <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>Hypotheses. In general, we expected that the deep RNNs would show the most improvement over shal- low RNNS for ESEs -phrases that implicitly convey subjectivity. Existing research has shown that these are harder to identify than direct expressions of sub- jectivity (DSEs): they are variable in length and in- volve terms that, in many (or most) contexts, are neu- tral with respect to sentiment and subjectivity. As a re- sult, models that do a better job interpreting the context should be better at disambiguating subjective vs. non- subjective uses of phrases involving common words (e.g. "as usual", "in fact"). Whether or not deep RNNs would be powerful enough to outperform the state-of- the-art semiCRF was unclear, especially if the semi- CRF is given access to the distributed word represen- tations (embeddings) employed by the deep RNNs. In addition, the semiCRF has access to parse tree informa- tion and opinion lexicons, neither of which is available to the deep RNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Activation Units. We employ the standard softmax activation for the output layer: g(x) = e xi / j e xj . For the hidden layers we use the rectifier linear ac- tivation: f (x) = max{0, x}. Experimentally, recti- fier activation gives better performance, faster conver- gence, and sparse representations. Previous work also reported good results when training deep neural net- works using rectifiers, without a pretraining step ( <ref type="bibr" target="#b9">Glorot et al., 2011</ref>    <ref type="bibr" target="#b1">(Breck et al., 2007;</ref><ref type="bibr" target="#b28">Yang and Cardie, 2012)</ref>, and Proportional Overlap imparts a partial cor- rectness, proportional to the overlapping amount, to each match ( <ref type="bibr" target="#b12">Johansson and Moschitti, 2010;</ref><ref type="bibr" target="#b28">Yang and Cardie, 2012)</ref>. All statistical comparisons are done us- ing a two-sided paired t-test with a confidence level of α = .05.</p><p>Baselines (CRF and SEMICRF). As baselines, we use the CRF-based method of <ref type="bibr" target="#b1">Breck et al. (2007)</ref> and the SEMICRF-based method of <ref type="bibr" target="#b28">Yang and Cardie (2012)</ref>, which is the state-of-the-art in opinion expres- sion extraction. Features that the baselines use are words, part-of-speech tags and membership in a manu- ally constructed opinion lexicon (within a [-1, +1] con- text window). Since SEMICRF relaxes the Markovian assumption and operates at the segment-level instead of the token-level, it also has access to parse trees of sentences to generate candidate segments <ref type="bibr" target="#b28">(Yang and Cardie, 2012)</ref>.</p><p>Word Vectors (+VEC). We also include versions of the baselines that have access to pre-trained word vec- tors. In particular, CRF+VEC employs word vectors as continuous features per every token. Since SEMI- CRF has phrase-level rather than word-level features, we simply take the mean of every word vector for a phrase-level vector representation for SEMICRF+VEC as suggested in <ref type="bibr" target="#b18">Mikolov et al. (2013)</ref>. In all of our experiments, we keep the word vec- tors fixed (i.e. do not finetune) to reduce the degree of freedom of our models. We use the publicly avail- able 300-dimensional word vectors of <ref type="bibr" target="#b18">Mikolov et al. (2013)</ref>, trained on part of the Google News dataset (∼100B words). Preliminary experiments with other word vector representations such as Collobert-Weston (2008) embeddings or HLBL <ref type="bibr" target="#b19">(Mnih and Hinton, 2007)</ref> provided poorer results (∼ −3% difference in propor- tional and binary F1).</p><p>Regularizer. We do not employ any regularization for smaller networks (∼24,000 parameters) because we have not observed strong overfitting (i.e. the differ- ence between training and test performance is small). Larger networks are regularized with the recently pro- posed dropout technique ( : we ran- domly set entries of hidden representations to 0 with a probability called the dropout rate, which is tuned over the development set. Dropout prevents learned  Network Training. We use the standard multiclass cross-entropy as the objective function when training the neural networks. We use stochastic gradient de- scent with momentum with a fixed learning rate (.005) and a fixed momentum rate (.7). We update weights after minibatches of 80 sentences. We run 200 epochs for training. Weights are initialized from small random uniform noise. We experiment with networks of vari- ous sizes, however we have the same number of hidden units across multiple forward and backward hidden lay- ers of a single RNN. We do not employ a pre-training step; deep architectures are trained with the supervised error signal, even though the output layer is connected to only the final hidden layer. With these configura- tions, every architecture successfully converges with- out any oscillatory behavior. Additionally, we employ early stopping for the neural networks: out of all itera- tions, the model with the best development set perfor- mance (Proportional F1) is selected as the final model to be evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results and Discussion</head><p>Bidirectional vs. Unidirectional.  <ref type="table" target="#tab_2">Tables 2  and 3</ref> show the evaluation of RNNs of various depths and sizes. In both tables, the first group networks have approximately 24,000 parameters and the second group networks have approximately 200,000 parame- ters. Since all RNNs within a group have approxi- mately the same number of parameters, they grow nar- rower as they get deeper. Within each group, bold shows the best result with an asterisk denoting statis- tically indistinguishable performance with respect to the best. As noted above, all statistical comparisons use a two-sided paired t-test with a confidence level of α = .05.</p><p>In both DSE and ESE detection and for larger net- works (bottom set of results), 3-layer RNNs provide the best results. For smaller networks (top set of results), 2, 3 and 4-layer RNNs show equally good performance for certain sizes and metrics and, in general, adding ad- ditional layers degrades performance. This could be re- lated to how we train the architectures as well as to the decrease in width of the networks. In general, we ob- serve a trend of increasing performance as we increase the number of layers, until a certain depth. deepRNNs vs. (semi)CRF. <ref type="table" target="#tab_5">Table 4</ref> shows compari- son of the best deep RNNs to the previous best results in the literature. In terms of F-measure, DEEP RNN performs best for both DSE and ESE detection, achiev- ing a new state-of-the-art performance for the more strict proportional overlap measure, which is harder to improve upon than the binary evaluation metric. SEMI- CRF, with its very high recall, performs comparably to the DEEP RNN on the binary metric. Note that RNNs do not have access to any features other than word vec- tors.</p><p>In general, CRFs exhibit high precision but low re- call (CRFs have the best precision on both DSE and ESE detection) while SEMICRFs exhibit a high re- call, low precision performance. Compared to SEMI- CRF, the DEEP RNNs produce an even higher recall but sometimes lower precision for ESE detection. This suggests that the methods are complementary, and can <ref type="formula" target="#formula_0">(1)</ref> The situation obviously remains fluid from hour to hour but it [seems to be] [going in the right direction] <ref type="bibr">DEEPRNN</ref> The situation <ref type="bibr">[obviously]</ref> remains fluid from hour to hour but it [seems to be going in the right] direction SHALLOW The situation <ref type="bibr">[obviously]</ref> remains fluid from hour to hour but it [seems to be going in] the right direction SEMICRF The situation [obviously remains fluid from hour to hour but it seems to be going in the right direction]  potentially be even more powerful when combined in an ensemble method.</p><p>Word vectors. Word vectors help CRFs on both pre- cision and recall on both tasks. However, SEMICRFs become more conservative with word vectors, produc- ing higher precision and lower recall on both tasks. This sometimes hurts overall F-measure. Among the (SEMI)CRF-based methods, SEMICRF obtains the highest F1 score for DSEs and for ESEs using the softer metric; SEMICRF+VEC performs best for ESEs according to the stricter proportional overlap measure.</p><p>Network size. Finally, we observe that even small networks (such as 4-layer deep RNN for DSE and 2-layer deep RNN for ESE) outperform conventional CRFs. This suggests that with the help of good word vectors, we can train compact but powerful sequential neural models.</p><p>When examining the output, we see some system- atic differences between the previously top-performing SEMICRF and the RNN-based models. (See <ref type="figure" target="#fig_1">Figure 2.</ref>) First, SEMICRF often identifies excessively long sub- jective phrases as in Example 1. Here, none of the mod- els exactly matches the gold standard, but the RNNs are much closer. And all three models appear to have identified an ESE that was mistakenly omitted by the human annotator -"obviously". At the same time, the SEMICRF sometimes entirely misses subjective ex- pressions that the RNNs identify -this seems to occur when there are no clear indications of sentiment in the subjective expression. The latter can be seen in Exam- ples 2 and 3, in which the SEMICRF does not identify "but equally", "would have to be based on evidence", "not yet", and "not enough".</p><p>We also observe evidence of the power of the DEEP- RNN over the SHALLOWRNN in Examples 4 and 5. (See <ref type="figure" target="#fig_2">Figure 3.</ref>) In contrast to <ref type="figure" target="#fig_1">Figure 2</ref>, <ref type="figure" target="#fig_2">Figure 3</ref> dis- tinguishes subjective expressions that are (correctly) assigned an initial Begin label from those that con- sist only of Inside labels 2 -the latter are shown in ALL CAPS and indicate some degree of confusion in the model that produced them. In Example 4, SHAL- LOWRNN exhibits some evidence for each ESE -it labels one or more tokens as Inside an ESE ("any" and "time"). But it does not explicitly tag the beginning of the ESE. DEEPRNN does better, identifying the first ESE in its entirety ("in any case") and identifying more words as being Inside the second ESE ("it is high time). A similar situation occurs in Example 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we have explored an application of deep recurrent neural networks to the task of sentence-level opinion expression extraction. We empirically evalu- ated deep RNNs against conventional, shallow RNNs that have only a single hidden layer. We also com- pared our models with previous (semi)CRF-based ap- proaches.</p><p>Experiments showed that deep RNNs outperformed shallow RNNs on both DSE and ESE extrac- <ref type="bibr">(4)</ref> [In any case] , [it is high time] that a social debate be organized ... DEEPRNN <ref type="bibr">[In any case]</ref> , it is HIGH TIME that a social debate be organized ... SHALLOW In ANY case , it is high TIME that a social debate be organized ... <ref type="formula" target="#formula_3">(5)</ref> Mr. Stoiber [has come a long way] from his refusal to [sacrifice himself] for the CDU in an election that [once looked impossible to win] , through his statement that he would [under no circumstances] run against the wishes... DEEPRNN Mr. Stoiber [has come a long way from] his [refusal to sacrifice himself] for the CDU in an election that [once looked impossible to win] , through his statement that he would [under no circumstances run against] the wishes... SHALLOW Mr. Stoiber has come A LONG WAY FROM his refusal to sacrifice himself for the CDU in an election that [once looked impossible] to win , through his statement that he would under NO CIRCUMSTANCES run against the wishes... tion. Furthermore, deep RNNs outperformed previous (semi)CRF baselines, achieving new state-of-the-art re- sults for fine-grained on opinion expression extraction. We have trained our deep networks without any pre- training and with only the last hidden layer connected to the output layer. One potential future direction is to explore the effects of pre-training on the architec- ture. Pre-training might help to exploit the additional representational power available in deeper networks. Another direction is to investigate the impact of fine- tuning the word vectors during supervised training. Additionally, alternative notions of depth that are or- thogonal to stacking, as in <ref type="bibr" target="#b21">Pascanu et al. (2013)</ref> can be investigated for this task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Recurrent neural networks. Each black, orange and red node denotes an input, hidden or output layer, respectively. Solid and dotted lines denote the connections of forward and backward layers, respectively. Top: Shallow unidirectional (left) and bidirectional (right) RNN. Bottom: 3-layer deep unidirectional (left) and bidirectional (right) RNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Examples of output. In each set, the gold-standard annotations are shown in the first line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: DEEPRNN Output vs. SHALLOWRNN Output. In each set of examples, the gold-standard annotations are shown in the first line. Tokens assigned a label of Inside with no preceding Begin tag are shown in ALL CAPS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>). Data. We use the MPQA 1.2 corpus (Wiebe et al., 2005) (535 news articles, 11,111 sentences) that is manually annotated with both DSEs and ESEs at the phrase level. As in previous work, we separate 135 documents as a development set and employ 10-fold CV over the remaining 400 documents. The develop- ment set is used during cross validation to do model selection.</figDesc><table>Layers 

|h| 
Precision 
Recall 
F1 
Prop. 
Bin. 
Prop. 
Bin. 
Prop 
Bin. 
Shallow 36 
62.24 
65.90 
65.63* 73.89* 63.83 
69.62 
Deep 2 
29 
63.85* 67.23* 65.70* 74.23* 64.70* 70.52* 
Deep 3 
25 
63.53* 67.67* 65.95* 73.87* 64.57* 70.55* 
Deep 4 
22 
64.19* 68.05* 66.01* 73.76* 64.96* 70.69* 
Deep 5 
21 
60.65 
61.67 
56.83 
69.01 
58.60 
65.06 
Shallow 200 62.78 
66.28 
65.66* 74.00* 64.09 
69.85 
Deep 2 
125 62.92* 66.71* 66.45* 74.70* 64.47 
70.36 
Deep 3 
100 65.56* 69.12* 66.73* 74.69* 66.01* 71.72* 
Deep 4 
86 
61.76 
65.64 
63.52 
72.88* 62.56 
69.01 
Deep 5 
77 
61.64 
64.90 
62.37 
72.10 
61.93 
68.25 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Experimental evaluation of RNNs for DSE extraction</head><label>2</label><figDesc></figDesc><table>Layers 
|h| 
Precision 
Recall 
F1 
Prop. 
Bin. 
Prop. 
Bin. 
Prop 
Bin. 
Shallow 36 
51.34 
59.54 
57.60 
72.89* 54.22 
65.44 
Deep 2 
29 
51.13 
59.94 
61.20* 75.37* 55.63* 66.64* 
Deep 3 
25 
53.14* 61.46* 58.01 
72.50 
55.40* 66.36* 
Deep 4 
22 
51.48 
60.59* 59.25* 73.22 
54.94 
66.15* 
Deep 5 
21 
49.67 
58.42 
48.98 
65.36 
49.25 
61.61 
Shallow 200 52.20* 60.42* 58.11 
72.64 
54.75 
65.75 
Deep 2 
125 51.75* 60.75* 60.69* 74.39* 55.77* 66.79* 
Deep 3 
100 52.04* 60.50* 61.71* 76.02* 56.26* 67.18* 
Deep 4 
86 
50.62* 58.41* 53.55 
69.99 
51.98 
63.60 
Deep 5 
77 
49.90* 57.82 
52.37 
69.13 
51.01 
62.89 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Experimental evaluation of RNNs for ESE extraction 

Evaluation Metrics. We use precision, recall and F-
measure for performance evaluation. Since the bound-
aries of expressions are hard to define even for human 
annotators (Wiebe et al., 2005), we use two soft notions 
of the measures: Binary Overlap counts every over-
lapping match between a predicted and true expres-
sion as correct </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Comparison of Deep RNNs to state-of-the-art (semi)CRF baselines for DSE and ESE detection 

features from co-adapting, and it has been reported 
to yield good results when training deep neural net-
works (Krizhevsky et al., 2012; Dahl et al., 2013). 

</table></figure>

			<note place="foot" n="1"> As a convention, we adopt the following notation throughout the paper: Superscript arrows for vectors disambiguate between forward and backward representations. Superscript arrows for matrices denote the resulting vector representations (connection outputs), and subscript arrows for matrices denote incoming vector representations (connection inputs). We omit subscripts when there is no ambiguity.</note>

			<note place="foot" n="2"> Sequences of I&apos;s are decoded as the associated DSE or ESE even though they lack the initial B.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by NSF grant IIS-1314778 and DARPA DEFT Grant FA8750-13-2-0015. The views and conclusions contained herein are those of the authors and should not be interpreted as necessar-ily representing the official policies or endorsements, either expressed or implied, of NSF, DARPA or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning deep architectures for ai. Foundations and trends R in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Identifying expressions of opinion in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2683" to="2688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hierarchical sequential learning for extracting opinions and their attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010 Conference Short Papers</title>
		<meeting>the ACL 2010 Conference Short Papers</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="269" to="274" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Identifying sources of opinions with conditional random fields and extraction patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT/EMNLP</title>
		<meeting>HLT/EMNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="355" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving deep neural networks for lvcsr using rectified linear units and dropout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><forename type="middle">N</forename><surname>George E Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>ICASSP</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page">2013</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<title level="m">IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="8609" to="8613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hierarchical recurrent neural networks for long-term dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">El</forename><surname>Salah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Hihi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="493" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Finding structure in time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeffrey L Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Artificial Intelligence and Statistics. JMLR W&amp;CP</title>
		<meeting>the 14th International Conference on Artificial Intelligence and Statistics. JMLR W&amp;CP</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Training and analysing deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michiel</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Schrauwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing coadaptation of feature detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Geoffrey E Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Syntactic and semantic structure for opinion expression detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Fourteenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="67" to="76" />
		</imprint>
		<respStmt>
			<orgName>Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extracting opinion expressions and their polarities: exploration of pipelines and joint models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="101" to="106" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Investigation of recurrent-neuralnetwork architectures and learning methods for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2010-01" />
			<biblScope unit="page" from="1045" to="1048" />
		</imprint>
	</monogr>
	<note>Cernock`Cernock`y, and Sanjeev Khudanpur</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Extensions of recurrent neural network language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Kombrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Cernocky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="5528" to="5531" />
		</imprint>
	</monogr>
	<note>2011 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Three new graphical models for statistical language modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="641" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Optimizing to arbitrary nlp metrics using ensemble selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arthur Munson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
	<note>Proceedings of HLT/EMNLP</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Glar Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6026</idno>
		<title level="m">How to construct deep recurrent neural networks</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning complex, extended sequences using the principle of history compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="234" to="242" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks. Signal Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuldip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Word representations: a simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Backpropagation through time: what it does and how to do it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul J Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity in phrase-level sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="347" to="354" />
		</imprint>
	</monogr>
	<note>Proceedings of HLT/EMNLP</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Extracting opinion expressions with semi-markov conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1335" to="1345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Joint inference for fine-grained opinion extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
