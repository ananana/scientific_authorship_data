<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khanh</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename><forename type="middle">♠</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
						</author>
						<title level="a" type="main">Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1464" to="1474"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
					<note>University of Maryland: Computer Science, Language Science, ♠ iSchool, ♣ UMIACS ♦ Microsoft Research, New York ♥</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Machine translation is a natural candidate problem for reinforcement learning from human feedback: users provide quick, dirty ratings on candidate translations to guide a system to improve. Yet, current neural machine translation training fo-cuses on expensive human-generated reference translations. We describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback. Our algorithm combines the advantage actor-critic algorithm (Mnih et al., 2016) with the attention-based neural encoder-decoder architecture (Luong et al., 2015). This algorithm (a) is well-designed for problems with a large action space and delayed rewards, (b) effectively optimizes traditional corpus-level machine translation metrics, and (c) is robust to skewed, high-variance, granular feedback modeled after actual human behaviors.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Bandit structured prediction is the task of learning to solve complex joint prediction problems (like parsing or machine translation) under a very lim- ited feedback model: a system must produce a sin- gle structured output (e.g., translation) and then the world reveals a score that measures how good or bad that output is, but provides neither a "cor- rect" output nor feedback on any other possible output ( <ref type="bibr" target="#b6">Chang et al., 2015;</ref><ref type="bibr" target="#b39">Sokolov et al., 2015)</ref>. Because of the extreme sparsity of this feedback, a common experimental setup is that one pre-trains a good-but-not-great "reference" system based on whatever labeled data is available, and then seeks to improve it over time using this bandit feedback.</p><p>A common motivation for this problem setting is cost. In the case of translation, bilingual "ex- perts" can read a source sentence and a possible translation, and can much more quickly provide a rating of that translation than they can produce a full translation on their own. Furthermore, one can often collect even less expensive ratings from "non-experts" who may or may not be bilingual ( <ref type="bibr" target="#b14">Hu et al., 2014)</ref>. Breaking this reliance on ex- pensive data could unlock previously ignored lan- guages and speed development of broad-coverage machine translation systems.</p><p>All work on bandit structured prediction we know makes an important simplifying assumption: the score provided by the world is exactly the score the system must optimize ( §2). In the case of pars- ing, the score is attachment score; in the case of machine translation, the score is (sentence-level) BLEU. While this simplifying assumption has been incredibly useful in building algorithms, it is highly unrealistic. Any time we want to optimize a system by collecting user feedback, we must take into account:</p><p>1. The metric we care about (e.g., expert ratings) may not correlate perfectly with the measure that the reference system was trained on (e.g., BLEU or log likelihood); 2. Human judgments might be more granu- lar than traditional continuous metrics (e.g., thumbs up vs. thumbs down); 3. Human feedback have high variance (e.g., different raters might give different responses given the same system output); 4. Human feedback might be substantially skewed (e.g., a rater may think all system out- puts are poor). Our first contribution is a strategy to simulate ex- pert and non-expert ratings to evaluate the robust- ness of bandit structured prediction algorithms in general, in a more realistic environment ( §4). We construct a family of perturbations to capture three attributes: granularity, variance, and skew. We apply these perturbations on automatically gener- ated scores to simulate noisy human ratings. To make our simulated ratings as realistic as possible, we study recent human evaluation data ( <ref type="bibr" target="#b9">Graham et al., 2017</ref>) and fit models to match the noise pro- files in actual human ratings ( §4.2).</p><p>Our second contribution is a reinforcement learning solution to bandit structured prediction and a study of its robustness to these simulated human ratings ( § 3). <ref type="bibr">1</ref> We combine an encoder- decoder architecture of machine translation <ref type="bibr" target="#b26">(Luong et al., 2015</ref>) with the advantage actor-critic al- gorithm <ref type="bibr" target="#b29">(Mnih et al., 2016)</ref>, yielding an approach that is simple to implement but works on low- resource bandit machine translation. Even with substantially restricted granularity, with high vari- ance feedback, or with skewed rewards, this com- bination improves pre-trained models ( §6). In par- ticular, under realistic settings of our noise param- eters, the algorithm's online reward and final held- out accuracies do not significantly degrade from a noise-free setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Bandit Machine Translation</head><p>The bandit structured prediction problem ( <ref type="bibr" target="#b6">Chang et al., 2015;</ref><ref type="bibr" target="#b39">Sokolov et al., 2015</ref>) is an extension of the contextual bandits problem ( <ref type="bibr" target="#b16">Kakade et al., 2008;</ref><ref type="bibr" target="#b22">Langford and Zhang, 2008</ref>) to structured prediction. Bandit structured prediction operates over time i = 1 . . . K as:</p><p>1. World reveals context x (i) 2. Algorithm predicts structured outputˆyoutputˆ</p><formula xml:id="formula_0">outputˆy (i) 3. World reveals reward R ˆ y (i) , x (i)</formula><p>We consider the problem of learning to trans- late from human ratings in a bandit structured prediction framework. In each round, a transla- tion model receives a source sentence x (i) , pro- duces a translationˆytranslationˆ translationˆy (i) , and receives a rating R ˆ y (i) , x (i) from a human that reflects the qual- ity of the translation. We seek an algorithm that achieves high reward over K rounds (high cumu- lative reward). The challenge is that even though the model knows how good the translation is, it knows neither where its mistakes are nor what the "correct" translation looks like. It must bal- ance exploration (finding new good predictions) <ref type="bibr">1</ref> Our code is at https://github.com/ khanhptnk/bandit-nmt (in PyTorch). <ref type="figure">Figure 1</ref>: A translation rating interface provided by Facebook. Users see a sentence followed by its machined-generated translation and can give rat- ings from one to five stars.</p><p>with exploitation (producing predictions it already knows are good). This is especially difficult in a task like machine translation, where, for a twenty token sentence with a vocabulary size of 50k, there are approximately 10 94 possible outputs, of which the algorithm gets to test exactly one.</p><p>Despite these challenges, learning from non- expert ratings is desirable. In real-world scenar- ios, non-expert ratings are easy to collect but other stronger forms of feedback are prohibitively ex- pensive. Platforms that offer translations can get quick feedback "for free" from their users to im- prove their systems <ref type="figure">(Figure 1</ref>). Even in a setting in which annotators are paid, it is much less expen- sive to ask a bilingual speaker to provide a rating of a proposed translation than it is to pay a profes- sional translator to produce one from scratch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Effective Algorithm for Bandit MT</head><p>This section describes the neural machine trans- lation architecture of our system ( § 3.1). We for- mulate bandit neural machine translation as a re- inforcement learning problem ( § 3.2) and discuss why standard actor-critic algorithms struggle with this problem ( § 3.3). Finally, we describe a more effective training approach based on the advantage actor-critic algorithm ( §3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Neural machine translation</head><p>Our neural machine translation (NMT) model is a neural encoder-decoder that directly computes the probability of translating a target sentence y = (y 1 , · · · , y m ) from source sentence x:</p><formula xml:id="formula_1">P θ (y | x) = m t=1 P θ (y t | y &lt;t , x)<label>(1)</label></formula><p>where P θ (y t | y &lt;t , x) is the probability of out- putting the next word y t at time step t given a translation prefix y &lt;t and a source sentence x.</p><p>We use an encoder-decoder NMT architecture with global attention ( <ref type="bibr" target="#b26">Luong et al., 2015)</ref>, where both the encoder and decoder are recurrent neu- ral networks (RNN) (see Appendix A for a more detailed description). These models are normally trained by supervised learning, but as reference translations are not available in our setting, we use reinforcement learning methods, which only require numerical feedback to function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bandit NMT as Reinforcement Learning</head><p>NMT generating process can be viewed as a Markov decision process on a continuous state space. The states are the hidden vectors h dec t gen- erated by the decoder. The action space is the tar- get language's vocabulary.</p><p>To generate a translation from a source sentence x, an NMT model starts at an initial state h dec 0 : a representation of x computed by the encoder. At time step t, the model decides the next ac- tion to take by defining a stochastic policy P θ (y t | y &lt;t , x), which is directly parametrized by the pa- rameters θ of the model. This policy takes the cur- rent state h dec t−1 as input and produces a probabil- ity distribution over all actions (target vocabulary words). The next actionˆyactionˆ actionˆy t is chosen by taking arg max or sampling from this distribution. The model computes the next state h dec t by updating the current state h dec t−1 by the action takenˆytakenˆ takenˆy t . The objective of bandit NMT is to find a policy that maximizes the expected reward of translations sampled from the model's policy:</p><formula xml:id="formula_2">max θ L pg (θ) = max θ E x∼Dtrˆy∼P x∼Dtrˆ x∼Dtrˆy∼P θ (·|x) R(ˆ y, x)<label>(2)</label></formula><p>where D tr is the training set and R is the reward function (the rater). <ref type="bibr">2</ref> We optimize this objective function with policy gradient methods. For a fixed x, the gradient of the objective in Eq 2 is:</p><formula xml:id="formula_3">θ L pg (θ) = E ˆ y∼P θ (·) [R(ˆ y) θ log P θ (ˆ y)] (3) = m t=1 E ˆ yt∼ P θ (·|ˆy·|ˆy &lt;t ) Q(ˆ y &lt;t , ˆ y t ) θ log P θ (ˆ y t | ˆ y &lt;t )</formula><p>where Q(ˆ y &lt;t , ˆ y t ) is the expected future reward ofˆy ofˆ ofˆy t given the current prefixˆyprefixˆ prefixˆy &lt;t , then continuing sampling from P θ to complete the translation:</p><formula xml:id="formula_4">Q(ˆ y &lt;t , ˆ y t ) = E ˆ y ∼P θ (·|x) ˜ R(ˆ y , x) (4) with˜Rwith˜ with˜R(ˆ y , x) ≡ R(ˆ y , x)1 ˆ y &lt;t = ˆ y &lt;t , ˆ y t = ˆ y t 2</formula><p>Our raters are stochastic, but for simplicity we denote the reward as a function; it should be expected reward.</p><p>1{·} is the indicator function, which returns 1 if the logic inside the bracket is true and returns 0 otherwise.</p><p>The gradient in Eq 3 requires rating all possible translations, which is not feasible in bandit NMT. Na¨ıveNa¨ıve Monte Carlo reinforcement learning meth- ods such as REINFORCE <ref type="bibr" target="#b43">(Williams, 1992)</ref> esti- mates Q values by sample means but yields very high variance when the action space is large, lead- ing to training instability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Why are actor-critic algorithms not effective for bandit NMT?</head><p>Reinforcement learning methods that rely on func- tion approximation are preferred when tackling bandit structured prediction with a large action space because they can capture similarities be- tween structures and generalize to unseen regions of the structure space. The actor-critic algo- rithm (Konda and Tsitsiklis) uses function approx- imation to directly model the Q function, called the critic model. In our early attempts on ban- dit NMT, we adapted the actor-critic algorithm for NMT in <ref type="bibr" target="#b2">Bahdanau et al. (2017)</ref>, which em- ploys the algorithm in a supervised learning set- ting. Specifically, while an encoder-decoder critic model Q ω as a substitute for the true Q function in Eq 3 enables taking the full expectation (because the critic model can be queried with any state- action pair), we are unable to obtain reasonable results with this approach. Nevertheless, insights into why this approach fails on our problem explains the effectiveness of the approach discussed in the next section. There are two properties in <ref type="bibr" target="#b2">Bahdanau et al. (2017)</ref> that our problem lacks but are key elements for a suc- cessful actor-critic. The first is access to refer- ence translations: while the critic model is able to observe reference translations during training in their setting, bandit NMT assumes those are never available. The second is per-step rewards: while the reward function in their setting is known and can be exploited to compute immediate rewards after taking each action, in bandit NMT, the actor- critic algorithm struggles with credit assignment because it only receives reward when a translation is completed. <ref type="bibr" target="#b2">Bahdanau et al. (2017)</ref> report that the algorithm degrades if rewards are delayed un- til the end, consistent with our observations.</p><p>With an enormous action space of bandit NMT, approximating gradients with the Q critic model induces biases and potentially drives the model to wrong optima. Values of rarely taken actions are often overestimated without an explicit constraint between Q values of actions (e.g., a sum-to-one constraint). <ref type="bibr" target="#b2">Bahdanau et al. (2017)</ref> add an ad-hoc regularization term to the loss function to mitigate this issue and further stablizes the algorithm with a delay update scheme, but at the same time intro- duces extra tuning hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Advantage Actor-Critic for Bandit NMT</head><p>We follow the approach of advantage actor- critic (Mnih et al., 2016, A2C) and combine it with the neural encoder-decoder architecture. The resulting algorithm-which we call NED-A2C- approximates the gradient in Eq 3 by a single samplê y ∼ P (· | ˆ x) and centers the reward R(ˆ y) using the state-specific expected future re- ward V (ˆ y &lt;t ) to reduce variance:</p><formula xml:id="formula_5">θ L pg (θ) ≈ m t=1 ¯ R t (ˆ y) θ log P θ (ˆ y t | ˆ y &lt;t )<label>(5)</label></formula><p>with</p><formula xml:id="formula_6">¯ R t (ˆ y) ≡ R(ˆ y) − V (ˆ y &lt;t ) V (ˆ y &lt;t ) ≡ E ˆ y t ∼P (·|ˆy·|ˆy &lt;t ) Q(ˆ y &lt;t , ˆ y t )</formula><p>We train a separate attention-based encoder- decoder model V ω to estimate V values. This model encodes a source sentence x and decodes a sampled translationˆytranslationˆ translationˆy. At time step t, it computes V ω (ˆ y &lt;t , x) = w h crt t , where h crt t is the current decoder's hidden vector and w is a learned weight vector. The critic model minimizes the MSE be- tween its estimates and the true values:</p><formula xml:id="formula_7">L crt (ω) = E x∼Dtrˆy∼P x∼Dtrˆ x∼Dtrˆy∼P θ (·|x) m t=1 L t (ˆ y, x) (6) with L t (ˆ y, x) ≡ [V ω (ˆ y &lt;t , x) − R(ˆ y, x)] 2 .</formula><p>We use a gradient approximation to update ω for a fixed x andˆyandˆ andˆy ∼ P (· | ˆ x):</p><formula xml:id="formula_8">ω L crt (ω) ≈ m t=1 [V ω (ˆ y &lt;t ) − R(ˆ y)] ω V ω (ˆ y &lt;t )<label>(7)</label></formula><p>NED-A2C is better suited for problems with a large action space and has other advantages over actor-critic. For large action spaces, approximat- ing gradients using the V critic model induces lower biases than using the Q critic model. As implied by its definition, the V model is robust to biases incurred by rarely taken actions since re- wards of those actions are weighted by very small probabilities in the expectation. In addition, the V model has a much smaller number of param- eters and thus is more sample-efficient and more stable to train than the Q model. These attractive properties were not studied in A2C's original pa- per ( <ref type="bibr" target="#b29">Mnih et al., 2016</ref>).</p><p>Algorithm 1 The NED-A2C algorithm for bandit NMT.</p><p>1:</p><formula xml:id="formula_9">for i = 1 · · · K do 2:</formula><p>receive a source sentence</p><formula xml:id="formula_10">x (i) 3: sample a translation: ˆ y (i) ∼ P θ (· | x (i) ) 4: receive reward R(ˆ y (i) , x (i) ) 5:</formula><p>update the NMT model using Eq 5. 6: update the critic model using Eq 7. 7: end for Algorithm 1 summarizes NED-A2C for bandit NMT. For each x, we draw a single samplê y from the NMT model, which is used for both estimat- ing gradients of the NMT model and the critic model. We run this algorithm with mini-batches of x and aggregate gradients over all x in a mini- batch for each update. Although our focus is on bandit NMT, this algorithm naturally works with any bandit structured prediction problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Modeling Imperfect Ratings</head><p>Our goal is to establish the feasibility of using real human feedback to optimize a machine translation system, in a setting where one can collect expert feedback as well as a setting in which one only collects non-expert feedback. In all cases, we con- sider the expert feedback to be the "gold standard" that we wish to optimize. To establish the fea- sibility of driving learning from human feedback without doing a full, costly user study, we begin with a simulation study. The key aspects <ref type="figure" target="#fig_0">(Fig- ure 2</ref>) of human feedback we capture are: (a) mis- match between training objective and feedback- maximizing objective, (b) human ratings typically are binned ( § 4.1), (c) individual human ratings have high variance ( §4.2), and (d) non-expert rat- ings can be skewed with respect to expert ratings ( §4.3).</p><p>In our simulated study, we begin by model- ing gold standard human ratings using add-one- smoothed sentence-level BLEU <ref type="bibr" target="#b8">(Chen and Cherry, 2014</ref>). <ref type="bibr">3</ref> Our evaluation criteria, therefore, is av- erage sentence-BLEU over the run of our algo- rithm. However, in any realistic scenario, human feedback will vary from its average, and so the reward that our algorithm receives will be a per- turbed variant of sentence-BLEU. In particular, if the sentence-BLEU score is s ∈ [0, 1], the algo- rithm will only observe s ∼ pert(s), where pert is a perturbation distribution. Because our ref- erence machine translation system is pre-trained using log-likelihood, there is already an (a) mis- match between training objective and feedback, so we focus on (b-d) below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Humans Provide Granular Feedback</head><p>When collecting human feedback, it is often more effective to collect discrete binned scores. A clas- sic example is the Likert scale for human agree- ment (Likert, 1932) or star ratings for product re- views. Insisting that human judges provide con- tinuous values (or feedback at too fine a granular- ity) can demotivate raters without improving rat- ing quality <ref type="bibr" target="#b33">(Preston and Colman, 2000</ref>).</p><p>To model granular feedback, we use a simple rounding procedure. Given an integer parameter g for degree of granularity, we define:</p><formula xml:id="formula_11">pert gran (s; g) = 1 g round(gs)<label>(8)</label></formula><p>This perturbation function divides the range of possible outputs into g + 1 bins. For ex- ample, for g = 5, we obtain bins [0, 0.1), [0.1, 0.3), [0.3, 0.5), [0.5, 0.7), [0.7, 0.9) and [0.9, 1.0]. Since most sentence-BLEU scores are much closer to zero than to one, many of the larger bins are frequently vacant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experts Have High Variance</head><p>Human feedback has high variance around its ex- pected value. A natural goal for a variance model of human annotators is to simulate-as closely as possible-how human raters actually perform. We use human evaluation data recently collected as part of the WMT shared task ( <ref type="bibr" target="#b9">Graham et al., 2017)</ref>. The data consist of 7200 sentences mul- tiply annotated by giving non-expert annotators on Amazon Mechanical Turk a reference sentence and a single system translation, and asking the raters to judge the adequacy of the translation. <ref type="bibr">4</ref> From these data, we treat the average human rating as the ground truth and consider how in- dividual human ratings vary around that mean. To visualize these results with kernel density es- timates (standard normal kernels) of the standard deviation. <ref type="figure">Figure 3</ref> shows the mean rating (x-axis) and the deviation of the human ratings (y-axis) at each mean. <ref type="bibr">5</ref> As expected, the standard deviation is small at the extremes and large in the middle (this is a bounded interval), with a fairly large range in the middle: a translation whose average score is 50 can get human evaluation scores anywhere be- tween 20 and 80 with high probability. We use a linear approximation to define our variance-based perturbation function as a Gaussian distribution, which is parameterized by a scale λ that grows or shrinks the variances (when λ = 1 this exactly matches the variance in the plot). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Non-Experts are Skewed from Experts</head><p>The preceding two noise models assume that the reward closely models the value we want to op- timize (has the same mean). This may not be the case with non-expert ratings. Non-expert   <ref type="table">Table 1</ref>: Sentence counts in data sets.</p><note type="other">40 60 80 100 sentence-level avg rating 0 20 40 60 human rating +-one st mean mean ± stddev linear</note><p>raters are skewed both for reinforcement learn- ing ( <ref type="bibr" target="#b42">Thomaz et al., 2006;</ref><ref type="bibr" target="#b41">Thomaz and Breazeal, 2008;</ref><ref type="bibr" target="#b25">Loftin et al., 2014</ref>) and recommender sys- tems ( <ref type="bibr" target="#b13">Herlocker et al., 2000;</ref><ref type="bibr" target="#b0">Adomavicius and Zhang, 2012</ref>), but are typically bimodal: some are harsh (typically provide very low scores, even for "okay" outputs) and some are motivational (pro- viding high scores for "okay" outputs). We can model both harsh and motivations raters with a simple deterministic skew perturbation function, parametrized by a scalar ρ ∈ [0, ∞):</p><formula xml:id="formula_12">pert skew (s; ρ) = s ρ<label>(10)</label></formula><p>For ρ &gt; 1, the rater is harsh; for ρ &lt; 1, the rater is motivational.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>We choose two language pairs from differ- ent language families with different typological properties: German-to-English and (De-En) and Chinese-to-English (Zh-En). We use parallel tran- scriptions of TED talks for these pairs of lan- guages from the machine translation track of the <ref type="bibr">IWSLT 2014</ref><ref type="bibr" target="#b5">(Cettolo et al., 2014</ref>). For each language pair, we split its data into four sets for supervised training, bandit train- ing, development and testing <ref type="table">(Table 1)</ref>. For En- glish and German, we tokenize and clean sen- tences using Moses ( <ref type="bibr" target="#b19">Koehn et al., 2007)</ref>. For Chi- nese, we use the Stanford Chinese word segmenter ( <ref type="bibr" target="#b7">Chang et al., 2008)</ref> to segment sentences and tok- enize. We remove all sentences with length greater than 50, resulting in an average sentence length of 18. We use IWSLT 2015 data for supervised train- ing and development, IWSLT 2014 data for ban- dit training and previous years' development and evaluation data for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation Framework</head><p>For each task, we first use the supervised train- ing set to pre-train a reference NMT model us- ing supervised learning. On the same training set, we also pre-train the critic model with translations sampled from the pre-trained NMT model. Next, we enter a bandit learning mode where our mod- els only observe the source sentences of the bandit training set. Unless specified differently, we train the NMT models with NED-A2C for one pass over the bandit training set. If a perturbation function is applied to Per-Sentence BLEU scores, it is only applied in this stage, not in the pre-training stage.</p><p>We measure the improvement ∆S of an eval- uation metric S due to bandit training: ∆S = S A2C − S ref , where S ref is the metric computed on the reference models and S A2C is the metric computed on models trained with NED-A2C. Our primary interest is Per-Sentence BLEU: average sentence-level BLEU of translations that are sam- pled and scored during the bandit learning pass. This metric represents average expert ratings, which we want to optimize for in real-world sce- narios. We also measure Heldout BLEU: corpus- level BLEU on an unseen test set, where transla- tions are greedily decoded by the NMT models. This shows how much our method improves trans- lation quality, since corpus-level BLEU correlates better with human judgments than sentence-level BLEU.</p><p>Because of randomness due to both the random sampling in the model for "exploration" as well as the randomness in the reward function, we repeat each experiment five times and report the mean re- sults with 95% confidence intervals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Model configuration</head><p>Both the NMT model and the critic model are encoder-decoder models with global atten- tion ( <ref type="bibr" target="#b26">Luong et al., 2015)</ref>. The encoder and the decoder are unidirectional single-layer LSTMs. They have the same word embedding size and LSTM hidden size of 500. The source and tar- get vocabulary sizes are both 50K. We do not use dropout in our experiments. We train our mod- els by the Adam optimizer ( <ref type="bibr" target="#b18">Kingma and Ba, 2015</ref>) with β 1 = 0.9, β 2 = 0.999 and a batch size of 64. For Adam's α hyperparameter, we use 10 −3 dur- ing pre-training and 10 −4 during bandit learning (for both the NMT model and the critic model). During pre-training, starting from the fifth pass, we decay α by a factor of 0.5 when perplexity on the development set increases. The NMT model reaches its highest corpus-level BLEU on the de- velopment set after ten passes through the super- vised training data, while the critic model's train- ing error stabilizes after five passes. The train- ing speed is 18s/batch for supervised pre-training and 41s/batch for training with the NED-A2C al- gorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Analysis</head><p>In this section, we describe the results of our ex- periments, broken into the following questions: how NED-A2C improves reference models <ref type="figure">( §6.1)</ref>; the effect the three perturbation functions have on the algorithm ( § 6.2); and whether the algorithm improves a corpus-level metric that corresponds well with human judgments ( §6.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Effectiveness of NED-A2C under</head><p>Un-perturbed Bandit Feedback</p><p>We evaluate our method in an ideal setting where un-perturbed Per-Sentence BLEU simulates rat- ings during both training and evaluation <ref type="table">(Table 2)</ref>.</p><p>Single round of feedback. In this setting, our models only observe each source sentence once and before producing its translation. On both De- En and Zh-En, NED-A2C improves Per-Sentence BLEU of reference models after only a single pass (+2.82 and +1.08 respectively).</p><p>Poor initialization. Policy gradient algorithms have difficulty improving from poor initializa- tions, especially on problems with a large ac- tion space, because they use model-based explo- ration, which is ineffective when most actions have equal probabilities ( <ref type="bibr" target="#b2">Bahdanau et al., 2017;</ref><ref type="bibr" target="#b35">Ranzato et al., 2016)</ref>. To see whether NED-A2C has this problem, we repeat the experiment with the same setup but with reference models pre- trained for only a single pass. Surprisingly, NED- A2C is highly effective at improving these poorly Comparisons with supervised learning. To further demonstrate the effectiveness of NED- A2C, we compare it with training the reference models with supervised learning for a single pass on the bandit training set. Surprisingly, observ- ing ground-truth translations barely improves the models in Per-Sentence BLEU when they are fully trained (less than +0.4 on both tasks). A possi- ble explanation is that the models have already reached full capacity and do not benefit from more examples. 6 NED-A2C further enhances the mod- els because it eliminates the mismatch between the supervised training objective and the evalua- tion objective. On weakly trained reference mod- els, NED-A2C also significantly outperforms su- pervised learning (∆Per-Sentence BLEU of NED- A2C is over three times as large as those of super- vised learning).</p><p>Multiple rounds of feedback. We examine if NED-A2C can improve the models even further with multiple rounds of feedback. 7 With super- vised learning, the models can memorize the ref- erence translations but, in this case, the mod- els have to be able to exploit and explore effec- tively. We train the models with NED-A2C for five</p><formula xml:id="formula_13">De-En Zh-En Reference ∆sup ∆A2C Reference ∆sup ∆A2C</formula><p>Fully pre-trained reference model</p><p>Per-Sentence BLEU 38.26 ± 0.02 0.07 ± 0.05 2.82 ± 0.03 32.79 ± 0.01 0.36 ± 0.05 1.08 ± 0.03 Heldout BLEU 24.94 ± 0.00 1.48 ± 0.00 1.82 ± 0.08 13.73 ± 0.00 1.18 ± 0.00 0.86 ± 0.11</p><p>Weakly pre-trained reference model</p><p>Per-Sentence BLEU 19.15 ± 0.01 2.94 ± 0.02 7.07 ± 0.06 14.77 ± 0.01 1.11 ± 0.02 3.60 ± 0.04 Heldout BLEU 19.63 ± 0.00 3.94 ± 0.00 1.61 ± 0.17 9.34 ± 0.00 2.31 ± 0.00 0.92 ± 0.13 <ref type="table">Table 2</ref>: Translation scores and improvements based on a single round of un-perturbed bandit feedback. Per-Sentence BLEU and Heldout BLEU are not comparable: the former is sentence-BLEU, the latter is corpus-BLEU.</p><p>passes and observe a much more significant ∆Per- Sentence BLEU than training for a single pass in both pairs of language (+6.73 on De-En and +4.56 on Zh-En) <ref type="figure" target="#fig_3">(Figure 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Effect of Perturbed Bandit Feedback</head><p>We apply perturbation functions defined in § 4.1 to Per-Sentence BLEU scores and use the per- turbed scores as rewards during bandit training ( <ref type="figure" target="#fig_4">Figure 5</ref>).</p><p>Granular Rewards. We discretize raw Per- Sentence BLEU scores using pert gran (s; g) ( §4.1).</p><p>We vary g from one to ten (number of bins varies from two to eleven). Compared to continuous re- wards, for both pairs of languages, ∆Per-Sentence BLEU is not affected with g at least five (at least six bins). As granularity decreases, ∆Per- Sentence BLEU monotonically degrades. How- ever, even when g = 1 (scores are either 0 or 1), the models still improve by at least a point.</p><p>High-variance Rewards. We simulate noisy rewards using the model of human rating variance pert var (s; λ) ( § 4.2) with λ ∈ {0.1, 0.2, 0.5, 1, 2, 5}. Our models can withstand an amount of about 20% the variance in our human eval data without dropping in ∆Per- Sentence BLEU. When the amount of variance attains 100%, matching the amount of variance in the human data, ∆Per-Sentence BLEU go down by about 30% for both pairs of languages. As more variance is injected, the models degrade quickly but still improve from the pre-trained models. Variance is the most detrimental type of perturbation to NED-A2C among the three aspects of human ratings we model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Skewed</head><p>Rewards. We model skewed raters using pert skew (s; ρ) ( § 4.3) with ρ ∈ {0.25, 0.5, 0.67, 1, 1.5, 2, 4}. NED-A2C is robust to skewed scores. ∆Per-Sentence BLEU is at least 90% of unskewed scores for most skew values. Only when the scores are extremely harsh (ρ = 4) does ∆Per-Sentence BLEU degrade sig- nificantly (most dramatically by 35% on Zh-En). At that degree of skew, a score of 0.3 is suppressed to be less than 0.08, giving little signal for the models to learn from. On the other spectrum, the models are less sensitive to motivating scores as Per-Sentence BLEU is unaffected on Zh-En and only decreases by 7% on De-En.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Held-out Translation Quality</head><p>Our method also improves pre-trained models in Heldout BLEU, a metric that correlates with trans- lation quality better than Per-Sentence BLEU (Ta- ble 2). When scores are perturbed by our rating model, we observe similar patterns as with Per- Sentence BLEU: the models are robust to most perturbations except when scores are very coarse, or very harsh, or have very high variance <ref type="figure" target="#fig_4">(Fig- ure 5, second row)</ref>. Supervised learning improves Heldout BLEU better, possibly because maximiz- ing log-likelihood of reference translations cor- relates more strongly with maximizing Heldout BLEU of predicted translations than maximizing Per-Sentence BLEU of predicted translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work and Discussion</head><p>Ratings provided by humans can be used as effec- tive learning signals for machines. Reinforcement learning has become the de facto standard for in- corporating this feedback across diverse tasks such as robot voice control (Tenorio-Gonzalez et al.,  , and device place- ment ( <ref type="bibr" target="#b27">Mirhoseini et al., 2017)</ref>. Other approaches to more general structured prediction under ban- dit feedback ( <ref type="bibr" target="#b6">Chang et al., 2015;</ref><ref type="bibr">Sokolov et al., 2016a,b)</ref> show the broader efficacy of this frame- work. <ref type="bibr" target="#b35">Ranzato et al. (2016)</ref> describe MIXER for training neural encoder-decoder models, which is a reinforcement learning approach closely related to ours but requires a policy-mixing strategy and only uses a linear critic model. Among work on bandit MT, ours is closest to <ref type="bibr" target="#b21">Kreutzer et al. (2017)</ref>, which also tackle this problem using neu- ral encoder-decoder models, but we (a) take ad- vantage of a state-of-the-art reinforcement learn- ing method; (b) devise a strategy to simulate noisy rewards; and (c) demonstrate the robustness of our method on noisy simulated rewards.</p><p>Our results show that bandit feedback can be an effective feedback mechanism for neural ma- chine translation systems. This is despite that er- rors in human annotations hurt machine learning models in many NLP tasks <ref type="bibr" target="#b36">(Snow et al., 2008</ref>). An obvious question is whether we could extend our framework to model individual annotator prefer- ences ( <ref type="bibr" target="#b31">Passonneau and Carpenter, 2014)</ref> or learn personalized models ( <ref type="bibr" target="#b28">Mirkin et al., 2015;</ref><ref type="bibr" target="#b34">Rabinovich et al., 2017)</ref>, and handle heteroscedastic noise <ref type="bibr" target="#b30">(Park, 1966;</ref><ref type="bibr" target="#b17">Kersting et al., 2007;</ref><ref type="bibr" target="#b1">Antos et al., 2010)</ref>. Another direction is to apply active learning techniques to reduce the sample complex- ity required to improve the systems or to extend to richer action spaces for problems like simulta- neous translation, which requires prediction ( <ref type="bibr" target="#b10">Grissom II et al., 2014</ref>) and reordering ( <ref type="bibr" target="#b12">He et al., 2015)</ref> among other strategies to both minimize delay and effectively translate a sentence ( <ref type="bibr" target="#b11">He et al., 2016</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Examples of how our perturbation functions change the "true" feedback distribution (left) to ones that better capture features found in human feedback (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Learning curves of models trained with NED-A2C for five epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performance gains of NMT models trained with NED-A2C in Per-Sentence BLEU (top row) and in Heldout BLEU (bottom row) under various degrees of granularity, variance, and skew of scores. Performance gains of models trained with un-perturbed scores are within the shaded regions.</figDesc></figure>

			<note place="foot" n="3"> &quot;Smoothing 2&quot; in Chen and Cherry (2014).</note>

			<note place="foot" n="4"> Typical machine translation evaluations evaluate pairs and ask annotators to choose which is better. 5 A current limitation of this model is that the simulated noise is i.i.d. conditioned on the rating (homoscedastic noise). While this is a stronger and more realistic model than assuming no noise, real noise is likely heteroscedastic: dependent on the input.</note>

			<note place="foot" n="6"> This result may vary if the domains of the supervised learning set and the bandit training set are dissimilar. Our training data are all TED talks. 7 The ability to receive feedback on the same example multiple times might not fit all use cases though.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Many thanks to Yvette Graham for her help with the WMT human evaluations data. We thank CU CLEAR and UMD CLIP lab members for useful discussions that led to the ideas of this paper. We also thank the anonymous reviewers for their thor-ough and insightful comments. This work was supported by NSF grants IIS-1320538. Boyd-Graber is also partially supported by NSF grants IIS-1409287, IIS-1564275, IIS-IIS-1652666, and NCSE-1422492. Daumé III is also supported by NSF grant IIS-1618193, as well as an Amazon Research Award. Any opinions, findings, con-clusions, or recommendations expressed here are those of the authors and do not necessarily reflect the view of the sponsor(s).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Impact of data characteristics on recommender systems performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gediminas</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Management Information Systems (TMIS)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Active learning in heteroscedastic noise. Theoretical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">András</forename><surname>Antos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Csaba</forename><surname>Szepesvári</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<biblScope unit="volume">411</biblScope>
			<biblScope unit="page" from="2712" to="2728" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An actor-critic algorithm for sequence prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philemon</forename><surname>Brakel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wit 3 : Web inventory of transcribed and translated talks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Girardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of the European Association for Machine Translation (EAMT)</title>
		<meeting><address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Stüker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roldano</forename><surname>Cattoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<title level="m">The IWSLT 2015 evaluation campaign. In International Workshop on Spoken Language Translation (IWSLT)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Report on the 11th IWSLT evaluation campaign, IWSLT 2014</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Stüker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Spoken Language Translation (IWSLT)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to search better than your teacher</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Optimizing chinese word segmentation for machine translation performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Machine Translation</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A systematic comparison of smoothing techniques for sentencelevel bleu</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Can machine translation systems be evaluated by the crowd alone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="30" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Don&apos;t until the final verb wait: Reinforcement learning for simultaneous machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Grissom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Interpretese vs. translationese: The uniqueness of human strategies in simultaneous interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Syntax-based rewriting for simultaneous machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Grissom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Explaining collaborative filtering recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Joseph A Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Computer Supported Cooperative Work</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Crowdsourced monolingual translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin B</forename><surname>Bederson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction (TOCHI)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">22</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A social reinforcement learning agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Isbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Christian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Shelton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satinder</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Autonomous Agents (AA)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient bandit algorithms for online multiclass prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Sham M Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambuj</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine learning (ICML)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Most likely heteroscedastic gaussian process regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Plagemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pfaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfram</forename><surname>Burgard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vijay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John N</forename><surname>Konda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsitsiklis</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint/>
	</monogr>
	<note>?? Actor-critic algorithms</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bandit structured prediction for neural sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association of Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The epochgreedy algorithm for multi-armed bandits with side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A technique for the measurement of attitudes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rensis</forename><surname>Likert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Archives of Psychology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="55" />
			<date type="published" when="1932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A strategy-aware technique for learning behaviors from discrete human feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Loftin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Macglashan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Michael L Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David L</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roberts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>North Carolina State University. Dept. of Computer Science</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Effective approaches to attentionbased neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Device placement optimization with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azalia</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rasmus</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuefeng</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Motivating personality-aware machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shachar</forename><surname>Mirkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Nowson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Brun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2015 Conference on Empirical Methods on Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Asynchronous methods for deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adria</forename><forename type="middle">Puigdomenech</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Estimation with heteroscedastic error terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rolla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">888</biblScope>
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The benefits of a model of annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rebecca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="311" to="326" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Online human training of a myoelectric prosthesis controller via actor-critic reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patrick M Pilarski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Michael R Dawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farbod</forename><surname>Degris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">P</forename><surname>Fahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard S</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Rehabilitation Robotics (ICORR)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Optimal number of response categories in rating scales: reliability, validity, discriminating power, and respondent preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Carolyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Preston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew M Colman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Personalized machine translation: Preserving original author traits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ella</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shachar</forename><surname>Mirkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><forename type="middle">Nath</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuly</forename><surname>Wintner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaremba</surname></persName>
		</author>
		<title level="m">Sequence level training with recurrent neural networks. International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cheap and fast-but is it good?: Evaluating non-expert annotations for natural language tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning structured predictors from bandit feedback for interactive NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Stochastic structured prediction under bandit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Bandit structured prediction for learning from partial feedback in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanguy</forename><surname>Urvoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MT Summit XV</title>
		<meeting>MT Summit XV<address><addrLine>Miami, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dynamic reward shaping: training a robot by voice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><forename type="middle">F</forename><surname>Ana C Tenorio-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Villaseñor-Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ibero-American Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="483" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Teachable robots: Understanding human teaching behavior to build more effective robot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Andrea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Thomaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Breazeal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">6-7</biblScope>
			<biblScope unit="page" from="716" to="737" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Reinforcement learning with human teachers: Evidence of feedback and guidance with implications for learning performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">Lockerd</forename><surname>Thomaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Breazeal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
