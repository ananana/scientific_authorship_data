<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Answering Elementary Science Questions by Constructing Coherent Scenes using Background Knowledge</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2007">2007-2012. September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Li</surname></persName>
							<email>yangli@cs.ucsb.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence Seattle</orgName>
								<orgName type="institution">UC Santa Barbara Santa Barbara</orgName>
								<address>
									<region>CA, WA</region>
									<country>USA, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
							<email>peterc@allenai.org</email>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence Seattle</orgName>
								<orgName type="institution">UC Santa Barbara Santa Barbara</orgName>
								<address>
									<region>CA, WA</region>
									<country>USA, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Answering Elementary Science Questions by Constructing Coherent Scenes using Background Knowledge</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2007">2007-2012. September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Much of what we understand from text is not explicitly stated. Rather, the reader uses his/her knowledge to fill in gaps and create a coherent, mental picture or &quot;scene&quot; depicting what text appears to convey. The scene constitutes an understanding of the text, and can be used to answer questions that go beyond the text. Our goal is to answer elementary science questions, where this requirement is pervasive ; A question will often give a partial description of a scene and ask the student about implicit information. We show that by using a simple &quot;knowledge graph&quot; representation of the question, we can leverage several large-scale linguistic resources to provide missing background knowledge , somewhat alleviating the knowledge bottleneck in previous approaches. The coherence of the best resulting scene, built from a question/answer-candidate pair, reflects the confidence that the answer candidate is correct, and thus can be used to answer multiple choice questions. Our experiments show that this approach outper-forms competitive algorithms on several datasets tested. The significance of this work is thus to show that a simple &quot;knowl-edge graph&quot; representation allows a version of &quot;interpretation as scene construc-tion&quot; to be made viable.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Elementary grade science tests are challenging as they test a wide variety of commonsense knowl- edge that human beings largely take for granted, yet are very difficult for machines <ref type="bibr" target="#b3">(Clark, 2015)</ref>. For example, consider a question from a NY Re- gents 4th Grade science test: * Work was done while the author was an intern at Allen Institute for Artificial Intelligence.</p><p>Question 1 "When a baby shakes a rattle, it makes a noise. Which form of energy was changed to sound energy?" [Answer: mechanical energy] Science questions are typically quite different from the entity-centric factoid questions exten- sively studied in the question answering (QA) community, e.g., "In which year was Bill Clinton born?" <ref type="bibr" target="#b5">(Ferrucci et al., 2010;</ref><ref type="bibr" target="#b17">Yao and Van Durme, 2014</ref>). While factoid questions are usually an- swerable from text search or fact databases, sci- ence questions typically require deeper analysis. A full understanding of the above question in- volves not just parsing and semantic interpreta- tion; it involves adding implicit information to cre- ate an overall picture of the "scene" that the text is intended to convey, including facts such as: noise is a kind of sound, the baby is holding the rattle, shaking involves movement, the rattle is making the noise, movement involves mechanical energy, etc. This mental ability to create a scene from par- tial information is at the heart of natural language understanding (NLU), which is essential for an- swering these kinds of question. It is also very dif- ficult for a machine because it requires substantial world knowledge, and there are often many ways a scene can be elaborated.</p><p>We present a method for answering multiple- choice questions that implements a simple ver- sion of this. A scene is represented as a "knowl- edge graph" of nodes (words) and relations, and the scene is elaborated with (node,relation,node) tuples drawn from three large-scale linguistic knowledge resources: WordNet <ref type="bibr" target="#b11">(Miller, 1995)</ref>, DART <ref type="bibr" target="#b1">(Clark and Harrison, 2009)</ref>, and the Free- Association database ( <ref type="bibr" target="#b12">Nelson et al., 2004</ref>). These elaborations reflect the mental process of "filling in the gaps", and multiple choice questions can then be answered by finding which answer option creates the most coherent scene.</p><p>The notion of NLU as constructing a most co- herent scene is not new, and has has been stud- ied in several contexts including work on scripts ( <ref type="bibr" target="#b15">Schank and Abelson, 1977)</ref>, interpretation as ab-duction ( <ref type="bibr" target="#b7">Hobbs et al., 1988;</ref><ref type="bibr" target="#b8">Hobbs, 1979;</ref><ref type="bibr">Ovchinnikova et al., 2014</ref>), bridging anaphora <ref type="bibr" target="#b0">(Asher and Lascarides, 1998;</ref><ref type="bibr" target="#b4">Fan et al., 2005</ref>), and para- graph understanding <ref type="bibr" target="#b18">(Zadrozny and Jensen, 1991;</ref><ref type="bibr" target="#b6">Harabagiu and Moldovan, 1997</ref>). These meth- ods are inspiring, but have previously been limited by the lack of background knowledge to supply implicit information, and with the complexity of their representations. To make progress, we have chosen to work with a simple "knowledge graph" representation of nodes (words) and edges (rela- tions). Although we lose some subtlety of expres- sion, we gain the ability to leverage several vast resources of world knowledge to supply implicit information. The significance of this work is thus to show that, by working with a simple "knowl- edge graph" representation, we can make a viable version of "interpretation as scene construction". Although the approach makes several simplifying assumptions, our experiments show that it outper- forms competitive algorithms on several datasets of (real) elementary science questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>The input to our question-answering system is a multiple choice question Q, a set of an- swer options a k , and one or more background knowledge base(s) each containing a set of (word i , relation, word j ) tuples, each denoting that word 1 is plausibly related to word j by relation. The output is a ranked list of the K an- swer options.</p><p>We define a scene S as a "knowledge graph" of nodes (words) and edges (relations between words), where all (word i , relation, word j ) edges are sanctioned by (contained in) at least one of the background knowledge bases. Each scene node has an associated measure of coherence (de- scribed shortly), denoting how well-connected it is. The question-answering objective is, for each answer option a k , to find the most coherent scene containing (at least) the question keywords kw i ∈ Q and answer option a k , and then return the an- swer option with the overall highest coherence score. Our implementation approximates this ob- jective using a simple elaborate-and-prune algo- rithm, illustrated in <ref type="figure" target="#fig_0">Figure 1</ref> 1 and now described.  <ref type="formula">(2)</ref> The scene is elaborated with background knowledge to add plausible rela- tionships. (3) For each answer option, it is added into the scene and connected with additional rela- tionships. Then the scene is pruned. (4) A score is derived from the final scene, reflecting confidence that the answer option is correct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Question Analyzer</head><p>The initial scene is simply the keywords (non-stop words) KW = {kw i } in the question Q, along with a measure of importance IS(kw i ) for each word kw i . For our purposes we compute impor- tance by sending the question to Google, grouping the top 20 result snippets into a document d, and computing:</p><formula xml:id="formula_0">IS(kw) = tf d (kw) df Q (kw) ,<label>(1)</label></formula><p>where tf d (kw) is the term frequency of kw in doc- ument d, and df Q (kw) is the document frequency of kw in question set Q containing all the available elementary science questions. The intuition here is</p><formula xml:id="formula_1">Size KB (# tuples) Examples WordNet 235k (dog,isa,animal) (sunlight,isa,energy) DART 2.3M (nutrients,in,food) (animal,eat,food) FreeAssoc 64k</formula><p>(car,relate to,tire) (ice,relate to,cold) <ref type="table">Table 1</ref>: Knowledge Bases Used that the words frequently mentioned in variations of the question should be important (reflected by "tf"), while the descriptive words (e.g. "follow- ing", "example") which are widely used in many questions should be penalized (reflected by "idf").</p><p>Other methods could equally be used to compute importance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Builder</head><p>In this step our goal is to inject implicit knowl- edge from the background KBs to form an elab- orated knowledge graph. To do this, we first fetch all the triples (kw, relation, w) that are directly connected with any keyword kw ∈ KW from the background KBs, as well as all (kw i , relation, kw j ) triples between keywords.</p><p>In our experiments we use three background knowledge bases to supply implicit knowledge, al- though in principle any triple store could be used: WordNet <ref type="bibr" target="#b11">(Miller, 1995)</ref>, DART <ref type="bibr" target="#b1">(Clark and Harrison, 2009)</ref>, and the FreeAssociation database ( <ref type="bibr" target="#b12">Nelson et al., 2004</ref>). <ref type="table">Table 1</ref> shows examples of each 2 . These triples introduce new nodes w into the graph. As we may get a large number of such nodes, we score them and retain only the top scor- ing ones (and all edges connecting to it). Infor- mally, a new word w is preferred if it is connected to many important keywords kw with strong rela- tionships. Formally, the scoring function is:</p><formula xml:id="formula_2">score(w) = kw∈K IS(kw) * rel(kw, w) (2)</formula><p>where IS(kw) is the importance score of keyword kw and rel(kw, w) is the relatedness score be- tween kw and w. In this work we use the co- sine similarity between word2vec ( <ref type="bibr" target="#b10">Mikolov et al., 2013</ref>) word vectors to measure two words' related- ness, as a rough proxy for the strength of related- ness in the KBs (the KBs themselves do not pro- vide meaningful strengths of relationship). After the ranking, the top N ×|KW | neighbor words w are retained 3 , along with their edges to keywords kw and each other.</p><p>Note that at this point the elaboration process is independent of any answer option; rather, the graph depicts the question scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Elaborate and Prune</head><p>To score the K different answer options, the sys- tem now builds K alternative elaborations of the scene so far, each one with answer option a k added, and assesses the coherence of the addition. The answer option a k that fits "most coherently" with the scene is returned as the answer to the question.</p><p>To do this for a given option a k , we add a k to the graph along with all triples (w i , relation, a k ) in the KBs that relate any node w i in the graph to a k . Now that the focus a k of the question is known, some of the earlier added nodes w in the graph may be only weakly relevant to the question and answer, and so we add a pruning step to re- move these nodes. The goal of this pruning is to find a dense subgraph (i.e. the coherent scene) that would ideally contain all the question keywords kw, the answer option a k , and extra words w k that are highly connected with them.</p><p>Inspired by Sozio et al's work (Sozio and Gio- nis, 2010) on finding strongly interconnected sub- groups in social networks, we have developed an iterative node removal algorithm for extracting this subgraph. We define the coherence of a node as the summed weight of its incident edges:</p><formula xml:id="formula_3">coherence(w) = w ∈{(w,r,w )} rel(w, w ) (3)</formula><p>where rel(w, w ) is the weight of edge (w, r, w ) in the graph, again computed using cosine similar- ity between w and w . We then iteratively remove the non-keyword node (and attached edges) with least coherence until the answer option a k is about to removed. The resulting graph is thus maximally pruned, subject to the constraint it must still de- scribe the question plus answer option.</p><p>Finally, we use the coherence of the answer op- tion a k in this final scene as the confidence that a k is the correct answer. The system repeats this for all K answer options and selects the a k with highest confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>The system was developed using a dataset of natu- ral (unedited) elementary science exam questions, and then tested on three similar, unseen (hidden) datasets. Its performance was compared with two other state-of-the-art systems for this task. As our system only fields questions where the answer op- tions are all single words, we evaluate it, and the other systems, only on these subsets. These sub- sets are in general easier than other questions, but this advantage is the same for all systems being compared so it is still a fair test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation Datasets</head><p>The datasets used are the non-diagram, multiple- choice questions with single-word answer options drawn from the following exams:</p><p>•  <ref type="bibr">(197 questions</ref>) Although these datasets are small (real exam ques- tions of this type are in limited supply), the num- bers are large enough to draw conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments</head><p>We compared our system (called SceneQA) with two other state-of-the-art systems for this task:</p><p>• LSModel (Lexical semantics model): SVM combination of several language models (likeli- hood of answer given question) and information retrieval scores (score of top retrieved sentence matching question plus answer), trained on a set of questions plus answers. (An expanded ver- sion of Section 4.3 of (Jansen et al., 2014))</p><p>• A*Rules: "Prove" the answer option from the question by applying lexical inference rules au- tomatically extracted from science texts. Select the option with the strongest "proof".  <ref type="table">Table 2</ref>: SceneQA outperforms two competitive systems on two of the three test sets. The high- lighted improvements are statistically significant.</p><p>The results (% scores, <ref type="table">Table 2)</ref> show SceneQA significantly outperforms the two other systems on two of the three test sets, including the largest <ref type="figure" target="#fig_0">(Test3, 197 questions)</ref>, suggesting the approach has merit.</p><p>We also performed some case studies to identify what kinds of questions SceneQA does well on, relative to the baselines. In general, SceneQA per- forms well when the question words and the (cor- rect) answer can be tightly related by background knowledge, including through intermediate nodes (words). For example, in Question 2 below:</p><p>Question 2 Which type of energy does a person use to pedal a bicycle? (A) light (B) sound (C) mechanical (D) electrical the KB relates the correct answer "mechanical" to the question words "energy", "pedal", "bicycle", and the intermediate node "power" forming a tight graph. In contrast, the other algorithms select the wrong answer "light" due to frequent mentions of "bicycle lights" in their supporting text corpora that confuses their algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablations</head><p>We also performed ablations to assess which parts of our method are contributing the most:</p><p>• -NewNodes: Only add edges but no new nodes w during the Build step.</p><p>• -Prune: Do not prune nodes during the Elabo- rate and Prune step.  <ref type="table">Table 3</ref>: SceneQA outperforms all the ablations on two of the three test sets. The highlighted im- provements are statistically significant.</p><p>The results (% scores, <ref type="table">Table 3</ref>) suggest that the two most important algorithmic features -adding concepts implied but not explicitly stated in the text (NewNodes), and later removing implied in- formation that is of low relevance to the answer (Prune) -are important for answering the ques- tions correctly. (The small gain without adding NewNodes on Test1 is not statistically significant).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Error Analysis</head><p>We also examined cases where SceneQA gave the wrong answer. Two problems were particularly common:</p><p>(1) There were two answer options with oppo- site meanings, and one of them was correct. For example:</p><p>Question 3 An animal that has a backbone is called a(n) (A) invertebrate (B) vertebrate (C) ex- oskeleton (D) sponge</p><p>Since the relatedness measure we use (i.e. word2vec) cannot distinguish words with similar distributional semantics (a common property of antonyms), our method cannot confidently iden- tify which of the opposites (e.g., here, vertebrate vs. invertebrate) is correct.</p><p>(2) The word ordering in the question is particu- larly important, e.g., questions about processes or sequences. For example:</p><p>Question 4 The process that changes a gas to liq- uid is called (A) condensation (B) melting (C) evaporation (D) vaporization</p><p>Because our method ignores word order (the knowledge graph is initially populated with key- words in the question), the representation is inher- ently incapable of capturing sequential informa- tion (e.g., here, gas to liquid vs. liquid to gas). As a result, it struggles with such questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Conclusion</head><p>Our goal is to answer simple science questions. Unlike entity-centric factoid QA tasks, science questions typically involve general concepts, and answering them requires identifying implicit re- lationships in the question. Our approach is to view question-answering as constructing a coher- ent scene. While the notion of scene construction is not new, our insight is that this can be done with a simple "knowledge graph" representation, allowing several massive background KBs to be applied, somewhat alleviating the knowledge bot- tleneck. Our contribution is to show this works well in the elementary science domain.</p><p>Despite this, there are clearly many limitations with our approach: we are largely ignoring syn- tactic structure in the questions; the KBs are noisy, contributing errors to the scenes; the graph representation has limited expressivity (e.g., no quantification or negation); the word2vec measure of relationship strength does not account for the question context; and contradictions are not de- tected within the scene. These all contributed to QA failures in the tests. However, the approach is appealing as it takes a step towards a richer picture of language understanding, the empirical results are encouraging, and there are many ways these initial limitations can be addressed going forward. We are confident that this is a rich and exciting space, worthy of further exploration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (1) Question keywords are extracted to form the initial scene. (2) The scene is elaborated with background knowledge to add plausible relationships. (3) For each answer option, it is added into the scene and connected with additional relationships. Then the scene is pruned. (4) A score is derived from the final scene, reflecting confidence that the answer option is correct.</figDesc><graphic url="image-1.png" coords="2,307.28,62.81,476.22,365.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2</head><label></label><figDesc>WordNet: all relationships types are used. DART: The NVN and NPN databases with frequency counts &gt; 10 are used. FreeAssoc: The top 3 associations per word were used.</figDesc></figure>

			<note place="foot" n="1"> The system constructs 4 alternative graphs, each contains only one answer option plus some additional related nodes. Figure 1 shows just one of these 4 graphs, namely the graph containing answer option &quot;food&quot;.</note>

			<note place="foot" n="3"> The optimal N (here 6) was selected using an independent set of training questions</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The research was supported by the Allen Insti-tute for Artificial Intelligence (AI2). We thank the Aristo team at AI2 for invaluable discussions, and the anonymous reviewers for helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lascarides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bridging. Journal of Semantics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="113" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Large-scale extraction and use of knowledge from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Harrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth international conference on Knowledge capture</title>
		<meeting>the fifth international conference on Knowledge capture</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic construction of inferencesupporting knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niranjan</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumithra</forename><surname>Bhakthavatsalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Kinkead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AKBC</title>
		<meeting>AKBC</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Elementary school science and math tests as a driver for ai: Take the aristo challenge!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Seventh IAAI Conference</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Indirect anaphora resolution as semantic path search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd international conference on Knowledge capture</title>
		<meeting>the 3rd international conference on Knowledge capture</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Building watson: An overview of the deepqa project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">A</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Prager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Textnet-a text-based intelligent system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">I</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="171" to="190" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Interpretation as abduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jerry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hobbs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Stickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual meeting on Association for Computational Linguistics</title>
		<meeting>the 26th annual meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1988" />
			<biblScope unit="page" from="95" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Coherence and coreference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry R</forename><surname>Hobbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="90" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discourse complements lexical semantics for nonfactoid answer reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="977" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The university of south florida free association, rhyme, and word fragment norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cathy</forename><forename type="middle">L</forename><surname>Douglas L Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas A</forename><surname>Mcevoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schreiber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="402" to="407" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Ovchinnikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niloofar</forename><surname>Montazeri</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Abductive reasoning with a large knowledge base for discourse processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodore</forename><surname>Alexandrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><forename type="middle">R</forename><surname>Hobbs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rutu</forename><surname>Mccord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mulkar-Mehta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing Meaning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="107" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Scripts, Plans, Goals and Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert P Abelson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<pubPlace>Erlbaum, Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The community-search problem and how to plan a successful cocktail party</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Sozio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aristides</forename><surname>Gionis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="939" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Information extraction over structured data: Question answering with freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantics of paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wlodek</forename><surname>Zadrozny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="209" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
