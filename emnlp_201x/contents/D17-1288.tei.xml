<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-modular domain-tailored OCR post-correction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Schulz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Natural Language Processing (IMS)</orgName>
								<orgName type="institution">University of Stuttgart</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Kuhn</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Natural Language Processing (IMS)</orgName>
								<orgName type="institution">University of Stuttgart</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-modular domain-tailored OCR post-correction</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2716" to="2726"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>One of the main obstacles for many Digital Humanities projects is the low data availability. Texts have to be digitized in an expensive and time consuming process whereas Optical Character Recognition (OCR) post-correction is one of the time-critical factors. At the example of OCR post-correction, we show the adaptation of a generic system to solve a specific problem with little data. The system accounts for a diversity of errors encountered in OCRed texts coming from different time periods in the domain of literature. We show that the combination of different approaches, such as e.g. Statistical Machine Translation and spell checking , with the help of a ranking mechanism tremendously improves over single-handed approaches. Since we consider the accessibility of the resulting tool as a crucial part of Digital Humanities collaborations , we describe the workflow we suggest for efficient text recognition and subsequent automatic and manual post-correction.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Humanities are no longer just the realm of schol- ars turning pages of thick books. As the worlds of humanists and computer scientists begin to in- tertwine, new methods to revisit known ground emerge and options to widen the scope of research questions are available. Moreover, the nature of language encountered in such research attracts the attention of the NLP community ( <ref type="bibr" target="#b11">Kao and Jurafsky (2015)</ref>, <ref type="bibr" target="#b16">Milli and Bamman (2016)</ref>). Yet, the basic requirement for the successful implemen- tation of such projects often poses a stumbling block: large digital corpora comprising the textual material of interest are rare. Archives and individ- ual scholars are in the process of improving this situation by applying Optical Character Recog- nition (OCR) to the physical resources. In the Google Books 1 project books are being digitized on a large scale. But even though collections of literary texts like Project Gutenberg 2 exist, these collections often lack the texts of interest to a spe- cific question. As an example, we describe the compilation of a corpus of adaptations of Goethe's Sorrows of the young Werther which allows for the analysis of character networks throughout the pub- lishing history of this work. The success of OCR is highly dependent on the quality of the printed source text. Recognition er- rors, in turn, impact results of computer-aided re- search ( <ref type="bibr" target="#b28">Strange et al., 2014</ref>). Especially for older books set in hard-to-read fonts and with stained paper the output of OCR systems is not good enough to serve as a basis for Digital Humanities (DH) research. It needs to be post-corrected in a time-consuming and cost-intensive process. We describe how we support and facilitate the manual post-correction process with the help of informed automatic post-correction. To account for the problem of relative data sparsity, we illus- trate how a generic architecture agnostic to a spe- cific domain can be adjusted to text specificities such as genre and font characteristics by including just small amounts of domain specific data. We suggest a system architecture (cf. <ref type="figure" target="#fig_0">Figure 1</ref>) with trainable modules which joins general and specific problem solving as required in many applications. We show that the combination of modules via a ranking algorithm yields results far above the per- formance of single approaches. We discuss the point of departure for our research in Section 2 and introduce the data we base our system on in Section 4. In Section 5, we illustrate the most common errors and motivate our multi- modular, partly customized architecture. Section 6 gives an overview of techniques included in our system and the ranking algorithm. In Section 7, we discuss results, the limitations of automatic post-correction and the influence the amount of training data takes on the performance of such a system. Finally, Section 8 describes a way to effi- ciently integrate the results of our research into a digitization work-flow as we see the easy accessi- bility of computer aid as a central point in Digital Humanities collaborations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>There are two obvious ways to automatically im- prove quality of digitized text: optimization of OCR systems or automatic post-correction. Com- monly, OCR utilizes just basic linguistic knowl- edge like character set of a language or reading direction. The focus lies on the image recognition aspect which is often done with artificial neural networks (cf. <ref type="bibr" target="#b9">Graves et al. (2009)</ref>, <ref type="bibr" target="#b6">Desai (2010)</ref>). Post-correction is focused on the correction of er- rors in the linguistic context. It thus allows for the purposeful inclusion of knowledge about the text at hand, e.g. genre-specific vocabulary. Neverthe- less, post-correction has predominantly been tack- led OCR system agnostic as outlined below. As an advantage, post-correction can also be applied when no scan or physical resource is available. There have been attempts towards shared datasets for evaluation. <ref type="bibr" target="#b15">Mihov et al. (2005)</ref> released a cor- pus covering four different kinds of OCRed text comprising German and Bulgarian. However, in 2017 the corpus was untraceable and no recent re- search relating to the data could be found. OCR post-correction is applied in a diversity of fields in order to compile high-quality datasets. This is not merely reflected in the homogeneity of techniques but in the metric of evaluation as well.</p><p>While accuracy has been widely used as evalu- ation measure in OCR post-correction research, Reynaert (2008a) advocates the use of precision and recall in order to improve transparency in eval- uations. Dependent on the paradigm of the applied technique even evaluation measures like BLEU score can be found (cf. <ref type="bibr" target="#b1">Afli et al. (2016)</ref>).</p><p>Since shared tasks are a good opportunity to estab- lish certain standards and facilitate the compara- bility of techniques, the Competition on Post-OCR Text Correction 3 organized in the context of IC- DAR 2017 could mark a milestone for more uni- fied OCR post-correction research efforts. Regarding techniques used for OCR post- correction, there are two main trends to be mentioned: statistical approaches utilizing error distributions inferred from training data and lex- ical approaches oriented towards the comparison of source words to a canonical form. Combina- tions of the two approaches are also available. Techniques residing in this statistical domain have the advantage that they can model specific distributions of the target domain if training data is available. <ref type="bibr" target="#b31">Tong and Evans (1996)</ref> approach post-correction as a statistical language modeling problem, taking context into account. <ref type="bibr">PérezCortes et al. (2000)</ref> employ stochastic finite-state automaton along with a modified version of the Viterbi Algorithm to perform a stochastic error correcting parsing. Extending the simpler stochastic context-sensitive models, <ref type="bibr" target="#b13">Kolak and Resnik (2002)</ref> apply the first noisy channel model, using edit distance from noisy to corrected text on character level. In order to train such a model, manually generated training data is required. Rey- naert (2008b) suggests a corpus-based correction method, taking spelling variation (especially in historical text) into account. <ref type="bibr" target="#b0">Abdulkader and Casey (2009)</ref> introduce an error estimator neural network that learns to assess error probabilities from ground truth data which in turn is then suggested for manual correction. This decreases the time needed for manual post-correction since correct words do not have to be considered as candidates for correction by the human corrector. <ref type="bibr" target="#b14">Llobet et al. (2010)</ref> combine information from the OCR system output, the error distribution and the language as weighted finite-state transducers. <ref type="bibr" target="#b21">Reffle and Ringlstetter (2013)</ref> use global as well as local error information to be able to fine-tune post-correction systems to historical documents. Related to the approach introduced by <ref type="bibr" target="#b19">Pérez-Cortes et al. (2000)</ref>, <ref type="bibr" target="#b1">Afli et al. (2016)</ref> use statistical machine translation for error correction using the Moses toolkit on character level. <ref type="bibr" target="#b33">Volk et al. (2010)</ref> merge the output of two OCR systems with the help of a language model to increase the quality of OCR text. The corpus of yearbooks of the Swiss Alpine Club which has been manually corrected via crowdsourcing (cf. <ref type="bibr" target="#b4">Clematide et al. (2016)</ref>) is available from their website. Lexical approaches often use rather generic distance measures between an erroneous word and a potential canonical lexical item. <ref type="bibr" target="#b29">Strohmaier et al. (2003)</ref> investigate the influence of the coverage of a lexicon on the post-correction task. Considering the fact that writing in historical documents is often not standardized, the success of such approaches is limited. Moreover, systems based on lexicons rely on the availability of such resources. Historical stages of a language -which constitute the majority of texts in need for OCR post-correction -often lack such resources or pro- vide incomplete lexicons which would drastically decrease performance of spell-checking-based systems. <ref type="bibr" target="#b24">Ringlstetter et al. (2007)</ref> address this problem by suggesting a way to dynamically collect specialized lexicons for this task. <ref type="bibr" target="#b30">Takahashi et al. (1990)</ref> apply spelling correction with preceding candidate word detection. <ref type="bibr" target="#b2">Bassil and Alwani (2012)</ref> use Google's online spelling suggestions for as they draw on a huge lexicon based on contents gathered from all over the web. The human component as final authority has been mentioned in some of these projects. Visual support of the post-correction process has been emphasized by e.g. <ref type="bibr" target="#b32">Vobl et al. (2014)</ref> who describe a system of iterative post-correction of OCRed historical text which is evaluated in an application-oriented way. They present the human corrector with an alignment of image and OCRed text and make batch correction of the same error in the entire document possible. They can show that the time needed by human correctors considerably decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation metrics</head><p>We describe and evaluate our data by means of word error rate (WER) and character error rate (CER). The error rates are a commonly used met- ric in speech recognition and machine translation evaluation and can also be referred to as length normalized edit distance. They quantify the num- ber of operations, namely the number of inser- tions, deletions and substitutions, that are needed to transform the suggested string into the manually corrected string and are computed as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>As mentioned in the introduction, errors found in OCRed texts are specific to time of origin, quality of scan and even the characteristics of a specific text. Our multi-modular architecture paves the way for a solution taking this into account by in- cluding general as well as specific modules. Thus, we suggest to include domain specific data as well as larger, more generic data sets in order to en- hance coverage of vocabulary and possible error classes. The data described hereafter constitutes parallel corpora with OCR output and manually corrected text which we utilize for training statis- tical models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Werther corpus</head><p>Since our system is developed to help in the process of compiling a corpus comprising adapta- tions of Goethe's The Sorrows Of Young Werther throughout different text types and centuries, we Berichtigung der Geschichte des jungen Werthers H. von Breitenbach 1775 2</p><p>Schwacher jedoch wohlgemeynter Tritt vor dem Riss, neben oder hinter Herren Pastor Goeze, gegen die Leiden des jungen Werthers und dessen ruchlose <ref type="table" target="#tab_1">Anhänger  anonymous  1775   3  Lorenz Konau  David Iversen  1776  4</ref> Werther der Jude Ludwig Jacobowski 1910 5</p><p>Eine rührende Erzählung aus geheimen Nachrichten von Venedig und Cadir (first letter) Joseph Codardo und Rosaura Bianki 1778 6</p><p>Afterwerther oder Folgen jugendlicher Eifersucht A. Henselt 1784 7</p><p>Der neue Werther oder Gefühl und Liebe Karl P. Bonafont 1804 8</p><p>Leiden des modernen Werther Max Kaufmann 1901 <ref type="table" target="#tab_1">Table 1</ref>: Werther texts included in our corpus from different authors and times of origin.</p><p>collected texts from this target domain. To be able to train a specialized system, we manually corrected a small corpus of relevant texts (cf. <ref type="table" target="#tab_2">Table 2</ref>). We use the output of Abbyy Fine Reader 7 for several Werther adaptations <ref type="table" target="#tab_1">(Table 1)</ref> all based on scans of books with German Gothic lettering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Deutsches Textarchive (DTA) corpus</head><p>Even though manual OCR post-correction is a vital part of many projects, only very little de- tailed documentation of this process exists.  <ref type="bibr" target="#b27">Smith and Inc, 2007)</ref> which comes with recogni- tion models for Gothic font.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Gutenberg data for language modeling</head><p>Since the output of our system is supposed to con- sist of well-formed German sentences, we need a method to assess the quality of the output lan- guage. This task is generally tackled by language modeling. We compiled a collection of 500 ran- domly chosen texts from Project Gutenberg 5 com- prising 28,528,078 tokens. With its relative close- ness to our target domain it constitutes the best approximation of a target language. The language model is trained with the KenLM toolkit <ref type="bibr" target="#b10">(Heafield, 2011</ref>) with an order of 5 on token level and 10 on character level following De Clercq et al. (2013).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Why OCR post-correction is hard</head><p>In tasks like the normalization of historical text ( <ref type="bibr" target="#b3">Bollmann et al., 2012)</ref> or social media, one can take advantage of regularities in the deviations from the standard form that appear throughout an entire genre or in case of social media e.g. dialect region <ref type="bibr" target="#b7">(Eisenstein, 2013)</ref>. Errors in OCR, how- ever, depend on the font and quality of the scan as well as the time of origin which makes each text unique in its composition of features and errors.</p><p>In order to exemplify this claim, we analyzed three different samples: Lorenz Konau (1776), Werther der Jude (1910) and a sample from the DTA data. <ref type="figure">Figure 2</ref> (a-c) illustrate the point that the qual- ity of scan is crucial for the OCR success. <ref type="figure">Fig- ure 2a</ref> shows a text from the 20th century where the type setting is rather regular and the distances between letters is uniform as opposed to <ref type="figure">Figure 2b</ref>. <ref type="figure">Figure 2c</ref> shows how the writing from the back of the page shines through and makes the script less readable. Thus, we observe a divergence in the frequency of certain character operations be- tween those texts: the percentage of substitutions range between 74% for Lorenz Konau and 60% for Werther der Jude and 18% and 30% of insertions, respectively. The varying percentage of insertions might be due to the fact that some scans are more "washed out" than others. Successful insertion of missing characters, however, relies on the precon- dition that a system knows a lot of actual words and sentences in the respective language and can- not be resolved via e.g. character similarity like in the substitution from l to t. Another factor that complicates the correction of a specific text is the number of errors per word. Words with an edit distance of one to the cor- rect version are easier to correct those with more than one necessary operation. With respect to er- rors per word our corpus shows significant dif- ferences in error distributions. Especially in our DTA corpus the number of words with two or more character-level errors per word is consider- ably higher than those with one error. For Werther Figure 2: Scans of three different texts from our corpora. Emphasizes differences in quality of scan and differences in type setting, font and genre (e.g. drama).</p><p>der Jude (WER 10.0, CER 2.4) the number of errors in general is much lower than for Konau (WER: 34.7, CER: 10.9). These characteristics in- dicate that subcorpus-specific training of a system is promising.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Specialized multi-modular post-correction</head><p>In order to account for the nature of errors that can occur in OCR text, we apply a variety of modules for post-correction. The system proceeds in two stages and is largely based on an architecture sug- gested by <ref type="bibr" target="#b26">Schulz et al. (2016)</ref> for normalization of user-generated contents. In the first stage, a set of specialized modules (Section 6.1) suggest cor- rected versions for the tokenized 6 OCR text lines. Those modules can be context-independent (work on just one word at a time) or context-dependent (an entire text line is processed at a time). The second stage is the decision phase. After the collection of various suggestions per input token, these have to be ranked to enable a decision for the most probable output token given the context. We achieve this by assigning weights the differ- ent modules with the help of Minimal Error Rate Training (MERT) (Och, 2003).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Suggestion modules</head><p>In the following, we give an outline of techniques included into our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Word level suggestion modules</head><p>• Original: the majority of words do not con- tain any kind of error, thus we want to have <ref type="bibr">6</ref> Tokenizer of TreeTagger (Schmid, 1997). The compound and word split techniques react to the variance in manual typesetting, where the dis- tances between letters vary. This means that the word boundary recognition becomes difficult (cf. <ref type="figure" target="#fig_4">Figure 3)</ref>. A problem related to the spell-checking approach is the limited coverage of the dictionary since it uses a modern German lexicon. Related to this is the difficulty of out-of-vocabulary words above average for literature text. Archaic words from e.g. the 17th century or named entities cannot be found in a dictionary and can therefore not be cov- ered with any of the approaches mentioned above.</p><p>However, especially named entities are crucial for the automatic or semi-automatic analysis of narra- tives e.g. with the help of network analysis. Our Text-Internal Vocabulary technique is designed to find frequent words in the input text, following the assumption that errors would not be regular enough to distort those frequencies. We compile a list from those high-frequency words. Subse- quently, erroneous words can be corrected cal- culating an OCR-adjusted Levenshtein distance. In this way misspelled words like Loveuzo could be resolved to Lorenzo if this name appears fre- quently. Since the ranking algorithm relies on a language model which will most probable not contain those suggestions, we insert the high- frequency words into the language modeling step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Sentence level suggestion modules</head><p>As has been suggested by <ref type="bibr" target="#b1">Afli et al. (2016)</ref>, we include Phrase-based Statistical Machine Trans- lation (SMT) into our system. We treat the post-correction as a translation problem translat- ing from erroneous to correct text. Like in stan- dard SMT, we train our models on a parallel cor- pus, the source language being the OCRed text and the target language being manually corrected text. We train models on token level as well as on character-level (unigram). This way, we aim at correcting frequently mis-recognized words along with frequent character-level errors. We train four different systems:</p><p>• token level -domain specific data (cf. Section 4.1) -general data (cf. Section 4.2)</p><p>• character level -domain specific data (cf. Section 4.1) -general data (cf. Section 4.</p><p>2)</p><p>The models are trained with the Moses toolkit ( <ref type="bibr" target="#b12">Koehn et al., 2007</ref>). Moreover, we use a subse- quent approach by forwarding the output of the character-based SMT model to the token-based SMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Additional feature</head><p>The information whether a word contains an er- ror can help to avoid the incorrect alternation of an initially correct word (overcorrection). In order to deliver this information to the decision module without making a hard choice for each word, we include the information whether a word has been found either in combination with the word before or after in a corpus (cf. Section 4.3) into the de- cision process in form of a feature that will be weighted along with the other modules. This naive language modeling approach allows for a context- relevant decision of the correctness of a word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Decision modules: the ranking mechanism</head><p>Since the recognition errors appearing in a text are hard to pre-classify by nature, we run all modules on each sentence of the input, returning sugges- tions for each word. Since the output of some of our modules are entire sentences, input sentence and output sentence have to be word-aligned in or- der to be able to make suggestions on word level. The word alignment between input and output sen- tence is done with the Needleman-Wunsch algo- rithm <ref type="bibr" target="#b17">(Needleman and Wunsch, 1970)</ref>, an algo- rithm originally developed in bioinformatics. From all corrected suggestions the most proba- ble well-formed combination has to be chosen.</p><p>To solve the combinatorial problem of deciding which suggestion is the most probable candidate for a word, the decision module makes use of the Moses decoder. As in general SMT, the decoder makes use of a language model (cf. Section 4.3) and a phrase table. The phrase table is compiled from all in- put words along with all possible correction sug- gestions. In order to assign weights to the single modules and the language model, we tune on the phrase tables collected from a run on our dev overall set, following the assumption that suggestions of certain modules are more reliable than others and expect their feature weights to be higher after tun- ing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Setup</head><p>To guarantee diversity, we split each of texts 1-4 (cf.   <ref type="table">Table 3</ref>: DTA parallel corpus of OCR text and corrected text showing the number of tokens be- fore and after post-correction along with WER and CER constitution. It constitutes an evaluation in which no initial manual correction as support for the au- tomatic correction is included in the workflow. We henceforth call this unknown set test unk (text 6). In contrast, the second set contains parts of the same texts as the training, thus specific vocabulary might have been introduced already. The results for this test set give a first indication of the extent to which pre-informing the system with manually correcting parts of a text could assist the automatic correction process. Since this scenario can be de- scribed as a text-specific initiated post-correction, we henceforth refer to this test set as test init .</p><p>We further on experiment with an extended training set train ext (train with texts 7 and 8) to as- sess the influence of the size of the specific train- ing set on the overall performance. The sizes of the datasets before and after correction along with WER and CER are summarized in <ref type="table" target="#tab_2">Table 2</ref>. The sizes for the general dataset before and after cor- rection along with WER and CER are summarized in <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Evaluation</head><p>In the following we concentrate on the compari- son of WER and CER before and after automatic post-correction. As a baseline for our system we chose the strongest single-handed module (SMT on character-level trained on Werther data).   <ref type="table">Table 4</ref>: WER and CER for both test sets be- fore and after automatic post-correction for the system trained with the small training set (train) and the larger training set (train ext ). Baselines: the original text coming from the OCR system and the character-level SMT system trained on the Werther data.</p><p>Overall performance As indicated previously, our test sets differ with respect to their similarity to the training set. The results for both test scenar- ios for systems trained on our two training sets are summarized in <ref type="table">Table 4</ref>. The results from test init and test unk show that our system performs con- siderably better than the baseline and can improve quality of the OCR output considerably. For test unk , the system improves the quality by almost 20 points of WER from 36.7 to 15.4 and over 10 points in CER from 30.0 to 19.6. For test init , our system improves the quality of the text with a reduction of approximately 20 points of WER from 23.5 to 4.7 and 7 points in CER from 15.1 to 8.0. It is not surprising that the decrease in WER is stronger than the decrease in CER. This is due to the fact that many words contain more than one error and require more than one charac- ter level operation to get from the incorrect to the correct string.</p><p>Just slight improvement can be shown by adding training material to the Werther-specific parts of the system (cf. train ext row of <ref type="table">Table 4</ref>). Merely the CER can be improved whereas the WER stays about the same. The improvement in test unk is higher than for test init .</p><p>Module specific analysis Since a WER and CER evaluation is not expedient for all mod- ules as they were designed to correct specific problems and not the entirety of them, we look into the specialized modules in terms of correct suggestions contributed to the suggestion pool and correct suggestions only suggested by one module (unique suggestions). As the system in- cluding the extended training set train ext delivered slightly better results, in the following we will describe the contribution of the single modules testinit test unk module # overcorrected # corrected # unique correct # overcorrected # corrected # unique correct <ref type="table" target="#tab_1">SMT Werther token  128  364  10  209  1,089  0  SMT Werther character  235  684  0  700  1,919  0  SMT Werther cascaded  273  697  2  728  1,933  4  SMT DTA token  2,179  229  8  1,627  893  19  SMT DTA character  4121  372  22  3,143  1,530  115  text-internal vocab  3,317  131  16  4,142  244  60  word split  594  3  0  720  45  2  spell check  1,329  219  15  2,819  731  40  compound  222  0  0  169  2  2   overall system  238  2171  - 675</ref> 2,642 - to the overall performance of this system (cf. <ref type="table" target="#tab_4">Table 5</ref>). For test unk the number of corrected tokens along with the number of overcorrections is higher than for test init throughout all modules. Clearly, for test init the Werther-specific modules are strongest. The more general modules prove useful for test unk . The number of corrected words increases for the SMT module trained on DTA data on character-level. The usefulness of the module extracting specific words (text-internal vocab) as well as the general SMT model and the spell checker becomes evident in terms of unique suggestions contributed by those modules. The analysis of the output of the individual modules and their contribution to the overall system uncovers an issue: those modules that produce a high number of incorrect suggestions, thus overcorrecting actually correct input tokens, are at the same time those modules that are the only ones producing correct suggestions for some of the incorrect input words. Consequently, those uniquely suggested corrections are not chosen in the decision modules due to an overall weak performance of this module. These suggestions are often crucial to the texts like the suggestions by the special vocabulary module which contain named entities or words specific to the time period. For our test unk set, the text-internal vocabulary module yields around 60 unique sug- gestions, out of which 15 are names (Friedrich, Amalia) or words really specific to the text (Auftrit spelled with one t instead of two).</p><p>Challenges In the context of literature OCR post-correction is a challenging problem since the texts themselves can be considered non-standard text. The aim is not to bring the text at hand to an agreed upon standard form but to digitize exactly what was contained in the print version. This can be far from the standard form of a language. In one of our texts, we find a character speaking German with a strong dialect. Her speech contains a lot of words that are incorrect in standard German, how- ever, the goal is it to preserve this "errors" in the digital version. Thus, correction merely on the ba- sis of the OCR text without consulting the printed version or an image-digitized facsimile, can essen- tially never be perfect. It follows, that the integra- tion of automatic post-correction techniques into the character recognition process could lead to fur- ther improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Adaptability</head><p>Reusability as a key concept in NLP for DH origi- nates in the time limitations given in such projects.</p><p>Since DH projects do not evolve around the devel- opment of tools but the analysis performed with the help this tools in order to answer a specific question, the tools are expected to be delivered in an early phase of collaborative projects. From- scratch development easily exceeds this time lim- its. We show that our OCR post-correction system is modular enough to be adjusted to correct texts from other languages by training it for two other languages, English and French, with data released in the OCR post-correction competition organized in the context of ICDAR 2017 9 . The texts origi- nate from the the last four centuries and come from different collections and therefore have been dig- itized using different OCR systems. The data is summarized in <ref type="table" target="#tab_6">Table 6</ref> 10 . We adjust our system to the language by retrain- ing the SMT models and including spell-checkers for the respective languages. Due to the modular architecture these adjustments can be made eas-language train ocr train gold dev1 ocr dev1 gold dev2 ocr dev2 gold test <ref type="bibr">ocr</ref>    <ref type="table">Table 7</ref>: The results reported in word error rate (WER) and character error rate (CER) for the En- glish and French test set.</p><p>The strongest unique module for these two languages is the subsequent combination of the character-level SMT and the token-level SMT models (Cascaded). For English it performs just slightly worse on WER and even outperforms the overall system on the CER. For French, the over- all system is clearly stronger than the Cascaded SMT system with more than 1 percent improve- ment of WER but also performs worse in terms of CER by 1.5 percent. Generally, the OCR post- correction system achieves about 25% reduction of WER for English and over 30% reduction in WER for French.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Digitization workflow</head><p>We integrate the automatic OCR process with tesseract and our automatic post-correction system into a workflow which results in an hocr file, an XML format which is readable by <ref type="bibr">PoCoTo (Vobl et al., 2014</ref>) a tool for supporting manual post- correction of OCRed text through alignment of image and digitized text. The upload of scans or images is provided online via a webapplication <ref type="bibr">11</ref> . This shields the user from the technicalities of the 11 http://clarin05.ims.uni-stuttgart.de/ ocr/, for access please contact the author. correction process and provides them with the in- put for the PoCoTo tool. The implementation of an easy-to-handle work- flow is an often underemphasized aspect of DH. It needs to be intuitive enough to not absorb the time ion has been saved via automation. Since the final post-correction step requires that the human corrector compares the digitized version with the scan, presenting both next to each other is an ideal scenario. This functionality is one of the main strengths of PoCoTo, a visual correction tool, sup- porting manually initiated correction operations and batch correction of the same error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>We can show that the enhancement of a general, adaptable architecture by including small but spe- cific data sets can improve results within a specific domain. Moreover, the combination of different techniques for of OCR post-correction is signif- icantly superior to single techniques. Especially the integration of SMT models on token level and character level contributes to the overall success of the system. Due to the complexity of OCR post-correction, there cannot be a general solution. Even though the ranking algorithm achieves large improvement, further potential lies in the inclusion of fine-tuned language models since the decision process highly depends upon it. The intrinsic char- acteristic of literature as being non-standard com- plicates the task. However, techniques that focus on these features like our module that is special- ized on extracting text-specific vocabulary show promising results for e.g. named entity correction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Multi-modular OCR post-correction system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>WER = word insertions + word substitutions + word deletions # words in the reference CER = char insertions + char substitutions + char deletions # characters in the reference</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Irregular type setting in German Gothic lettering. sind and insgemein are two separate words but yet written closely together. the initial token available in our suggestion pool • Spell checker: spelling correction suggestion for misspelled words with hunspell 7 • Compounder: merges two tokens into one token if it is evaluated as an existing word by hunspell • Word splitter: splits two tokens into two words using compound-splitter module from the Moses toolkit (Koehn et al., 2007) • Text-Internal Vocabulary: extracts highfrequent words from the input texts and suggests them as correction of words with small adjusted Levenshtein distance 8</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>training</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 )</head><label>1</label><figDesc></figDesc><table>into three parts and combined the 
respective parts: 80% train (train), 10% develop-
ment (dev SM T ) and 10% test (test init ). 

Test setup We introduce two different test sce-
narios. Even though both test sets are naturally 
compiled from unseen data, the first test set con-
sists of a self-contained Werther adaptation intro-
ducing new named entities, originating from a dif-
ferent source and thus showing a different error </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Werther specific parallel corpus of OCR 
text and corrected text showing the number of to-
kens before and after post-correction along with 
WER and CER 

set # tokens (OCR) # tokens (corr) WER CER 

train 
3,452,922 
3,718,712 
41.6 13.2 
dev 
663,376 
836,974 
30.4 
9.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Number of overcorrected, corrected and uniquely corrected words per module out of 17,367 
tokens in test init (2,726 erroneous words) and 13,304 tokens in test unk (4,141 erroneous words) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 6 : Number of tokens in the English and French corpus provided by the competition on OCR- postcorrection.</head><label>6</label><figDesc></figDesc><table>ily and with a low expenditure of time. Since 
the datasets are compilation of a variety of texts, 
we use all modules but the domain-specific SMT 
models. We solely include one token-level and 
character-level SMT module for each language. 

language system 
WER CER 

English 
original 
29.4 
28.4 
SMT Cascaded 22.7 
23.6 
overall system 
22.1 
24.5 

French 
original text 
13.3 
25.0 
SMT Cascaded 9.9 
20.0 
overall system 
8.7 
21.5 

</table></figure>

			<note place="foot" n="1"> https://books.google.de/, 02.04.2017. 2 http://www.gutenberg.org, 14.04.2017.</note>

			<note place="foot" n="3"> https://sites.google.com/view/ icdar2017-postcorrectionocr/home, 3.07.2017.</note>

			<note place="foot" n="4"> Considering the open source aspect of our resulting system, we decided to use the open source OCR software tesseract and move away from Abbyy some time after our project started: https://github.com/tesseract-ocr. 5 Project Gutenberg. Retrieved January 21, 2017, from www.gutenberg.org.</note>

			<note place="foot" n="7"> https://github.com/hunspell/hunspell. 8 OCR-adjusted Levenshtein distance taking frequent substitution, insertion and deletion patterns learned from training data into account.</note>

			<note place="foot" n="9"> https://sites.google.com/view/ icdar2017-postcorrectionocr/home, 3.07.2017. 10 The test set does not comply with the official shared task set since the manually corrected data is not yet available for the test set. We test on a combination of periodicals and monographs.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Acknowledgements</head><p>We thank the German Ministry of Education and Research (BMBF) for supporting this research completed within the Center for Reflected Text Analytics (CRETA). Furthermore, we acknowl-edge the support of our colleagues at Deutsches Textarchiv.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Low Cost Correction of OCR Errors Using Learning in a Multi-Engine Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmad</forename><surname>Abdulkader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathew</forename><forename type="middle">R</forename><surname>Casey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Conference on Document Analysis and Recognition</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-07" />
			<biblScope unit="page" from="576" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using SMT for OCR Error Correction of Historical Texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haithem</forename><surname>Afli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengwei</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praic</forename><surname>Sheridan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">OCR Post-Processing Error Correction Algorithm Using Google&apos;s Online Spelling Suggestion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youssef</forename><surname>Bassil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Alwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Emerging Trends in Computing and Information Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="99" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Manual and semi-automatic normalization of historical spelling Case studies from Early New High German</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Bollmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Krasselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Petran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KONVENS 2012 (LThist 2012 workshop</title>
		<meeting>KONVENS 2012 (LThist 2012 workshop</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="342" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Crowdsourcing an OCR Gold Standard for a German and French Heritage Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Clematide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lenz</forename><surname>Furrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Volk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation LREC</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation LREC<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05-23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Normalization of Dutch user-generated content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Orphée De Clercq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Desmet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Recent Advances in Natural Language Processing</title>
		<meeting>Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
	<note>Els Lefever, and Veronique Hoste. INCOMA</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Gujarati Handwritten Numeral Optical Character Reorganization Through Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Apurva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Desai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2582" to="2589" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What to do about bad language on the Internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="359" to="369" />
		</imprint>
	</monogr>
	<note>Georgia</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">TEI und Textkorpora: Fehlerklassifikation und Qualittskontrolle vor, whrend und nach der Texterfassung im Deutschen Textarchiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Geyken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susanne</forename><surname>Haaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Jurish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wiegand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Jahrbuch für Computerphilologie</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">page online</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Novel Connectionist System for Unconstrained Handwriting Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Bertolami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bunke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="855" to="868" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">KenLM: Faster and smaller language model queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A computational analysis of poetic style: Imagism and its influence on modern professional and amateur poetry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justine</forename><forename type="middle">T</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistic Issues in Language Technology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Moses: Open Source Toolkit for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07</title>
		<meeting>the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">OCR Error Correction Using a Noisy Channel Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okan</forename><surname>Kolak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Human Language Technology Research, HLT &apos;02</title>
		<meeting>the Second International Conference on Human Language Technology Research, HLT &apos;02<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="257" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">OCR Post-processing Using Weighted Finite-State Transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Llobet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juancarlos</forename><surname>Jose-Ramon Cerdan-Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joaquim</forename><surname>Perez-Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arlandis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 20th International Conference on Pattern Recognition, ICPR &apos;10</title>
		<meeting>the 2010 20th International Conference on Pattern Recognition, ICPR &apos;10<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2021" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Corpus for Comparative Evaluation of OCR Software and Postcorrection Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stoyan</forename><surname>Mihov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><forename type="middle">U</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Ringlstetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselka</forename><surname>Dojchinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanja</forename><surname>Nakova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Document Analysis and Recognition (ICDAR 2005)</title>
		<meeting><address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-08-29" />
			<biblScope unit="page" from="162" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Beyond Canonical Texts: A Computational Analysis of Fanfiction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smitha</forename><surname>Milli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-01" />
			<biblScope unit="page" from="2048" to="2053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A general method applicable to the search for similarities in the amino acid sequence of two proteins</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">D</forename><surname>Needleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wunsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Molecular Biology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="443" to="453" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Minimum Error Rate Training in Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
	<note>ACL &apos;03</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Carlos Pérez-Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan-Carlos</forename><surname>Amengual</surname></persName>
		</author>
		<title level="m">Joaquim Arlandis, and Rafael Llobet</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stochastic Error-Correcting Parsing for OCR PostProcessing</title>
	</analytic>
	<monogr>
		<title level="m">15th International Conference on Pattern Recognition, ICPR&apos;00</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="4405" to="4408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unsupervised Profiling of OCRed Historical Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Reffle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Ringlstetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1346" to="1357" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">All, and only, the Errors: more Complete and Consistent Spelling and OCRError Correction Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Reynaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Language Resources and Evaluation (LREC&apos;08)</title>
		<meeting>the Sixth International Language Resources and Evaluation (LREC&apos;08)<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Non-interactive OCR Postcorrection for Giga-scale Digitization Projects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Reynaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Computational Linguistics and Intelligent Text Processing, CICLing&apos;08</title>
		<meeting>the 9th International Conference on Computational Linguistics and Intelligent Text Processing, CICLing&apos;08<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="617" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adaptive Text Correction with Webcrawled Domain-dependent Dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Ringlstetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><forename type="middle">U</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stoyan</forename><surname>Mihov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Probabilistic Part-of-Speech Tagging Using Decision Trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Methods in Language Processing</title>
		<editor>Daniel Jones and Harold Somers</editor>
		<meeting><address><addrLine>London, GB</addrLine></address></meeting>
		<imprint>
			<publisher>UCL Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="154" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multimodular Text Normalization of Dutch User-Generated Content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><forename type="middle">De</forename><surname>Pauw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orphée</forename><surname>De Clercq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Desmet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Véronique</forename><surname>Hoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lieve</forename><surname>Macken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">22</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An overview of the Tesseract OCR Engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Inc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th IEEE Intl. Conf. on Document Analysis and Recognition (ICDAR)</title>
		<meeting>9th IEEE Intl. Conf. on Document Analysis and Recognition (ICDAR)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="629" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mining for the Meanings of a Murder: The Impact of OCR Quality on the Use of Digitized Historical Newspapers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolyn</forename><surname>Strange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Wodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Humanities Quarterly</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Lexical Postcorrection of OCR-Results: The Web as a Dynamic Secondary Dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">M</forename><surname>Strohmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Ringlstetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><forename type="middle">U</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stoyan</forename><surname>Mihov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Document Analysis and Recognition (ICDAR 2003)</title>
		<meeting><address><addrLine>Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1133" to="1137" />
		</imprint>
	</monogr>
	<note>inburgh</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A spelling correction method and its application to an OCR system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyasu</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuyasu</forename><surname>Itoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomio</forename><surname>Amano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akio</forename><surname>Yamashita</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="363" to="377" />
		</imprint>
	</monogr>
<note type="report_type">Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Statistical Approach to Automatic OCR Error Correction in Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth Workshop on Very Large Corpora</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="88" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">PoCoTo-an Open Source System for Efficient Interactive Postcorrection of OCRed Historical Texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Vobl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annette</forename><surname>Gotscharek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uli</forename><surname>Reffle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Ringlstetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><forename type="middle">U</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Digital Access to Textual Cultural Heritage, DATeCH &apos;14</title>
		<meeting>the First International Conference on Digital Access to Textual Cultural Heritage, DATeCH &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="57" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Reducing OCR errors by combining two OCR systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Volk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Marek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ECAI 2010 Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</title>
		<meeting>the ECAI 2010 Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="61" to="65" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
