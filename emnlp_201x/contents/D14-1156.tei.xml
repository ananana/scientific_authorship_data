<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Leveraging Effective Query Modeling Techniques for Speech Recognition and Summarization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Yu</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Science</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Hung</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Science</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berlin</forename><surname>Chen</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">National Taiwan Normal University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ea-Ee</forename><surname>Jan</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">IBM Thomas J. Watson Research Center</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Min</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Science</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Lian</forename><surname>Hsu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Science</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Leveraging Effective Query Modeling Techniques for Speech Recognition and Summarization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1474" to="1480"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Statistical language modeling (LM) that purports to quantify the acceptability of a given piece of text has long been an interesting yet challenging research area. In particular, language modeling for information retrieval (IR) has enjoyed remarkable empirical success; one emerging stream of the LM approach for IR is to employ the pseudo-relevance feedback process to enhance the representation of an input query so as to improve retrieval effectiveness. This paper presents a continuation of such a general line of research and the main contribution is threefold. First, we propose a principled framework which can unify the relationships among several widely-used query modeling formulations. Second, on top of the successfully developed framework, we propose an extended query modeling formulation by incorporating critical query specific information cues to guide the model estimation. Third, we further adopt and formalize such a framework to the speech recognition and summarization tasks. A series of empirical experiments reveal the feasibility of such an LM framework and the performance merits of the deduced models on these two tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Along with the rapidly growing popularity of the Internet and the ubiquity of social web commu- nications, tremendous volumes of multimedia contents, such as broadcast radio and television programs, digital libraries and so on, are made available to the public. Research on multimedia content understanding and organization has wit- nessed a booming interest over the past decade. By virtue of the developed techniques, a variety of functionalities were created to help distill im- portant content from multimedia collections, or provide locations of important speech segments in a video accompanied with their corresponding transcripts, for users to listen to or to digest. Sta- tistical language modeling (LM) <ref type="bibr" target="#b17">(Jelinek, 1999;</ref><ref type="bibr" target="#b18">Jurafsky and Martin, 2008;</ref><ref type="bibr" target="#b46">Zhai, 2008)</ref>, which manages to quantify the acceptability of a given word sequence in a natural language or capture the statistical characteristics of a given piece of text, has been proved to offer both efficient and effective modeling abilities in many practical applications of natural language processing and speech recognition <ref type="bibr" target="#b35">(Ponte and Croft, 1998;</ref><ref type="bibr" target="#b17">Jelinek, 1999;</ref><ref type="bibr" target="#b15">Huang, et al., 2001;</ref> a ; <ref type="bibr" target="#b18">Jurafsky and Martin, 2008;</ref><ref type="bibr" target="#b10">Furui et al., 2012;</ref><ref type="bibr" target="#b23">Liu and Hakkani-Tur, 2011</ref>).</p><p>The LM approach was first introduced for the information retrieval (IR) problems in the late 1990s, indicating very good potential, and was subsequently extended in a wide array of follow- up studies. One typical realization of the LM ap- proach for IR is to access the degree of relevance between a query and a document by computing the likelihood of the query generated by the doc- ument (usually referred to as the query- likelihood approach) <ref type="bibr" target="#b46">(Zhai, 2008;</ref><ref type="bibr" target="#b0">Baeza-Yates and Ribeiro-Neto, 2011)</ref>. A document is deemed to be relevant to a given query if the correspond- ing document model is more likely to generate the query. On the other hand, the Kullback- Leibler divergence measure (denoted by KLM for short hereafter), which quantifies the degree of relevance between a document and a query from a more rigorous information-theoretic per- spective, has been proposed (  b ; Baeza-Yates and Ribeiro-Neto, 2011). KLM not only can be thought as a natural generalization of the query- likelihood approach, but also has the additional merit of being able to accommodate extra infor- mation cues to improve the performance of doc- ument ranking. For example, a main challenge facing such a measure is that since a given query usually consists of few words, the true infor- mation need is hard to be inferred from the sur- face statistics of a query. As such, one emerging stream of thought for KLM is to employ the pseudo-relevance feedback process to construct an enhanced query model (or representation) so as to achieve better retrieval effectiveness <ref type="bibr" target="#b12">(Hiemstra et al., 2004;</ref><ref type="bibr" target="#b28">Lv and Zhai, 2009;</ref><ref type="bibr" target="#b4">Carpineto and Romano, 2012;</ref><ref type="bibr" target="#b31">Lee and Croft, 2013)</ref>.</p><p>Following this line of research, the major con- tribution of this paper is three-fold: 1) we ana- lyze several widely-used query models and then propose a principled framework to unify the rela- tionships among them; 2) on top of the success- fully developed query models, we propose an extended modeling formulation by incorporating additional query-specific information cues to guide the model estimation; 3) we explore a nov- el use of these query models by adapting them to the speech recognition and summarization tasks. As we will see, a series of experiments indeed demonstrate the effectiveness of the proposed models on these two tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Language Modeling Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Kullback-Leibler Divergence Measure</head><p>A promising realization of the LM approach to IR is the Kullback-Leibler divergence measure (KLM), which determines the degree of rele- vance between a document and a query from a rigorous information-theoretic perspective. Two different language models are involved in KLM: one for the document and the other for the query. The divergence of the document model with re- spect to the query model is defined by</p><formula xml:id="formula_0">. ) | ( ) | ( log ) | ( ) || ( KL    V w D w P Q w P Q w P D Q (1)</formula><p>KLM not only can be thought as a natural gener- alization of the traditional query-likelihood ap- proach ( <ref type="bibr" target="#b42">Yi and Allan, 2009;</ref><ref type="bibr" target="#b0">Baeza-Yates and Ribeiro-Neto, 2011</ref>), but also has the additional merit of being able to accommodate extra infor- mation cues to improve the estimation of its component models in a systematic way for better document ranking <ref type="bibr" target="#b46">(Zhai, 2008)</ref>.</p><p>Due to that a query usually consists of only a few words, the true query model P(w|Q) might not be accurately estimated by the simple ML estimator <ref type="bibr" target="#b16">(Jelinek, 1991)</ref>. There are several stud- ies devoted to estimating a more accurate query modeling, saying that it can be approached with the pseudo-relevance feedback process <ref type="bibr" target="#b25">(Lavrenko and Croft, 2001;</ref><ref type="bibr">Zhai and Lafferty, 2001 b</ref> ). However, the success depends largely on the as- sumption that the set of top-ranked documents,</p><formula xml:id="formula_1">D Top ={D 1 ,D 2 ,...,D r ,.</formula><p>..}, obtained from an initial round of retrieval, are relevant and can be used to estimate a more accurate query language model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Relevance Modeling</head><p>Under the notion of relevance modeling (RM, often referred to as RM-1), each query Q is as- sumed to be associated with an unknown rele- vance class R Q , and documents that are relevant to the semantic content expressed in query are samples drawn from the relevance class R Q . Since there is no prior knowledge about R Q , we may use the top-ranked documents D Top to ap- proximate the relevance class R Q . The corre- sponding relevance model can be estimated using the following equation <ref type="bibr" target="#b25">(Lavrenko and Croft, 2001;</ref><ref type="bibr" target="#b26">Lavrenko, 2004)</ref>:</p><formula xml:id="formula_2">. ) | ( ) ( ) | ( ) | ( ) ( ) | ( RM                    Top r D Top r D Q w r r Q w r r r D w P D P D w P D w P D P Q w P D D (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Simple Mixture Model</head><p>Another perspective of estimating an accurate query model with the top-ranked documents is the simple mixture model (SMM), which as- sumes that words in D Top are drawn from a two- component mixture model: 1) One component is the query-specific topic model P SMM (w|Q), and 2) the other is a generic background model P(w|BG). By doing so, the SMM model P SMM (w|Q) can be estimated by maximizing the likelihood over all the top-ranked documents  b ; <ref type="bibr" target="#b38">Tao and Zhai, 2006</ref>):</p><formula xml:id="formula_3">  , ) | ( ) 1 ( ) | ( ) , ( SMM          Top r r D V w D w c BG w P Q w P L D   (3)</formula><p>where  is a pre-defined weighting parameter used to control the degree of reliance between P SMM (w|Q) and P(w|BG). This estimation will enable more specific words to receive more probability mass, thereby leading to a more dis- criminative query model P SMM (w|Q).</p><p>Although the SMM modeling aims to extract extra word usage cues for enhanced query mod- eling, it may confront two intrinsic problems. One is the extraction of word usage cues from D Top is not guided by the original query. The oth- er is that the mixing coefficient  is fixed across all top-ranked documents albeit that different documents would potentially contribute different amounts of word usage cues to the enhanced query model. To mitigate these two problems, the regularized simple mixture model has been proposed and can be estimated by maximizing the likelihood function ( <ref type="bibr" target="#b38">Tao and Zhai, 2006;</ref><ref type="bibr" target="#b9">Dillon and Collins-Thompson, 2010)</ref> </p><formula xml:id="formula_4">  , ) | ( ) 1 ( ) | ( ) | ( ) , ( RSMM ) | ( RSMM              Top r r r r D V w D w c D D V w Q w P BG w P Q w P Q w P L D    (4)</formula><p>where is a weighting factor indicating the con- fidence on the prior information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Proposed Modeling Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Fundamentals</head><p>It is obvious that the major difference among the representative query models mentioned above is how to capitalize on the set of top-ranked docu- ments and the original query. Several subtle rela- tionships can be deduced through the following in-depth analysis. First, a direct inspiration of the LM-based query reformulation framework can be drawn from the celebrated Rocchio's formula- tion, while the former can be viewed as a proba- bilistic counterpart of the latter <ref type="bibr" target="#b36">(Robertson, 1990;</ref><ref type="bibr" target="#b35">Ponte and Croft, 1998;</ref><ref type="bibr">Baeza-Yates and RibeiroNeto, 2011</ref>). Second, after some mathematical manipulation, the formulation of the RM model (c.f. Eq. <ref type="formula">(2)</ref>) can be rewritten as</p><formula xml:id="formula_5">. ) ( ) | ( ) ( ) | ( ) | ( ) | ( RM            Top r D Top r D r r r r r D P D Q P D P D Q P D w P Q w P D D (5)</formula><p>It becomes evident that the RM model is com- posed by mixing a set of document models P(w|D r ). As such, the RM model bears a close resemblance to the Rocchio's formulation. Fur- thermore, based on Eq. <ref type="formula">(5)</ref>, we can recast the estimation of the RM model as an optimization problem, and the likelihood (or objective) func- tion is formulated as</p><formula xml:id="formula_6">1 ) | ( . . , ) | ( ) | ( ) , (                 Top r Top r D r V w Q w c D r r Q D P t s Q D P D w P L D D (6)</formula><p>where the document models P(w|D r ) are known in advance; the conditional probability P(D r |Q) of each document D r is unknown and leave to be estimated. Finally, a principled framework can be obtained to unify all of these query models, including RM (c.f. Eq. <ref type="formula">(6)</ref>), SMM (c.f. Eq. <ref type="formula">(3)</ref>) and RSMM (c.f. Eq. (4))), by using a generalized objective likelihood function:</p><formula xml:id="formula_7">1 ) ( . . , ) ( ) | ( ) , (                   M E M r i i r M r V w E E w c M r r M P t s M P M w P L (7)</formula><p>where E represents a set of observations which we want to maximize their likelihood, and M denotes a set of mixture components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query-specific Mixture Modeling</head><p>The SMM model and the RSMM model are in- tended to extract useful word usage cues from D Top , which are not only relevant to the original query Q but also external to those already cap- tured by the generic background model. Howev- er, we argue in this paper that the "generic in- formation" should be carefully crafted for each query due mainly to the fact that users' infor- mation needs may be very diverse from one an- other. To crystallize the idea, a query-specific background model P Q (w|BG) for each query Q can be derived from D Top directly. Another con- sideration is that since the original query model P(w|Q) cannot be accurately estimated, it thus may not necessarily be the best choice for use in defining a conjugate Dirichlet prior for the en- hanced query model to be estimated. We propose to use the RM model as a prior to guide the esti- mation of the enhanced query model. The en- hanced query model is termed query-specific mixture model (QMM), and its corresponding training objective function can be expressed as</p><formula xml:id="formula_8">               Top r r r r D V w D w c Q D D V w Q w P BG w P Q w P Q w P L D . ) | ( ) 1 ( ) | ( ) | ( ) , ( QMM ) | ( QMM RM    (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Applications</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Speech Recognition</head><p>Language modeling is a critical and integral component in any large vocabulary continuous speech recognition (LVCSR) system <ref type="bibr" target="#b15">(Huang et al., 2001;</ref><ref type="bibr" target="#b18">Jurafsky and Martin, 2008;</ref><ref type="bibr" target="#b10">Furui et al., 2012</ref>). More concretely, the role of language modeling in LVCSR can be interpreted as calcu- lating the conditional probability P(w|H), in which H is a search history, usually expressed as a sequence of words H=h 1 , h 2 ,…, h L , and w is one of its possible immediately succeeding words. Once the various aforementioned query modeling methods are applied to speech recogni- tion, for a search history H, we can conceptually regard it as a query and each of its immediately succeeding words w as a (single-word) document. Then, we may leverage an IR procedure that takes H as a query and poses it to a retrieval sys- tem to obtain a set of top-ranked documents from a contemporaneous (or in-domain) corpus. Final- ly, the enhanced query model (that is P(w|H) in speech recognition) can be estimated by RM, SMM, RSMM or QMM, and further combined with the background n-gram (e.g., trigram) lan- guage model to form an adaptive language model to guide the speech recognition process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Speech Summarization</head><p>On the other hand, extractive speech summariza- tion aims at producing a concise summary by selecting salient sentences or paragraphs from the original spoken document according to a pre- defined target summarization ratio <ref type="bibr" target="#b3">(Carbonell and Goldstein, 1998;</ref><ref type="bibr">Mani and Maybury, 1999;</ref><ref type="bibr" target="#b33">Nenkova and McKeown, 2011;</ref><ref type="bibr" target="#b23">Liu and Hakkani-Tur, 2011</ref>). Intuitively, this task could be framed as an ad-hoc IR problem, where the spoken document is treated as an information need and each sentence of the document is re- garded as a candidate information unit to be re- trieved according to its relevance to the infor- mation need. Therefore, KLM can be used to quantify how close the document D and one of its sentences S are: the closer the sentence model P(w|S) to the document model P(w|D), the more likely the sentence would be part of the summary. Due to that each sentence S of a spoken docu- ment D to be summarized usually consists of only a few words, the corresponding sentence model P(w|S) might not be appropriately esti- mated by the ML estimation. To alleviate the deficiency, we can leverage the merit of the above query modeling techniques to estimate an accurate sentence model for each sentence to enhance the summarization performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>The speech corpus consists of about 196 hours of Mandarin broadcast news collected by the Aca- demia Sinica and the Public Television Service Foundation of Taiwan between <ref type="bibr">November 2001</ref><ref type="bibr">and April 2003</ref><ref type="bibr" target="#b41">(Wang et al., 2005</ref>), which is publicly available and has been segmented into separate stories and transcribed manually. Each story contains the speech of one studio anchor, as well as several field reporters and interviewees. A subset of 25-hour speech data compiled during November 2001 to December 2002 was used to bootstrap the acoustic model training. The vo- cabulary size is about 72 thousand words. The background language model was estimated from a background text corpus consisting of 170 mil- lion Chinese characters collected from the Chi- nese Gigaword Corpus released by LDC.</p><p>The dataset for use in the speech recognition experiments is compiled by a subset of 3-hour speech data from the corpus within 2003 (1.5 hours for development and 1.5 hours for test). The contemporaneous (in-domain) text corpus used for training the various LM adaptation methods was collected between 2001 and 2003 from the corpus (excluding the test set), which consists of one million Chinese characters of the orthographic broadcast news transcripts. In this paper, all the LM adaptation experiments were performed in word graph rescoring. The associ- ated word graphs of the speech data were built beforehand with a typical LVCSR system <ref type="bibr" target="#b34">(Ortmanns et al., 1997;</ref><ref type="bibr" target="#b43">Young et al., 2006</ref>).</p><p>In addition, the summarization task also em- ploys the same broadcast news corpus as well. A subset of 205 broadcast news documents com- piled between November 2001 and August 2002 was reserved for the summarization experiments (185 for development and 20 for test). A subset of about 100,000 text news documents, compiled during the same period as the documents to be summarized, was employed to estimate the relat- ed summarization models compared in this paper. We adopted three variants of the widely-used ROUGE metric (i.e., ROUGE-1, ROGUE-2 and ROUGE-L) for the assessment of summarization performance <ref type="bibr" target="#b21">(Lin, 2003)</ref>. The summarization ratio, defined as the ratio of the number of words in the automatic (or manual) summary to that in the reference transcript of a spoken document, was set to 10% in this research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Results</head><p>In the first part of experiments, we evaluate the effectiveness of the various query models applied to the speech recognition task. The correspond- ing results with respect to different numbers of top-ranked documents being used for estimating their component models are shown in <ref type="table" target="#tab_0">Table 1</ref>. Also worth mentioning is that the baseline sys- tem with the background trigram language model, which was trained with the SRILM toolkit ( <ref type="bibr" target="#b37">Stolcke, 2005</ref>) and Good-Turing smoothing <ref type="bibr" target="#b17">(Jelinek, 1999)</ref>, results in a Chinese character error rate (CER) of 20.08% on the test set. Con- sulting <ref type="table" target="#tab_0">Table 1</ref> we notice two particularities. One is that there is more fluctuation in the CER re- sults of SMM than in those of RM. The reason might be that, for SMM, the extraction of rele- vance information from the top-ranked docu- ments is conducted with no involvement of the test utterance (i.e., the query; or its correspond- ing search histories), as elaborated earlier in Sec- tion 2. When too many feedback documents are being used, there would be a concern for SMM to be distracted from being able to appropriate model the test utterance, which is probably caused by some dominant distracting (or irrele- vant) feedback documents. The other interesting observation is that RSMM only achieves a com- parable (even worse) result when compared to SMM. A possible reason is that the prior con- straint of the RSMM may contain too much noisy information so as to bias the model estima- tion. Furthermore, it is evident that the proposed QMM is the best-performing method among all the query models compared in the paper. Alt- hough the improvements made by QMM are not as pronounced as expected, we believe that QMM has demonstrated its potential to be ap- plied to other related applications. On the other hand, we compare the various query models with two well-practiced language models, namely the cache model (Cache) ( <ref type="bibr" target="#b19">Kuhn and Mori, 1990;</ref><ref type="bibr" target="#b16">Jelinek et al., 1991)</ref> and the latent Dirichlet allo- cation (LDA) ( <ref type="bibr" target="#b22">Liu and Liu, 2007;</ref><ref type="bibr" target="#b39">Tam and Schultz, 2005</ref>). The CER results of these two models are also shown in <ref type="table" target="#tab_0">Table 1</ref>, respectively. For the cache model, bigram cache was used since it can yield better results than the unigram and trigram cache models in our experiments. It is worthy to notice that the LDA model was trained with the entire set of contemporaneous text document collection (c.f. Section 4), while all of the query models explored in the paper were estimated based on a subset of the corpus selected by an initial round of retrieval. The re- sults reveal that most of these query models can achieve superior performance over the two con- ventional language models.</p><p>In the second part of experiments, we evaluate the utilities of the various query models as ap- plied to the speech summarization task. At the outset, we assess the performance level of the baseline KLM method by comparison with two well-practiced unsupervised methods, viz. the vector space model (VSM) <ref type="bibr" target="#b11">(Gong and Liu, 2001)</ref>, and its extension, maximal marginal relevance (MMR) <ref type="bibr" target="#b3">(Carbonell and Goldstein, 1998</ref>). The corresponding results are shown in <ref type="table" target="#tab_1">Table 2</ref> and can be aligned with several related literature re- views. By looking at the results, we find that KLM outperforms VSM by a large margin, con- firming the applicability of the language model- ing framework for speech summarization. Fur- thermore, MMR that presents an extension of VSM performs on par with KLM for the text summarization task (TD) and exhibits superior performance over KLM for the speech summari- zation task (SD). We now turn to evaluate the effectiveness of the various query models (viz. RM, SMM, RSMM and QMM) in conjunction with the pseudo-relevance feedback process for enhancing the sentence model involved in the KLM method. The corresponding results are also shown in <ref type="table" target="#tab_1">Table 2</ref>. Two noteworthy observations can be drawn from <ref type="table" target="#tab_1">Table 2</ref>. One is that all these query models can considerably improve the summarization performance of the KLM method, which corroborates the advantage of using them for enhanced sentence representations. The other is that QMM is the best-performing one among all the formulations studied in this paper for both the TD and SD cases.</p><p>Going one step further, we explore to use extra prosodic features that are deemed complemen- tary to the LM cue provided by QMM for speech summarization. To this end, a support vector ma- chine (SVM) based summarization model is trained to integrate a set of 28 commonly-used prosodic features ( <ref type="bibr" target="#b23">Liu and Hakkani-Tur, 2011</ref>) for representing each spoken sentence, since SVM is arguably one of the state-of-the-art su- pervised methods that can make use of a diversi- ty of indicative features for text or speech sum- marization ( <ref type="bibr" target="#b27">Xie and Liu, 2010;</ref><ref type="bibr" target="#b7">Chen et al., 2013)</ref>. The sentence ranking scores derived by QMM and SVM are in turn integrated through a simple log-linear combination. The correspond- ing results are shown in <ref type="table" target="#tab_1">Table 2</ref>, demonstrating consistent improvements with respect to all the three variants of the ROUGE metric as compared to that using either QMM or SVM in isolation. We also investigate using SVM to additionally integrate a richer set of lexical and relevance fea- tures to complement QMM and further enhance the summarization effectiveness. However, due to space limitation, we omit the details here. As a side note, there is a sizable gap between the TD and SD cases, indicating room for further im- provements. We may seek remedies, such as ro- bust indexing schemes, to compensate for imper- fect speech recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Outlook</head><p>In this paper, we have presented a systematic and thorough analysis of a few well-practiced query models for IR and extended their novel applica- bility to speech recognition and summarization in a principled way. Furthermore, we have pro- posed an extension of this research line by intro- ducing query-specific mixture modeling; the util- ities of the deduced model have been extensively compared with several existing query models. As to future work, we would like to investigate jointly integrating proximity and other different kinds of relevance and lexical/semantic infor- mation cues into the process of feedback docu- ment selection so as to improve the empirical effectiveness of such query modeling.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 . The speech recognition results (in CER (%)) achieved by various language models along with different numbers of latent topics/pseudo- relevance feedback documents.</head><label>1</label><figDesc></figDesc><table>16 
32 
64 
128 
Baseline 
20.08 
Cache 
19.86 
LDA 
19.29 
19.30 
19.28 
19.15 
RM 
19.26 
19.26 
19.26 
19.26 
SMM 
19.19 
19.00 
19.14 
19.10 
RSMM 
19.18 
19.14 
19.15 
19.19 
QMM 
19.05 
18.97 
19.00 
18.99 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table>The summarization results (in F-scores) 
achieved by various language models along with 
text and spoken documents. 

Text Documents (TD) 
Spoken Documents (SD) 

ROUGE-1 ROUGE-2 ROUGE-L ROUGE-1 ROUGE-2 ROUGE-L 

VSM 0.347 
0.228 
0.290 
0.342 
0.189 
0.287 
MMR 0.407 
0.294 
0.358 
0.381 
0.226 
0.331 
KLM 0.411 
0.298 
0.361 
0.364 
0.210 
0.307 
RM 
0.453 
0.335 
0.403 
0.382 
0.239 
0.331 
SMM 0.439 
0.320 
0.388 
0.383 
0.229 
0.327 
RSMM 0.472 
0.365 
0.423 
0.381 
0.235 
0.329 
QMM 0.486 
0.382 
0.435 
0.395 
0.256 
0.349 
SVM 0.441 
0.334 
0.396 
0.370 
0.222 
0.326 
QMM+ 
SVM 
0.492 
0.395 
0.448 
0.398 
0.261 
0.358 </table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research is supported in part by the "Aim for the Top University Project" of National Tai-wan Normal University (NTNU), sponsored by the Ministry of Education, Taiwan, and by the Ministry of Science and Technology, Taiwan, under Grants MOST 103-2221-E-003-016-MY2, NSC 101-2221-E-003-024-MY3, NSC 102-2221-E-003-014-, NSC 101-2511-S-003-057-MY3, NSC 101-2511-S-003-047-MY3 and NSC 103-2911-I-003-301.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Modern information retrieval: the concepts and technology behind search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Baeza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Yates</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berthier</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>ACM Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Mining: Theory and Applications</title>
		<editor>A. Srivastava and M. Sahami,</editor>
		<imprint>
			<publisher>Taylor and Francis</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The use of MMR, diversitybased reranking for reordering documents and producing summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jade</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="335" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A survey of automatic query expansion in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Romano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1" to="56" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A theoretical analysis of pseudo-relevance feedback models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephane</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICTIR</title>
		<meeting>ICTIR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Selecting good expansion terms for pseudo-relevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="243" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Extractive speech summarization using evaluation metricrelated training criteria. Information Processing &amp; Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Hsiang</forename><surname>Berlin Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Mei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Wen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Royal Statistical Society B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A unified optimization framework for robust pseudo-relevance feedback algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">V</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevyn</forename><surname>Collins-Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1069" to="1078" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fundamental technologies in modern speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadaoki</forename><surname>Furui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Gales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiichi</forename><surname>Tokuda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="16" to="17" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generic text summarization using relevance measure and latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="19" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Parsimonious language models for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised learning by probabilistic latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="177" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Spoken language processing: a guide to theory, algorithm, and system development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Wuen</forename><surname>Hon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Prentice Hall PTR</publisher>
			<pubPlace>Upper Saddle River, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A dynamic language model for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Merialdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Strauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the DARPA workshop on speech and natural language</title>
		<meeting>the DARPA workshop on speech and natural language</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="293" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Statistical methods for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Jelinek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Speech and language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Prentice Hall PTR</publisher>
			<pubPlace>Upper Saddle River, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A cache-based natural language model for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renato</forename><forename type="middle">D</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="570" to="583" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On information and sufficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Solomon</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">A</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">ROUGE: Recall-oriented Understudy for Gisting Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://haydn.isi.edu/ROUGE/" />
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised language model adaptation incorporating named entity information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="672" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Speech summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Understanding: Systems for Extracting Semantic Information from Speech</title>
		<editor>G. Tur and R. D. Mori</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Document language models, query models, and risk minimization for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="111" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Relevance-based language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A Generative Theory of Relevance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<pubPlace>Amherst</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improving supervised learning for meeting summarization using sampling and regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shasha</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="495" to="514" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A comparative study of methods for estimating query language models with pseudo feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhua</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1895" to="1898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Positional relevance model for pseudo-relevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhua</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="579" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A cluster-based resampling method for pseudo-relevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyung</forename><surname>Soon Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="235" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A deterministic resampling method using overlapping document clusters for pseudorelevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyung</forename><surname>Soon Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="792" to="806" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Advances in automatic text summarization</title>
		<editor>Inderjeet Mani and Mark T. Maybury</editor>
		<imprint>
			<date type="published" when="1999" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Automatic summarization. Foundations and Trends in Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="103" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A word graph algorithm for large vocabulary continuous speech recognition. Computer Speech and Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ortmanns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Aubert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="43" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A language modeling approach to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On term selection for query expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="359" to="364" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">SRILM-An extensible language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="901" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Regularized estimation of mixture models for robust pseudo-relevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="162" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dynamic language model adaptation using variational Bayes inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yik-Cheung</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="5" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A study of methods for negative relevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="219" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">MATBN: A Mandarin Chinese broadcast news corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Min</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berlin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jen-Wei</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Sian</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computational Linguistics &amp; Chinese Language Processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="219" to="236" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A comparative study of utilizing topic models for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECIR</title>
		<meeting>ECIR</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="29" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Valtcho Valtchev, and Phil Woodland</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Kershaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Odell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Ollason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The HTK book version 3.4</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A study of smoothing methods for language models applied to ad hoc information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Statistical language models for information retrieval: a critical review. Foundations and Trends in Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="137" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Novelty and redundancy detection in adaptive filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Minka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
