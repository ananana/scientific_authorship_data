<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MTNT: A Testbed for Machine Translation of Noisy Text</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Michel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MTNT: A Testbed for Machine Translation of Noisy Text</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="543" to="553"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>543</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Noisy or non-standard input text can cause disastrous mistranslations in most modern Machine Translation (MT) systems, and there has been growing research interest in creating noise-robust MT systems. However, as of yet there are no publicly available parallel corpora of with naturally occurring noisy inputs and translations, and thus previous work has resorted to evaluating on synthetically created datasets. In this paper, we propose a benchmark dataset for Machine Translation of Noisy Text (MTNT), consisting of noisy comments on Reddit 1 and professionally sourced translations. We commissioned translations of En-glish comments into French and Japanese, as well as French and Japanese comments into English, on the order of 7k-37k sentences per language pair. We qualitatively and quantitatively examine the types of noise included in this dataset, then demonstrate that existing MT models fail badly on a number of noise-related phenomena, even after performing adaptation on a small training set of in-domain data. This indicates that this dataset can provide an attractive testbed for methods tailored to handling noisy text in MT. 2</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>#nlproc is actualy f*ing hARD tbh This handcrafted sentence showcases several types of noise that are commonly seen on so- cial media: abbreviations ("#nlproc"), typograph- ical errors ("actualy"), obfuscated profanities ("f*ing"), inconsistent capitalization ("hARD"), Internet slang ("tbh" for "to be honest") and emojis ( ). Although machine translation has achieved significant quality improvements over the past few years due to the advent of Neu- ral Machine Translation (NMT) <ref type="bibr" target="#b13">(Kalchbrenner and Blunsom;</ref><ref type="bibr" target="#b37">Sutskever et al., 2014;</ref><ref type="bibr">Bahdanau et al., 2014;</ref><ref type="bibr">Wu et al., 2016)</ref>, systems are still not robust to noisy input like this <ref type="bibr">(Belinkov and Bisk, 2018;</ref><ref type="bibr" target="#b14">Khayrallah and Koehn)</ref>. For exam- ple, Google Translate 3 translates the above exam- ple into French as: #nlproc est en train de f * ing dur hb which translates back into English as "#nlproc is in the process of [f * ing] hard hb". This shows that noisy input can lead to erroneous translations that can be misinterpreted or even offensive.</p><p>Noise in social media text is a known issue that has been investigated in a variety of pre- vious work (Eisenstein; <ref type="bibr">Baldwin et al.)</ref>. Most recently, <ref type="bibr">Belinkov and Bisk (2018)</ref> have fo- cused on the difficulties that character based NMT models have translating text with character level noise within individual words (from scram- bling to simulated human errors such as typos or spelling/conjugation errors). This is a good first step towards noise-robust NMT systems, but as we demonstrate in §2, word-by-word replacement or scrambling of characters doesn't cover all the id- iosyncrasies of language on the Internet.</p><p>At this point, despite the obvious utility of cre- ating noise-robust MT systems, and the scientific challenges contained therein, there is currently a bottleneck in that there is no standard open bench- mark for researchers and developers of MT sys- tems to test the robustness of their models to these and other phenomena found in noisy text on the Internet. In this work, we introduce MTNT, a new, realistic dataset aimed at testing robust- ness of MT systems to these phenomena. The dataset contains naturally created noisy source sentences with professionally sourced translations both in a pair of typologically close languages (English and French) and distant languages (En- glish and Japanese). We collect noisy comments from the Reddit online discussion website ( §3) in English, French and Japanese, and ask pro- fessional translators to translate to and from En- glish, resulting in approximately 1000 test sam- ples and from 6k to 36k training samples in four language pairs (English-French (en-fr), French- English (fr-en), English-Japanese (en-ja) and Japanese-English (ja-en)). In addition, we re- lease additional small monolingual corpora in those 3 languages to both provide data for semi- supervised adaptation approaches as well as noisy Language Modeling (LM) experiments. We test standard translation models ( §5) and language models ( §6) on our data to understand their failure cases and to provide baselines for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Noise and Input Variations in</head><p>Language on the Internet</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Examples from Social Media Text</head><p>The term "noise" can encompass a variety of phe- nomena in natural language, with variations across languages (e.g. what is a typo in logographic writ- ing systems?) and type of content ( <ref type="bibr">Baldwin et al.)</ref>.</p><p>To give the reader an idea of the challenges posed to MT and Natural Language Processing (NLP) systems operating on this kind of text, we provide a non-exhaustive list of types of noise and more generally input variations that deviate from stan- dard MT training data we've encountered in Red- dit comments:</p><p>• Spelling/typographical errors: "across" → "accross", "receive" → "recieve", "could have" → "could of", "temps" → "tant", " " → ""</p><p>• Word omission/insertion/repetition: "je n'aime pas" → "j'aime pas","je pense" → "moi je pense"</p><p>• Grammatical errors: "a ton of" → "a tons of", "There are fewer people" → "There are less people"</p><p>• Spoken language: "want to" → "wanna", "I am" → "I'm", "je ne sais pas" → "chais pas", "" → " ",</p><p>• Internet slang: "to be honest" → "tbh", "shaking my head" → "smh", "mort de rire" → "mdr", "" → "w"/""</p><p>• Proper nouns (with or without correct capi- talization): "Reddit"→ "reddit"</p><p>• Dialects: African American Vernacular En- glish, Scottish, Provençal, Québécois, Kan- sai, Tohoku...</p><p>• Code switching: "This is so cute" → "This is so kawaii", "C'est trop conventionel" → "C'est trop mainstream", ". . . " → "Now ing..."</p><p>• Jargon: on Reddit: "upvote", "downvote", "sub", "gild"</p><p>• Emojis and other unicode characters: , , , , , ,</p><p>• Profanities/slurs (sometimes masked) "f*ck", "m*rde" . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Is Translating Noisy Text just another</head><p>Adaptation Problem?</p><p>To a certain extent, translating noisy text is a type of adaptation, which has been studied extensively in the context of both Statistical Machine Transla- tion (SMT) and NMT (Axelrod et al.; Li et al.; Lu- ong and Manning, 2015; Chu et al.; Miceli Barone et al.; <ref type="bibr">Wang et al.;</ref><ref type="bibr" target="#b23">Michel and Neubig, 2018)</ref>. However, it presents many differences with previ- ous domain adaptation problems, where the main goal is to adapt from a particular topic or style. In the case of noisy text, it will not only be the case that a particular word will be translated in a dif- ferent way than it is in the general domain (e.g. as in the case of "sub"), but also that there will be increased lexical variation (e.g. due to spelling or typographical errors), and also inconsistency in grammar (e.g. due to omissions of critical words or mis-usage). The sum of these differences war- rants that noisy MT be treated as a separate in- stance than domain adaptation, and our experi- mental analysis in 5.4 demonstrates that even af- ter performing adaptation, MT systems still make a large number of noise-related errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Collection Procedure</head><p>We first collect noisy sentences in our three lan- guages of interest, English, French and Japanese. 3.4</p><p>3.4</p><p>Figure 1: Summary of our collection process and the respective sections addressing them. We apply the same procedure for each language.</p><p>We refer to <ref type="figure">Figure 1</ref> for an overview of the data collection and translation process.</p><p>We choose Reddit as a source of data because (1) its content is likely to exhibit noise, (2) some of its sub-communities are entirely run in dif- ferent languages, in particular, English, French and Japanese, and (3) Reddit is a popular source of data in curated and publicly distributed NLP datasets ( <ref type="bibr">Tan et al.)</ref>. We collect data using the pub- lic Reddit API. <ref type="bibr">4</ref> Note that the data collection and translation is performed at the comment level. We split the par- allel data into sentences as a last step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Sources</head><p>For each language, we select a set of communities ("subreddits") that we know contain many com- ments in that language:</p><p>English: Since an overwhelming majority of the discussions on Reddit are conducted in En- glish, we don't restrict our collection to any community in particular. for Japanese. The large difference in collection time is due to the variance in comment through- put and relative amount of noise between the languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Contrast Corpora</head><p>Not all comments found on Reddit exhibit noise as described in Section 2. Because we would like to focus our data collection on noisy comments, we devise criteria that allow us to distinguish poten- tially noisy comments from clean ones. Specifi- cally, we compile a contrast corpus composed of clean text that we can compare to, and find poten- tially noisy text that differs greatly from the con- trast corpus. Given that our final goal is MT robust to noise, we prefer that these contrast corpora con- sist of the same type of data that is often used to train NMT models. We select different datasets for each language:</p><p>English: The English side of the preprocessed parallel training data provided for the German-English WMT 2017 News transla- tion task, 5 as provided on the website. This amounts to ≈ 5.85 million sentences.</p><p>French: The entirety of the French side of the parallel training data provided for the English-French WMT 2015 translation task. <ref type="bibr">6</ref> This amounts to ≈ 40.86 million sentences.</p><p>Japanese: We aggregate three small/medium sized MT datasets: KFTT (Neubig, 2011), JESC (Pryzant et al.) and TED talks ( <ref type="bibr" target="#b1">Cettolo et al., 2012</ref>), amounting to ≈ 4.19 million sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Identifying Noisy Comments</head><p>We now describe the procedure used to identify comments containing noise.</p><p>Pre-filtering First, we perform three pre- processing to discard comments that do not repre- sent natural noisy text in the language of interest:</p><p>1. Comments containing a URL, as detected by a regular expression.</p><p>2. Comments where the author's username con- tains "bot" or "AutoModerator". This mostly removes automated comments from bots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Comments in another language: we run</head><p>langid.py 7 (Lui and Baldwin) and discard comments where p(lang | comment) &gt; 0.5 for any language other than the one we are interested in.</p><p>This removes cases that are less interesting, i.e. those that could be solved by rule-based pattern matching or are not natural text created by regu- lar users in the target language. Our third criterion in particular discards comments that are blatantly in another language while still allowing comments that exhibit code-switching or that contain proper nouns or typos that might skew the language iden- tification. In preliminary experiments, we noticed that these criteria 14.47, 6.53 and 7.09 % of the collected comments satisfied the above criteria re- spectively.</p><p>Normalization After this first pass of filtering, we pre-process the comments before running them through our noise detection procedure. We first strip Markdown 8 syntax from the comments. For English and French, we normalize the punctua- tion, lowercase and tokenize the comments using the Moses tokenizer. For Japanese, we simply lowercase the alphabetical characters in the com- ments. Note that this normalization is done for the purpose of noise detection only. The collected comments are released without any kind of pre- processing. We apply the same normalization pro- cedure to the contrast corpora.</p><p>Unknown words In the case of French and En- glish, a clear indication of noise is the presence of out-of-vocabulary words (OOV): we record all lowercased words encountered in our reference corpus described in Section 3.2 and only keep comments that contain at least one OOV. Since we did not use word segmentation for the Japanese reference corpus, we found this method not to be very effective to select Japanese comments and therefore skipped this step.</p><p>Language model scores The final step of our noise detection procedure consists of selecting those comments with a low probability under a language model trained on the reference monolin- gual corpus. This approach mirrors the one used in Moore and Lewis and Axelrod et al. to se- lect data similar to a specific domain using lan- guage model perplexity as a metric. We search for comments that have a low probability under a sub-word language model for more flexibility in the face of OOV words. We segment the contrast corpora with Byte-Pair Encoding (BPE) using the sentencepiece 9 implementation. We set the vocab- ulary sizes to 1, 000, 1, 000 and 4, 000 for English, French and Japanese respectively. We then use a 5-gram Kneser-Ney smoothed language model trained using kenLM <ref type="bibr">10 (Heafield et al.)</ref> to calcu- late the log probability, normalized by the number of tokens for every sentence in the reference cor- pus. Given a reddit comment, we compute the nor- malized log probability of each of its lines under our subword language model. If for any line this score is below the 1st percentile of scores in the reference corpus, the comment is labeled as noisy and saved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Creating the Parallel Corpora</head><p>Once enough data has been collected, we isolate 15, 000 comments in each language by the follow-#samples #src tokens #trg tokens en-fr 1,020 15,919 18,445 fr-en 1,022 16,662 16,038 en-ja 1,002 11,040 20,008 ja-en 1,020 23,997 33,429 ing procedure:</p><p>• Remove all duplicates. In particular, this han- dles comments that might have been scraped twice or automatic comments from bots.</p><p>• To further weed out outliers (comments that are too noisy, e.g. ASCII art, wrong lan- guage. . . or not noisy enough), we discard comments that are on either end of the dis- tribution of normalized LM scores within the set of collected comments. We only keep comments whose normalized score is within the 5-70 percentile for English (resp. 5-60 for French and 10-70 for Japanese). These num- bers are chosen by manually inspecting the data.</p><p>• Choose 15, 000 samples at random.</p><p>We then concatenate the title of the thread where the comment was found to the text and send everything to an external vendor for manual trans- lations. Upon reception of the translations, we no- ticed a certain amount of variation in the quality of translations, likely because translating social me- dia text, with all its nuances, is difficult even for humans. In order to ensure the highest quality in the translations, we manually filter the data to seg- ment the comments into sentences and weed out poor translations for our test data. We thereby re- tain around 1, 000 sentence pairs in each direction for the final test set.</p><p>We gather the samples that weren't selected for the test sets to be used for training or fine-tuning models on noisy data. We automatically split com- ments into sentences with a regular expression detecting sentence delimiters, and then align the source and target sentences. Should this alignment fail (i.e. the source comment contains a different number of sentences than the target comment af- ter automatic splitting), we revert back to provid- ing the whole comment without splitting. For the training data, we do not verify the correctness of translations as closely as for the test data. Finally, #samples #src tokens #trg tokens en-fr 36,058 841k 965k fr-en 19,161 661k 634k en-ja 5,775 281k 506k ja-en 6,506 172k 128k  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Monolingual Corpora</head><p>After the creation of the parallel train and test sets, a large number of unused comments remain in each language, which we provide as monolingual corpora. This additional data has two purposes: first, it serves as a resource for in-domain training using semi-supervised methods relying on mono- lingual data (e.g. Cheng et al.; Zhang and Zong). Second, it provides a language modeling dataset for noisy text in three languages.</p><p>We select 3, 000 comments at random in each dataset to form a validation set to be used to tune hyper-parameters, and provide the rest as training data. The data is provided with one comment per line. Newlines within individual comments are re- placed with spaces.   on the size of the datasets. As with the parallel MT data, we provide the number of tokens after tokenization with the Moses tokenizer for English and French and Kytea for Japanese.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dataset Analysis</head><p>In this section, we investigate the proposed data to understand how different categories of noise are represented and to show that our test sets contain more noise overall than established MT bench- marks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Quantifying Noisy Phenomena</head><p>We run a series of tests to count the number of oc- currences of some of the types of noise described in Section 2. Specifically we pass our data through spell checkers to count spelling and grammar er- rors. Due to some of these tests being impractical to run on a large scale, we limit our analysis to the test sets of MTNT. We use slightly different procedures depend- ing on the tools available for each language. We test for spelling and grammar errors in English data using Grammarly <ref type="bibr">11</ref> , an online resource for English spell-checking. Due to the unavailabil- ity of an equivalent of Grammarly in French and Japanese, we test for spelling and grammar er- ror using the integrated spell-checker in Microsoft Word 2013 12 . Note that Word seems to count proper nouns as spelling errors, giving higher numbers of spelling errors across the board in French as compared to English.</p><p>For all languages, we also count the number of profanities and emojis using custom-made lists and regular expressions <ref type="bibr">13</ref> . In order to compare re- sults across datasets of different sizes, we report all counts per 100 words.</p><p>The results are recorded in the last row of each section in <ref type="table" target="#tab_6">Table 5</ref>. In particular, for the languages with a segmental writing system, English and French, spelling errors are the dominant type of noise, followed by grammar error. Unsurprisingly, the former are much less present in Japanese. <ref type="table" target="#tab_6">Table 5</ref> also provide a comparison with the rel- evant side of established MT test sets. For En- glish and French, we compare our data to new- stest2014 14 and newsdiscusstest2015 15 test sets. For Japanese, we compare with the test sets of the datasets described in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison to Existing MT Test Sets</head><p>Overall, MTNT contains more noise in all met- rics but one (there are more profanities in JESC, a Japanese subtitle corpus). This confirms that MTNT indeed provides a more appropriate bench- mark for translation of noisy or non-standard text.</p><p>Compared to synthetically created noisy test sets <ref type="bibr">(Belinkov and Bisk, 2018)</ref> MTNT contains less systematic spelling errors and more varied types of noise (e.g. emojis and profanities) and is thereby more representative of naturally occurring noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Machine Translation Experiments</head><p>We evaluate standard NMT models on our pro- posed dataset to assess its difficulty. Our goal is not to train state-of-the art models but rather to test standard off-the-shelf NMT systems on our data, and elucidate what features of the data make it dif- ficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Model Description</head><p>All our models are implemented in DyNet ( <ref type="bibr" target="#b26">Neubig et al., 2017</ref>) with the XNMT toolkit (?). We use approximately the same setting for all lan- guage pairs: the encoder is a bidirectional LSTM with 2 layers, the attention mechanism is a multi layered perceptron and the decoder is a 2 layered LSTM. The embedding dimension is 512, all other dimensions are 1024. We tie the target word em- beddings and the output projection weights (Press and Wolf). We train with Adam ( <ref type="bibr" target="#b15">Kingma and Ba, 2014</ref>) with XNMT's default hyper-parameters, as well as dropout (with probability 0.3). We used BPE subwords to handle OOV words. Full con- figuration details as well as code to reproduce the baselines is available at https://github. com/pmichel31415/mtnt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Training Data</head><p>We train our models on standard MT datasets:</p><p>• en ↔ fr: Our training data consists in the europarl-v7 <ref type="bibr">16</ref> and news-commentary- v10 17 corpora, totaling 2, 164, 140 samples, 54, 611, 105 French tokens and 51, 745, 611 English tokens (non-tokenized). We use the newsdiscussdev2015 14 dev set from WMT15 as validation data and evaluate the model on the newsdiscusstest2015 15 and newstest2014 14 test sets.</p><p>• en ↔ ja: We concatenate the respective train, validation and test sets of the three corpora mentioned in 3.2. In particular we detokenize the Japanese part of each dataset to make sure that any tokenization we perform will be uniform (in practice we remove ASCII spaces). This amounts to 3, 900, 772 training samples <ref type="bibr">(34,</ref><ref type="bibr">989,</ref><ref type="bibr">346</ref> English tokens without tokenization). We concatenate the dev sets associated with these corpora to serve as val- idation data and evaluate on each respective test set separately.</p><note type="other">en-fr fr-en newstest2014 33.52 28.93 newsdiscusstest2015 33.03 30.76 MTNT 21.77 23.27 MTNT (+tuning) 29.73 30.29 en-ja ja-en TED 14.51 13.25 KFTT 20.82 20.77 JESC 15.77 18.00 MTNT 9.02 6.65 MTNT (+tuning) 12.45 9.82</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>We use sacreBLEU 18 , a standardized BLEU score evaluation script proposed by <ref type="bibr" target="#b30">Post (2018)</ref>, for BLEU evaluation of our benchmark dataset. It takes in detokenized references and hypothe- ses and performs its own tokenization before com- puting BLEU score. We specify the intl tok- enization option. In the case of Japanese text, we run both hypothesis and reference through KyTea before computing BLEU score. We strongly en- courage that evaluation be performed in the same manner in subsequent work, and will provide both scripts and an evaluation web site in order to facil- itate reproducibility. <ref type="table" target="#tab_7">Table 6</ref> lists the BLEU scores for our models on the relevant test sets in the two language pairs, including the results on MTNT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Analysis</head><p>To better understand the types of errors made by our model, we count the n-grams that are over- and under-generated with respect to the reference translation. Specifically, we compare the count ra- tios of all 1-to 3-grams in the output and in the reference and look for the ones with the highest (over-generated) and lowest (under-generated) ra- tio.</p><p>We find that in English, the model under- generates the contracted form of the negative ("do not"/"don't") or of auxiliaries ("That is"/"I'm").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head><p>Moi faire la gueule dans le métro me manque, c'est grave ? Target I miss sulking in the underground, is that bad? Our model I do not know what is going on in the metro, that is a serious matter. + fine-tuning I do not want to be in the metro, it's serious? Source :o 'tain je me disais bien que je passais à côté d'un truc vu les upvotes. Target :o damn I had the feeling that I was missing something considering the upvotes. Our model o, I was telling myself that I was passing over a nucleus in view of the Yupvoots. + fine-tuning o, I was telling myself that I was going next to a nucleus in view of the &lt;unk&gt;upvotes. Source * C'est noël / pâques / pentecôte / toussaint : Pick One, je suis pas catho Target</p><p>Christmas / Easter / Pentecost / All Saints: Pick One, I'm not Catholic! Our model &lt;unk&gt; It is a pale/poward, a palec&lt;unk&gt;te d'&lt;unk&gt;tat: Pick One, I am not a catho! + fine-tuning &lt;unk&gt; It's no&lt;unk&gt;l / pesc&lt;unk&gt;e /pentecate /mainly: Pick One, I'm not catho! <ref type="table">Table 7</ref>: Comparison of our model's output before and after fine-tuning in fr-en.</p><p>Similarly, in French, our model over generates "de votre" (where "votre" is the formal 2nd per- son plural for "your") and "n'ai pas" which show- cases the "ne [. . . ] pas" negation, often dropped in spoken language. Conversely, the informal sec- ond person "tu" is under-generated, as is the in- formal and spoken contraction of "cela", "ça". In Japanese, the model under-generates, among oth- ers, the informal personal pronoun ("ore") or the casual form ("da") of the verb ("desu", to be). In ja-en the results are difficult to inter- pret as the model seems to produce incoherent out- puts (e.g. "no, no, no. . . ") when the NMT system encounters sentences it has not seen before. The full list of n-grams with the top 5 and bottom 5 count ratios in each language pair is displayed in  <ref type="table" target="#tab_8">Table 8</ref>: Over and under generated n-grams in our model's output for en-fr</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Fine-Tuning</head><p>Finally, we test a simple domain adaptation method by fine-tuning our models on the training data described in Section 3.4. We perform one epoch of training with vanilla SGD with a learn- ing rate of 0.1 and a batch size of 32. We do not use the validation data at all. As evidenced by the results in the last row of <ref type="table" target="#tab_7">Table 6</ref>, this drives BLEU score up by 3.17 to 7.96 points depending on the language pair. However large this increase might be, our model still breaks on very noisy sentences. <ref type="table">Table 7</ref> shows three examples in fr-en. Al- though our model somewhat improves after fine- tuning, the translations remain inadequate in all cases. In the third case, our model downright fails to produce a coherent output. This shows that de- spite improving BLEU score, naive domain adap- tation by fine-tuning doesn't solve the problem of translating noisy text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Language Modeling Experiments</head><p>In addition to our MT experiments, we report character-level language modeling results on the monolingual part of our dataset. We use the data described in Section 3.5 as training and validation sets. We evaluate the trained model on the source side of our en-fr, fr-en and ja-en test sets for English, French and Japanese respectively. We report results for two models: a Kneser- Ney smoothed 6-gram model (implemented with KenLM) and an implementation of the AWD- LSTM proposed in ( <ref type="bibr" target="#b21">Merity et al., 2018)</ref>  <ref type="bibr">19</ref> . We re- port the Bit-Per-Character (bpc) counts in table 9.  We intend these results to serve as a baseline for future work in language modeling of noisy text in either of those three languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related work</head><p>Handling noisy text has received growing attention among various language processing tasks due to the abundance of user generated content on popu- lar social media platforms <ref type="bibr" target="#b5">(Crystal, 2001;</ref><ref type="bibr">Herring, 2003;</ref><ref type="bibr" target="#b6">Danet and Herring, 2007)</ref>. These contents are considered as noisy when compared to news corpora which have been the main data source for language tasks (Baldwin et al.; Eisenstein). They pose several unique challenges because they con- tain a larger variety of linguistic phenomena that are absent in the news domain and that lead to degraded quality when applying an model to out- of-domain data ( <ref type="bibr" target="#b33">Ritter et al.;</ref><ref type="bibr" target="#b20">Luong and Manning, 2015)</ref>. Additionally, they are live examples of the Cmabrigde Uinervtisy (Cambridge University) ef- fect, where state-of-the-art models become brittle while human's language processing capability is more robust ( <ref type="bibr" target="#b34">Sakaguchi et al., 2017;</ref><ref type="bibr">Belinkov and Bisk, 2018)</ref>.</p><p>Efforts to address these challenges have been focused on creating in-domain datasets and an- notations ( <ref type="bibr" target="#b28">Owoputi et al.;</ref><ref type="bibr" target="#b17">Kong et al.;</ref><ref type="bibr">Blodgett et al., 2017)</ref>, and domain adaptation training <ref type="bibr" target="#b20">(Luong and Manning, 2015)</ref>. In MT, improvements were obtained for SMT (Formiga and Fonollosa). However, the specific challenges for neural ma- chine translation have not been studied until re- cently ( <ref type="bibr">Belinkov and Bisk, 2018;</ref><ref type="bibr" target="#b36">Sperber et al.;</ref><ref type="bibr" target="#b2">Cheng et al., 2018</ref>). The first provides empirical evidence of non-trivial quality degradation when source sentences contain natural noise or syn- thetic noise within words, and the last two explore data augmentation and adversarial approaches of adding noise efficiently to training data to improve robustness.</p><p>Our work also contributes to recent advances in evaluating neural machine translation quality with regard to specific linguistic phenomena, such as manually annotated test sentences for English to French translation, in order to identify errors due to specific linguistic divergences between the two languages ( <ref type="bibr">Isabelle et al.)</ref>, or automatically gener- ated test sets to evaluate typical errors in English to German translation (Sennrich). Our contribu- tion distinguishes itself from this previous work and other similar initiatives <ref type="bibr" target="#b29">(Peterson, 2011)</ref> by providing an open test set consisting of naturally occurring text exhibiting a wide range of phenom- ena related to noisy input text from contempora- neous social media.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We proposed a new dataset to test MT models for robustness to the types of noise encountered in nat- ural language on the Internet. We contribute par- allel training and test data in both directions for two language pairs, English ↔ French and English ↔ Japanese, as well as monolingual data in those three languages. We show that this dataset con- tains more noise than existing MT test sets and poses a challenge to models trained on standard MT corpora. We further demonstrate that these challenges cannot be overcome by a simple do- main adaptation approach alone. We intend this contribution to provide a standard benchmark for robustness to noise in MT and foster research on models, dataset and evaluation metrics tailored for this specific problem. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>The first two are among the biggest French speaking communities on Reddit. The third is a humor/sarcasm based offspring of /r/france. Japanese: /r/newsokur, /r/bakanewsjp, /r/newsokuvip, /r/lowlevelaware 4 In particular, we use this implementation: praw.readthedocs.io/en/latest, and our com- plete code is available at http://www.cs.cmu.edu/ ~pmichel1/mtnt/. and /r/steamr. Those are the biggest Japanese speaking communities, with over 2,000 subscribers. We collect comments made during the 03/27/2018-03/29/3018 time period for English, 09/2018-03/2018 for French and 11/2017-03/2018</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Test set numbers. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Training sets numbers. 

#samples #src tokens #trg tokens 
en-fr 
852 
16,957 
18,948 
fr-en 
886 
41,578 
46,886 
en-ja 
852 
40,124 
46,886 
ja-en 
965 
25,010 
23,289 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Validation sets numbers. we isolate ≈ 900 samples in each direction to serve as validation data. Information about the size of the data can be found in Table 1, 2 and 3 for the test, training and validation sets respectively. We tokenize the English and French data with the Moses (Koehn et al.) tokenizer and the Japanese data with Kytea (Neubig et al., 2011) before counting the number of tokens in each dataset.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 4 contains information</head><label>4</label><figDesc></figDesc><table>#samples 
#tok 
#char 

en 
train 
81,631 
3,99M 18,9M 
dev 
3,000 
146k 
698k 

fr 
train 
26,485 
1,52M 7,49M 
dev 
3,000 
176k 
867k 

ja 
train 
32,042 
943k 
3.9M 
dev 
3,000 
84k 
351k 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 : Monolingual data numbers.</head><label>4</label><figDesc></figDesc><table>Spelling Grammar Emojis Profanities 

en 

newstest2014 
0.210 
0.189 
0.000 
0.030 
newsdiscusstest2015 
0.621 
0.410 
0.021 
0.076 
MTNT (en-fr) 
2.180 
0.559 
0.289 
0.239 

fr 

newstest2014 
2.776 
0.091 
0.000 
0.245 
newsdiscusstest2015 
1.686 
0.457 
0.024 
0.354 
MTNT 
4.597 
1.464 
0.252 
0.690 

ja 

TED 
0.011 
0.266 
0.000 
0.000 
KFTT 
0.021 
0.228 
0.000 
0.000 
JESC 
0.096 
0.929 
0.090 
0.058 
MTNT 
0.269 
1.527 
0.156 
0.036 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Numbers, per 100 tokens, of quantifiable noise occurrences. For each language and category, the dataset with the highest amount of noise is highlighted.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>BLEU scores of NMT models on the various 
datasets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="true"><head>Table 8 .</head><label>8</label><figDesc></figDesc><table>fr-en en-fr ja-en en-ja 
Over generated 

&lt;unk&gt; 
&lt;unk&gt; 
no, no, 


it is not 
qu'ils 
i 


I do not 
de votre 
no, no, no, 
? 

That is 
s'il 
so on and 


not have 
n'ai pas 
on and so 
? 

Under generated 

it's 
tu 
| 


I'm 
ça 
Is 


I don't 
que tu 
&gt; 


&gt; 
! 
""The 


doesn't 
as 
those 


</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Language modeling scores 

</table></figure>

			<note place="foot" n="1"> www.reddit.com 2 The data is publicly available at http://www.cs. cmu.edu/~pmichel1/mtnt/.</note>

			<note place="foot" n="3"> translate.google.com as of May 2018</note>

			<note place="foot" n="5"> http://www.statmt.org/wmt17/ translation-task.html</note>

			<note place="foot" n="6"> http://www.statmt.org/wmt15/ translation-task.html 7 https://github.com/saffsd/langid.py 8 https://daringfireball.net/projects/ markdown</note>

			<note place="foot" n="9"> https://github.com/google/ sentencepiece 10 https://kheafield.com/code/kenlm/</note>

			<note place="foot" n="11"> https://www.grammarly.com/ 12 https://products.office.com/en-us/ microsoft-word-2013</note>

			<note place="foot" n="13"> available with our code at https://github.com/ pmichel31415/mtnt 14 http://www.statmt.org/wmt15/dev-v2. tgz 15 http://www.statmt.org/wmt15/test.tgz</note>

			<note place="foot" n="16"> http://www.statmt.org/europarl/ 17 http://www.statmt.org/wmt15/ training-parallel-nc-v10.tgz</note>

			<note place="foot" n="18"> https://github.com/mjpost/sacreBLEU</note>

			<note place="foot" n="19"> https://github.com/salesforce/ awd-lstm-lm</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<title level="m">Proceedings of the 3rd Workshop on Noisy User-generated Text</title>
		<meeting>the 3rd Workshop on Noisy User-generated Text</meeting>
		<imprint>
			<biblScope unit="page" from="56" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wit 3 : Web inventory of transcribed and translated talks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Girardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16 th Conference of the European Association for Machine Translation (EAMT)</title>
		<meeting>the 16 th Conference of the European Association for Machine Translation (EAMT)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Towards robust neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-supervised learning for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1965" to="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An empirical comparison of domain adaptation methods for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhui</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><surname>Dabre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="385" to="391" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Language and the Internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crystal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The Multilingual Internet: Language, Culture, and Communication Online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brenda</forename><surname>Danet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Herring</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What to do about bad language on the internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<biblScope unit="page" from="359" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dealing with input noise in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Formiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fonollosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computational Linguistics 2012: Posters</title>
		<meeting>the Conference on Computational Linguistics 2012: Posters</meeting>
		<imprint>
			<biblScope unit="page" from="319" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Scalable modified</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Pouzyrevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Kneser-Ney language model estimation</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<biblScope unit="page" from="690" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Media and Language Change</title>
	</analytic>
	<monogr>
		<title level="j">Special issue of Journal of Historical Pragmatics</title>
		<editor>Susan Herring</editor>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A challenge set approach to evaluating machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Isabelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="2486" to="2496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recurrent continuous translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="1700" to="1709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the impact of various types of noise on neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Neural Machine Translation and Generation</title>
		<meeting>the 2nd Workshop on Neural Machine Translation and Generation</meeting>
		<imprint>
			<biblScope unit="page" from="74" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics on Interactive Poster and Demonstration Sessions</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A dependency parser for tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Archna</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<biblScope unit="page" from="1001" to="1012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adaptive development data selection for loglinear model in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinggong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="662" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">langid.py: An offthe-shelf language identification tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics 2012 System Demonstrations</title>
		<meeting>the Association for Computational Linguistics 2012 System Demonstrations</meeting>
		<imprint>
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stanford neural machine translation systems for spoken language domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation</title>
		<meeting>the International Workshop on Spoken Language Translation</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Regularizing and optimizing lstm language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Regularization techniques for fine-tuning in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sennrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="1490" to="1495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Extreme adaptation for personalized neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Intelligent selection of language model training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics 2010 Conference Short Papers</title>
		<meeting>the Association for Computational Linguistics 2010 Conference Short Papers</meeting>
		<imprint>
			<biblScope unit="page" from="220" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The Kyoto free translation task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<ptr target="http://www.phontron.com/kftt" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Clothiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.03980</idno>
	</analytic>
	<monogr>
		<title level="m">The dynamic neural network toolkit</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pointwise prediction for robust, adaptable japanese morphological analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yosuke</forename><surname>Nakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACLHLT)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="529" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Improved part-of-speech tagging for online conversational text with word clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olutobi</forename><surname>Owoputi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Openmt12 evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kay</forename><surname>Peterson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.08771</idno>
		<title level="m">A call for clarity in reporting bleu scores</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Using the output embedding to improve language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Britz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jesc</surname></persName>
		</author>
		<title level="m">Japanese-english subtitle corpus</title>
		<imprint/>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Named entity recognition in tweets: an experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1524" to="1534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Robsut wrod reocginiton via semi-character recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3281" to="3287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">How grammatical is character-level neural machine translation? assessing mt quality with contrastive translation pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="376" to="382" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Toward robust neural machine translation for noisy input sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Sperber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation</title>
		<meeting>the International Workshop on Spoken Language Translation</meeting>
		<imprint>
			<biblScope unit="page" from="90" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescuniculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on world wide web</title>
		<meeting>the 25th international conference on world wide web</meeting>
		<imprint>
			<biblScope unit="page" from="613" to="624" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
