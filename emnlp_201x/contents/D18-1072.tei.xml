<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Auto-Dialabel: Labeling Dialogue Data with Unsupervised Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Sha</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lintao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Auto-Dialabel: Labeling Dialogue Data with Unsupervised Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="684" to="689"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>684</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The lack of labeled data is one of the main challenges when building a task-oriented dialogue system. Existing dialogue datasets usually rely on human labeling, which is expensive , limited in size, and in low coverage. In this paper, we instead propose our framework auto-dialabel to automatically cluster the dialogue intents and slots. In this framework, we collect a set of context features, leverage an autoencoder for feature assembly, and adapt a dynamic hierarchical clustering method for intent and slot labeling. Experimental results show that our framework can promote human labeling cost to a great extent, achieve good intent clustering accuracy (84.1%), and provide reasonable and instructive slot labeling results.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Building a task-oriented dialogue system is chal- lenging. In real world, unlabeled dialogue data is usually available for companies who has inter- active platform with users. Based on these unla- beled data, the well-known sequence-to-sequence framework <ref type="bibr" target="#b11">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b1">Cho et al., 2014</ref>) is widely used in dialogue response genera- tion ( <ref type="bibr" target="#b12">Vinyals and Le, 2015;</ref><ref type="bibr" target="#b10">Sordoni et al., 2015;</ref><ref type="bibr" target="#b8">Shang et al., 2015</ref>), but it can not handle task- oriented scenario well since it needs accuracy in- stead of fluency. Generally, a task-oriented dia- logue system needs to realize user's intent, which means user's current goal in a dialogue session. To fulfill this intent, the system usually needs sev- eral key information (slot). As shown in <ref type="figure" target="#fig_0">Fig- ure 1</ref>, a dialogue utterance is labeled with intent flight, and several slots such as its from location, arrive time. Training a task-oriented dialogue sys- tem usually needs abundant such labeled data.</p><p>Existing well-known dialogue datasets are mostly human-labeled, such as ATIS ( <ref type="bibr" target="#b5">Hemphill et al., 1990</ref>), DSTC ( <ref type="bibr" target="#b14">Williams et al., 2013</ref>), Frames <ref type="bibr" target="#b3">(El Asri et al., 2017)</ref>, and the Stanford dataset ( <ref type="bibr" target="#b4">Eric et al., 2017)</ref>. Human-labeled datasets are expensive to produce, limited in size, and re- stricted to a specific domain, which make them difficult to extend. Moreover, the intent and slot label sets are usually decided by human experi- ence. Since we usually do not know the exact intents or slots of a new unlabeled data, the as- signed label names may be subjective in some extent. To better assist the human labeling pro- cess, <ref type="bibr" target="#b13">Wen et al. (2017)</ref> proposed an improved ver- sion of Wizard-of-Oz <ref type="bibr" target="#b6">(Kelley, 1984)</ref> data collec- tion methods, which incorporate crowdsourcing to collect domain specific data. Instead of human- labeling, <ref type="bibr" target="#b2">Cohn et al. (1995)</ref> proposed a semisu- pervised framework active learning, which can minimize the need for human annotation in a cer- tain extent. However, these approaches are still mostly or selectively human-labeled, and may be distracted by the disadvantages raised above.</p><p>Thus, in this paper, we propose an unsuper- vised labeling method to automatically cluster di- alogue intents and corresponding slots. Since the intent of a dialogue utterance may depend on its topic or some frequent key words, utterances in the same intent may share similar context features. Hence, we cluster these utterances into different intents. Given a new dialogue dataset whose num- ber and type of intents are uncharted, the cluster- ing process does not need any prior information and can derive a new set of intents. We modify dy- namic clustering methods to automatically decide the number of clustering classes. The clustered in- tents are labeled as integer indices. Before cluster- ing, for better utilization of extracted features, we leverage an autoencoder to map all features into the same space. For the slot labeling, since the phrases of same slots such as location and time may share same type of features, we leverage a similar way to cluster slots within each intent.</p><p>I want to fly one way from Chicago on 8 am this Wednesday and arrive in San Francisco 11 pm in the evening.  Experimental results on the ATIS dataset ( <ref type="bibr" target="#b5">Hemphill et al., 1990)</ref> show that our proposed methods can achieve 84.1% intent clustering accuracy, and provide reasonable and instructive slot labeling results. Moreover, since the whole process is unsupervised, it can be much faster and more consistent and objective than human labeling, and extended to other domains. We think the proposed methods can be a good attempt for the automatic dialogue labeling task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intent: flight</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Slot</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Auto-Dialabel Framework</head><p>Formally, we treat a multi-turn dialogue session D = {Q 1 , R 1 , · · · , Q N , R N } as a sequence of N query-response pairs between two interlocutors, in which query Q * represents user's utterance and re- sponse R * represents assistance's utterance. Each query utterance Q t should be labeled with an in- tent I t ∈ <ref type="bibr">[0, K]</ref>, which represents the interlocu- tor's purpose in current utterance. K is the num- ber of intent classes, and should be dynamically decided during the labeling procedure.</p><p>Since each intent has its corresponding slots, for intent I t , we set its slot as S t = {S t,1 , · · · , S t,Lt }, where L t is number of slots in I t . S t is also learned automatically and dynamically.</p><p>In detail, given a set of query utterances, the unsupervised dialogue auto-labeling system labels the intents and slots based on the following steps:</p><p>feature extraction and assembly, which extracts a set of context features F from query utterance, and leverages an autoencoder to compress each extracted feature into same size, then concatenate them as the assembled feature embedding E. intent clustering, which adopt dynamic hierar- chical clustering to get intents based on E.</p><p>slot clustering, which leverages the same clus- tering methods to get slots based on word-level features and labeled intents.</p><p>The process of intent labeling is shown in <ref type="figure" target="#fig_2">Fig- ure 2</ref>. Slot labeling has a similar process to intent labeling. Features are a key to both intent label- ing and slot labeling. We first introduce the fea- ture extraction and assembly, which involves all the features used in our model. It is noted that we leverage all the features for intent clustering while we only use word-level features for slot labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Feature Extraction and Assembly</head><p>We design a set of context features F * at different levels of granularity to model the query utterance, including word embedding, POS tag, frequent key words, and topic features.</p><p>Word Embedding Given an n-words Q = {w 1 , · · · , w n }, intuitively, the feature of Q re- lied on each words within it. One frequently-used way to model a sentence by words is to use a mean pooling for all word embeddings: F W = 1 n n i embedding of w i POS Tag Since the distribution of the POS tag may effect the sentence's structure in syntactic level, we use bag-of-POS as the POS tag fea- ture F P . Given n p types of POS tags, F P = {p 1 , · · · , p np } is a discrete vector in which each dimension p i represents the existence of a POS tag P OS i .</p><p>Frequent Key Words In several occasions, the intent of a sentence is decided by some key words. So we specially emphasize it by introduc- ing the frequent key words feature F X . F X = {x 1 , · · · , x c } represents the information of key words in query utterance. To centralize the word information, we cluster all the noun words into c different classes by its word embedding, then count the occurrence frequency of each class as a discrete vector F X .</p><p>Topic The topic-level feature denotes the topic information of query utterance. We leverage an unsupervised topic model to get the topic distribu- tion F T ∈ R t as the topic-level feature, t is the number of topics. Since query utterance are short   texts, while conventional topic models such as LDA and PLSA depends on document-level word co-occurrence patterns to detect topics, which may suffer from data sparsity, thus directly applying those models may not work well. In this paper, we leverage the biterm topic model (BTM) proposed by Yan et al. <ref type="formula">(2013)</ref> for better performance. The assembled feature embedding E is the com- bination of each F i . Since each F i has different dimensions, which may unequally affect the clus- tering results, we use an autoencoder to encode all F i into same dimensions as E i , then we concate- nate all the E i as E, which will be used in the clus- tering procedure, as shown in <ref type="figure" target="#fig_2">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Intent Clustering</head><p>Since given a new set of dialogue data, we do not know the number of intents it contains, thus we adapt the hierarchical clustering method to a dy- namic version which can automatically decide the end of the clustering process by the cohesion of different classes. At the beginning of clustering, each query utterance is considered as a different class. At each steps, the cluster model chooses two classes which are the closest in distance, and clus- ter them into the same class. We use radial basis function (rbf) as the clustering distance. This pro- cess ends when all the distances exceed the thresh- old value, which is tuned on a labeled dataset, and fixed for future use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Slot Clustering</head><p>Since slots usually correspond to intents, we do slot labeling based on both the query utterance and the labeled intents. Considering that most slots are composed of noun words, we extract all the noun words in a dialogue, and leverage the same clus- tering methods as in the intent clustering part to cluster them into different slot classes. Note that the slot clustering are word-level. So in feature ex- traction, it did not extract the topic-level features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Baseline Systems</head><p>We conduct experiments on the widely used ATIS dataset ( <ref type="bibr" target="#b5">Hemphill et al., 1990</ref>). The clustering pa- rameters are tuned on the training set of the ATIS dataset ( <ref type="bibr" target="#b5">Hemphill et al., 1990)</ref>, while the exper- iments are conducted on its test set. During clus- tering, we tune the clustering distance limit since it may be more general than the number of classes, and can be transferred to other datasets. The ra- dial basis function (rbf) is used with sklearn de- fault settings.</p><p>Since there is no existing systems specially designed for unsupervised dialogue labeling, we choose three well-known and widely used sen- tence representation methods, and leverage the re- sults vector for clustering as our baseline systems. The first one is the BTM topic model ( <ref type="bibr" target="#b15">Yan et al., 2013)</ref>. We use the topic distribution for clustering. The second one is the CDSSM model proposed by <ref type="bibr" target="#b9">Shen et al. (2014)</ref>. We use the clickthrough data for pre-training and get encoded sentence vector for clustering. The third one is the sentence em- bedding calculated by the average of word embed- ding in query utterance. For each baseline, we leverage the k-means for clustering and use the gold intent number as the cluster number of these models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Intent Labeling</head><p>We leverage glove.6B.300d ( <ref type="bibr" target="#b7">Pennington et al., 2014</ref>) as the pre-trained word embedding in all the baseline and proposed systems. The POS tag is labeled through NLTK toolkit ( <ref type="bibr" target="#b0">Bird et al., 2009</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Intent Labeling Acc (%) topic model 25.4 CDSSM vector 20.7 glove embedding 25.6 auto-dialabel 84.1 <ref type="table">Table 1</ref>: Intent labeling accuracy.</p><p>The topic number of BTM is set to 20 as default.</p><p>Each encoded feature dimension is set to 30, then concatenated to a 120 dimension assembled vec- tor. We have 17 kinds of gold intents, and our sys- tem predicted 18 kinds of intents. Since the clus- tering results have no label information, we sort the predicted intent classes and gold intent classes by size, and manually map them. We leverage in- tent labeling accuracy as the evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Overall Performance</head><p>Our auto-dialabel can reduce the tedious work of understanding the intent of each dialogue utter- ance and finding slot words in it. It clusters all utterances into several intent classes, and words into slot classes, which leaves human labelers only small labors to set label names for each class. Ex- perimental results show that with auto-dialabel, we can label the whole ATIS dataset in less than 1 hour from end to end, compared to days we spend by human labeling. <ref type="table">Table 1</ref> shows the perfor- mance comparison of our model with other base- line systems. From <ref type="table">Table 1</ref>, we find that our pro- posed auto-dialabel achieves high intent labeling accuracy (84.1%) and outperforms other baseline systems by a large margin. This may be because that the baseline systems are not specifically de- signed for intent scenario so that they can not han- dle the intent and slot clustering well, or are not capable of capturing complex intent relevant in- formation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Ablation Tests</head><p>Feature Extraction  <ref type="table">Table 2</ref>: Intent labeling ablation tests. F * shows the performance of the system with only feature F * . −F * shows the performance of the system excluded feature F * . no encode shows the performance of the system excluded the autoencoder parts.</p><p>Intent Slot flight period of day : noon, evening month name : november, april day name : monday, sunday city name : cleveland, houston ground service period of day : night, morning; day name : monday; city name : denver, washington  <ref type="table">Table 2</ref>. From <ref type="table">Table 2</ref>, we find the frequent key in- formation as the most important feature. Since the intent is usually influenced by key words occur- ring in utterance, these kind of features can better capture key information which contributes most to the intent detection. On the contrary, the topic fea- ture is less useful. Since it is not designed for this task, the information it represents may not directly assist the detection of intents.</p><p>Feature Assembly We concatenate the origi- nally extracted features for clustering. The results are shown in <ref type="table">Table 2</ref> as no encode, which suggests that the encoding part is essential in feature assem- bly. Since each feature has a different dimension, if we alternatively concatenate them directly, the "longer" feature may get more "attention", which may distract the clustering results. Generally, en- coding all the features into the same dimension is an efficient way to balance the information.</p><p>Dynamic Clustering To test the performance of our modified dynamic clustering method, we leverage two most common used clustering meth- ods for ablation test, which are k-means and spec- tral clustering. Both clustering numbers are set to gold intent number. The results are shown in <ref type="table">Table 2</ref>, and we can find both methods per- form worse than our methods, which shows that our methods can handle this task well. Besides, both baseline methods need prior intent number which is unavailable in advance in most cases. Compared with these baseline clustering methods, our method can dynamically determine the intent number and is more practical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Slot Labeling</head><p>Due to the limitation of space, we just show some slot clustering result cases in <ref type="table" target="#tab_3">Table 3</ref>. After man- ually assigning names, we find that auto-dialabel can extract about 70% of the slots with accuracy, including city name, period of day, month name, and day name. The labeled slots above are the main slots for this scenario and could cover a large portion of airline ticket reservation demands. Gen- erally, the slots clustered by auto-dialabel are rea- sonable and constructive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we formalize the auto-labeling task for dialogue data, and propose an unsupervised framework auto-dialabel. We design a set of lin- guistics and neural-network based features, lever- age an autoencoder for feature assembly, and mod- ify a hierarchical clustering method for dialogue intents and slots labeling. Experimental results show that our framework can achieve 84.1% in- tent clustering accuracy, and provide reasonable and instructive slot labeling results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of the dialogue labeling task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>I</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An illustration of our proposed auto-dialabel framework for intent labeling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Value From_loc Chicago To_loc San Francisco Depart_date Wednesday Depart_time 8 am Arrive_time 11 pm Round_trip one way</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>would like a flight from Denver to Los Angeles for April first on delta airlines.</figDesc><table>…… 

…… 

Unlabeled 
Data 
Feature 
Extraction 
Autoencoder 
Feature 
Assembly 
Dynamic 
Clustering 
Clustering 
Results 

On April first I need a flight 
going from Phoenix to San 
Diego. 

feature 1 

feature 2 

feature 3 

input feature 

input feature 

Encoder 

Decoder 

encoded 
feature 1 

encoded 
feature 2 

encoded 
feature 3 

encoded 
feature 

assembled 
feature 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Slot clustering cases 

tests including and excluding each kind of features 
to see the performance. The results are shown in 
</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Natural Language Processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Active learning with statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>David A Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="705" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Frames: a corpus for adding memory to goal-oriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Layla</forename><forename type="middle">El</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannes</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremie</forename><surname>Zumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emery</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="207" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Key-value retrieval networks for task-oriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lakshmi</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Charette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="37" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The atis spoken language systems pilot corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">J</forename><surname>Hemphill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George R</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley</title>
		<meeting><address><addrLine>Pennsylvania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-06-24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An iterative design methodology for user-friendly natural language office information applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kelley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="26" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A latent semantic model with convolutional-pooling structure for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management</title>
		<meeting>the 23rd ACM International Conference on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A neural conversational model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A networkbased end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina M Rojas</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deepak Ramachandran, and Alan Black</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Raux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2013 Conference</title>
		<meeting>the SIGDIAL 2013 Conference</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="404" to="413" />
		</imprint>
	</monogr>
	<note>The dialog state tracking challenge</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A biterm topic model for short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
		<meeting>the 22nd international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1445" to="1456" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
