<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic Poetry Generation with Mutual Reinforcement Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyuan</forename><surname>Yi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">State Key Lab on Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Jiangsu Collaborative Innovation Center for Language Ability</orgName>
								<orgName type="institution">Jiangsu Normal University</orgName>
								<address>
									<addrLine>5 6ESTATES</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">PTE LTD</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoyu</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhao</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">State Key Lab on Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic Poetry Generation with Mutual Reinforcement Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3143" to="3153"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3143</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Poetry is one of the most beautiful forms of human language art. As a crucial step towards computer creativity, automatic poetry generation has drawn researchers&apos; attention for decades. In recent years, some neural models have made remarkable progress in this task. However, they are all based on maximum likelihood estimation, which only learns common patterns of the corpus and results in loss-evaluation mismatch. Human experts evaluate poetry in terms of some specific criteria, instead of word-level likelihood. To handle this problem, we directly model the criteria and use them as explicit rewards to guide gradient update by reinforcement learning, so as to motivate the model to pursue higher scores. Besides, inspired by writing theories, we propose a novel mutual reinforcement learning schema. We simultaneously train two learners (generators) which learn not only from the teacher (rewarder) but also from each other to further improve performance. We experiment on Chinese poetry. Based on a strong basic model, our method achieves better results and outperforms the current state-of-the-art method.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Language is one of the most important forms of human intelligence and poetry is a concise and graceful art of human language. Across different countries, nationalities and cultures, poetry is al- ways popular, having far-reaching influence on the development of human society.</p><p>In this work, we concentrate on automatic po- etry generation. Besides the long-term goal of building artificial intelligence, research on this task could become the auxiliary tool to better anal- yse poetry and understand the internal mechanism of human writing. In addition, these generation systems are also helpful for electronic entertain- ments and literary education.</p><p>In recent years, neural networks have proven to be powerful on poetry generation. Some neu- ral models are proposed and achieve significant improvement. However, existing models are all based on maximum likelihood estimation (MLE), which brings two substantial problems. First, MLE-based models tend to remember common patterns of the poetry corpus ( <ref type="bibr" target="#b29">Zhang et al., 2017)</ref>, such as high-frequency bigrams and stop words, losing some diversity and innovation for generated poetry. Moreover, based on word-level likelihood, two kinds of loss-evaluation mismatch <ref type="bibr" target="#b25">(Wiseman and Rush, 2016)</ref> arise. One is evaluation gran- ularity mismatch. When evaluating, human ex- perts usually focus on sequence level (a poem line) or discourse level (a whole poem), while MLE optimizes word-level loss, which fails to hold a wider view of generated poems. The other is cri- teria mismatch. Instead of the likelihood, humans usually evaluate poetry in terms of some criteria. In this work we focus on the main four criteria <ref type="bibr" target="#b14">(Manurung, 2003;</ref><ref type="bibr" target="#b30">Zhang and Lapata, 2014;</ref><ref type="bibr" target="#b26">Yan, 2016;</ref><ref type="bibr" target="#b28">Yi et al., 2017)</ref>: fluency (are the lines fluent and well-formed?), coherence (is the poem as a whole coherent in meaning and theme?), mean- ingfulness (does the poem convey some certain messages?), overall quality (the reader's general impression on the poem). This mismatch may make the model lean towards optimizing easier criteria, e.g., fluency, and ignore other ones.</p><p>To tackle these problems, we directly model the four aforementioned human evaluation crite- ria and use them as explicit rewards to guide gra- dient update by reinforcement learning. This is a criterion-driven training process, which motivates the model to generate poems with higher scores on these criteria. Besides, in writing theories, writing requires observing other learners <ref type="bibr" target="#b1">(Bandura, 2001)</ref>. It is also shown that writing is supported as an ac- tivity in which writers will learn from more ex- perienced writers, such as other students, teach- ers, or authors <ref type="bibr" target="#b19">(Prior, 2006</ref>). Therefore it is nec- essary to equip generators with the ability of mu- tual learning and communication. Inspired by this, we propose a novel mutual reinforcement learn- ing schema <ref type="figure">(Figure 1</ref>), where we simultaneously train two learners (generators). During the train- ing process, one learner will learn not only from the teacher (rewarder) but also from the other. We will show this mutual learning-teaching process leads to better results.</p><p>In summary, our contributions are as follows:</p><p>• To the best of our knowledge, for the sake of tackling the loss-evaluation mismatch prob- lem in poetry generation, we first utilize re- inforcement learning to model and optimize human evaluation criteria.</p><p>• We propose a novel mutual reinforcement learning schema to further improve perfor- mance, which is transparent to model archi- tectures. One can apply it to any poetry gen- eration model.</p><p>• We experiment on Chinese quatrains. Both automatic and human evaluation results show that our method outperforms a strong basic method and the state-of-the-art model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>As a desirable entry point of automatic analysing, understanding and generating literary text, the re- search on poetry generation has lasted for decades.</p><p>In recent twenty years, the models can be catego- rized into two main paradigms. The first one is based on statistical machine learning methods. Genetic algorithms <ref type="bibr" target="#b14">(Manurung, 2003;</ref><ref type="bibr" target="#b10">Levy, 2001</ref>), Statistical Machine Transla- tion (SMT) approaches <ref type="bibr" target="#b7">(He et al., 2012;</ref><ref type="bibr" target="#b8">Jiang and Zhou, 2008)</ref> and Automatic Summarization ap- proaches ( <ref type="bibr">Yan et al., 2013)</ref> are all adopted to gen- erate poetry.</p><p>More recently, the second paradigm, neural net- work, has shown great advantages in this task, compared to statistical models. Recurrent Neu- ral Network (RNN) is first used to generate Chi- nese quatrains by <ref type="bibr" target="#b30">(Zhang and Lapata, 2014</ref>). To improve fluency and coherence, Zhang's model needs to be interpolated with extra SMT features as shown in their paper. Focusing on coher- ence, some works ( <ref type="bibr" target="#b28">Yi et al., 2017;</ref><ref type="bibr" target="#b22">Wang et al., 2016a</ref>) use sequence-to-sequence model with at- tention mechanism ( <ref type="bibr" target="#b0">Bahdanau et al., 2015)</ref> to gen- erate poetry. <ref type="bibr" target="#b23">Wang et al. (2016b)</ref> design a special Planning schema, which plans some sub-keywords in advance by a language model and then gen- erates each line with the planned sub-keyword to improve coherence. Pursuing better overall quality, <ref type="bibr" target="#b26">Yan (2016)</ref> proposes an iterative polish- ing schema to generate Chinese poetry, which re- fines the poem generated in one pass for sev- eral times. Aiming at enhancing meaningfulness, <ref type="bibr" target="#b4">Ghazvininejad et al. (2016)</ref> extend user keywords to incorporate richer semantic information. <ref type="bibr" target="#b29">Zhang et al. (2017)</ref> combine a neural memory, which saves hundreds of human-authored poems, with a sequence-to-sequence model to improve innova- tion of generated poems and achieve style transfer.</p><p>These neural structures have made some progress and improved different aspects of gener- ated poetry. Nevertheless, as discussed in Section 1, the two essential problems, lack of diversity and loss-evaluation mismatch, are still challenging re- sulting from MLE. Compared to further adjusting model structures, we believe a better solution is to design more reasonable optimization objectives.</p><p>Deep Reinforcement Learning (DRL) first shows its magic power in automatic game playing, such as Atari electronic games ( <ref type="bibr" target="#b17">Mnih et al., 2013)</ref> and the game of Go ( <ref type="bibr" target="#b21">Silver et al., 2016)</ref>. Soon, DRL is used to playing text games <ref type="bibr" target="#b18">(Narasimhan et al., 2015;</ref><ref type="bibr" target="#b6">He et al., 2016</ref>) and then applied to dialogue generation ( .</p><p>From the perspective of poetry education, the teacher will judge student-created poems in terms of some specific criteria and guide the student to cover the shortage, which naturally accords with DRL process. Therefore we take advantage of DRL. We design four automatic rewarders for the criteria, which act as the teacher. Furthermore, we train two generators and make them learn from each other, which imitates the mutual learning of students, as a step towards multi-agent DRL in lit- erary text generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic Generation Model</head><p>We apply our method to a basic poetry genera- tion model, which is pre-trained with MLE. There- fore, we first formalize our task and introduce this model. The inputs are user topics specified by K key-</p><formula xml:id="formula_0">words, W = {w k } K k=1 .</formula><p>The output is a poem con- sisting of n lines, P = L 1 , L 2 , · · · , L n . Since we take the line-by-line generation process, the task can be converted to the generation of an i-th line given previous i-1 lines L 1:i−1 and W.</p><p>We use GRU-based ( <ref type="bibr" target="#b3">Cho et al., 2014</ref>) sequence- to-sequence model. − → h t , ← − h t and s t represent the forward encoder, backward encoder and de- coder hidden states respectively. For each topic word w k = c 1 , c 2 , · · · , c T k , we feed characters into the encoder and get the keyword representa- </p><formula xml:id="formula_1">tion v k = [ − → h T k ; ← − h T k ],</formula><formula xml:id="formula_2">o = f ( 1 K K ∑ t=1 v k ),<label>(1)</label></formula><p>where f defines a non-linear layer.</p><p>Denote the generated i-th line in decoder, Y = (y 1 y 2 . . . y T i ). e(y t ) is the word embedding of y t . The probability distribution of each y t to be gen- erated in L i is calculated by:</p><formula xml:id="formula_3">s t = GRU (s t−1 , [e(y t−1 ); o; g i−1 ]),<label>(2)</label></formula><formula xml:id="formula_4">P (y t |y 1:t−1 , L 1:i−1 , W) = sof tmax(W s t ), (3)</formula><p>where W is the projection parameter. g i−1 is a global history vector, which records what has been generated so far and provides global-level infor- mation for the model. Once L i is generated, it is 1 For brevity, we omit biases in all equations. updated by a convolutional layer:</p><formula xml:id="formula_5">a t = f ([s t ; · · · ; s t+d−1 ]),<label>(4)</label></formula><formula xml:id="formula_6">g i = f (g i−1 , ∑ t a t ), g 0 = 0,<label>(5)</label></formula><p>where 0 is a vector with all 0-s and d is convo- lution window size. Then the basic model is pre- trained by minimizing standard MLE loss:</p><formula xml:id="formula_7">L M LE (θ) = − M ∑ m=1 logP (P m |W m ; θ),<label>(6)</label></formula><p>where M is data size and θ is the parameter set to be trained.</p><p>This basic model is a modified version of <ref type="bibr" target="#b26">(Yan, 2016)</ref>. The main differences are that we replace vanilla RNN with GRU unit, use convolution to calculate the line representation rather than di- rectly use the last decoder hidden state, and we remove the polishing schema to better obverse the influence of DRL itself. We select this model as our basic framework since it achieves satisfac- tory performance and the author has done thor- ough comparisons with other models, such as ( <ref type="bibr">Yan et al., 2013)</ref> and (Zhang and Lapata, 2014).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Single-Learner Reinforcement Learning</head><p>Before presenting the single-learner version of our method (abbreviated as SRL), we first design cor- responding automatic rewarders for the four hu- man evaluation criteria.</p><p>Fluency Rewarder. We use a neural language model to measure fluency. Given a poem line L i , higher probability P lm (L i ) indicates the line is more likely to exist in the corpus and thus may be more fluent and well-formed. However, it's in- advisable to directly use P lm (L i ) as the reward, since over high probability may damage diversity and innovation. We expect moderate probabilities which fall into a reasonable range, neither too high nor too low. Therefore, we define the fluency re- ward of a poem P as:</p><formula xml:id="formula_8">r(L i ) = max(|P lm (L i ) − µ| − δ 1 * σ, 0), (7) R 1 (P) = 1 n n ∑ i=1 exp(−r(L i )),<label>(8)</label></formula><p>where µ and σ are the mean value and standard deviation of P lm calculated over all training sets. δ 1 is a hyper-parameter to control the range.</p><p>Coherence Rewarder. For poetry, good coher- ence means each line L i should be coherent with previous lines in a poem. We use Mutual Infor- mation (MI) to measure the coherence of L i and L 1:i−1 . As shown in ( <ref type="bibr" target="#b11">Li et al., 2016a</ref>), MI of two sentences, S 1 and S 2 , can be calculated by:</p><formula xml:id="formula_9">M I(S 1 , S 2 ) = logP (S 2 |S 1 ) − λlogP (S 2 ), (9)</formula><p>where λ is used to regulate the weight of generic sentences. Based on this, we calculate the coher- ence reward as:</p><formula xml:id="formula_10">M I(L 1:i−1 , L i ) = logP seq2seq (L i |L 1:i−1 ) − λlogP lm (L i ),<label>(10)</label></formula><formula xml:id="formula_11">R 2 (P) = 1 n − 1 n ∑ i=2 M I(L 1:i−1 , L i ),<label>(11)</label></formula><p>where P seq2seq is a GRU-based sequence-to- sequence model, which takes the concatenation of previous i-1 lines as input, and predicts L i . A bet- ter choice is to use a dynamic λ instead of a static one. Here we directly set λ = exp(−r(L i )) + 1, which gives smaller weights to lines with extreme language model probabilities.</p><p>Meaningfulness Rewarder. In dialogue gen- eration task, neural models are prone to generate generic sentences such as "I don't know" ( <ref type="bibr" target="#b11">Li et al., 2016a;</ref><ref type="bibr" target="#b20">Serban et al., 2016</ref>). We observed similar issues in poetry generation. The basic model tends to generate some common and meaningless words, such as bu zhi (don't know), he chu (where), and wu ren (no one). It's quite intractable to quantify the meaningfulness of a whole poem, but we find that TF-IDF values of human-authored poems are significantly higher than values of generated ones <ref type="figure" target="#fig_0">(Figure 2</ref>). Consequently, we utilize TF-IDF to motivate the model to generate more meaningful words. This is a simple and rough attempt, but it makes generated poems more "meaningful" from the readers perspective.</p><p>Direct use of TF-IDF leads to serious out-of- vocabulary (OOV) problem and high variance, be- cause we need to sample poems during the train- ing process of DRL, which causes many OOV words. Therefore we use another neural network to smooth TF-IDF values. In detail, we have:</p><formula xml:id="formula_12">R 3 (P) = 1 n n ∑ i=1 F (L i ),<label>(12)</label></formula><p>where F (L i ) is a neural network which takes a line as input and predicts its estimated TF-IDF value. For each line in training sets, we calculate standard TF-IDF values of all words and use the average as the line TF-IDF value. Then we use them to train F (L i ) with Huber loss.</p><p>Overall Quality Rewarder. The three kinds of rewards above are all based on line-level. In fact, human experts will also focus on discourse- level to judge the overall quality of a poem, ig- noring some minor defects. We train a neural classifier to classify a given poem (in terms of the concatenation of all lines) into three classes: computer-generated poetry (class 1), ordinary human-authored poetry (class 2) and masterpiece (class 3). Then we get the reward by:</p><formula xml:id="formula_13">R 4 (P) = 3 ∑ k=1 P cl (k|P) * k.<label>(13)</label></formula><p>This classifier should be as reliable as possible. Due to the limited amount of masterpieces, normal classifiers don't work well. Therefore we use an adversarial training based classifier ( <ref type="bibr" target="#b16">Miyato et al., 2017)</ref>, which achieves F-1 0.96, 0.73, 0.76 for the three classes respectively on the validation set.</p><p>Based on these rewarders, the total reward is:</p><formula xml:id="formula_14">R(P) = 4 ∑ j=1 α j * ˜ R j (P),<label>(14)</label></formula><p>where α j is the weight and the symbol˜meanssymbol˜symbol˜means the four rewards are re-scaled to the same magni- tude. As ( <ref type="bibr" target="#b5">Gulcehre et al., 2018)</ref>, we reduce the variance by:</p><formula xml:id="formula_15">R ′ (P) = R(P) − b u √ σ 2 u + ϵ − B(P),<label>(15)</label></formula><p>where b u and σ u are running average and stan- dard deviation of R respectively. B(P) is a neu- ral network trained with Huber loss, which takes a poem as input and predicts its estimated reward.</p><p>DRL Process. For brevity, we use P g (·|W; θ) to represent a basic generator and use REIN- FORCE algorithm <ref type="bibr" target="#b24">(Williams, 1992</ref>) to optimize the model, which minimizes:</p><formula xml:id="formula_16">L DRL (θ) = − M ∑ m=1 E P∼Pg(·|W m ;θ) (R ′ (P)).<label>(16)</label></formula><p>Training with solely Eq. <ref type="formula" target="#formula_2">(16)</ref>  Sample P m 1 ∼ P g (·|W m ; θ 1 );</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Sample P m 2 ∼ P g (·|W m ; θ 2 );</p><p>7:</p><p>Add R(P m 1 ) to V 1 , R(P m 2 ) to V 2</p><p>8:</p><p>end for 9:</p><formula xml:id="formula_17">Set L M (θ 1 )=L(θ 1 ), L M (θ 2 )=L(θ 2 ); 10: if mean value V 2 &gt; V 1 * (1 + δ 3 ) then 11: L M (θ 1 )=L(θ 1 ) + KL(P g (θ 2 )||P g (θ 1 ));</formula><p>12:</p><formula xml:id="formula_18">else if V 1 &gt; V 2 * (1 + δ 3 ) then 13: L M (θ 2 )=L(θ 2 ) + KL(P g (θ 1 )||P g (θ 2 )); 14:</formula><p>end if</p><formula xml:id="formula_19">15:</formula><p>Update θ 1 with L M (θ 1 ), θ 2 with L M (θ 2 ); 16: end for model is easy to get lost and totally ignore the cor- responding topics specified by W, leading to ex- plosive increase of MLE loss. We use two steps to alleviate this issue. The first one is the Teacher Forcing ( . For each W, we es- timate E(R ′ (P)) by n s sampled poems, as well as the ground-truth P g whose reward is set to max(R ′ (P g ), 0). The second step is to combine MLE loss and DRL loss as:</p><formula xml:id="formula_20">L(θ) = (1 − β) * L M LE (θ) + β * ˜ L DRL (θ),<label>(17)</label></formula><p>where˜meanswhere˜where˜means the DRL loss is re-scaled to the same magnitude with MLE loss. Ultimately, we use Eq. <ref type="formula" target="#formula_2">(17)</ref> to fine-tune the basic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Mutual Reinforcement Learning</head><p>As discussed in Section 1 &amp; 2, to further im- prove the performance, we mimic the mutual writ- ing learning activity by simultaneously training two generators defined as P g (θ 1 ) and P g (θ 2 ). The two learners (generators) learns not only from the teacher (rewarders) but also from each other.</p><p>From the perspective of machine learning, one generator may not explore the policy space suffi- ciently and thus is easy to get stuck in the local minima. Two generators can explore along differ- ent directions. Once one generator finds a better path (higher reward), it can communicate with the other and lead it towards this path. This process could also be considered as the ensemble of dif- ferent generators during the training phase. We implement the Mutual Reinforcement Learning (abbreviated as MRL) by two methods.</p><note type="other">Models˜R1˜R2˜R3˜R4 Models˜ Models˜R1 Models˜R1˜ Models˜R1˜R2 Models˜R1˜R2˜ Models˜R1˜R2˜R3 Models˜R1˜R2˜R3˜ Models˜R1˜R2˜R3˜R4 R</note><p>Local MRL. The first one is a simple instance- based method. For the same input, suppose P 1 , P 2 are generated by P g (θ 1 ) and P g (θ 2 ) respec- tively. If R(P 1 ) &gt; R(P 2 ) * (1+δ 2 ) and˜Rand˜ and˜R j (P 1 ) &gt; ˜ R j (P 2 ) for all j, then P g (θ 2 ) uses P 1 instead of P 2 to update itself in Eq.(16) and vice versa. That is, if a learner creates a significantly better poem, then the other learner will learn it. This process gives a generator more high-reward instances and allows it to explore larger space along a more proper di- rection so as to escape from the local minima.</p><p>Global MRL. During the training process, we need to sample poems from the generator, and hence local MRL may cause high variance. In- stead of an instance, mutual learning can also be applied on the distribution level. We can pull the distribution of a generator towards that of the other by minimizing KL divergence of them. We de- tail this method in algorithm 1. The inner thought is that if learner 1 is generally better than learner 2, that is, during the creating history, learner 1 achieves higher average rewards, then learner 2 should directly learn from learner 1, rather than learn the poem itself. This process allows the gen- erator to learn from long-period history and focus on a higher level.</p><p>In practice, we combine these two methods by simultaneously communicating high-reward sam- ples and using KL loss, which leads to the best testing rewards <ref type="table">(Table 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data and Setups</head><p>Our corpus consists of three sets: 117,392 Chinese quatrains (CQ), 10,000 Chinese regulated verses (CRV) and 10,000 Chinese iambics (CI). As men-  tioned, we experiment on the generation of qua- train which is the most popular genre of Chinese poetry and accounts for the largest part of our cor- pus. From the three sets, we randomly select 10% for validation. From CQ, we select another 10% for testing. The rest are used for training.</p><p>For our model and baseline models, we run Tex- tRank ( <ref type="bibr" target="#b15">Mihalcea and Tarau, 2004</ref>) on all training sets and then extract four keywords from each qua- train. Then we build four &lt; keyword(s), poem &gt; pairs for each quatrain using 1 to 4 keywords re- spectively, so as to enable the model to cope with different numbers of keywords.</p><p>For the models and rewarders, the sizes of word embedding and hidden state are 256 and 512 re- spectively. History vector size is 512 and convolu- tion window size d = 3. The word embedding is initialized with pre-trained word2vec vectors. We use tanh as the activation function. For other more configurations of the basic model, we directly fol- low <ref type="bibr" target="#b26">(Yan, 2016)</ref>. P lm and P seq2seq are trained with the three sets. We train F (L i ) and B(P) with the CQ, CRV and 120,000 generated poems. There are 9,465 mas- terpieces in CQ. We use these poems, together with 10,000 generated poems and 10,000 ordinary human-authored poems to train the classifier P cl . For training rewarders, half of the generated po- ems are sampled and the other half are generated with beam search (beam size 20). For testing, all models generate poems with beam search.</p><p>We use Adam ( <ref type="bibr" target="#b9">Kingma and Ba, 2015</ref>) with shuffled mini-batches. The batch size is 64 for MLE and 32 for DRL. For DRL, we random se- lect batches to fine-tune the basic model. We set δ 1 = 0.5, δ 2 = 0.1, δ 3 = 0.001, α 1 = 0.25, A key point for MRL is to give the two pre- trained generators some diversity, which can be achieved by using different model structures or pa- rameters. Here we simply initialize the generators differently and train one of them for more epoches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Models for Comparisons</head><p>We compare MRL 2 (our model, with both local and global mutual learning), GT (ground-truth, namely human-authored poems), Base (the basic model described in Section 3.1) and Mem ( <ref type="bibr" target="#b29">Zhang et al., 2017</ref>). The Mem model is the current state- of-the-art model for Chinese quatrain generation, which also achieves the best innovation so far.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Automatic Evaluation</head><p>Some previous models <ref type="bibr" target="#b7">(He et al., 2012;</ref><ref type="bibr" target="#b30">Zhang and Lapata, 2014;</ref><ref type="bibr" target="#b26">Yan, 2016</ref>) adopt BLEU and per- plexity as automatic evaluation metrics. Neverthe- less, as discussed in Section 1, word-level likeli- hood or n-gram matching will greatly diverge from human evaluation manner. Therefore we dispense with them and automatically evaluate generated poems as follows:</p><p>Rewarder Scores. The four rewarder scores are objective and model-irrelevant metrics which approximate corresponding human criteria. They  <ref type="table">Table 3</ref>: Human evaluation results. Diacritic ** (p &lt; 0.01) indicates MRL significantly outperforms baselines; ++ (p &lt; 0.01) indicates GT is significantly better than all models. can reflect poetry quality to some extent. As shown in <ref type="table">Table 1</ref>, on each criterion, GT gets much higher rewards than all these models. Compared to Base, MRL gets closer to GT and achieves 31% improvement on the weighted average re- ward. Mem outperforms Base on the criteria ex- cept for meaningfulness <ref type="bibr">( ˜ R 3</ref> ). This is mainly be- cause Mem generates more distinct words <ref type="table" target="#tab_4">(Table  2)</ref>, but these words tend to concentrate on the high- frequency area, resulting in unsatisfactory TF-IDF reward. We also test different strategies of MRL. With naive single-learner RL, the improvement is limited, only 14%. With mutual RL, the improve- ment increases to 27%. Combining local MRL and global MRL leads to another 4% improve- ment. The results demonstrate our explicit opti- mization (RL) is more effective than the implicit ones and MRL gets higher scores than SRL.</p><p>Diversity and Innovation. Poetry is a kind of literature text with high requirements on diversity and innovation. Users don't expect the machine to always generate monotonous poems. We eval- uate innovation of generated poems by distinct bi- gram ratio as ( ). More novel gener- ated bigrams can somewhat reflect higher innova- tion. The diversity is measured by bigram-based average Jaccard similarity of each two generated poems. Intuitively, a basic requirement for inno- vation is that, with different inputs, the generated poems should be different from each other.</p><p>As shown in <ref type="table" target="#tab_4">Table 2</ref>, Mem gets the highest bi- gram ratio, close to GT, benefiting from its spe- cially designed structure for innovation. Our MRL achieves 43% improvement over Base, compara- ble to Mem. We will show later this satisfactory performance may lie in the incorporation of TF- IDF ( <ref type="figure" target="#fig_0">Figure 2</ref>). On Jaccard, MRL gets the best re- sult due to the utilization of MI. MI brings richer context-related information which can enhance di- versity as shown in ( <ref type="bibr" target="#b11">Li et al., 2016a</ref>). In fact, human-authored poems often contain strong diver- sity of personal emotion and experience. There- fore, despite prominent improvement, there is still a large gap between MRL and GT.</p><p>TF-IDF Distribution. As mentioned, the basic model tends to generate common and meaningless words. Consequently, we use TF-IDF as one of the rewards. <ref type="figure" target="#fig_0">Figure 2</ref> shows the TF-IDF distributions. As we can see, Base generates poems with lower TF-IDF compared to GT, while MRL pulls the dis- tribution towards that of GT, making the model generate more meaningful words and hence ben- efiting innovation and diversity.</p><p>Topic Distribution. We run LDA ( <ref type="bibr" target="#b2">Blei et al., 2003</ref>) with 20 topics on the whole corpus and then inference the topic of each generated poem. <ref type="figure" target="#fig_1">Figure  3</ref> gives the topic distributions. Poems generated by Base center in a few topics, which again demon- strates the claim: MLE-based models tend to re- member the common patterns. In contrast, human- authored poems spread on more topics. After fine- tuning by our MRL method, the topic distribution shows better diversity and balance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Human Evaluation</head><p>From the testing set, we randomly select 80 sets of keywords to generate poems with these mod- els. For GT, we select poems containing the given words. Therefore, we obtain 320 quatrains (80*4). We invite 12 experts on Chinese poetry to evaluate these poems in terms of the four criteria: fluency, coherence, meaningfulness and overall quality and each needs to be scored in a 5-point scale ranging from 1 to 5. Since it's tiring to evaluate all poems for one person, we randomly divide the 12 experts into three groups. Each group evaluates the ran- domly shuffled 320 poems (80 for each expert). Then for each model, each poem, we get 3 scores on each criterion and we use the average to allevi- ate individual preference. <ref type="table">Table 3</ref> gives human evaluation results. MRL achieves better results than the other two models. Since fluency is quite easy to be optimized, our method gets close to human-authored poems on Fluency. The biggest gap between MRL and GT lies on Meaning. It's a complex criterion involv- ing the use of words, topic, emotion expression and so on. The utilization of TF-IDF does amelio- rate the use of words on diversity and innovation, hence improving Meaningfulness to some extent, but there are still lots to do.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Further Analyses and Discussions</head><p>In this section we give more discussions.</p><p>Learning Curve. We show the learning curves of SRL and MRL in <ref type="figure" target="#fig_2">Figure 4</ref>. As we can see, for SRL, the adequately pre-trained generator 2 al- ways gets higher rewards than the other one dur- ing the DRL training process. With the increase of training steps, the gap between their rewards gets larger. After several hundred steps, rewards of the two generators converge.</p><p>For MRL, generator 2 gets higher rewards at the beginning, but it is exceeded by generator 1 since generator 1 learns from it and keeps chas- ing. Finally, the two generators converge to higher rewards compared to SRL.</p><p>Case Study. We show some generated poems in <ref type="figure" target="#fig_3">Figure 5</ref>. The Base model generates two words, 'sunset' and 'moon' in poem (1), which appear to- gether and thus cause the conflict of time. The word 'fishing jetty' is confusing without any nec- essary explanation in the context. In contrast, poem (2) describes a clearer scene and expresses some emotion: a lonely man takes a boat from morning till night and then falls asleep solitarily.</p><p>In poem (3), Mem generates some meaningful words, such as 'phoenix tree', 'wild goose' and 'friend'. However, there isn't any clue to link them together, resulting in poor coherence. On the con- trary, things in poem (4) are tightly connected. For example, 'moonlight' is related to 'night'; 'rain', 'frost' and 'dew' are connected with 'cold'. Poem (5) expresses almost nothing. The first two lines seem to talk about the change of time. But the last two lines are almost unrelated to 'time change'. Poem (6) talks about an old poet, with the description of cheap wine, poem and dream, ex- pressing something about life and time. However, the human-authored poem (7) does much better. It seems to describe a mosquito, but in fact, it's a metaphor of the author himself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this work, we address two substantial problems in automatic poetry generation: lack of diversity, and loss-evaluation mismatch, which are caused by MLE-based neural models. To this end, we di- rectly model the four widely used human evalu- ation criteria and design corresponding automatic rewarders. We use these explicit rewards to guide gradient update by reinforcement learning. Fur- thermore, inspired by writing theories, we pro- pose a novel mutual learning schema to further improve the performance. Mimicking the poetry learning activity, we simultaneously train two gen- erators, which will not only be taught by the re- warders but also learn from each other. Experi- mental results show our method achieves signifi- cant improvement both on automatic rewards and human evaluation scores, outperforming the cur- rent state-of-the-art model <ref type="bibr">3</ref> .</p><p>There are still lots to do. Can we better model the meaningfulness of a whole poem? Can we quantify some other intractable criteria, e.g, poet- icness? Besides, we only tried two learners in this work. Would the collaboration of more learners lead to better results? How to design the methods of communication among many generators? We will explore these questions in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: TF-IDF distributions of poems generated by different models. We show real TF-IDF, instead of the estimated˜Restimated˜ estimated˜R 3 .</figDesc><graphic url="image-2.png" coords="6,307.97,62.81,216.89,180.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Topic Distributions of different models.</figDesc><graphic url="image-3.png" coords="7,85.40,187.13,188.75,188.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The learning curves of SRL and MRL. Learner (generator) 2 is pre-trained for more epoches to allow some diversity.</figDesc><graphic url="image-4.png" coords="8,72.79,62.81,216.69,203.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Sampled poems generated by different models. Poems between two solid lines are generated with the same input keywords. Some defects are shown in red boxes.</figDesc><graphic url="image-5.png" coords="9,72.64,62.80,449.55,253.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Set history reward lists V 1 and V 2 empty; 2: for number of iterations do 3:</head><label></label><figDesc></figDesc><table>is unstable. Lack-
ing of original MLE supervisory signals, the Algorithm 1 Global Mutual Learning 
1: Sample batch (W m , P m 
g ) from training 
data set; 

4: 

for each W m do 

5: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Automatic evaluation results of diversity and 
innovation. The Jaccard values are multiplied by 10 for 
clearer observation. We expect higher bigram ratio and 
smaller Jaccard values. 

</table></figure>

			<note place="foot" n="2"> Due to length limit, we only display the better of the two simultaneously trained generators. Our source code will be available at https://github.com/XiaoyuanYi/MRLPoetry.</note>

			<note place="foot" n="3"> Our method will be incorporated into Jiuge, the THUNLP online poetry generation system, https:// jiuge.thunlp.cn.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Cheng Yang, Jiannan Liang, Zhipeng Guo, Huimin Chen and anony-mous reviewers for their insightful comments. This research is funded by the National 973 project (No. 2014CB340501). It is also partially supported by the NExT++ project, the National Research Foundation, Prime Ministers Office, Sin-gapore under its IRC@Singapore Funding Initia-tive.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Conference on Learning Representations</title>
		<meeting>the 2015 International Conference on Learning Representations<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Social cognitive theory: An agentic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Bandura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating topical poetry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1183" to="1191" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dynamic neural turing machine with continuous and discrete addressing schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="857" to="884" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning with a natural language action space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1621" to="1630" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generating chinese classical poems with statistical machine translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 26th AAAI Conference on Artificial Intelligence<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1650" to="1656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generating chinese couplets using a statistical mt approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Conference on Learning Representations</title>
		<meeting>the 2015 International Conference on Learning Representations<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A computational model of poetic creativity with neural network as measure of adaptive fitness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICCBR-01 Workshop on Creative Systems</title>
		<meeting>the ICCBR-01 Workshop on Creative Systems</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1192" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adversarial learning for neural dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2157" to="2169" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">An Evolutionary Algorithm Approach to Poetry Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manurung</forename><surname>Hisar Maruli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Textrank: Bringing order into texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
	<note>Proceedings of EMNLP 2004</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adversarial training methods for semisupervised text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 International Conference on Learning Representations</title>
		<meeting>the 2017 International Conference on Learning Representations<address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Playing atari with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Language understanding for textbased games using deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tejas</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Handbook of Writing Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Prior</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>chapter A Sociocultural Theory of Writing. Guilford Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian V Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aja</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veda</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lanctot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Chinese song iambics generation with neural attention-based model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2943" to="2949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Chinese poetry generation with planning based neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu Nad Haiyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics:Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics:Technical Papers<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1051" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sequence-to-sequence learning as beam-search optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1296" to="1306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">I, poet:automatic poetry composition through recurrent neural networks with iterative polishing schema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2238" to="2244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">2013. I, poet:automatic chinese poetry composition through a generative summarization framework under constrained optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqiang</forename><surname>Shou-De Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Joint Conference on Artificial Intelligence</title>
		<meeting>the 23rd International Joint Conference on Artificial Intelligence<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="2197" to="2203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Generating chinese classical poems with rnn encoderdecoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth Chinese Computational Linguistics</title>
		<meeting>the Sixteenth Chinese Computational Linguistics<address><addrLine>Nanjing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="211" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Flexible and creative chinese poetry generation using neural memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Abel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1364" to="1373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Chinese poetry generation with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="670" to="680" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
