<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recovering Missing Characters in Old Hawaiian Writing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Shillingford</surname></persName>
							<email>brendan.shillingford@cs.ox.ac.uk, oiwi.parkerjones@wolfson.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Oxford 1</orgName>
								<address>
									<country>DeepMind</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oiwi</forename><forename type="middle">Parker</forename><surname>Jones</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Oxford 1</orgName>
								<address>
									<country>DeepMind</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Recovering Missing Characters in Old Hawaiian Writing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="4929" to="4934"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>4929</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In contrast to the older writing system of the 19th century, modern Hawaiian orthography employs characters for long vowels and glottal stops. These extra characters account for about one-third of the phonemes in Hawaiian, so including them makes a big difference to reading comprehension and pronunciation. However , transliterating between older and newer texts is a laborious task when performed manually. We introduce two related methods to help solve this transliteration problem automatically. One approach is implemented, end-to-end, using finite state transducers (FSTs). The other is a hybrid deep learning approach, which approximately composes an FST with a recurrent neural network language model.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>From 1834 to 1948, more than 125,000 newspa- per pages were published in the Hawaiian lan- guage <ref type="bibr" target="#b14">(Nogelmeier, 2010</ref>). Yet by 1981, many expected this once flourishing language to die <ref type="bibr" target="#b0">(Benton, 1981)</ref>. Hawaiian has since defied ex- pectations and experienced the beginnings of a remarkable recovery <ref type="bibr" target="#b25">(Warner, 2001;</ref><ref type="bibr" target="#b27">Wilson and Kaman¯ a, 2001</ref>). However much of the literary in- heritance that is contained in the newspapers has become difficult for modern Hawaiians to read, since the newspapers were written in an orthogra- phy that failed to represent about one-third of the language's phonemes. This orthography, which we will refer to as the missionary orthography, ex- cluded Hawaiian phonemes that did not have equiv- alents in American English (see <ref type="bibr" target="#b22">Schütz, 1994)</ref>, in- cluding Hawaiian's long vowels /i: e: a: o: u:/ and glottal stop /P/. By contrast, the modern Hawaiian orthography, an innovation of Pukui and Elbert's Hawaiian dictionary <ref type="bibr" target="#b18">(Pukui and Elbert, 1957)</ref>, presents a nearly perfect, one-to-one * Authors contributed equally. mapping between graphemes and phonemes (see Appendix A.1). The process of manual translit- eration from missionary to modern Hawaiian or- thography is extremely labor intensive. Yet the cultural benefits are so great that hundreds of pages of newspaper-serials have already been transliter- ated by hand, such as Nogelmeier's new edition of the epic tale of Hi'iakaikapoliopele, the volcano goddess's sister <ref type="bibr" target="#b6">(Ho'oulum¯ ahiehie, 2007)</ref>. Criti- cally important as such efforts are to the continued revitalization of this endangered language, they are still only an introduction to the material that could be translated for a modern Hawaiian audience.</p><p>In this paper, we propose to automate, or semi- automate, the transliteration of old Hawaiian texts into the modern orthography. Following a brief review of related work (Section 2), we begin by de- scribing a dataset of modern Hawaiian (Section 3). In Section 4, we present two methods for recover- ing missing graphemes (and hence phonemes) from the missionary orthography. The first composes a series of weighted FSTs; the second approximately composes a FST with a recurrent neural network language model (RNNLM) using a beam search procedure. Both approaches require only modern Hawaiian texts for training, which are much more plentiful than parallel corpora. Section 5 reports the results of our transliteration experiments us- ing a simulated parallel corpus, as well as two 19th century newspaper articles for which we also have modern Hawaiian transcriptions. Being based on FSTs, both approaches are modular and exten- sible. We observe useful and promising results for both of our methods, with the best results ob- tained by the hybrid FST-RNNLM. These results showcase the strength of combining established hand-engineering methods with deep learning in a smaller data regime, with practical applications for an endangered language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Many of the themes that we address relate to ex- isting literature. For example, <ref type="bibr" target="#b4">Hajič et al. (2000)</ref> and <ref type="bibr" target="#b21">Scannell (2014)</ref> have written on machine trans- lation (MT) for closely related languages and on multilingual text normalization. Though language- relatedness makes MT easier <ref type="bibr" target="#b11">(Kolovratník et al., 2010)</ref>, state-of-the-art techniques such as neural machine translation (NMT) have not performed well for languages with little data <ref type="bibr" target="#b15">( ¨ Ostling and Tiedemann, 2017)</ref>. So while the Hawaiian translit- eration problem could be cast as an instance of MT or of NMT, we chose to sidestep the scarcity of parallel data by not considering such approaches.</p><p>Hybrid approaches that combine expert knowl- edge for well-understood structures with deep learning for data-plentiful subproblems offer rich opportunities for data-efficient modelling. Prior work has combined FSTs with RNNs, although not using the approximate FST-to-RNN composition algorithm that we introduce here (in <ref type="bibr">Appendix A.4)</ref>. For example, <ref type="bibr" target="#b23">Sproat and Jaitly (2016)</ref> used an FST to restrict the search space when decoding from an <ref type="bibr">RNN and Rastogi et al. (2016)</ref> incorporated RNN information into an FST.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Missionary &amp; modern orthography</head><p>The primary difference between the missionary and modern Hawaiian orthographies is that the mission- ary orthography does not encode long vowels or the glottal stop (see Appendix A.1). For example, the following Hawaiian phrases were recorded by a 19th-century German traveller in the missionary orthography: Ua oia au, E ue ae oe ia Ii, E ao ae oe ia ia (Chamisso, 1837, p. 7). In the mod- ern orthography these become: Ua '¯ o 'ia au 'I am speared', E u¯ e a'e 'oe i¯ a ' ¯ I'¯ ı 'You must weep for ' ¯ I'¯ ı (a person)', and E a'o a'e 'oe i¯ a ia 'You teach him' <ref type="bibr">(Elbert and Pukui, 1979, p. 3)</ref>.</p><p>We can convert text in the modern Hawaiian or- thography backward chronologically to an approx- imate missionary orthography by mapping each glottal stop ' to the empty string ε, and each long vowel, e.g. ¯ a ¯ e ¯ ı ¯ o ¯ u, to its corresponding short vowel, a e i o u. As a first approximation, we may treat mappings from the modern-to-missionary or- thographies as unambiguously many-to-one; thus there is information loss. We will return to sec- ondary differences between the orthographies in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head><p>Chars Words</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ulukau(160 texts) 6,518,451 1,334,451 Hi'iakaikapoliopele 1,272,935 259,947 Wikipedia 577,794 10,221</head><p>Total 8,369,180 1,604,619</p><p>Figure 1: Modern data sources and their sizes.</p><p>Section 6. To illustrate, the following four words in the modern orthography all map to the same missionary string aa: a'a (root), 'a'a (brave), 'a'¯ a (crumbly lava rock), and '¯ a'¯ a (stutter). The forward mapping from missionary-to- modern orthographies is one-to-many. Thus the missionary string aa could map to a'a, 'a'a, 'a'¯ a, or '¯ a'¯ a. The transliteration problem we address here seeks to discover how we can use context to recover the information not present in the mission- ary orthography that modern Hawaiian orthography retains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data sources</head><p>We draw on three sources for modern Hawai- ian text: the main text of Hi'iakaikapoliopele (Ho'oulum¯ ahiehie, 2007), 160 short texts from Ulukau: The Hawaiian Electronic Library, and the full Hawaiian Wikipedia (see <ref type="figure">Figure 1</ref>). <ref type="bibr">1</ref> For evaluation, we simulate a missionary-era ver- sion of the modern texts using the backward map- ping described above. In addition, we evaluated our models on a couple of 19th century newspaper samples for which we have parallel missionary-era and modern text. Both simulated and real parallel corpora will be described in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Finite state transducers</head><p>Our initial approach represents the mapping from missionary to modern orthography using a compo- sition of (weighted) FSTs. For a thorough review of FSTs, see <ref type="bibr" target="#b13">Mohri (1997)</ref>.</p><p>First, we construct a finite state acceptor, I, from the input text. Here we construct a trivial chain- shaped acceptor that accepts only the input text. Each symbol in the input text is represented by a state which emits this symbol on a single transition that moves to the next state. The transition emit- ting the final symbol in the string leads to the sole accepting state.</p><p>Second, we construct a missionary-to-modern or- thography conversion FST which we call C, which models potential orthography changes that can oc- cur when transliterating from the missionary to modern Hawaiian orthography. For example, two non-deterministic transitions introduce an optional long-vowel map (a : ¯ a) and (a : a). Another transi- tion inserts glottal stops: ( : '). By capturing the orthographic changes we know to occur, the com- position I • C produces a large set of candidates to be narrowed using the language model. Third, we use the modern Hawaiian text from Section 3.2 to construct and evaluate a number of character-level n-gram language models, of vari- ous combinations of order and Katz backoff and Kneser-Ney (KN) smoothing <ref type="bibr" target="#b9">(Katz, 1987;</ref><ref type="bibr" target="#b10">Kneser and Ney, 1995)</ref>; see Appendix A.5 for details. N-gram language models can be expressed as weighted FSTs. We denote the n-gram or weighted FST language model as G. Character-level mod- els are used as we wanted to generalize to out- of-vocabulary words, which we expected to occur frequently in a small corpus like the one we have for Hawaiian.</p><p>Finally, we use this model to infer modern or- thography given a piece of text in missionary or- thography as input, then compose the FSTs to form the search graph FST: S = I•C•G. The minimum cost path through S gives the predicted modern or- thography. Of these n-gram-based approached, we found the Kneser-Ney-based models to perform best; these approaches are called FST-C-NGRAM- KN and FST-C wb -NGRAM-KN.</p><p>We circumvent the lack of a large, non-simulated parallel corpus by training the language model ex- clusively on text in the modern Hawaiian orthogra- phy. In turn, the orthographic transliteration FST C produces candidates which are disambiguated by the language model. The result is finally evaluated against the ground-truth modern text.</p><p>Although the orthographic transliteration model is an approximation, and thus not exhaustive, it embodies an explicit and interpretable represen- tation that can be easily extended independently of the rest of the model. To illustrate how the ap- proach can be extended, we constructed a variant C wb (where wb stands for word boundary). C wb op- tionally inserts a space after each vowel using an ad- ditional arc that maps ( : space), as diagrammed in Appendix A.2. This variant is able to model some changes in Hawaiian's word-boundary con- ventions <ref type="bibr" target="#b26">(Wilson, 1976)</ref>, such as alaila becoming a laila which demarcates the preposition a 'until' and noun laila 'then'. We employ this variant to predict modern equivalents from 19th century newspaper samples in Section 5. Pseudocode summarizing this method is shown in Appendix A.3. Example predictions can be found in Appendix A.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">FSTs with LSTM language models</head><p>As an alternative approach, we combined the FST C in the previous section with an RNNLM ( <ref type="bibr" target="#b12">Mikolov et al., 2010)</ref>. RNNLMs often generalize better than n-gram models.</p><p>An RNN is a neural network that models tem- poral or sequential data, by iterating a function mapping a state and input to a new state and out- put. These can be stacked to form a deep RNN. For language modelling, each step of the final RNN layer models a word or character sequence via p(w 1 , . . . ,w n ) = n i=1 p(w i |w 1:i−1 ) and can be trained by maximum likelihood. Recent lan- guage modeling work has typically used the long short-term memory (LSTM) unit (Hochreiter and Schmidhuber, 1997) for its favorable gradient prop- agation properties. All RNNs in this paper are LSTMs.</p><p>Our goal is to replace the n-gram language model in the end-to-end FST approach with an RNNLM. While the minimum cost path through an FST can be computed exactly as done in the previous sec- tion, it is not straightforward to compose the re- lation defined by an FST with an arbitrary one like that defined by an RNNLM. A minimum cost path through the composition of the FST and the RNNLM can be defined as a path (i.e. label se- quence) that minimizes the sum of the FST path cost and the RNNLM cost.</p><p>We can approximately find a minimum cost path of the composition of the two models by a breadth- first search over the FST graph, or using a beam search, as follows. At any particular iteration, con- sider a single beam element. The beam element holds the current FST and RNN states, and the path taken through the FST so far. We follow each possi- ble arc from the current FST state, each producing a new child beam element, and feed the output symbol into the RNN (unless it is ). There may be duplicate beam elements due the nondeterminicity of the FST; in this case, the lower cost edge wins. We sort by the sum of the FST and RNN costs, keep the lowest-cost K, and then proceed to the next iteration. If a beam element is on an accepting state of the FST, it is kept as-is between iterations. Detailed pseudocode is provided in <ref type="bibr">Appendix A.4.</ref> In the following we will refer to the hybrid mod- els as FST-RNNLM-or as FST-RNNLM-C and FST-RNNLM-C wb if we want to distinguish be- tween which FST we used. Similarly, the FST- only models will be referred to as FST-C and FST- C wb , with suffixes denoting what kind of n-gram and smoothing were used. For example, FST-C- 7GRAM-KN denotes a FST-only model with an 7-gram language model and Kneser-Ney smooth- ing. Details of the language models trained can be found in Appendix A.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Evaluation. Since we were unable to find a suf- ficiently large corpus of parallel texts in the mis- sionary and modern Hawaiian orthographies, we instead used a corpus of modern Hawaiian texts (ground-truth) as summarized in Section 3.2 and <ref type="figure">Figure 1</ref>. Note that training the n-gram and RNN language models required only this modern corpus.</p><p>To evaluate the accuracy of our approaches, we derived a synthetic parallel corpus from these mod- ern Hawaiian texts. We also used a small but real parallel corpus, based on two 19th century newspa- per texts and their hand-edited modern equivalents.</p><p>Simulated parallel corpus. To produce a simu- lated parallel corpus (input-missionary), we sys- tematically reduced the orthography in the mod- ern texts using the backward mapping described in Section 3.1. We then applied the two approaches described in Section 4, with the aim of recovering the information lost.</p><p>We evaluated the predicted modern text (predic- tions) by computing</p><formula xml:id="formula_0">CERR = d(prediction, ground-truth) d(input-missionary, ground-truth) ,</formula><p>where d denotes character-level edit distance. This is a modification of character error rate, normalized by the distance of the input and target rather than by the length of the target. We note that CERR may be high even when the predictions are very accu- rate as d(input-missionary, ground-truth) is small when the text is similar in both orthographies. <ref type="table">Table 1</ref> reports the results of the approaches we described in Section 4. Out of the Kneser-Ney n-gram models, we found that the FST-C-9GRAM- KN and the version modelling word boundaries (FST-C wb -9GRAM-KN) to perform best on the synthetic parallel corpus and newspapers, respec- tively. C wb was not applied to the synthetic parallel corpus as we did not model word splitting. The hybrid models (FST-RNNLM) outperformed all FST-only approaches.</p><p>Real parallel corpus (newspaper texts). Not content to evaluate the model on simulated mis- sionary orthography, we also evaluated it on two newspaper texts, using selections originally pub- lished in 1867 and 1894 for which we had 19th century and manually-edited modern equivalents. The newspaper selections discuss Kahahana, one of the last kings of O'ahu ( <ref type="bibr" target="#b8">Kamakau and Perreira, 2002)</ref>, and Uluhaimalama, a garden party and se- cret political gathering, held after the deposition of Hawai'i's last queen ( <ref type="bibr" target="#b19">Pukui et al., 2006</ref>). Unlike the synthetic missionary corpus evaluation where we did not model word splitting, we found that replacing C with C wb on the newspaper texts sig- nificantly improved the output, especially on the FST-RNNLM model. Thus, we found the word- splitting hybrid model (FST-RNNLM-C wb ) to be the best performing model overall <ref type="table">(Table 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and future work</head><p>With this paper we introduced a new translitera- tion problem to the field, that of mapping between old and new Hawaiian orthographies-where the modern Hawaiian orthography represents linguistic information that is missing from older missionary- era texts. One difficulty of this problem is that there is a limited amount of Hawaiian data, making data-hungry solutions like end-to-end deep learning   unlikely to work. To solve the transliteration prob- lem, we therefore proposed two models: the first was implemented end-to-end using weighted FSTs; the second was a hybrid deep learning approach that combined an FST and an RNNLM. Both mod- els gave promising results, but the hybrid approach, which allowed us to use a more powerful recurrent neural network-based language model despite our dataset's small size, performed best. Factoring a problem like ours into one part that can be mod- elled exactly using expert domain knowledge and into another part that can be learned directly from data using deep learning is not novel; however it is a promising research direction for data-efficient modelling. To our knowledge, this paper is the first to describe a procedure to compose an FST with an RNN by approximately performing beam search over the FST.</p><p>While the role of the RNNLM part of the hy- brid approach may be obvious, the FST compo- nent plays an important role too. For example, the hand-designed FST component can be replaced without needing to retrain the RNNLM. We tried to showcase this modularity by constructing two FSTs which we referred to as C and C wb , where only the latter allowed the insertion of spaces. Fu- ture work could extend the FST to model ortho- graphic changes suggested by an error analysis of the current model's predictions (see Appendix A.6). These errors motivate new mappings for consonant substitutions like (r : l) and (s : k) observed in loanword adaptations (e.g. rose ⇒ loke). The error analysis also motivates mappings to delete spaces ( : ) and to handle contractions, like na'lii ⇒ n¯ a ali'i. We could further incorporate linguistic knowl- edge of Hawaiian into the FST, which tells us, for example, that a consonant is typically followed by a vowel <ref type="bibr" target="#b16">(Parker Jones, 2010)</ref>. Additional improve- ments to the hybrid model might be obtained by in- creasing the amount of modern Hawaiian text used to train the RNNLM. One way to do this would be to accelerate the rate at which missionary-era Hawaiian texts are modernized. To this end, we hope that the present models will be used within the Hawaiian community to semi-automate, and thereby accelerate, the modernization of old Hawai- ian texts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>LM</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of (missionary input, predicted modern text, ground-truth), from each newspaper. Note the correctly split word in the second example. Incorrect characters, which are quite rare, are shown as red and underlined. More sample predictions can be found in Appendix A.6.</figDesc></figure>

			<note place="foot" n="4"> Models We can frame the task of transliterating from missionary-to-modern Hawaiian orthographies as a sequence transduction problem. Many deep learning approaches (e.g. Sutskever et al., 2014; Graves, 2012) are not easily applicable to this task since we do not have a sufficiently large dataset of parallel texts. Instead, we focus on approaches that mix hand-designed finite state transducers with trained language models, including deep learning approaches like RNNLMs (Mikolov et al., 2010). 1 Ulukau: The Hawaiian Electronic Library: http: //ulukau.org/, Hawaiian Wikipedia: https://haw. wikipedia.org/. Both accessed 19 May 2018.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to M. Puakea Nogelmeier for pro-viding an electronic copy of Hi'iakaikapoliopele (Ho'oulum¯ ahiehie, 2007).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The flight of the Amokura: Oceanic languages and formal education in the South Pacific</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Richard A Benton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
			<pubPlace>Wellington</pubPlace>
		</imprint>
		<respStmt>
			<orgName>New Zealand Council for Educational Research</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<title level="m">Adelbert von Chamisso. 1837. ¨ Uber die Hawaiische Sprache, Vorgelegt der Königlichen Academie der Wissenschaften zu Berlin am 12, Januar, 1837. Weidmann</title>
		<meeting><address><addrLine>Leipzig</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Kawena</forename><surname>Elbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pukui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Hawaiian Grammar. University of Hawai&apos;i Press</publisher>
			<pubPlace>Honolulu</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1211.3711</idno>
		<title level="m">Sequence transduction with recurrent neural networks</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Machine translation of very close languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladislav</forename><surname>Kuboň</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ANLC &apos;00 Proceedings of the sixth conference on Applied natural language processing</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hi&amp;apos;iakaikapoliopele</surname></persName>
		</author>
		<editor>M. Puakea Nogelmeier</editor>
		<imprint>
			<publisher>Awaiaulu Press</publisher>
			<pubPlace>Honolulu</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Ka mo&apos;olelo o Kahahana, m¯ ahele 1. Ka Ho&apos;oilina</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaiakalani</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiapo</forename><surname>Kamakau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Perreira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="102" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Estimation of probabilities from sparse data for the language model component of a speech recognizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slava</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on acoustics, speech, and signal processing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="401" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improved backing-off for m-gram language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Kneser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="181" to="184" />
		</imprint>
	</monogr>
	<note>International Conference on</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Statistical machine translation between related and unrelated languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kolovratník</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Klyueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Theory and Practice of Information Technologies (ITAT-09)</title>
		<meeting>the Conference on Theory and Practice of Information Technologies (ITAT-09)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="31" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukás</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaňjaň</forename><surname>Cernock´ycernock´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1045" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Finite-state transducers in language and speech processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="269" to="311" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Mai Pa&apos;a i ka Leo: Historical Voice in Hawaiian Primary Materials: Looking Forward and Listening Back</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Puakea</forename><surname>Nogelmeier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Bishop Museum Press</publisher>
			<pubPlace>Honolulu</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural machine translation for low-resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert¨ostlingrobert¨</forename><surname>Robert¨ostling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.05729</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A computational phonology and morphology of Hawaiian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parker</forename><surname>Oiwi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>University of Oxford</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Illustrations of the IPA: Hawaiian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parker</forename><surname>Oiwi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the International Phonetic Association</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="103" to="115" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Kawena</forename><surname>Pukui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">H</forename><surname>Elbert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1957" />
			<pubPlace>Honolulu</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Hawaiian-English Dictionary. University of Hawai&apos;i Press</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">No ka mahi&apos;ai &apos;ana, m¯ ahele 6. Ka Ho&apos;oilina</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Kawena Pukui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holo</forename><surname>Ho&amp;apos;opai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oiwi</forename><forename type="middle">Parker</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keao</forename><surname>Nesmith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Weighted finite-state transductions with neural context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpendre</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="623" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Statistical models for text normalization and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Scannell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Celtic Language Technology Workshop</title>
		<meeting>the First Celtic Language Technology Workshop</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The Voices of Eden: A history of Hawaiian language studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><forename type="middle">J</forename><surname>Schütz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<pubPlace>Honolulu</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Hawai&apos;i Press</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Sproat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.00068</idno>
		<title level="m">RNN approaches to text normalization: A challenge. Computing Research Repository</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The movement to revitalize Hawaiian language and culture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Warner</forename><surname>No&amp;apos;eau</surname></persName>
		</author>
		<editor>Leanne Hinton and Kenneth Hale</editor>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Academic Press</publisher>
			<biblScope unit="page">144</biblScope>
			<pubPlace>San Diego, CA</pubPlace>
		</imprint>
	</monogr>
	<note>The Green Book of Language Revitalization in Practice</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Standardized Hawaiian orthography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976" />
		</imprint>
		<respStmt>
			<orgName>University of Hawai&apos;i</orgName>
		</respStmt>
	</monogr>
	<note>Manuscript</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Mai loko mai o ka &apos;i&apos;ini: Proceeding from a dream&quot;: The &apos;Aha P¯ unana Leo connection in Hawaiian language revitalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kauanoe</forename><surname>Wilson</surname></persName>
		</author>
		<editor>Leanne Hinton and Kenneth Hale</editor>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Academic Press</publisher>
			<biblScope unit="page" from="147" to="176" />
			<pubPlace>San Diego, CA</pubPlace>
		</imprint>
	</monogr>
	<note>The Green Book of Language Revitalization in Practice</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
