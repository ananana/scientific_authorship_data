<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Put It Back: Entity Typing with Language Model Enhancement</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Xin</surname></persName>
							<email>ji.xin@uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory on Intelligent Technology and System Beijing National Research Center for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">David R. Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory on Intelligent Technology and System Beijing National Research Center for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory on Intelligent Technology and System Beijing National Research Center for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory on Intelligent Technology and System Beijing National Research Center for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory on Intelligent Technology and System Beijing National Research Center for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Put It Back: Entity Typing with Language Model Enhancement</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="993" to="998"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>993</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Entity typing aims to classify semantic types of an entity mention in a specific context. Most existing models obtain training data using distant supervision, and inevitably suffer from the problem of noisy labels. To address this issue, we propose entity typing with language model enhancement. It utilizes a language model to measure the compatibility between context sentences and labels , and thereby automatically focuses more on context-dependent labels. Experiments on benchmark datasets demonstrate that our method is capable of enhancing the entity typing model with information from the language model, and significantly outperforms the state-of-the-art baseline. Code and data for this paper can be found from https://github. com/thunlp/LME.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Entity typing classifies semantic types of an en- tity mention in a context sentence, and can be beneficial for a large number of natural language processing tasks <ref type="bibr" target="#b12">(Neelakantan and Chang, 2015)</ref>, such as entity linking <ref type="bibr" target="#b1">(Chabchoub et al., 2016)</ref>, relation extraction ( <ref type="bibr" target="#b11">Miwa and Sasaki, 2014)</ref>, and question answering ( <ref type="bibr" target="#b24">Yahya et al., 2013)</ref>. Fine- grained entity typing (FET) ( <ref type="bibr" target="#b8">Ling and Weld, 2012;</ref><ref type="bibr" target="#b27">Yosef et al., 2012;</ref><ref type="bibr" target="#b25">Yao et al., 2013;</ref><ref type="bibr" target="#b4">Gillick et al., 2014;</ref><ref type="bibr" target="#b2">Del Corro et al., 2015;</ref><ref type="bibr" target="#b26">Yogatama et al., 2015;</ref><ref type="bibr" target="#b23">Yaghoobzadeh and Schütze, 2015;</ref><ref type="bibr" target="#b14">Ren et al., 2016a;</ref><ref type="bibr" target="#b28">Yuan and Downey, 2018</ref>) is based on a large set of fine-grained types and is therefore more challenging. So far, neural mod- els ( <ref type="bibr" target="#b3">Dong et al., 2015;</ref><ref type="bibr" target="#b18">Shimaoka et al., 2017;</ref><ref type="bibr" target="#b21">Xin et al., 2018</ref>) have achieved state-of-the-art results on FET.</p><p>All current FET models rely on distant super- vision (DS) ( <ref type="bibr" target="#b10">Mintz et al., 2009</ref>) to obtain training * Corresponding author: Zhiyuan Liu.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Raw</head><p>Schwarzenegger was elected to be the governor.</p><p>Schwarzenegger acted in the film Terminator.</p><p>Good (A) politician was elected to be the governor.</p><p>(An) actor acted in the film Terminator.</p><p>Bad (An) actor was elected to be the governor.</p><p>(A) politician acted in the film Terminator. data, due to the lack of large-scale human-labeled data. Such reliance on DS has been a signifi- cant problem for entity typing. In DS, an entity mention in the context sentence is first linked to a named entity in the knowledge base (KB). The entity has type labels 1 stored in the KB, and all labels will be assigned to this entity mention. In other words, these are noisy global labels with- out considering the specific context of the entity mention. On the other hand, entity typing aims to predict context-dependent types of the entity mention, and test datasets are all human-labeled. The difference between DS and human annotation leads to a huge gap in performances between train- ing/development and test dataset. <ref type="bibr">2</ref> To address this problem, we propose En- tity Typing with Language Model Enhancement (LME). It is able to measure the compatibility be- tween the context sentence and each distantly su- pervised label, in an unsupervised manner using meaning of the label.</p><p>In previous works, the hierarchical structure of labels has been considered ( <ref type="bibr" target="#b15">Ren et al., 2016b;</ref><ref type="bibr" target="#b6">Karn et al., 2017;</ref><ref type="bibr" target="#b22">Xu and Barbosa, 2018)</ref>. How- ever, to the best of our knowledge, precious information inside names of labels has never been used. For example, whether the label is /person/actor or /foo/bar makes no dif- ference. We argue that, the meaning of entity men- tion words can also be expressed by the name of its context-dependent type, to some extent. Based on this argument, replacements with context- dependent types make more sense than those with global-but-context-irrelevant ones. We provide an example in <ref type="table" target="#tab_0">Table 1</ref>. The entity Schwarzenegger has types /actor and /politician, and we can see that replacements with context-dependent types produce better sentences.</p><p>The natural way to evaluate the soundness of sentences is language modeling ( <ref type="bibr" target="#b0">Bengio et al., 2003;</ref><ref type="bibr">Mikolov et al., 2010)</ref>. Our method em- ploys a language model to evaluate the soundness of each synthetic sentence generated by replacing the entity mention with its type's name. It is able to focus more on context-dependent types.</p><p>We conduct experiments to compare our model with the state-of-the-art baseline on two widely used datasets. The results demonstrate that LME is capable of improving entity typing systems by considering the meaning of labels, and alleviating the problem of noise in distantly-supervised entity typing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>Our model <ref type="figure" target="#fig_0">(Figure 1</ref>) consists of two parts: an en- tity typing (ET) module, and a language model en- hancement (LME) module.</p><p>ET predicts a probability distribution vector y for an entity mention, where each entry y i repre- sents the predicted probability for each type label.</p><p>In the training phase, LME optimizes a lan- guage model whose input includes y, and also back-propagates gradients through y to parame- ters inside ET. In the testing phase, LME is not involved and y is directly used for inference: if y i is greater than a threshold 0.5, the i th type is con- sidered true; if all entries are below the threshold, the type with the greatest entry is considered true.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Entity Typing Module</head><p>Entity typing is defined on an ontology T (the set of all labels). Given an entity mention e and its context sentence s = {l 1 , l 2 , ..., e, r 1 , r 2 , ...} (l i and r i are left and right context words), the typing model predicts a vector y indicating the probabil- Schwarzenegger acted in the film Terminator ity distribution over all labels in the ontology:</p><formula xml:id="formula_0">y = σ(W y [v M ; v C ; v F ]),<label>(1)</label></formula><p>where σ is the sigmoid function, W y is a param- eter matrix, and [; ; ] denotes concatenation. Three vectors: Mention, Context and Feature, are built from e and s as follows:</p><p>Entity mention vector There may be multi- ple words e 1 , e 2 , ... in the entity mention, and v M is the average of word embeddings of these words.</p><p>Context vector Two bi-directional LSTMs <ref type="bibr" target="#b5">(Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr" target="#b17">Schuster and Paliwal, 1997</ref>) are used for left and right con- text words. The outputs of BiLSTMs further go through a self-attention layer. v C is the concate- nation of the attention-layer outputs.</p><p>Hand-crafted feature vector A sparse fea- ture vector f is built from the entity mention e. The features are adopted from those used by <ref type="bibr" target="#b4">Gillick et al. (2014)</ref> and <ref type="bibr" target="#b26">Yogatama et al. (2015)</ref>. v F is a dense projection of f :</p><formula xml:id="formula_1">v F = W f f ,<label>(2)</label></formula><p>where W f is the projection matrix. After y is calculated, DS provides a label vector y * ∈ {0, 1} |T | , where |T | is the number of labels. The loss function for typing is the cross-entropy between y and y * :</p><formula xml:id="formula_2">J type = H(y * , y) = − i y * i log(y i ) + (1 − y * i ) log(1 − y i ),<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Language Model Enhancement Module</head><p>The core part of the LME module is an LSTM lan- guage model <ref type="bibr" target="#b19">(Sundermeyer et al., 2012</ref>). The lan- guage model takes a sentence {w 1 , w 2 , ..., w n } as input, and assigns a probability to this sentence. Concretely, at step i, the LSTM reads the word sub-sequence {w 1 , ..., w i }, and predicts the prob- ability of w i+1 succeeding the sub-sequence. A well trained language model predicts high proba- bility for a reasonable sentence. Before applying the LME module to enhance the ET module, the language model is pre-trained with sentences from the training set. The loss function for s in the pre-train phase is:</p><formula xml:id="formula_3">J pre = LM({l 1 , l 2 , ..., e, r 1 , r 2 , ...}),<label>(4)</label></formula><p>where bold face letters are word embeddings for corresponding words. LM(·) is the language model loss function: accumulative step-wise log- probability of each word of the input sequence. A well-trained language model calculates smaller loss for a more reasonable sentence. After pre-training the language model, the LME module is combined with the ET module. Con- cretely, we assign an embedding vector L i for each label, and take the sum of label embeddings weighted by y. The sum h replaces e in the input sequence of the language model:</p><formula xml:id="formula_4">h = T i=1 y i L i ,<label>(5)</label></formula><formula xml:id="formula_5">J lm = LM({l 1 , l 2 , ..., h, r 1 , r 2 , ...}),<label>(6)</label></formula><p>where L is the matrix of all label embeddings, and J lm is loss function of the language model used in the training phase. In order to ensure that label embeddings are in the same semantic space with word embeddings, L is initialized with word em- beddings of the labels' names.</p><p>In the training phase, parameters of the ET mod- ule are updated w.r.t.</p><formula xml:id="formula_6">J train = J type + λJ lm ,<label>(7)</label></formula><p>where λ is the weight to balance the loss.</p><p>The ET module has a much smaller parame- ter space than the language model. In order to make full use of the gradients, we only update pa- rameters of the ET module and fix the language model in the training phase. Now that the lan- guage model is fixed, when J lm is being mini- mized, it adjusts the probability distribution in y. If a label i is compatible with the context sen- tence, its corresponding entry y i is expected to have a high value. Gradients are back-propagated through y and update parameters of the ET mod- ule. In this way, y can learn to be more context- dependent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>We employ two well-established and widely-used dataset for evaluating our model: WIKI (Ling and Weld, 2012) and ONTONOTES ( <ref type="bibr" target="#b4">Gillick et al., 2014)</ref>.</p><p>Training parts of both datasets are labeled with DS, and testing parts are annotated by human. Therefore they are suitable for evaluating how our model can narrow the gap between DS and ground-truth context-dependent labels. Statistics of the two datasets are provided in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiment Settings</head><p>The baseline for comparison is the hybrid model NFGEC proposed by <ref type="bibr" target="#b18">Shimaoka et al. (2017)</ref>. It is described as the ET module of our model. Our own model is referred to as NFGEC+LME. We implement our model based on the source code of NFGEC. <ref type="bibr">3</ref> For a fair comparison, the ET module is unchanged, including all hyperparame- ters and methods of parameter random initializa- tion. Word embeddings are initialized with pre- trained embeddings provided by <ref type="bibr" target="#b13">Pennington et al. (2014)</ref>.</p><p>There are a few additional hyperparameters in our model. The most important one is λ, the weight between two parts of the loss function. Other ones include the learning rate r for pretrain- ing the language model and the hidden size h of LSTM used in the language model. We perform a grid-search based on performances on the de- velopment set, and set r = 0.005 and h = 500. Details of λ will be discussed in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Overall Results</head><p>We compare vanilla NFGEC and NFGEC+LME in <ref type="table" target="#tab_4">Table 3</ref>. The results of NFGEC come from the paper by <ref type="bibr" target="#b18">Shimaoka et al. (2017)</ref>. For run- ning NFGEC+LME, λ is set to 0.005 in WIKI and 0.001 in ONTONOTES.</p><p>Evaluation metrics include strict accuracy, macro-F1 score and micro-F1 score <ref type="bibr" target="#b8">(Ling and Weld, 2012</ref>  From the results we see that:</p><p>(1) In both datasets, LME consistently helps NFGEC to better classify entity mentions into their context-dependent types. We can see im- provements in all metrics. This is because LME is capable of evaluating the appropriateness of each label and distinguishing context-dependent ones from global-but-context-irrelevant ones. There- fore LME helps the system to focus on more rea- sonable types.</p><p>(2) Among all metrics, the improvement on strict accuracy is the most significant. Strict ac- curacy is the proportion of entity mentions whose predicted types are completely identical with hu- man annotation. It is therefore the most impor- tant metric for evaluating how robust the system is against noisy labels. The ability of LME alleviat- ing noises from DS contributes to improving strict accuracy most.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Analysis of λ</head><p>We choose the optimal λ values for results in <ref type="table" target="#tab_4">Table  3</ref> according to their performances on the develop- ment set. After they are chosen, we compare the results on the test set under different values of λ in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>Conclusions from the previous subsection can be seen again: when λ is set to a proper value, our model can consistently outperform the base- line over all metrics; strict accuracy is the metric with the most significant improvements. Also, we notice that the performances deteri- orate when λ grows too large, and may even be worse than the baseline. The reason is that LME is a kind of regularization: its role is only in the training phase, exchanging the performance on training set with that on test set. So λ, as a reg- ularization coefficient, must be carefully chosen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Qualitative Analysis</head><p>In order to have an intuitive feeling of the model, we provide an example of LME's effect.</p><p>In the following sentence (from the test set of WIKI), both models try to predict the type of Lake Placid which, in this very context, is a town in New York. We show all labels with at least one score over the threshold 0.5, or is annotated true by human in  NFGEC predicts a high score for /person and a low score for /location, probably be- cause both words of the entity mention are first- letter capitalized and thus look like a person's name. LME, however, may consider the sen- tence structure person of location to be more rea- sonable than person of person, and makes the correct judgment between these two labels. As for /location/city, LME also shows higher confidence than NFGEC, but it is still regretfully below the threshold. This also demonstrates a weakness of LME: limited by the performance of the ET module. Addressing this limitation can be considered as a future direction for improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose a novel architecture LME to improve entity typing systems. It utilizes a language model and a set of label embeddings to judge the compatibility between labels and con- text sentences, and reduces noises introduced by DS. Experiments demonstrate that LME is capable of helping NFGEC, a state-of-the-art entity typing model, to alleviate the problem of noisy labels, and reaching a new state-of-the-art performance. Since the LME module does not depend on the ET module, we are confident that LME can be adapted to other entity typing systems as well.</p><p>Future Work Utilizing meaning of labels to al- leviate the problem of noises from DS is an intere- sting direction. We make the first attempt in this paper, and we believe the direction is worth further exploring. For example, (1) how to train a lan- guage model that is sensitive with incorrect labels; (2) how to combine meaning of labels with the hi- erarchical structure of types; (3) how to find the optimal λ easily for a new dataset. LME may also be extended to other tasks that also suffer from noises and incompleteness of DS, such as relation extraction ( <ref type="bibr" target="#b20">Takamatsu et al., 2012;</ref><ref type="bibr" target="#b16">Ritter et al., 2013;</ref><ref type="bibr" target="#b7">Lin et al., 2016)</ref>. However, since a relation does not have a specific location in the sentence, it needs more effort than a simple replacement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Our model: an entity typing (ET) module and a language model enhancement (LME) module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The performance under different λ values. λ = 0 is the vanilla NFGEC. Note that values of the vertical axis are improvements compared to vanilla NFGEC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples of entity mention-type name re-
placement. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table>Dataset 
Train Development 
Test 

WIKI 
2,000,000 
10,000 
563 
ONTONOTES 
251,039 
2,202 8,963 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Number of instances in each part of datasets.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>Dataset 
WIKI 
ONTONOTES 

Metric 
Strict Macro Micro Strict Macro Micro 

NFGEC 59.68 78.97 75.36 50.89 70.80 64.93 
+LME 
62.88 80.61 76.95 52.90 72.41 65.17 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Performance of entity typing, evaluated by 
strict accuracy, macro-F1 and micro-F1 score. (%) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table>Scaringe dismissed Brian Barrett of Lake 
Placid as one of his defense attorneys. 

Type 
NFGEC +LME Human 

/person 
0.622 
0.150 
False 
/location 
0.323 
0.627 
True 
/location/city 
0.024 
0.208 
True 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>An example, showing the scores by two mod-
els as well as human annotation. 

</table></figure>

			<note place="foot" n="1"> Since entities are classified into labels of types, type and label have the same meaning in this paper. 2 In the WIKI dataset, strict accuracies and macro-F1 scores are respectively 72.3%/89.2% on the development set and 59.7%/79.0% on the test set, using the model NFGEC from (Shimaoka et al., 2017).</note>

			<note place="foot" n="3"> https://github.com/shimaokasonse/ NFGEC</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work is supported by the 973 Program (No. 2014CB340501), the National Natural Science Foundation of China (NSFC No. 61572273, 61661146007) and Tsinghua University Initiative Scientific Research <ref type="bibr">Program (20151080406)</ref>. This work is also funded by China Association for Sci-ence and Technology (2016QNRC001). We also thank anonymous reviewers for their insightful suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Jauvin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Collective disambiguation and semantic annotation for entity linking and typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Chabchoub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Gagnon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amal</forename><surname>Zouaq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SWEC</title>
		<meeting>SWEC</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Finet: Context-aware fine-grained named entity typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdalghani</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A hybrid neural model for type classification of entity mentions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Contextdependent fine-grained entity type tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nevena</forename><surname>Lazic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Huynh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.1820</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">End-to-end trainable attentive decoder for hierarchical entity classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Karn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulli</forename><surname>Waltinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural relation extraction with selective attention over instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fine-grained entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel S Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">JaňJaň Cernock`Cernock`y, and Sanjeev Khudanpur. 2010. Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukáš</forename><surname>Burget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Rion Snow, and Dan Jurafsky</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modeling joint entity and relation extraction with table representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Sasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<title level="m">ferring missing entity type instances for knowledge base completion: New dataset and methods. Proceedings of NAACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Afet: Automatic finegrained entity typing by hierarchical partial-label embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Xiang Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Label noise reduction in entity typing by heterogeneous partial-label embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Xiang Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Modeling missing data in distant supervision for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuldip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural architectures for fine-grained entity type classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonse</forename><surname>Shimaoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Lstm neural networks for language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reducing wrong labels in distant supervision for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shingo</forename><surname>Takamatsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improving neural fine-grained entity typing with knowledge attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural finegrained entity type classification with hierarchyaware loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denilson</forename><surname>Barbosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Corpus-level fine-grained entity typing using contextual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Robust question answering over the web of linked data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shady</forename><surname>Elbassuoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Universal schema for entity type prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on AKBC</title>
		<meeting>Workshop on AKBC</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Embedding methods for fine grained entity type classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nevena</forename><surname>Lazic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">HYENA: Hierarchical type classification for entity names</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Amir Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Otyper: A neural architecture for open named entity typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
