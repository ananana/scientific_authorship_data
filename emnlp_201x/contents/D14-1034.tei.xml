<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:10+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Unsupervised Model for Instance Level Subcategorization Acquisition</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Baker</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Laboratory</orgName>
								<orgName type="institution" key="instit1">Computer Laboratory University of Cambridge</orgName>
								<orgName type="institution" key="instit2">IIT Haifa</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Unsupervised Model for Instance Level Subcategorization Acquisition</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="278" to="289"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Most existing systems for subcategoriza-tion frame (SCF) acquisition rely on supervised parsing and infer SCF distributions at type, rather than instance level. These systems suffer from poor portability across domains and their benefit for NLP tasks that involve sentence-level processing is limited. We propose a new unsuper-vised, Markov Random Field-based model for SCF acquisition which is designed to address these problems. The system relies on supervised POS tagging rather than parsing, and is capable of learning SCFs at instance level. We perform evaluation against gold standard data which shows that our system outperforms several supervised and type-level SCF baselines. We also conduct task-based evaluation in the context of verb similarity prediction, demonstrating that a vector space model based on our SCFs substantially outper-forms a lexical model and a model based on a supervised parser 1 .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Subcategorization frame (SCF) acquisition in- volves identifying the arguments of a predicate and generalizing about its syntactic frames, where each frame specifies the syntactic type and number of arguments permitted by the predicate. For example, in sentences (1)-(3) the verb distin- guish takes three different frames, the difference between which is not evident when considering the phrase structure categorization: (1) Direct Transitive:</p><p>[They]NP <ref type="bibr">[distinguished]</ref>  As SCFs describe the syntactic realization of the verbal predicate-argument structure, they are highly valuable for a variety of NLP tasks. For example, verb subcategorization information has proven useful for tasks such as parsing ( <ref type="bibr" target="#b6">Carroll and Fang, 2004;</ref><ref type="bibr" target="#b1">Arun and Keller, 2005;</ref><ref type="bibr" target="#b8">Cholakov and van Noord, 2010)</ref>, semantic role labeling ( <ref type="bibr" target="#b3">Bharati et al., 2005;</ref><ref type="bibr" target="#b34">Moschitti and Basili, 2005</ref>), verb clustering, (Schulte im <ref type="bibr" target="#b48">Walde, 2006;</ref><ref type="bibr" target="#b51">Sun and Korhonen, 2011</ref>) and machine translation (hye <ref type="bibr" target="#b15">Han et al., 2000;</ref><ref type="bibr" target="#b14">Hajiƒç et al., 2002;</ref><ref type="bibr" target="#b57">Weller et al., 2013)</ref>.</p><p>SCF induction is challenging. The argument- adjunct distinction is difficult even for humans, and is further complicated by the fact that both ar- guments and adjuncts can appear frequently in po- tential argument head positions ( <ref type="bibr" target="#b21">Korhonen et al., 2000</ref>). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in ques- tion (e.g. ( <ref type="bibr" target="#b45">Roland and Jurafsky, 1998;</ref><ref type="bibr" target="#b28">Lippincott et al., 2010;</ref><ref type="bibr" target="#b43">Rimell et al., 2013</ref>), Section 4).</p><p>Because of the strong impact of domain vari- ation, SCF information is best acquired automat- ically. Existing data-driven SCF induction sys- tems, however, do not port well between do- mains. Most existing systems rely on hand- written rules <ref type="bibr" target="#b4">(Briscoe and Carroll, 1997;</ref><ref type="bibr" target="#b22">Korhonen, 2002;</ref><ref type="bibr" target="#b38">Preiss et al., 2007)</ref> or simple co- occurrence statistics <ref type="bibr" target="#b35">(O'Donovan et al., 2005;</ref><ref type="bibr" target="#b7">Chesley and Salmon-Alt, 2006</ref>; <ref type="bibr" target="#b16">Ienco et al., 2008;</ref><ref type="bibr" target="#b26">Lenci et al., 2008;</ref><ref type="bibr">Altamirano and Alonso i Alemany, 2010;</ref><ref type="bibr" target="#b18">Kawahara and Kurohashi, 2010)</ref> applied to the gram- matical dependency output of supervised statisti- cal parsers. Even the handful of recent systems that use modern machine learning techniques <ref type="bibr" target="#b11">(Debowski, 2009;</ref><ref type="bibr" target="#b29">Lippincott et al., 2012;</ref><ref type="bibr" target="#b55">Van de Cruys et al., 2012;</ref><ref type="bibr" target="#b40">Reichart and Korhonen, 2013)</ref> use supervised parsers to pre-process the data 2 .</p><p>Supervised parsers are notoriously sensitive to domain variation ( <ref type="bibr" target="#b25">Lease and Charniak, 2005</ref>). As annotation of data for each new domain is un- realistic, current SCF systems suffer from poor portability. This problem is compounded for the many systems that employ manually devel- oped SCF rules because rules are inherently ig- norant to domain-specific preferences. The few SCF studies that focused on specific domains (e.g. biomedicine) have reported poor performance due to these reasons ( <ref type="bibr" target="#b43">Rimell et al., 2013)</ref>.</p><p>Another limitation of most current SCF systems is that they produce a type-level SCF lexicon (i.e. a lexicon which lists, for a given predicate, dif- ferent SCF types with their relative frequencies). Such a lexicon provides a useful high-level pro- file of the syntactic behavior of the predicate in question, but is less useful for downstream NLP tasks (e.g. information extraction, parsing, ma- chine translation) that involve sentence processing and can therefore benefit from SCF information at instance level. Sentences (1)-(3) demonstrate this limitation -a prior distribution over the pos- sible syntactic frames of distinguish provides only a weak signal to a sentence level NLP application that needs to infer the verbal argument structure of its input sentences.</p><p>We propose a new unsupervised model for SCF induction which addresses these problems with existing systems. Our model does not use a parser or hand-written rules, only a part-of-speech (POS) tagger is utilizes in order to produce features for machine learning. While POS taggers are also sensitive to domain variation, they can be adapted to domains more easily than parsers because they require much smaller amounts of annotated data ( <ref type="bibr" target="#b25">Lease and Charniak, 2005;</ref><ref type="bibr" target="#b44">Ringger et al., 2007)</ref>. However, as we demonstrate in our experiments, domain adaptation of POS tagging may not even be necessary to obtain good results on the SCF ac- quisition task.</p><p>Our model, based on the Markov Random Field (MRF) framework, performs instance-based SCF learning. It encodes syntactic similarities among verb instances across different verb types (derived from a lexical and POS-based feature representa- tion of verb instances) as well as prior beliefs on the tendencies of specific instances of the same verb type to take the same SCF.</p><p>We evaluate our model against corpora anno- tated with verb instance SCFs ( <ref type="bibr" target="#b39">Quochi et al., 2012</ref>). In addition, following the Levin verb clustering tradition <ref type="bibr" target="#b27">(Levin, 1993)</ref> which ties verb meanings with their syntactic properties, we eval- uate the semantic predictive power of our clusters. In the former evaluation, our model outperforms a number of strong baselines, including supervised and type-level ones, achieving an accuracy of up to 69.2%. In the latter evaluation a vector space model that utilized our induced SCFs substantially outperforms the output of a type-level SCF system that uses the fully trained Stanford parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Work</head><p>Several SCF acquisition systems are available for English <ref type="bibr" target="#b35">(O'Donovan et al., 2005;</ref><ref type="bibr" target="#b38">Preiss et al., 2007;</ref><ref type="bibr" target="#b29">Lippincott et al., 2012;</ref><ref type="bibr" target="#b55">Van de Cruys et al., 2012;</ref><ref type="bibr" target="#b40">Reichart and Korhonen, 2013</ref>) and other languages, including French (Messiant, 2008), Italian ( <ref type="bibr" target="#b26">Lenci et al., 2008</ref>), Turkish ( <ref type="bibr">Uzun et al., 2008)</ref>, Japanese ( <ref type="bibr" target="#b18">Kawahara and Kurohashi, 2010)</ref> and Chinese ( <ref type="bibr">Han et al., 2008</ref>). The promi- nent input to these systems are grammatical re- lations (GRs) which express binary dependen- cies between words (e.g. direct and indirect ob- jects, various types of complements and conjunc- tions). These are generated by some parsers (e.g. ( <ref type="bibr" target="#b5">Briscoe et al., 2006</ref>)) and can be extracted from the output of others <ref type="bibr" target="#b10">(De-Marneffe et al., 2006</ref>).</p><p>Two representative systems for English are the Cambridge system ( <ref type="bibr" target="#b38">Preiss et al., 2007</ref>) and the BioLexicon system which was used to acquire a substantial lexicon for biomedicine ( <ref type="bibr" target="#b56">Venturi et al., 2009</ref>). These systems extract GRs at the verb in- stance level from the output of a parser: the RASP general-language unlexicalized parser <ref type="bibr">3 (Briscoe et al., 2006</ref>) and the lexicalized Enju parser tuned to the biomedical domain ( <ref type="bibr" target="#b33">Miyao and Tsujii, 2005</ref>), respectively. They generate potential SCFs by mapping GRs to a predefined SCF inventory us- ing a set of manually developed rules (the Cam- bridge system) or by simply considering the sets of GRs including verbs in question as potential SCFs (BioLexicon). Finally, a type level lexicon is built through noisy frame filtering (based on frequencies or on external resources and annota- tions), which aims to remove errors from parsing and argument-adjunct distinction. Clearly, these systems require extensive manual work: a-priori definition of an SCF inventory and rules, manu- ally annotated sentences for training a supervised parser, SCF annotations for parser lexicalization, and manually developed resources for optimal fil- tering.</p><p>A number of recent works have applied mod- ern machine learning techniques to SCF induc- tion, including point-wise co-occurrence of ar- guments <ref type="bibr" target="#b11">(Debowski, 2009)</ref>, a Bayesian network model ( <ref type="bibr" target="#b29">Lippincott et al., 2012</ref>), multi-way tensor factorization (Van de Cruys et al., 2012) and De- terminantal Point Processes (DPPs) -based clus- tering <ref type="bibr" target="#b40">(Reichart and Korhonen, 2013)</ref>. However, all of these systems induce type-level SCF lexi- cons and, except from the system of ( <ref type="bibr" target="#b29">Lippincott et al., 2012</ref>) that is not capable of learning traditional SCFs, they all rely on supervised parsers.</p><p>Our new system differs from previous ones in a number of respects. First, in contrast to most previous systems, our system provides SCF anal- ysis for each verb instance in its sentential con- text, yielding more precise SCF information for systems benefiting from instance-based analysis. Secondly, it addresses SCF induction as an unsu- pervised clustering problem, avoiding the use of supervised parsing or any of the sources of man- ual supervision used in previous works. Our sys- tem relies on POS tags -however, we show that it is not necessary to train a tagger with in-domain data to obtain good performance on this task, and therefore our approach provides a more domain- independent solution to SCF acquisition.</p><p>We employ POS-tagging instead of unsuper- vised parsing for two main reasons. First, while a major progress has been made on unsupervised parsing (e.g. ( <ref type="bibr" target="#b9">Cohen and Smith, 2009;</ref><ref type="bibr">BergKirkpatrick et al., 2010)</ref>), the performance is still considerably behind that of supervised parsing. For example, the state-of-the-art discriminative model of <ref type="bibr" target="#b2">(Berg-Kirkpatrick et al., 2010</ref>) achieves only 63% directed arc accuracy for WSJ sentences of up to 10 words, compared to more than 95% obtained with supervised parsers. Second, current unsupervised parsers produce unlabeled structures which are substantially less useful for SCF acqui- sition than labeled structures produced by super- vised parsers (e.g. grammatical relations).</p><p>Finally, a number of recent works addressed re- lated tasks such as argument role clustering for SRL ( <ref type="bibr" target="#b23">Lang and Lapata, 2011a;</ref><ref type="bibr" target="#b24">Lang and Lapata, 2011b;</ref><ref type="bibr" target="#b52">Titvo and Klementiev, 2012</ref>) in an unsu- pervised manner. While these works differ from ours in the task (clustering arguments rather than verbs) and the level of supervision (applying a su- pervised parser), like us they analyze the verb ar- gument structure at the instance level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>We address SCF induction as an unsupervised verb instance clustering problem. Given a set of plain sentences, our algorithm aims to cluster the verb instances in its input into syntactic clusters that strongly correlate with SCFs. In this sec- tion we introduce a Markov Random Field (MRF) model for this task: Section 3.1 describes our model's structure, components and objective; Sec- tion 3.2 describes the model potentials and the knowledge they encode; and Section 3.3 describes how clusters are induced from the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Structure</head><p>We implement our model in the MRF framework <ref type="bibr" target="#b20">(Koller and Friedman, 2009)</ref>. This enables us to encode the two main sources of information that govern SCF selection in verb instances: (1) At the sentential context, the verbal syntactic frame is encoded through syntactic features. Verb in- stances with similar feature representations should therefore take the same syntactic frame; and <ref type="formula">(2)</ref> At the global context, per verb type SCF distribu- tions tend to be Zipfian ( <ref type="bibr" target="#b21">Korhonen et al., 2000</ref>). Instances of the same verb type should therefore be biased to take the same syntactic frame.</p><p>Given a collection of plain input sentences, we denote the number of verb instances in the col- lection with n, and the number of data-dependent equivalence classes (ECs) with K (see below for their definition), and define an undirected graphi- cal model (MRF), G = (V, E, L). We define the vertex set as V = X ‚à™ C, with X = {x 1 , . . . , x n } consisting of one vertex for every verb instance in the input collection, and C = {c 1 . . . c K } consist- ing of one vertex for each data-dependent EC. The set of labels used by the model, L, corresponds to the syntactic frames taken by the verbs in the in- put data. The edge set E is defined through the model's potentials that are described below.</p><p>We encode information in the model through three main sets of potentials: one set of single- ton potentials -defined over individual model ver- texes, and two sets of pairwise potentials -defined between pairs of vertexes. The first set consists of a singleton potential for each vertex in the model. Reflecting the Zipfian distribution of SCFs across the instances of the same verb type, these poten- tials encourage the model to assign such verb in- stances to the same frame (cluster). The infor- mation encoded in these potentials is induced via a pre-processing clustering step. The second set consists of a pairwise potential for each pair of ver- texes x i , x j ‚àà X -that is, for each verb instance pair in the input, across verb types. These poten- tials encode the belief, computed as feature-based similarity (see below), that their verb instance ar- guments implement the same SCF.</p><p>Finally, potentials from the last set bias the model to assign the same SCF to high cardinal- ity sets of cross-type verb instances based on their syntactic context. While these are pairwise poten- tials defined between verb instance vertexes (X) and EC vertexes (C), they are designed so that they bias the assignment of all verb instance ver- texes that are connected to the same EC vertex to- wards the same frame assignment (l ‚àà L). The two types of pairwise potentials complement each other by modeling syntactic similarities among verb instance pairs, as well as among higher cardi- nality verb instance sets.</p><p>The resulted maximum aposteriori problem (MAP) takes the following form:</p><formula xml:id="formula_0">M AP (V ) = arg max x,c‚ààV n i=1 Œ∏i(xi) + n i=1 n j=1 Œ∏i,j(xi, xj)+ n i=1 K j=1 œÜi,j(xi, cj) ¬∑ I(xi ‚àà ECj) + K i=1 K j=1 Œæi,j(ci, cj)</formula><p>where the predicate I(x i ‚àà EC j ) returns 1 if the i-th verb instance belongs the j-th equivalence class and 0 otherwise. The Œæ pairwise potentials defined between EC vertexes are very simple po- tentials designed to promise different assignments for each pair of EC vertexes. They do so by assign- ing a ‚àí‚àû score to assignments where their argu- ment vertexes take the same frame and a 0 other- wise. In the rest of this section we do not get back to this simple set of potentials.</p><p>A graphical illustration of the model is given in <ref type="figure">Figure 1</ref>. Note that we could have selected a richer model structure, for example, by defining a similarity potential over all verb instance ver- texes that share an equivalence class. However, as the figure demonstrates, even the structure of the pruned version of our model (see Section 3.3) usu- ally contains cycles, which makes inference NP- hard <ref type="bibr" target="#b49">(Shimony, 1994)</ref>. Our design choices aim to balance between the expressivity of the model and the complexity of inference. In Section 3.3 we de- scribe the LP relaxation algorithm we use for in- ference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C1 C2</head><p>Figure 1: A graphical illustration of our model (after pruning, see Sec. 3.3) for twenty verb in- stances (|X| = 20), each represented with a black vertex, and two equivalence classes (ECs), each represented with a gray vertex (|C| = 2). Solid lines represent edges (and Œ∏ i,j pairwise potentials) between verb instance vertexes. Dashed lines rep- resent edges between verb instance vertexes and EC vertexes (œÜ i,j pairwise potentials) or between EC vertexes (Œæ i,j pairwise potentials) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Potentials and Encoded Knowledge</head><p>Pairwise Syntactic Similarity Potentials. The pairwise syntactic similarity potentials are defined for each pair of verb instance vertexes, x i , x j ‚àà X. They are designed to encourage the model to as- sign verb instances with similar fine-grained fea- ture representations to the same frame (l ‚àà L) and verb instances with dissimilar representations to different frames. For this aim, for every verb pair i, j with feature representation vectors v i , v j and verb instance vertexes x i , x j ‚àà X, we define the following potential function:</p><formula xml:id="formula_1">Œ∏i,j(xi = l1, xj = l2) = Œª(vi, vj) if l1 = l2 0 otherwise</formula><p>Where l 1 , l 2 ‚àà L are label pairs and Œª is a verb instance similarity function. Below we describe the feature representation and the Œª function. The verb instance feature representation is de- fined through the following process. For each word instance in the input sentences we first build a basic feature representation (see below). Then, for each verb instance we construct a final fea- ture representation defined to be the concatena- tion of that verb's basic feature representation with the basic representations of the words in a size 2 window around the represented verb. The fi- nal feature representation for the i-th verb in- stance in our dataset is therefore defined to be</p><formula xml:id="formula_2">v i = [w ‚àí2 , w ‚àí1 , vb i , w +1 , w +2 ],</formula><note type="other">where w ‚àík and w +k are the basic feature representations of the words in distance ‚àík or +k from the i-th verb in- stance in its sentence, and vb i is the basic feature representation of that verb instance.</note><p>Our basic feature representation is inspired from the feature representation of the MST parser ( <ref type="bibr" target="#b30">McDonald et al., 2005</ref>) except that in the parser the features represent a directed edge in the com- plete directed graph defined over the words in a sentence that is to be parsed, while our features are generated for word n-grams. Particularly, our fea- ture set is a concatenation of two sets derived from the MST set described in <ref type="table">Table 1</ref> of <ref type="bibr" target="#b30">(McDonald et al., 2005</ref>) in the following way: (1) In both sets the parent word in the parser's set is replaced with the represented word; (2) In one set every child word in the parser's set is replaced by the word to the left of the represented word and in the other set it is replaced by the word to its right. This choice of features allows us to take advantage of a provably useful syntactic feature representation without the application of any parse tree annotation or parser.</p><p>We compute the similarity between the syntac- tic environments of two verb instances, i, j, using the following equation:</p><formula xml:id="formula_3">Œª(v i , v j ) = W ¬∑ cos(v i , v j ) ‚àí S</formula><p>Where W is a hyperparameter designed to bias verb instances of the same verb type towards the same frame. Practically, W was tuned to be 3 for instances of the same type, and 1 otherwise <ref type="bibr">4</ref> .</p><p>While the cosine function is the standard mea- sure of similarity between two vectors, its val- ues are in the <ref type="bibr">[0,</ref><ref type="bibr">1]</ref> range. In the MRF modeling framework, however, we must encode a negative pairwise potential value between two vertexes in order to encourage the model to assign different labels (frames) to them. We therefore added the positive hyperparameter S which was tuned, with-out access to gold standard manual annotations, so that there is an even number of negative and pos- itive pairwise syntactic similarity potentials after the model is pruned (see Section 3.3) <ref type="bibr">5</ref> .</p><p>Type Level Singleton Potentials. The goal of these potentials is to bias verb instances of the same type to be assigned to the same syntactic frame while still keeping the instance based nature of our algorithm. For this aim, we applied Algo- rithm 1 for pre-clustering of the verb instances and encoded the induced clusters into the local poten- tials of the corresponding x ‚àà X vertexes. For every x ‚àà X the singleton potential is therefore defined to be:</p><formula xml:id="formula_4">Œ∏i(xi = l) = F ¬∑ max Œª if l is induced by Algorithm 1 0 otherwise</formula><p>where max Œª is the maximum Œª score across all verb instance pairs in the model and F = 0.2 is a hyperparamter. Algorithm 1 has two hyperparameters: T and M , the first is a similarity cut-off value used to de- termine the initial set of clusters, while the second is used to determine whether two clusters are simi- lar enough to be merged. We tuned these hyperpa- rameters, without manually annotated data, so that the number of clusters induced by this algorithm will be equal to the number of gold standard SCFs. T was tuned so that the first part of the algorithm generates an excessive number of clusters, and M was then tuned so that these clusters are merged to the desired number of clusters.</p><p>The Œª function, used to measure the similar- ity between two verbs, is designed to bias the in- stances of the same verb type to have a higher sim- ilarity score. Algorithm 1 therefore tends to assign such instances to the same cluster. In our experi- ments that was always the case for this algorithm.</p><p>High Cardinality Verb Sets Potentials. This set of potentials aims to bias larger sets of verb instances to share the same SCF. It is inspired by <ref type="bibr" target="#b47">(Rush et al., 2012</ref>) who demonstrated, that syn- tactic structures that appear at the same syntac- tic context, in terms of the surrounding POS tags, tend to manifest similar syntactic behavior. While they demonstrated the usefulness of their method for dependency parsing and POS tagging, we im- plement it for higher level SCFs.</p><p>We identified syntactic contexts that imply simi- lar SCFs for verb instances appearing inside them. Algorithm 1 Verb instance pre-clustering algo- rithm. ÀÜ Œª is the average Œª score between the mem- bers of its cluster arguments. T and M are hyper- parametes tuned without access to gold standard data.</p><formula xml:id="formula_5">Require: K = ‚àÖ for all x ‚àà X do for all k ‚àà K do for all u ‚àà k do if Œª(vx, vu) &gt; T then k = k ‚à™ {x} Go to next x end if end for end for k1 = {x} K = K ‚à™ k1 end for for all k1, k2 ‚àà K: k1 = k2 do ifÀÜŒªifÀÜ ifÀÜŒª(k1, k2) &gt; M then Merge (k1, k2) end if end for</formula><p>Contexts are characterized by the coarse POS tag to the left and to the right of the verb instance. While the number of context sets is bounded only by the number of frames our model is designed to induce, in practice we found that defining two equivalence sets led to the best performance gain, and the sets we used are presented in <ref type="table">Table 1</ref>.</p><p>In order to encode this information into our MRF, each set of syntactic contexts is associated with an equivalence class (EC) vertex c ‚àà C and the verb instance vertexes of all verbs that appear in a context from that set are connected with an edge to c. The pairwise potential between a vertex x ‚àà X and its equivalence class is defined to be:</p><formula xml:id="formula_6">œÜ i,j (x i = l 1 , c j = l 2 ) = U if l 1 = l 2 0 otherwise U = 10</formula><p>is a hyperparameter that strongly biases x vertexes to get the same SCF as their EC vertex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Verb Cluster Induction</head><p>In this section we describe how we induce verb instance clusters from our model. This process is based on the following three steps: (1) Graph pruning; (2) Induction of an Ensemble of approx- imate MAP inference solutions in the resulted graphical model; and, (3) Induction of a final clus- tering solution based on the ensemble created at step 2. Below we explain the necessity of each of these steps and provide the algorithmic details. <ref type="table">Table 1</ref>: POS contexts indicative for the syntactic frame of the verb instance they surround. D: de- terminer, N: noun, V: verb, T: the preposition 'to' (which has its own POS tag in the WSJ POS tag set which we use), R: adverb. EC-1 and EC-2 stand for the first and second equivalence class respec- tively. In addition, the following contexts where associated with both ECs: (T, D), (T, N ), (N, N ) and (V, I) where I stands for a preposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EC-1 EC-2 Left Right Left Right</head><formula xml:id="formula_7">, D V T N D R T V . N D R D R N</formula><p>Graph Pruning. The edge set of our model consists of an edge for every pair of verb in- stance vertexes and of the edges that connect verb instance vertexes and equivalence class vertexes. This results in a large tree-width graph which sub- stantially complicates MRF inference. To alleviate this we prune all edges with a positive score lower than p + and all edges with a negative score higher than p ‚àí , where p + and p ‚àí are manually tuned hy- perparametes <ref type="bibr">6</ref> .</p><p>MAP Inference. For most reasonable values of p + and p ‚àí our graph still contains cycles even af- ter it is pruned, which makes inference NP-hard <ref type="bibr" target="#b49">(Shimony, 1994</ref>). Yet, thanks to our choice of an edge-factorized model, there are various approxi- mate inference algorithms suitable for our case.</p><p>We applied the message passing algorithm for linear-programming (LP) relaxation of the MAP assignment <ref type="bibr">(MPLP, (Sontag et al., 2008)</ref>). LP re- laxation algorithms for the MAP problem define an upper bound on the original objective which takes the form of a linear program. Consequently, a minimum of this upper bound can be found us- ing standard LP solvers or, more efficiently, using specialized message passing algorithms <ref type="bibr" target="#b58">(Yanover et al., 2006</ref>). The MPLP algorithm described in ( <ref type="bibr" target="#b50">Sontag et al., 2008</ref>) is appealing in that it itera- tively computes tighter upper bounds on the MAP objective (for details see their paper).</p><p>Cluster Ensemble Generation and a Final Solution. As our MAP objective is non-convex, the convergent point of an optimization algorithm applied to it is highly sensitive to its initializa- tion. To avoid convergence to arbitrary local max- ima which may be of poor quality, we turn to a perturbation protocol where we repeatedly intro- duce random noise to the MRF's potential func- tions and then compute the approximate MAP so- lution of the resulted model using the MPLP algo- rithm. Noising was done by adding an term to the lambda values described in section 3.2 <ref type="bibr">7</ref> . This protocol results in a set of cluster (label) assign- ments for the involved verb instances, which we treat as an ensemble of experts from which a final, high quality, solution is to be induced.</p><p>The basic idea in ensemble learning is that if several experts independently cluster together two verb instances, our belief that these verbs belong in the same cluster should increase. ) implemented this idea through the k- way normalized cut clustering algorithm ( <ref type="bibr" target="#b59">Yu and Shi, 2003)</ref>. Its input is an undirected graphÀÜGgraphÀÜ graphÀÜG = ( ÀÜ V , ÀÜ E, ÀÜ W ) wher√™ V is the set of vertexes, ÀÜ E is the set of edges andÀÜWandÀÜ andÀÜW is a non-negative and sym- metric edge weight matrix. To apply this model to our task, we construct the input graphÀÜGgraphÀÜ graphÀÜG from the labelings (frame assignments) contained in the ensemble. The graph vertexesÀÜVvertexesÀÜ vertexesÀÜV correspond to the verb instances and the (i, j)-th entry of the matrixÀÜW matrixÀÜ matrixÀÜW is the number of ensemble members that assign the same label to the i-th and j-th verb instances.</p><p>For A, B ‚äÜ ÀÜ V define:</p><formula xml:id="formula_8">links(A, B) = i‚ààA,j‚ààBÀÜW j‚ààBÀÜ j‚ààBÀÜW (i, j)</formula><p>Using this definition, the normalized link ratio of A and B is defined to be:</p><formula xml:id="formula_9">N ormLinkRatio(A, B) = links(A, B) links(A, ÀÜ V )</formula><p>The k-way normalized cut problem is to mini- mize the links that leave a cluster relative to the total weight of the cluster. Denote the set of clus- terings ofÀÜVofÀÜ ofÀÜV that consist of k clusters byÀÜCbyÀÜ byÀÜC = { ÀÜ c 1 , . . . ÀÜ c t } and the j-th cluster of the i-th cluster-ing byÀÜcbyÀÜ byÀÜc ij . Then</p><formula xml:id="formula_10">c * = argminÀÜc argminÀÜ argminÀÜc i ‚àà ÀÜ C k j=1 N ormLinkRatio( ÀÜ c ij , ÀÜ V ‚àí ÀÜ c ij )</formula><p>The algorithm of ( <ref type="bibr" target="#b59">Yu and Shi, 2003)</ref> solves this problem very efficiently as it avoids the heavy eigenvalues and eigenvectors computations re- quired by traditional approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>Our model is unique compared to existing systems in two respects. First, it does not utilize supervi- sion in the form of either a supervised syntactic parser and/or manually crafted SCF rules. Conse- quently, it induces unnamed frames (clusters) that are not directly comparable to the named frames induced by previous systems. Second, it induces syntactic frames at the verb instance, rather than type, level. Evaluation, and especially comparison to previous work, is therefore challenging.</p><p>We therefore evaluate our system in two ways. First, we compare its output, as well as the output of a number of clustering baselines, to the gold standard annotation of corpora from two differ- ent domains (the only publicly available ones with instance level SCF annotation, to the best of our knowledge). Second, in order to compare the out- put of our system to a rule-based SCF system that utilizes a supervised syntactic parser, we turn to a task-based evaluation. We aim to predict the degree of similarity between verb pairs and, fol- lowing ( <ref type="bibr" target="#b36">Pado and Lapata, 2007)</ref> , we do so using a syntactic-based vector space model (VSM). We construct three VSMs -(a) one that derives fea- tures from our clusters; (b) one whose features come from the output of a state-of-the-art verb type level, rule based, SCF system <ref type="bibr" target="#b40">(Reichart and Korhonen, 2013</ref>) that uses a modern parser ( ; and (c) a standard lexical VSM. Below we show that our system compares favorably in both evaluations.</p><p>Data. We experimented with two datasets taken from different domains: labor legislation and en- vironment ( <ref type="bibr" target="#b39">Quochi et al., 2012</ref>). These datasets were created through web crawling followed by domain filtering. Each sentence in both datasets may contain multiple verbs but only one target verb has been manually annotated with a SCF. The labour legislation domain dataset contains 4415 annotated verb instances (and hence also sentences) of 117 types, and the environmental domain dataset contains 4503 annotated verb in- stances of 116 types. In both datasets no verb type accounts for more than 4% of the instances and only up to 35 verb types account for 1% of the instances or more. The lexical difference between the corpora is substantial: they share only 42 anno- tated verb types in total, of which only 2 verb types (responsible for 4.1% and 5.2% of the instances in the environment and labor legislation domains re- spectively) belong to the 20 most frequent types (responsible for 37.9% and 46.85% of the verb in- stances in the respective domains) of each corpus.</p><p>The 29 members of the SCF inventory are de- tailed in <ref type="figure" target="#fig_0">(Quochi et al., 2012)</ref>. <ref type="table" target="#tab_1">Table 2</ref>, presenting the distribution of the 5 highest frequency frames in each corpus, demonstrates that, in addition to the significant lexical difference, the corpora differ to some extent in their syntactic properties. This is reflected by the substantially different frequencies of the "dobj:iobj-prep:su" and "dobj:su" frames.</p><p>As a pre-processing step we first POS tagged the datasets with the Stanford tagger ( <ref type="bibr" target="#b53">Toutanova et al., 2003</ref>) trained on the standard POS training sections of the WSJ PennTreebank corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Against SCF Gold Standard</head><p>Experimental Protocol The computational com- plexity of our algorithm does not allow us to run it on thousands of verb instances in a feasible time. We therefore repeatedly sampled 5% of the sen- tences from each dataset, ran our algorithm as well as the baselines (see below) and report the average performance of each method. The number of rep- etitions was 40 and samples were drawn from a uniform distribution while still promising that the distribution of gold standard SCFs in each sam- ple is identical to their distribution in the entire dataset. Before running this protocol, 5% of each corpus was kept as held-out data on which hyper- parameter tuning was performed.</p><p>Evaluation Measures and Baselines. We com- pare our system's output to instance-level gold standard annotation. We use standard measures for clustering evaluation, one measure from each of the two leading measure types: the V measure <ref type="bibr" target="#b46">(Rosenberg and Hirschberg, 2007)</ref>, which is an in- formation theoretic measure, and greedy many-to- one accuracy, which is a mapping-based measure. For the latter, each induced cluster is first mapped to the gold SCF frame that annotates the highest number of verb instances this induced cluster also annotates and then a standard instance-level accu- racy score is computed (see, e.g., <ref type="bibr" target="#b41">(Reichart and Rappoport, 2009)</ref>). Both measures scale from 100 (perfect match with gold standard) to 0 (no match).</p><p>As mentioned above, comparing the perfor- mance of our system with respect to a gold stan- dard to the performance of previous type-level systems that used hand-crafted rules and/or su- pervised syntactic parsers would be challenging. We therefore compare our model to the follow- ing baselines: (a) The most frequent class (MFC) baseline which assigns all verb instances with the SCF that is the most frequent one in the gold stan- dard annotation of the data; (b) The Random base- line which simply assigns every verb instance with a randomly selected SCF; (c) Algorithm 1 of sec- tion 3.2 which generates unsupervised verb in- stance clustering such that verb instances of the same type are assigned to the same cluster; and (d) Finally, we also compare our model against versions where everything is kept fixed, except a subset of potentials which is omitted. This enables us to study the intricacies of our model and the rel- ative importance of its components. For all mod- els, the number of induced clusters is equal to the number of SCFs in the gold standard.</p><p>Results <ref type="table">Table 3</ref> presents the results, demon- strating that our full model substantially outper- forms all baselines. For the first two simple heuris- tic baselines (MFC and Random) the margin is higher than 20% for both the greedy M-1 mapping measure and the V measure. Note tat the V score of the MFC baseline is 0 by definition, as it as- signs all items to the same cluster. The poor per- formance of these simple baselines is an indication of the difficulty of our task.</p><p>Recall that the type level clustering induced by Algorithm 1 is the main source of type level in- formation our model utilizes (through its single- ton potentials). The comparison to the output of this algorithm (the Type Pre-clustering baseline) therefore shows the quality of the instance level refinement our model provides. As seen in table 3, our model outperforms this baseline by 6.9% for the M-1 measure and 5.2% for the V measure.</p><p>In order to compare our model to its compo- nents we exclude either the EC potentials (œÜ and Œæ) only (Model -EC), or the EC and the singleton potentials (Œ∏ i , Model -EC -Type pre-clustering). The results show that our model gains much more Environment Labour Legislation SCF Frequency SCF Frequency dobj:su 46% dobj:su 39% su 9% dobj:iobj-prep:su 15% iobj-prep:su 8% su 10% dobj:iobj-prep:su 6% su:xcompto-vbare 8% su:xcompto-vbare 6% iobj-prep:su 7%  <ref type="table">Table 3</ref>: Results for our full model, the baselines (Type Pre-clustering: the pre-clustering algorithm (Algorithm 1 of section 3.2), MFC: the most frequent class (SCF) in the gold standard annotation and Random: random SCF assignment) and the model components. The full model outperforms all other models across measures and datasets.</p><p>from the type level information encoded through the singleton potentials than from the EC poten- tials. Yet, EC potentials do lead to an improvement of up to 1.5% in M-1 and up to 1.1% in V and are therefore responsible for up to 26.1% and 21.2% of the improvement over the type pre-clustering baseline in terms of M-1 and V, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Task Based Evaluation</head><p>We next evaluate our model in the context of vec- tor space modeling for verb similarity prediction <ref type="bibr" target="#b54">(Turney and Pantel, 2010)</ref>. Since most previous word similarity works used noun datasets, we con- structed a new verb pair dataset, following the pro- tocol used in the collection of the wordSimilarity- 353 dataset ( <ref type="bibr" target="#b12">Finkelstein et al., 2002</ref>). Our dataset consists of 143 verb pairs, con- structed from 122 unique verb lemma types. The participating verbs appear ‚â• 10 times in the con- catenation of the labour legislation and the envi- ronment datasets. Only pairs of verbs that were considered at least remotely similar by human judges (independent of those that provided the similarity scores) were included. A similarity score between 1 and 10 was assigned to each pair by 10 native English speaking annotators and were then averaged in order to get a unique pair score.</p><p>Our first baseline is a standard VSM based on lexical collocations. In this model features corre- spond to the number of collocations inside a size 2 window of the represented verb with each of the 5000 most frequent nouns in the Google n-gram corpus <ref type="bibr" target="#b13">(Goldberg and Orwant, 2013)</ref>. Since our corpora are limited in size, we use the collocation counts from the Google corpus. We used our model to generate a vector repre- sentation of each verb in the following way. We run the model 5000 times, each time over a set of verbs consisting of one instance of each of the 122 verb types participating in the verb similarity set. The output of each such run is transformed to a binary vector for each participating verb, where all coordinates are assigned the value of 0, ex- cept from the one that corresponds to the cluster to which the verb was assigned which has the value of 1. The final vector representation is a concate- nation of the 5000 binary vectors. Note that for this task we did not use the graph cut algorithm to generate a final clustering from the multiple MRF runs. Instead we concatenated the output of all these runs into one feature representation that fa- cilitates similarity prediction. For our model we estimated the verb pair similarity using the Tani- mato similarity score for binary vectors:</p><formula xml:id="formula_11">T (X, Y ) = i X i ‚àß Y i i x i ‚à® Y i</formula><p>For the baseline model, where the features are collocation counts, we used the standard cosine similarity.</p><p>Our second baseline is identical to our model, except that: (a) the data is parsed with the Stan- ford parser (version 3.3.0, ( ) which was trained with sections 2-21 of the WSJ corpus; (b) the phrase structure output of the parser is transformed to the CoNLL dependency format using the official CoNLL 2007 conversion script <ref type="bibr" target="#b17">(Johansson and Nugues, 2007)</ref>; and then (c) the SCF of each verb instance is inferred using the rule-based system used by <ref type="bibr" target="#b40">(Reichart and Korhonen, 2013</ref>). The vector space representation for each verb is then created using the process we de- scribed for our model and the same holds for vec- tor comparison. This baseline allows direct com- parison of frames induced by our SCF model with those derived from a supervised parser's output.</p><p>We computed the Pearson correlation between the scores of each of the models and the human scores. The results demonstrate the superiority of our model in predicting verb similarity: the correlation of our model with the human scores is 0.642 while the correlation of the lexical col- location baseline is 0.522 and that of the super- vised parser baseline is only 0.266. The results indicate that in addition to their good alignment with SCFs, our clusters are also highly useful for verb meaning representation. This is in line with the verb clustering theory of the Levin tradition <ref type="bibr" target="#b27">(Levin, 1993)</ref> which ties verb meaning with their syntactic properties. We consider this an intrigu- ing direction of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We presented an MRF-based unsupervised model for SCF acquisition which produces verb instance level SCFs as output. As opposed to previous sys- tems for the task, our model uses only a POS tag- ger, avoiding the need for a statistical parser or manually crafted rules. The model is particularly valuable for NLP tasks benefiting from SCFs that are applied across text domains, and for the many tasks that involve sentence-level processing.</p><p>Our results show that the accuracy of the model is promising, both when compared against gold standard annotations and when evaluated in the context of a task. In the future we intend to im- prove our model by encoding additional informa- tion in it. We will also adapt it to a multilingual setup, aiming to model a wide range of languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 2 )</head><label>2</label><figDesc>Indirect Transitive: [They]NP [distin- guished]VP [between [me and you]ADVP ]PP . (3) Ditransitive: [They]NP [distinguished]VP [him]NP [from [the other boys]NP ]PP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>VP [the mast]NP [of [ships on the horizon ]NP ]PP . 1 The verb similarity dataset used for the evaluation of our model is publicly available at ie.technion.ac.il/‚àºroiri/.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Top 5 most frequent SCFs for the Environment and Labour Legislation datasets used in our 
experiments. 

Environment Labour Legislation 
M-1 V 
M-1 V 
Full Model 
66.4 57.3 
69.2 55.6 
Baselines 
MFC 
46.2 0 
39.4 0 
Random 
34.6 28.1 
36.5 27.8 
Type Pre-clustering 
60.1 52.1 
62.3 51.4 
Model Components 
Model -EC 
64.9 56.2 
67.4 54.6 
Model -EC -Type pre-clustering 48.3 48.9 
45.7 44.7 

</table></figure>

			<note place="foot" n="2"> (Lippincott et al., 2012) does not use a parser, but the syntactic frames induced by the system do not capture sets of arguments for verbs, so are not SCFs in a traditional sense.</note>

			<note place="foot" n="3"> A so-called unlexicalized parser is a parser trained without explicit SCF annotations.</note>

			<note place="foot" n="4"> All hyperparameters that require gold-standard annotation for tuning, were tuned using held-out data (Section 4).</note>

			<note place="foot" n="5"> The values in practice are S = 0.43 for labour legislation and S = 0.38 for environment.</note>

			<note place="foot" n="6"> The values used in practice are p+ = 0.28, p‚àí = ‚àí0.17 for the labour legislation dataset, and p+ = 0.25, p‚àí = ‚àí0.20 for the environment set.</note>

			<note place="foot" n="7"> was accepted by first sampling a number in the [0, 1] range using the Java psuodorandom generator and then scaling it to 1% of cos(vi, vj). This value was tuned, without access to gold standard manual annotations, so that there is an even number of negative and positive pairwise syntactic similarity potentials after the model is pruned (Section 3.3).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The first author is supported by the Common-wealth Scholarship Commission (CSC) and the Cambridge Trust.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">IRASubcat, a highly customizable, language independent tool for the acquisition of verbal subcategorization information from corpus</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL 2010 Workshop on Computational Approaches to Languages of the Americas</title>
		<editor>Ivana Romina Altamirano and Laura Alonso i Alemany</editor>
		<meeting>the NAACL 2010 Workshop on Computational Approaches to Languages of the Americas</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Lexicalization in crosslinguistic probabilistic parsing: The case of french</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-05</title>
		<meeting>ACL-05</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Painless unsupervised learning with features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Bouchard-Cote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT-10</title>
		<meeting>NAACL-HLT-10</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Inferring semantic roles using subcategorization frames and maximum entropy model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshar</forename><surname>Bharati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Venkatapathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashanth</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-05</title>
		<meeting>CoNLL-05</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic extraction of subcategorization from corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ANLP-97</title>
		<meeting>ANLP-97</meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The second release of the rasp system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-COLING-06</title>
		<meeting>ACL-COLING-06</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The automatic acquisition of verb subcategorisations and their impact on the performance of an HPSG parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP-04</title>
		<meeting>IJCNLP-04</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic extraction of subcategorization frames for french</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paula</forename><surname>Chesley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susanne</forename><surname>Salmon-Alt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC-06</title>
		<meeting>LREC-06</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using unknown word techniques to learn known words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Cholakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gertjan Van Noord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-10</title>
		<meeting>EMNLP-10</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT-09</title>
		<meeting>NAACL-HLT-09</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De-Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC-06</title>
		<meeting>LREC-06</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Valence extraction using EM selection and co-occurrence matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Debowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedins of LREC-09</title>
		<meeting>eedins of LREC-09</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Placing search in context: The concept revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zach</forename><surname>Solan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gadi</forename><surname>Wolfman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eitan</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="116" to="131" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A dataset of syntactic-ngrams over time from a very large corpus of english books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Orwant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of (*SEM)-13. Association for Computational Linguistics</title>
		<meeting>(*SEM)-13. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Natural language generation in the context of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajiƒç</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Martin Mejrek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Parton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Center for Language and Speech Processing</title>
		<meeting><address><addrLine>Baltimore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>Johns Hopkins University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
	<note>Dragomir Radev, and Owen Rambow. Summer Workshop Final Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Handling structural divergences and recovering dropped arguments in a korean/english machine translation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Chung Hye Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Lavoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanya</forename><surname>Kittredge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myunghee</forename><surname>Korelsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
		<idno>Pro- ceedings of the AMTA-00</idno>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automatic extraction of subcategorization frames for italian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dino</forename><surname>Ienco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><surname>Bosco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC-08</title>
		<meeting>LREC-08</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Extended constituent-to-dependency conversion for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NODALIDA-07</title>
		<meeting>NODALIDA-07</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Acquiring reliable predicate-argument structures from raw corpora for case frame compilation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC-10</title>
		<meeting>LREC-10</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-03</title>
		<meeting>ACL-03</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Probabilistic graphical models: principles and techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nir</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Statistical filtering and subcategorization frame acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genevieve</forename><surname>Gorrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-00</title>
		<meeting>EMNLP-00</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semantically motivated subcategorization acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition</title>
		<meeting>the ACL-02 workshop on Unsupervised lexical acquisition</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unsupervised semantic role induction via split-merge clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-11</title>
		<meeting>ACL-11</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unsupervised semantic role induction with graph partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-11</title>
		<meeting>EMNLP-11</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Parsing biomedical literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Lease</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP05</title>
		<meeting>IJCNLP05</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unsupervised acquisition of verb subcategorization frames from shallow-parsed corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Mcgillivray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simonetta</forename><surname>Montemagni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vito</forename><surname>Pirrelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC08</title>
		<meeting>LREC08</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">English verb classes and alternations: A preliminary investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Levin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<pubPlace>Chicago, IL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Exploring subdomain variation in biomedical language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Lippincott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid</forename><surname>Oseaghdha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning syntactic verb frames using graphical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Lippincott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aanna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid</forename><surname>Oseaghdha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-12</title>
		<meeting>ACL-12</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Online large-margin training of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-05</title>
		<meeting>ACL-05</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">LexSchem: A large subcategorization lexicon for French verbs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cedric</forename><surname>Messiant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Poibeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC-08</title>
		<meeting>LREC-08</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A subcategorization acquistion system for french verbs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cedric</forename><surname>Messiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL08-SRW</title>
		<meeting>ACL08-SRW</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Probabilistic disambiguaton models for wide-coverage hpsg parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-05</title>
		<meeting>ACL-05</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Verb subcategorization kernels for automatic semantic labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition</title>
		<meeting>the ACL-SIGLEX Workshop on Deep Lexical Acquisition</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Large-scale induction and evaluation of lexical resources from the penn-ii and penn-iii treebanks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ruth O&amp;apos;donovan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoife</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Van Genabith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="328" to="365" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Pado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dependency-based construction of semantic space models</title>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="161" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A system for large-scale acquisition of verbal, nominal and adjectival subcategorization frames from corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judita</forename><surname>Preiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-07</title>
		<meeting>ACL-07</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Third evaluation report. evaluation of panacea v3 and produced resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valeria</forename><surname>Quochi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Frontini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Bartolini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Poch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muntsa</forename><surname>Padr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuria</forename><surname>Bel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregor</forename><surname>Thurmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Toral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Kamram</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Improved lexical acquisition through dpp-based verb clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-13</title>
		<meeting>ACL-13</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The nvi clustering evaluation measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-09</title>
		<meeting>CoNLL-09</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A diverse dirichlet process ensemble for unsupervised induction of syntactic categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Elidan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-12</title>
		<meeting>COLING-12</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Acquisition and evaluation of verb subcategorization resources for biomedicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lippincott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="228" to="237" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Active learning for part-of-speech tagging: Accelerating corpus annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Ringger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Mcclanahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robbie</forename><surname>Haertel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Busby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Carmen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Seppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deryle</forename><surname>Lonsdale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-07 Linguistic Annotation Workshop</title>
		<meeting>the ACL-07 Linguistic Annotation Workshop</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">subcategorization frequencies are affected by corpus choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Roland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-98</title>
		<meeting>ACL-98</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">V measure: a conditional entropybased external cluster evaluation measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-07</title>
		<meeting>EMNLP-07</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Improved parsing and pos tagging using inter-sentence consistency constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-12</title>
		<meeting>EMNLP-12</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Experiments on the automatic induction of german semantic verb classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="194" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Finding the maps for belief networks is np-hard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Solomon</forename><surname>Shimony</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="399" to="310" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Tightening lp relaxations for map using message passing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Talya</forename><surname>Meltzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of UAI-08</title>
		<meeting>UAI-08</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Hierarchical verb clustering using graph factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-11</title>
		<meeting>EMNLP-11</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A bayesian approach to unsupervised semantic role induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-12</title>
		<meeting>EMNLP-12</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Feature-rich part-ofspeech tagging with a cyclic dependency network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-03</title>
		<meeting>NAACL-03</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">From frequency to meaning: Vector space models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Multi-way tensor factorization for unsupervised lexical acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Van De Cruys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Poibeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-12</title>
		<meeting>COLING-12</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Bootstrapping a verb lexicon for biomedical information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giulia</forename><surname>Venturi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simonetta</forename><surname>Montemagni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Marchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mcnaught</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">5449</biblScope>
			<biblScope unit="page" from="137" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Using subcategorization knowledge to improve case prediction for translation to german</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marion</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-13</title>
		<meeting>ACL-13</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Linear programming relazations and belief propogataion an empitical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Yanover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Talya</forename><surname>Meltzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR Special Issue on Machine Learning and Large Scale Optimization</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Multiclass spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV-13</title>
		<meeting>ICCV-13</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
