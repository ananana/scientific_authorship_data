<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Author-aware Aspect Topic Sentiment Model to Retrieve Supporting Opinions from Reviews</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lahari</forename><surname>Poddar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wynne</forename><surname>Hsu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mong</forename><forename type="middle">Li</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Author-aware Aspect Topic Sentiment Model to Retrieve Supporting Opinions from Reviews</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="472" to="481"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>User generated content about products and services in the form of reviews are often diverse and even contradictory. This makes it difficult for users to know if an opinion in a review is prevalent or biased. We study the problem of searching for supporting opinions in the context of reviews. We propose a framework called SURF, that first identifies opinions expressed in a review, and then finds similar opinions from other reviews. We design a novel probabilistic graphical model that captures opinions as a combination of aspect, topic and sentiment dimensions, takes into account the preferences of individual authors, as well as the quality of the entity under review, and encodes the flow of thoughts in a review by constraining the aspect distribution dynamically among successive review segments. We derive a similarity measure that considers both lexical and semantic similarity to find supporting opinions. Experiments on TripAd-visor hotel reviews and Yelp restaurant reviews show that our model outperforms existing methods for modeling opinions, and the proposed framework is effective in finding supporting opinions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In order to make an informed decision when book- ing a hotel online, a user will often read through its reviews looking for specific feedbacks. For ex- ample, if he or she plans to do an early check-in and comes across a review that mentions a hassle- free early check-in as shown in <ref type="figure">Figure 1</ref>, it will be helpful to know whether other guests had sim- ilar experiences. If a review complains about bed <ref type="figure">Figure 1</ref>: A sample hotel review bugs or noise from construction nearby, then it is important to know if that was an occasional prob- lem based on a single user's experience or happens frequently. However, it is impossible for an indi- vidual to go through the large volume of reviews to verify whether an opinion is prevalent.</p><p>In this work, we study the problem of finding supporting sentences from reviews that corrobo- rate the opinions expressed in a target review sen- tence. This is useful as it enables users to easily look for appropriate comments on the specific is- sues they are interested in.</p><p>A review is a collection of sentences where each sentence may have multiple segments separated by punctuations or conjunctions. Each segment ex- presses an opinion that can be represented as a combination of aspect, topic and sentiment. An aspect refers to the overall theme of a segment, a topic is the specific subject or issue discussed and the sentiment for each topic can be neutral, posi- tive or negative. <ref type="table">Table 1</ref> shows the segments and the possible latent aspect, topics and sentiment for a sentence of the review in <ref type="figure">Figure 1</ref>. Given an opinion (in a target segment), we say that a review supports the opinion, if it contains some segment whose aspect, topic and sentiment are similar to those in the target segment. Find- ing such supporting reviews is a challenge since reviews are typically short unstructured text and discuss a wide range of topics on various aspects with differing sentiments and vocabulary used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Review</head><p>Topic modeling have been widely used to re- duce the effect of huge vocabulary by grouping words in topics. However, the fundamental as- sumption of topic models is the independence of topics even in the same document. This fails to capture the natural coherence present in reviews, which rarely consist of isolated, unrelated sen- tences, but are composed of collocated, structured and coherent groups of sentences <ref type="bibr">(Hovy, 1993)</ref>. We observe that an author's train of thoughts when writing a review is often linear, i.e., he or she will finish discussing one aspect before moving on to the next. In <ref type="figure">Figure 1</ref>, we see that the user first commented on Service ("front-desk staff was very accommodating"), then the Location aspect, fol- lowed by the comment on Food, and finally moved on to Room. This shows that aspects discussed in a review are not chosen from a simple independent mixture, but rather, words in close proximity tend to discuss the same aspect and within a review the aspects discussed in the current segment will affect the possible aspects for the successive segments.</p><p>We explicitly model this by constraining aspect transition between segments using a review spe- cific Markov chain. Each segment is assumed to discuss a single aspect and possible aspects for a segment are made dependent on the aspects of the previous segments. By tracking aspects of previ- ous segments we are able to ensure constrained as- pect sampling for accurate modeling of a review structure. This non-iterative nature of discourse has not been considered by existing works.</p><p>For opinion modeling, capturing the sentiment expressed for an aspect is important. Recent works ( <ref type="bibr">Kim et al., 2013;</ref><ref type="bibr">Jo and Oh, 2011;</ref><ref type="bibr">Moghaddam and Ester, 2011;</ref><ref type="bibr">Wang et al., 2010;</ref><ref type="bibr">Titov and McDonald, 2008a,b)</ref> have developed models to cap- ture aspect and sentiment. However, they do not consider the preferences of authors, or the inherent quality of the entity for the aspect. In a hotel re- view, the sentiment expressed for service depends on both the service standard of the hotel (evident from the sentiment distribution of service of all re- views for the hotel) and the expectation of the au- thor for service (evident from the sentiment distri- bution of the author on service across all hotels) ( <ref type="bibr">Poddar et al., 2017</ref>). We take this into account by making the sentiment distribution of a review dependent on both entity and author.</p><p>We propose an Author-aware Aspect Topic Sen- timent model (Author-ATS) to capture the diverse opinions, taking into account user preferences and thought patterns. The model considers a word to be generated from a hierarchy of aspect, topic and sentiment and encodes the coherent struc- tural property of a review by dynamically con- straining aspect distributions. We also develop a non-parametric version of Author-ATS based on Dirichlet Process called Author-ATS (DP).</p><p>We develop a SUpporting Review Framework (SURF) that utilizes the Author-ATS model to compute the lexical and semantic similarity of an opinion in a target segment to those in the re- view corpus, and returns the top-k supporting re- views. Experiments on real world review datasets show the effectiveness of Author-ATS in model- ing opinions compared to existing topic models. Furthermore, SURF outperforms keyword-based approaches and word embedding based similarity measures in finding supporting opinions. To the best of our knowledge, this is the first work to find supporting reviews for an opinion expressed in user generated contents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There has been substantial research to mine online reviews using topic models <ref type="bibr">(Paul and Girju, 2010;</ref><ref type="bibr">Trabelsi and Zaiane, 2014;</ref><ref type="bibr">Lin and He, 2009;</ref><ref type="bibr">Jo and Oh, 2011;</ref><ref type="bibr">Mukherjee and Liu, 2012;</ref><ref type="bibr" target="#b1">Chen et al., 2013</ref>). The Topic Aspect Model (TAM) <ref type="bibr">(Paul and Girju, 2010)</ref> jointly discovers aspects and topics from documents. The aspect and topic are independent and each aspect affects all topics in similar manner. However, in reviews, the top- ics discussed are often closely related to an aspect. JTV ( <ref type="bibr">Trabelsi and Zaiane, 2014</ref>) encodes topic- viewpoint dependency, but assumes that a docu- ment contains only one aspect. JST ( <ref type="bibr">Lin and He, 2009)</ref> assumes that there is a single sentiment po- larity for a review and the topics are chosen condi- tioned on that, while ASUM in ( <ref type="bibr">Jo and Oh, 2011)</ref> assumes that all words in a sentence are associ- ated with the same topic and sentiment. In con- trast, our proposed model handles the more realis- tic scenario where sentiments may vary depending on the topics discussed in a review.</p><p>For incorporating author information, the User- Sentiment topic model ( <ref type="bibr">Zhao et al., 2012</ref>) con- siders the topic-sentiment distribution only from the author perspective and ignores the character- istics of the entity. Supervised topic model ( <ref type="bibr">Li et al., 2014</ref>) uses explicit ratings to infer senti- ments. PDA-LDA ( <ref type="bibr">Zhang and Wang, 2015</ref>) asso- ciates its Dirichlet prior distribution with user and item topic factors. The work in ( <ref type="bibr">Yang et al., 2015</ref>) models aspects and sentiments based on the de- mography of authors. However, such demographic information are not always available and it cannot model the bias or preference of an individual.</p><p>Additionally, most topic models are concerned about the discourse at word level, and ignore the document structure. HTMM ( <ref type="bibr">Gruber et al., 2007</ref>) models topic coherence by considering topic tran- sition between sentences. HTSM (Rahman and <ref type="bibr">Wang, 2016)</ref> extends HTMM by capturing senti- ment shifts along with topic coherence. Both mod- els do not capture the non-repetitive discourse of reviews. Progressive topical dependency model ( <ref type="bibr" target="#b2">Du et al., 2010</ref><ref type="bibr" target="#b3">Du et al., , 2015</ref>) captures the sequential nature of ideas among segments, especially in movies or books. However, unlike books, the sequence of topics in reviews is not significant. Rather, once a topic has been discussed in a re- view, it is unlikely to be mentioned again in a later segment. From this perspective, it is similar to labeled LDA ( <ref type="bibr">Ramage et al., 2009)</ref> where topic distribution of a document is constrained. How- ever, unlike labeled LDA, the possible aspects of a segment are dynamically constrained depending on previously sampled aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Author-ATS Model</head><p>Author-ATS models an opinion as hierarchical de- pendent mixtures, where words are generated from a three-level hierarchical structure of aspects, top- ics and sentiments. We assume there are A dis- tinct aspects for a domain, for each aspect there are Z topics and for each aspect-topic pair S pos- sible sentiments. We treat a segment as the ba- sic semantic unit, discussing a particular aspect. A review r is a collection of D r segments where each segment is a document d, consisting of N d words. We now describe the assumptions and de- tailed construction of the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Constrained Aspect Generation</head><p>We explicitly model the behavior that after an author has finished discussing an aspect and has moved on to the next, he or she is unlikely to re- turn to it again. We assume that each document d discusses a single aspect a d . The aspect distribu- tion σ r is drawn from a Dirichlet with parameter α. In order to model the linear writing style of authors, we constrain the possible aspects that can be sampled from σ r . Whenever an author starts writing a segment, he or she can choose to either (a) talk about an aspect not yet discussed, or (b) continue with the aspect of the previous segment. This is captured by imposing the constraint that the aspect of the j th document is dependent on the aspects of the (j − 1) th , (j − 2) th , · · · , 1 st docu- ments of the same review.</p><p>With this we relax the independent mixture as- sumption of the standard LDA model for aspects and form a review-specific Markov chain (see <ref type="figure" target="#fig_0">Figure 2</ref>). Such a higher order Markov chain would normally incur intractable computational complexity due to the exponential size of transi- tion probability matrix. However, in our case, the transition probability can be determined by over- all aspect distribution of the review, σ r and a list of possible aspects for the segment. Since we assume a non-repetitive nature of discourse, the number of possible aspects for a segment is mono- tonically decreasing for successive segments. This special property enables us to devise a dynamic programming strategy to solve the problem with linear complexity.</p><p>Each document is associated with a binary as- pect vector Λ. We restrict the sampled aspect of a document to be drawn from only the aspects that are turned on, in Λ of that document. For a document d, Λ d =&lt; l 1 , · · · , l A &gt; where each l a ∈ {0, 1} and A is the total number of aspects. Traditionally, for a document d, an aspect a d is sampled from a multinomial distribution σ r . Here, we restrict the possible sampled aspects to the list Λ d . A value of 1 for the entry l a indicates that the aspect a can be sampled, while 0 indicates that the aspect should not be sampled.</p><p>We generate Λ d by tossing a Bernoulli coin for each aspect a with prior probability Φ a for value 0. We set Φ a as the sampling probability for as- pects which have been sampled for a previous doc- ument. This ensures that an aspect which has been discussed before has lesser probability of coming up again. We set Φ a = 0 for aspects not sam- pled in the past, and for the aspect of (immedi- ately) preceding segment. This models aspect co- herency in a review document where an author ei- ther chooses to discuss a new aspect or continues to talk about the current one.</p><p>We define the list of possible aspects for the document d to be</p><formula xml:id="formula_0">λ d = {a | Λ d [a] = 1}.</formula><p>We sam- ple an aspect a d from σ r with the constraint that a d ∈ λ d i.e. an aspect can be sampled for a doc- ument only if it is turned on in the binary aspect vector for the document and thereby exists in the list of possible aspects for the document. Thus, the aspect transition probability among documents be- comes dependent on σ r and the vector λ d . Unlike regular topic models, Author-ATS is no longer in- variant to reshuffling of words and is able to model linear aspect coherency in a review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Author-Entity dependent Sentiment Distribution</head><p>We account for the dual role of entity and author in a review, by observing that the sentiments ex- pressed are influenced by both the quality of the entity being reviewed and the preferences of the author. We use two Dirichlet distributions to de- rive sentiment, namely, entity-dependent distribu- tion (ξ) and author-dependent distribution (χ). For each aspect-topic combination, ξ is drawn from a Dirichlet distribution with prior γ 1 and χ is drawn from a Dirichlet distribution with prior γ 0 .</p><p>Since online reviews describe experiences of people, some words tend to appear frequently (e.g.: 'hotel','trip' or 'mobile', 'phone' for hotel and mobile reviews respectively). We call them domain stopwords as they are not specific to any aspect. We use a binary switching variable y i to determine the type for the i th word. If y i = 0, then the word is aspect neutral (domain stopword); and if y i = 1, it is aspect dependent. The generative process of the model is as follows:</p><p>• Draw a multinomial word distribution φ0 for domain stopwords and φ1 for each aspect, topic and sentiment words from Dir (ω).</p><p>• For each author u, draw a multinomial sentiment mix- ture χ for each aspect and topic from Dir(γ 0 ) <ref type="figure">Figure 3</ref>: Graphical representation of Author-ATS</p><p>• For each entity e, draw a multinomial sentiment mix- ture ξ for each aspect and topic from Dir (γ 1 ) • For each review r:</p><p>1. Draw multinomial aspect mixture σ from Dir(α) 2. For each document d ∈ r: Note that for the first document of a review, we set λ 0 to the set of all possible aspects, such that there is no constraint when sampling for the first segment of a review. <ref type="figure">Figure 3</ref> shows the plate no- tation for Author-ATS model.</p><formula xml:id="formula_1">(a) Draw Λ d from Bernoulli (Φ) (b) Draw a type mixture ψ from Beta (δ0, δ1) (c) Sample an aspect a d from σ s.t. a d ∈ λ d (d) For sampled aspect a d , draw</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Bayesian Inference</head><p>We employ collapsed Gibbs sampling for in- ference. Markov chain introduced for aspect coherency makes the aspects non-exchangeable, hence sampling an aspect for a segment will also affect all subsequent segments. Since the exact sampling for this would be computationally ex- pensive, we propose the following approximate posterior considering only the previous segments, which has been shown to work well in similar cases previously ( <ref type="bibr">Mimno et al., 2011</ref>).</p><p>We sample an aspect (a d ) for each document based on the posterior probability of the type, topic and sentiment assignment of each word in the doc- ument and the aspects sampled for preceding doc- uments in the review.</p><formula xml:id="formula_2">P (a d | a −d , y −d , z −d , s −d , w) ∝ P (a d | a 1:d−1 ) Z z=1 S s=1 W w=1 B(n a d ,z,s w + ω) W w=1 B(n a d ,z,s,−d w + ω)<label>(1)</label></formula><formula xml:id="formula_3">P (a d | a 1:d−1 ) ∝    n r,−d a d +α a∈λ d n r,−d a +|λ d | * α if a d ∈ λ d 0 otherwise (2) 475</formula><p>where B( x) is the multidimensional extension of the Beta function. The notation n b,−c a refers to the number of times a has been assigned to b exclud- ing current occurrence c, e.g. n r,−d a d denotes the number of documents in review r that has been assigned aspect a d excluding current document d.</p><p>The target aspect a d is dependent on the aspects sampled for the 1 st to (d − 1) th documents of the review, denoted by a 1:d−1 . We restrict the target aspect a d to belong to the set defined by Λ d of the document d to achieve coherence among as- pects respecting the nature of discourse observed in review writing styles. This constrained aspect sampling differentiates Author-ATS from existing topic modeling works on review text by explicitly modeling the topic coherence of opinionated text.</p><p>After sampling the aspect for the document, we jointly sample the latent type, topic and sentiment for each word within the document. The posterior for the i th word of document d (written by author u for entity e) is given as:</p><formula xml:id="formula_4">P (yi, zi, si|a d , w, y−i, z−i, s−i) ∝ P (yi|d) * P (zi|a d , d) * P (si|a d , zi, u, e, d) * P (wi|yi, a d , zi, si, )<label>(3)</label></formula><formula xml:id="formula_5">∝ n d,−i y i + δy i 1 y=0 (n d,−i y + δy) * n d,a d ,−i z i + β Z z=1 n d,a d ,−i z + Zβ * q1 n u,a d ,z i ,−i s i + γ 0 S s=1 n u,a d ,z i ,−i s + Sγ 0 + q2 n e,a d ,z i ,−i s i + γ 1 S s=1 n e,a d ,z i ,−i s + Sγ 1 * n ζ,−i w i + ω W w=1 n ζ,−i w + W ω<label>(4)</label></formula><formula xml:id="formula_6">yi = 0 ⇒ ζ = yi yi = 1 ⇒ ζ = a d , zi, si</formula><p>For sampling sentiment, instead of using a sin- gle Dirichlet density we use a Dirichlet mixture as the prior <ref type="bibr">(Sjölander et al., 1996;</ref><ref type="bibr">Smucker et al., 2005</ref>). It is a weighted combination of two indi- vidual Dirichlet densities χ and ξ. Mixture coeffi- cients q 1 , q 2 are set to 0.5, giving equal weights to both author and entity. This ensures that the cho- sen sentiment reflects both the entity's quality for that topic as well as the author's preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Non-parametric Author-ATS (DP) Model</head><p>While the number of aspects for a domain are lim- ited, the number of topics for each aspect may vary significantly and can be difficult to estimate. For restaurants, the topics for ambiance are fewer (e.g. music, crowd etc.) compared to food. This mo- tivates us to propose a non-parametric version of the Author-ATS model where the number of top- ics can be automatically discovered.</p><p>In this non-parametric version, topic infer- ence is done through Chinese Restaurant Pro- cess (CRP), a popular variant of Dirichlet Process (DP). In a Chinese restaurant with infinite number of tables, each with infinite capacity, CRP deter- mines if a customer chooses to sit at an occupied table (with a probability proportional to the num- ber of customers already sitting at the table), or an unoccupied one. Following the idea of CRP, each observed aspect dependent word can either be as- signed to an existing topic or to a new topic. The conditional distributions for the Gibbs sampler are omitted due to space constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SURF Framework</head><p>Given a target sentence in a review SURF com- putes its similarity with other review sentences us- ing the distributions learned by Author-ATS and returns a list of supporting reviews.</p><p>A sentence supports another sentence if they are either lexically or semantically similar. Two sen- tences are lexically similar if they share keywords that are important for an aspect. Whereas two sen- tences can be semantically similar if they share the same sentiment for an aspect and topic even though they use different words. For example, "The hotel was quite close to space needle" and "Major attractions are just walking distance from the hotel" have high semantic similarity as they both talk about the same aspect 'location' on the topic 'attractions' with a positive sentiment.</p><p>We treat each review sentence as a vector and lexical similarity (lexical sim) is computed as cosine-similarity between the two vectors. The i th entry of a vector signifies importance of the cor- responding word to its assigned aspect computed using the tf-idf weighting scheme. We define the tf-idf of a word w w.r.t. an aspect a as:</p><formula xml:id="formula_7">tf (w, a) = D d=1 P (w|d, a) P (w|d, a) = P (w) if w assigned to a in d 0 otherwise</formula><p>idf (w, A) = log A 1 + |a ∈ A : ∃d ∈ D, P (w|d, a) &gt; 0| P (w) is the generation probability obtained from Author-ATS model. Since words are important with respect to an aspect, unlike traditional tf-idf, these values are computed across reviews on the whole corpus. Words frequently used for describ- ing an aspect often tend to converge across re- views, even though written by different users. Two sentences are considered semantically sim- ilar if they share the same sentiment for an aspect. Let C be the set of words in a sentence. Aspect- topic probability of a sentence is defined as the ra- tio of generation probability of words generated from the aspect-topic pair a, z to the summation of generation probabilities of all the words. P (C|a, z) = w∈C P (w|w has aspect a and topic z) w∈C P (w)</p><p>We define sim 0 to measure the similarities be- tween two sentences (C 1 and C 2 ) having the same aspect, topic and sentiment, and sim 1 to measure the similarities of two sentences with the same as- pect and sentiment but discussing different topics.</p><formula xml:id="formula_8">sim0(C1, C2, a) = Z z=1 P (C1|a, z)P (C2|a, z) sim1(C1, C2, a) = z 1 ,z 2 ∈[1···Z]z 1 =z 2 P (C1|a, z1)P (C2|a, z2)</formula><p>The semantic similarity between two sentences is:</p><formula xml:id="formula_9">semantic sim(C1, C2, a) = sim0(C1, C2, a) + δsim1(C1, C2, a)</formula><p>where δ is a damping factor with value less than 1. Lexical-semantic similarity (LSS) of two sentences with same sentiment for an aspect is measured as a weighted combination of their lexical sim and semantic sim as defined above.</p><p>Ranking of Reviews. Given a review sentence, we employ kNN search to find the k most similar sentences for each of its aspects according to LSS measure. Since a target sentence C may contain multiple aspects, we determine the importance of an aspect a to C as follows:</p><p>Imp(C, a) = w∈C P (w|w has aspect a) w∈C P (w)</p><p>For each aspect a with Imp(C, a) &gt; 0 , we return the top k * Imp(C, a) sentences from the review corpus. Proportionately allocating support- ing sentences from each aspect in the top-k results diversifies the result set and ensures that a user is able to find information about whichever aspect of the target sentence she wished to verify.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We perform two sets of experiments to evalu- ate our proposed framework. We first compare <ref type="table" target="#tab_1">TripAdvisor 12,773 781,403 1,621,956 20,244,293 980,323  Yelp  578  16,981  25,459  232,107  56,200   Table 2</ref>: Statistics of datasets used</p><note type="other">Dataset # entity # author # review # sentence # vocab</note><p>Author-ATS with state-of-the-art topic models us- ing perplexity on test data. Then we evaluate the performance of SURF, for the task of retriev- ing supporting opinions using human annotation, against keyword based search engine Lucene and a competent word embedding model Word2Vec. We use two real world datasets: (a) hotel reviews from TripAdvisor ( <ref type="bibr">Wang et al., 2010)</ref>, and (b) restaurant reviews from yelp.com. <ref type="table">Table 2</ref> shows the statis- tics of the two datasets. We pre-process both datasets by removing do- main independent stopwords 1 . We retain some negation stopwords (e.g.: not, can't, didn't) and join them with the next word (so that 'not good' is treated as a single unit) to help discover senti- ment properly. We use common punctuations like '.', '?', '!' to split into sentences. To further split a sentence into segments we use punctuations used to separate clauses like ',', ';' and conjunctions like 'and', 'however', 'but' as separators. We use a domain independent subjectivity lexicon 2 to ini- tialize sentiment distributions. Since aspect words may consist of highly co-occurring words (e.g. 'front-desk', 'walking distance') we use Pointwise Mutual Information (PMI) <ref type="bibr">(Manning and Schütze, 1999</ref>) to find such collocations. Bigrams with PMI greater than a threshold (we use 0.05 in our exper- iments) are treated as a single word.</p><p>To make the discovered aspects understandable and intuitive, we provide a few seed words to the models. The seeds are only used during initializa- tion and subsequent iterations of Gibbs sampling are not dependent on them.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation of Author-ATS Model</head><p>In this set of experiments, we examine the ability of Author-ATS to capture the opinions in reviews. Perplexity is derived from the likelihood of un- seen test data and is a standard measure for eval- uating topic models. The lower the perplexity, the less confused the model is on seeing new data, im- plying a better generalization power. We compare with the following state-of-the-art opinion models:</p><p>LDA ( <ref type="bibr" target="#b0">Blei et al., 2003</ref>) : A topic model where words are generated from a latent topic dimension.</p><p>TAM (Paul and Girju, 2010): A topic model for opinion mining where words are generated from a two-level hierarchy of aspect and topic.</p><p>JTV ( <ref type="bibr">Trabelsi and Zaiane, 2014</ref>): A topic model especially for contentious documents where each word has a topic and a viewpoint.</p><p>We also implement a baseline model ATS based on three-level Aspect-Topic-Sentiment hierarchy. We use this model to show the performance gain by just considering a hierarchical dependency be- tween these dimensions while capturing an opin- ion. For Author-ATS and ATS, we use 6 aspects, 5 topics for each aspect and 3 sentiments. For fair comparison, we keep the total number of dimen- sions as close as possible across models. We par- tition our dataset into train (80%) and test (20%) sets and report five fold cross validation results. <ref type="table">Table 4</ref> shows that ATS outperforms other mod- els in both datasets due to its hierarchical mod- eling of words. Author-ATS further improves the performance by considering author and entity characteristics as well as the thought patterns of the authors. We note that the performance of the non-parametric model is comparable with Author- ATS, making it easier to use the model for any new domain without having much prior knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>TripAdvisor  <ref type="table">Table 4</ref>: Perplexity values for different models. <ref type="table" target="#tab_4">Table 5</ref> shows the top words extracted by Author-ATS as domain stopwords. Although these words do not convey any aspect information, they are domain dependent and are not found in a gen- eral stopword dictionary.</p><p>From <ref type="table">Table 6</ref>, we observe that the majority of the words are correctly clustered in aspects, and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Domain Stopwords TripAdvisor hotel, nice, stay, trip, times, day, place, back Yelp good, place, food, time, order, bit, make  <ref type="table">Table 6</ref>: Top words for aspect-topic-sentiments found by Author-ATS for TripAdvisor dataset. further into specific topics. For example, the first topic for aspect Room is about in-room experi- ence ('bed','king-size','view'), whereas the sec- ond topic seems to be about bathroom ('shower', 'towels', 'tub'). We also observe that the model is able to obtain contextual sentiment terms which are aspect-topic coherent. For example, words such as 'noise', 'night', 'hear' could be assigned negative sentiment labels for topic 0 of Room due to the context in which they are used, e.g., when describing a room, these words probably indicate a noisy room bothering their sleep at night.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact of Seed Words</head><p>We vary the number of seed words for an aspect and examine its effect on the aspect discovery. We use p@n, the fraction of correctly discovered aspect words among the top n words, to evaluate the quality of the results. The average precision of top-n words for differ- ent aspects is obtained by taking the average over all combinations 6 m of seed words where m is the number of selected seed words, 2 ≤ m ≤ 6. <ref type="figure" target="#fig_2">Figure 4</ref> shows the results. We observe that the average precision increases with the number of seeds, and stabilizes when m ≥ 4. This demon- strates that providing a handful of seed words can go a long way for discovering intended, explain- able domain specific aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation of SURF</head><p>We now evaluate Author-ATS model and LSS measure on retrieving sentences that are relevant to a target sentence. A sentence is considered rel- evant if it expresses similar opinions as the target sentence. A sentence with multiple aspects is rel- evant if it expresses at least one of the opinions in the target sentence. Precision of the top-k answers are manually determined by three annotators and conflicts are resolved by majority voting.</p><p>Recall that LSS considers both lexical and se- mantic similarity. The computation of semantic similarity requires the aspect-topic-sentiment dis- tribution which is only available in the baseline ATS and Author-ATS models. We define a sim- ilarity measure called CJSD that can be used by the various topic models to facilitate comparison. CJSD measures the lexical similarity of two sen- tences as the cosine similarity of their tf-idf vec- tors, while the semantic similarity is measured by the similarity of their topic distributions using Jensen-Shannon Divergence(JSD) as follows:</p><p>CJSD(s1, s2) = λ cosine sim(s1, s2)+(1−λ) JSD(s1, s2)</p><p>We randomly select 5 hotels from TripAdvisor and 5 restaurants from Yelp datasets. For each hotel/restaurant, we randomly pick 10 target sen- tences and retrieve their supporting sentences.The topic distributions of these sentences are obtained using LDA, TAM, JTV, and the proposed models ATS and Author-ATS. <ref type="table" target="#tab_6">Table 7</ref> shows the average precision for top 5, 10 and 20 results retrieved using various topic models with similarity measure CJSD. We see that Author-ATS model always outperforms other topic models for the task of retrieving supporting sentences. This is consistent with the perplexity results of the models obtained previously. <ref type="table" target="#tab_7">Table 8</ref> shows the average precision using vari- ants of the proposed model with LSS. Clearly, us- ing LSS always yields a better precision compared to using CJSD, with the best performer being the Author-ATS with LSS combination. SURF frame- work utilizes this combination for retrieving top-k supporting reviews.   Lucene: A popular keyword based ranking method. We used its default combination of vector space model and boolean model for retrieval.</p><p>Word2Vec: (Mikolov et al., 2013) A state-of- the-art algorithm for word embeddings using neu- ral network. Supporting sentences are ranked with Word Mover's distance using the word embed- dings. We train on TripAdvisor dataset using CBOW algorithm with context window set to 5 as recommended by the authors. We do not train Word2Vec on the Yelp dataset as it is too small. We set the vector dimension to 500 based on grid search. We also compare with Word2Vec model pre-trained on the large GoogleNews dataset 3 . <ref type="table" target="#tab_9">Table 9</ref> shows the average precision for the top 5, 10 and 20 results retrieved using Lucene, Word2Vec and SURF. Word2Vec performs bet- ter when trained on review data, compared to the model trained on general news data. This confirms that domain knowledge is important. It is evident from the results that SURF significantly outper- forms existing approaches for opinion search.  For evaluating the coherence of retrieved set of supporting reviews for an aspect, we look at their corresponding user given aspect ratings. For each aspect of each review sentence, we retrieve its top- k supporting sentences. Then we compute the Target Sentence: bedroom had the most comfortable mattress, feather soft pillows as well as firmer ones, they thought of keeping every guest comfortable Supporting Sentences by SURF Supporting Sentences by Lucene Supporting Sentences by Word2Vec</p><p>Aspect : Room Statement: bill clinton suite was huge with two baths, a wonderful jacuzzi and a comfortable bed bed was very comfortable, as were the large pillows The room had a microwave, coffemaker, hairdryer, bottled water replenished each day (x) Aspect : Room Statement: the beds are the most comfortable of any hotel I have stayed in we were recommending it for our out of town wedding guests, and wanted to make sure they were comfortable (x)</p><p>It really is a shame because the bed and pillows were super comfortable and we could have had a great night sleep on both nights Aspect : Room Statement: the beds were comfortable and they had good selection of towels who would have imagined that somebody actually thought about where a guest would watch tv (x) They took regular sized hotel rooms and divided them into a sitting room with a bedroom with a door, keeping the bathroom to divide the two areas (x)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) Target Sentence with Single Aspect</head><p>Target Sentence: the check in was quick, with friendly polite service, and the room was very big with a very comfortable king size bed Supporting Sentences by SURF Supporting Sentences by Lucene Supporting Sentences by Word2Vec</p><p>Aspect : Room Statement: bed was extremely comfortable, I'm hard to please in the department because I sleep on a sleep number bed at home the room was a great size; bed was very comfortable The first room assigned was very small and dingy with one king sized bed that just fit (x)</p><p>Aspect : Room Statement: room size was large and bed was comfortable king size bed was comfy bathroom was well furnished with soap, shampoo/ conditioner, very large, soft towels -perfect (x) Aspect : Service Statement: service is very friendly our room faced denny park (x) the room was large and the bed very comfortable and our room faced the street and it was very quiet (b) Target Sentence with Multiple Aspects  standard deviation of the ratings for that aspect in the retrieved supporting reviews. We aggregate the standard deviation values for each aspect over all the reviews and look at the average value. <ref type="figure" target="#fig_3">Figure  5</ref> shows results for two aspects from the TripAdvi- sor dataset. Other aspects also had similar trends. We rank the retrieved results based on their sim- ilarity to the target sentence. Naturally, the longer the retrieved list, the larger is the average standard deviation. We see that SURF has a smaller av- erage standard deviation compared to Word2Vec and Lucene. The gap between the performance of SURF and the other methods also widens as the size of the retrieved results increases. This demonstrates SURF's superiority in retrieving re- views with similar opinions. <ref type="table" target="#tab_10">Table 10</ref> shows samples of supporting sentences extracted by the different methods. We observe that the sentences retrieved by SURF are seman- tically similar although the words may be quite different from the target sentence. In contrast, Lucene may retrieve irrelevant sentences match- ing a keyword used in a totally different context. Word2Vec considers words used in proximity of one another (e.g. bed, pillow with microwave, cof- femaker etc.) to be similar which clearly does not always imply conformity of opinions.</p><p>Furthermore, the retrieved results of SURF are categorized according to their aspects making them easy to interpret. Particularly if a target sen- tence has multiple aspects, then SURF will re- trieve results for each aspect. For example, for the second target sentence shown in <ref type="table" target="#tab_10">Table 10</ref>, the re- sults contain supporting statements for both room and service. If a user then wishes to view more re- sults for one of those aspects it will be possible for SURF to fetch more results only for that aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We studied the problem of finding supporting sen- tences to help a user get an idea of consensus about an entity. To this end, we developed a hier- archical topic model to jointly infer aspect-topic- sentiment, and a fine-grained similarity measure. Author-ATS model encodes the coherent writing style of a review by constraining the aspect dis- tributions dynamically. It considers the sentiment distribution of a review to have influence of both the author and the entity. Experimental results on two datasets indicate that the proposed approach is promising compared to existing techniques. With growing amount of user generated content on the web, and more people relying on them to make de- cisions, we believe that the ability to verify opin- ions will become increasingly important.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Constrained aspect generation in AuthorATS. Aspects in review form a Markov chain.</figDesc><graphic url="image-2.png" coords="3,318.90,62.81,195.02,113.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>a topic mixture θ from Dir (β) (e) For each word position i where 0 ≤ i ≤ N d i. Sample a type yi from ψ ii. Sample a topic zi from θ iii. Sample a sentiment si from χ and ξ iv. Sample a word wi from φ0 if yi = 0, φ1 if yi = 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Impact of varying number of seeds.</figDesc><graphic url="image-7.png" coords="7,425.14,601.91,100.40,61.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Average standard deviations of aspect ratings for supporting reviews. Smaller deviation implies greater coherence.</figDesc><graphic url="image-8.png" coords="9,72.05,306.93,215.43,97.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 3 lists the aspect seed words used for both domains.</head><label>3</label><figDesc></figDesc><table>Aspects 
Seed Words 

Value for Money 
value, rate, price 
Room 
room, bed, bathroom, clean 
Location 
location, walk, minute 
Service 
staff, reservation, front-desk 
Food 
restaurant, breakfast, buffet 
Amenities 
pool, parking, internet, wifi 

(a) TripAdvisor Dataset 

Aspects 
Seed Words 

Value for Money 
value, rate, portions, price 
Service 
ambience, wifi, music, service 
Food 
steak, rice, burger, cocktail 

(b) Yelp Dataset 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 : Sample Aspect Seed Words</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 5 : Domain stopwords from Author-ATS.</head><label>5</label><figDesc></figDesc><table>Aspect: Room 
Topic 0 
Positive 
Negative Neutral 
bed 
noise 
room 
comfortable night 
floor 
spacious 
sleep 
view 
king-size 
window size 
clean 
hear 
modern 
Topic 1 
Positive 
Negative Neutral 
bathroom 
small 
room 
large 
door 
bathroom 
tub 
barely 
shower 
shower 
tiny 
water 
shampoo 
kitchen 
towels 

Aspect: Service 
Topic 0 
Positive 
Negative Neutral 
staff 
night 
staff 
extremely greet 
call 
welcoming problem 
front-desk 
care 
asked 
service 
friendly 
manager shuttle 
Topic 1 
Positive 
Negative Neutral 
card 
called 
check-in 
reservation upgrade 
day 
airport 
manager arrived 
polite 
rude 
directions 
excellent 
questions time 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 7 : Average precision using CJSD</head><label>7</label><figDesc></figDesc><table>TripAdvisor 
Yelp 
p@5 p@10 p@20 p@5 p@10 p@20 
ATS 
0.69 0.62 
0.58 
0.62 0.59 
0.58 
Author-ATS 
0.74 0.66 
0.60 
0.68 0.64 
0.62 
Author-ATS (DP) 0.64 0.63 
0.57 
0.62 0.56 
0.54 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Average precision using LSS 

Next, we compare SURF with the following: 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 9 : Comparison with Lucene and Word2Vec</head><label>9</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 10 :</head><label>10</label><figDesc></figDesc><table>Sample Supporting Sentences Retrieved by SURF, Lucene and Word2Vec. Aspects shown for 
SURF are discovered by Author-ATS model. 

</table></figure>

			<note place="foot" n="1"> http://www.ranks.nl/stopwords 2 http://mpqa.cs.pitt.edu/lexicons/subj lexicon</note>

			<note place="foot" n="3"> https://code.google.com/archive/p/word2vec/</note>
		</body>
		<back>
			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploiting domain knowledge in aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meichun</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malu</forename><surname>Castellanos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riddhiman</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sequential latent dirichlet allocation: Discover underlying topic structures within a document</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wray</forename><surname>Buntine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huidong</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE ICDM</title>
		<meeting>of IEEE ICDM</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Topic segmentation with an ordering-based topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>John K Pate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AAAI</title>
		<meeting>of AAAI</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
