<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exploiting Deep Representations for Neural Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi-Yi</forename><surname>Dou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Tencent AI Lab</orgName>
								<orgName type="department" key="dep2">Tencent AI Lab</orgName>
								<orgName type="department" key="dep3">Tencent AI Lab</orgName>
								<orgName type="department" key="dep4">Tencent AI Lab</orgName>
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
							<email>zptu@tencent.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Tencent AI Lab</orgName>
								<orgName type="department" key="dep2">Tencent AI Lab</orgName>
								<orgName type="department" key="dep3">Tencent AI Lab</orgName>
								<orgName type="department" key="dep4">Tencent AI Lab</orgName>
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Tencent AI Lab</orgName>
								<orgName type="department" key="dep2">Tencent AI Lab</orgName>
								<orgName type="department" key="dep3">Tencent AI Lab</orgName>
								<orgName type="department" key="dep4">Tencent AI Lab</orgName>
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Shi</surname></persName>
							<email>shumingshi@tencent.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Tencent AI Lab</orgName>
								<orgName type="department" key="dep2">Tencent AI Lab</orgName>
								<orgName type="department" key="dep3">Tencent AI Lab</orgName>
								<orgName type="department" key="dep4">Tencent AI Lab</orgName>
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Tencent AI Lab</orgName>
								<orgName type="department" key="dep2">Tencent AI Lab</orgName>
								<orgName type="department" key="dep3">Tencent AI Lab</orgName>
								<orgName type="department" key="dep4">Tencent AI Lab</orgName>
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Exploiting Deep Representations for Neural Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="4253" to="4262"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>4253</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Advanced neural machine translation (NMT) models generally implement encoder and de-coder as multiple layers, which allows systems to model complex functions and capture complicated linguistic structures. However, only the top layers of encoder and decoder are leveraged in the subsequent process, which misses the opportunity to exploit the useful information embedded in other layers. In this work, we propose to simultaneously expose all of these signals with layer aggregation and multi-layer attention mechanisms. In addition , we introduce an auxiliary regularization term to encourage different layers to capture diverse information. Experimental results on widely-used WMT14 English⇒German and WMT17 Chinese⇒English translation data demonstrate the effectiveness and universality of the proposed approach.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural machine translation (NMT) models have advanced the machine translation community in recent years ( <ref type="bibr" target="#b12">Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b5">Cho et al., 2014;</ref><ref type="bibr" target="#b23">Sutskever et al., 2014</ref>). NMT models generally consist of two components: an encoder network to summarize the input sentence into sequential representations, based on which a decoder network generates target sentence word by word with an attention model ( <ref type="bibr" target="#b2">Bahdanau et al., 2015;</ref><ref type="bibr" target="#b15">Luong et al., 2015)</ref>.</p><p>Nowadays, advanced NMT models generally implement encoder and decoder as multiple lay- ers, regardless of the specific model architectures such as RNN ( <ref type="bibr">Zhou et al., 2016;</ref><ref type="bibr" target="#b27">Wu et al., 2016)</ref>, <ref type="bibr">CNN (Gehring et al., 2017)</ref>, or Self-Attention Net- work ( <ref type="bibr" target="#b26">Vaswani et al., 2017;</ref>. * Zhaopeng Tu is the corresponding author of the paper. This work was conducted when Zi-Yi Dou was interning at Tencent AI Lab. Several researchers have revealed that different layers are able to capture different types of syntax and semantic information ( <ref type="bibr" target="#b22">Shi et al., 2016;</ref><ref type="bibr" target="#b18">Peters et al., 2018;</ref><ref type="bibr" target="#b0">Anastasopoulos and Chiang, 2018)</ref>. For example, <ref type="bibr" target="#b22">Shi et al. (2016)</ref> find that both local and global source syntax are learned by the NMT encoder and different types of syntax are captured at different layers.</p><p>However, current NMT models only leverage the top layers of encoder and decoder in the sub- sequent process, which misses the opportunity to exploit useful information embedded in other lay- ers. Recently, aggregating layers to better fuse se- mantic and spatial information has proven to be of profound value in computer vision tasks <ref type="bibr" target="#b11">(Huang et al., 2017;</ref><ref type="bibr">Yu et al., 2018)</ref>. In natural language processing community, <ref type="bibr" target="#b18">Peters et al. (2018)</ref> have proven that simultaneously exposing all layer rep- resentations outperforms methods that utilize just the top layer for transfer learning tasks.</p><p>Inspired by these findings, we propose to exploit deep representations for NMT models. Specifically, we investigate two types of strate- gies to better fuse information across layers, rang- ing from layer aggregation to multi-layer atten- tion. While layer aggregation strategies combine hidden states at the same position across different layers, multi-layer attention allows the model to combine information in different positions. In ad- dition, we introduce an auxiliary objective to en- courage different layers to capture diverse infor- mation, which we believe would make the deep representations more meaningful.</p><p>We evaluated our approach on two widely- used WMT14 English⇒German and WMT17 Chinese⇒English translation tasks. We employed TRANSFORMER ( <ref type="bibr" target="#b26">Vaswani et al., 2017</ref>) as the baseline system since it has proven to outper- form other architectures on the two tasks ( <ref type="bibr" target="#b26">Vaswani et al., 2017;</ref><ref type="bibr" target="#b9">Hassan et al., 2018)</ref>. Experimen-tal results show that exploiting deep represen- tations consistently improves translation perfor- mance over the vanilla TRANSFORMER model across language pairs. It is worth mention- ing that TRANSFORMER-BASE with deep rep- resentations exploitation outperforms the vanilla TRANSFORMER-BIG model with only less than half of the parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background: Deep NMT</head><p>Deep representations have proven to be of pro- found value in machine translation ( <ref type="bibr" target="#b16">Meng et al., 2016;</ref><ref type="bibr">Zhou et al., 2016)</ref>. Multiple-layer encoder and decoder are employed to perform the transla- tion task through a series of nonlinear transforma- tions from the representation of input sequences to final output sequences. The layer can be imple- mented as RNN ( <ref type="bibr" target="#b27">Wu et al., 2016)</ref>, <ref type="bibr">CNN (Gehring et al., 2017)</ref>, or Self-Attention Network ( <ref type="bibr" target="#b26">Vaswani et al., 2017)</ref>. In this work, we take the advanced Transformer as an example, which will be used in experiments later. However, we note that the proposed approach is generally applicable to any other type of NMT architectures.</p><p>Specifically, the encoder is composed of a stack of L identical layers, each of which has two sub- layers. The first sub-layer is a self-attention net- work, and the second one is a position-wise fully connected feed-forward network. A residual con- nection ( <ref type="bibr" target="#b10">He et al., 2016</ref>) is employed around each of the two sub-layers, followed by layer normal- ization ( <ref type="bibr">Ba et al., 2016)</ref>. Formally, the output of the first sub-layer C l e and the second sub-layer H l e are calculated as</p><formula xml:id="formula_0">C l e = LN ATT(Q l e , K l−1 e , V l−1 e ) + H l−1 e , H l e = LN FFN(C l e ) + C l e ,<label>(1)</label></formula><p>where ATT(·), LN(·), and FFN(·) are self- attention mechanism, layer normalization, and feed-forward networks with ReLU activation in between, respectively. {Q l e , K l−1 e , V l−1 e } are query, key and value vectors that are transformed from the (l-1)-th encoder layer H l−1 e . The decoder is also composed of a stack of L identical layers. In addition to two sub-layers in each decoder layer, the decoder inserts a third sub- layer D l d to perform attention over the output of the encoder stack H L e :</p><formula xml:id="formula_1">C l d = LN ATT(Q l d , K l−1 d , V l−1 d ) + H l−1 d , D l d = LN ATT(C l d , K L e , V L e ) + C l d , H l d = LN FFN(D l d ) + D l d ,<label>(2)</label></formula><p>where Multi-layer network can be considered as a strong feature extractor with extended receptive fields capable of linking salient features from the entire sequence ). However, one potential problem about the vanilla Transformer, as shown in <ref type="figure" target="#fig_1">Figure 1a</ref>, is that both the encoder and decoder stack layers in sequence and only uti- lize the information in the top layer. While stud- ies have shown deeper layers extract more seman- tic and more global features <ref type="bibr">(Zeiler and Fergus, 2014;</ref><ref type="bibr" target="#b18">Peters et al., 2018</ref>), these do not prove that the last layer is the ultimate representation for any task. Although residual connections have been in- corporated to combine layers, these connections have been "shallow" themselves, and only fuse by simple, one-step operations ( <ref type="bibr">Yu et al., 2018)</ref>. We investigate here how to better fuse information across layers for NMT models.</p><formula xml:id="formula_2">{Q l d , K l−1 d , V l−1 d } are</formula><p>In the following sections, we simplify the equa- tions to H l = LAYER(H l−1 ) for brevity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Approaches</head><p>In this section, we first introduce how to exploit deep representations by simultaneously exposing all of the signals from all layers (Sec 3.1). Then, to explicitly encourage different layers to incor- porate various information, we propose one way to measure the diversity between layers and add a regularization term to our objective function to maximize the diversity across layers (Sec 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Deep Representations</head><p>To exploit deep representations, we investigate two types of strategies to fuse information across layers, from layer aggregation to multi-layer atten- tion. While layer aggregation strategies combine hidden states at the same position across different layers, multi-layer attention allows the model to combine information in different positions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Layer Aggregation</head><p>While the aggregation strategies are inspired by previous work, there are several differences since we have simplified and generalized from the orig- inal model, as described below. Dense Connection. The first strategy is to allow all layers to directly access previous layers:</p><formula xml:id="formula_3">H l = f (H 1 , . . . , H l−1 ).<label>(3)</label></formula><p>In this work, we mainly investigate whether densely connected networks work for NMT, which have proven successful in computer vision tasks ( <ref type="bibr" target="#b11">Huang et al., 2017</ref>). The basic strategy of densely connected networks is to connect each layer to every previous layer with a residual con- nection: <ref type="figure" target="#fig_1">Figure 1b</ref> illustrates the idea of this approach. Our implementation differs from ( <ref type="bibr" target="#b11">Huang et al., 2017</ref>) in that we use an addition instead of a concatena- tion operation in order to keep the state size con- stant. Another reason is that concatenation oper- ation is computationally expensive, while residual connections are more efficient.</p><formula xml:id="formula_4">H l = Layer(H l−1 ) + l−1 i=1 H i .<label>(4)</label></formula><p>While dense connection directly feeds previ- ous layers to the subsequent layers, the following mechanisms maintain additional layers to aggre- gate standard layers, from shallow linear combi- nation, to deep non-linear aggregation.</p><p>Linear Combination. As shown in <ref type="figure" target="#fig_1">Figure 1c</ref>, an intuitive strategy is to linearly combine the out- puts of all layers:</p><formula xml:id="formula_5">H = L l=1 W l H l ,<label>(5)</label></formula><p>where</p><formula xml:id="formula_6">{W 1 , . . . , W L } are trainable matrices.</formula><p>While the strategy is similar in spirit to ( <ref type="bibr" target="#b18">Peters et al., 2018)</ref>, there are two main differences: (1) they use normalized weights while we directly use parameters that could be either positive or negative numbers, which may benefit from more modeling flexibility. (2) they use a scalar that is shared by all elements in the layer states, while we use learnable matrices. The latter offers a more precise control of the combination by allowing the model to be more expressive than scalars ( <ref type="bibr" target="#b24">Tu et al., 2017</ref>).</p><p>We also investigate strategies that iteratively and hierarchically merge layers by incorporating more depth and sharing, which have proven effec- tive for computer vision tasks ( <ref type="bibr">Yu et al., 2018</ref>).</p><p>Iterative Aggregation. As illustrated in <ref type="figure" target="#fig_1">Figure  1d</ref>, iterative aggregation follows the iterated stack- ing of the backbone architecture. Aggregation be- gins at the shallowest, smallest scale and then it- eratively merges deeper, larger scales. The itera- tive deep aggregation function I for a series of lay- ers H l 1 = {H 1 , · · · , H l } with increasingly deeper and semantic information is formulated as</p><formula xml:id="formula_7">H l = I(H l 1 ) = AGG(H l , H l−1 ),<label>(6)</label></formula><p>where we set</p><formula xml:id="formula_8">H 1 = H 1 and AGG(·, ·) is the ag- gregation function:</formula><p>AGG(x, y) = LN(FF( <ref type="bibr">[x; y]</ref>) + x + y).</p><p>As seen, in this work, we first concatenate x and y into z = [x; y], which is subsequently fed to a feed-forward network with a sigmoid activation in between. Residual connection and layer nor- malization are also employed. Specifically, both x and y have residual connections to the output. The choice of the aggregation function will be further studied in the experiment section. Hierarchical Aggregation. While iterative ag- gregation deeply combines states, it may still be insufficient to fuse the layers for its sequential ar- chitecture. Hierarchical aggregation, on the other hand, merges layers through a tree structure to preserve and combine feature channels, as shown in <ref type="figure" target="#fig_2">Figure 2</ref>. The original model proposed by <ref type="bibr">Yu et al. (2018)</ref> requires the number of layers to be the power of two, which limits the applicability of these methods to a broader range of NMT archi- tectures (e.g. six layers in ( <ref type="bibr" target="#b26">Vaswani et al., 2017)</ref>).</p><p>To solve this problem, we introduce a CNN-like tree with the filter size being two, as shown in , we first merge aggregation nodes of the same depth for efficiency so that there would be at most one aggregation node for each depth. Then, we further feed the output of an aggregation node back into the back- bone as the input to the next sub-tree, instead of only routing intermediate aggregations further up the tree, as shown in <ref type="figure" target="#fig_2">Figure 2b</ref>. The interaction between aggregation and backbone nodes allows the model to better preserve features. Formally, each aggregation node H i is calcu- lated as</p><formula xml:id="formula_10">H i = AGG(H 2i−1 , H 2i ), i = 1 AGG(H 2i−1 , H 2i , H i−1 ), i = 2, 3</formula><p>where AGG(H 2i−1 , H 2i ) is computed via Eqn. 7, and AGG(</p><formula xml:id="formula_11">H 2i−1 , H 2i , H i−1 ) is computed as AGG(x, y, z) = LN(FF([x; y; z]) + x + y + z).</formula><p>The aggregation node at the top layer H L/2 serves as the final output of the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Multi-Layer Attention</head><p>Partially inspired by <ref type="bibr" target="#b16">Meng et al. (2016)</ref>, we also propose to introduce a multi-layer attention mech- anism into deep NMT models, for more power of Figure 3: Multi-layer attention allows the model to attend multiple layers to construct each hid- den state. We use two-layer attention for illustra- tion, while the approach is applicable to any layers lower than l.</p><p>transforming information across layers. In other words, for constructing each hidden state in any layer-l, we allow the self-attention model to attend any layers lower than l, instead of just layer l-1:</p><formula xml:id="formula_12">C l −1 = ATT(Q l , K l−1 , V l−1 ), C l −2 = ATT(Q l , K l−2 , V l−2 ), . . . C l −k = ATT(Q l , K l−k , V l−k ), C l = AGG(C l −1 , . . . , C l −k ),<label>(8)</label></formula><p>where C l −i is sequential vectors queried from layer l-i using a separate attention model, and AGG(·) is similar to the pre-defined aggregation function to transform k vectors {C l −1 , . . . , C l −k } to a d-dimension vector, which is subsequently used to construct the encoder and decoder layers via Eqn. 1 and 2 respectively. Note that multi- layer attention only modifies the self-attention blocks in both encoder and decoder, while does not revises the encoder-decoder attention blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Layer Diversity</head><p>Intuitively, combining layers would be more meaningful if different layers are able to capture diverse information. Therefore, we explicitly add a regularization term to encourage the diversities between layers:</p><formula xml:id="formula_13">L = L likelihood + λL diversity ,<label>(9)</label></formula><p>where λ is a hyper-parameter and is set to 1.0 in this paper. Specifically, the regularization term measures the average of the distance between ev-ery two adjacent layers:</p><formula xml:id="formula_14">L diversity = 1 L − 1 L−1 l=1 D(H l , H l+1 ). (10)</formula><p>Here D(H l , H l+1 ) is the averaged cosine-squared distance between the states in layers</p><formula xml:id="formula_15">H l = {h l 1 , . . . , h l N } and H l+1 = {h l+1 1 , . . . , h l+1 N }: D(H l , H l+1 ) = 1 N N n=1 (1 − cos 2 (h l n , h l+1 n )).</formula><p>The cosine-squared distance between two vectors is maximized when two vectors are linearly inde- pendent and minimized when two vectors are lin- early dependent, which satisfies our goal. 1 For the Zh⇒En task, we used all of the avail- able parallel data with maximum length limited to 50, consisting of about 20.62 million sentence pairs. We used newsdev2017 as the develop- ment set and newstest2017 as the test set. For the En⇒De task, we trained on the widely-used WMT14 dataset consisting of about 4.56 million sentence pairs. We used newstest2013 as the de- velopment set and newstest2014 as the test set. Byte-pair encoding (BPE) was employed to al- leviate the Out-of-Vocabulary problem (Sennrich et al., 2016) with 32K merge operations for both language pairs. We used 4-gram NIST BLEU score ( <ref type="bibr" target="#b17">Papineni et al., 2002</ref>) as the evaluation met- ric, and sign-test <ref type="bibr" target="#b6">(Collins et al., 2005</ref>) to test for statistical significance.</p><p>Models. We evaluated the proposed approaches on advanced Transformer model ( <ref type="bibr" target="#b26">Vaswani et al., 2017)</ref>, and implemented on top of an open-source toolkit -THUMT ( <ref type="bibr">Zhang et al., 2017</ref>). We fol- lowed <ref type="bibr" target="#b26">Vaswani et al. (2017)</ref> to set the configura- tions and train the models, and have reproduced their reported results on the En⇒De task. The pa- rameters of the proposed models were initialized by the pre-trained model. We tried k = 2 and k = 3 for the multi-layer attention model, which allows to attend to the lower two or three layers. We have tested both Base and Big models, which differ at hidden size (512 vs. 1024), filter size (2048 vs. 4096) and the number of attention heads (8 vs. 16). <ref type="bibr">2</ref> All the models were trained on eight NVIDIA P40 GPUs where each was al- located with a batch size of 4096 tokens. In con- sideration of computation cost, we studied model variations with Base model on En⇒De task, and evaluated overall performance with Big model on both Zh⇒En and En⇒De tasks. <ref type="table">Table 1</ref> shows the results on WMT14 En⇒De translation task. As seen, the proposed approaches improve the translation quality in all cases, al- though there are still considerable differences among different variations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Model Complexity Except for dense connec- tion, all other deep representation strategies in- troduce new parameters, ranging from 14.7M to 33.6M. Accordingly, the training speed decreases due to more efforts to train the new parameters. Layer aggregation mechanisms only marginally decrease decoding speed, while multi-layer atten- tion decreases decoding speed by 21% due to an additional attention process for each layer.</p><p>Layer Aggregation (Rows 2-5): Although dense connection and linear combination only marginally improve translation performance, it- erative and hierarchical aggregation strategies achieve more significant improvements, which are up to +0.99 BLEU points better than the baseline model. This indicates that deep aggregations out- perform their shallow counterparts by incorporat- ing more depth and sharing, which is consistent with the results in computer vision tasks ( <ref type="bibr">Yu et al., 2018</ref>).</p><p>Multi-Layer Attention (Rows 6-7): Benefiting from the power of attention models, multi-layer attention model can also significantly outperform baseline, although it only attends to one or two additional layers. However, increasing the num- ber of lower layers to be attended from k = 2 to  <ref type="table">Table 1</ref>: Evaluation of translation performance on WMT14 English⇒German ("En⇒De") translation task. "# Para." denotes the number of parameters, and "Train" and "Decode" respectively denote the training speed (steps/second) and decoding speed (sentences/second) on Tesla P40.  Main Results <ref type="table" target="#tab_3">Table 2</ref> lists the results on both WMT17 Zh⇒En and WMT14 En⇒De transla- tion tasks. As seen, exploiting deep represen- tations consistently improves translation perfor- mance across model variations and language pairs, demonstrating the effectiveness and universality of the proposed approach. It is worth mention- ing that TRANSFORMER-BASE with deep rep- resentations exploitation outperforms the vanilla TRANSFORMER-BIG model, with only less than half of the parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis</head><p>We conducted extensive analysis from different perspectives to better understand our model. All results are reported on the En⇒De task with TRANSFORMER-BASE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>e Length</head><p>Source Sentence Hier.+Div. Hier. Base <ref type="figure">Figure 4</ref>: BLEU scores on the En⇒De test set with respect to various input sentence lengths. "Hier." denotes hierarchical aggregation and "Div." de- notes diversity regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Length Analysis</head><p>Following <ref type="bibr" target="#b2">Bahdanau et al. (2015)</ref> and , we grouped sentences of similar lengths together and computed the BLEU score for each group, as shown in <ref type="figure">Figure 4</ref>. Generally, the per- formance of TRANSFORMER-BASE goes up with the increase of input sentence lengths, which is superior to the performance of RNN-based NMT models on long sentences reported by <ref type="bibr" target="#b3">(Bentivogli et al., 2016</ref>). We attribute this to the strength of self-attention mechanism to model global depen- dencies without regard to their distance. Clearly, the proposed approaches outperform the baseline model in all length segments, while there are still considerable differences between the two variations. Hierarchical aggregation consis- tently outperforms the baseline model, and the im- provement goes up on long sentences. One pos- sible reason is that long sentences indeed require deep aggregation mechanisms. Introducing diver- sity regularization further improves performance on most sentences (e.g. ≤ 45), while the improve- ment degrades on long sentences (e.g. &gt; 45). We conjecture that complex long sentences may need to store duplicate information across layers, which conflicts with the diversity objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Effect on Encoder and Decoder</head><p>Both encoder and decoder are composed of a stack of L layers, which may benefit from the proposed approach. In this experiment, we investigated how our models affect the two components, as shown  in <ref type="table" target="#tab_5">Table 3</ref>. Exploiting deep representations of encoder or decoder individually consistently out- performs the vanilla baseline model, and exploit- ing both components further improves the perfor- mance. These results provide support for the claim that exploiting deep representations is useful for both understanding input sequence and generating output sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Impact of Aggregation Choices</head><p>Model  <ref type="table">Table 4</ref>: Impact of residual connections and aggre- gation functions for hierarchical layer aggregation.</p><p>As described in Section 3.1.1, the function of hierarchical layer aggregation is defined as</p><formula xml:id="formula_16">AGG(x, y, z) = LN(FF([x; y; z]) + x + y + z),</formula><p>where FF(·) is a feed-forward network with a sig- moid activation in between. In addition, all the input layers {x, y, z} have residual connections to the output. In this experiment, we evaluated the impact of residual connection options, as well as different choices for the aggregation function, as shown in <ref type="table">Table 4</ref>.</p><p>Concerning residual connections, if none of the input layers are connected to the output layer ("None"), the performance would decrease. The translation performance is improved when the out- put is connected to only the top level of the input layers ("Top"), while connecting to all input layers ("All") achieves the best performance. This indi-cates that cross-layer connections are necessary to avoid the gradient vanishing problem.</p><p>Besides the feed-forward network with sigmoid activation, we also tried two other aggregation functions for FF(·): (1) A feed-forward network with a RELU activation in between; and (2) multi- head self-attention layer that constitutes the en- coder and decoder layers in the TRANSFORMER model. As seen, all the three functions consis- tently improve the translation performance, prov- ing the robustness of the proposed approaches.  H i denotes the i-th aggrega- tion layer, and H i denotes the i-th encoder layer. The rightmost and topmost position in x-axis and y-axis respectively represent the highest layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Visualization of Aggregation</head><p>To investigate the impact of diversity regular- ization, we visualized the exploitation of the in- put representations for hierarchical aggregation in encoder side, as shown in <ref type="figure" target="#fig_7">Figure 5</ref>. Let H i = {H 2i , H 2i−1 , H i−1 } be the input representations, we calculated the exploitation of the j-th input as</p><formula xml:id="formula_17">s j = w∈W j |w| H j ∈H { w ∈W j |w |} ,<label>(11)</label></formula><p>where W j is the parameter matrix associated with the input H j . The score s j is a rough estimation of the contribution of H j to the aggregation H i . We have two observations. First, the model tends to utilize the bottom layer more than the top one, indicating the necessity of fusing information across layers. Second, using the diversity regu- larization in <ref type="figure" target="#fig_7">Figure 5</ref>(b) can encourage each layer to contribute more equally to the aggregation. We hypothesize this is because of the diversity regu- larization term encouraging the different layers to contain diverse and equally important information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Representation learning is at the core of deep learning. Our work is inspired by technological advances in representation learning, specifically in the field of deep representation learning and rep- resentation interpretation.</p><p>Deep Representation Learning Deep neural networks have advanced the state of the art in var- ious communities, such as computer vision and natural language processing. One key challenge of training deep networks lies in how to transform information across layers, especially when the net- work consists of hundreds of layers.</p><p>In response to this problem, ResNet (He et al., 2016) uses skip connections to combine layers by simple, one-step operations. Densely connected network ( <ref type="bibr" target="#b11">Huang et al., 2017</ref>) is designed to better propagate features and losses through skip con- nections that concatenate all the layers in stages. <ref type="bibr">Yu et al. (2018)</ref> design structures iteratively and hierarchically merge the feature hierarchy to bet- ter fuse information in a deep fusion.</p><p>Concerning machine translation, <ref type="bibr" target="#b16">Meng et al. (2016)</ref> and <ref type="bibr">Zhou et al. (2016)</ref> have shown that deep networks with advanced connecting strate- gies outperform their shallow counterparts. Due to its simplicity and effectiveness, skip connection becomes a standard component of state-of-the-art NMT models ( <ref type="bibr" target="#b27">Wu et al., 2016;</ref><ref type="bibr" target="#b8">Gehring et al., 2017;</ref><ref type="bibr" target="#b26">Vaswani et al., 2017)</ref>. In this work, we prove that deep representation exploitation can further improve performance over simply using skip con- nections.</p><p>Representation Interpretation Several re- searchers have tried to visualize the representation of each layer to help better understand what information each layer captures <ref type="bibr">(Zeiler and Fergus, 2014;</ref><ref type="bibr" target="#b7">Ding et al., 2017)</ref>. Concerning natural language processing tasks, <ref type="bibr" target="#b22">Shi et al. (2016)</ref> find that both local and global source syntax are learned by the NMT encoder and different types of syntax are captured at different layers. <ref type="bibr" target="#b0">Anastasopoulos and Chiang (2018)</ref> show that higher level layers are more representative than lower level layers. <ref type="bibr" target="#b18">Peters et al. (2018)</ref> demonstrate that higher-level layers cap- ture context-dependent aspects of word meaning while lower-level layers model aspects of syntax. Inspired by these observations, we propose to expose all of these representations to better fuse information across layers. In addition, we introduce a regularization to encourage different layers to capture diverse information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we propose to better exploit deep representations that are learned by multiple lay- ers for neural machine translation.</p><p>Specif- ically, the hierarchical aggregation with di- versity regularization achieves the best perfor- mance by incorporating more depth and shar- ing across layers and by encouraging layers to capture different information. Experimental re- sults on WMT14 English⇒German and WMT17 Chinese⇒English show that the proposed ap- proach consistently outperforms the state-of-the- art TRANSFORMER baseline by +0.54 and +0.63 BLEU points, respectively. By visualizing the ag- gregation process, we find that our model indeed utilizes lower layers to effectively fuse the infor- mation across layers.</p><p>Future directions include validating our ap- proach on other architectures such as RNN (Bah- danau et al., 2015) or CNN ( <ref type="bibr" target="#b8">Gehring et al., 2017</ref>) based NMT models, as well as combining with other advanced techniques ( <ref type="bibr" target="#b20">Shaw et al., 2018;</ref><ref type="bibr" target="#b21">Shen et al., 2018;</ref> to further improve the performance of TRANS- FORMER.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>transformed from the (l-1)-th decoder layer H l−1 d , and {K L e , V L e } are transformed from the top layer of the encoder. The top layer of the decoder H L d is used to gener- ate the final output sequence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of (a) vanilla model without any aggregation and (b,c,d) layer aggregation strategies. Aggregation nodes are represented by green circles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Hierarchical aggregation (b) that aggregates layers through a tree structure (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig- ure 2a. Following (Yu et al., 2018)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Visualization of the exploitation of input representations for hierarchical aggregation. xaxis is the aggregation node and y-axis is the input representation. H i denotes the i-th aggregation layer, and H i denotes the i-th encoder layer. The rightmost and topmost position in x-axis and y-axis respectively represent the highest layer.</figDesc><graphic url="image-8.png" coords="8,100.34,273.96,64.03,64.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Comparing with existing NMT systems on WMT14 English⇒German and WMT17 
Chinese⇒English tasks. "+ Deep Representations" denotes "+ Hierarchical Aggregation + L diversity ". 
" †" indicates statistically significant difference (p &lt; 0.01) from the TRANSFORMER baseline. 

k = 3 only gains marginal improvement, at the 
cost of slower training and decoding speeds. In 
the following experiments, we set set k = 2 for 
the multi-layer attention model. 

Layer Diversity (Rows 8-10): The introduced 
diversity regularization consistently improves per-
formance in all cases by encouraging different 
layers to capture diverse information. Our best 
model outperforms the vanilla Transformer by 
+1.14 BLEU points. In the following experiments, 
we used hierarchical aggregation with diversity 
regularization (Row 8) as the default strategy. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Experimental results of applying hier-
archical aggregation to different components on 
En⇒De validation set. 

</table></figure>

			<note place="foot" n="1"> We use cosine-squared distance instead of cosine distance, since the latter is maximized when two vectors are in opposite directions. In such case, the two vectors are in fact linearly dependent, while we aim at encouraging the vectors independent from each other.</note>

			<note place="foot" n="2"> Here &quot;filter size&quot; refers to the hidden size of the feedforward network in the Transformer model.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their in-sightful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tied multitask learning for neural speech translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint/>
	</monogr>
<note type="report_type">ton. 2016. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural versus phrasebased machine translation quality: a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arianna</forename><surname>Bisazza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Mia Xu Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goerge</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parmar</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Niki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Macduff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hughes</surname></persName>
		</author>
		<title level="m">The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation. In ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Clause restructuring for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivona</forename><surname>Kucerova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visualizing and understanding neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanzhuo</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Convolutional sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann N</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Achieving human parity on automatic chinese to english news translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Aue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Chowdhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05567</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recurrent continuous translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-head attention with disagreement regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baosong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Convergent learning: Do different neural networks learn the same representations? In ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hod</forename><surname>Lipson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">E</forename><surname>Hopcroft</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A deep memory-based architecture for sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Self-Attention with Relative Position Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">DiSAN: directional self-attention network for RNN/CNN-free language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Does string-based neural mt learn source syntax? In EMNLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkit</forename><surname>Padhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Context gates for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Modeling coverage for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
	</analytic>
	<monogr>
		<title level="m">Bridging the gap between human and machine translation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Modeling localness for self-attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baosong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidia</forename><forename type="middle">S</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
