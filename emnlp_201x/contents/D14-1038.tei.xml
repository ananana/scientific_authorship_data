<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ReNoun: Fact Extraction for Nominal Attributes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
							<email>myahya@mpi-inf.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">Euijong</forename><surname>Whang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Halevy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Research</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ReNoun: Fact Extraction for Nominal Attributes</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="325" to="335"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Search engines are increasingly relying on large knowledge bases of facts to provide direct answers to users&apos; queries. However , the construction of these knowledge bases is largely manual and does not scale to the long and heavy tail of facts. Open information extraction tries to address this challenge, but typically assumes that facts are expressed with verb phrases, and therefore has had difficulty extracting facts for noun-based relations. We describe ReNoun, an open information extraction system that complements previous efforts by focusing on nominal attributes and on the long tail. ReNoun&apos;s approach is based on leveraging a large on-tology of noun attributes mined from a text corpus and from user queries. ReNoun creates a seed set of training data by using specialized patterns and requiring that the facts mention an attribute in the ontol-ogy. ReNoun then generalizes from this seed set to produce a much larger set of extractions that are then scored. We describe experiments that show that we extract facts with high precision and for attributes that cannot be extracted with verb-based techniques .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One of the major themes driving the current evo- lution of search engines is to make the search experience more efficient and mobile friendly for users by providing them concrete answers to queries. These answers, that apply to queries about entities that the search engine knows about (e.g., famous individuals, organizations or loca- tions) complement the links that the search en- * Work done during an internship at Google Research.</p><p>gine typically returns <ref type="bibr">(Sawant and Chakrabati, 2013;</ref><ref type="bibr" target="#b20">Singhal, 2012;</ref><ref type="bibr" target="#b22">Yahya et al., 2012</ref>). To support such answers, the search engine main- tains a knowledge base that describes various at- tributes of an entity (e.g., <ref type="bibr">(Nicolas Sarkozy, wife, Carla Bruni)</ref>). Upon receiving a query, the search engine tries to recognize whether the answer is in its knowledge base.</p><p>For the most part, the aforementioned knowl- edge bases are constructed using manual tech- niques and carefully supervised information ex- traction algorithms. As a result, they obtain high coverage on head attributes, but low coverage on tail ones, such as those shown in <ref type="table">Table 1</ref>. For ex- ample, they may have the answer for the query "Sarkozy's wife", but not for "Hollande's ex- girlfriend" or "Google's philanthropic arm". In addition to broadening the scope of query answer- ing, extending the coverage of the knowledge base to long tail attributes can also facilitate providing Web answers to the user. Specifically, the search engine can use lower-confidence facts to corrob- orate an answer that appears in text in one of the top Web results and highlight them to the user. This paper describes ReNoun, an open- information extraction system that focuses on ex- tracting facts for long tail attributes. The obser- vation underlying our approach is that attributes from the long tail are typically expressed as nouns, whereas most previous work on open-information extraction (e.g., <ref type="bibr" target="#b11">Mausam et al. (2012)</ref>) extend techniques for extracting attributes expressed in verb form. Hence, the main contribution of our work is to develop an extraction system that com- plements previous efforts, focuses on nominal at- tributes and is effective for the long tail. To that end, ReNoun begins with a large but imperfect on- tology of nominal attributes that is extracted from text and the query stream ( <ref type="bibr" target="#b7">Gupta et al., 2014)</ref>. ReNoun proceeds by using a small set of high- precision extractors that exploit the nominal na-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attribute</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fact</head><p>Phrase Verb form seen legal affairs (NPR, legal affairs NPR welcomed Nina Totenberg as correspondent correspondent, Nina Totenberg) its new legal affairs correspondent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>economist (Princeton, economist, Princeton economist Paul Krugman</head><p>Paul Krugman) was awarded the Nobel prize in 2008.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ex-boyfriend (Trierweiler, ex-boyfriend, Trierweiler did not have any children</head><p>Hollande with her ex-boyfriend Hollande.</p><p>staff writer (The New Yorker, staff writer, Adam Gopnik is one of The New</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adam Gopnik)</head><p>Yorker's best staff writers. <ref type="table">Table 1</ref>: Examples of noun phrases as attributes, none which are part of a verb phrase. Additionally, the first two attributes do not occur within a verb phrase in a large corpus (see § 2 for details) in a setting where they can be associated with a triple.</p><p>ture of the attributes to obtain a training set, and then generalizes from the training set via distant supervision to find a much larger set of extraction patterns. Finally, ReNoun scores extracted facts by considering how frequently their patterns ex- tract triples and the coherence of these patterns, i.e., whether they extract triples for semantically similar attributes. Our experiments demonstrate that ReNoun extracts a large body of high preci- sion facts, and that these facts are not extracted with techniques based on verb phrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>The goal of ReNoun is to extract triples of the form (S,A,O), where S is subject, A is the attribute, and O is the object. In our setting, the attribute is al- ways a noun phrase. We refer to the subject and object as the arguments of the attribute.</p><p>ReNoun takes as input a set of attributes, which can be collected using the methods described in <ref type="bibr">Gupta el al. (2014)</ref>, <ref type="bibr">Lee et al. (2012)</ref>, and Pasca and van <ref type="bibr" target="#b18">Durme (2007)</ref>. In this work, we use Biper- pedia ( <ref type="bibr" target="#b7">Gupta et al., 2014)</ref>, which is an ontology of nominal attributes automatically extracted from Web text and user queries. For every attribute, Biperpedia supplies the Freebase ( <ref type="bibr" target="#b2">Bollacker et al., 2008</ref>) domain type (e.g., whether the attribute ap- plies to people, organizations or hotels). Since the attributes themselves are the result of an extraction algorithm, they may include false positives (i.e., attributes that do not make sense).</p><p>The focus of ReNoun is on attributes whose val- ues are concrete objects (e.g., wife, protege, chief-economist). Other classes of attributes that we do not consider in this work are (1) nu- meric (e.g., population, GDP) that are better ex- tracted from Web tables <ref type="bibr" target="#b3">(Cafarella et al., 2008)</ref>, and (2) vague (e.g., culture, economy) whose value is a narrative that would not fit the current mode of query answering on search engines.</p><p>We make the distinction between the fat head and long tail of attributes. To define these two sets, we ordered the attributes in decreasing order of the number of occurrences in the corpus <ref type="bibr">1</ref> . We defined the fat head to be the attributes until the point N in the ordering such that the sum of the total num- ber of occurrences of attributes before N equaled the number of total occurrences of the attributes after N . In our news corpus, the fat head included 218 attributes (i.e., N = 218) and the long tail included 60K attributes. <ref type="table">Table 2</ref> shows examples from both. Long tail chief economist, defender, philanthropic arm, protege <ref type="table">Table 2</ref>: Examples of fat head and long tail attributes.</p><p>The output of ReNoun is a set of facts, where each fact could be generated by multiple extrac- tions. We store the provenance of each extraction and the number of times each fact was extracted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noun versus verb attributes</head><p>ReNoun's goal is to extract facts for attributes ex- pressed as noun phrases. A natural question is whether we can exploit prior work on open in- formation extraction, which focused on extracting relations expressed as verbs. For example, if we can extract facts for the attribute advised or is advisor of, we can populate the noun attribute advisor with the same facts. In Section 7.2 we demonstrate that this approach is limited for sev- eral reasons.</p><p>First, attributes in knowledge bases are typically expressed as noun phrases. <ref type="table">Table 3 shows that Knowledge Base %Nouns %Verbs  Freebase  97  3  DBpedia  96  4  Table 3: Percentage of attributes expressed as nouns phrases  among the 100 attributes with the most facts.</ref> the vast majority of the attributes in both <ref type="bibr">Freebase and DBpedia (Auer et al., 2007</ref>) are expressed as nouns even for the fat head (and even more so for the long tail). Hence, if we extract the verb form of attributes we would need to translate them into noun form, which would require us to solve the paraphrasing problem and introduce more sources of error <ref type="bibr" target="#b15">(Madnani and Dorr, 2010)</ref>. Second, as we dig deeper into the long tail, attributes tend to be expressed in text more in noun form rather than verb form. One of the reasons is that the attribute names tend to get longer and therefore unnatural to express as verbs (e.g. chief privacy officer, au- tomotive division). Finally, there is often a sub- tle difference in meaning between verb forms and noun forms of attributes. For example, it is com- mon to see the phrase "Obama advised Merkel on saving the Euro," but that would not necessarily mean we want to say that Obama is an advisor of Angela Merkel, in the common sense of advisor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Processed document corpus</head><p>ReNoun extracts facts from a large corpus of 400M news articles. We exploit rich synactic and linguistic cues, by processing these docu- ments with a natural language processing pipeline comprising of -dependency parsing, noun phrase chunking, named entity recognition, coreference resolution, and entity resolution to Freebase. The chunker identifies nominal mentions in the text that include our attributes of interest. As discussed later in the paper, we exploit the dependency parse, coreference and entity resolution heavily during various stages of our pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overview of ReNoun</head><p>Since ReNoun aims at extracting triples for at- tributes not present in head-heavy knowledge bases, one key challenge is that we do not have any labeled data (i.e. known facts) for such attributes, especially in the long tail. Therefore ReNoun has an initial seed fact extraction step that automati- cally generates a small corpus of relatively precise seed facts for all attributes, so that distant supervi- sion can be employed. The second big challenge is to filter the noise from the resulting extractions.</p><p>ReNoun's extraction pipeline, shown in <ref type="figure" target="#fig_1">Fig- ure 1</ref>, is composed of four stages. Seed fact extraction: We begin by extracting a small number of high-precision facts for our at- tributes. For this step, we rely on manually spec- ified lexical patterns that are specifically tailored for noun phrases, but are general enough to be in- dependent of any specific attributes. When apply- ing such patterns, we exploit coreference to make the generated seed facts more precise by requiring the attribute and object noun phrases of a seed fact to refer to the same real-world entity. This is elab- orated further in Section 4. Extraction pattern generation: Utilizing the seed facts, we use distant supervision ( <ref type="bibr" target="#b13">Mintz et al., 2009</ref>) to learn a set of dependency parse patterns that are used to extract a lot more facts from the text corpus. Candidate generation: We apply the learned de- pendency parse patterns from the previous stage to generate a much larger set of extractions. We aggregate all the extractions that give rise to the same fact and store with them the provenance of the extraction. The extractions generated here are called candidates because they are assigned scores that determine how they are used. The applica- tion consuming an extraction can decide whether to discard an extraction or use it, and in this case the manner in which it is used, based on the scores we attach to it and the application's precision re- quirements. Scoring: In the final stage, we score the facts, re- flecting our confidence in their correctness. In- tuitively, we give a pattern a high score if it ex- tracts many facts that have semantically similar at- tributes, and then propagate this score to the facts extracted by the pattern (Section 6).  <ref type="table">Table 4</ref>: High precision patterns used for seed fact extraction along with an example of each. Here, the object (O) and the attribute (A) corefer and the subject (S) is in close proxim- ity. In all examples, the resulting fact is (Google, CEO, Larry Page). Patterns are not attribute specific.</p><p>entity. For example, in <ref type="figure" target="#fig_2">Figure 2</ref>, CEO is in our on- tology and we can use a coreference resolver to in- fer that CEO and Larry Page refer to the same en- tity. The use of coreference follows from the sim- ple observation that objects will often be referred to by nominals, many of which are our attributes of interest. Since the sentence matches our sixth ex- traction rule, ReNoun extracts the triple (Google, CEO, Larry Page). We rely on a coreference resolver in the spirit of <ref type="bibr" target="#b8">Haghighi and Klein (2009)</ref>. The resolver clusters the mentions of entities in a document so the ref- erences in each cluster are assumed to refer to the same real-world entity. The resolver also chooses for each cluster a representative phrase, which is a proper noun or proper adjective (e.g., Canadian). Other phrases in the same cluster can be other proper nouns or adjectives, common nouns like CEO or pronouns like he in the example. Each cluster is possibly linked by an entity resolver to a Freebase entity using a unique Freebase ID. <ref type="figure">Fig- ure</ref> 2(b) shows the coreference clusters from the sample document, with representative phrases in bold, along with the Freebase ID of each clus- ter. Note that in our example the phrase execu- tive chairman, which is also in our ontology of attributes, is not part of any coreference cluster. Therefore, the fact centered around this attribute in the example will not be part of the seed extrac- tions, but could be extracted in the next phase. The resulting facts use Freebase IDs for the subject and object (for readability, we will use entity names in the rest of this work). In summary, our seed extraction proceeds in two steps. First, we find sentences with candidate attribute-object pairs that corefer and in which the attribute is in our ontol- ogy. Second, we match these sentences against our hand-crafted rules to generate the extractions. In Section 7 we show that the precision of our seed facts is 65% for fat head attributes and 80% for long tail ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Pattern and candidate fact generation</head><p>In this section we describe how ReNoun uses the seed facts to learn a much broader set of extrac- tion patterns. ReNoun uses the learned patterns to extract many more candidate facts that are then assigned scores reflecting their quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dependency patterns</head><p>We use the seed facts to learn patterns over de- pendency parses of text sentences. A dependency parse of a sentence is a directed graph whose ver- tices correspond to tokens labeled with the word and the POS tag, and the edges are syntactic rela- tions between the corresponding tokens ( <ref type="bibr" target="#b5">de Marneffe et al., 2006</ref>). A dependency pattern is a sub- graph of a dependency parse where some words have been replaced by variables, but the POS tags have been retained (called delexicalization). A de- pendency pattern enables us to extract sentences with the same dependency parse as the sentence that generated the pattern, modulo the delexical- ized words. We note that one big benefit of using dependency patterns is that they generalize well, as they ignore extra tokens in the sentence that do not belong to the dependency subgraph of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Generating dependency patterns</head><p>The procedure for dependency pattern generation is shown in Algorithm 1, and <ref type="figure">Figure 3</ref> shows an example of its application. The input to the algo- rithm is the ontology of attributes, the seed facts (Section 4), and our processed text corpus (Sec- tion 2).   <ref type="figure">Figure 3</ref>: Dependency pattern generation using seed facts, corresponding to Algorithm 1: (a) shows the input to the pro- cedure (dependency parse partially shown); (b) P ; (c) P .</p><p>The procedure iterates over the sentences in the corpus, looking for matches between a sentence s and a seed fact f . A sentence s matches f if s contains (i) the attribute in f , and (ii) phrases in coreference clusters that map to the same Freebase IDs as the subject and object of f . When a match is found, we generate a pattern as follows.</p><p>We denote by P the minimal subgraph of the dependency parse of s containing the head tokens of the subject, attribute and object <ref type="figure">(Figure 3 (b)</ref>). We delexicalize the three vertices corresponding to the head tokens of the subject, attribute and ob- ject by variables indicating their roles. The POS tag associated with the attribute token is always a noun. The subject and object are additionally al- lowed to have pronouns and adjectives associated with their tokens. All POS tags corresponding to nouns are lifted to N, in order to match the vari- ous types of nouns. We denote the resulting de- pendency pattern by P and add it to our output, associated with the matched attribute. We note that in principle, the vertex corresponding to the head of the attribute does not need to be delexi- calized. However, we do this to improve the ef- ficiency of pattern-matching, since we will often have patterns for different attributes differing only at the attribute vertex.</p><p>It is important to note that because of the man- ner in which the roles of subject and object were assigned during seed fact extraction, the patterns ReNoun generates clearly show which argument will take the role of the subject, and which will take the role of the object. This is in contrast to previous work such as Ollie ( <ref type="bibr" target="#b11">Mausam at al., 2012)</ref>, where the assignment depends on the order in which the arguments are expressed in the sen- tence from which the fact is being extracted. For example, from the sentence "Opel was described as GM's most successful subsidiary." and the seed fact (GM, subsidiary, Opel), the pattern that ReNoun generates will consistently extract facts like (BMW, subsidiary, Rolls-Royce), and not the incorrect inverse, regardless of the relative or- dering of the two entities in the sentence.</p><p>At this point we have dependency patterns ca- pable of generating more extractions for their seed fact attributes. For efficient matching, we use the output of Algorithm 1 to generate a map from de- pendency patterns to their attributes with entries like that shown in <ref type="figure">Figure 4(a)</ref>. This way, a pat- tern match can be propagated to all its mapped at- tributes in one shot, as we explain in Section 5.3. Finally, we discard patterns that do not pass a sup- port threshold, where support is the number of dis- tinct seed facts from which a pattern could be gen- erated. </p><note type="other">{A/N} like/IN prep {O/N} pobj of/IN prep {S/N} pobj attributes: {executive chairman, creative director, ..</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Applying the dependency patterns</head><p>Given the learned patterns, we can now generate new extractions. Each match of a pattern against the corpus will indicate the heads of the poten- tial subject, attribute and object. The noun phrase headed by the token matching the {A/N} vertex is checked against the set of attributes to which the pattern is mapped. If the noun phrase is found among these attributes, then a triple (S, A, O) is constructed from the attribute and the Freebase en- tities to which the tokens corresponding to the S and O nodes in the pattern are resolved. This triple is then emitted as an extraction along with the pat- tern that generated it. <ref type="figure">Figure 4</ref>(b) and (c) show two sentences that match the dependency pattern in our running example and the resulting extractions.</p><p>Finally, we aggregate our extractions by their generated facts. For each fact f , we save the dis- tinct dependency patterns that yielded f and the total number of times it was found in the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Scoring extracted facts</head><p>In this section we describe how we score the can- didate facts extracted by applying the dependency patterns in Section 5. Recall that a fact may be obtained from multiple extractions, and assigning scores to each fact (rather than each extraction) en- ables us to consider all extractions of a fact in ag- gregate.</p><p>We score facts based on the patterns which ex- tract them. Our scheme balances two character- istics of a pattern: its frequency and coherence. Pattern frequency is defined as the number of ex-   tractions produced by the pattern. Our first ob- servation is that patterns with a large number of extractions are always able to produce correct ex- tractions (in addition to incorrect ones). We also observe that generic patterns produce more er- roneous facts compared to more targeted ones. To capture this, we introduce pattern coherence, which reflects how targeted a pattern is based on the attributes to which it applies. For example, we observed that if an extraction pattern yields facts for the coherent set of attributes ex-wife, boyfriend, and ex-partner, then its output is consistently good. On the other hand, a pattern that yields facts for a less coherent set of attributes ex-wife, general manager, and subsidiary is more likely to produce noisy extractions. Generic, more incoherent patterns are more sensitive to noise in the linguistic annotation of a document. <ref type="figure" target="#fig_6">Figure 5</ref> shows an example pattern for each case, along with its frequency and coherence.</p><p>We capture coherence of attributes using word- vector representations of attributes that are cre- ated over large text corpora ( <ref type="bibr" target="#b12">Mikolov et al., 2013</ref>). The word-vector representation v(w) for a word w (multi-word attributes can be preprocessed into single words) is computed in two steps. First, the algorithm counts the number of occurrences of a word w 1 that occurs within the text window cen- tered at w (typically a window of size 10), pro- ducing an intermediate vector that potentially has a non-zero value for every word in the corpus. The intermediate vector is then mapped to a much smaller dimension (typically less than 1000) to produce v(w). As shown in ( <ref type="bibr" target="#b12">Mikolov et al., 2013</ref>), two words w 1 and w 2 for which the cosine dis-tance between v(w 1 ) and v(w 2 ) is small tend to be semantically similar. Therefore, a pattern is co- herent if it applies to attributes deemed similar as per their word vectors.</p><p>Given an extraction pattern P that extracts facts for a set of attributes A, we define the coherence of P to be the average pairwise coherence of all at- tributes in A, where the pairwise coherence of two attributes a 1 and a 2 is the cosine distance between v(a 1 ) and v(a 2 ).</p><p>Finally, we compute the score of a fact f by summing the product of frequency and coherence for each pattern of f as shown in Equation 1.</p><formula xml:id="formula_0">S(f ) = P ∈P at(f ) f requency(P ) × coherence(P ) (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Evaluation</head><p>We describe a set of experiments that validate the contributions of ReNoun. In Sections 7.2 and 7.3 we validate our noun-centric approach: we show that extractions based on verb phrases cannot yield the results of ReNoun and that NomBank, the re- source used by state of the art in semantic role- labeling for nouns, will not suffice either. In Sec- tions 7.4-7.6 we evaluate the different components of ReNoun and its overall quality, and in Sec- tion 7.7 we discuss the cases in which ReNoun was unable to extract any facts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Setting</head><p>We used the fat head (FH) and long tail (LT) at- tributes and annotated news corpus described in Section 2. When evaluating facts, we used major- ity voting among three human judges, unless oth- erwise noted. The judges were instructed to con- sider facts with inverted subjects and objects as in- correct. For example, while <ref type="bibr">(GM, subsidiary, Opel)</ref> is correct, its inverse is incorrect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Verb phrases are not enough</head><p>State-of-art open information extraction systems like Ollie <ref type="bibr" target="#b11">(Mausam at al., 2012</ref>) assume that a re- lation worth extracting is expressed somewhere in verb form. We show this is not the case and jus- tify our noun-centric approach. In this experiment we compare ReNoun to a custom implementation of Ollie that uses the same corpus as ReNoun and supports multi-word attributes. While Ollie does try to find relations expressed as nouns, its seed facts are relations expressed as verbs.</p><p>We randomly sampled each of FH and LT for 100 attributes for which ReNoun extracts facts and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ReNoun</head><p>Ollie flagship company - railway minister - legal affairs correspondent - spokesperson be spokesperson of president-elect be president elect of co-founder be co-founder of <ref type="table">Table 5</ref>: ReNoun attributes with and without a corresponding Ollie relation. asked a judge to find potentially equivalent Ol- lie relations. Note that we did not require the judge to find exactly the same triple (thereby bias- ing the experiment towards finding more attribute matches). Furthermore, the judge was instructed that a verb phrase like advised by should be con- sidered a match to the ReNoun attribute advisor. However, looking at the data, most facts involving the relation advised are not synonymous with the advisor relation as we think of it (e.g., "Obama advised Merkel on saving the Euro"). This obser- vation suggests that there is an even more subtle difference between the meaning of verb expres- sions and noun-based expressions in text. This ex- periment, therefore, gives an upper bound on the number of ReNoun attributes that Ollie can cover.</p><p>For FH, not surprisingly, we could find matches for 99 of the 100 attributes. However, for LT, only 31 of the 100 attributes could be found, even under our permissive setting. Most attributes that could not be matched were multi-word noun phrases. While in principle, one could use the Ollie patterns that apply to the head of a multi-word attribute, we found that we generate more interesting patterns for specific multi-word attributes. <ref type="table">Table 5</ref> shows examples of attributes with and without verb map- pings in Ollie.</p><p>We also compare in the other direction and esti- mate the portion of Ollie relations centered around nouns for which ReNoun fails to extract facts. For this experiment, we randomly sampled 100 Ollie relations that contained common nouns whose ob- jects are concrete values, and looked for equivalent attributes in ReNoun extractions. ReNoun extracts facts for 48 of the Ollie relations. Among the 52 relations with no facts, 25 are not in Biperpedia (which means that ReNoun cannot extract facts for them no matter what). For the other 27 relations, ReNoun did not extract facts for the following reasons. First, some relations expressed actions, which cannot be expressed using nouns only, and are not considered attributes describing the subject entity (e.g., citation of in "Obama's citation of the Bible"). Second, some relations have the object (a common noun) embedded within them (e.g., have microphone in) and do not have cor- responding attributes that can be expressed us- ing nouns only. The remaining relations either have meaningless extractions or use common noun phrases as arguments. ReNoun only uses proper nouns (i.e., entities) for arguments because facts with common noun arguments are rarely interest- ing without more context. We note that the major- ity of the 25 Ollie relations without corresponding Biperpedia attributes also fall into one of the three categories above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Comparison against NomBank</head><p>In principle, the task of extracting noun-mediated relations can be compared to that of semantic role labeling (SRL) for nouns. The task in SRL is to identify a relation, expressed either through a verb or a noun, map it to a semantic frame, and map the arguments of the relation to the various roles within the frame. State of the art SRL systems, such as that of <ref type="bibr" target="#b9">Johansson and Nugues (2008)</ref>, are trained on NomBank ( <ref type="bibr" target="#b14">Meyers et al., 2004</ref>) for handling nominal relations, which also means that they are limited by the knowledge it has. We asked a judge to manually search NomBank for 100 at- tributes randomly drawn from each of FH and LT for which ReNoun extracts facts. For multi-word attributes, we declare a match if its head word was found. We were able to find 80 matches for the FH attributes and 42 for LT ones. For example, we could not find entries for the noun attributes coach or linebacker (of a football team). This result is easy to explain by the fact that NomBank only has 4700 attributes.</p><p>In addition, for some nouns, the associated frames do not allow for the extraction of triples. For example, all frames for the noun member spec- ify one argument only, so in the sentence "John became a member of ACM", the output relation is (ACM, member) instead of the desired triple (ACM, member, John).</p><p>As we did with Ollie, we also looked at nouns from NomBank for which ReNoun does not ex- tract facts. Out of a random sample of 100 Nom- Bank nouns, ReNoun did not extract facts for 29 nouns (four of which are not in Biperpedia). The majority of the missed nouns cannot be used by ReNoun because they either take single ar- guments (instead of two) or take either preposi- tional phrases or common nouns (instead of proper nouns correponding to entities) as one their argu- ments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Quality of seed facts</head><p>In Section 4, we described our method for ex- tracting seed facts for our attributes. Applying the method to our corpus resulted in 139M extrac- tions, which boiled down to about 680K unique facts covering 11319 attributes. We sampled 100 random facts from each of FH and LT, and ob- tained 65% precision for FH seed facts and 80% precision for LT ones. This leads us to two obser- vations.</p><p>First, the precision of seed facts for LT attributes is high, which makes them suitable for use as a building block in a distant supervision scheme to learn dependency parse patterns. We are pri- marily interested in LT attributes, which earlier approaches cannot deal with satisfactorily as we demonstrated above.</p><p>Second, LT attributes have higher precision than FH attributes. One reason is that multi-word at- tributes (which tend to be in LT) are sometimes incorrectly chunked, and only their head words are recognized as attributes (which are more likely to be in FH). For example, in the phrase "America's German coach, Klinsmann", the correct attribute is German coach (LT), but bad chunking may pro- duce the attribute coach (FH) with Germany as the subject. Another reason is that FH attributes are likely to occur in speculative contexts where the presence of the attribute is not always an asser- tion of a fact. (While both FH and LT attributes can be subject to speculative contexts, we observe this more for FH than LT in our data.) For ex- ample, before a person is a railway minister of a country, there is little mention of her along with the attribute. However, before a person is elected president, there is more media about her candidacy. Speculative contexts, combined with incorrect linguistic analysis of sentences, can re- sult in incorrect seed facts (e.g., from "Republi- can favorite for US president, Mitt Romney, vis- ited Ohio", we extract the incorrect seed fact (US, president, Mitt Romney)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Candidate generation</head><p>Using the seed facts, we ran our candidate gen- eration algorithm (Section 5). In the first step of the algorithm we produced a total of about 2 mil- lion unique dependency patterns. A third of these patterns could extract values for exactly one at- tribute. Manual inspection of these long tail pat- terns showed that they were either noise, or do not generalize. We kept patterns supported by at least 10 seed facts, yielding more than 30K patterns.</p><p>We then applied the patterns to the corpus. The result was over 460M extractions, aggregated into about 40M unique facts. Of these, about 22M facts were for LT attributes, and 18M for FH. We now evaluate the quality of these facts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Scoring extracted facts</head><p>In Section 6, we presented a scheme for scoring facts using pattern frequency and coherence. To show its effectiveness we (i) compare it against other scoring schemes, and (ii) show the quality of the top-k facts produced using this scheme, for various k. To compute coherence, we generated attribute word vectors using the word2vec 2 tool trained on a dump of Wikipedia.</p><p>First, we compare the quality of our scoring scheme (FREQ COH) with three other schemes as shown in <ref type="table">Table 6</ref>. The scheme FREQ is identical to FREQ COH except that all coherences are set to 1. PATTERN counts the number of distinct pat- terns that extract the fact while PATTERN COH sums the pattern coherences. We generated a ran- dom sample of 252 FH and LT nouns with no en- tity disambiguation errors by the underlying nat- ural language processing pipeline. The justifi- cation is that none of the schemes we consider here capture such errors. Accounting for such errors requires elaborate signals from the entity linking system, which we leave for future work. For each scoring scheme, we computed the Spear- man's rank correlation coefficient ρ between the scores and manual judgments (by three judges). A larger ρ indicates more correlation, and comput- ing ρ was statistically significant (p-value&lt;0.01) for all schemes.  <ref type="table">Table 7</ref>: Precision of random samples of the top-k scoring facts, along with the attribute yield. that adding coherence helps when two facts have similar frequencies, but this effect is tempered when considering a large number of facts.</p><p>Second, we evaluate the scoring of facts gener- ated by ReNoun by the precision of top-k results for several values of k. In this evaluation, facts with disambiguation errors are counted as wrong. The particular context in which ReNoun is applied will determine where in the ordering to set the threshold of facts to consider. We compute pre- cision based on a sample of 50 randomly chosen facts for each k. <ref type="table">Table 7</ref> shows the precision re- sults, along with the number of distinct attributes (#Attr) for which values are extracted at each k.</p><p>As we can see, ReNoun is capable of generat- ing a large number of high quality facts (≥70% precise at 1M), which our scoring method man- ages to successfully surface to the top. The ma- jor sources of error were (i) incorrect dependency parsing mainly due to errors in boilerplate text re- moval from news documents, (ii) incorrect coref- erence resolution of pronouns, (iii) incorrect entity resolution against Freebase, and (iv) cases where a triple is not sufficient (e.g., ambassador where both arguments are countries.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7">Missed extractions</head><p>We analyze why ReNoun does not extract facts for certain attributes. For FH, we investigate all the 77 attributes for which ReNoun is missing facts. For LT, there are about 50K attributes without corre- sponding facts, and we use a random sample of 100 of those attributes.  <ref type="table">Table 8</ref> shows the categorization of the missed attributes. The first three categories are cases that are currently outside the scope of ReNoun: vague attributes whose values are long narratives, nu- meric attributes, and typed attributes (e.g., email) whose values are not modeled as Freebase enti- ties. The next two categories are due to limitations of the ontology, e.g., plural forms of attributes are not always synonymized with singular forms and some attributes are bad. Finally, the "Value ex- pected" category contains the attributes for which ReNoun should have extracted values. One reason for missing values is that the corpus itself does not contain values of all attributes. Another reason is that some attributes are not verbalized in text. For example, attributes like nationality are usually not explicitly stated when expressed in text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related Work</head><p>Open information extraction (OIE) was introduced by <ref type="bibr" target="#b1">Banko et al. (2007)</ref>. For a pair of noun phrases, their system, TEXTRUNNER, looks for the at- tribute (or more generally the relation) in the text between them and uses a classifier to judge the trustworthiness of an extraction. WOE parse ( <ref type="bibr" target="#b21">Wu and Weld, 2010)</ref> extends this by using dependency parsing to connect the subject and object. Both systems assume that the attribute is between its two arguments, an assumption that ReNoun drops since it is not suitable for nominal attributes.</p><p>Closest to our work are <ref type="bibr">ReVerb (Fader et al., 2011) and</ref><ref type="bibr">Ollie (Mausam at al., 2012</ref>). ReVerb uses POS tag patterns to locate verb relations and then looks at noun phrases to the left and right for arguments. Ollie uses the ReVerb extractions as its seeds to train patterns that can further extract triples. While Ollie's patterns themselves are not limited to verb relations (they also support noun relations), the ReVerb seeds are limited to verbs, which makes Ollie's coverage on noun relations also limited. In comparison, ReNoun take a noun- centric approach and extracts many facts that do not exist in Ollie.clo <ref type="bibr">ClausIE (Del Corro and Gemulla, 2013</ref>) is an OIE framework that exploits knowledge about the grammar of the English language to find clauses in a sentence using its dependency parse. The clauses are subsequently used to generate extrac- tions at multiple granularities, possibly with more than triples. While ClausIE comes with a prede- fined set of rules on how to extract facts from a dependency parse, ReNoun learns such rules from its seed facts.</p><p>Finally, <ref type="bibr">Nakashole et al. (2014)</ref> and <ref type="bibr" target="#b13">Mintz et al. (2009)</ref> find additional facts for attributes that al- ready have facts in a knowledge base. In contrast, ReNoun is an OIE framework whose goal is to find facts for attributes without existing facts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusions</head><p>We described ReNoun, an open information ex- traction system for nominal attributes that focuses on the long tail. The key to our approach is to start from a large ontology of nominal attributes and ap- ply noun-specific manual patterns on a large pre- processed corpus (via standard NLP components) to extract precise seed facts. We then learn a set of dependency patterns, which are used to generate a much larger set of candidate facts. We proposed a scoring function for filtering candidate facts based on pattern frequency and coherence. We demon- strated that the majority of long tail attributes in ReNoun do not have corresponding verbs in Ol- lie. Finally, our experiments show that our scor- ing function is effective in filtering candidate facts (top-1M facts are ≥70% precise).</p><p>In the future, we plan to extend ReNoun to ex- tract triples whose components are not limited to Freebase IDs. As an example, extending ReNoun to handle numerical or typed attributes would in- volve extending our extraction pattern learning to accommodate units (e.g., kilograms) and other special data formats (e.g., addresses).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Extraction Pipeline: we begin with a set of high-precision extractors and use distant supervision to train other extractors. We then apply the new extractors and score the resulting triples based on the frequency and coherence of the patterns that produce them.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Document: "[Google]1 [CEO]2 [Larry Page]2 started his term in 2011, when [he]2 succeeded [Eric Schmidt]3. [Schmidt]3 has since assumed the role of executive chairman of [the company]1."Coreference clusters: (a) a document annotated with coreference clusters; (b) a table showing each cluster with the representative phrases in bold and the Freebase ID to which each cluster maps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 1 :</head><label>1</label><figDesc>Dependency pattern generation input : Set of attributes A, Seed facts I, Corpus D. P := An empty set of dependency pattern-attribute pairs. foreach sentence s ∈ D do foreach triple t = (S, A, O) found in s do if t ∈ I then G(s) = dependency parse of s P = minimal subgraph of G(s) containing the head tokens of S, A and O P = Delexicalize(P , S, A, O) P = P ∪ {{P, A} return P Attributes: A ={executive chairman} Seed fact: I = {(Google, executive chairman, Eric Schmidt)} Sentence: s ="An executive chairman, like Eric Schmidt of Google, wields influence over company operations." An/DET executive/NN chairman/NN det nn like/IN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>.} (a) "An executive chairman, like Steve Chase of AOL, is responsible for representing the company." ↓ (AOL, executive chairman, Steve Chase) (b) "A creative director, like will.i.am of 3D Systems, may also be referred to as chief creative officer." ↓ (3D Systems, creative director, will.i.am) (c) Figure 4: A dependency pattern and its use in extraction: (a) the pattern in our running example and the set of attributes to which it applies; (b) and (c) sentences matching the pattern and the resulting extractions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>(a) a coherent pattern extracting facts for semanti- cally similar attributes and (b) an incoherent pattern.</figDesc></figure>

			<note place="foot" n="1"> The occurrences were weighted by the number of semantic classes they occur with in the ontology because many classes overlap.</note>

			<note place="foot" n="4"> Seed fact extraction Since we do not have facts, but only attributes, the first phase of ReNoun&apos;s pipeline is to extract a set of high-precision seed facts that are used to train more general extraction patterns. ReNoun extracts seed facts using a manually crafted set of extraction rules (see Table 4). However, the extraction rules and the application of these rules are tailored to our task of extracting noun-based attributes. Specifically, when we apply an extraction rule to generate a triple (S,A,O), we require that (1) A is an attribute in our ontology, and (2) the value of A and the object O corefer to the same real-world</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Luna Dong, Anjuli Kan-nan, Tara McIntosh, and Fei Wu for many discus-sions about the paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DBpedia: A Nucleus for a Web of Open Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">G</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Semantic Web Conference</title>
		<meeting>the International Semantic Web Conference</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Open Information Extraction from the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Broadhead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Freebase: a Collaboratively Created Graph Database for Structuring Human Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><forename type="middle">D</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Management of Data</title>
		<meeting>the International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">WebTables: Exploring the Power of Tables on the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><forename type="middle">Y</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisy</forename><forename type="middle">Zhe</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ClausIE: Clause-based Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International World Wide Web Conference</title>
		<meeting>the International World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generating Typed Dependency Parses from Phrase Structure Parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Language Resources and Evaluation</title>
		<meeting>Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Identifying Relations for Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Biperpedia: An Ontology for Search Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simple Coreference Resolution with Rich Syntactic and Semantic Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Effect of Syntactic Representation on Semantic Role Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics</title>
		<meeting>the International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Attribute Extraction and Scoring: A Probabilistic Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyuan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Data Engineering</title>
		<meeting>the International Conference on Data Engineering</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Haixun Wang, and Seung-won Hwang</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Open Language Learning for Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distant Supervision for Relation Extraction Without Labeled Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Rion Snow, and Daniel Jurafsky</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Annotating Noun Argument Structure for NomBank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Macleod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronika</forename><surname>Zielinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Language Resources and Evaluation</title>
		<meeting>Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generating Phrasal and Sentential Paraphrases: A Survey of Data-Driven Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bonnie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scalable Knowledge Harvesting with High Precision and High Recall</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ndapandula</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Web Search and Data Mining</title>
		<meeting>Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Acquisition of Open-domain Classes via Intersective Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International World Wide Web Conference</title>
		<meeting>the International World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">What You Seek Is What You Get: Extraction of Class Attributes from Query Logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning Joint Query Interpretation and Response Ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uma</forename><surname>Sawant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International World Wide Web Conference</title>
		<meeting>the International World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Introducing the Knowledge Graph: things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<ptr target="http://googleblog.blogspot.com/2012/05/introducing-knowledge-graph-things-not.html" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Open Information Extraction Using Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the the Association for Computational Linguistics</title>
		<meeting>the the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Natural Language Questions for the Web of Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shady</forename><surname>Elbassuoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
