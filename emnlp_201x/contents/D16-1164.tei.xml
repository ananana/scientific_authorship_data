<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MixKMeans: Clustering Question-Answer Archives</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><forename type="middle">P</forename></persName>
							<email>deepaksp@acm.org</email>
							<affiliation key="aff0">
								<orgName type="department">Centre for Data Sciences</orgName>
								<orgName type="institution">Scalable Computing Queen&apos;s University Belfast</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MixKMeans: Clustering Question-Answer Archives</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1576" to="1585"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Community-driven Question Answering (CQA) systems that crowdsource experiential information in the form of questions and answers and have accumulated valuable reusable knowledge. Clustering of QA datasets from CQA systems provides a means of organizing the content to ease tasks such as manual curation and tagging. In this paper, we present a clustering method that exploits the two-part question-answer structure in QA datasets to improve clustering quality. Our method, MixKMeans, composes question and answer space similarities in a way that the space on which the match is higher is allowed to dominate. This construction is motivated by our observation that semantic similarity between question-answer data (QAs) could get localized in either space. We empirically evaluate our method on a variety of real-world labeled datasets. Our results indicate that our method significantly outperforms state-of-the-art clustering methods for the task of clustering question-answer archives.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Community-based Question Answering (CQA) sys- tems such as Yahoo! Answers 1 , StackOverflow 2 and Baidu Zhidao <ref type="bibr">3</ref> have become dependable sources of knowledge to solve common user problems. Unlike factoid question answering <ref type="bibr">4</ref> , CQA systems focus on crowdsourcing how and why questions and their an- swers. As is the case with any system where con- tent is generated by web users, the generated con- tent would be of varying quality, reliability, readabil- ity and abstraction. Thus, manual curation of such datasets is inevitable to weed out low quality and duplicate content to ensure user satisfaction. A nat- ural way to aid manual curation of such broad-based CQA archives is to employ clustering so that seman- tically related QAs are grouped together; this would help organize the corpus in a way that experts en- gaged in manual curation be assigned specific clus- ters relating to areas of their expertise. Cluster- ing also provides a platform to enable tagging the QA dataset; cluster topics could be used as tags, or other QAs in the same cluster could be tagged as being related to a QA. The fundamental difference between CQA archives and general text document collections is the existence of a two-part structure in QAs and the difference in lexical "character" be- tween the question and answer parts. This lexical chasm (i.e., gap) ( <ref type="bibr" target="#b3">Berger et al., 2000</ref>) between ques- tion and answer parts has been a subject of much study, especially, in the context of improving QA re- trieval. In this paper, we consider using the two-part structure in QAs for clustering CQA datasets.</p><p>Motivating Example: <ref type="table" target="#tab_0">Table 1</ref> lists four example QAs from the context of a CQA system focused on addressing myriad technical issues. These QAs have been tagged in the table with a manually identified root-cause to aid understanding; the root-cause is not part of the CQA data per se. QA1 and QA2 are seen to address related issues pertaining to routers, whereas QA3 and QA4 are focused on the same nar-row issue dealing with java libraries. Since QA1 and QA2 address different problems, they may not be expected to be part of the same cluster in fine- grained clusterings. On the other hand, the solu- tions suggested in QA3 and QA4 are distinct and different legitimate solutions to the same problem cause. Thus, from a semantics perspective, it is intu- itive that QA3 and QA4 should be part of the same cluster in any clustering of the CQA dataset to aid actioning on them together; a human expert might decide to merge the question parts and tag one of the answers as an alternative answer. Let us now examine the lexical relatedness between the pairs as illustrated in <ref type="table" target="#tab_1">Table 2</ref>. State-of-the-art text similar- ity measures that quantify word overlaps are likely to judge QA1 and QA2 to be having a medium sim- ilarity when either the question-part or the answer- part are considered. For the pair (QA3, QA4), the question-part similarity would be judged to be high and the answer-part similarity as low. Thus, the high similarity between the root-causes of QA3 and QA4 manifest primarily in their question-parts. Analo- gously, we observed that some QAs involving the same root-cause lead to high answer-part similarity despite poor question-part similarity. This is espe- cially true in cases involving suggestion of the same sequence of solution steps despite the question-part being divergent due to focusing on different symp- toms of the same complex problem. From these ob- servations, we posit that high similarities on either the question-space or answer-space is indicative of semantic relatedness. Any clustering method that uses a sum, average or weighted sum aggregation function to arrive at pair-wise similarities, such as a K-Means clustering that treats the collated QA as a single document, would intuitively be unable to heed to such differential manifestation of semantic similarities across the two parts. Our Contributions: We address the problem of harnessing the two-part structure in QA pairs to im- prove clustering of CQA data. Based on our obser- vations on CQA data such as those illustrated in the example, we propose a clustering approach, MixK- Means, that composes similarities (dissimilarities) in the question and answer spaces using a max (min) operator style aggregation. Through abundant em- pirical analysis on real-world CQA data, we illus- trate that our method outperforms the state-of-the- art approaches for the task of CQA clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>To enable position our work in the context of exist- ing literature, we now summarize prior work along three related directions, viz., (1) processing of CQA datasets, (2) multi-modal data clustering, and (3) K- Means extensions. Processing CQA Datasets: Most work on pro- cessing CQA data has been in the realm of re- trieval, where the task addressed is to leverage CQA datasets to aid answering new questions. These start with a new question and find one of (i) related ques- tions ( <ref type="bibr" target="#b26">Zhou et al., 2015)</ref>, (ii) potentially usable an- swers ( <ref type="bibr" target="#b20">Shtok et al., 2012</ref>), or (iii) related QAs ( <ref type="bibr" target="#b25">Xue et al., 2008)</ref>. Different methods differ in the tech- nique employed to overcome the lexical chasm, with statistical translation models ( <ref type="bibr" target="#b5">Brown et al., 1993)</ref> that model word-level correlations between ques- tions and answers being the most popular tool for the same. Usage of topic models (e.g., <ref type="bibr" target="#b6">(Cai et al., 2011)</ref>) and combining evidence from topic and translation models ( <ref type="bibr" target="#b26">Zhou et al., 2015</ref>) have also met with suc- cess. The usage of deep-learning methods such as deep belief networks ( <ref type="bibr" target="#b24">Wang et al., 2011</ref>) and auto- encoders ( <ref type="bibr" target="#b27">Zhou et al., 2016</ref>) have also been explored for QA retrieval. While the problem of estimat- ing the relevance of a QA to address a new ques- tion is related to the problem of estimating sim- ilarities between QAs to aid clustering, the latter problem is different in that both question and an- swer parts are available at either side. In fact, our problem, CQA clustering, has been largely unex- plored among literature in CQA data processing. In the interest of benchmarking our work against tech- niques from the CQA processing community, we consider the correlated latent representation learnt by the recent auto-encoder based neural network (AENN) method ( <ref type="bibr" target="#b27">Zhou et al., 2016</ref>) as input to K-Means, and empirically validate our technique against the AENN+K-Means combination (referred to as AENN, for short) in our experimental study. Outside the task of retrieval, there has been work on getting QAs from experience reports ) and discussion forums <ref type="bibr" target="#b15">(P and Visweswariah, 2014</ref>). Conversational transcripts from contact cen- tres, as outlined in ( <ref type="bibr" target="#b12">Kummamuru et al., 2009</ref>), form  Q: My internet connection is not working, my router shows the "Internet" led blinking in red. Router A: Please go to the router login page and re-login with broadband credentials; click "connect" Authentication and you should be on the internet. Issue QA2 Q: My internet connection is not working, only the power led is lit in the router. Router A: Check whether the router login page is loading. Else, the broadband cable Loose may not be connected properly. Connection    <ref type="table" target="#tab_0">Table 1</ref> another rich source of QA data, but need careful seg- mentation due to interleaving of question and an- swer parts. proposes a single-pass leader-clustering 5 style for- mulation called GHF-ART to progressively assign data objects to clusters. Unlike most other methods that assume that vector representations are obtained from general multimedia data, the authors of GHF- ART lay out how text data be pre-processed for us- age in GHF-ART, making it an appropriate method for usage in our setting. Accordingly, we will use GHF-ART as a baseline method for our experimen- tal study. K-Means Extensions: The method that we propose in this paper, MixKMeans, draws generous inspira- tion from the classical K-Means clustering formula- tion <ref type="bibr">(MacQueen and others, 1967)</ref>. There have been numerous extensions to the basic K-Means formula- tion over the last many decades; many such exten- sions have been covered in focused surveys <ref type="bibr" target="#b21">(Steinley, 2006;</ref><ref type="bibr" target="#b10">Jain, 2010</ref> along the closest attribute to that along the farthest attribute. Despite the plethora of work around ex- tending K-Means to work with a variety of methods to aggregate distances across attributes, we have not come across previous work composing distances at the level of attribute sets (or modalities) like we will do in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Definition</head><p>Let D = {(q 1 , a 1 ), . . . , (q n , a n )} be a dataset of QAs from a CQA archive where each answer a i was posted in response to the corresponding question q i .</p><p>The CQA clustering problem is the task of parti-</p><formula xml:id="formula_0">tioning D into k clusters C = {C 1 , . . . , C k } where ∪ i C i = D and ∀(i, j), i = j ⇒ C i ∩ C j = φ (dis- jointedness)</formula><p>hold such that similar QAs are grouped into the same cluster and dissimilar QAs are as- signed to different clusters. The key aspect that dif- ferentiates the CQA clustering problem from gen- eral clustering of relational data is the opportunity to leverage the specifics of the CQA data, such as the two-part structure, to model the similarity measure that would drive the clustering.</p><p>Evaluation: The quality of a clustering method may be quantified by assessing how well the clustering it produces, i.e., C, reflects the semantic similari- ties between QAs in D. Given a QA (q i , a i ) ∈ D, the other QAs that share the same cluster may be thought of as the result set, i.e., the set of related QAs according to C. In a labeled dataset such as CQADupStack ( <ref type="bibr" target="#b8">Hoogeveen et al., 2015</ref>) where re- lated QA pairs have been manually identified for each (q i , a i ), the quality of the results set may be as- sessed by contrasting against the labeled set using a standard metric such as F-score 6 . These QA-specific F-scores are then aggregated across the QAs in D to arrive at a single quality measure for the clustering. We will use such aggregated dataset-level F-scores as our primary evaluation measure. It may be noted that the related labellings may not be "clustering- friendly"; for example, there may not exist any k- clustering with no related labels going across clus- ters. Additionally, we observed that not all related QAs were labeled to be related in the CQADupStack dataset. The dataset owners confirm the problem of missing labelings in a very recent study (Hoogeveen <ref type="bibr">6</ref> https://en.wikipedia.org/wiki/F1 score et al., 2016). It is conceivable that only a few po- tential results were manually inspected to inject la- bellings. Thus, while the relative trends on F-score offer insights, the absolute F-scores may only be treated as a loose lower bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MixKMeans: Our Method</head><p>We now describe the key details of our proposed technique, MixKMeans. The name is motivated by the flexibility that is built into the method to mix (dis)similarities across question and answer spaces in a formulation that derives inspiration from the classical K-Means algorithm <ref type="bibr">(MacQueen and others, 1967)</ref>. Throughout this formulation, we repre- sent question and answer parts of QAs by their re- spective tf-idf vectors. We start with our objective function and move on to the iterative optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Objective Function</head><p>Guided by our observation from Section 1 that the space in which a pair of QAs are more similar should hold sway in determining their overall match, we outline a penalty function for a clustering C:</p><formula xml:id="formula_1">O * = C∈C (q,a)∈C min w q d(q, C.µ.q), w a d(a, C.µ.a)<label>(1)</label></formula><p>where C.µ = (C.µ, q, C.µ.a) is a prototypi- cal QA vector for cluster C and the parameter pair [w q , w a ] control the relative weighting between question and answer parts. d(., .) is a dissimilar- ity function modeled as a simple sum of squares of element-wise differences between vector entries, i.e.,</p><formula xml:id="formula_2">d(x, y) = i (x[i] − y[i]) 2 .</formula><p>Intuitively, O * sums up the distance between each QA in D and the prototypical QA vector of the clus- ter to which it is assigned to, making it a penalty function. Since we use dissimilarities that are in- versely related to similarities, the min function cap- tures the idea that the aggregate (dis)similarity be es- timated according to the measure in the best match- ing space. For optimization convenience, we replace the min construction by a differentiable approxima- tion to get a modified objective function:</p><formula xml:id="formula_3">O = C∈C (q,a)∈C w q d(q, C.µ.q) x + w a d(a, C.µ.a) x 1 x (2)</formula><p>where x is a reasonably high negative value or x → −∞. This is used since (a x + b x ) 1/x approxi- mates min{a, b} for high negative values of x. It is worth noting that the opposite effect (i.e., max ap- proximation) is achieved when x → ∞ for usage in scenarios where a max combination is desirable. The remainder of the steps are applicable for posi- tive values of x too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Optimization Approach</head><p>There are two sets of variables in Equation 2, viz., cluster assignments of QAs in D and the cluster pro- totypes (C.µs). We optimize for each set of variables alternatively, much like in the EM-steps used in the classical K-Means algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Estimating Cluster Memberships</head><p>The cluster membership estimation directly falls out from the objective function and the current es- timates of cluster prototypes since O (Equation 2) involves an instance-specific term for each QA. We will simply assign each QA to the cluster such that the respective instance-specific term is minimized:</p><formula xml:id="formula_4">Cluster((q, a)) = arg min C∈C d x Q+A ((q, a), C.µ) 1 x (3) d x Q+A (., .</formula><p>) is a short-hand for composite distance, composed of two terms (which we will denote as d x Q (., .) and d x A (., .) respectively):</p><formula xml:id="formula_5">d x Q+A ((q, a), C.µ • ) = w q × d(q, C.µ • .q) x + w a × d(a, C.µ • .a) x (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Estimating Cluster Prototypes</head><p>We now estimate the cluster prototype in element- wise fashion. Consider a particular element in the C.µ.q vector, C.µ.q <ref type="bibr">[i]</ref>; computing the partial deriva- tive and simplifying:</p><formula xml:id="formula_6">∂O ∂C.µ.q[i] = (q,a)∈C − 2 d x Q+A ((q, a), C.µ) 1−x x d x−1 Q ((q, a), C.µ) w q (q[i] − C.µ.q[i])<label>(5)</label></formula><p>Equating the first derivative to zero and solving for C.µ.q <ref type="bibr">[i]</ref> gets us to the following form:</p><formula xml:id="formula_7">C.µ.q[i] = (q,a)∈C q[i] d x Q+A ((q,a),C.µ • ) 1−x x d x−1 Q ((q,a),C.µ • ) (q,a)∈C d x Q+A ((q,a),C.µ • ) 1−x x d x−1 Q ((q,a),C.µ • ) (6)</formula><p>where C.µ • is used to indicate the estimate of C.µ from the previous iteration. The corresponding esti- mation for C.µ.a <ref type="bibr">[i]</ref> is:</p><formula xml:id="formula_8">C.µ.a[i] = (q,a)∈C a[i] d x Q+A ((q,a),C.µ • ) 1−x x d x−1 A ((q,a),C.µ • ) (q,a)∈C d x Q+A ((q,a),C.µ • ) 1−x x d x−1 A ((q,a),C.µ • )<label>(7)</label></formula><p>Equations 6 and 7 form the cluster prototype esti- mation steps of our method. It may be noted that for the choice of parameters (x = 1, w q = w a ), either equations reduce it to the usual centroid estimation process for K-Means (since the terms within <ref type="bibr">[. . .]</ref> re- duce to 1.0), as intuitively expected. Thus, the mod- ified formulation generalizes K-Means by allowing to weigh each element differently, the weight being modeled as a product two components:</p><formula xml:id="formula_9">• First component involves d x Q+A (., .</formula><p>) and is a function of the composite distance of (q, a) to the cluster prototype.</p><p>• Second component involves one of d x−1 Q (., .) or d x−1 A (., .) and is a function of the respective space (Q or A) to which the specific vector ele- ment belongs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alg. 1 MixKMeans</head><p>Input. Dataset D, number of clusters k Hyper-parameters: x, w q , w a Output. Clustering C 1: Initialize C.µs using data points from D <ref type="bibr">2:</ref> while not yet converged do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>∀(q, a) ∈ D, assign cluster using Eq. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>∀C ∈ C, estimate C.µ using Eq. 6 &amp; 7 5: end while 6: Return current clustering assignments as C</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MixKMeans: The Algorithm</head><p>Having outlined the various steps, we are now ready to present the overall M ixKM eans algorithm in Algorithm 1. As the pseudo-code indicates, the clus- ter assignment and prototype estimation steps are run in a loop until the clustering converges. Addi- tionally, we terminate after a threshold number of it- erations even if the clustering does not converge by then; we set the threshold to 10.</p><p>Initialization: In the initialization step, we ini- tialize the first cluster prototype using a random QA from D. Each of the next cluster prototypes are ini- tialized using the QA that has the highest sum of distances to all pre-chosen cluster prototypes, dis- tance computed using (d x Q+A (., .)) 1/x . This is in- spired by previous work on spreading out the clus- ter centroids <ref type="bibr">(Arthur and Vassilvitskii, 2007</ref>) in K- Means initialization.</p><p>Hyperparameters: The algorithm has three hyper-parameters, viz., the exponentiation parame- ter x and the weight parameters w q and w a . As outlined in Sec. 4.1, x should be a negative value; we observed that any value beyond −3.0 does not make any significant differences to the final cluster- ing (while higher absolute values for the exponent pose an underflow risk) and thus use x = −3.0 con- sistently. For the weights, we set w q = 0.2 and w a = 0.8. Due to the min-formulation in the ob- jective function, a lower weight increases the in- fluence of the respective space. Thus, we let our composed similarities be influenced more by the question-space similarities as in previous work <ref type="bibr" target="#b25">(Xue et al., 2008)</ref>. lection, <ref type="bibr">CQADupStack (Hoogeveen et al., 2015)</ref>, for our experimental evaluation. Unlike most other datasets, this has each QA labeled with a set of related QAs, as alluded to in Section 3; this makes automated evaluation feasible in lieu of a laborious user study. We use the android, gis, stats and physics datasets from the CQADupStack collection, with our choice of datasets motivated by dataset size. These datasets comprise 2193, 3726, 4004 and 5044 QAs respectively.</p><p>Baselines: We use two baselines from literature in our study, (i) AENN ( <ref type="bibr" target="#b27">Zhou et al., 2016)</ref>, (ii) GHF-ART ( <ref type="bibr" target="#b14">Meng et al., 2014</ref>). AENN, as alluded to in Section 2, refers to the K-Means clustering in the latent space learnt by correlated auto-encoders across the Q-A subspaces. AENN requires triplets of the form <ref type="bibr">[question, answer, other answer]</ref> in the training phase; we populate the other answer part by the answer to a related question from the dataset (it may be noted that this is advantageous to AENN since it gets to 'see' some related labelings in the training, whereas other methods can't). GHF- ART is the state-of-the-art multi-modal clustering approach that is targeted towards scenarios that involve a text modality. Unlike typical clustering algorithms that can generate a pre-specified (k) number of clusters, the number of clusters in the GHF-ART output is controlled by a vigilance parameter, ρ. Lower values of ρ result in smaller number of clusters and vice versa. A third intuitive baseline is the degenerate x = 1 instantiation of MixKMeans, which we will denote as X1. We are interested in evaluating the improvement achieved by MixKMeans over the best possible instantiation of X1; towards that, for every setting denoted by the combination <ref type="bibr">[dataset, k]</ref>, we do a search over possible positive values of w q and w a within the locus of the line w q + w a = 1. It may be noted that this search space includes simple QA clustering us- ing K-Means, being the case where w q = w a = 0.5. We collect the best result of X1 from across the grid-search for each setting. This approach, which we will denote as X1 * , while impractical in real scenarios due to usage of labeled data, gives an empirical upper bound of the accuracy of X1.</p><p>Experimental Setup: We use a latent space di-    <ref type="figure" target="#fig_5">3)</ref>. We use the F- score 7 measure to experimentally compare the ap- proaches. The F-score is computed using the related labellings in the CQADupStack data, in a manner as described in Section 3. As pointed out therein, due to the sparse labellings, the F-score may only be re- garded as a loose lower bound of their real values on a fully-labeled dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Comparative Analysis</head><p>The results of the comparative analysis benchmark- ing our approach MixKMeans (MKM) against base- lines X1 * , AENN and GHF-ART for the various datasets appear in Since the number of clusters cannot be pre-specified for GHF-ART directly, we varied its ρ parameter to generate varying number of clusters to generate a trend-line that can be compared against MixKMeans, AENN and X1 * directly. It may be noted that F- score is generally seen to increase when the cluster- ing is more fine-grained (i.e., high k); this is an arti- fact of the sparse labeling that causes large clusters to have very low precision, causing precision and re- call to diverge at low k, thus reducing the F-score. In most cases, MixKMeans is seen to outperform the other methods by scoring significantly higher in the F-Score, illustrating the superiority of our method. A notable exception appears in the higher values of k in the android dataset where GHF-ART quickly catches up and surpasses the others; however, it may be noted that k ≈ 1000 is an extremely fine-grained clustering for the android dataset with 2193 QAs, and is thus not a very useful setting in practice. On the average, MixKMeans achieves an F-score im- provement of between 30 − 100% over the other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">MixKMeans Parameter Analysis</head><p>We now analyze the F-score trends of MixKMeans against varying values of the weight parameters. Since the relative weighting between w q and w a is what matters (simply scaling them both up by the same multiplier does not make any difference due to the construction of the objective), we set w a = (1.0 − w q ) and do the analysis for varying values of w q keeping k = 600. As may be observed from the results in <ref type="figure" target="#fig_7">Figure 5</ref>, MixKMeans was seen to peak around w q = 0.2-0.5 while degrading gracefully to- wards higher values of w q . The android dataset, per- haps due to its relatively small size, records a dif- ferent behavior as compared to the other trend-lines. Similar trends were observed for other values of k, indicating MixKMeans is not highly sensitive to the parameter and degrades gracefully outside the peak.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>We considered the problem of clustering question- answer archives from CQA systems. Clustering, we observed, helps in organizing CQA archival data for purposes such as manual curation and tagging. We motivated, by way of examples, as to why simi- larities along question and answer spaces be better composed using methods other than simple sum or average type aggregation. In particular, we noted that there are potentially different ways to answer questions pertaining to the same root-cause, miti- gating the manifestation of the inherent root-cause similarity in the answer-space. Analogously, a so- phisticated root-cause could be narrated differently by different people in the question part, while elicit- ing very similar answers. In short, we observe that legitimate reasons cause manifestation of semantic similarity between QAs to be localized on to one of the spaces. Accordingly, we propose a cluster- ing method for QA archives, MixKMeans, that can heed to high similarities in either spaces to drive the clustering. MixKMeans works by iteratively opti- mizing the two sets of parameters, cluster assign- ments and cluster prototype learning, in an approach inspired by the classical K-Means algorithm. We empirically benchmark our method against current methods on multiple real-world datasets. Our exper- imental study illustrates that our method is able to significantly outperform other methods, establishing MixKMeans as the preferred method for the task of clustering CQA datasets.</p><p>Future Work: As discussed in Section 4.4, MixKMeans is eminently generalizable to beyond two spaces. Considering the usage of other kinds of data (e.g., tags, comments) as additional "spaces" to extend the CQA clustering problem is an interesting direction for future work. The applicability of MixK- Means and it's max variant (i.e., with x &gt; 0) for other kinds of multi-modal clustering problems from domains such as multimedia processing is worth ex- ploring. The extension of the formulation to include a weight learning step may be appropriate for sce- narios where prior information on the relative im- portance of the different spaces is not available. It is easy to observe that MixKMeans is prone to local op- tima issues; this makes devising better initialization strategies another potential direction. Yet another di- rection of interest is to make MixKMeans clusters interpretable, potentially by augmenting each clus- ter with word-level rules as used in earlier work on partitional document clustering ( <ref type="bibr" target="#b1">Balachandran et al., 2012</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>QA3Q:</head><label></label><figDesc>My Java app is picking up the old dojo 0.4.4 libraries though I have a newer version. Multiple A: Search for dojo 0.4.4 in Windows, and delete off the folder, and it should Libraries in automatically start using the newer version. Classpath QA4 Q: My java application is not picking up the new dojo 1.11.1 libraries that I just installed. Multiple A: Update the java classpath variable to exclude the Libraries in path to the earlier version, and add the path to the new version. Classpath</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Multi-modal Data Clustering: The problem of clustering CQA data is an instance of the gen- eral problem of clustering multi-modal (aka multi- relational, multi-view or heterogeneous) data when the question and answer parts are seen as instanti- ations of the same root cause, but in question and answer 'modalities'. Clustering multi-modal data has been explored well in the context of multi-media data clustering where each data element comes in multi-modal form such as [image, caption] pairs or [audio, text] pairs. The pioneering work in this field adapted markov random fields (Bekkerman and Jeon, 2007) to generate separate clusterings for each modality. Later approaches are closer to our task of generating a unified clustering across modalities; they work by learning a unified latent space embed- ding of the dataset, followed by usage of K-Means clustering (MacQueen and others, 1967). Eigen- decomposition (Petkos et al., 2012), spectral meth- ods (Blaschko and Lampert, 2008) and canonical correlation analysis (Jin et al., 2015) have been ex- ploited for learning the latent space prior to the clus- tering step. A recent work (Meng et al., 2014)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Android: F-Score (Y-Axis) vs. k</figDesc><graphic url="image-2.png" coords="7,314.28,176.33,224.64,101.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Stats: F-Score (Y-Axis) vs. k</figDesc><graphic url="image-4.png" coords="7,314.28,432.78,224.64,106.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Physics: F-Score (Y-Axis) vs. k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: MixKMeans: F-Score (Y-Axis) vs. wq at k = 600</figDesc><graphic url="image-5.png" coords="8,73.08,57.83,224.64,117.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig 1 (</head><label>1</label><figDesc>Android), Fig 2 (GIS), Fig 3 (Stats) and Fig 4 (Physics). Each of the trend- lines plot the F-Score against varying number of clusters in the output (k) in the range {100, 1000}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Example CQA Data</head><label>1</label><figDesc></figDesc><table>QA 
Lexical 
Pair 
Part 
Similarity 

QA1 QA2 Question 
Medium 
QA1 QA2 Answer 
Medium 
QA3 QA4 Question 
High 
QA3 QA4 Answer 
Low 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Similarity Analysis of QAs from</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://answers.yahoo.com 2 http://www.stackoverflow.com 3 http://en.wikipedia.org/en/Baidu Knows 4 e.g., http://trec.nist.gov/data/qa.html</note>

			<note place="foot" n="5"> https://cran.r-project.org/web/packages/leaderCluster/index.html</note>

			<note place="foot" n="7"> https://en.wikipedia.org/wiki/F1 score</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Generalizing MixKMeans</head><p>Since the question and answer spaces are neatly seg- regated into different terms in the parameter up- date equations, MixKMeans is easily generalizable to work with more than two spaces. Consider the set of spaces to be M = {. . . , M, . . .} and that each object, X ∈ D be represented by an |M| tuple; now, the modified update equations are as follows:</p><p>where the somewhat awkward notation</p><p>) to cover all spaces in M.</p><p>A simple modeling extension to use the general- ized MixKMeans in the CQA setting is to consider the question title and question description as two separate spaces instead of using a single question space, increasing the total number of spaces to three; such a split of the question-part was used in ( <ref type="bibr" target="#b19">Qiu et al., 2013</ref>). In certain cases, one might want to use spaces that are of questionable quality due to rea- sons such as sparsity (e.g., set of tags associated with a question) and reliability (e.g., comments attached to a QA that could be noisy). The best way to lever- age such spaces would be to include it in M for the modeling, but use a high weight for w M ; due to the min-style construction in the objective function, that setting will ensure that that space is called into play only when (a) signals from other spaces are not very strong, and (b) the signal from the space in question is very strong.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets, Baselines and Setup</head><p>Datasets: We use the recently released data col-</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">2007. k-means++: The advantages of careful seeding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms</title>
		<meeting>the eighteenth annual ACM-SIAM symposium on Discrete algorithms</meeting>
		<imprint>
			<biblScope unit="page" from="1027" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Interpretable and reconfigurable clustering of document datasets by deriving word-based rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vipin Balachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Deepak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Khemani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="475" to="503" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-modal clustering for multimedia collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Bekkerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Jeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition, 2007. CVPR&apos;07. IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bridging the lexical chasm: statistical approaches to answer-finding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayne</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhu</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="192" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Correlational spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>CVPR 2008. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert L</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning the latent topics for question retrieval in community qa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="273" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Two-part segmentation of text documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Deepak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Visweswariah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nirmalie</forename><surname>Wiratunga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadiq</forename><surname>Sani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21st ACM International Conference on Information and Knowledge Management, CIKM&apos;12</title>
		<meeting><address><addrLine>Maui, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-10-29" />
			<biblScope unit="page" from="793" to="802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cqadupstack: A benchmark data set for community question-answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doris</forename><surname>Hoogeveen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><forename type="middle">M</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Australasian Document Computing Symposium</title>
		<meeting>the 20th Australasian Document Computing Symposium</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Cqadupstack: Gold or silver?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doris</forename><surname>Hoogeveen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><forename type="middle">M</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Data clustering: 50 years beyond k-means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anil K Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition letters</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="651" to="666" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cross-modal image clustering via canonical correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuejie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Ninth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Unsupervised segmentation of conversational transcripts. Statistical Analysis and Data Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><surname>Kummamuru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Padmanabhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shourya</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Subramaniam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="231" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth Berkeley symposium on mathematical statistics and probability</title>
		<meeting>the fifth Berkeley symposium on mathematical statistics and probability<address><addrLine>Oakland, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1967" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semisupervised heterogeneous fusion for multimedia data co-clustering. Knowledge and Data Engineering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ah-Hwee</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2293" to="2306" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised solution post identification from discussion forums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Deepak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Visweswariah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014-06-22" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vaishali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupa</forename><forename type="middle">G</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mehta</surname></persName>
		</author>
		<title level="m">chapter Data Clustering: Integrating Different Distance Measures with Modified k-Means Algorithm</title>
		<meeting><address><addrLine>India, India</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011-12-20" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="691" to="700" />
		</imprint>
	</monogr>
	<note>Proceedings of the International Conference on Soft Computing for Problem Solving</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Social event detection using multimodal clustering and integrating supervisory signals</title>
	</analytic>
	<monogr>
		<title level="m">Georgios Petkos, Symeon Papadopoulos, and Yiannis Kompatsiaris</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<title level="m">Proceedings of the 2nd ACM International Conference on Multimedia Retrieval</title>
		<meeting>the 2nd ACM International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Latent semantic tensor indexing for community-based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (2)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="434" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning from the past: answering new questions with past answers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Shtok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gideon</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoelle</forename><surname>Maarek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st international conference on World Wide Web</title>
		<meeting>the 21st international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="759" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">K-means clustering: A halfcentury synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steinley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A modified version of the k-means algorithm with a distance based on cluster symmetry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Hsing</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis &amp; Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="674" to="680" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">K-means clustering using max-min distance measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthikeyani</forename><surname>Visalakshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Suguna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAFIPS 2009. Annual Meeting of the North American</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>Fuzzy Information Processing Society</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep learning approaches to semantic relevance modeling for chinese question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyuan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Retrieval models for question and answer archives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 31st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="475" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to suggest questions in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom Chao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Rung-Tsong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="389" to="416" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning semantic representation with neural networks for community question answering retrieval. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingting</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wensheng</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="75" to="83" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
