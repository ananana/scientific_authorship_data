<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sarcastic or Not: Word Embeddings to Predict the Literal or Sarcastic Meaning of Words</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debanjan</forename><surname>Ghosh</surname></persName>
							<email>debanjan.ghosh@rutgers.edu,</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
							<email>weiwei@cs.columbia.edu, smara@ccls.columbia.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Center for Computational Learning Systems</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Communication and Information</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sarcastic or Not: Word Embeddings to Predict the Literal or Sarcastic Meaning of Words</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Sarcasm is generally characterized as a figure of speech that involves the substitution of a literal by a figurative meaning , which is usually the opposite of the original literal meaning. We re-frame the sarcasm detection task as a type of word sense disambiguation problem, where the sense of a word is either literal or sarcastic. We call this the Literal/Sarcastic Sense Disambiguation (LSSD) task. We address two issues: 1) how to collect a set of target words that can have either literal or sarcastic meanings depending on context ; and 2) given an utterance and a target word, how to automatically detect whether the target word is used in the literal or the sarcastic sense. For the latter, we investigate several distributional semantics methods and show that a Support Vector Machines (SVM) classifier with a modified kernel using word embeddings achieves a 7-10% F1 improvement over a strong lexical baseline.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recognizing sarcasm is important for understand- ing people's actual sentiments and beliefs. For example, failing to recognize the following mes- sage as being sarcastic "I love that I have to go back to the emergency room", will lead a senti- ment and opinion analysis system to infer that the author's sentiment is positive towards the event of "going to the emergency room". Current ap- proaches have framed the sarcasm detection task as predicting whether a full utterance is sarcastic or not ( <ref type="bibr" target="#b6">Davidov et al., 2010;</ref><ref type="bibr" target="#b8">González-Ibáñez et al., 2011;</ref><ref type="bibr" target="#b25">Riloff et al., 2013;</ref><ref type="bibr" target="#b16">Liebrecht et al., 2013;</ref><ref type="bibr" target="#b17">Maynard and Greenwood, 2014)</ref>.</p><p>We propose a re-framing of sarcasm detection as a type of word sense disambiguation problem:</p><p>given an utterance and a target word, identify whether the sense of the target word is literal or sarcastic. We call this the Literal/Sarcastic Sense Disambiguation (LSSD) task. In the above utter- ance, the word "love" is used in a sarcastic, non- literal sense (the author's intended meaning be- ing most likely the opposite of the original literal meaning -a negative sentiment, such as "hate").</p><p>Two key challenges need to be addressed: 1) how to collect a set of target words that can have a lit- eral or a sarcastic sense, depending on context; and 2) given an utterance containing a target word, how can we determine whether the target word is used in its literal sense (e.g., "I love to take a nice stroll in the park every morning"), or in a sarcastic sense (e.g., "I love going to the dentist.").</p><p>To address the first challenge, we need to iden- tify a set of words from sarcastic utterances, which have a figurative/sarcastic sense (e.g., "love" in the utterance "I love going to the dentist"). We pro- pose a crowdsourcing task where Turkers in Ama- zon Mechanical Turk (MTurk) platform are given sarcastic utterances (tweets labeled with #sarcasm or #sarcastic hashtags) and are asked to re-phrase those messages so that they convey the author's in- tended meaning ("I love going to the dentist" can be rephrased as "I hate going to the dentist" or "I don't like going to the dentist"). <ref type="bibr">1</ref> Given this parallel dataset, we use unsupervised alignment techniques to identify semantically opposite words (e.g., "love" ↔ "hate", "brilliant" ↔ "stupid", "never" ↔ "always"). The words from these pairs that appear in the original sarcastic utterances are then considered as our collection of target words (e.g., "love", "brilliant", "never") that can have both a sarcastic and a literal sense depending on the context (Section 2).</p><p>To address the second challenge, we compare several distributional semantics methods generally used in word sense disambiguation tasks (Sec-Target Sense Utterance S . . . starting off the new year great !!!!! sick in bed . . . great L . . . you don't need a record label to have great music . . . Lsent . . . i'm in love with this song great job justin . . . S yay something to be proud of 3rd poorest in the NATION . . . proud L im filipino with dark brown eye and forever true and proud . . . Lsent but i'm proud of all the beliebers AROUND THE WORLD . . . <ref type="table">Table 1</ref>: Examples of Targets and their Senses tion 3). We show that using word embeddings in a modified SVM kernel achieves the best results (Section 4). To collect training and test datasets for each of the target words, we use Twitter mes- sages that contain those words. For the sarcas- tic sense (S), we use tweets that contain the target word and are labeled with the #sarcasm or #sar- castic hashtags. For the literal sense (L), we col- lect tweets that contain the target word and are not labeled with the #sarcastic or #sarcasm hash- tags. <ref type="table">Table 1</ref> shows examples of two targets words ("great" and "proud") and their sarcastic sense (S) and literal sense (L). In addition, for the literal sense, we also consider a special case, where the tweets are labeled with either positive or nega- tive hashtags (e.g., #happy, #sad) as proposed by <ref type="bibr">Gonzalez et al. (2011)</ref>. We denote these senti- ment tweets as L sent <ref type="table">(Table 1)</ref>. <ref type="bibr">Gonzalez et al. (2011)</ref> argue that it is harder to distinguish sar- castic from non-sarcastic messages where the non- sarcastic messages contain sentiment. Our results support this argument (97% F1 measure for the best result for S vs. L, compared to 84% F1 for the best result for S vs. L sent ; Section 4). <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Collection of Target Words</head><p>To collect a set of target words that can have either literal or sarcastic meaning depending on context, we propose a two step approach: 1) a crowdsourc- ing task to collect a parallel dataset of sarcastic utterances and their re-phrasings that convey the authors' intended meaning; and 2) unsupervised alignment techniques to detect semantically oppo- site words/phrases.</p><p>Crowdsourcing Task. Given a sarcastic mes- sage (SM), Turkers were asked to re-phrase the message so that the new message is likely to ex- press the author's intended meaning (IM). Exam- ples of an original sarcastic message (1) and three messages generated by the Turkers (2) is given be- low:</p><p>( From the above examples, we can see that align- ing the sarcastic message (SM) to the re-phrasings containing the author's intended meaning gener- ated by the Turkers (IM 1 , IM 2 , IM 3 ) will al- low us to detect that "happy" can be aligned to "don't like", "upset", and "unhappy". Based on this alignment, "happy" will be considered as a target word for the LSSD task.</p><p>We used 1,000 sarcastic messages collected from Twitter using the #sarcasm and #sarcastic hashtags. The Turkers were provided with de- tailed instructions of the task including a defini- tion of sarcasm, the task description, and multi- ple examples. In addition, for messages that con- tain one or more sentences and where sarcasm is related to only a part of the message, the Turk- ers were instructed to consider the entire message in their rephrasing. This emphasis was added to avoid high asymmetry in the length between the original sarcastic message and the rephrasing of the intended meaning. For each original sarcas- tic message (SM), we asked five Turkers to do the rephrasing task. Each HIT contains 1 sarcastic message, and Turkers were paid 5 cents for each HIT. To ensure a high quality level, only quali- fied workers were allowed to perform the task (i.e., more than 90% approval rate and at least 500 ap- proved HITs). In this way, we obtained a dataset of 5,000 SM-IM pairs.</p><p>Unsupervised Techniques to Detect Semanti- cally Opposite Words/Phrases. We use two methods for unsupervised alignment. First, we use the co-training algorithm for paraphrase detec- tion developed by <ref type="bibr" target="#b2">Barzilay and McKeown (2001)</ref>. This algorithm is used for two specific reasons. First, our dataset is similar in nature to the parallel monolingual dataset used in <ref type="bibr" target="#b2">Barzilay and McKeown (2001)</ref>, and thus lexical and contextual in- formation from tweets can be used to extract the candidate targets words for LSSD. For instance, we can align the <ref type="bibr">[SM]</ref> and <ref type="bibr">[IM 3</ref> ] (from the above examples), where except for the words happy and unhappy, the majority of the words in the two messages are anchor words and thus happy and unhappy can be extracted as paraphrases via co- training. To model contextual information, such as part of speech tagging for the co-training algo- rithm, we used Tweet NLP ( <ref type="bibr" target="#b7">Gimpel et al., 2011</ref>). Second, <ref type="bibr" target="#b0">Bannard and Callison-Burch (2005)</ref> no- ticed that the co-training method proposed by- <ref type="bibr" target="#b2">Barzilay and McKeown (2001)</ref> requires identical bounding substrings and has bias towards single words while extracting paraphrases. This apparent limitation, however, is advantageous to us because we are specifically interested in extracting target words. Co-training resulted in 367 extracted pairs of paraphrases.</p><p>We also considered a statistical machine transla- tion (SMT) alignment method -IBM Model 4 with HMM alignment implemented in Giza++ <ref type="bibr" target="#b21">(Och and Ney, 2000</ref>). We used Moses software( <ref type="bibr" target="#b14">Koehn et al., 2007</ref>) to extract lexical translations by align- ing the dataset of 5,000 SM-IM pairs. From the set of 367 extracted paraphrases using <ref type="bibr" target="#b2">Barzilay and McKeown (2001)</ref>'s approach, we selected only those paraphrases where the lexical transla- tion scores φ (resulted after running Moses) are ≥ 0.8. After filtering via translation scores and manual inspection, we obtained a set of 80 seman- tically opposite paraphrases. Given this set of se- mantically opposite words, the words that appear in the sarcastic messages were consider our target words for LSSD (70 target words after lemmatiza- tion). They range from verbs, such as "love" and "like", adjectives, such as "brilliant", "genius", and adverbs, such as "really".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Literal/Sarcastic Sense Disambiguation</head><p>Our Literal/Sarcastic Sense Disambiguation (LSSD) task is formulated as follows: given a candidate utterance (i.e., a tweet) that contains a target word t, identify whether the sense of t is sarcastic (S) or literal (L). In order to be able to solve this problem we need training and test data for each target word that consists of utterances where the target word is used either in the literal sense or the sarcastic sense. love(26802), like(14995), great(14495), good(11624), really(9825), right(6771), fun(6603), best(6182), better(5960), glad(5748), yeah(5504), nice(4443), awesome(4196), excited(4027), always(3807), happy(3098), cool(2705), amazing(1952), fa- vorite(1883), perfect(1792), wonderful(1749), won- der(1476), lovely(1424), super(1390), fantastic(1369), joy(1176), cute(1007), beautiful(981), sweet(800), hot(729), proud(703), shocked(645), interested(624), brilliant(576), genius(481), attractive(449), mature(427) <ref type="table">Table 2</ref>: Target words and # of training instances per sense</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collection</head><p>To collect training and test datasets for each of the target words, we use Twitter messages that contain those words. For the sarcastic sense (S), we use tweets that contain the target word and are labeled with the #sarcasm or #sarcastic hashtag. For the literal sense (L), we collect tweets that contain the target word and are not labeled with the #sarcastic or #sarcasm hashtags. In addition, for the literal sense we also consider a special case, where the tweets are labeled with either positive or negative sentiment hashtags (e.g., #happy, #sad). Thus, we consider two LSSD tasks: S vs. L and S vs. L sent , and aim to collect a balanced dataset for each tar- get word.</p><p>For the 70 target words (see Section 2), we col- lected a total of 2,542,249 tweets via Twitter API . We considered a setup where 80% of data is used for training, 10% for development, and 10% for test. We empirically set the number of minimum training instances for each sense of the target word to 400 without any upper restriction. This resulted in 37 target words to be used in the LSSD exper- iments. <ref type="table">Table 2</ref> shows all the target words and their corresponding number of training instances for each sense (S and L/L sent ). The size of train- ing data ranges from 26,802 for the target word "love" to 427 for the word "mature". As we will see in the results sections, however, the size of the training data is not always the key factor in the LSSD task, especially for the methods that use word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning Approaches</head><p>We consider two classical approaches used in word sense disambiguation tasks: 1) distributional approaches where each sense of a target word is represented as a context vector derived from the training data; and 2) classification approaches (S vs. L; S vs. L sent ) for each target word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Distributional Approaches</head><p>The Distributional Hypothesis in linguistics is de- rived from the semantic theory of language usage, i.e., words that are used and occur in the same contexts tend to purport similar meanings <ref type="bibr" target="#b11">(Harris, 1954)</ref>. Distributional semantic models (DSMs) use vectors that represent the contexts (e.g., co- occurring words) in which target words appear in a corpus, as proxies for meaning representations. Geometric techniques such as cosine similarity are then applied to these vectors to measure the simi- larity in meaning of corresponding words.</p><p>The DSMs are a natural approach to model our LSSD task. For each target word t we build two context-vectors that will represent the two senses of the target word t using the training data: one for the sarcastic sense S using the sarcastic training data for t ( v s ) and one for the literal sense L using the literal sense training data for t ( v l ). 3 Given a test message u containing a target word t, we first represent the target word as a vector v u using all the context words inside u. To predict whether t is used in a literal or sarcastic sense in the test message u we simply apply geometric techniques (e.g., cosine similarity) between v u and the two sense vectors v s and v l , choosing the one with the maximum score.</p><p>To create the two sense vectors v s and v l for each of the target words t, we use the posi- tive pointwise mutual information model (PPMI) <ref type="bibr" target="#b4">(Church and Hanks, 1990</ref>). Based on t's con- text words c k in a window of 10 words, we sep- arately computed PPMI for sarcastic and literal senses using t's training data. The size of the con- text widow used in DSMs is generally between 5 and 10, and in our experiments we used a win- dow of 10 words since tweets often include mean- ingful words/tokens at the end of the tweets (e.g., interjections, such as "yay", "ohh"; upper-case words, such as, "GREAT"; novel hashtags, such as "#notreally", "#lolol"; emoticons, such as ":("). We sorted the context words based on the PPMI scores and for each target word t we selected a maximum of 1,000 context words per sense to ap- proximate the two senses of the target word (i.e., the vectors v s and v l for each target word t consist of a maximum of 1,000 words). <ref type="table">Table 3</ref> shows some target words and their corresponding con-Targets Senses Context Vector S ignored, being, waking, work, sick, #not love L please, follow, ♥, her, :) Lsent happy, family, blessed, cute, birth- day S work, tomorrow, homework, friday, sleep fun L hope, join, girl, game, friend Lsent #friends, #family, weekend, amaz- ing, #christmas S working, snow, waking, studying, sick joy L yesterday, sweet, special, prayer, laughter Lsent wishing, warmth, love, christmas, peace <ref type="table">Table 3</ref>: Target words and their context words text words that were selected based on high PPMI scores.</p><p>To predict whether t is used in a literal or sar- castic sense in the test message u we simply apply the cosine similarity to the v u (vector representa- tion of the target word t in the test message u) and the two sense vectors v s and v l of t, choosing the one with the maximum score. All vector elements are given by the tf-idf values of the corresponding words. This approach, denoted as the "PPMI base- line", is the baseline for our DSM experiments. After removing the tweets that are used as test sets, we build the three word embedding mod- els in an unsupervised fashion with the remaining 2,482,763 tweets from our original data collection (Section 3.1). In each of the three models, each word w is represented by its d-dimensional vec- tor w of real numbers, where d=100 for all of the embedding algorithms in our experiments. For the size of the embedding vectors, it is common to use 100 or 300 dimensions, with larger dimensions for larger datasets. Our current dataset is smaller than the ones used in other applications of word embed- dings (e.g., <ref type="bibr" target="#b23">Pennington et al. (2014)</ref> have used bil- lion tweets to create word embedding) so we opted for 100 dimensional vectors. Below are the short descriptions of the three word embedding models:</p><p>• Weighted Textual Matrix Factorization (WTMF): Low-dimensional vectors have been used in WSD tasks, since they are computationally efficient and provide better generalization than surface words. A dimen- sion reduction method is Weighted Textual Matrix Factorization (WTMF) (Guo and Diab, 2012b), which is designed specifically for short texts, and has been successfully applied in WSD tasks <ref type="bibr" target="#b9">(Guo and Diab, 2012a</ref>). WTMF models unobserved words, thus providing more robust embeddings for short texts such as tweets.</p><p>• word2vec Representation: We use both the Skip-gram model and the Continuous Bag- of-Words (CBOW) model (Mikolov et al., 2013a; Mikolov et al., 2013c) as imple- mented in the word2vec gensim python li- brary. <ref type="bibr">4</ref> Given a window size of n words around a word w, the skip-gram model pre- dicts the neighboring words given the current word. In contrast, the CBOW model predicts the current word w, given the neighboring words in the window. We considered a con- text window of 10 words.</p><p>• GloVe Representation: GloVe ( <ref type="bibr" target="#b23">Pennington et al., 2014</ref>) is a word embedding model that is based upon weighted least-square model trained on global word-word co-occurrence counts instead of the local context used by word2vec.</p><p>Here, the LSSD task is similar to the baseline: to predict whether the target word t in the test mes- sage u is used in a literal or sarcastic sense, we simply use a similarity measure between the v u (vector representation of the target word t in the test message u) and the two sense vectors v s and v l of t, choosing the one with the maximum score. The difference from the baseline is twofold: First, all vectors elements are word embeddings (i.e., <ref type="bibr">100-d vectors)</ref>. Second, we use the maximum- valued matrix-element (MVME) algorithm intro- duced by <ref type="bibr" target="#b12">Islam and Inkpen (2008)</ref>, which has been shown to be particularly useful for computing the similarity of short texts. We modify this algorithm to use word embeddings (M V M E we ). The idea behind the MVME algorithm is that it finds a one- to-one "word alignment" between two utterances (i.e., sentences) based on the pairwise word sim- ilarity. Only the aligned words contribute to the overall similarity score. max ← getM ax(M )</p><formula xml:id="formula_0">Algorithm 1 M V M E we 1: procedure M V M E we (v s ,v u ) 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>17:</head><p>Sim ← Sim + max</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>18:</head><p>r m , c m ← getRowCol(M, max)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>19:</head><p>Remove r m row and c m column from M</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>20:</head><p>remove(M, r m , c m )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>21:</head><p>until max &gt; 0 Or M.size() &gt; 0 row, col ← M.indexOf (max)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>31:</head><p>Return row, col 32: end procedure Algorithm 1 presents the pseudocode of our modified algorithm for word embeddings, M V M E we . Let the total similarity between v s and v u be Sim. For each context word c k from v s and each word w j from v u , we compute a ma- trix where the value of the matrix element M jk denotes the cosine similarity between the embed- ded vectors c k and w j [lines 5 -13]. Next, we first select the matrix cell that has the highest similarity value in M (max) and add this to the Sim score [lines <ref type="bibr">[16]</ref><ref type="bibr">[17]</ref>. Let the r m and c m be the row and the column of the cell containing max (maximum- valued matrix element), respectively. Next, we re- move all the matrix elements of the r m -th row and the c m -th column from M [line 20]. We repeat this procedure until we have traversed through all the rows and columns of M or max = 0 [line 21].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Classification Approaches</head><p>The second approach for our LSSD task is to treat it as a binary classification task to identify the sar- castic or literal sense of a target word t. We have two classification tasks: S vs. L and S vs. L sent for each of the 37 target words. We use the lib- SVM toolkit ( <ref type="bibr" target="#b3">Chang and Lin, 2011</ref>). Development data is used for tuning parameters.</p><p>SVM Baseline: The SVM baseline for LSSD tasks uses n-grams and lexicon-based binary- valued features that are commonly used in exist- ing state-of-the-art sarcasm detection approaches <ref type="bibr" target="#b8">(González-Ibáñez et al., 2011;</ref><ref type="bibr" target="#b26">Tchokni et al., 2014</ref>). They are derived from i) bag-of-words (BoW) representations of words, ii) LIWC dic- tionary ( <ref type="bibr" target="#b22">Pennebaker et al., 2001)</ref>, and iii) a list of interjections (e.g., "ah", "oh", "yeah"), punc- tuations (e.g., "!", "?"), and emoticons collected from Wikipedia. CMU Tweet Tokenizer is em- ployed for tokenization. <ref type="bibr">5</ref> We kept unigrams unchanged when all the characters are upper- case (e.g., "NEVER" in "A shooting in Oakland? That NEVER happens! #sarcasm") but otherwise words are converted to lower case. We also change all numbers to a generic number token "22". To avoid any bias during experiments, we removed the target words from the tweets as well as any hashtag used to determine the sense of the tweet (e.g., #sarcasm, #sarcastic, #happy, #sad).</p><p>SVM with M V M E we Kernel: We propose a new kernel kernel we to compute the semantic similarity between two tweets u r and u s using the M V M E we method introduced for the DSM ap- proach, and the three types of word embeddings (WTMF, word2vec, and GloVe). The similarity measure in the kernel is similar to the algorithm M V M E we described in Algorithm 1, but instead 5 http://www.ark.cs.cmu.edu/TweetNLP/ of measuring the similarity between the sense vec- tors of t ( v s , v l ) and the vector representation of t in test message ( v u ), now we measure the similar- ity between two tweets u r and u s . For each k-th index word w k in u r and l-th index word w l in u s we compute the cosine similarity between the embedded vectors of the words and fill up a sim- ilarity matrix M . We select the matrix cell that has the highest similarity, add this similarity score to the total similarity Sim, remove the row and column from M that has highest similarity score, and repeat the procedure (similar to Algorithm 1). We noticed that M V M E we algorithm carefully chooses the best candidate word w l in u s for the w k word in u r since w l is the most similar word to w k . The algorithm continues the same procedure for all the remaining words in u r and u s . The fi- nal Sim is used as the kernel similarity between u r and u s . We augment this kernel kernel we into libSVM and during evaluation we run supervised LSSD classification for each target word t sepa- rately. <ref type="table" target="#tab_3">Tables 4 and 5</ref> show the results for the LSSD experiments using distributional approaches and classification-based approaches, respectively. For brevity, we only report the average Precision (P), Recall (R), and F1 scores with their standard deviation (SD) (given by '±'), and the targets with maximum/minimum F1 scores. w2v sg and w2v cbow represent the skip-gram and CBOW mod- els implemented in word2vec, respectively. <ref type="table" target="#tab_3">Table 4</ref> presents the results of distributional approaches (Section 3.2.1). We observe that the word embedding methods have better perfor- mance than the PPMI baseline for both S vs. L and S vs. L sent disambiguation tasks. Also, the average P/R/F1 scores for S vs. L are much higher than for S vs. L sent . Since all tweets with L sent sense were collected using sentiment hash- tags ( <ref type="bibr" target="#b8">González-Ibáñez et al., 2011</ref>), they might be lexically more similar to the S tweets than the L tweets are and thus identifying the sense of a tar- get word t between S vs. L sent is a harder task. In <ref type="table" target="#tab_3">Table 4</ref> we also observe that the average F1 scores between WTMF, w2v sg , w2v cbow , and GloVe are comparable and between 84%-86%, with w2v sg and w2v cbow achieving slightly higher F1. <ref type="table" target="#tab_4">Table 5</ref> outlines the LSSD experiments us-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1008</head><p>Expr.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Senses</head><p>Avg. P Avg. R Avg. F1 Max. F1(Target) Min. F1(Target) S 73.5 ± 3.6 84.6 ± 6.0 78.5 ± 3.2 83.9(mature) 68.8(wonder) L 83.1 ± 5.0 70.6 ± 5.5 76.1 ± 3.4 82.7(love) 68.3(nice) P P M I bl S 67.8 ± 7.0 76.2 ± 13.6 70.4 ± 7.6 81.8(joy) 43.8(like) Lsent 74.2 ± 7.1 62.7 ± 12.8 66.9 ± 6.6 78.6(joy) 47.1(interested) S 83.0 ± 3.4 87.2 ± 5.4 84.9 ± 2.4 91.4(mature) 78.7(wonder) L 87.5 ± 4.4 82.7 ± 4.5 84.9 ± 2.2 90.5(mature) 80.6(nice) WTMF S 67.4 ± 5.5 86.5 ± 5.1 75.6 ± 3.9 84.4(joy) 65.8(interested) Lsent 82.1 ± 5.8 58.9 ± 9.7 68.1 ± 7.2 81.5(joy) 50.0(genius) S 83.7 ± 3.6 85.6 ± 5.6 84.5 ± 2.8 90.6(joy) 78.8(sweet) L 86.3 ± 4.6 84.0 ± 4.3 85.0 ± 2.5 89.6(joy) 79.2(like) GloVe S 70.7 ± 5.1 84.3 ± 5.0 76.8 ± 3.9 85.4(joy) 67.1(interested) Lsent 80.7 ± 5.4 64.7 ± 8.5 71.5 ± 6.1 84.0(joy) 54.7(hot) S 84.9 ± 3.3 87.0 ± 4.8 85.8 ± 2.6 90.9(mature) 80.7(like) L 87.5 ± 4.1 85.1 ± 4.0 86.2 ± 2.5 90.7(mature) 80.2(like) <ref type="bibr">w2vsg</ref> S 70.8 ± 4.8 85.7 ± 5.1 77.4 ± 4.0 86.7(joy) 68.1(interested) Lsent 82.2 ± 5.7 64.3 ± 7.8 71.9 ± 5.9 85.4(joy) 57.4(interested) S 84.9 ± 3.2 86.7 ± 4.7 85.6 ± 2.5 90.9(mature) 80.7(like) L 87.3 ± 4.0 85.1 ± 3.8 86.1 ± 2.4 90.7(mature) 80.2(like) w2v cbow S 70.7 ± 4.8 85.8 ± 5.0 77.4 ± 4.0 86.4(joy) 68.6(attractive) Lsent 82.0 ± 5.6 64.0 ± 7.7 71.7 ± 5.8 85.0(joy) 58.7(interested)   <ref type="bibr">w2vsg</ref> , and kernel w2v cbow ). The classification approaches give better perfor- mance compared to the distributional approaches.</p><p>The SV M bl is around 7-8 % higher than the P P M I bl and comparable with the word embed- dings used in distributional approaches <ref type="table" target="#tab_3">(Table 4)</ref>. In addition, our new SVM kernel method using word embeddings shows significantly better re- sults when compared to the SV M bl (and distri- butional approaches). For instance, for the S vs. L task, the average F1 is 96-97%, which is more than 10% higher than SV M bl . Similarly, for S vs. L sent task, F1 scores reported by the kernel using word2vec embeddings are in the range of 83%-84% compared to 77% given by the SV M bl , showing an absolute increase of 7%. As stated ear- lier, MVME algorithm aligns similar word pairs found in its inputs and this performs well for short texts (i.e., tweets). Thus, the MVME algorithm combined with word embedding in kernel we re- sults in very high F1. Among the word embedding models, word2vec models give marginally better results compared to GloVe and WTMF, and GloVe outperforms marginally WTMF. Similar to <ref type="table" target="#tab_3">Table  4</ref>, here, the average F1 scores for S vs. L task are higher than the S vs. L sent results. In terms of the best and worst performing tar-gets, SV M bl prefers targets with more training data (e.g., "yeah", "love" vs. "sweet", "attractive"; see <ref type="table">Table 2</ref>). In contrast, word embedding mod- els for "joy" and "mature", two targets with com- paratively low number of training instances have achieved very high F1 using both distributional and classification approaches <ref type="table" target="#tab_3">(Table 4</ref> and 5). This can be explained by the fact that for words, such as "joy", "mature", "cute", and "brilliant", the con- texts of their literal and sarcastic sense are quite different, and DSMs and word embeddings are able to capture the difference. For example, ob- serve in the <ref type="table">Table 3</ref>, negative sentiment words, i.e., "sick", "working", "snow" are the context words for targets "joy" and "love", where as posi- tive sentiment words, such as, "blessed", "family", "christmas", and "peace" are the context words for L or L sent senses. Overall, out of 37 targets, only 5 targets ("mature", "joy", "cute", "love", and "yeah") achieved "maximum" F1 scores in vari- ous experimental settings <ref type="table" target="#tab_3">(Tables 4 and 5</ref>) whereas targets such as "interested", "genius", and "attrac- tive" achieved low F1 scores.</p><p>In terms of variance in results, SVM results show low SD (0-4%). For distributional ap- proaches, SD is slightly higher (5-8%) for several cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Two lines of research are directly relevant to our work: sarcasm detection in Twitter and applica- tion of distributional semantics, such as word em- bedding techniques to various NLP tasks. In con- trast to current research on sarcasm and irony de- tection ( <ref type="bibr" target="#b6">Davidov et al., 2010;</ref><ref type="bibr" target="#b25">Riloff et al., 2013;</ref><ref type="bibr" target="#b16">Liebrecht et al., 2013;</ref><ref type="bibr" target="#b17">Maynard and Greenwood, 2014)</ref>, we have introduced a reframing of this task as a type of word sense disambiguation problem, where the sense of a word is sarcastic or literal. Our SVM baseline uses the lexical features pro- posed in previous research on sarcasm detection (e.g., LIWC lexicon, interjections, pragmatic fea- tures) ( <ref type="bibr" target="#b16">Liebrecht et al., 2013;</ref><ref type="bibr" target="#b8">González-Ibáñez et al., 2011;</ref><ref type="bibr" target="#b24">Reyes et al., 2013)</ref>. Our analysis of tar- get words where the sarcastic sense is the opposite of the literal sense is related to the idea of "pos- itive sentiment toward a negative situation" pro- posed by <ref type="bibr" target="#b25">Riloff et al. (2013)</ref> and recently studied by <ref type="bibr" target="#b13">Joshi et al. (2015)</ref>. In our approach, we chose distributional semantic approaches that learn con- textual information of targets effectively from a large corpus containing both literal and sarcastic uses of words and show that word embedding are highly accurate in predicting the sarcastic or lit- eral sense of a word <ref type="table" target="#tab_3">(Tables 4 and 5</ref>). This ap- proach has the potential to capture more nuanced cases of sarcasm, beyond "positive sentiment to- wards a negative situation" (e.g., one of our target words was "shocked" which is negative). How- ever, our current framing is still inherently limited to cases where sarcasm is characterized as a figure of speech where the author means the opposite of what she says, due to our approach of selecting the target words.</p><p>Low-dimensional text representation, such as WTMF, have been successful in WSD disam- biguation research and in computing similarity be- tween short texts <ref type="bibr" target="#b9">(Guo and Diab, 2012a;</ref><ref type="bibr" target="#b10">Guo and Diab, 2012b</ref>). word2vec and GloVe representa- tions have provided state-of-the-art results on var- ious word similarity and analogy detection task ( <ref type="bibr" target="#b20">Mikolov et al., 2013c;</ref><ref type="bibr" target="#b19">Mikolov et al., 2013b;</ref><ref type="bibr" target="#b23">Pennington et al., 2014</ref>). Word embedding based models are also used for other NLP tasks such as dependency parsing, semantic role labeling, POS tagging, NER, question-answering ( <ref type="bibr" target="#b1">Bansal et al., 2014;</ref><ref type="bibr" target="#b5">Collobert et al., 2011;</ref><ref type="bibr" target="#b27">Weston et al., 2015)</ref> and our work on LSSD is a novel application of word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>We proposed a reframing of the sarcasm detec- tion task as a type of word sense disambiguation problem, where the sense of a word is its sarcas- tic or literal sense. Using a crowdsourcing exper- iment and unsupervised methods for detecting se- mantically opposite phrases, we collected a set of target words to be used in the LSSD task. We compared several distributional semantics meth- ods, and showed that using word embeddings in a modified SVM kernel achieves the best results (an increase of 10% F1 and 8% F1 for S vs. L and S vs. L sent disambiguation task, respectively, against a SVM baseline). While the SVM base- line preferred larger amounts of training data (best performance achieved on the targets words with higher number of training examples), the methods using word embeddings seem to perform well on target words where there might be an inherent dif- ference in the contextual sarcastic and literal use of a target word, even if the training data was smaller.</p><p>We want to investigate further the nature and size of training data useful for the LSSD task. For example, to test the effect of larger training dataset, we utilized pre-trained word vectors from GloVe (trained with 2 Billion tweets, using 100 di- mensions). <ref type="bibr">6</ref> For S vs. L disambiguation, the av- erage F1 was 88.9%, which is 7% lower than the result using GloVe on our training set of tweets (much smaller) designed for the LSSD task. This shows the training data utilized to create word em- bedding models in GloVe probably do not contain enough sarcastic tweets.</p><p>Regarding the size of the training data, recall that the unsupervised alignment approach had ex- tracted 70 target words (Section 2), although we have used 37 target words as we did not have enough training data for the remaining targets. Thus, we plan to collect more training data for these targets as well as more target words (espe- cially for the S vs. L sent task). In addition, we plan to improve our unsupervised methods for de- tecting semantically opposite meaning (e.g., us- ing the IM-IM dataset in addition to the SM-IM dataset).</p><p>One common criticism of research based on use of hashtags as gold labels is that the training ut- terances could be noisy. In other words, tweets might be sarcastic but not have #sarcasm or #sar- castic hashtags. We did a small manual validation on a dataset of 180 tweets from the L sent class us- ing 3 annotators (we asked them to say whether the tweet is sarcastic or not). For cases where all 3 coders agree none of them were considered sar- castic, while when only 2 coders agree 1 tweet out of 180 was considered sarcastic. In future, we plan to perform additional experiments to study the is- sue of noisy data. We hope that the release of our datasets will stimulate other studies related to the sarcasm detection problem, including addressing the issue of noisy data.</p><p>We also plan to study the effect of hyper- parameters in designing the DSMs. Recently, <ref type="bibr" target="#b15">Levy et al. (2015)</ref> have argued that parameter set- tings have a large impact on the success of word embedding models. We want to follow their ex- periments to study whether parameter tuning in PMI based disambiguation can improve its perfor- mance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Context Vectors with Word Embedding: The above method considers that the context vectors v s and v l of each target word t contain the co- occurring words selected by their PPMI values. We enhance the representation of context vectors to represent each word in the context vector by its word embedding. We experiment with three different methods of obtaining word embeddings: Weighted Textual Matrix Factorization (WTMF) (Guo and Diab, 2012b); word2vec that imple- ments the skip-gram and continuous bag-of-words models (CBOW) of Mikolov et al. (2013a), and GloVe (Pennington et al., 2014), a log-bilinear re- gression model based upon global word-word co- occurrence count in the training corpora.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>22 :</head><label>22</label><figDesc></figDesc><table>end while 

23: 

Return Sim 
24: end procedure 

25: 

26: procedure GETEMBEDDING(word) 

27: 

Return we model [word] 
28: end procedure 
29: procedure GETROWCOL(M,max) 

30: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Evaluation of distributional approaches (PMI and word embedding) for LSSD experiments 

Expr. 
Senses 
Avg. P 
Avg. R 
Avg. F1 
Max. F1(Target) Min. F1(Target) 
S 
87.0 ± 3.3 85.6 ± 3.1 86.3 ± 2.7 
91.7(yeah) 
75.4(sweet) 
L 
85.9 ± 2.8 87.1 ± 3.6 86.5 ± 2.8 
91.8(yeah) 
76.1(sweet) 
SV M bl 
S 
77.3 ± 4.6 78.2 ± 4.2 77.7 ± 3.8 
85.5(love) 
68.6(brilliant) 
Lsent 
77.8 ± 3.7 76.7 ± 6.4 77.1 ± 4.7 
85.8(love) 
64.6(attractive) 
S 
94.1 ± 2.2 94.6 ± 1.8 94.3 ± 1.8 
97.3(brilliant) 
88.3(joy) 
L 
94.6 ± 1.8 94.0 ± 2.3 94.3 ± 1.9 
97.2(mature) 
87.9(joy) 
kernelW T M F 
S 
79.0 ± 4.6 78.8 ± 4.4 78.8 ± 3.8 
84.8(mature) 
61.0(genius) 
Lsent 
78.8 ± 3.7 78.9 ± 4.9 78.8 ± 3.6 
85.4(mature) 
63.5(genius) 
S 
95.7 ± 1.6 97.4 ± 1.7 96.5 ± 1.1 
99.1(mature) 
92.9(glad) 
L 
97.4 ± 1.6 95.6 ± 1.7 96.5 ± 1.2 
99.1(mature) 
92.7(interested) 
kernel GloV e 
S 
79.5 ± 3.5 83.1 ± 3.0 81.2 ± 2.8 
86.9(joy) 
74.2(attractive) 
Lsent 
82.2 ± 3.0 78.3 ± 4.4 80.2 ± 3.4 
86.6(joy) 
69.2(attractive) 
S 
96.6 ± 1.1 98.5 ± 0.6 97.5 ± 0.4 
99.2(cute) 
93.8(interested) 
L 
98.5 ± 0.7 96.5 ± 1.2 97.5 ± 0.5 
99.2(cute) 
93.5(interested) 
kernelw2v sg 
S 
81.9 ± 3.8 88.1 ± 3.2 84.8 ± 3.0 
88.8(love) 
74.2(genius) 
Lsent 
87.0 ± 3.2 80.2 ± 4.7 83.4 ± 3.5 
88.8(love) 
73.3(genius) 
S 
96.4 ± 1.0 98.2 ± 1.1 97.3 ± 0.6 
99.1(mature) 
93.8(interested) 
L 
98.2 ± 1.1 96.3 ± 1.1 97.2 ± 0.7 
99.1(mature) 
93.5(interested) 
kernelw2v cbow 
S 
81.7 ± 3.8 88.6 ± 2.9 84.9 ± 2.8 
89.5(love) 
74.8(genius) 
Lsent 
87.4 ± 2.9 79.9 ± 4.8 83.4 ± 3.4 
89.2(love) 
74.4(genius) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Evaluation of classification approaches (SV M bl and kernel we ) for LSSD experiments 

ing the classification approaches (Section 3.2.2): 
SVM baseline (SV M bl ) and SVM using the 
kernel we with word embeddings (kernel W T M F , 
kernel GloV e , kernel </table></figure>

			<note place="foot" n="1"> utterances and messages are used interchangeably.</note>

			<note place="foot" n="2"> The datasets used in the experiments is available at https://github.com/debanjanghosh/sarcasm wsd.</note>

			<note place="foot" n="3"> In the remaining of this section we will only mention L and not Lsent for clarity and brevity.</note>

			<note place="foot" n="4"> https://radimrehurek.com/gensim/models/word2vec.html</note>

			<note place="foot" n="6"> Downloaded from http://nlp.stanford.edu/projects/glove/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This paper is based on work supported by the DARPA-DEFT program. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government. The authors thank the anonymous reviewers for helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Paraphrasing with bilingual parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Bannard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="597" to="604" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Tailoring continuous word representations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Extracting paraphrases from a parallel corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kathleen R Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 39th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename><surname>Chih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/˜cjlin/libsvm" />
	</analytic>
	<monogr>
		<title level="m">27. Software available at</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Word association norms, mutual information, and lexicography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">Ward</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Hanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semi-supervised recognition of sarcastic sentences in twitter and amazon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Davidov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Tsur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning, CoNLL &apos;10</title>
		<meeting>the Fourteenth Conference on Computational Natural Language Learning, CoNLL &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Part-of-speech tagging for twitter: Annotation, features, and experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="42" to="47" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identifying sarcasm in twitter: A closer look</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>González-Ibáñez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Wacholder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (Short Papers)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="581" to="586" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning the latent semantics of a concept from its definition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="140" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modeling sentences in the latent space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="864" to="872" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
		<title level="m">Distributional structure. Word</title>
		<imprint>
			<date type="published" when="1954" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="146" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semantic text similarity using corpus-based word similarity and string similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aminul</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Harnessing context incongruity for sarcasm detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinita</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="757" to="762" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th annual meeting of the ACL on interactive poster and demonstration sessions</title>
		<meeting>the 45th annual meeting of the ACL on interactive poster and demonstration sessions</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving distributional similarity with lessons learned from word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The perfect solution for detecting sarcasm in tweets# not</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Liebrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apj</forename><surname>Fa Kunneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bosch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Greenwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Giza++: Training of statistical translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Linguistic inquiry and word count: Liwc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><forename type="middle">E</forename><surname>James W Pennebaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger J</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Booth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mahway: Lawrence Erlbaum Associates</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Empiricial Methods in Natural Language Processing</title>
		<meeting>the Empiricial Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A multidimensional approach for detecting irony in twitter. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Veale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="239" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sarcasm as contrast between a positive sentiment and negative situation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashequl</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Surve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lalindra De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="704" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Emoticons and phrases: Status symbols in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simo</forename><surname>Tchokni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Diarmuid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Quercia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.05698</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
