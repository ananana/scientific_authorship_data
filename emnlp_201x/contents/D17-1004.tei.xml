<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Position-aware Attention and Supervised Data Improve Slot Filling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Position-aware Attention and Supervised Data Improve Slot Filling</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="35" to="45"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Organized relational knowledge in the form of &quot;knowledge graphs&quot; is important for many applications. However, the ability to populate knowledge bases with facts automatically extracted from documents has improved frustratingly slowly. This paper simultaneously addresses two issues that have held back prior work. We first propose an effective new model, which combines an LSTM sequence model with a form of entity position-aware attention that is better suited to relation extraction. Then we build TACRED, a large (119,474 examples) supervised relation extraction dataset, obtained via crowdsourcing and targeted towards TAC KBP relations. The combination of better supervised data and a more appropriate high-capacity model enables much better relation extraction performance. When the model trained on this new dataset replaces the previous relation extraction component of the best TAC KBP 2015 slot filling system, its F 1 score increases markedly from 22.2% to 26.7%.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A basic but highly important challenge in natu- ral language understanding is being able to pop- ulate a knowledge base with relational facts con- tained in a piece of text. For the text shown in <ref type="figure" target="#fig_0">Fig- ure 1</ref>, the system should extract triples, or equiv- alently, knowledge graph edges, such as hPenner, per:spouse, Lisa Dillmani. Combining such ex- tractions, a system can produce a knowledge graph of relational facts between persons, organizations, and locations in the text. This task involves en- tity recognition, mention coreference and/or entity linking, and relation extraction; we focus on the  most challenging "slot filling" task of filling in the relations between entities in the text. Organized relational knowledge in the form of "knowledge graphs" has become an important knowledge resource. These graphs are now exten- sively used by search engine companies, both to provide information to end-users and internally to the system, as a way to understand relationships. However, up until now, automatic knowledge ex- traction has proven sufficiently difficult that most of the facts in these knowledge graphs have been built up by hand. It is therefore a key challenge to show that NLP technology can effectively con- tribute to this important problem.</p><p>Existing work on relation extraction (e.g., <ref type="bibr" target="#b34">Zelenko et al., 2003;</ref><ref type="bibr" target="#b20">Mintz et al., 2009;</ref> has been unable to achieve sufficient re- call or precision for the results to be usable ver- sus hand-constructed knowledge bases. Super- vised training data has been scarce and, while techniques like distant supervision appear to be a promising way to extend knowledge bases at low cost, in practice the training data has often been too noisy for reliable training of relation extrac- tion systems <ref type="bibr" target="#b3">(Angeli et al., 2015)</ref>. As a result most systems fail to make correct extractions even in apparently straightforward cases like <ref type="figure" target="#fig_0">Figure 1</ref>,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity Types &amp; Label</head><p>Carey will succeed Cathleen P. Black, who held the position for 15 years and will take on a new role as chairwoman of Hearst Magazines, the company said.</p><p>Types  where the best system at the NIST TAC Knowl- edge Base Population (TAC KBP) 2015 evaluation failed to recognize the relation between Penner and Dillman. 1 Consequently most automatic sys- tems continue to make heavy use of hand-written rules or patterns because it has been hard for ma- chine learning systems to achieve adequate pre- cision or to generalize as well across text types. We believe machine learning approaches have suf- fered from two key problems: (1) the models used have been insufficiently tailored to relation extrac- tion, and (2) there has been insufficient annotated data available to satisfy the training of data-hungry models, such as deep learning models. This work addresses both of these problems. We propose a new, effective neural network se- quence model for relation classification. Its ar- chitecture is better customized for the slot fill- ing task: the word representations are augmented by extra distributed representations of word posi- tion relative to the subject and object of the puta- tive relation. This means that the neural attention model can effectively exploit the combination of semantic similarity-based attention and position- based attention. Secondly, we markedly improve the availability of supervised training data by us- ing Mechanical Turk crowd annotation to pro- duce a large supervised training dataset <ref type="table" target="#tab_2">(Table 1)</ref>, suitable for the common relations between peo- ple, organizations and locations which are used in the TAC KBP evaluations. We name this dataset the TAC Relation Extraction Dataset (TACRED), and will make it available through the Linguistic Data Consortium (LDC) in order to respect copy- rights on the underlying text.</p><p>Combining these two gives a system with markedly better slot filling performance. This is 1 Note: former spouses count as spouses in the ontology.</p><p>shown not only for a relation classification task on the crowd-annotated data but also for the incorpo- ration of the resulting classifiers into a complete cold start knowledge base population system. On TACRED, our system achieves a relation classi- fication F 1 score that is 7.9% higher than that of a strong feature-based classifier, and 3.5% higher than that of the best previous neural architecture that we re-implemented. When this model is used in concert with a pattern-based system on the TAC KBP 2015 Cold Start Slot Filling evaluation data, the system achieves an F 1 score of 26.7%, which exceeds the previous state-of-the-art by 4.5% ab- solute. While this performance certainly does not solve the knowledge base population problem - achieving sufficient recall remains a formidable challenge -this is nevertheless notable progress.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Position-aware Neural Sequence Model Suitable for Relation Extraction</head><p>Existing work on neural relation extraction (e.g., <ref type="bibr" target="#b35">Zeng et al., 2014;</ref><ref type="bibr" target="#b21">Nguyen and Grishman, 2015;</ref><ref type="bibr" target="#b38">Zhou et al., 2016</ref>) has focused on convolutional neural networks (CNNs), recurrent neural net- works (RNNs), or their combination. While these models generally work well on the datasets they are tested on, as we will show, they often fail to generalize to the longer sentences that are com- mon in real-world text (such as in TAC KBP).</p><p>We believe that existing model architectures suffer from two problems: (1) Although modern sequence models such as Long Short-Term Mem- ory (LSTM) networks have gating mechanisms to control the relative influence of each individual word to the final sentence representation (Hochre- iter and Schmidhuber, 1997), these controls are not explicitly conditioned on the entire sentence being classified; (2) Most existing work either</p><formula xml:id="formula_0">h 1 p s 1 p o 1 h 2 p s 2 p o 2 h n p s n p o n q z … a n a 2 a 1 x 1 x 2 x n Mike and Lisa 0 -2 1 -1 h 3 x 3 p s 3 p o 3 2 0 married … 4 2 a 3</formula><p>(subject) (object) does not explicitly model the positions of entities (i.e., subject and object) in the sequence, or mod- els the positions only within a local region.</p><p>Here, we propose a new neural sequence model with a position-aware attention mechanism over an LSTM network to tackle these challenges. This model can (1) evaluate the relative contribution of each word after seeing the entire sequence, and (2) base this evaluation not only on the semantic in- formation of the sequence, but also on the global positions of the entities within the sequence.</p><p>We formalize the relation extraction task as fol- lows: Let X = [x 1 , ..., x n ] denote a sentence, where x i is the i-th token. A subject entity s and an object entity o are identified in the sen- tence, corresponding to two non-overlapping con- secutive spans:</p><formula xml:id="formula_1">X s = [x s 1 , x s 1 +1 , . . . , x s 2 ] and X o = [x o 1 , x o 1 +1 , . . . , x o 2 ]</formula><p>. Given the sentence X and the positions of s and o, the goal is to pre- dict a relation r 2 R (R is the set of relations) that holds between s and o or no relation otherwise. </p><formula xml:id="formula_2">p s i = 8 &gt; &lt; &gt; : i s 1 , i &lt; s 1 0, s 1  i  s 2 i s 2 , i &gt; s 2 (1)</formula><p>Here s 1 , s 2 are the starting and ending indices of the subject entity respectively, and p s i 2 Z can be viewed as the relative distance of token x i to the subject entity. Similarly, we obtain a position se- quence [p o 1 , ..., p o n ] relative to the object entities. Let x = [x 1 , ..., x n ] be word embeddings of the sentence, obtained using an embedding matrix E. Similarly, we obtain position embedding vectors</p><formula xml:id="formula_3">p s = [p s 1 , ..., p s n ] and p o = [p o 1 , ..., p o n ]</formula><p>using a shared position embedding matrix P respectively. Next, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>, we obtain hidden state representations of the sentence by feeding x into an LSTM:</p><formula xml:id="formula_4">{h 1 , ..., h n } = LSTM({x 1 , ..., x n })<label>(2)</label></formula><p>We define a summary vector q = h n (i.e., the out- put state of the LSTM). This summary vector en- codes information about the entire sentence. Then for each hidden state h i , we calculate an attention weight a i as:</p><formula xml:id="formula_5">u i = v &gt; tanh(W h h i + W q q+ W s p s i + W o p o i )<label>(3)</label></formula><formula xml:id="formula_6">a i = exp(u i ) P n j=1 exp(u j )<label>(4)</label></formula><p>Here W h , W q 2 R da⇥d , W s , W o 2 R da⇥dp and v 2 R da are learnable parameters of the net- work, where d is the dimension of hidden states, d p is the dimension of position embeddings, and d a is the size of attention layer. Additional param- eters of the network include embedding matrices E 2 R |V|⇥d and P 2 R (2L1)⇥dp , where V is the vocabulary and L is the maximum sentence length. We regard attention weight a i as the relative contribution of the specific word to the sentence representation. The final sentence representation z is computed as:</p><formula xml:id="formula_7">z = X n i=1 a i h i (5)</formula><p>z is later fed into a fully-connected layer followed by a softmax layer for relation classification. Note that our model significantly differs from the attention mechanism in <ref type="bibr" target="#b4">Bahdanau et al. (2015)</ref> and <ref type="bibr" target="#b38">Zhou et al. (2016)</ref> in our use of the summary vector and position embeddings, and the way our attention weights are computed. An intuitive way to understand the model is to view the attention calculation as a selection process, where the goal is to select relevant contexts over irrelevant ones.</p><formula xml:id="formula_8">Dataset # Rel. # Ex. % Neg.</formula><p>SemEval-2010 <ref type="table" target="#tab_2">Task 8  19 10,717 17.4%  ACE 2003-2004  24 16,771  N/A  TACRED  42 119,474</ref> 78.7% <ref type="table">Table 2</ref>: A comparison of existing datasets and our proposed TACRED dataset. % Neg. denotes the percentage of negative examples (no relation).</p><p>Here the summary vector (q) helps the model to base this selection on the semantic information of the entire sentence (rather than on each word only), while the position vectors (p s i and p o i ) pro- vides important spatial information between each word and the entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The TAC Relation Extraction Dataset</head><p>Previous research has shown that slot filling sys- tems can greatly benefit from supervised data. For example, <ref type="bibr" target="#b2">Angeli et al. (2014b)</ref> showed that even a small amount of supervised data can boost the end-to-end F 1 score by 3.9% on the TAC KBP tasks. However, existing relation extrac- tion datasets such as the SemEval-2010 Task 8 dataset ( <ref type="bibr" target="#b13">Hendrickx et al., 2009</ref>) and the Automatic Content Extraction (ACE) ( <ref type="bibr" target="#b26">Strassel et al., 2008</ref>) dataset are less useful for this purpose. This is mainly because: (1) these datasets are relatively small for effectively training high-capacity mod- els (see <ref type="table">Table 2</ref>), and (2) they capture very differ- ent types of relations. For example, the SemEval dataset focuses on semantic relations (e.g., Cause- Effect, Component-Whole) between two nominals.</p><p>One can further argue that it is easy to obtain a large amount of training data using distant super- vision ( <ref type="bibr" target="#b20">Mintz et al., 2009</ref>). In practice, however, due to the large amount of noise in the induced data, training relation extractors that perform well becomes very difficult. For example, <ref type="bibr" target="#b24">Riedel et al. (2010)</ref> show that up to 31% of the distantly super- vised labels are wrong when creating training data from aligning Freebase to newswire text.</p><p>To tackle these challenges, we collect a large supervised dataset TACRED, targeted towards the TAC KBP relations.</p><p>Data collection. We create TACRED based on query entities and annotated system responses in the yearly TAC KBP evaluations. In each year of the TAC KBP evaluation <ref type="bibr">(2009)</ref><ref type="bibr">(2010)</ref><ref type="bibr">(2011)</ref><ref type="bibr">(2012)</ref><ref type="bibr">(2013)</ref><ref type="bibr">(2014)</ref><ref type="bibr">(2015)</ref>, 100 enti- ties (people or organizations) are given as queries, <ref type="table" target="#tab_2">Train  75,050 2009-2012  Dev  25,764  2013  Test  18,660  2014   Table 3</ref>: Statistics on TACRED: number of exam- ples and the source of each portion.</p><formula xml:id="formula_9">Data Split # Ex. Years</formula><p>for which participating systems should find asso- ciated relations and object entities. We make use of Mechanical Turk to annotate each sentence in the source corpus that contains one of these query entities. For each sentence, we ask crowd workers to annotate both the subject and object entity spans and the relation types. Due to space constraints, we describe the data collection and validation process, system inter- faces, and more statistics and examples of TAC- RED in the supplementary material. We will make TACRED publicly available through the LDC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section we evaluate the effectiveness of our proposed model and TACRED on improving slot filling systems. Specifically, we run two sets of ex- periments: (1) we evaluate model performance on the relation extraction task using TACRED, and (2) we evaluate model performance on the TAC KBP 2015 cold start slot filling task, by training the models on TACRED.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline Models</head><p>We compare our model against the following base- line models for relation extraction and slot filling:</p><p>TAC KBP 2015 winning system. To judge our proposed model against a strong baseline, we compare against Stanford's top performing system on the TAC KBP 2015 cold start slot filling task ( <ref type="bibr" target="#b3">Angeli et al., 2015)</ref>. At the core of this system are two relation extractors: a pattern-based extrac- tor and a logistic regression (LR) classifier. The pattern-based system uses a total of 4,528 surface patterns and 169 dependency patterns. The logis- tic regression model was trained on approximately 2 million bootstrapped examples (using a small annotated dataset and high-precision pattern sys- tem output) that are carefully tuned for TAC KBP slot filling evaluation. It uses a comprehensive fea- ture set similar to the MIML-RE system for re- lation extraction ( <ref type="bibr" target="#b27">Surdeanu et al., 2012</ref>), includ- ing lemmatized n-grams, sequence NER tags and POS tags, positions of entities, and various fea- tures over dependency paths, etc.</p><p>Convolutional neural networks. We follow the 1-dimensional CNN architecture by <ref type="bibr" target="#b21">Nguyen and Grishman (2015)</ref> for relation extraction. This model learns a representation of the input sen- tence, by first running a series of convolutional op- erations on the sentence with various filters, and then feeding the output into a max-pooling layer to reduce the dimension. The resulting represen- tation is then fed into a fully-connected layer fol- lowed by a softmax layer for relation classifica- tion. As an extension, positional embeddings are also introduced into this model to better capture the relative position of each word to the subject and object entities and were shown to achieve im- proved results. We use "CNN-PE" to represent the CNN model with positional embeddings.</p><p>Dependency-based recurrent neural networks. In dependency-based neural models, shortest de- pendency paths between entities are often used as input to the neural networks. The intuition is to eliminate tokens that are potentially less relevant to the classification of the relation. For the ex- ample in <ref type="figure" target="#fig_0">Figure 1</ref>, the shortest dependency path between the two entities is: <ref type="bibr">[Penner]</ref> survived ! brother</p><formula xml:id="formula_10">! wife ! [Lisa Dillman]</formula><p>We follow the SDP-LSTM model proposed by <ref type="bibr" target="#b32">Xu et al. (2015b)</ref>. In this model, each shortest depen- dency path is divided into two separate sub-paths from the subject entity and the object entity to the lowest common ancestor node. Each sub-path is fed into an LSTM network, and the resulting hid- den units at each word position are passed into a max-over-time pooling layer to form the output of this sub-path. Outputs from the two sub-paths are then concatenated to form the final representation.</p><p>In addition to the above models, we also com- pare our proposed model against an LSTM se- quence model without attention mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We map words that occur less than 2 times in the training set to a special &lt;UNK&gt; token. We use the pre-trained GloVe vectors ( <ref type="bibr" target="#b22">Pennington et al., 2014</ref>) to initialize word embeddings. For all the LSTM layers, we find that 2-layer stacked LSTMs generally work better than one-layer LSTMs. We minimize cross-entropy loss over all 42 relations using AdaGrad ( <ref type="bibr" target="#b8">Duchi et al., 2011</ref>). We apply Dropout with p = 0.5 to CNNs and LSTMs. Dur- ing training we also find a word dropout strategy to be very effective: we randomly set a token to be &lt;UNK&gt; with a probability p. We set p to be 0.06 for the SDP-LSTM model and 0.04 for all other models.</p><p>Entity masking. We replace each subject entity in the original sentence with a special &lt;NER&gt;- SUBJ token where &lt;NER&gt; is the corresponding NER signature of the subject as provided in TAC- RED. We do the same processing for object en- tities. This processing step helps (1) provide a model with entity type information, and (2) pre- vent a model from overfitting its predictions to specific entities.</p><p>Multi-channel augmentation. Instead of using only word vectors as input to the network, we augment the input with part-of-speech (POS) and named entity recognition (NER) embeddings. We run Stanford CoreNLP ( ) to obtain the POS and NER annotations.   We describe our model hyperparameters and training in detail in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation on TACRED</head><p>We first evaluate all models on TACRED. We train each model for 5 separate runs with inde- pendent random initializations. For each run we perform early stopping using the dev set. We then select the run (among 5) that achieves the median F 1 score on the dev set, and report its test set per- formance. <ref type="table" target="#tab_5">Table 4</ref> summarizes our results. We observe that all neural models achieve higher F 1 scores than the logistic regression and patterns systems, which demonstrates the effectiveness of neural models for relation extraction. Although positional em- beddings help increase the F 1 by around 2% over the plain CNN model, a simple (2-layer) LSTM model performs surprisingly better than CNN and dependency-based models. Lastly, our proposed position-aware mechanism is very effective and achieves an F 1 score of 65.4%, with an absolute in- crease of 3.9% over the best baseline neural model (LSTM) and 7.9% over the baseline logistic re- gression system. We also run an ensemble of our position-aware attention model which takes major- ity votes from 5 runs with random initializations and it further pushes the F 1 score up by 1.6%.</p><p>We find that different neural architectures show a different balance between precision and recall. CNN-based models tend to have higher precision; RNN-based models have better recall. This can be explained by noting that the filters in CNNs are essentially a form of "fuzzy n-gram patterns".  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation on TAC KBP Slot Filling</head><p>Second, we evaluate the slot filling performance of all models using the TAC KBP 2015 cold start slot filling task ( <ref type="bibr" target="#b9">Ellis et al., 2015)</ref>. In this task, about 50k newswire and Web forum documents are selected as the evaluation corpus. A slot filling system is asked to answer a series of queries with two-hop slots <ref type="figure" target="#fig_5">(Figure 3</ref>): The first slot asks about fillers of a relation with the query entity as the sub- ject (Mike Penner), and we term this a hop-0 slot; the second slot asks about fillers with the system's hop-0 output as the subject, and we term this a hop-1 slot. System predictions are then evaluated against gold annotations, and micro-averaged pre- cision, recall and F 1 scores are calculated at the hop-0 and hop-1 levels. Lastly hop-all scores are calculated by combining hop-0 and hop-1 scores. <ref type="bibr">2</ref> Evaluating relation extraction systems on slot filling is particularly challenging in that: (1) End- to-end cold start slot filling scores conflate the per- formance of all modules in the system (i.e., en- tity recognizer, entity linker and relation extrac- tor). (2) Errors in hop-0 predictions can easily propagate to hop-1 predictions. To fairly evalu- ate each relation extraction model on this task, we use Stanford's 2015 slot filling system as our basic pipeline. 3 It is a very strong baseline specifically tuned for TAC KBP evaluation and ranked top in the 2015 evaluation. We then plug in the corre- sponding relation extractor trained on TACRED, keeping all other modules unchanged. <ref type="table" target="#tab_7">Table 5</ref> presents our results. We find that: (1) by only training our logistic regression model on TACRED (in contrast to on the 2 million boot- strapped examples used in the 2015 Stanford sys- tem) and combining it with patterns, we obtain a higher hop-0 F 1 score than the 2015 Stanford sys-</p><formula xml:id="formula_11">Hop-0 Hop-1 Hop-all Model P R F 1 P R F 1 P R F 1</formula><p>Patterns 63.8 17.7 27.7 49.3 8.6 14.7 58.9 13.3 21.8 LR 36.6 21.9 27.4 15.1 10.1 12.2 25.6 16.3 19.9 + Patterns (2015 winning system) 37. <ref type="bibr">5</ref>    <ref type="table">Table 6</ref>: An ablation test of our position-aware attention model, evaluated on TACRED dev set. Scores are median of 5 models.</p><p>tem, and a similar hop-all F 1 ; (2) our proposed position-aware attention model substantially out- performs the 2015 Stanford system on all hop-0, hop-1 and hop-all F 1 scores. Combining it with the patterns, we achieve a hop-all F 1 of 26.7%, an absolute improvement of 4.5% over the previous state-of-the-art result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Analysis</head><p>Model ablation. <ref type="table">Table 6</ref> presents the results of an ablation test of our position-aware atten- tion model on the development set of TACRED. The entire attention mechanism contributes about 1.5% F 1 , where the position-aware term in Eq. <ref type="formula" target="#formula_5">(3)</ref> alone contributes about 1% F 1 score.</p><p>Impact of negative examples. <ref type="figure" target="#fig_6">Figure 4</ref> shows how the slot filling evaluation scores change as we change the amount of negative (i.e., no relation) training data provided to our proposed model. We find that: (1) At hop-0 level, precision increases as we provide more negative examples, while recall stays almost unchanged. about 10% as we change the amount of negative examples from 20% to 100%.</p><p>Performance by sentence length. <ref type="figure">Figure 5</ref> shows performance on varying sentence lengths. We find that: (1) Performance of all models de- grades substantially as the sentences get longer.  <ref type="figure">Figure 5</ref>: TACRED development set F 1 scores for sentences of varying lengths.</p><p>Improvement by slot types. We calculate the F 1 score for each slot type and compare the improvement from using our proposed model across slot types. When compared with the CNN-PE model, our position-aware attention model achieves improved F 1 scores on 30 out of the 41 slot types, with the top 5 slot types being org:members, per:country of death, org:shareholders, per:children and per:religion. When compared with SDP-LSTM model, our model achieves improved F 1 scores on 26 out of the 41 slot types, with the top 5 slot types being org:political/religious affiliation, per:country of death, org:alternate names, per:religion and per:alternate names. We ob- serve that slot types with relatively sparse training examples tend to be improved by using the position-aware attention model. Attention visualization. Lastly, <ref type="figure">Figure 6</ref> shows the visualization of attention weights assigned by our model on sampled sentences from the devel- opment set. We find that the model learns to pay more attention to words that are informative for the relation (e.g., "graduated from", "niece" and "chairman"), though it still makes mistakes (e.g., "refused to name the three"). We also observe that the model tends to put a lot of weight onto object entities, as the object NER signatures are very in- formative to the classification of relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Relation extraction. There are broadly three main lines of work on relation extraction: first, fully-supervised approaches ( <ref type="bibr" target="#b34">Zelenko et al., 2003;</ref><ref type="bibr" target="#b5">Bunescu and Mooney, 2005)</ref>, where a statisti- cal classifier is trained on an annotated dataset; second, distant supervision ( <ref type="bibr" target="#b20">Mintz et al., 2009;</ref><ref type="bibr" target="#b27">Surdeanu et al., 2012)</ref>, where a training set is formed by projecting the relations in an existing knowledge base onto textual instances that contain the entities that the relation connects; and third, Open IE <ref type="bibr" target="#b10">(Fader et al., 2011;</ref><ref type="bibr" target="#b18">Mausam et al., 2012)</ref>, which views its goal as producing subject-relation- object triples and expressing the relation in text.</p><p>Slot filling and knowledge base population. The most widely-known effort to evaluate slot fill- ing and KBP systems is the yearly TAC KBP slot filling tasks, starting from 2009 <ref type="bibr" target="#b19">(McNamee and Dang, 2009)</ref>. Participants in slot filling tasks usu- ally make use of hybrid systems that combine pat- terns, Open IE, distant supervision and supervised systems for relation extraction ( <ref type="bibr" target="#b16">Kisiel et al., 2015;</ref><ref type="bibr" target="#b11">Finin et al., 2015;</ref><ref type="bibr" target="#b37">Zhang et al., 2016)</ref>.</p><p>Datasets for relation extraction. Popular general-domain datasets include the ACE dataset ( <ref type="bibr" target="#b26">Strassel et al., 2008</ref>) and the SemEval-2010 task 8 dataset <ref type="bibr" target="#b13">(Hendrickx et al., 2009</ref>). In addition, the BioNLP Shared Tasks ( ) are yearly efforts on creating datasets and evaluations for biomedical information extraction systems.</p><p>Deep learning models for relation extraction. Many deep learning models have been proposed for relation extraction, with a focus on end-to-end training using CNNs ( <ref type="bibr" target="#b35">Zeng et al., 2014;</ref><ref type="bibr" target="#b21">Nguyen and Grishman, 2015</ref>) and RNNs ( <ref type="bibr" target="#b36">Zhang et al., 2015)</ref>. Other popular approaches include using CNN or RNN over dependency paths between en- tities ( <ref type="bibr">Xu et al., 2015a,b)</ref>, augmenting RNNs with different components ( <ref type="bibr" target="#b38">Zhou et al., 2016)</ref>, and combining RNNs and CNNs ( <ref type="bibr" target="#b28">Vu et al., 2016;</ref><ref type="bibr" target="#b29">Wang et al., 2016)</ref>.  com- pares the performance of CNN models against tra- ditional approaches on slot filling using a portion of the TAC KBP evaluation data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We introduce a state-of-the-art position-aware neural sequence model for relation extraction, as well as TACRED, a large-scale, crowd-sourced dataset that is orders of magnitude larger than pre- vious relation extraction datasets. Our proposed model outperforms a strong feature-based classi- fier and all baseline neural models. In combination with the new dataset, it improves the state-of-the-Sampled Sentences Predicted Labels PER-SUBJ graduated from North Korea 's elite Kim Il Sung University and ORG-OBJ ORG-OBJ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>per:schools attended</head><p>The cause was a heart attack following a case of pneumonia , said PER-SUBJ 's niece , PER-OBJ PER-OBJ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>per:other family</head><p>Independent ORG-SUBJ ORG-SUBJ ORG-SUBJ ( ECC ) chairman PER-OBJ PER-OBJ refused to name the three , saying they would be identified when the final list of candidates for the august 20 polls is published on Friday .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>org:top members/employees</head><p>Figure 6: Sampled sentences from the TACRED development set, with words highlighted according to the attention weights produced by our best model. art hop-all F 1 on the TAC KBP 2015 slot filling task by 4.5% absolute.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of relation extraction from the TAC KBP corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Our proposed position-aware neural sequence model. The model is shown with an example sentence Mike and Lisa got married.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Inspired by the position encoding vectors used in Collobert et al. (2011) and Zeng et al. (2014), we define a position sequence relative to the sub- ject entity [p s 1 , ..., p s n ], where</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Model</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example query and corresponding fillers in the TAC KBP cold start slot filling task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Change of slot filling hop-0 and hopall scores as number of negative training examples changes. 100% is with all the negative examples included in the training set; the left side scores have positives and negatives roughly balanced.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>: PERSON/TITLE Relation: per:title Irene Morgan Kirkaldy, who was born and reared in Baltimore, lived on Long Island and ran a child-care center in Queens with her second husband, Stanley Kirkaldy. Types: PERSON/CITY Relation: per:city of birth</head><label></label><figDesc></figDesc><table>Pandit worked at the brokerage Morgan Stanley for about 11 years until 2005, when he and some 
Morgan Stanley colleagues quit and later founded the hedge fund Old Lane Partners. 
Types: ORGANIZATION/PERSON 
Relation: org:founded by 

Baldwin declined further comment, and said JetBlue chief executive Dave Barger was unavailable. 
Types: PERSON/TITLE 
Relation: no relation 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Sampled examples from the TACRED dataset. Subject entities are highlighted in blue and 
object entities are highlighted in red. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Model performance on the test set of 
TACRED, micro-averaged over instances. LR = 
Logistic Regression. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Model performance on TAC KBP 2015 slot filling evaluation, micro-averaged over queries. 
Hop-0 scores are calculated on the simple single-hop slot filling results; hop-1 scores are calculated 
on slot filling results chained on systems' hop-0 predictions; hop-all scores are calculated based on the 
combination of the two. LR = logistic regression. 

Model 
Dev F 1 

Final Model 
66.22 
-Position-aware attention 
65.12 
-Attention 
64.71 
-Pre-trained embeddings 
65.34 
-Word dropout 
65.69 
-All above 
63.60 

</table></figure>

			<note place="foot" n="2"> In the TAC KBP cold start slot filling evaluation, a hop-1 slot is transferred to a pseudo-slot which is treated equally as a hop-0 slot. Hop-all precision, recall and F1 are then calculated by combining these pseudo-slot predictions and hop-0 predictions. 3 This system uses the fine-grained NER system in Stanford CoreNLP (Manning et al., 2014) for entity detection and the Illinois Wikifier (Ratinov et al., 2011) for entity linking.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their help-ful suggestions. We gratefully acknowledge the support of the Allen Institute for Artificial Intelli-gence and the support of the Defense Advanced Research Projects Agency (DARPA) Deep Ex-ploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract No. FA8750-13-2-0040. Any opinions, findings, and conclusion or recommendations ex-pressed in this material are those of the authors and do not necessarily reflect the view of the DARPA, AFRL, or the US government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Comparing convolutional neural networks to traditional models for slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stanford&apos;s distantly supervised slot filling systems for KBP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><forename type="middle">Johnson</forename><surname>Premkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Analysis Conference (TAC) Proceedings</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Combining distant and partial supervision for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bootstrapped self training for knowledge base population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Chaganty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><forename type="middle">Johnson</forename><surname>Premkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Analysis Conference (TAC) Proceedings</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A shortest path dependency kernel for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Razvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (EMNLP 2005)</title>
		<meeting>the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (EMNLP 2005)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="724" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Entity-centric coreference resolution with model stacking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Overview of linguistic resources for the TAC KBP 2015 evaluations: Methodologies and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Getman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dana</forename><surname>Fore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Kuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyi</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Analysis Conference (TAC) Proceedings</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="16" to="17" />
		</imprint>
	</monogr>
	<note>Ann Bies, and Stephanie Strassel</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiuchang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshi</forename><surname>Mackin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dowd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<title level="m">HLTCOE participation in TAC KBP 2015: Cold start and TEDL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Text Analysis Conference (TAC) Proceedings</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iris</forename><surname>Hendrickx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><forename type="middle">Nam</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´odiarmuid´</forename><forename type="middle">Diarmuid´o</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pennacchiotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenza</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Szpakowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions</title>
		<meeting>the Workshop on Semantic Evaluations: Recent Achievements and Future Directions</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="94" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Overview of BioNLP&apos;09 shared task on event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshinobu</forename><surname>Kano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing: Shared Task</title>
		<meeting>the Workshop on Current Trends in Biomedical Natural Language Processing: Shared Task</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">CMUML System for KBP 2015 cold start slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Mcdowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ndapandula</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Emmanouil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abulhair</forename><surname>Platanios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Saparov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derry</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Wijaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Analysis Conference (TAC) Proceedings</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL) System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Open language learning for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Overview of the TAC 2009 knowledge base population track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Analysis Conference (TAC) Proceedings</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="111" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Relation extraction: Perspective from convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huu</forename><surname>Thien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT)</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Local and global algorithms for disambiguation to Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL 2011)</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL 2011)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1375" to="1384" />
		</imprint>
	</monogr>
	<note>and Mike Anderson</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Modeling relations and their mentions without labeled text. Machine learning and knowledge discovery in databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Linguistic resources and evaluation techniques for evaluation of cross-document automatic content extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kay</forename><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyi</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Combining recurrent and convolutional neural networks for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Relation classification via multi-level attention CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semantic relation classification via convolutional neural networks with simple negative sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Improved relation classification by deep recurrent neural networks with data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics</title>
		<meeting>the 26th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Classifying relations via long short term memory networks along shortest dependency paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1785" to="1794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.2329</idno>
		<title level="m">Ilya Sutskever, and Oriol Vinyals. 2014. Recurrent neural network regularization</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Kernel methods for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Zelenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chinatsu</forename><surname>Aone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Richardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1083" to="1106" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Computational Linguistics (COLING 2014)</title>
		<meeting>the 24th International Conference on Computational Linguistics (COLING 2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Relation classification via recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CSLT 20150024, Tsinghua University</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Stanford at TAC KBP 2016: Sealing pipeline leaks and understanding chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Chaganty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Analysis Conference (TAC) Proceedings</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Attentionbased bidirectional long short-term memory networks for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">207</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
