<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PizzaPal: Conversational Pizza Ordering using a High-Density Conversational AI Platform</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Raux</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>/ botbotbotbot, Inc. 3225 Ash Street Palo Alto</addrLine>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>/ botbotbotbot, Inc. 3225 Ash Street Palo Alto</addrLine>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>/ botbotbotbot, Inc. 3225 Ash Street Palo Alto</addrLine>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felicia</forename><surname>Wong</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>/ botbotbotbot, Inc. 3225 Ash Street Palo Alto</addrLine>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PizzaPal: Conversational Pizza Ordering using a High-Density Conversational AI Platform</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations)</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations) <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="151" to="156"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>151</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper describes PizzaPal, a voice-only agent for ordering pizza, as well as the Conversational AI architecture built at b4.ai. Based on the principles of high-density conversational AI, it supports natural and flexible interactions through neural conversational language understanding, robust dialog state tracking , and hierarchical task decomposition.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">High-Density Conversational AI</head><p>Following the recent rise to prominence of smart speakers, as well as the continuous improvement of core technologies for speech recognition and natural language understanding, voice-only inter- active applications, whether in the home or in car, have attracted increasing attention and investment from the industry. Such applications generally fall under two broad categories: assistants and bots. Voice assistants, pioneered by Siri in 2010, aim at providing a broad range of information and ser- vices across many domains, primarily by lever- aging natural language's evocative power, i.e. its ability to summon any intent, concept or entity at any point in a conversation. On the other hand, bots (also known as skills on Alexa and action on Google Assistant) are much narrower in scope, of- ten providing a voice interface to a single brand, service, or API.</p><p>While technological progresses are undeniable, these applications have only met limited suc- cess 1 , and largely fail to sustain even simple task- oriented conversations with humans. We believe this relatively poor user experience stems from the fact that neither assistants nor bots are able to cover the space of possible (or even reason- able) conversations with enough density. In other words, while a given set of user intents are rec- ognized and supported, even small variations over those are not properly handled. There are several root causes to these limitations. While platforms such as Google's DialogFlow or Facebook's wit.ai provide a simple way of building a relatively small set of distinct intents to a large developer commu- nity, these alone cannot support truly natural, sus- tained, interaction. Therefore, companies (typi- cally startups) that develop bots might not have the necessary resources or knowledge to build truly compelling conversational experiences. On the other hand, some of the largest tech companies are behind most voice assistants (Apple, Google, Amazon) have plenty of resources, financial, hu- man, and intellectual, but they are typically fo- cused on expanding the breadth of their applica- tions, to the expense of its density. <ref type="figure" target="#fig_0">Figure 1</ref> gives an example of the contrast between breadth and density.</p><p>At b4.ai, we believe that only high-density con- versational AI can deliver the seamless, natural ex- perience that matches users' expectations of Ar- tificial Intelligence and leads to truly successful conversational consumer products. The following sections describe how we are tackling this chal- lenge by first focusing on domain-specific appli- cations in the form of Alexa skills and Google Ac- tions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The PizzaPal Conversational Ordering System</head><p>The PizzaPal system is a voice-only conversa- tional agent that supports ordering pizza, drinks and side dishes for delivery or pickup. It runs ei- ther as an Alexa skill or a Google Assistant ac- tion and is connected to the Domino's Pizza API. While there exist other conversational agents (as- sistants, skills or actions) that support pizza or-   The italicized sentences show instances of natu- <ref type="bibr">2</ref> The video of this dialog is available at https:// youtu.be/BQrzgJk4-yI ral conversational behavior exhibited by PizzaPal: * PizzaPal proactively suggests sizes and items based on the dialog history when possible. * * While the system can drive the conversation to completion by asking the user direct ques- tions, it also allows the user to take the initia- tive at any time. * * * The user can express constraints and in- tents freely, including using contextual ex- pressions.</p><p>These are a few examples of features character- istic of high-density AI, which are implemented in PizzaPal. In the remainder of the paper, we will describe the b4.ai framework architecture and components that support the PizzaPal system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Architecture</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>At a high level, the b4.ai framework is composed of three main services that run on top of a front end platform such as Amazon Alexa or Google Assistant. As illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>, the front end controls application launch, voice recognition and voice synthesis. The front end sends the tran- scription of each user input to the core dialog ser- vice, which first calls the NLU service to extract non-contextual semantic information, and inter- acts with the knowledge backend, before return- ing the bot response to the front end as a string to be spoken back to the user. All three services are implemented as REST APIs hosted on AWS EC2 instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Knowledge Service</head><p>The role of the Knowledge Service is to retrieve domain knowledge (e.g. menus, restaurant ad- dresses, as well as user prefererences), help re- solve references (e.g. when the user says "add chicken to my pizza", "chicken" might match to different possible toppings like "BBQ Chicken", "Garlic Chicken" or "Teriyaki Chicken"), and ex- ecute transactions with 3rd party services (e.g. placing the order for delivery). Even for a sin- gle domain application such as pizza ordering, this requires access to a variety of databases, APIs and services. The Knowledge Service abstracts away these different source schemas and allows unified access from the dialog service. In gen- eral, the Knowledge Service supports a variety of queries, both structured (e.g. getting the menu of a given store given its store ID) and unstructured (e.g. finding menu items matching certain key- words and key phrases), which are performed via an API defined in terms of questions about enti- ties and properties (e.g. "get the available toppings for menu item X", "resolve ingredient named N for dish type T"). The initial implementation of the Knowledge Service relies on 3rd party REST APIs, and our own PostGres and ElasticSearch databases to access restaurant and menu informa- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Natural Language Generation</head><p>The NLG service takes the semantic output gener- ated by the Dialog service and converts it to natu- ral language. We have implemented a simple, scal- able template based approach to NLG, that allows to control the language used by the system with some amount of variation. The templates incor- porate some conditionals so that entities such as menu items or ingredients can be rendered differ- ently based on entity properties and context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Natural Language Understanding</head><p>The Natural Language Understanding (NLU) ser- vice of PizzaPal converts the surface text of a user's request (taken from Alexa or Google As- sistant's APIs) into a structured semantic repre- sentation that serves as the input for the Dialog Manager. The output of the NLU follows a food ordering schema that defines what a MenuItem consists of.</p><p>Conventional task-oriented dialog systems use intent detection and slot filling to identify user's intention and extract semantic constituents from the natural language query. This intent-slot con- figuration might suffice when the backend task is outlined as a database lookup operation where the extracted slots are used as constraints and the re- trieved information is presented to the user by pop- ulating fixed language templates. However, it is not sufficient for building a genuinely natural con- versational system that requires frequent elaborate high-density actions. Consider the following user input:</p><p>"I want three large pizzas, the Honolulu Hawaiian, and two with cheese and chicken."</p><p>The NLU should identify three separate enti- ties (in bold) in order to resolve the ambiguity that the</p><note type="other">user requested two kinds of pizzas with differ- ent quantities instead of three Honolulu Hawaiian with extra chicken, which is inferred by the entity model. The Subsection 4.1.1 and 4.1.2 describe the intent and slot model; with Subsection 4.1.3 explains the entity model.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model Description</head><p>All the neural networks for our NLU service are trained and run using the Python deep learning li- brary <ref type="bibr">Keras (Chollet et al., 2015)</ref>, with a Tensor- Flow backend ( <ref type="bibr">Abadi et al., 2015</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Intent Model</head><p>The intent model learns a Convolutional Neural Networks (CNN) with multiple filters and fixed kernel size from an n × k representation of sen- tence using GloVe word embeddings ( <ref type="bibr">Pennington et al., 2014</ref>). Random word vectors were gen- erated for Out-of-vocabulary (OOV) words be- fore training. In addition to the word embed- ding features, we are adding a few more dimen- sions to the word representation with additional one-hot encoding categorical features based on whether the word appears in different sets of col- lections of phrases that specify ingredients, dish names, or portion sizes etc. At the time of writ- ing, there are 26 intents in the current model. A few example intents include RequestItem, GivePortionSize, and AddToppings etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Slot Model</head><p>Slot model is independent of the intent model, which allows different intents to share the same set of slots. The input for learning the slot model is identical to that for learning the intent model. The slot model learns a Bidirectional Long Short- Term Memory (LSTM) Networks with dropout and emits a slot label for each token in the word sequence. Currently, the slot model pre- dicts a label from a total of 21 slots. Example slots include dish name, portion size, and ingredient etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Entity Model</head><p>Similar to the slot model, the entity model learns a Bidirectional LSTM Networks with dropout that emits one of the B, I, O labels for each token in the word sequence to indicate the boundaries of sep- arate entities. Usually an entity corresponds to a MenuItem in the schema. As shown in the ex- ample user request below, each underlined chunk of text represents an entity.</p><p>"I'd like two large hand tossed Hawaiian and a medium cheese pizza with double pepperoni."</p><p>In addition to the word embedding and categor- ical features as used for learning the intent and slot model, the input for learning the entity model ad- ditionally contains the one-hot encoding of the slot label information. The ground truth slot labels are used for training the entity model, while during prediction the output of the slot model is used as features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data Collection</head><p>In order to bootstrap our NLU models before we obtain real user data from the released product, we have been leveraging crowdsourcing to generate reasonable sentences for the various intents, slots and entities. We have collected both freeform sen- tences by giving crowdworkers a general scenario and asking them what they would say to PizzaPal, as well as paraphrases, for which we provide a tar- get sentence with known annotation and ask work- ers to provide variations with the same meaning. The first approach has proven useful to uncover intents, slots and ways to formulate queries, while the paraphrase approach allows us to rapidly col- lect data for specific intents and scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Dialog Management</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overview</head><p>Once the NLU service has extracted intents, slots and entities from a user utterance, the Dialog ser- vice first updates the persistent state of the dia- log based on the new input, and second decides what response to give to the user. Recent work on dialog management has focused on Deep Learn- ing based approaches ( <ref type="bibr">Liu et al., 2018)</ref>, show- ing great promise when large amounts of train- ing dialog data are available. We also believe that such data-driven approaches are part of the solu- tion to scale high-density AI. However, in order to bootstrap an initial system that displays our target flexibility and naturalness, we opted for an engi- neered solution based on data structures and al- gorithms inspired by computational linguistics re- search. Specifically, the two core components of • A topic stack which tracks the hierarchical topic structure of the conversation and al- lows switching to new topics and coming back to previous topics. This is inspired by the RavenClaw architecture <ref type="bibr">(Bohus and Rudnicky, 2009</ref>). Practically speaking, the stack contains modules, each in charge of a partic- ular subdialog.</p><p>• An entity reference set that can be retrieved by content as well as recency to match refer- ring expressions provided by the user such as "my pizza", "the large one", "the pepperoni", etc.</p><p>In the current implementation, the domain logic within each module is implemented in Python code. We are also exploring ways of implementing modules as Deep Networks trained on example di- alogs for both state tracking and decision making.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Example Runtime Flow</head><p>Initially, the stack contains the root module. Af- ter each user input, the stack is traversed from top to bottom and each module attempts to interpret the NLU according to its own context to update the dialog state. As soon as a module does so, the iteration stops and the decision making phase starts, where the module at the top of the stack can either output a prompt to the user, push an- other module, or pop itself from the stack, indi- cating that it has completed its intended subtask. For example, one module might be in charge of handling the specification of one item from the menu (HandleItem). When executing this mod- ule, it might decide (e.g. based on information from the backend about the given item) that it needs to enquire about the size of the item, and push another module specialized in this subtask AskSize. If, instead of answering the ques- tion by providing a size, the user asks a question (e.g. "How big is a large?"), the corresponding module is pushed on top of the stack and han- dles the question (ProvideSizeInfo). Once it is done (presumably by providing the answer), ProvideSizeInfo pops itself from the stack and AskSize is back on top and tries again to obtain a size from the user. <ref type="figure" target="#fig_3">Figure 4</ref> shows a sim- plified example of a dialog flow and the evolution of the stack. Modules operate as asynchronous functions that perform a task. Once a module is completed (which could involve several turns of interactions with the user), it returns the information that it was able to obtain from the user to its calling module via callback function. This asynchronous mecha- nism allows the system to both lead the conversa- tion to complete the task, while also leaving the option of the user to switch topics and ask ques- tions, without losing track of the main task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Challenges</head><p>The ambitious goals of high-density AI outlined in section 1 raise significant challenges on all com- ponents of the system. First, of course, are speech recognition errors, which, even given the high quality of ASR provided by today's voice plat- forms, are still prominent for certain idiosyncratic words or phrases. Since we do not control the ASR module, there is little we can do here, though we have observed that training the NLU on prop- erly annotated ASR output help resolves the most common issues (e.g. "I want two pizzas" misrec- ognized as "I want to pizzas").</p><p>Even when ASR faithfully transcribes the ut- terances, some nuances that are essential to un-derstanding the user intent are sometimes minute such as the difference between "I want a pepperoni pizza" and "I just want a pepperoni pizza" which, in some contexts, means that the user wants to re- move all other items from the order. This type of small but crucial distinctions, characteristic of high-density AI, point to the limitations of the tra- ditional intent/slot approach where every nuance must be captured by a different intent. In addition, while it is more practical to implement NLU as independent of context (and leave the contextual interpretation to the Dialog service), the strong in- fluence of context on interpretation makes NLU labeling (both by human annotators, particularly when crowdsourcing the task, and by the trained DNNs) a challenging task. For these reasons, we are exploring new approaches to conversational NLU that avoid these pitfalls by integrating Dia- log and NLU more tightly.</p><p>Finally, we found that project and product man- agement tasks for high-density AI, while critical to the development of a robust and useful prod- uct, present some significant challenges too. Be- cause dialog flows are never rigidly defined and the user can always say anything at any point of the conversation, representing different features of the agent (e.g. "supporting crust customization") for purposes of communication between product, engineering and QA teams is a non trivial prob- lem. Similarly, traditional metrics used for track- ing progress toward milestones and product re- leases often fail to capture the seemingly infinite number of ways users can interact with each fea- ture. We believe that new metrics, tools and pro- cesses appropriate to high-density AI systems are a critical requirement toward the development of large scale successful conversational products and we are actively working on building them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we present PizzaPal, a pizza ordering bot that customers can interact with through Ama- zon Alexa and Google Assistant using multi-turn dialogs with natural language. It is based on a pro- prietary dialog framework developed by b4.ai and is the first implementation of High-Density Con- versational AI (#highdensityai) as a commercially viable product.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Leveraging Natural Conversation for Breadth vs Density</figDesc><graphic url="image-1.png" coords="2,104.65,62.81,385.52,297.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example dialogue with PizzaPal. 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of the b4.ai dialog framework.</figDesc><graphic url="image-2.png" coords="3,115.99,62.81,362.84,172.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Example of Dialog Flow</figDesc><graphic url="image-3.png" coords="5,104.65,62.81,385.51,127.13" type="bitmap" /></figure>

			<note place="foot" n="1"> According to Smith (2017), the retention rate after two weeks for Alexa skills was only 6% in September 2017.</note>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
