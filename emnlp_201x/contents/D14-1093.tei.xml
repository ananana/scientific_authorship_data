<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Domain Adaptation for CRF-based Chinese Word Segmentation using Free Annotations</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijia</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Design ‡Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution" key="instit1">†Singapore University of Technology</orgName>
								<orgName type="institution" key="instit2">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Design ‡Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution" key="instit1">†Singapore University of Technology</orgName>
								<orgName type="institution" key="instit2">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Design ‡Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution" key="instit1">†Singapore University of Technology</orgName>
								<orgName type="institution" key="instit2">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Design ‡Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution" key="instit1">†Singapore University of Technology</orgName>
								<orgName type="institution" key="instit2">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Design ‡Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution" key="instit1">†Singapore University of Technology</orgName>
								<orgName type="institution" key="instit2">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Domain Adaptation for CRF-based Chinese Word Segmentation using Free Annotations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="864" to="874"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Supervised methods have been the dominant approach for Chinese word segmen-tation. The performance can drop significantly when the test domain is different from the training domain. In this paper, we study the problem of obtaining partial annotation from freely available data to help Chinese word segmentation on different domains. Different sources of free annotations are transformed into a unified form of partial annotation and a variant CRF model is used to leverage both fully and partially annotated data consistently. Experimental results show that the Chi-nese word segmentation model benefits from free partially annotated data. On the SIGHAN Bakeoff 2010 data, we achieve results that are competitive to the best reported in the literature.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Statistical Chinese word segmentation gains high accuracies on newswire <ref type="bibr" target="#b22">(Xue and Shen, 2003;</ref><ref type="bibr" target="#b24">Zhang and Clark, 2007;</ref><ref type="bibr" target="#b5">Jiang et al., 2009;</ref><ref type="bibr" target="#b27">Zhao et al., 2010;</ref><ref type="bibr" target="#b15">Sun and Xu, 2011</ref>). However, man- ually annotated training data mostly come from the news domain, and the performance can drop severely when the test data shift from newswire to blogs, computer forums and Internet literature ( <ref type="bibr" target="#b11">Liu and Zhang, 2012)</ref>.</p><p>Several methods have been proposed for solv- ing the domain adaptation problem for segmenta- tion, which include the traditional token-and type- supervised methods ( <ref type="bibr" target="#b14">Song et al., 2012;</ref><ref type="bibr" target="#b25">Zhang et al., 2014</ref>). While token-supervised methods rely on manually annotated target-domain sentences, type-supervised methods leverage manually as- sembled domain-specific lexicons to improve target-domain segmentation accuracies. Both</p><formula xml:id="formula_0">. . 浦 . 东 . 开 . 发 . 与 . 法 . 制 . 建 .</formula><p>设 . The segmentation problem, illustrated using the sentence "浦东 (Pudong) 开发 (devel- opment) 与 (and) 法制 (legal) 建设 (construc- tion)". Possible segmentation labels are drawn un- der each character, where b, m, e, s stand for the beginning, middle, end of a multi-character word, and a single character word, respectively. The path shows the correct segmentation by choosing one label for each character. methods are competitive given the same amount of annotation effects ( <ref type="bibr" target="#b4">Garrette and Baldridge, 2012;</ref><ref type="bibr" target="#b25">Zhang et al., 2014</ref>). However, obtaining manually annotated data can be expensive.</p><p>On the other hand, there are free data which contain limited but useful segmentation informa- tion over the Internet, including large-scale un- labeled data, domain-specific lexicons and semi- annotated web pages such as Wikipedia. In the last case, word-boundary information is contained in hyperlinks and other markup annotations. Such free data offer a useful alternative for improving the segmentation performance, especially on do- mains that are not identical to newswire, and for which little annotation is available.</p><p>In this paper, we investigate techniques for adopting freely available data to help improve the performance on Chinese word segmentation. We propose a simple but robust method for construct- ing partial segmentation from different sources of free data, including unlabeled data and the Wikipedia. There has been work on making use of both unlabeled data ( <ref type="bibr" target="#b15">Sun and Xu, 2011;</ref><ref type="bibr" target="#b19">Wang et al., 2011</ref>) and Wikipedia ( <ref type="bibr" target="#b7">Jiang et al., 2013)</ref> to improve segmentation. However, no empiri- cal results have been reported on a unified ap- proach to deal with different types of free data. We use a conditional random fields ( <ref type="bibr" target="#b8">Lafferty et al., 2001;</ref><ref type="bibr" target="#b18">Tsuboi et al., 2008)</ref> variant that can lever- age the partial annotations obtained from different sources of free annotation. Training is achieved by a modification to the learning objective, incorpo- rating partial annotation likelihood, so that a single model can be trained consistently with a mixture of full and partial annotation.</p><p>Experimental results show that our method of using partially annotated data can consistently im- proves cross-domain segmentation performance. We obtain results which are competitive to the best reported in the literature. Our segmentor is freely released at https://github.com/ ExpResults/partial-crfsuite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Obtaining Partially Annotated Data</head><p>We model the Chinese word segmentation task as a character sequence tagging problem, which is to give each character in a sentence a word-boundary tag <ref type="bibr" target="#b22">(Xue and Shen, 2003)</ref>. We adopt four tags, b, m, e and s, which represent the beginning, middle, end of a multi-character word, and a single char- acter word, respectively. A manually segmented sentence can be represented as a tag sequence, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>We investigate two major sources of freely- available annotations: lexicons and natural anno- tation, both with the help of unannotated data. To make use of the first source of informa- tion, we incorporate words from a lexicon into unannotated sentences by matching of character sequences, resulting in partially annotated sen- tences, as shown in <ref type="figure" target="#fig_3">Figure 2a</ref>. In this example, the word "狐 岐 山 (the Huqi Mountain)" in the unannotated sentence matches an item in the lex- icon. As a result, we obtain a partially-annotated sentence, in which the segmentation ambiguity of the characters "狐 (fox)", "岐 (brandy road)" and "山 (mountain)" are resolved ("狐" being the be- ginning, "岐" being the middle and "山" being the end of the same word). At the same time, the seg- mentation ambiguity of the surrounding characters "在 (at)" and "救 (save)" are reduced ("在" be- ing either a single-character word or the end of a multi-character word, and "救" being either a single-character word or the beginning of a multi- character word). . .  Natural annotation, which refers to word boundaries that can be inferred from URLs, fonts or colors on web pages, also result in partially- annotated sentences. Taking a web page shown in <ref type="figure" target="#fig_3">Figure 2b</ref> for example. It can be inferred from the URL tags on "乳铁蛋白" that "乳" should be either the beginning of a multi-character word or a single-character word, and "白" should be either the end a multi-character word or single-character word. Similarly, possible tags of the surrounding character "如" and "、" can also be inferred.</p><formula xml:id="formula_1">. . 在 . 狐 . 歧 . 山 . 救 . 治 . 碧 . 瑶 . ， . b . b . b . b . b . b . b . b . b . m . m . m . m . m . m . m .</formula><formula xml:id="formula_2">如 . 乳 . 铁 . 蛋 . 白 . 、 . 溶 . 菌 . 酶 .</formula><p>We turn both lexicons and natural annotation into the same form of partial annotation with same unresolved ambiguities, as shown in <ref type="figure" target="#fig_3">Figure  2</ref>, and use them together with available full anno- tation <ref type="figure" target="#fig_0">(Figure 1)</ref> as the training data for the seg- mentor. In this section, we describe in detail how to obtain partially annotated sentences from each resource, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Lexicons</head><p>In this scenario, we assume that there are unla- beled sentences along with a lexicon for the target domain. We obtain partially segmented sentences by extracting word boundaries from the unlabeled sentences with the help of the lexicon. Previous matching methods ( <ref type="bibr" target="#b21">Wu and Tseng, 1993;</ref><ref type="bibr" target="#b20">Wong and Chan, 1996)</ref> for Chinese word segmentation largely rely on the lexicons, and are generally con- sidered being weak in ambiguity resolution (Gao People's Daily 看到 (saw) 海南 (Hainan) 旅游业 (tourist industry) 充满 (full) 希望 (hope) saw tourist industry in Hainan is full of hope Wikipedia 主要(mainly) 是(is) 旅游 (tourist) 业 (industry) 和(and) 软件 (software) 产业(industry) mainly is tourist industry and software industry  In this paper, we apply two matching schemes to the same raw sentences to obtain partially an- notated sentences. The first is a simple forward- maximum matching (FMM) scheme, which is very close to the forward maximum matching al- gorithm of Wu and Tseng (1993) for Chinese word segmentation. This scheme scans the input sen- tence from left to right. At each position, it at- tempts to find the longest subsequence of Chi- nese characters that matches a lexicon entry. If such an entry is found, the subsequence is tagged with the corresponding tags, and its surrounding characters are also constrained to a smaller set of tags. If no subsequence is found in the lexicon, the character is left with all the possible tags. Taking the sentence in <ref type="figure" target="#fig_3">Figure 2a</ref> for example. When the algorithm scans the second character, "狐", and finds the entry "狐岐山" in the lexicon, the sub- sequence of characters is recognized as a word, and tagged with b, m and e, respectively. At the same time, the previous character "在" can be in- ferred as only end of a multi-character word (e) or a single-character word (s). The second matching scheme is backward maximum matching, which can be treated as the application of FMM on the reverse of unlabeled sentences using a lexicon of reversed words.</p><p>To mitigate the errors resulting from one single matching scheme, we combine the two matching results by agreement. The basic idea is that if a subsequence of sentence is recognized as word by multiple matching results, it can be considered as a more precise annotation. Our algorithm reads par- tial segmentation by different methods and selects the subsequences that are identified as word by all methods as annotated words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Natural Annotation</head><p>We use the Chinese Wikipedia for natural anno- tation. Partially annotated sentences are readily formed in Wikipedia by markup syntax, such as URLs. However, some subtle issues exist if the sentences are used directly. One problem is in- compatibility of segmentation standards between the annotated training data and Wikipedia. <ref type="bibr" target="#b5">Jiang et al. (2009)</ref> discuss this incompatibility problem between two corpora -the CTB and the Peo- ple's Daily; the problem is even more severe on Wikipedia because it can be edited by any user. <ref type="table" target="#tab_0">Table 1a</ref> shows a case of incompatible annota- tion between the People's Daily data and natural annotation in Wikipedia, where the three charac- ters "旅游业" are segmented differently. Both can be treated as correct, although they have different segmentation granularities.</p><p>Another problem is the intrinsic ambiguity of segmentation. The same character sequence can be segmented into different words under differ- ent contexts. If the training and test data contain different contexts, the learned model can give in- correct results on the test data. This is particu- larly true across different domains. <ref type="table" target="#tab_0">Table 1b</ref> gives such an example, where the character sequence "字段" is segmented differently in two of our test domains, but both cases exist in Wikipedia.</p><p>In summary, Wikipedia introduces both use- ful information for domain adaptation and harm- ful noise with negative effects on the model. To achieve better performance of domain adaptation using Wikipedia, one intuitive approach is to se- lect more domain-related data and less irrelevant data to minimize the risks that result from incom- patible annotation and domain difference.</p><p>To this end, we assume that there are some raw sentences on the target domain, which can be used to evaluate the relevance between Wikipedia and target domain test data. We assume that URL- tagged entries reflect the segmentation standards of Wikipedia sentence, and use them to match Wikipedia sentences with the raw target domain data. If the character sequence of any URL-tagged entry in a Wikipedia sentence matches the target domain data, the Wikipedia sentence is selected for training. Another advantage of such data se- lection is that the training time consumption can be reduced by reducing the size of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CRF for Word Segmentation</head><p>We follow the work of <ref type="bibr" target="#b27">Zhao et al. (2010)</ref> and <ref type="bibr" target="#b15">Sun and Xu (2011)</ref>, and adopt the Conditional Random Fields (CRF) model ( <ref type="bibr" target="#b8">Lafferty et al., 2001</ref>) for the sequence labeling problem of word segmentation. Given an input characters sequence, the task is to assign one segmentation label from {b, m, e, s} on each character. Let x = (x 1 , x 2 , ..., x T ) be the sequence of characters in sentence whose length is T , and y = (y 1 , y 2 , ..., y T ) be the correspond- ing label sequence, where y i ∈ Y . The linear- chain conditional random field for Chinese word segmentation can be formalized as</p><formula xml:id="formula_3">p(y|x) = 1 Z exp T ∑ t=1 ∑ k λ k f k (y t , y t−1 , x) (1)</formula><p>where λ k are the model parameters, f k are the fea- ture functions and Z is the probability normalizer.</p><formula xml:id="formula_4">Z = ∑ y exp T ∑ t=1 ∑ k λ k f k (y t , y t−1 , x)<label>(2)</label></formula><p>We follow Sun and Xu (2011) and use the fea- ture templates shown in <ref type="table" target="#tab_1">Table 2</ref> to model the seg- mented task. For ith character in the sentence, the n-gram features represent the surrounding charac- ters of this character; T ype categorizes the charac- ter it into digit, punctuation, english and other; Identical indicates whether the input character is the same with its surrounding characters. This feature captures repetition patterns such as "试 试 (try)" or "走走 (stroll)". For fully-annotated training data, the learning problem of conditional random fields is to maxi- mize the log likelihood over all the training data ( <ref type="bibr" target="#b8">Lafferty et al., 2001</ref>)</p><formula xml:id="formula_5">Type Template unigram C s (i − 3 &lt; s &lt; i + 3) bigram C s C s+1 (i − 3 &lt; s &lt; i + 2) C s C s+2 (i − 3 &lt; s &lt; i + 1) type T ype(C i ) T ype(C s )T ype(C s+1 ) (i − 1 &lt; s &lt; i + 2) identical Identical(C s , C s+1 ) (i − 3 &lt; s &lt; i + 1) Identical(C s , C s+2 ) (i − 3 &lt; s &lt; i)</formula><formula xml:id="formula_6">L = N ∑ n=1 log p(y (n) |x (n) )</formula><p>Here N is the number of training sentences. Both the likelihood p(y (n) |x (n) ) and its gradient can be calculated by performing the forward-backward algorithm ( <ref type="bibr" target="#b0">Baum and Petrie, 1966</ref>) on the se- quence, and several optimization algorithm can be adopted to learn parameters from data, including L-BFGS ( <ref type="bibr" target="#b10">Liu and Nocedal, 1989)</ref> and SGD (Bot- tou, 1991).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Training a CRF with partially annotated data</head><p>For word segmentation with partially annotated data, some characters in a sentence can have a definite segmentation label, while some can have multiple labels with ambiguities remain- ing. Taking the partially annotated sentence in <ref type="figure" target="#fig_3">Figure 2a</ref> for example, the corresponding potential label sequence for "在狐岐山救" is {(e, s), (b), (m), (e), (b, s)}, where the characters "狐", "岐" and "山" have fixed labels but for "在" and "救", some ambiguities exist. Note that the full annotation in <ref type="figure" target="#fig_0">Figure 1</ref> can be regarded as a special case of partial annotation, where the num- ber of potential labels for each character is one. We follow <ref type="bibr" target="#b18">Tsuboi et al. (2008)</ref> and model marginal probabilities over partially annotated data. Define the possible labels that correspond to the partial annotation as</p><formula xml:id="formula_7">L = (L 1 , L 2 , ..., L T ),</formula><p>where each L i is a non-empty subset of Y that cor- responds to the set of possible labels for x i . Let Y L be the set of all possible label sequences where</p><formula xml:id="formula_8">∀y ∈ Y L , y i ∈ L i . The marginal probability of Y L can be modeled as p(Y L |x) = 1 Z ∑ y∈Y L exp T ∑ t=1 ∑ k λ k f k (yt, yt−1, x)<label>(3)</label></formula><p>Defining the unnormalized marginal probability as</p><formula xml:id="formula_9">Z Y L = ∑ y∈Y L exp T ∑ t=1 ∑ k λ k f k (y t , y t−1 , x),</formula><p>and the normalizer Z being the same as Equation 2, the log marginal probability of Y L over N par- tially annotated training examples can be formal- ized as</p><formula xml:id="formula_10">L Y L = N ∑ n=1 log p(Y L |x) = N ∑ n=1 (log Z Y L − log Z)</formula><p>The gradient of the likelihood can be written as</p><formula xml:id="formula_11">∂L Y L ∂λ k = N ∑ n=1 T ∑ t=1 ∑ y Y L ∈L t , y ′ Y L ∈L t−1 f k (y Y L , y ′ Y L , x)p Y L (y Y L , y ′ Y L |x) − N ∑ n=1 T ∑ t=1 ∑ y,y ′ f k (y, y ′ , x)p(y, y ′ |x)</formula><p>Both Z Y L and its gradient are similar in form to Z. By introducing a modification to the forward- backward algorithm, Z Y L and L Y L can be calcu- lated. Define the forward variable for partially an- notated data α Y L ,t (j) = p Y L (x ⟨1,...,t⟩ , y t = j). A modification on the forward algorithm can be for- malized as</p><formula xml:id="formula_12">α Y L ,t (j) = { 0 j / ∈ Lt ∑ i∈L t−1 Ψt(j, i, xt)α Y L ,t−1 (i) j ∈ Lt where Ψ t (j, i, x) is a potential function that equals ∑ k λ k f k (y t = j, y t−1 = i, x t ). Similarly, for the backward variable β Y L ,t , β Y L ,t (i) = { 0 i / ∈ Lt ∑ j∈L t+1 Ψt(j, i, xt+1)β Y L ,t+1 (j) i ∈ Lt Z Y L can be calculated by α Y L (T ), and p Y L (y, y ′ |x) can be calculated by α Y L ,t−1 (y ′ )Ψ t (y, y ′ , x t )β Y L ,t (y).</formula><p>Note that if each element in Y L is constrained to one single label, the CRF model in Equation 3 degrades into Equation 1. So we can train a unified model with both fully and partially annotated data. We implement this CRF model based on a open source toolkit CRFSuite. <ref type="bibr">1</ref> In our experiments, we use the L-BFGS ( <ref type="bibr" target="#b10">Liu and Nocedal, 1989)</ref> algo- rithm to learn parameters from both fully and par- tially annotated data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We perform our experiments on the domain adap- tation test data from SIGHAN Bakeoff <ref type="bibr">2010</ref>  For comparison with related work on using a lexicon to improve segmentation, another set of test data is chosen for this setting. We use the Chi- nese Treebank (CTB) as the source domain data, and Zhuxian (a free Internet novel, also named as "Jade dynasty", referred to as ZX henceforth) as the target domain data. <ref type="bibr">3</ref> The ZX data are written in a different style from newswire, and contains many out-of-vocabulary words. This setting has been used by <ref type="bibr" target="#b11">Liu and Zhang (2012)</ref> and <ref type="bibr" target="#b25">Zhang et al. (2014)</ref> for domain adaptation of segmentation and POS-tagging. We use the standard training, development and test split. Statistics of the test data annotated by <ref type="bibr" target="#b25">Zhang et al. (2014)</ref> are shown in the second half of <ref type="table" target="#tab_4">Table 3</ref>.</p><p>The data preparation method in Section 2 and the CRF method in Section 4 are used for all the experiments. Both recall of out-of-vocabulary words (R oov ) and F-score are used to evaluate the   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Free Lexicons</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Obtaining lexicons</head><p>For domain adaption from CTB to ZX, we use a lexicon released by <ref type="bibr" target="#b25">Zhang et al. (2014)</ref>. The lexicon is crawled from a online encyclopedia 4 , and contains the names of 159 characters and ar- tifacts in the Zhuxian novel. We follow <ref type="bibr" target="#b25">Zhang et al. (2014)</ref> and name it NR for convenience of fur- ther discussion. The NR lexicon can be treated as a strongly domain-related, high quality but rel- atively small lexicon. It's a typical example of freely available lexicon over the Internet. For domain adaptation from PD to medicine and computer, we collect a list of page titles under the corresponding categories in Wikipedia. For medicine, entries under essential medicines, bi- ological system and diseases are collected. For computer, entries under computer network, Mi- crosoft Windows and software widgets are se- lected. These lexicons are typical freely available lexicons that we can access to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Obtaining Unlabeled Sentences</head><p>For ZX, partially annotated sentences are obtained using the NR lexicon and unlabeled ZX sentences by applying the matching scheme described in # of sentences * 1000 F score on development <ref type="figure">Figure 3</ref>: F-score on the development data when using different numbers of unlabeled data. Section 2. The CTB5 training data and the par- tially annotated data are mixed as the final train- ing data. Different amounts of unlabeled data are applied to the development test set, and results are shown in <ref type="figure">Figure 3</ref>. From this figure we can see that incorporating 16K sentences gives the high- est accuracy, and adding more partial labeled data does not change the accuracy significantly. So for the ZX experiments, we choose the 16K sentences as the unlabeled data.</p><p>For the medicine and computer experiments, we selected domain-specific sentences by matching with the domain-specific lexicons. About 46K out of the 5.45 million wiki sentences contain subse- quences in the medicine lexicon and 22K in the case of the computer domain. We randomly se- lect 16K sentences as the unlabeled data for each domain, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Final results</head><p>We incorporate the partially annotated data ob- tained with the help of lexicon for each of the test domain. For adaptation from CTB to ZX, we trained our baseline model on the CTB5 training data with the feature templates in  <ref type="formula" target="#formula_4">(2014)</ref> 88.34 - - - - - <ref type="table">Table 4</ref>: Final result for adapting CTB to Zhuxian and adapting PD to the medicine and computer domains, using partially annotated data (referred to as PA) obtained from unlabeled data and lexicons. trained our baseline model on the PD training data with the same feature template setting. Previous research makes use of a lexicon by adding lexicon features directly into a model ( <ref type="bibr" target="#b15">Sun and Xu, 2011;</ref><ref type="bibr" target="#b25">Zhang et al., 2014</ref>), rather than transforming them into partially annotated sen- tences. To make a comparison, we follow Sun and Xu (2011) and add three lexicon features to repre- sent whether c i is located at the beginning, middle or the end of a word in the lexicon, respectively. For each test domain, the lexicon for the lexi- con feature model consists of the most frequent words in the source domain training data (about 6.7K for CTB5 and 8K for PD, respectively) and the domain-specific lexicon we obtained in Sec- tion 5.1.1.</p><p>The results are shown in <ref type="table">Table 4</ref>, where the first row shows the performance of the baseline mod- els and the second row shows the performance of the model incorporating lexicon feature. The third row shows our method using partial anno- tation. On the ZX test set, our method outper- forms the baseline by more than 3 absolute per- centage. The model with partially annotated data performs better than the one with additional lexi- con features. Similar conclusion is obtained when adapting from PD to medicine and computer. By incorporating the partially annotated data, the seg- mentation of lexicon words, along with the con- text, is learned.</p><p>We also compare our method with the work of <ref type="bibr" target="#b25">Zhang et al. (2014)</ref>, who reported results only on the ZX test data. We use the same lexicon settings. Our method gives better result than <ref type="bibr" target="#b25">Zhang et al. (2014)</ref>, showing that the combination of a lexicon and unannotated sentence into partially annotated data can lead to better performance than using a dictionary alone in type-supervision. Given that we only explore the use of free resource, combin- ing a lexicon with unannotated sentences is a bet- ter option than using the lexicon directly.  <ref type="table" target="#tab_7">Table 5</ref>: The performance of data selection on the development set of the computer domain.</p><p>type-and token-annotation. Our partial annota- tion can thus be treated as a compromise to obtain some pseudo partial token-annotations when full token annotations are unavailable. Another thing to note is that the model of <ref type="bibr" target="#b25">Zhang et al. (2014</ref>) is a joint model for segmentation and POS-tagging, which is generally considered stronger than a sin- gle segmentation model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Free Natural Annotation</head><p>When extracting word boundaries from Wikipedia sentences, we ignore natural annotations on En- glish words and digits because these words are rec- ognized by the preprocessor. Following <ref type="bibr" target="#b7">Jiang et al. (2013)</ref>, we also recognize a naturally annotated two-character subsequence as a word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Effect of data selection</head><p>To make better use of more domain-specific data, and to alleviate noise in partial annotation, we ap- ply the selection method proposed in Section 2 to the Wikipedia data. On the computer domain development test data, this selection method re- sults in 9.4K computer-related sentences with par- tial annotation. A model is trained with both the PD training data and the partially annotated com- puter domain Wikipedia data. For comparison, we also trained a model with 160K randomly selected Wikipedia sentences. The experimental result is shown in  the domain adaption accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Final Result</head><p>The final results on the four test domains are shown in <ref type="table" target="#tab_8">Table 6</ref>. From this table, we can see that significant improvements are achieved with the help of the partially annotated Wikipedia data, when compared to the baseline. The models trained with selected partial annotation perform better than those trained with random partial an- notation. Our F-scores are competitive to those re- ported by <ref type="bibr" target="#b7">Jiang et al. (2013)</ref>. However, since their model is trained on a different source domain, the results are not directly comparable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Analysis</head><p>In this section, we study the effect of Wikipedia on domain adaptation when no data selection is per- formed, in order to analyze the effect of partially annotated data. We randomly sample 10K, 20K, 40K, 80K and 160K sentences from the 5.45 mil- lion Wikipedia sentences, and incorporate them into the training process, respectively. Five models are obtained adding the baseline, and we test their performances on the four test domains. <ref type="figure" target="#fig_7">Figure 4</ref> shows the results. From the figure we can see that for the medicine and computer domains, where the OOV rate is rel- atively high, the F-score generally increases when more data from Wikipedia are used. The trends of F-score and OOV recall against the volume of Wikipedia data are almost identical. However, for the finance and literature domains, which have low OOV rates, such a relation between data size and accuracy is not witnessed. For the literature do- main, even an opposite trends is shown.</p><p>We can draw the following conclusions: (1) Natural annotation on Wikipedia data contributes to the recognition of OOV words on domain adap- tation; (2) target domains with more OOV words benefit more from Wikipedia data. <ref type="formula" target="#formula_8">(3)</ref>   the positive effect on OOV recognition, Wikipedia data can also introduce noise, and hence data se- lection can be useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Combining Lexicon and Natural Annotation</head><p>To make the most use of free annotation, we com- bine available free lexicon and natural annotation resources by joining the partially annotated sen- tences derived using each resource, training our CRF model with these partially annotated sen- tences and the fully annotated PD sentences. The tests are performed on medicine and computer do- mains. <ref type="table" target="#tab_10">Table 7</ref> shows the results, where further improvements are made on both domains when the two types of resources are combined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>There has been a line of research on making use of unlabeled data for word segmentation. <ref type="bibr" target="#b26">Zhao and Kit (2008)</ref> improve segmentation performance by mutual information between characters, collected from large unlabeled data; <ref type="bibr" target="#b9">Li and Sun (2009)</ref> use punctuation information in a large raw corpus to learn a segmentation model, and achieve better recognition of OOV words; Sun and Xu (2011) ex- plore several statistical features derived from un- labeled data to help improve character-based word segmentation. These investigations mainly focus on in-domain accuracies. <ref type="bibr" target="#b11">Liu and Zhang (2012)</ref>  study domain adaptation using an unsupervised self-training method. In contrast to their work, we make use of not only unlabeled data, but also leverage any free annotation to achieve better re- sults for domain adaptation. There has also been work on making use of a dictionary and natural annotation for segmenta- tion. <ref type="bibr" target="#b25">Zhang et al. (2014)</ref> study type-supervised do- main adaptation for Chinese segmentation. They categorize domain difference into two types: dif- ferent vocabulary and different POS distributions. While the first type of difference can be effec- tively resolved by using lexicon for each domain, the second type of difference needs to be resolved by using annotated sentences. They found that given the same manual annotation time, a com- bination of the lexicon and sentence is the most effective. <ref type="bibr" target="#b7">Jiang et al. (2013)</ref> use 160K Wikipedia sentences to improves segmentation accuracies on several domains. Both <ref type="bibr" target="#b25">Zhang et al. (2014)</ref> and <ref type="bibr" target="#b7">Jiang et al. (2013)</ref> work on discriminative mod- els using the structure perceptron <ref type="bibr" target="#b2">(Collins, 2002</ref>), although they study two different sources of infor- mation. In contrast to their work, we unify both types of information under the CRF framework.</p><p>CRF has been used for Chinese word segmenta- tion ( <ref type="bibr" target="#b17">Tseng, 2005;</ref><ref type="bibr" target="#b13">Shi and Wang, 2007;</ref><ref type="bibr" target="#b26">Zhao and Kit, 2008;</ref><ref type="bibr" target="#b19">Wang et al., 2011</ref>). However, most pre- vious work train a CRF by using full annotation only. In contrast, we study CRF based segmenta- tion by using both full and partial annotation.</p><p>Several other variants of CRF model has been proposed in the machine learning literature, such as the generalized expectation method <ref type="bibr" target="#b12">(Mann and McCallum, 2008)</ref>, which introduce knowledge by incorporating a manually annotated feature dis- tribution into the regularizer, and the JESS-CM ( <ref type="bibr" target="#b16">Suzuki and Isozaki, 2008)</ref>, which use a EM-like method to iteratively optimize the parameter on both the annotated data and unlabeled data. In contrast, we directly incorporate the likelihood of partial annotation into the objective function. The work that is the most similar to ours is <ref type="bibr" target="#b18">Tsuboi et al. (2008)</ref>, who modify the CRF learning objec- tive for partial data. They focus on Japanese lexi- cal analysis using manually collected partial data, while we investigate the effect of partial annota- tion from freely available sources for Chinese seg- mentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we investigated the problem of do- main adaptation for word segmentation, by trans- ferring various sources of free annotations into a consistent form of partially annotated data and ap- plying a variant of CRF that can be trained using fully-and partially-annotated data simultaneously. We performed a large set of experiments to study the effectness of free data, finding that they are useful for improving segmentation accuracy. Ex- periments also show that proper data selection can further benefit the model's performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>872</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The segmentation problem, illustrated using the sentence "浦东 (Pudong) 开发 (development) 与 (and) 法制 (legal) 建设 (construction)". Possible segmentation labels are drawn under each character, where b, m, e, s stand for the beginning, middle, end of a multi-character word, and a single character word, respectively. The path shows the correct segmentation by choosing one label for each character.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>狐岐山 (Huqi Mountain) 救 治 (save) 碧 瑶 (Biyao)", where "狐岐山" matches a lexicon word.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>乳铁蛋白 (lysozyme) 、 溶菌酶 (lactoferrin)", where "乳铁蛋白" is a hyperlink.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Examples of partially annotated data. The paths show possible correct segmentations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>(</head><label></label><figDesc>a) Case of incompatible annotation on "旅游业(tourist industry)" between People's Daily and Wikipedia. Literature 《说文解字 (Shuo Wen Jie Zi, a book) 段(segmented) 注(annotated) 》 the segmented and annotated version of Shuo Wen Jie Zi Computer 每条(each) 记录(record) 被(is) 分隔(splitted) 为(into) 字段 (fields) each record is splitted into several fields (b) Similar subsequence "字段(field)" is segmented differently under different domains in Wikipedia.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>PD</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>4</head><label></label><figDesc>http://baike.baidu.com/view/18277.htm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance of the model incorporating difference sizes of Wikipedia data. The solid line represents the F-score and dashed line represents the recall of OOV words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples natural annotation from Wikipedia. Underline marks annotated words. 

et al., 2005). But for obtaining the partial labeled 
data with lexicon, the matching method can still be 
a solution. Since we do not aim to recognize every 
word from sentence, we can select a lexicon with 
smaller coverage but less ambiguity to achieve rel-
atively precise matching result. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Feature templates for the ith character.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>(Zhao et al., 2010), adapting annotated training sentences from People's Daily (PD) (Yu et al., 2001) to different test domains. The fully annotated data is selected from the People's Daily newspaper in January of 1998, and the four test domains from the SIGHAN Bakeoff 2010 include finance, medicine, literature and computer. Sample seg- mented data in the computer domain from this bakeoff is used as development set. Statistics of the data are shown in first half of Table 3. We use wikidump20140419 2 for the Wikipedia data. All the traditional Chinese pages in Wikipedia are converted to simplified Chinese. After filtering functional pages like redirection and removing du- plication, 5.45 million sentences are reserved.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>→ SIGHAN</head><label>SIGHAN</label><figDesc></figDesc><table>Data set 
Train Development 
Test 
PD 
Computer Finance 
Medicine Literature Computer 
# sent. 
19,056 
1,000 
560 
1,308 
670 
1,329 
# words 1,109,734 
21,398 
33,035 
31,499 
35,735 
35,319 
OOV 
0.1766 
0.0874 
0.1102 
0.0619 
0.1522 

CTB5 → ZX 

Data set 
Train Development 
Test 
Unlabeled 
Wikipedia 
Unlabeled 
CTB5 
ZX 
# sent. 
18,086 
788 
1,394 
32,023 
5,456,151 
# words 
493,934 
20,393 34,355 
OOV 
0.1377 0.1550 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Statistics of data used in this paper. segmentation performance. There is a mixture of Chinese characters, English words and numeric expression in the test data from SIGHAN Bakeoff 2010. To test the influence of Wikipedia data on Chinese word segmentation alone, we apply reg- ular expressions to detect English words and nu- meric expressions, so that they are marked as not segmented. After performing this preprocessing step, cleaned test input data are fed to the CRF model to give a relatively strong baseline.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table>For 
adaptation from PD to medicine and computer, we </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table>The model incorporating se-
lected data achieves better performance compared 
to the model with randomly sampled data, demon-
strating that data selection is helpful to improving </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Experimental results on the SIGHAN Bakeoff 2010 data. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>along with</head><label>with</label><figDesc></figDesc><table>Method 
Med. Com. 
F 
F 
Baseline 
91.36 93.16 
Baseline+PA (Lex) 
91.68 93.47 
Baseline+PA (Natural) 
92.47 93.93 
Baseline+PA (Lex+Natural) 92.63 94.07 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 7 :</head><label>7</label><figDesc>Results by combining different sources of free annotation.</figDesc><table></table></figure>

			<note place="foot" n="1"> http://www.chokkan.org/software/ crfsuite/ 2 http://dumps.wikimedia.org/zhwiki/ 20140419/ 3 Annotated target domain test data and lexicon are available from http://ir.hit.edu.cn/ ˜ mszhang/ eacl14mszhang.zip.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their con-structive comments. This work was supported by the National Key Basic Research Program of China via grant 2014CB340503 and the National Natural Science Foundation of China (NSFC) via grant 61133012 and 61370164, the Singapore Ministry of Education (MOE) AcRF Tier 2 grant T2MOE201301 and SRG ISTD 2012 038 from Singapore University of Technology and Design.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Statistical inference for probabilistic functions of finite state markov chains. The annals of mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Petrie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
			<biblScope unit="page" from="1554" to="1563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stochastic gradient learning in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Neuro-NˆımesNˆımes 91</title>
		<meeting>Neuro-NˆımesNˆımes 91<address><addrLine>Nimes, France. EC2</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2002 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Chinese word segmentation and named entity recognition: A pragmatic approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Ning</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="531" to="574" />
			<date type="published" when="2005-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Typesupervised hidden markov models for part-of-speech tagging with incomplete tag dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="821" to="831" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic adaptation of annotation standards: Chinese word segmentation and pos tagging-a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th</title>
		<meeting>the Joint Conference of the 47th</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<title level="m">Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting><address><addrLine>Suntec, Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="522" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminative learning with natural annotations: Word segmentation as a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lü</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yating</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria, August</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="761" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML &apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML &apos;01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Punctuation as implicit annotations for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="505" to="512" />
			<date type="published" when="2009-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the limited memory bfgs method for large scale optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="503" to="528" />
			<date type="published" when="1989-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for joint segmentation and POS-tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-12" />
			<biblScope unit="page" from="745" to="754" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012: Posters</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generalized expectation criteria for semi-supervised learning of conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gideon</forename><forename type="middle">S</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="870" to="878" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A dual-layer crfs based joint decoding method for cascaded segmentation and labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Joint Conference on Artifical Intelligence, IJCAI&apos;07</title>
		<meeting>the 20th International Joint Conference on Artifical Intelligence, IJCAI&apos;07<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1707" to="1712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Entropy-based training data selection for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prescott</forename><surname>Klassen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<meeting><address><addrLine>Mumbai, India, December</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1191" to="1200" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012: Posters</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Enhancing chinese word segmentation using unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK.</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="970" to="979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised sequential labeling and segmentation using gigaword scale unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL08: HLT</title>
		<meeting>ACL08: HLT<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="665" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A conditional random field word segmenter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihsin</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth SIGHAN Workshop on Chinese Language Processing</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Training conditional random fields using incomplete annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Tsuboi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisashi</forename><surname>Kashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-08" />
			<biblScope unit="page" from="897" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improving chinese word segmentation and pos tagging with semi-supervised methods using large auto-analyzed data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Jun&amp;apos;ichi Kazama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing<address><addrLine>Chiang Mai, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-11" />
			<biblScope unit="page" from="309" to="317" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Chinese word segmentation based on maximum matching and word binding force</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chorkin</forename><surname>Pak-Kwong Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference on Computational Linguistics</title>
		<meeting>the 16th Conference on Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="200" to="203" />
		</imprint>
	</monogr>
	<note>COLING &apos;96</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Chinese text segmentation for text retrieval: Achievements and problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zimin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gwyneth</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Soc. Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="532" to="542" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Chinese word segmentation as lmr tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Second SIGHAN Workshop on Chinese Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="176" to="179" />
		</imprint>
	</monogr>
	<note>SIGHAN &apos;03. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Processing norms of modern chinese corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiwen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuefeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiming</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyong</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Zhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Chinese segmentation with a word-based perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="840" to="847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Type-supervised domain adaptation for joint segmentation and pos-tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-04" />
			<biblScope unit="page" from="588" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An empirical comparison of goodness measures for unsupervised chinese word segmentation with a unified framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Third International Joint Conference on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>IJCNLP-2008</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A unified character-based tagging framework for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Ning</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bao-Liang</forename><surname>Lu</surname></persName>
		</author>
		<idno>5:1-5:32</idno>
		<imprint>
			<date type="published" when="2010-06" />
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
