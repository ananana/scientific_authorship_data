<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Limbic: Author-Based Sentiment Aspect Modeling Regularized with Word Embeddings and Discourse Relations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhang</surname></persName>
							<email>zhangzhe@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science North</orgName>
								<orgName type="institution" key="instit1">Watson Group IBM Corporation Research Triangle Park</orgName>
								<orgName type="institution" key="instit2">Carolina State University Raleigh</orgName>
								<address>
									<postCode>27703-9141, 27695-8206</postCode>
									<region>NC, NC</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munindar</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
							<email>singh@ncsu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science North</orgName>
								<orgName type="institution" key="instit1">Watson Group IBM Corporation Research Triangle Park</orgName>
								<orgName type="institution" key="instit2">Carolina State University Raleigh</orgName>
								<address>
									<postCode>27703-9141, 27695-8206</postCode>
									<region>NC, NC</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Limbic: Author-Based Sentiment Aspect Modeling Regularized with Word Embeddings and Discourse Relations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3412" to="3422"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3412</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose Limbic, an unsupervised proba-bilistic model that addresses the problem of discovering aspects and sentiments and associating them with authors of opinionated texts. Limbic combines three ideas, incorporating authors, discourse relations, and word embed-dings. For discourse relations, Limbic adopts a generative process regularized by a Markov Random Field. To promote words with high semantic similarity into the same topic, Lim-bic captures semantic regularities from word embeddings via a generalized Pólya Urn process. We demonstrate that Limbic (1) discovers aspects associated with sentiments with high lexical diversity; (2) outperforms state-of-the-art models by a substantial margin in topic cohesion and sentiment classification.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>How can we understand opinionated texts, e.g., so- cial media postings, expressing sentiments about various entities? Three phenomena are key. First, even for similar entities, authors may differ both on aspects and sentiments about those aspects. For example, when reviewing a hotel, Alice may consider aspects such as Concierge and Room, whereas Bob may consider aspects such as Nearby and Room. Capturing similarities and differences among authors can help produce recommenda- tions for services that are better aligned with a user's expectations ( <ref type="bibr" target="#b30">Wang et al., 2013)</ref>. Second, reviews exhibit discourse structure, i.e., relations between propositions, which carries valuable in- formation about sentiment. Third, crucial relation- ships between rare words are lost because each re- view may be short and use distinct rare words.</p><p>Probabilistic topic models <ref type="bibr" target="#b9">(Hofmann, 1999;</ref><ref type="bibr" target="#b1">Blei et al., 2003</ref>) provide an unsupervised means to learn latent constructs from texts. Author- specific topic discovery associates texts with their authors <ref type="bibr" target="#b26">(Rosen-Zvi et al., 2004;</ref><ref type="bibr" target="#b11">Kim et al., 2012;</ref><ref type="bibr" target="#b4">Diao and Jiang, 2013</ref>) but ignores sentiments. Sentiment analysis methods jointly model aspects and sentiments but exclude either authors <ref type="bibr" target="#b14">(Lazaridou et al., 2013)</ref>, discourse relations ( <ref type="bibr" target="#b20">Mukherjee et al., 2014;</ref><ref type="bibr" target="#b25">Poddar et al., 2017)</ref>, or both ( <ref type="bibr" target="#b10">Jo and Oh, 2011;</ref><ref type="bibr" target="#b16">Lin et al., 2012;</ref><ref type="bibr" target="#b12">Kim et al., 2013)</ref>.</p><p>Word co-occurrence sparsity plagues existing approaches, which model documents as distribu- tions over latent topics and estimate them from word co-occurrence. Since word frequency fol- lows a power law, most words are rare and rep- resentative words of a topic rarely co-occur, es- pecially in short opinionated texts, despite seman- tic proximity. For example, a reviewer would not use both spotless and immaculate to express a pos- itive sentiment toward the cleanliness of a hotel room. Losing information about word relatedness impedes learning effectiveness, producing topics that are not semantically cohesive.</p><p>We contribute Limbic, an unsupervised prob- abilistic model for discovering author-based as- pects and sentiments from opinionated texts that incorporates discourse-level topic modeling and semantic cohesion. (1) It associates authors and sentiment-aspect pairs by generating a mixture over sentiments and aspects for each author. (2) It captures discourse relations by applying a Markov Random Field over Sentiment Expression Units (SEUs), i.e., text elements describing sentiment- aspect pairs. (3) It promotes words with high semantic similarity into the same topic by incor- porating semantic regularities from word embed- dings using a generalized Pólya Urn process.</p><p>We empirically compare Limbic with state-of- the-art models using datasets from two domains. Qualitatively, Limbic discovers aspect-sentiment pairs with higher lexical diversity. Quantitatively, Limbic obtains substantial improvements in topic cohesion and sentiment classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model and Inference in Limbic</head><p>We now introduce our proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sentiment Expression Unit (SEU)</head><p>Existing topic models represent documents as bags of words or as sentences. Bag-of-words mod- els, e.g., LDA ( <ref type="bibr" target="#b1">Blei et al., 2003)</ref>, AT <ref type="bibr">(RosenZvi et al., 2004</ref>), JST ( <ref type="bibr" target="#b16">Lin et al., 2012</ref>), JAST ( <ref type="bibr" target="#b20">Mukherjee et al., 2014)</ref>, and AATS ( <ref type="bibr" target="#b25">Poddar et al., 2017)</ref>, rely on word co-occurrence at the docu- ment level, which is problematic when applied to opinionated texts. Sentence-based models, e.g., ASUM (Jo and Oh, 2011), assume that words ap- pearing in a sentence belong to the same aspect and sentiment, which often fails to hold in real text. For instance, the TripAdvisor review sen- tence Service was good and friendly, location is good and my room was spacious but oldish, ex- hibits three aspects, Service, Location, and Room, and two sentiments. <ref type="bibr" target="#b33">Zhang and Singh's (2014)</ref> segmentation algorithm leverages transition cues to convert sentences into segments. Although tran- sition cues are good indicators for capturing senti- ment change, their algorithm disregards syntactic information in sentences, which also helps reveal changes of aspects and sentiments. Figure 1: Generate SEUs from a sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROOT</head><p>We propose a concept of sentiment expression unit (SEU). Each SEU contains either a sentiment, or an aspect, or both. We extract SEUs by incor- porating both discourse and syntactic information. We first split sentences in reviews into snippets based on contradiction transition cues, such as but. Then we apply a grammar parser on each snip- pet. We extract phrases from snippets by using two syntactic patterns commonly observed in opinion- ated texts including (1) existential (EX) with verb (VB) and adjective (JJ) and (2) noun (NN) with verb (VB) and adjective (JJ). If a phrase matches a pattern, we identify it as an SEU. Otherwise, the phrase joins its following phrases iteratively un- til the combination matches a pattern. <ref type="figure">Figure 1</ref> demonstrates the process of generating SEUs from the above hotel review sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Discourse Relation</head><p>Markov Random Field (MRF) is a probabilistic framework to model statistical dependencies be- tween variables. Limbic applies an MRF to cap- ture the discourse relations between SEUs. Given a document containing N SEUs, let a i and s i be the aspect and sentiment assignments of SEU i , respectively. Limbic creates an undirected edge s i , s j between the sentiment assignments of this SEU and its preceding SEU. Let r be the discourse relation between SEUs, Limbic imposes a binary potential on the edge.</p><p>Limbic focuses on two discourse relations fre- quently observed in opinionated texts: Compari- son and Expansion. Comparison highlights promi- nent differences between two SEUs and often signals a change of sentiment regardless of the change of aspect. For example, in SEU 1 : {The location was great} and SEU 2 : {but it was just too noisy}, we see that but indicates a sentiment dif- ference. Other transition cues for Comparison in- clude however, in contrast, and such.</p><p>Expansion extends the discourse and indicates a continuation of sentiment across SEUs. For ex- ample, in SEU 3 : {There are no safes here which is unfortunate} and SEU 4 : {And speaking of un- fortunate, the breakfast is hardly impressive}, we see that and and unfortunate indicate the negative sentiment in SEU 3 continues toward aspect Break- fast in SEU 4 . Other transition cues for Expansion include also, moreover, and such. Formally, R r,i,j asserts discourse relation r be- tween SEU i and SEU j . For Comparison, R c,i,j holds if s i = s j , SEU j contains Comparison cues, and (1) SEU j contains syntactic patterns described in Section 2.1 and a i = a j or (2) SEU j contains incomplete syntactic patterns and a i = a j .</p><p>For Expansion, R e,i,j holds if s i = s j , SEU j contains Expansion cues, and (1) SEU j contains syntactic patterns and a i = a j or (2) SEU j con- tains incomplete syntactic patterns and a i = a j .</p><p>Given document d, the joint probability of its sentiment assignments is:</p><formula xml:id="formula_0">p(s|θ d ) = i p(s i |θ d ) exp{λ R r=1 (I(R r,i−1,i ))}, (1)</formula><p>where R is the number of discourse relation types; θ d is the sentiment distribution of d; I is an iden- tity function that returns 1 if its argument is true; λ controls reinforcing the effects of discourse re- lations.</p><p>Take the expansion relation, for example. Dur- ing the sampling process, Equation 1 generates a large value if two SEUs share an expansion rela- tion and have the same sentiments and yields a small value if the two SEUs have different senti- ments. Therefore, SEUs in an expansion relation have a high probability to be associated with the same sentiment. <ref type="figure">Figure 2</ref> shows Limbic's model. With Dir (·) and Mul (·) as Dirichlet and multinomial distributions, hyperparameter α is the Dirichlet prior of the word distribution φ, β is the Dirichlet prior of the senti- ment distribution θ, and γ is the Dirichlet prior of the aspect distribution ψ. Given a set of reviews D written by a set of authors U with regards to a set of aspects T and a set of sentiments S, the generative process in Limbic is as follows. <ref type="figure">Figure 2</ref>: Generative process of Limbic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Generative Process</head><formula xml:id="formula_1">S n N 2 N 1 N D ✓ t a w 1 … U S T ↵ s 1 s 2 s n w 2 … w n Markov Random Field G</formula><p>First, for each pair of aspect t and sentiment s, draw a word distribution φ t,s ∼ Dir (α). Second, for each author a and each sentiment s, draw an aspect distribution ψ s,a ∼ Dir (γ). Third, given a review d written by a, draw a sentiment distri- bution θ d ∼ Dir (β), and for each SEU in d, (a) choose a sentiment s using Equation 1; (b) given s, choose an aspect t ∼ Mul (ψ s,a ); (c) given t and s, sample word w ∼ Mul (φ t,s ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Model Inference</head><p>Limbic estimates p(s, t|w, a), the posterior distri- bution of latent variables, sentiments s and aspects t, given all words used in reviews written by au- thor a. We factor the joint probability of the as- signments of sentiments, aspects, and words for a:</p><formula xml:id="formula_2">p(s, t,w|a, α, β, γ) = p(w|s, t, α)p(t|s, a, γ)p(s|β).<label>(2)</label></formula><p>By integrating over</p><formula xml:id="formula_3">Φ = {φ i } S×T i=1</formula><p>, we calculate the first term of Equation 2 as follows.</p><formula xml:id="formula_4">p(w|s,t,α)= p(w|s,t,Φ)p(Φ|α)dΦ = Γ( W w=1 α w ) W w=1 Γ(α w ) S×T × S s=1 T t=1 W w=1 Γ(n w s,t +α w ) Γ W w=1 (n w s,t +α w ) ,<label>(3)</label></formula><p>where W is the size of the vocabulary; n w s,t equals the number of occurrences of the word w that are assigned to sentiment s and aspect t; and Γ(·) is the Gamma function. Next, by integrating over</p><formula xml:id="formula_5">Ψ a = {ψ i } S i=1</formula><p>, we calculate the second term in Equation 2 as follows.</p><formula xml:id="formula_6">p(t|s,γ,a)= p(t|s,Ψ a ,a)p(Ψ a |γ)dΨ a = Γ( T t=1 γ t ) T t=1 Γ(γ t ) S × S s=1 T t=1 Γ(n t s,a +γ t ) Γ T t=1 (n t s,a +γ t ) ,<label>(4)</label></formula><p>where n t s,a equals the number of SEUs in author a's reviews associated with sentiment s and aspect t.</p><p>Similarly, for the third term in Equation 2, by integrating over</p><formula xml:id="formula_7">Θ = {θ i } D i=1</formula><p>, we obtain</p><formula xml:id="formula_8">p(s|β)= p(s|Θ)p(Θ|β)dΘ = Γ( S s=1 β s ) S s=1 Γ(β s ) D × D d=1 S s=1 Γ(n s d +β s ) Γ S s=1 (n s d +β s ) × L l=1 exp{λ R r=1 (I(R r,i−1,i ))},<label>(5)</label></formula><p>where D is the number of reviews; n s d is the number of times that an SEU from review d is as- sociated with sentiment s; and n d is the number of SEUs in review d; L is the number of SEUs.</p><p>We obtain the conditional probability for a via Gibbs sampling ( <ref type="bibr" target="#b17">Liu, 1994)</ref> </p><formula xml:id="formula_9">p(s i = s, t i = t|s −i , t −i , w, a) ∝ n t s,a,−i + γ t T t=1 (n t s,a,−i + γ t ) × n s d,−i + β s S s=1 (n s d,−i + β s ) × v C i v −1 c=0 (n v t,s,−i + α v + c) C i −1 c=0 (n t,s,−i + W w=1 α w + c) × exp{λ R r=1 (I(R r,i−1,i ))} (6)</formula><p>where n t s,a , as in Equation 4, is the number of SEUs associated with sentiment s and aspect t from reviews written by author a; n s d is the number of SEUs from review d associated with sentiment s; C i is the number of words in SEU i ; C i v is the number of words v in SEU i ; n v t,s is the number of words v assigned sentiment s and aspect t; n t,s is the number of words assigned sentiment s and aspect t in all reviews; an index of −i means we exclude SEU i from the count; R, I, and R are as in Equation 1.</p><p>Equations 7, 8, and 9, respectively, approximate the probabilities of word w occurring given senti- ment s and aspect t; of aspect t of an SEU occur- ring given sentiment s and author a; of sentiment s occurring given document d.</p><formula xml:id="formula_10">φ s,t,w = n w s,t + α w W w=1 (n w s,t + α w ) . (7) ψ s,t,a = n t s,a + γ t T t=1 (n t s,a + γ t ) . (8) θ d,s = n s d + β s S s=1 (n s d + β s ) .<label>(9)</label></formula><p>Incorporating Word Embeddings. Word em- bedding approaches ( <ref type="bibr" target="#b18">Mikolov et al., 2013;</ref><ref type="bibr" target="#b24">Pennington et al., 2014</ref>) leverage local contextual in- formation surrounding words to map the words into continuous vector representations. Word em- beddings are known to effectively capture seman- tic and syntactic regularities among words. Based on word embeddings trained using Word2Vec on a hotel review dataset, we observe that the gen- erated word embeddings correctly link opinion- ated words that are semantically correlated even though they do not co-occur frequently. For ex- ample, the three closest words of spotless are im- maculate, clean, and well appointed.</p><p>A Generalized Pólya Urn Process. To promote words with high semantic similarity into the same topic, Limbic incorporates semantic regularities from word embeddings using a generalized Pólya Urn process <ref type="bibr" target="#b19">(Mimno et al., 2011)</ref>. Start with an urn containing colored balls. At each time step, randomly choose a ball from the urn, observe its color, and return it to the urn with one replicated ball of the same color. A Pólya Urn model de- scribes a random sampling process with reinforce- ment. In a generalized Pólya Urn process, given a sampled ball with a color, we put back that ball along with a certain number of balls of similar col- ors. When applied to document generation, balls of different colors represent distinct words. The similarity of colors represents semantic similarity of the words. Given words v and w in vocabulary W , we com- pute their semantic similarity sim(v, w) based on the cosine similarity between their word embed- dings. For word v, we create its similarity word set S v by adding all words w ∈ W for which sim(v, w) is higher than a predefined threshold . During sampling, if word v is drawn, we reinforce w ∈ S v via a predefined weight ρ which controls the reinforcement of semantically similar words. Sentiment Alignment. Widely used Word em- bedding approaches, such as Word2Vec ( <ref type="bibr" target="#b18">Mikolov et al., 2013</ref>), <ref type="bibr">GloVe (Pennington et al., 2014)</ref>, and fastText ( <ref type="bibr" target="#b2">Bojanowski et al., 2017)</ref>, are se- mantically oriented and do not explicitly en- code sentiment information in the generated word- vector representations. Hence, semantically re- lated words with opposite polarity may have close vectors. For example, smell and aroma are syn- onyms but smell often expresses a negative senti- ment toward aspect Cleanliness whereas aroma is often positive. Simply promoting all words may adversely affect the generated topics. Therefore, we calculate the sentiment alignment of each word in a vocabulary based on its average cosine simi- larity to the words in a general sentiment word list. In the sampling process, we promote words only if their sentiments align with sampled sentiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>To assess Limbic's effectiveness, we prepare on- line review datasets from two domains. Trip- User is a collection of hotel reviews from Trip- Advisor <ref type="table" target="#tab_1">. It contains 28,165 reviews posted by  202</ref>  <ref type="table" target="#tab_1">Table 1</ref> reports statis- tics on the datasets. We remove stop words and HTML tags, expand typical abbreviations, and mark special named entities using a rule-based algorithm (e.g., re- place a monetary amount by #MONEY#) and the Stanford Named Entity Recognizer ( <ref type="bibr" target="#b5">Finkel et al., 2005</ref>). To handle negation, we employ the Stanford Dependency Parser to detect nega- tions. For any word in a negation relation, we add the negated term as a prefix of the word, e.g., not work. Finally, we split each review into SEUs. Datasets and source code are publicly available for research purposes (Limbic, 2018).</p><note type="other">randomly selected reviewers, each of whom contributes at least 100 hotel reviews. YelpUser is a set of restaurant reviews from Yelp Dataset Challenge (2017). It contains 23,873 restaurant reviews posted by 144 users, each of whom con- tributes at least 100 reviews.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Parameter Settings</head><p>Limbic includes three hand-tuned hyperparame- ters that influence its sampling via a smoothing ef- fect on the associated multinomial distribution. It uses a short list of sentiment words shown in Ta- ble 2 as prior knowledge to set asymmetric priors.</p><p>Consider hyperparameter α, the Dirichlet prior of the word distribution. For any word in the pos- itive list, α = 0 if the word appears in an SEU assigned a negative sentiment, and α = 5 if the word appears in an SEU assigned a positive sen- timent, and conversely for words in the negative list. For all remaining words, we set α = 0.05. And, hyperparameter β = 5 for both sentiments is the Dirichlet prior of the sentiment distribution. Using T as the number of aspects, hyperparame- ter γ = 50 T is the Dirichlet prior of the aspect dis- tribution. We set the number of sentiments, S, to two (positive and negative), although our approach generalizes to additional sentiment categories. For each fold in cross validation, we pretrain two sets of Word2Vec ( <ref type="bibr" target="#b18">Mikolov et al., 2013)</ref> word embeddings with 300 dimensions and a window size of five using the training split in TripUser (hotels) and YelpUser (restaurants). We exclude words with frequency lower than three. We set the reinforcement weight ρ to 0.3 and 0.1 for hotel and restaurant reviews, respectively, and set the simi- larity threshold to 0.6. For all models, we per- form 1,000 Gibbs iterations with a burn-in phase of 200 and a sampling gap of 50 iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sentiment Aspect Discovery</head><p>Our first experiment shows how Limbic discovers sentiment-aspect pairs. We apply Limbic and all baseline models (AT, JST, ASUM, and AATS) to TripUser and YelpUser with the number of aspects set to 30. We manually assign an aspect for each cluster of words. ASUM generates the best results among baseline models. For brevity, we show only some aspects identified by Limbic and ASUM. <ref type="table" target="#tab_3">Table 3</ref> (top) shows the results on hotel reviews. We see that Limbic discovers word clusters with higher lexical diversity than ASUM. For example, for aspect Decoration, in addition to words, decor, modern and design, Limbic discovers words con- temporary, minimalist, chic, and so on. For as- pect Service, comparing with ASUM, Limbic ex- tracts an expanded list of sentiment words includ- ing competent, knowledgeable, and so on.</p><p>Limbic discovers finer and more distinctive word clusters than ASUM. For example, for aspect Cleanliness, ASUM generates a word cluster that includes negative sentiment words toward multi- ple entities, such as carpet and hallway. Limbic generates two distinctive word clusters for aspect Cleanliness. One cluster contains words, such as smoke and reek, which describe bad odor in room and hallway. The other cluster contains words such as, worn and stain, describes negative senti- ments toward carpets. By capturing word semantic relatedness, Limbic discovers highly diverse as- pects, including those that arise rarely in reviews, such as peaceful, relaxing, and lush, as positive words describing aspect Environment. Limbic yields promising results for restaurant reviews. In <ref type="table" target="#tab_3">Table 3</ref> (bottom), we see that Limbic yields more specific sentiment words than ASUM. Aspect Service in Limbic contains additional pos- itive words, efficient, prompt, knowledgeable, and so on. For aspect Decoration, Limbic produces sleek, ambiance, and so on. By incorporating con- straints from discourse relations, Limbic yields as- pects that are more sentiment coherent. For exam- ple, we see that positive aspect Portion in ASUM contains the negative word small whereas words in aspect Portion in Limbic are all positive.</p><p>We observe that restaurants associate more complex aspects than hotels-presumably, be- cause of the large variety of cuisines and thus, on average, smaller data relevant to a cuisine. <ref type="bibr" target="#b29">Titov and McDonald's (2008b)</ref> Multi-Grain LDA (MG- LDA) model performs well for hotel reviews but discovers only few ratable aspects from restaurant reviews, which they ascribe to the relatively small occurrences of words describing aspects for spe- cific cuisines (e.g., Italian) and general categories (e.g., Meat), compared with the words describing major aspects, such as Service. In contrast, Limbic discovers words describing specific cuisines, such as Mexican and Seafood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Quantitative Evaluation</head><p>Whether topics (word clusters) are semantically cohesive is an important factor in assessing topic modeling approaches. Normalized Pointwise Mu- tual Information (NPMI) ( <ref type="bibr" target="#b13">Lau et al., 2014</ref>) has strong correlation with human-judged topic coher- ence ratings and is widely used for accessing topic modeling approaches (Nguyen et al., 2015a,b;   <ref type="formula" target="#formula_2">(2015)</ref> propose a topic coherence measure, W2V, based on word embeddings. For complete- ness, we adopt both metrics. Topics with higher scores of NPMI and W2V are semantically more coherent. We compare Limbic with four baselines: AT, JST, ASUM, and AATS, using both TripUser and YelpUser based on the top 15 words in each sentiment-aspect pair. For each number of aspects, we perform five-fold cross-validation. We perform the two-tailed exact permutation test <ref type="bibr">(Good, 2005)</ref> on the improvement of Limbic over the best per- forming baseline. (Throughout, * and † indicate significance at 0.05 and 0.001, respectively.) <ref type="table" target="#tab_4">Table 4</ref> shows average NPMI and W2V scores of each model on hotel reviews for different num- bers of aspects. We observe that Limbic statisti- cally outperforms the other models for both met- rics in all settings. Limbic yields substantial im- provements, with average gains over the second best models of 6.00 and 0.18 in NPMI and W2V, respectively, which validates that the incorpora- tion of semantic regularities helps Limbic promote semantically equivalent and related words into the same aspect-sentiment pair. Of the baseline mod- els, AT yields the lowest topic coherence. AATS outperforms AT but does not perform well when the number of aspects is small, possibly due to the undesirable mixture of words with different aspects, topics, and sentiments in individual sen- tences. ASUM, and JST yield comparable results that are consistently better than AATS. <ref type="table" target="#tab_5">Table 5</ref> shows similar conclusions for restaurant reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Sentiment Classification</head><p>We now evaluate Limbic for document-level sen- timent classification visàvis`visà vis JST, ASUM, and AATS. For comparison purposes, we add a super- vised baseline, BiLSTM, using the bidirectional LSTM model <ref type="bibr" target="#b27">(Schuster and Paliwal, 1997</ref>). Bi- LSTM uses 100 as hidden state size and 0.2 as both the recurrent dropout rate and the dropout rate in the last layer. For training, we run 20 epochs with a minibatch size of 1,000. We use two datasets, TripUser and YelpUser. To collect ground-truth labels, we use integer ratings (three and above as positive and rest as negative). Note that our review datasets are imbalanced. Our re- sults are based on five-fold cross-validation (80% of each author's reviews for training and 20% for testing) with the two-tailed exact permuta- tion test. As our principal evaluation metrics, we adopt accuracy; the receiver operating char- acteristic (ROC) curve; and area under the curve (AUC). ROC and AUC are standard metrics used for evaluating classifiers on data with class imbal- ance <ref type="bibr" target="#b3">(Bradley, 1997;</ref><ref type="bibr" target="#b8">Hoens and Chawla, 2013)</ref>. <ref type="table" target="#tab_6">Tables 6 and 7</ref> report accuracy and AUC on ho- tel and restaurant reviews. AATS yields high accu- racy but low AUC due to a strong bias toward the majority class. Compared with AATS, JST yields higher AUC for both datasets but lower accuracy for TripUser. ASUM outperforms JST, indicating that sentences are more effective as units of senti- ment analysis than bags of words. Limbic signifi- cantly outperforms ASUM in all settings. For ho- tel reviews, Limbic attains average gains of 4.0% and 2.3% in accuracy and AUC, respectively. For restaurant reviews, Limbic yields average gains of 5.1% and 3.0% in accuracy and AUC, respectively. In <ref type="figure">Figure 3</ref> and 4, we compare the ROC curves of Limbic with baselines. The ROC curves show how the true positive rate (TPR) (vertical axis) varies with the false positive rate (FPR) (horizontal axis) by moving the decision boundary. We see that for all FPRs, Limbic yields the highest TPRs. Its ROC curves dominate other models' curves. The results demonstrate that, among all models, Lim-  bic achieves the best tradeoff between positive and negative sentiment classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Model Analysis</head><p>To  <ref type="bibr">(Alpaydin, 2010, p. 501)</ref>. We see that Limbic is significantly different from each variant, including L A (omitted for space).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Related Work</head><p>Sentiment and aspect discovery are often based on Latent Dirichlet Allocation (LDA) (Blei et al.,  in a document, AT conditions the probability of the topic assignment on the author of the document. <ref type="bibr">Kim et al.'s (2012)</ref> topic model captures entities mentioned in documents and models the probabil- ity of generating a word as conditioned on both entity and topic. <ref type="bibr" target="#b4">Diao and Jiang's (2013)</ref> jointly model topics, events, and users on Twitter. Al- though these models capture the author associated with a text, they do not handle sentiments. <ref type="bibr">Mukherjee et al.'s (2014)</ref> JAST model jointly considers authors, sentiments, topics, and ratings. JAST does not consider discourse relations and word semantic similarity in its generative process. <ref type="bibr" target="#b25">Poddar et al. (2017)</ref> propose a model that jointly considers author, aspect, sentiment, and the non- repetitive generation of aspect sequences. The model uses a Bernoulli process to capture the non- repetitive nature of aspect sequences. This mecha- nism does not consider discourse relations or syn- tactic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Discussion</head><p>Limbic provides an unsupervised method to dis- cover aspects and sentiments from opinionated texts. By incorporating authors as a factor, Limbic allows for reviews written by the same or similar authors to exhibit an idiosyncratic preference to- ward certain aspects and sentiments. It assigns as- pects of SEUs by sampling author-specific aspect distributions. This makes the model more suitable for opinionated texts in which aspects and sen- timents are tightly bound to authors who follow their specific criteria and preferences when writ- ing reviews. By incorporating a Markov Random Field and word embeddings into its sampling pro- cess, Limbic imposes constraints associated with discourse relations, effectively captures word se- mantic relatedness, and generates word clusters with high topic cohesion and lexical diversity. In future work, we plan to extend Limbic to capture long-distance discourse relations and the influence decay of discourse relations between SEUs as their distance increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgments</head><p>Thanks to Chung-Wei Hang and the anonymous reviewers for helpful comments, corrections and inspiration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: ROC curves comparing the performance of three models on hotel reviews.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Summary of the evaluation datasets.</head><label>1</label><figDesc></figDesc><table>Statistic 
TripUser YelpUser 

Number of reviews 
28,165 
23,873 
Number of SEUs 
484,805 359,191 
Average SEUs / review 
17 
15 
Average words / SEU 
7 
6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Sentiment words used as prior knowledge.</head><label>2</label><figDesc></figDesc><table>Positive 

good, nice, excellent, positive, fortunate, correct, free, love 
attractive, awesome, perfect, comfortable, enjoy, amazing 
fun, glad, great, happy, impressive, superior, thank, best 
satisfied, worth, not bad, recommend, fantastic, favorite 

Negative 

bad, nasty, poor, negative, unfortunate, wrong, inferior 
slow, junk, mess, not good, not like, not recommend 
unacceptable, upset, waste, small, worthless, problem 
complain, terrible, trouble, regret, annoying, not worth 
sorry, disappointed, worst, hate 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 : Top words discovered from hotel (top section) and restaurant (bottom section) reviews.</head><label>3</label><figDesc></figDesc><table>Decoration 
Service 
Cleanliness 
Environment 

ASUM 
Limbic 
ASUM 
Limbic 
ASUM 
Limbic 
Limbic 
Limbic 

room 
contemporary 
staff 
staff 
carpet 
smell 
carpet 
beautiful 
modern 
decor 
friendly 
friendly 
smell 
room 
wallpaper 
setting 
furniture 
colour 
helpful 
helpful 
stain 
cigarette 
old 
peaceful 
decor 
tasteful 
desk 
attentive 
bathroom 
smoke 
furniture 
relaxing 
wood 
room 
front 
courteous 
room 
floor 
paint 
golf 
lobby 
marble 
english 
hostess 
dirty 
odor 
need 
lush 
design 
chic 
professional 
professional 
furniture 
elevator 
stain 
gorgeous 
wall 
lobby 
efficient 
gracious 
wall 
reek 
worn 
environment 
color 
modern 
service 
accommodating 
hallway 
odour 
carpeting 
countryside 
look 
elegant 
reception 
welcoming 
paint 
smelt 
bedspread 
atmosphere 
style 
artwork 
attentive 
desk 
smoke 
smoking 
remodel 
ground 
bathroom 
stone 
polite 
knowledgeable 
worn 
hallway 
update 
course 
dark 
stylish 
speak 
competent 
clean 
stair 
room 
place 
ceiling 
minimalist 
courteous 
front 
old 
non-smoking 
look 
quiet 
decorate 
design 
pleasant 
service 
tile 
lift 
bathroom 
surroundings 

Service 
Decoration 
Portion 
Mexican 
Seafood 

ASUM 
Limbic 
ASUM 
Limbic 
ASUM 
Limbic 
Limbic 
Limbic 

friendly 
friendly 
decor 
decor 
portion 
portion 
asada 
crab 
server 
service 
atmosphere 
atmosphere 
size 
size 
carne 
lobster 
staff 
attentive 
place 
sleek 
small 
half 
taco 
scallop 
service 
staff 
modern 
interior 
large 
large 
tostada 
shrimp 
attentive 
helpful 
feel 
vibe 
plate 
huge 
burrito 
roll 
helpful 
efficient 
restaurant 
ambiance 
huge 
serving 
bean 
risotto 
nice 
server 
cool 
clean 
price 
big 
refried 
salmon 
waitress 
prompt 
inside 
modern 
big 
could 
corn 
mussel 
owner 
consistently 
clean 
ambience 
share 
salad 
guacamole 
calamari 
bartender 
nice 
vibe 
cozy 
#MONEY# 
eat 
cabbage 
bisque 
waiter 
professional 
nice 
contemporary 
enough 
plate 
torta 
tuna 
greet 
host 
like 
place 
half 
share 
pinto 
jumbo 
manager 
great 
interior 
comfortable 
generous 
bowl 
guac 
clam 
hostess 
quick 
space 
stylish 
bowl 
sandwich 
jalapeno 
ahi 
table 
knowledgeable 
look 
inside 
inch 
generous 
flour 
tempura 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 4 : Topic coherence: Hotel reviews. NPMI T=10 T=20 T=30 T=40 T=50 T=60</head><label>4</label><figDesc></figDesc><table>AT 
3.64 
4.04 
4.37 
4.49 
4.86 
5.14 
AATS 
5.63 
9.08 10.41 10.78 11.05 11.00 
JST 
8.99 10.78 11.45 11.54 11.56 11.46 
ASUM 
9.48 10.64 11.02 11.33 11.39 11.56 
Limbic 16.04  † 17.16  † 17.75  † 17.65  † 17.16  † 16.60  † 

W2V 
T=10 T=20 T=30 T=40 T=50 T=60 

AT 
0.10 
0.10 
0.10 
0.09 
0.09 
0.09 
AATS 
0.13 
0.16 
0.18 
0.18 
0.18 
0.18 
JST 
0.15 
0.18 
0.18 
0.19 
0.19 
0.19 
ASUM 
0.17 
0.18 
0.18 
0.18 
0.18 
0.18 
Limbic 
0.35  † 0.37  † 0.38  † 0.37  † 0.35  † 0.34  † 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 5 : Topic coherence: Restaurant reviews.</head><label>5</label><figDesc></figDesc><table>NPMI 
T=10 T=20 T=30 T=40 T=50 T=60 

AT 
5.64 
5.21 
5.30 
5.65 
6.54 
7.94 
AATS 
6.05 
8.02 
9.03 
9.35 
9.90 
9.95 
JST 
9.46 11.13 11.73 11.92 12.14 12.31 
ASUM 
8.81 
9.7 
9.92 10.09 10.07 10.04 
Limbic 11.72  † 13.41  † 13.77  † 13.06  † 12.08 11.30 

W2V 
T=10 T=20 T=30 T=40 T=50 T=60 

AT 
0.16 
0.15 
0.14 
0.13 
0.13 
0.14 
AATS 
0.11 
0.14 
0.16 
0.17 
0.18 
0.18 
JST 
0.21 
0.21 
0.20 
0.20 
0.20 
0.19 
ASUM 
0.20 
0.19 
0.18 
0.18 
0.17 
0.17 
Limbic 
0.28  † 0.29  † 0.27  † 0.25  † 0.25  † 0.25  † 

Yang et al., 2017). More recently, O'Callaghan 
et al. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 6 : Accuracy and AUC of sentiment classification on hotel reviews.</head><label>6</label><figDesc></figDesc><table>T=10 
T=20 
T=30 
T=40 
T=50 
T=60 

Accuracy 
AUC Accuracy 
AUC Accuracy 
AUC Accuracy 
AUC Accuracy 
AUC Accuracy 
AUC 

BiLSTM 
0.907 0.820 
0.907 0.820 
0.907 0.820 
0.907 0.820 
0.907 0.820 
0.907 0.820 

AATS 
0.729 0.485 
0.794 0.454 
0.809 0.443 
0.824 0.475 
0.835 0.468 
0.839 0.482 
JST 
0.601 0.813 
0.609 0.818 
0.634 0.826 
0.641 0.830 
0.654 0.835 
0.665 0.836 
ASUM 
0.793 0.828 
0.804 0.832 
0.819 0.829 
0.835 0.838 
0.850 0.835 
0.872 0.829 
Limbic 
0.838  † 0.849 * 
0.859  † 0.853 * 
0.868  † 0.857 * 
0.870  † 0.859 * 
0.885  † 0.858 * 
0.890 0.858 * 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Accuracy and AUC of sentiment classification on restaurant reviews. 

T=10 
T=20 
T=30 
T=40 
T=50 
T=60 

Accuracy 
AUC Accuracy 
AUC Accuracy 
AUC Accuracy 
AUC Accuracy 
AUC Accuracy 
AUC 

BiLSTM 
0.876 0.841 
0.876 0.841 
0.876 0.841 
0.876 0.841 
0.876 0.841 
0.876 0.841 

AATS 
0.763 0.500 
0.789 0.472 
0.785 0.474 
0.804 0.477 
0.813 0.499 
0.816 0.492 
JST 
0.579 0.708 
0.589 0.713 
0.595 0.724 
0.606 0.731 
0.629 0.727 
0.642 0.733 
ASUM 
0.773 0.775 
0.799 0.778 
0.811 0.778 
0.836 0.775 
0.859 0.752 
0.867 0.744 
Limbic 
0.872  † 0.797 * 
0.873  † 0.803  † 
0.874  † 0.795  † 
0.876  † 0.795  † 
0.877  † 0.798  ‡ 
0.876  † 0.794  † 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="true"><head>Table 8 : SEU sentiment classification accuracy.</head><label>8</label><figDesc></figDesc><table>Accuracy 
LA 
LAD 
LAW 
L 

tSEU 
0.702 
0.723 
0.733 
0.750 
tSEU(D) 
0.692 
0.715 
0.716 
0.735 

p value 
LAD:LA LAW:LA LAD:LAW L:LAD L:LAW 

tSEU 
0.015 
0.003 
0.331 0.005 0.002 
tSEU(D) 
0.017 
0.042 
0.934 0.055 0.003 

2003). LDA represents a document (for us, a re-
view) as a mixture of topics, each topic being a 
multinomial distribution over words. The learn-
ing process approximates the topic and word dis-
tributions based on their co-occurrence in docu-
ments. Titov and McDonald's (2008b) model han-
dles global and local topics involved in documents, 
and their (2008a) framework discovers topics us-
ing aspect ratings provided by reviewers. JST (Lin 
et al., 2012) and ASUM (Jo and Oh, 2011) model a 
review via multinomial distributions of topics and 
sentiments and use them to condition the proba-
bility of generating words. Kim et al. (2013) ex-
tend ASUM by allowing its probabilistic model to 
discover a hierarchical structure of aspect-based 
sentiments. Lazaridou et al. (2013) introduce dis-
course transitions into the document generating 
process as aspect and sentiment shifters. Although 
the above models produce good results, they omit 
author information, which is an intrinsic attribute 
of opinionated texts. 
Rosen-Zvi et al.'s Author Topic model (AT) 
(2004) captures authorship by building a topic dis-
tribution for each author. When generating a word </table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ethem Alpaydin</surname></persName>
		</author>
		<title level="m">Introduction to Machine Learning</title>
		<meeting><address><addrLine>Cambridge, Massachusetts</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The use of the area under the ROC curve in the evaluation of machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">P</forename><surname>Bradley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1145" to="1159" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A unified model for topics, events and users on Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiming</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18 th Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 18 th Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1869" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by Gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43 rd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 43 rd Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Ann Arbor</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<title level="m">Permutation, Parametric, and Bootstrap Tests of Hypotheses</title>
		<editor>Phillip I. Good</editor>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Springer Series in Statistics</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Imbalanced datasets: From sampling to classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Hoens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitesh</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Imbalanced Learning: Foundations, Algorithms, and Applications</title>
		<editor>Haibo He and Yunqian Ma</editor>
		<meeting><address><addrLine>Hoboken, New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="43" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 15 th Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>15 th Conference on Uncertainty in Artificial Intelligence (UAI)<address><addrLine>Stockholm</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="289" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Aspect and sentiment unification model for online review analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohan</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">Haeyun</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4 th ACM International Conference on Web Search and Data Mining (WSDM)</title>
		<meeting>the 4 th ACM International Conference on Web Search and Data Mining (WSDM)<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="815" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ETM: Entity topic models for mining documents associated with entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyungsul</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12 th IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>the 12 th IEEE International Conference on Data Mining (ICDM)<address><addrLine>Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="349" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A hierarchical aspectsentiment model for online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixia</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27 th AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 27 th AAAI Conference on Artificial Intelligence (AAAI)<address><addrLine>Bellevue</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="804" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jey Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14 th Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the 14 th Conference of the European Chapter of the Association for Computational Linguistics (EACL)<address><addrLine>Gothenburg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="530" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Bayesian model for joint unsupervised induction of sentiment, aspect and discourse representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51 st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 51 st Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1630" to="1639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Limbic</surname></persName>
		</author>
		<ptr target="https://research.csc.ncsu.edu/mas/code/limbic/.Accessed:08/23/2018" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Weakly supervised joint sentiment-topic detection from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Everson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><forename type="middle">M</forename><surname>Rüger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1134" to="1145" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The collapsed Gibbs sampler in Bayesian computations with applications to a gene regulation problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">427</biblScope>
			<biblScope unit="page" from="958" to="966" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27 th Annual Conference on Neural Information Processing Systems (NIPS)</title>
		<meeting>the 27 th Annual Conference on Neural Information Processing Systems (NIPS)<address><addrLine>Lake Tahoe</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimizing semantic coherence in topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanna</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edmund</forename><forename type="middle">M</forename><surname>Talley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Leenders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16 th Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 16 th Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Edinburgh</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="262" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Joint author sentiment topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhabrata</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurab</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachindra</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14 th International Conference on Data Mining (SDM)</title>
		<meeting>the 14 th International Conference on Data Mining (SDM)<address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="370" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improving topic models with latent feature word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Dat Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Billingsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="299" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Is your anchor going up or down? Fast and accurate supervised topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><forename type="middle">L</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Seppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">K</forename><surname>Ringger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16 th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 16 th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)<address><addrLine>Denver</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="746" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An analysis of the coherence of descriptors in topic modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Derek O&amp;apos;callaghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pádraig</forename><surname>Carthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="5645" to="5657" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19 th Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 19 th Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Author-aware aspect topic sentiment model to retrieve supporting opinions from reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lahari</forename><surname>Poddar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wynne</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mong-Li</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22 nd Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 22 nd Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Copenhagen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="472" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The authortopic model for authors and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Rosen-Zvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padhraic</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20 th Conference in Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>the 20 th Conference in Uncertainty in Artificial Intelligence (UAI)<address><addrLine>Banff, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="487" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldip</forename><forename type="middle">K</forename><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A joint model of text and aspect ratings for sentiment summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46 th Annual Meeting on Association for Computational Linguistics (ACL)</title>
		<meeting>the 46 th Annual Meeting on Association for Computational Linguistics (ACL)<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="308" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling online reviews with multi-grain topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17 th International Conference on World Wide Web (WWW)</title>
		<meeting>the 17 th International Conference on World Wide Web (WWW)<address><addrLine>Beijing</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="308" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Recommendation for new users with partial preferences by integrating product reviews with static specifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weike</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21 st International Conference on User Modeling, Adaptation, and Personalization (UMAP)</title>
		<meeting>the 21 st International Conference on User Modeling, Adaptation, and Personalization (UMAP)<address><addrLine>Rome</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="281" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adapting topic models using lexical associations with tree priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><forename type="middle">L</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22 nd Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 22 nd Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Copenhagen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1901" to="1906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<ptr target="https://www.yelp.com/datasetchallenge/.Accessed:05/20/2018" />
		<title level="m">Yelp dataset challenge</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">ReNew: A semi-supervised framework for generating domainspecific lexicons and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munindar</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52 nd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 52 nd Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Baltimore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="542" to="551" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
