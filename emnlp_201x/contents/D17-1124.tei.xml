<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Idiom-Aware Compositional Distributed Semantics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
								<address>
									<addrLine>825 Zhangheng Road</addrLine>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Qian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
								<address>
									<addrLine>825 Zhangheng Road</addrLine>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
								<address>
									<addrLine>825 Zhangheng Road</addrLine>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
								<address>
									<addrLine>825 Zhangheng Road</addrLine>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Idiom-Aware Compositional Distributed Semantics</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1204" to="1213"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Idioms are peculiar linguistic constructions that impose great challenges for representing the semantics of language, especially in current prevailing end-to-end neural models, which assume that the semantics of a phrase or sentence can be literally composed from its constitutive words. In this paper, we propose an idiom-aware distributed semantic model to build representation of sentences on the basis of understanding their contained idioms. Our models are grounded in the literal-first psycholinguistic hypothesis, which can adaptively learn semantic composi-tionality of a phrase literally or idiomatically. To better evaluate our models, we also construct an idiom-enriched sentiment classification dataset with considerable scale and abundant peculiarities of idioms. The qualitative and quantitative experimental analyses demonstrate the efficacy of our models. The newly-introduced datasets are publicly available at http: //nlp.fudan.edu.cn/data/</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Currently, neural network models have achieved great success for many natural language process- ing (NLP) tasks , such as text classification ( <ref type="bibr" target="#b43">Zhao et al., 2015;</ref><ref type="bibr" target="#b26">Liu et al., 2017)</ref>, semantic matching ( <ref type="bibr">Liu et al., 2016a,b)</ref>, and machine translation ( ). The key factor of these neural mod- els is how to compose a phrase or sentence rep- resentation from its constitutive words. Typically, a shared compositional function is used to com- pose word vectors recursively until obtaining the representation of the phrase or sentence. The form of compositional function involves many kinds of neural networks, such as recurrent neural networks <ref type="bibr" target="#b15">(Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr" target="#b5">Chung et al., 2014</ref>), convolutional neural networks <ref type="bibr" target="#b6">(Collobert et al., 2011;</ref><ref type="bibr" target="#b16">Kalchbrenner et al., 2014)</ref>, and re- cursive neural networks <ref type="bibr" target="#b39">(Socher et al., 2013;</ref><ref type="bibr" target="#b40">Tai et al., 2015;</ref><ref type="bibr" target="#b44">Zhu et al., 2015)</ref>.</p><p>However, these methods show an obvious de- fect in representing idiomatic phrases, whose se- mantics are not literal compositions of the individ- ual words. For example, "pulling my leg" is idiomatic, and its meaning cannot be directly derived from a literal combination of its con- tained words. Due to its importance, some pre- vious work focuses on automatic identification of idioms ( <ref type="bibr" target="#b18">Katz and Giesbrecht, 2006</ref>; <ref type="bibr" target="#b24">Li and Sporleder, 2009;</ref><ref type="bibr" target="#b8">Fazly et al., 2009;</ref><ref type="bibr" target="#b32">Peng et al., 2014;</ref><ref type="bibr" target="#b35">Salton et al., 2016)</ref>. However, challenge re- mains to take idioms into account to improve neu- ral based semantic representations of phrases or sentences.</p><p>Motivated by the literal-first psycholinguistic hypothesis proposed by <ref type="bibr" target="#b1">Bobrow and Bell (1973)</ref>, in this paper, we propose an end-to-end neural model for idiom-aware distributed semantic rep- resentation, in which we adopt a neural architec- ture of recursive network <ref type="bibr" target="#b39">(Socher et al., 2013;</ref><ref type="bibr" target="#b40">Tai et al., 2015;</ref><ref type="bibr" target="#b44">Zhu et al., 2015</ref>) to learn the composi- tional semantics over a constituent tree. More con- cretely, we introduce a neural idiom detector for each phrase in a sentence to adaptively determine their compositionality: literal or idiomatic man- ner. For the literal phrase, we compute its seman- tics from its constituents while for the idiomatic phrase, we design two different ways to learn rep- resentations of idioms grounded in two different linguistic views of idioms <ref type="bibr" target="#b19">(Katz, 1963;</ref><ref type="bibr" target="#b10">Fraser, 1970;</ref><ref type="bibr" target="#b29">Nunberg et al., 1994)</ref>.</p><p>To evaluate our models towards the ability to understand sentences with idioms, we conduct our experiments on sentiment classification task due to the following reasons: 1) Idioms typically im- ply an affective stance toward something and they are common in reviews and comments <ref type="bibr" target="#b42">(Williams et al., 2015</ref>).</p><p>2) The error analysis of sentiment classification results reveals that a large number of errors are caused by idioms ( <ref type="bibr" target="#b0">Balahur et al., 2013)</ref>.</p><p>The contributions of this work are summarized as follows:</p><p>• We grow the capacity of recursive neural net- work, enabling it to model idiomatic phrases and handle ubiquitous phenomenon of id- iomatic variations when learning a sentential representation.</p><p>• We integrate idioms understanding into a real-world NLP task instead of evaluating id- iom detection as a standalone task.</p><p>• We construct a new real-world dataset cover- ing abundant idioms with original and vari- ational forms. The elaborate qualitative and quantitative experimental analyses show the effectiveness of our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Linguistic Interpretation of Idioms</head><p>Recently, idioms have raised eyebrows among lin- guists, psycholinguists, and lexicographers due to their pervasiveness in daily discourse and their fas- cinating properties in linguistics literature <ref type="bibr" target="#b41">(Villavicencio et al., 2005;</ref><ref type="bibr" target="#b34">Salton et al., 2014</ref>). As pecu- liar linguistic constructions ( <ref type="bibr" target="#b41">Villavicencio et al., 2005;</ref><ref type="bibr" target="#b34">Salton et al., 2014</ref>), idioms have three fol- lowing properties:</p><p>Invisibility Idioms always disguise themselves as normal multi-words in sentences. It makes end-to-end training hard since we should de- tect idioms first, and then understand them. Idiomaticity Idioms are semantically opaque, whose meanings cannot be derived from their constituent words. Existing composi- tional distributed approaches fail due to the hypothesis that the meaning of any phrase can be composed of the meanings of its con- stituents. Flexibility While structurally fixed, idioms allow variations. The words of some idioms can be removed or substituted by other words. <ref type="table">Table 1</ref> shows the three properties of idioms and the resulting challenges for distributed com- positional semantics. To address these challenges, two different perspectives have been held for id- iom comprehension.</p><p>The first perspective treats idioms as long words whose meanings are stipulated arbitrarily and can not be predict from its constituent <ref type="bibr" target="#b19">(Katz, 1963;</ref><ref type="bibr" target="#b10">Fraser, 1970)</ref>. However, a lot of idioms have shown certain degree of flexibility in term of mor- phology and lexeme, so this kind of method han- dles variation badly and fails to generalize.</p><p>The second perspective considers idioms as lin- guistic expressions <ref type="bibr" target="#b29">(Nunberg et al., 1994)</ref>, whose meanings are determined by the meanings of their constituent parts and some compositional rules can be used to combine them. This fully compo- sitional view may handle lexical variations, but it suffers from the idiomaticity problem, for the meanings of idioms are opaque.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Models</head><p>We propose an end-to-end neural model for idiom- aware distributed semantic representation. Specifi- cally, in terms of invisibility, we introduce a neural idiom detector to adaptively distinguish literal and idiomatic meaning of each phrase when learning sentence representations. For the literal phrase, we compute its semantics from its constituents with Tree-structured LSTM (TreeLSTM) <ref type="bibr" target="#b40">(Tai et al., 2015;</ref><ref type="bibr" target="#b44">Zhu et al., 2015</ref>). For the idiomatic phrase, we design two different ways to learn representa- tions of idioms grounded in two different linguis- tic views of idioms, which considers the idiomatic- ity and flexibility properties of idioms. <ref type="figure" target="#fig_0">Figure 1</ref> il- lustrates the framework of our proposed models, which consist of three modules: literal interpreter, idiom detector and idiomatic interpreter. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Literal Interpreter</head><p>The literal interpreter is basically a composi- tional semantic model, in which the semantics of a phrase is composed by literal meanings of its constituent words. Several existing models could serve as literal interpreter. In this paper, we adopt TreeLSTM ( <ref type="bibr" target="#b40">Tai et al., 2015</ref>) due to its superior performance.</p><p>Formally, given a binary constituency tree T in- duced by a sentence, each non-leaf node corre- sponds to a phrase. We refer to h j and c j as the hidden state and memory cell of each node j. The transition equations of node j are as follows:</p><formula xml:id="formula_0">      ˜ c j o j i j f l j f r j       =       tanh σ σ σ σ       T A,b   x j h l j h r j   ,<label>(1)</label></formula><formula xml:id="formula_1">c j = ˜ c j i j + c l j f l j + c r j f r j , (2) h j = o j tanh (c j ) ,<label>(3)</label></formula><p>where x j denotes the input vector and is non-zero if and only if it is a leaf node. The superscript l and r represent the left child and right child re- spectively. σ represents the logistic sigmoid func- tion and denotes element-wise multiplication. T A,b is an affine transformation which depends on parameters of the network A and b. <ref type="figure" target="#fig_0">Figure 1</ref>-(a) gives an illustration of TreeLSTM unit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Idiom Detector</head><p>Despite the success of TreeLSTM, there is still ex- isting potential weakness of the hypothesis that the meaning of a phrase or a sentence can be com- posed from the meanings of its constituents. Pre- vious neural sentence models are poor at learning the meanings of idiomatic phrases, not to mention modeling the idiomatic variations. Therefore, we introduce a parameterized idiom detector, which is used for detecting the boundary between literal and idiomatic meanings. Specifi- cally, if a compositional interpretation is nonsen- sical in the context of a sentence, then the de- tector is supposed to check whether an idiomatic sense should be taken and whether it makes sense. This literal-first model of idiom comprehension is motivated by the psycholinguistic hypothesis pro- posed by <ref type="bibr" target="#b1">Bobrow and Bell (1973)</ref>.</p><p>Due to ignoring the context information, TreeLSTM suffers from the problem of disam- biguation. For example, the phrase "in the bag" is compositional in the sentence "The dictionary is in the bag" while it has idiomatic meaning in the sentence "The election is in the bag unless the voters find out about my past". To address this problem, we explicitly model the context representation and integrate it into the process of sentence composition.</p><p>Context Representation More concretely, for each non-leaf node i and its corresponding phrase p i , we define C as a word set which contains words surrounding the phrase p i . Then the context repre- sentation s i can be obtained as follow:</p><formula xml:id="formula_2">s i = f (c 1 , c 2 , ..., c k ; θ)<label>(4)</label></formula><p>where f is a function with learnable parameter θ. Here, the function is implemented in two ap- proaches, NBOW and LSTM.</p><p>Detector The detector outputs a scalar α to de- termine whether the meaning of a phrase is literal or idiomatic. Formally, for the phrase i (non-leaf node i) with its context information s i and literal meaning h i , we compute the semantic composi- tional score α i using a single layer multilayer per- ceptron.</p><formula xml:id="formula_3">α i = σ(v T s tanh(W s [h (l) i , s i ])),<label>(5)</label></formula><p>where W s ∈ R d×2d and v s ∈ R d are learnable parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Idiomatic Interpreter</head><p>Idiomatic phrases pose a clear challenge to cur- rent compositional models of language compre- hension. However, until recently, there is little in- vestigation of learning idiomatic phrases in a real- world task. Here, based on different views of id- ioms <ref type="bibr" target="#b19">(Katz, 1963;</ref><ref type="bibr" target="#b10">Fraser, 1970;</ref><ref type="bibr" target="#b29">Nunberg et al., 1994)</ref>, we propose two idiomatic interpreters to model them.</p><p>Direct Look-Up Model Inspired by the direct access theory for idiom comprehension <ref type="bibr" target="#b12">(Glucksberg, 1993)</ref>, in this model, once a phrase p is de- tected as an idiom, it will be regarded as a long word like a key, and then their meanings can be directly retrieved from an external memory M , which is a table and stores idiomatic information for each idiom as depicted in the top subfigure in <ref type="figure" target="#fig_0">Figure 1</ref>-(c). Formally, the idiomatic meaning for a phrase can be obtained as:</p><formula xml:id="formula_4">h (i) = M[k]<label>(6)</label></formula><p>where k denotes the index of the corresponding phrase p.</p><p>Morphology-Sensitive Model Since most id- ioms enjoy certain flexibility in morphology, lex- icon, syntax, the above model suffers from the problem of idiom variations. To remedy this, in- spired by the compositional view of idioms <ref type="bibr" target="#b29">(Nunberg et al., 1994)</ref> and recent success of character- based models ( <ref type="bibr" target="#b21">Kim et al., 2016;</ref><ref type="bibr" target="#b23">Lample et al., 2016;</ref><ref type="bibr" target="#b4">Chung et al., 2016)</ref>, we propose to use CharLSTM to directly encode the meaning of a phrase in an idiomatic space and generate an id- iomatic representation, which is not contaminated by its literal meaning and sensitive to different variations. Formally, for each non-leaf node i and its cor- responding phrase p i in a constituency tree, we apply charLSTM to phrase p i as depicted in the bottom subfigure in <ref type="figure" target="#fig_0">Figure 1-(c)</ref> and utilize the emitted hidden states r j to represent the idiomatic meaning of the phrase.</p><formula xml:id="formula_5">r j = Char-LSTM(r j−1 , c j−1 , x j )<label>(7)</label></formula><p>where j = 1, 2, · · · , m and m represents the length of the input phrase. Then, we can obtain the idiomatic representa- tion:</p><formula xml:id="formula_6">h (i) = r m<label>(8)</label></formula><p>After obtaining the literal or idiomatic mean- ings, we can compute the final representation for phrase p i :</p><formula xml:id="formula_7">h i = α i h (i) i + (1 − α i )h (l) i (9)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Analysis of Two Proposed Idiomatic Interpreters</head><p>Given a phrase, both interpreters can generate a corresponding semantic representation, which is not contaminated by its literal meaning. The dif- ference is that Look-Up Model takes a totally non- compositional view that the meanings of idioms can be directly accessed from an external dictio- nary. This straightforward retrieval mechanism is more efficient and can introduce external prior knowledge by utilizing pre-trained external dictio- nary. By contrast, Morphology-Sensitive Model holds the idea that idiomatic meanings can still be composed in an idiomatic space, which allows this model to understand idioms better in terms of flexibility. Besides, this kind of model does not require an extra dictionary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">iSent: A Benchmark for Idiom-Enriched Sentiment Classification Dataset</head><p>To evaluate our models, we need a task that heav- ily depends on the understanding of idioms. In this paper, we choose sentiment classification task due to following reasons: 1) Idioms typically im- ply an affective stance toward something and they are common in reviews and comments <ref type="bibr" target="#b42">(Williams et al., 2015</ref>).</p><p>2) The error analysis of sentiment classification results reveals that a large number of errors are caused by idioms ( <ref type="bibr" target="#b0">Balahur et al., 2013)</ref>.</p><p>In this section, we will first give a brief descrip- tion of the most commonly used datasets for sen- timent classification so as to motivate the need for a new benchmark dataset.</p><p>Dataset Train Dev.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test</head><p>Class <ref type="table" target="#tab_4">Lavg  |V|  MR  9596  - 1066  2  22  21K  SST-1  8544 1101 2210  5  19  18K  SST-2  6920  872  1821  2  18  15K  SUBJ  9000  - 1000  2  21  21K   Table 2</ref>: Statistics of the four mainstream datasets for sentiment classification. L avg denotes the av- erage length of documents; |V| denotes the size of vocabulary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Mainstream Datasets for Sentiment Classification</head><p>We list four kinds of datasets which are most com- monly used for sentiment classification in NLP community. Additionally, we also evaluate our models on these datasets to make a comparison with many recent proposed models. Each dataset is briefly described as follows.</p><p>• SST-1  <ref type="bibr" target="#b31">Lee, 2005</ref>).</p><p>• SUBJ Subjectivity data set where the goal is to classify each instance (snippet) as being subjective or objective. ( <ref type="bibr" target="#b30">Pang and Lee, 2004)</ref> The detailed statistics about these four datasets are listed in <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Reasons for a New Dataset</head><p>Differing from previous work, which evaluating idiom detection as a standalone task, we want to integrate idiom understanding into sentiment clas- sification task. However, most of existing senti- ment datasets do not cover enough idioms or re- lated linguistic phenomenon. To better evaluate our models on idiom understanding task, we pro- posed an idiom-enriched sentiment classification dataset, in which each sentence contains at least one idiom.</p><p>Additionally, considering most idioms have cer- tain flexibility in morphology, lexicon and syn- tax, we enrich our dataset by introducing different types of idiom variations so that we can further evaluate the ability that the model handle different idiomatic variations. As shown in <ref type="table" target="#tab_2">Table 3</ref>, we sum up two types of phenomena towards idiom vari- ations and, for each variation, we obtain several corresponding sentences from a large corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Data collection</head><p>We crawl the website rottentomatoes.com to excerpt movie reviews with corresponding scores and collect the idioms from dictionary ( <ref type="bibr" target="#b9">Flavell and Flavell, 2006</ref>). The idiom dictionary contains lexical variations while has no morphol- ogy variations. To address this problem, we man- ually annotate the morphological variation of each idiom in term of verb(tense), noun(plural or singu- lar).</p><p>Then we filter these movie reviews with idioms ensuring that each sentence covers at least one id- iom. After that, we obtain nearly 15K movie re- views covering 1K idioms. To further improve the quality of these idiom-enriched sentences, we take some strategies to filter the dataset and finally con- struct 13K idiom-enriched sentences.</p><p>• If the occurrence of an idiom in all the re- views is less than 3, we threw this idiom and corresponding reviews. 3 • We find some "idioms" in sentences are movie names rather than expressing id- iomatic meanings and we filtered this kind of noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Statistics</head><p>The iSent dataset finally contains 9752 training samples , 1020 development samples and 2003 test samples. Besides, the development and test sets cover different types of idiom variations allow- ing us to test the model's generalization. <ref type="table">Table 4</ref> shows the detailed statistics and <ref type="figure" target="#fig_2">Figure 2</ref> shows the distribution of the number of reviews over dif- ferent lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head><p>We first evaluate our proposed models on four popular sentiment datasets, so that we can make a comparison with varieties of competitors. And then, we use the newly-introduced dataset to make more detailed experiment analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Examples</head><p>Morp. Verb go bananas → went bananas Noun in a nutshell → in nutshells</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lexical</head><p>Add. in the lurch → in the big lurch Sub.</p><p>on the same page → on different pages  <ref type="table">Table 4</ref>: Key statistics for the idioms and sen- tences in iSent dataset. O(Original) denotes the idioms in dev/test sets are in original forms and have appeared in training set. M(Morphology) and L(Lexical) represent the morphology and lexical idiom variations respectively and they are unseen in training set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>Loss Function Given a sentence and its label, the output of neural network is the probabilities of the different classes. The parameters of the net- work are trained to minimise the cross-entropy of the predicted and true label distributions. To mini- mize the objective, we use stochastic gradient de- scent with the diagonal variant of <ref type="bibr">AdaGrad (Duchi et al., 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initialization and Hyperparameters</head><p>In all of our experiments, the word embeddings for all of the models are initialized with the GloVe vectors ( <ref type="bibr" target="#b33">Pennington et al., 2014</ref>). The other parameters are initialized by randomly sampling from uniform distribution in [−0.1, 0.1].</p><p>For each task, we take the hyperparameters which achieve the best performance on the devel- opment set via a small grid search over combina- tions of the initial learning rate [0.1, 0.01, 0.001], l 2 regularization [0.0, 5E−5, 1E−5] The final hyper-parameters are as follows. The initial learn- ing rate is 0.1. The regularization weight of the parameters is 1E−5.</p><p>For all the sentences from the five datasets, we parse them with constituency parser <ref type="bibr" target="#b22">(Klein and Manning, 2003)</ref> to obtain the trees for our and some competitor models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Competitor Models</head><p>We give some descriptions about the setting of our models and several baseline models.</p><p>• CharLSTM: Character level LSTM.</p><p>• TLSTM: Vanilla tree-based LSTM, proposed by <ref type="table">Tai</ref>  Morphology-Sensitive interpreter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation over Mainstream Datasets</head><p>The experimental results are shown in <ref type="table" target="#tab_4">Table 5</ref>.</p><p>We can see Cont-TLSTM outperforms TLSTM on all four tasks, showing the importance of context- sensitive composition. Besides, both iTLSTM-Lo and iTLSTM-Mo achieve better results than TL- STM and Cont-LSTM, which indicates the ef- fectiveness of our introduced modules (detector and idiomatic interpreter). Additionally, compared with iTLSTM-Lo, iTLSTM-Mo behaves better, suggesting its char-based idiomatic interpreter is more powerful. Although four mainstream datasets are not rich in idioms, we could also observe substantial im- provement gained from our models. We attribute this success to the power of introduced detector in identifying other non-compositional collocations besides idioms. We will discuss about this later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Evaluation over iSent Dataset</head><p>Since iSent is a newly-introduced dataset, there is no existing baselines. Nevertheless, we provide several strong baselines implemented by ourselves as shown in <ref type="table" target="#tab_5">Table 6</ref>, and we can observe that:</p><p>• Differing from the improvement achieved on mainstream datasets, proposed models have shown their advantages on idiom-enriched sentences. They obtain more significant im- provements.   • Additionally, iTLSTM-Lo performs worse than iTLSTM-Mo while still surpasses baseline models, which also indicates the variation-sensitive model (iTLSTM-Mo) of idioms could further improve the perfor- mance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Analysis</head><p>In this section, we will provide more detailed quantitative and qualitative analysis in terms of three properties of idioms described in <ref type="table">Table 1</ref>: flexibility, invisibility and idiomaticity.</p><p>Flexibility Besides the overall accuracies on the test set, we also list the performance achieved by different models over the different parts of test set: original, morphological and lexical, which repre- sents different types of variations and have been described in <ref type="table">Table 4</ref>.</p><p>We can see from <ref type="figure" target="#fig_4">Figure 3</ref>, both idiom-aware models achieve better performance than Cont- TLSTM by a large margin on the original part of test set, which indicates the importance of under- standing idiomatic phrases during sentence mod- elling. Additionally, iTLSTM+Mo outperforms the other two models on the test set, suggesting the effectiveness of morphology-based model for modeling idiom variations.</p><p>Invisibility and Idiomaticity Previous experi- mental results have shown the effectiveness of our models. Here, we want to know how the intro- duced idiom detector contributes to the improve- ment of performance. Toward this end, we analyze all the 157 samples which our model predicts cor- rectly while baseline model (Cont-TLSTM) fails on iSent, and find more than 120 sentences are given wrong sentiment by Cont-TLSTM due to ig- noring the figurative meanings of idioms. For ex- ample, as shown in <ref type="figure" target="#fig_5">Figure 4</ref>, we randomly sam- ple a sentence and analyze the changes of the pre- dicted sentiment score at different nodes of the tree.</p><p>The sentence "The movie enable my friends to blow a gasket" has negative sentiment. Cont-TLSTM gives a wrong predic- tion due to ignoring the information expressed by the idiomatic phrase "blow a gasket". By contrast, our model correctly detects this idiom, whose meaning plays a major role in final sentiment prediction.</p><p>Non-compositional Phrases Detection Besides idioms, we find the introduced detector can also pick up other types of non-compositional phrases <ref type="bibr">4</ref> . We roughly sum up these non-   compositional phrases picked up by introduced detector from all the five development sets and list them in <ref type="table" target="#tab_7">Table 7</ref>.</p><p>From the table, we can see that most of these phrases either imply an affective stance to- ward something: "thumbs down", or are criti- cal to the understanding of sentences such as the "Verb Phrases" and "Adverb Phrases". For exam- ple, the sentence "More often than not, this mixed bag hit its mark" has a positive sentiment. Cont-TLSTM pays much more attention to the word "not" without realizing that it belongs to the collocation "more often than not", which expresses neutral emotion. In comparison, our model regards this collocation as a whole with neutral sentiment, which is crucial for the final prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Previous work related to idioms focused on their identification, which falls in two kinds of paradigms: idiom type classification <ref type="bibr" target="#b11">(Gedigian et al., 2006;</ref><ref type="bibr" target="#b36">Shutova et al., 2010</ref>) and idiom to- ken classification ( <ref type="bibr" target="#b18">Katz and Giesbrecht, 2006;</ref><ref type="bibr" target="#b24">Li and Sporleder, 2009;</ref><ref type="bibr" target="#b8">Fazly et al., 2009;</ref><ref type="bibr" target="#b32">Peng et al., 2014;</ref><ref type="bibr" target="#b35">Salton et al., 2016)</ref>. Different with these work, we integrate idioms understanding into a real-world task and consider different peculiarities of idioms in an end-to-end trainable framework.</p><p>Recently, there are some work exploring the compositionality of various types of phrases <ref type="bibr" target="#b17">(Kartsaklis et al., 2012;</ref><ref type="bibr" target="#b28">Muraoka et al., 2014;</ref><ref type="bibr" target="#b14">Hermann, 2014;</ref><ref type="bibr" target="#b13">Hashimoto and Tsuruoka, 2016</ref>). Compared with these work, we focus on how to properly model idioms under the context of sentence rep- resentations.</p><p>More recently, <ref type="bibr" target="#b45">Zhu et al. (2016)</ref> propose a DAG-structured LSTM to incorporate external semantics including non-compositional or holis- tically learned semantics. Its key characteris- tic is that a DAG needs be built in advance, which merges some detected n-grams as the non- compositional phrases based on external knowl- edge. Different from this work, we focus on how to integrate detection and understanding of idioms into a unified end-to-end model, in which an id- iomatic detector is introduced to adaptively con- trol the semantic compositionality. Particularly, in the whole process no extra information is given to tell which phrases should be regarded as non- compositional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this paper, we lay idioms understanding in the context of sentence-level semantic representation based on two linguistic perspectives. To apply our model into the real-world task, we introduce a sizeable idiom-enriched sentiment classification dataset, which covers abundant peculiarities of id- ioms. We make an elaborate experiment design and case analysis to evaluate the effectiveness of our proposed models.</p><p>In future work, we would like to investigate more complicated idiom-enriched NLP tasks, such as machine translation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of different modules for our proposed idiom-aware composition network corresponding to the sentence "The plot speaks volumes"</figDesc><graphic url="image-1.png" coords="3,117.36,62.80,362.83,144.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The distribution of the number of reviews over different lengths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>et al. (2015). • Cont-TLSTM: Context-dependent tree-based LSTM, introduced by Bowman et al. (2016). • iTLSTM-Lo: Proposed model with Look-Up idiomatic interpreter. • iTLSTM-Mo: Proposed model with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performances achieved by different models are subdivided into three parts. Original, Morphology, Lexical represents accuracies achieved by corresponding part of test data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The change of the predicted sentiment score at different nodes of the tree. The red and blue color represent positive and negative sentiment respectively, where darker indicates higher confidence. Dashed triangle or square box denote not being selected by detector.</figDesc><graphic url="image-2.png" coords="8,127.33,62.81,340.15,104.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Idiom variations at morphological and 
lexical level. Add. and Sub. refer to lexical addi-
tion and substitution respectively. 

Train 
Dev 
Test 
O 
M 
L 
O 
M 
L 
Idiom 
1247 
124 
21 
40 
124 
21 
40 
Sent. 
9752 
720 200 100 1403 400 200 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Accuracies of our models on four datasets 
against state-of-the-art neural models. 

Model 
Train Dev. Test 

NBOW 
80.9 
77.1 74.5 
LSTM 
87.5 
76.9 75.0 
BiLSTM 
93.4 
76.8 76.3 
CharLSTM 
92.4 
75.1 74.4 
TLSTM 
88.2 
75.3 74.9 
Cont-TLSTM 
90.8 
76.2 75.5 

iTLSTM-Lo 
88.9 
79.6 78.1 
iTLSTM-Mo 
91.3 
81.1 80.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Accuracies of our models on iSent dataset 
against typical baselines. BiLSTM represents bidi-
rectional LSTM. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>PN, VP, NP and AP represent proper 
noun, noun phrase, verb phrase and adverbial 
phrase respectively. 

</table></figure>

			<note place="foot" n="1"> http://nlp.stanford.edu/sentiment. 2 https://www.cs.cornell.edu/people/ pabo/movie-review-data/.</note>

			<note place="foot" n="3"> The reason is that, for some idioms, we should split their corresponding reviews into train/dev/test sets.</note>

			<note place="foot" n="4"> An idiom itself is a non-compositional phrase.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous re-viewers for their valuable comments. This work was partially funded by National Natural Sci-ence Foundation of China (No. 61532011 and 61672162), Shanghai Municipal Science and Technology Commission (No. 16JC1420401), and Young Elite Scientists Sponsorship Program By CAST (2015QNRC001).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Balahur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mijail</forename><surname>Kabadjov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanni</forename><surname>Zavarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matina</forename><surname>Goot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Halkia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenya</forename><surname>Pouliquen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belyaeva</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.6202</idno>
		<title level="m">Sentiment analysis in the news</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On catching on to idiomatic expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan M</forename><surname>Bobrow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="343" to="346" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A fast unified model for parsing and sentence understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06021</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A character-level decoder without explicit segmentation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06147</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555</idno>
		<title level="m">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised type and token identification of idiomatic expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afsaneh</forename><surname>Fazly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="103" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Dictionary of idioms and their origins</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><surname>Flavell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Flavell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Kyle Cathie Limited</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Idioms within a transformational grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations</title>
		<imprint>
			<biblScope unit="page" from="22" to="42" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Catching metaphors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gedigian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srini</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Branimir</forename><surname>Ciric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Scalable Natural Language Understanding. Association for Computational Linguistics</title>
		<meeting>the Third Workshop on Scalable Natural Language Understanding. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Glucksberg</surname></persName>
		</author>
		<title level="m">Idiom meanings and allusional content. Idioms: Processing, structure, and interpretation pages</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="3" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adaptive joint learning of compositional and noncompositional phrase embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06067</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Distributed representations for compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.3146</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A unified sentence space for categorical distributional-compositional semantics: Theory and experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitri</forename><surname>Kartsaklis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrnoosh</forename><surname>Sadrzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Pulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING: Posters. Citeseer</title>
		<meeting>COLING: Posters. Citeseer</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic identification of non-compositional multiword expressions using latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugenie</forename><surname>Giesbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties</title>
		<meeting>the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="12" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Semantic interpretation of idioms and sentences containing them. Research Laboratory of Electronics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerrold J</forename><surname>Katz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963" />
			<pubPlace>Massachusetts Institute of Technology</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Character-aware neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01360</idno>
		<title level="m">Neural architectures for named entity recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Classifier combination for contextual idiom detection without labelled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep fusion LSTMs for text semantic matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Adversarial multi-task learning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05742</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Modelling interaction of sentence pair with coupled-lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on EMNLP</title>
		<meeting>the 2016 Conference on EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Finding the best model among representative compositional models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayasu</forename><surname>Muraoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonse</forename><surname>Shimaoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazeto</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yotaro</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Pacific Asia Conference on Language, Information, and Computation</title>
		<meeting>the 28th Pacific Asia Conference on Language, Information, and Computation</meeting>
		<imprint>
			<publisher>PACLIC</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Nunberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Sag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wasow</surname></persName>
		</author>
		<title level="m">Idioms. Language pages</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="491" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd annual meeting on association for computational linguistics</title>
		<meeting>the 43rd annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Classifying idiomatic and literal expressions using topic models and intensity of emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2019" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the EMNLP</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">An empirical study of the impact of idioms on phrase based statistical machine translation of en</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giancarlo</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Kelleher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>glish to brazilian-portuguese</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Idiom token classification using sentential distributed semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Giancarlo D Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John D</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kelleher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="194" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Metaphor identification using verb and noun clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1002" to="1010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Semantic compositionality through recursive matrix-vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brody</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1201" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Semi-supervised recursive autoencoders for predicting sentiment distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Improved semantic representations from tree-structured long short-term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai Sheng</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.00075</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Introduction to the special issue on multiword expressions: Having a crack at a hard nut</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aline</forename><surname>Villavicencio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Bond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The role of idioms in sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lowri</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bannister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Arribasayllon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alun</forename><surname>Preece</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irena</forename><surname>Spasi´cspasi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="7375" to="7385" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Poupart</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.05070</idno>
		<title level="m">Self-adaptive hierarchical sentence model</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Long short-term memory over recursive structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao-Dan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1604" to="1612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dag-structured long short-term memory for semantic compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="917" to="926" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
