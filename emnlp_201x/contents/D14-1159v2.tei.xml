<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Biological Processes for Reading Comprehension</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Chun</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brad</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abby</forename><forename type="middle">Vander</forename><surname>Linden</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brittany</forename><surname>Harding</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle, Seattle</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Biological Processes for Reading Comprehension</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Machine reading calls for programs that read and understand text, but most current work only attempts to extract facts from redundant web-scale corpora. In this paper , we focus on a new reading comprehension task that requires complex reasoning over a single document. The input is a paragraph describing a biological process , and the goal is to answer questions that require an understanding of the relations between entities and events in the process. To answer the questions, we first predict a rich structure representing the process in the paragraph. Then, we map the question to a formal query, which is executed against the predicted structure. We demonstrate that answering questions via predicted structures substantially improves accuracy over baselines that use shallower representations.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of machine reading is to develop pro- grams that read text to learn about the world and make decisions based on accumulated knowl- edge. Work in this field has focused mostly on macro-reading, i.e., processing large text collec- tions and extracting knowledge bases of facts <ref type="bibr" target="#b11">(Etzioni et al., 2006;</ref><ref type="bibr">Carlson et al., 2010;</ref><ref type="bibr" target="#b12">Fader et al., 2011</ref>). Such methods rely on redundancy, and are thus suitable for answering common factoid ques- tions which have ample evidence in text <ref type="bibr" target="#b13">(Fader et al., 2013)</ref>. However, reading a single document (micro-reading) to answer comprehension ques- tions that require deep reasoning is currently be- yond the scope of state-of-the-art systems.</p><p>In this paper, we introduce a task where given a paragraph describing a process, the goal is to * Both authors equally contributed to the paper.</p><p>answer reading comprehension questions that test understanding of the underlying structure. In par- ticular, we consider processes in biology text- books such as this excerpt and the question that follows: This excerpt describes a process in which a com- plex set of events and entities are related to one another. A system trying to answer this ques- tion must extract a rich structure spanning multi- ple sentences and reason that water splitting com- bined with light absorption leads to transfer of ions. Note that shallow methods, which rely on lexical overlap or text proximity, will fail. Indeed, both answers are covered by the paragraph and the wrong answer is closer in the text to the question.</p><p>We propose a novel method that tackles this challenging problem (see <ref type="figure">Figure 1</ref>). First, we train a supervised structure predictor that learns to ex- tract entities, events and their relations describing the biological process. This is a difficult prob- lem because events have complex interactions that span multiple sentences. Then, treating this struc- ture as a small knowledge-base, we map ques- tions to formal queries that are executed against the structure to provide the answer.</p><p>Micro-reading is an important aspect of natural language understanding ( <ref type="bibr" target="#b29">Richardson et al., 2013;</ref><ref type="bibr" target="#b19">Kushman et al., 2014)</ref>. In this work, we focus specifically on modeling processes, where events and entities relate to one another through com- plex interactions. While we work in the biology ". . . Water is split, providing a source of elec- trons and protons (hydrogen ions, H + ) and giving off O2 as a by-product. Light ab- sorbed by chlorophyll drives a transfer of the electrons and hydrogen ions from water to an acceptor called NADP+ . . . "</p><p>Q What can the splitting of water lead to? a Light absorption Step 1</p><p>Step 2</p><p>Step 3: Answer = b</p><p>Figure 1: An overview of our reading comprehension system. First, we predict a structure from the input paragraph (the top right portion shows a partial structure skipping some arguments for brevity). Circles denote events, squares denote argu- ments, solid arrows represent event-event relations, and dashed arrows represent event-argument relations. Second, we map the question paired with each answer into a query that will be answered using the structure. The bottom right shows the query representation. Last, the two queries are executed against the structure, and a final answer is returned.</p><p>domain, processes are abundant in domains such as chemistry, economics, manufacturing, and even everyday events like shopping or cooking, and our model can be applied to these domains as well. The contributions of this paper are:</p><p>1. We propose a reading comprehension task which requires deep reasoning over struc- tures that represent complex relations be- tween multiple events and entities. 2. We present PROCESSBANK, a new dataset consisting of descriptions of biological pro- cesses, fully-annotated with rich process structures, and accompanied by multiple- choice questions. 3. We present a novel method for answer- ing questions, by predicting process struc- tures and mapping questions to queries. We demonstrate that by predicting structures we can improve reading comprehension accu- racy over baselines that do not exploit the un- derlying structure. The data and code for this paper are avail- able at http://www-nlp.stanford.edu/ software/bioprocess.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition and Setup</head><p>This section describes the reading comprehension task we address and the accompanying dataset. We will use the example in <ref type="figure">Figure 1</ref> as our run- ning example throughout the paper.</p><p>Our goal is to tackle a complex reading com- prehension setting that centers on understanding the underlying meaning of a process description. We target a multiple-choice setting in which each input consists of a paragraph of text describing a biological process, a question, and two possible answers. The goal is to identify the correct answer using the text <ref type="figure">(Figure 1, left)</ref>. We used the 148 paragraphs from the textbook Biology ( <ref type="bibr" target="#b1">Campbell and Reece, 2005</ref>) that were manually identified by <ref type="bibr" target="#b33">Scaria et al. (2013)</ref>. We extended this set to 200 paragraphs by including additional paragraphs that describe biological processes. Each paragraph in the collection represents a single biological pro- cess and describes a set of events, their partici- pants and their interactions.</p><p>Because we target understanding of paragraph meaning, we use the following desiderata for building the corpus of questions and answers:</p><p>1. The questions should focus on the events and entities participating in the process described in the paragraph, and answering the questions should require reasoning about the relations between those events and entities. 2. Both answers should have similar lexical overlap with the paragraph. Moreover, names of entities and events in the question and an- swers should appear as in the paragraph and not using synonyms. This is to ensure that the task revolves around reading comprehension rather than lexical variability. 1 A biologist created the question-answer part of the corpus comprising of 585 questions spread over the 200 paragraphs. A second annotator val- idated 326 randomly chosen questions and agreed on the correct answer with the first annotator in 98.1% of cases. We provide the annotation guide- lines in the supplementary material. <ref type="figure">Figure 1</ref> (left) shows an excerpt of a paragraph describing a process and an example of a ques- tion based on it. In general, questions test an un- derstanding of the interactions between multiple events (such as causality, inhibition, temporal or- dering), or between events and entities (i.e., roles of entities in events), and require complex reason- ing about chains of event-event and event-entity relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Structure of Processes</head><p>A natural first step for answering reading compre- hension questions is to identify a structured rep- resentation of the text. In this section, we define this structure. We broadly follow the definition of <ref type="bibr" target="#b33">Scaria et al. (2013)</ref>, but modify important aspects, highlighted at the end of this section.</p><p>A paragraph describing a process is a sequence of tokens that describes events, entities and their relations (see <ref type="figure">Figure 1</ref>, top right). A process is a directed graph (T , A, E tt , E ta ), where the nodes T are labeled event triggers, the nodes A are ar- guments, E tt are labeled edges describing event- event relations, and E ta are labeled edges from triggers to arguments denoting semantic roles (see <ref type="figure">Figure 1</ref> top right for a partial structure of the run- ning example). The goal of process extraction is to generate the process graph given the input para- graph.</p><p>Triggers and arguments A trigger is a token span denoting the occurrence of an event. In <ref type="figure">Fig- ure 1</ref>, split, absorbed and transfer are event trig- gers. In rare cases, a trigger denotes the non- occurrence of an event. For example, in "sym- patric speciation can occur when gene flow is blocked", sympatric speciation occurs if gene flow does not happen. Thus, nodes in T are labeled as either a T-YES or T-NO to distinguish triggers of events that occur from triggers of events that do not occur. Arguments are token spans denoting entities that participate in the process (such as wa- ter, light and ions in <ref type="figure">Figure 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic roles</head><p>The edges E ta from triggers to arguments are labeled by the semantic roles AGENT, THEME, SOURCE, DESTINATION, LO- CATION, RESULT, and OTHER for all other roles. Our running example shows three THEME seman- tic roles for the three triggers. For brevity, the fig- ure does not show the RESULT of the event split, namely, both source of electrons and protons (hy- drogen ions, H + ) and O 2 .</p><p>Event-event relations The directed edges E tt between triggers are labeled by one of eight pos- sible event-event relations. These relations are central to answering reading comprehension ques- tions, which test understanding of the depen- dencies and causal relations between the process events. We first define three relations that express a dependency between two event triggers u and v.</p><p>1. CAUSE denotes that u starts before v, and if u happens then v happens ( <ref type="figure">Figure 1</ref>). 2. ENABLE denotes that u creates conditions necessary for the occurrence of v. This means that u starts before v and v can only happen if u happens ( <ref type="figure">Figure 1</ref>). 2 3. PREVENT denotes that u starts before v and if u happens, then v does not happen.</p><p>In processes, events sometimes depend on more than one other event. For example, in <ref type="figure">Figure 1</ref> (right top) transfer of ions depends on both water splitting as well as light absorption. Conversely, in <ref type="figure" target="#fig_1">Figure 2</ref>, the shifting event results in either one of two events but not both. To express both con- junctions and disjunctions of related events we add the relations CAUSE-OR, ENABLE-OR and PREVENT-OR, which express disjunctions, while the default CAUSE, ENABLE, and PREVENT ex- press conjunction (Compare the CAUSE-OR rela- tions in <ref type="figure" target="#fig_1">Figure 2</ref> with the relations in <ref type="figure">Figure 1</ref>).</p><p>We define the SUPER relation to denote that event u is part of event v. (In <ref type="figure" target="#fig_1">Figure 2</ref>, slip- page is a sub-event of replication.) Last, we use the event coreference relation SAME to denote two event mentions referring to the same event.</p><p>Notice that the assignments of relation labels in- teract across different pairs of events. As an ex- ample, if event u causes event v, then v can not cause u. Our inference algorithm uses such struc- tural constraints when predicting process structure (Section 4).  <ref type="table">Table 1</ref>: Statistics of triggers, arguments and rela- tions over the 200 annotated paragraphs.</p><p>Three biologists annotated the same 200 para- graphs described in Section 2 using the brat anno- tation tool ( <ref type="bibr" target="#b34">Stenetorp et al., 2012</ref>). For each para- graph, one annotator annotated the process, and a second validated its correctness. Importantly, the questions and answers were authored sepa- rately by a different annotator, thus ensuring that the questions and answers are independent from the annotated structures. <ref type="table">Table 1</ref> gives statistics over the dataset. The annotation guidelines are in- cluded in the supplementary material.</p><p>Relation to <ref type="bibr" target="#b33">Scaria et al. (2013</ref><ref type="bibr" target="#b33">) Scaria et al. (2013</ref> also defined processes as graphs where nodes are events and edges describe event-event relations. Our definition differs in a few important aspects.</p><p>First, the set of event-event relations in that work included temporal relations in addition to causal ones. In this work, we posit that because events in a process are inter-related, causal depen- dencies are sufficient to capture the relevant tem- poral ordering between them. <ref type="figure">Figure 1</ref> illustrates this phenomenon, where the temporal ordering be- tween the events of water splitting and light ab- sorption is unspecified. It does not matter whether one happens before, during, or after the other. Fur- thermore, the incoming causal links to transfer im- ply that the event should happen after splitting and absorption.</p><p>A second difference is that Scaria et al. (2013) do not include disjunctions and conjunctions of events in their formulation. Last, <ref type="bibr" target="#b33">Scaria et al. (2013)</ref> predict only relations given input triggers, while we predict a full process structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Predicting Process Structures</head><p>We now describe the first step of our algorithm. Given an input paragraph we predict events, their arguments and event-event relations <ref type="figure">(Figure 1</ref>, top). We decompose this into three sub-problems:</p><p>1. Labeling trigger candidates using a multi- class classifier (Section 4.1). 2. For each trigger, identifying an over- complete set of possible arguments, using a classifier tuned for high recall (Section 4.2). 3. Jointly assigning argument labels and rela- tion labels for all trigger pairs (Section 4.3). The event-event relations CAUSE, ENABLE, CAUSE-OR and ENABLE-OR, form a semantic cluster: If (u, v) is labeled by one of these, then the occurrence of v depends on the occurrence of u. Since our dataset is small, we share statistics by collapsing all four labels to a single ENABLE la- bel. Similarly, we collapse the PREVENT and PREVENT-OR labels, overall reducing the number of relations to four.</p><p>For brevity, in what follows we only provide a flavor of the features we extract, and refer the reader to the supplementary material for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Predicting Event Triggers</head><p>The first step is to identify the events in the pro- cess. We model the trigger detector as a multi- class classifier that labels all content words in the paragraph as one of T-YES, T-NO or NOT- TRIGGER (Recall that a word can trigger an event that occurred, an event that did not occur, or not be a trigger at all). For simplicity, we model trig- gers as single words, but in the gold annotation about 14% are phrases (such as gene flow). Thus, we evaluate trigger prediction by taking heads of gold phrases. To train the classifier, we extract the lemma and POS tag of the word and adja- cent words, dependency path to the root, POS tag of children and parent in the dependency tree, and clustering features from WordNet <ref type="bibr">(Fellbaum, 1998)</ref>, <ref type="bibr">Nomlex (Macleod et al., 1998</ref>), Levin verb classes <ref type="bibr" target="#b20">(Levin, 1993)</ref>, and a list of biological pro- cesses compiled from Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Filtering Argument Candidates</head><p>Labeling trigger-argument edges is similar to se- mantic role labeling. Following the standard ap- proach ( <ref type="bibr" target="#b28">Punyakanok et al., 2008)</ref>, for each trigger we collect all constituents in the same sentence to build an over-complete set of plausible candidate arguments. This set is pruned with a binary classi- fier that is tuned for high recall (akin to the argu- ment identifier in SRL systems). On the develop- ment set we filter more than half of the argument candidates, while achieving more than 99% recall. This classifier is trained using argument identifica- tion features from <ref type="bibr" target="#b28">Punyakanok et al. (2008)</ref>.</p><p>At the end of this step, each trigger has a set of candidate arguments which will be labeled during joint inference. In further discussion, the argument candidates for trigger t are denoted by A t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Predicting Arguments and Relations</head><p>Given the output of the trigger classifier, our goal is to jointly predict event-argument and event- event relations. We model this as an integer linear program (ILP) instance described below. We first describe the inference setup assuming a model that scores inference decisions and defer description of learning to Section 4.4. The ILP has two types of decision variables: arguments and relations.</p><p>Argument variables These variables capture the decision that a candidate argument a, belong- ing to the set A t of argument candidates, takes a label A (from Section 3). We denote the Boolean variables by y t,a,A , which are assigned a score b t,a,A by the model. We include an additional label NULL-ARG, indicating that the candidate is not an argument for the trigger.</p><p>Event-event relation variables These variables capture the decision that a pair of triggers t 1 and t 2 are connected by a directed edge (t 1 , t 2 ) labeled by the relation R. We denote these variables by z t 1 ,t 2 ,R , which are associated with a score c t 1 ,t 2 ,R . Again, we introduce a label NULL-REL to indicate triggers that are not connected by an edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name Description Unique labels</head><p>Every argument candidate and trigger pair has ex- actly one label. Argument overlap Two arguments of the same trigger cannot overlap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation symmetry</head><p>The SAME relation is symmetric. All other rela- tions are anti-symmetric, i.e., for any relation la- bel other than SAME, at most one of (ti, tj ) or (tj , ti) can take that label and the other is assigned the label NULL-REL. Max arguments per trigger Every trigger can have no more than two arguments with the same label. Max triggers per ar- gument</p><p>The same span of text can not be an argument for more than two triggers. Connectivity</p><p>The triggers must form a connected graph, framed as flow constraints as in <ref type="bibr" target="#b22">Magnanti and Wolsey (1995)</ref> and <ref type="bibr" target="#b24">Martins et al. (2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shared arguments</head><p>If the same span of text is an argument of two trig- gers, then the triggers must be connected by a rela- tion that is not NULL-REL. This ensures that trig- gers that share arguments are related. Unique parent For any trigger, at most one outgoing edge can be labeled SUPER. Formulation Given the two sets of variables, the objective of inference is to find a global as- signment that maximizes the score. That is, the objective can be stated as follows:</p><formula xml:id="formula_0">max y,z t,a∈At,A b t,a,A · y t,a,A + t 1 ,t 2 ,R c t 1 ,t 2 ,R · z t 1 ,t 2 ,R</formula><p>Here, y and z refer to all the argument and rela- tion variables respectively. Clearly, all possible assignments to the infer- ence variables are not feasible and there are both structural as well as prior knowledge constraints over the output space. <ref type="table" target="#tab_1">Table 2</ref> states the con- straints we include, which are expressed as linear inequalities over output variables using standard techniques (e.g., <ref type="bibr" target="#b31">(Roth and Yih, 2004)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Learning in the Joint Model</head><p>We train both the trigger classifier and the argu- ment identifier using L 2 -regularized logistic re- gression. For the joint model, we use a linear model for the scoring functions, and train jointly using the structured averaged perceptron algo- rithm <ref type="bibr" target="#b8">(Collins, 2002)</ref>.</p><p>Since argument labeling is similar to semantic role labeling (SRL), we extract standard SRL fea- tures given the trigger and argument from the syn- tactic tree for the corresponding sentence. In ad- dition, we add features extracted from an off-the- shelf SRL system. We also include all feature con- junctions. For event relations, we include the fea- tures described in <ref type="bibr" target="#b33">Scaria et al. (2013)</ref>, as well as context features for both triggers, and the depen- dency path between them, if one exists.</p><p>This section describes our question answering sys- tem that, given a process structure, a question and two answers, chooses the correct answer (steps 2 and 3 in <ref type="figure">Figure 1</ref>).</p><p>Our strategy is to treat the process structure as a small knowledge-base. We map each answer along with the question into a structured query that we compare against the structure. The query can prove either the correctness or incorrectness of the answer being considered. That is, either we get a valid match for an answer (proving that the cor- responding answer is correct), or we get a refu- tation in the form of a contradicted causal chain (thus proving that the other answer is correct). This is similar to theorem proving approaches sug- gested in the past for factoid question answering ( <ref type="bibr" target="#b26">Moldovan et al., 2003)</ref>.</p><p>The rest of this section is divided into three parts: Section 5.1 defines the queries we use, Sec- tion 5.2 describes a rule-based algorithm for con- verting a question and an answer into a query and finally, 5.3 describes the overall algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Queries over Processes</head><p>We model a query as a directed graph path with regular expressions over edge labels. The bot- tom right portion of <ref type="figure">Figure 1</ref> shows examples of queries for our running example. In general, given a question and one of the answer candidates, one end of the path is populated by a trigger/argument found in the question and the other is populated with a trigger/ argument from the answer.</p><p>We define a query to consist of three parts: 1. A regular expression over relation labels, de- scribing permissible paths, 2. A source trigger/argument node, and 3. A target trigger/argument node. For example, the bottom query in <ref type="figure">Figure 1</ref> looks for paths labeled with CAUSE or ENABLE edges from the event split to the event transfer.</p><p>Note that the representation of questions as di- rected paths is a modeling choice and did not influ- ence the authoring of the questions. Indeed, while most questions do fit this model, there are rare cases that require a more complex query structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Query Generation</head><p>Mapping a question and an answer into a query involves identifying the components of the query listed above. We do this in two phases: (1) In the alignment phase, we align triggers and arguments in the question and answer to the process structure to give us candidate source and target nodes. <ref type="formula">(2)</ref> In the query construction phase, we identify the regular expression and the direction of the query using the question, the answer and the alignment.</p><p>We identify three broad categories of QA pairs (see <ref type="table">Table 3</ref>) that can be identified using simple lexical rules: (a) Dependency questions ask which event or argument depends on another event or ar- gument, (b) Temporal questions ask about tempo- ral ordering of events, and (c) True-false questions ask whether some fact is true. Below, we describe the two phases of query generation primarily in the context of dependency questions with a brief dis- cussion about temporal and true-false questions at the end of the section.</p><p>Alignment Phase We align triggers in the struc- ture to the question and the answer by matching lemmas or nominalizations. In case of multiple matches, we use the context to disambiguate and resolve ties using the highest matching candidate in the syntactic dependency tree.</p><p>We align arguments in the question and the an- swer in a similar manner. Since arguments are typically several words long, we prefer maximal spans. Additionally, if a question (or an answer) contains an aligned trigger, we prefer to align words to its arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Construction Phase</head><p>We construct a query using the aligned question and answer trig- gers/arguments. We will explain query construc- tion using our running example (reproduced as the dependency question in <ref type="table">Table 3</ref>).</p><p>First, we identify the source and the target of the query. We select either the source or the tar- get to be a question node and populate the other end of the query path with an answer node. To make the choice between source or target for the question node, we use the main verb in the ques- tion, its voice and relative position of the question word with respect to the main verb. In our exam- ple, the main verb lead to is in active voice and the question word what is not in subject position. This places the trigger from the question as the source of the query path (see both queries in the bottom right portion of the running example). In contrast, had the verb been require, the trigger would be the target of the query. We construct two verb clusters that indicate query direction using a small seed set Type Example # (%) Dependency Q: What can the splitting of water lead to? 407 (69.57%) a: Light absorption b: Transfer of ions Temporal Q: What is the correct order of events? 57 (9.74%) a: PDGF binds to tyrosine kinases, then cells divide, then wound healing b: Cells divide, then PDGF binds to tyrosine kinases, then wound healing True-False Q: Cdk associates with MPF to become cyclin 121 (20.68%) a: True b: False <ref type="table">Table 3</ref>: Examples and statistics for each of the three coarse types of questions.</p><p>Is main verb trigger?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Condition</head><p>Regular Exp. Wh-word subjective?</p><p>AGENT Wh-word object? THEME</p><formula xml:id="formula_1">Condition Regular Exp. default (ENABLE|SUPER) + DIRECT (ENABLE|SUPER) PREVENT (ENABLE|SUPER) * PREVENT(ENABLE|SUPER) *</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes No</head><p>Figure 3: Rules for determining the regular expressions for queries concerning two triggers. In each table, the condition column decides the regular expression to be chosen. In the left table, we make the choice based on the path from the root to the Wh-word in the question. In the right table, if the word directly modifies the main trigger, the DIRECT regular expression is chosen. If the main verb in the question is in the synset of prevent, inhibit, stop or prohibit, we select the PREVENT regular expression. Otherwise, the default one is chosen. We omit the relation label SAME from the expressions, but allow going through any number of edges labeled by SAME when matching expressions to the structure.</p><p>that we expand using WordNet.</p><p>The final step in constructing the query is to identify the regular expression for the path con- necting the source and the target. Due to paucity of data, we do not map a question and an answer to arbitrary regular expressions. Instead, we con- struct a small set of regular expressions, and build a rule-based system that selects one. We used the training set to construct the regular expressions and we found that they answer most questions (see Section 6.4). We determine the regular expression based on whether the main verb in the sentence is a trigger and whether the source and target of the path are triggers or arguments. <ref type="figure">Figure 3</ref> shows the possible regular expressions and the procedure for choosing one when both the source and target are triggers. If either of them are argument nodes, we append the appropriate semantic role to the regu- lar expression, based on whether the argument is the source or the target of the path (or both).</p><p>True-false questions are treated similarly, ex- cept that both source and target are chosen from the question. For temporal questions, we seek to identify the ordering of events in the answers. We use the keywords first, then, or simultaneously to identify the implied order in the answer. We use the regular expression SUPER + for questions ask- ing about simultaneous events and ENABLE + for those asking about sequential events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Answering Questions</head><p>We match the query of an answer to the process structure to identify the answer. In case of a match, the corresponding answer is chosen. The matching path can be thought of as a proof for the answer.</p><p>If neither query matches the graph (or both do), we check if either answer contradicts the struc- ture. To do so, we find an undirected path from the source to the target. In the event of a match, if the matching path traverses any ENABLE edge in the incorrect direction, we treat this as a refutation for the corresponding answer and select the other one. In our running example, in addition to the valid path for the second query, for the first query we see that there is an undirected path from split to absorb through transfer that matches the first query. This tells us that light absorption cannot be the answer because it is not along a causal path from split.</p><p>Finally, if none of the queries results in a match, we look for any unlabeled path between the source and the target, before backing off to a dependency- based proximity baseline described in Section 6. When there are multiple aligning nodes in the question and answer, we look for any proof or refutation before backing off to the baselines.</p><p>In this section we aim to empirically evaluate whether we can improve reading comprehension accuracy by predicting process structures. We first provide details of the experimental setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental setup</head><p>We used 150 processes (435 questions) for train- ing and 50 processes (150 questions) as the test set. For development, we randomly split the train- ing set 10 times (80%/20%), and tuned hyper- parameters by maximizing average accuracy on question answering. We preprocessed the para- graphs with the Stanford CoreNLP pipeline ver- sion 3.4 <ref type="bibr" target="#b23">(Manning et al., 2014</ref>) and Illinois SRL ( <ref type="bibr" target="#b28">Punyakanok et al., 2008;</ref><ref type="bibr" target="#b7">Clarke et al., 2012</ref>). We used the Gurobi optimization package 3 for infer- ence.</p><p>We compare our system PROREAD to baselines that do not have access to the process structure:</p><p>1. BOW: For each answer, we compute the proportion of content word lemmas covered by the paragraph and choose the one with higher coverage. For true-false questions, we compute the coverage of the question state- ment, and answer "True" if it is higher than a threshold tuned on the development set. 2. TEXTPROX: For dependency questions, we align content word lemmas in both the ques- tion and answer against the text and select the answer whose aligned tokens are closer to the aligned tokens of the question. For tempo- ral questions, we return the answer for which the order of events is identical to their order in the paragraph. For true-false questions, we return "True" if the number of bigrams from the question covered in the text is higher than a threshold tuned on the development set. 3. SYNTPROX: For dependency questions, we use proximity as in TEXTPROX, except that distance is measured using dependency tree edges.  higher than a threshold tuned on the training set. To separate the contribution of process struc- tures from the performance of our structure pre- dictor, we also run our QA system given manually annotated gold standard structures (GOLD). <ref type="bibr">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Reading Comprehension Task</head><p>We evaluate our system using accuracy, i.e., the proportion of questions answered correctly. Ta- ble 4 presents test set results, where we break down questions by their coarse-type.</p><p>PROREAD improves accuracy compared to the best baseline by 6.7 absolute points (last column). Most of the gain is due to improvement on de- pendency questions, which are the most common question type. The performance of BOW indicates that lexical coverage alone does not distinguish the correct answer from the wrong answer. In fact, guessing the answer with higher lexical overlap results in performance that is slightly lower than random. Text proximity and syntactic proximity provide a stronger cue, but exploiting predicted process structures substantially outperforms these baselines.</p><p>Examining results using gold information high- lights the importance of process structures inde- pendently of the structure predictor. Results of GOLD demonstrate that given gold structures we can obtain a dramatic improvement of almost 17 points compared to the baselines, using our sim- ple deterministic QA system.</p><p>Results on true-false questions are low for PROREAD and all the baselines. True-false ques- tions are harder for two main reasons. First, in dependency and temporal questions, we create a query for both answers, and can find a proof or a refutation for either one of them. In true-false  questions we must determine given a single state- ment whether it holds. Second, an analysis of true- false questions reveals that they focus less on re- lations between events and entities in the process, and require modeling lexical variability. 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Structure Prediction Task</head><p>Our evaluation demonstrates that gold structures improve accuracy substantially more than pre- dicted structures. To examine this, we now di- rectly evaluate the structure predictor by com- paring micro-average precision, recall and F 1 be- tween predicted and gold structures ( <ref type="table" target="#tab_5">Table 5)</ref>.</p><p>While performance for trigger identification is reasonable, performance on argument and relation prediction is low. This explains the higher perfor- mance obtained in reading comprehension given gold structures. Note that errors in trigger predic- tion propagate to argument and relation prediction -a relation cannot be predicted correctly if either one of the related triggers is not previously identi- fied. One reason for low performance is the small size of the dataset. Thus, training process predic- tors with less supervision is an important direction for future work. Furthermore, the task of process prediction is inherently difficult, because often re- lations are expressed only indirectly in text. For example, in <ref type="figure">Figure 1</ref> the relation between water splitting and transfer of ions is only recoverable by understanding that water provides the ions that need to be transferred.</p><p>Nevertheless, we find that questions can often be answered correctly even if the structure con- tains some errors. For example, the gold structure for the sentence "Some . . . radioisotopes have long half-lives, allowing . . . ", contains the trigger long half-lives, while we predict have as a trigger and long half-lives as an argument. This is good enough to answer questions related to this part of the structure correctly, and overall, to improve per- formance using predicted structures.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Error Analysis</head><p>This section presents the results of an analysis of 20 sampled errors of GOLD (gold structures), and 20 errors of PROREAD (predicted structures). We have categorized the primary reason for error in <ref type="table" target="#tab_7">Table 6</ref>. As expected, the main problem when using pre- dicted structures, is structure errors which account for more than half of the errors.</p><p>Errors in GOLD are distributed across various categories, which we briefly describe. Alignment errors occur due to multiple words aligning to mul- tiple triggers and arguments. For example, in the question "What is the result of gases being pro- duced in the lysosome?", the answer "engulfed pathogens are poisoned" is incorrectly aligned to the trigger engulfed rather than to poisoned.</p><p>Another reason for errors are cases where ques- tions are asked about parts of the paragraph that are missing from annotation. This is possible since questions were authored independently of struc- ture annotation. Two other causes for errors are entity coreference errors, where a referent for an entity is missing from the structure, and lexical variability, where the author of questions uses names for triggers or arguments that are missing from the paragraph, and so alignment fails.</p><p>Last, in 10% of the cases in GOLD we found that the answer could not be retrieved using the set of regular expressions that are currently used by our QA system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>This work touches on several strands of work in NLP including information extraction, semantic role labeling, semantic parsing and reading com- prehension.</p><p>Event and relation extraction have been studied via the ACE data ( <ref type="bibr" target="#b10">Doddington et al., 2004</ref>) and related work. The BioNLP shared tasks <ref type="bibr" target="#b16">(Kim et al., 2009;</ref><ref type="bibr" target="#b17">Kim et al., 2011;</ref><ref type="bibr" target="#b30">Riedel and McCallum, 2011</ref>) focused on biomedical data to extract events and their arguments. Event-event relations have been mostly studied from the perspective of temporal ordering; e.g., <ref type="bibr" target="#b4">(Chambers and Jurafsky, 2008;</ref><ref type="bibr" target="#b36">Yoshikawa et al., 2009;</ref><ref type="bibr" target="#b9">Do et al., 2012;</ref><ref type="bibr" target="#b25">McClosky and Manning, 2012</ref>). The process struc- ture predicted in this work differs from these lines of work in two important ways: First, we predict events, arguments and their interactions from mul- tiple sentences, while most earlier work focused on one or two of these components. Second, we model processes, and thus target causal relations between events, rather than temporal order only.</p><p>Our semantic role annotation is similar to ex- isting SRL schemes such as PropBank ( <ref type="bibr" target="#b27">Palmer et al., 2005</ref>), FrameNet ( <ref type="bibr" target="#b32">Ruppenhofer et al., 2006</ref>) and BioProp ( <ref type="bibr" target="#b5">Chou et al., 2006</ref>). However, in con- trast to PropBank and FrameNet, we do not allow all verbs to trigger events and instead let the an- notators decide on biologically important triggers, which are not restricted to verbs (unlike BioProp, where 30 pre-specified verbs were selected for an- notation). Like PropBank and BioProp, the argu- ment labels are not trigger specific.</p><p>Mapping questions to queries is effectively a se- mantic parsing task. In recent years, several lines of work addressed semantic parsing using vari- ous formalisms and levels of supervision <ref type="bibr" target="#b37">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b35">Wong and Mooney, 2006;</ref><ref type="bibr" target="#b6">Clarke et al., 2010;</ref>). In particular, <ref type="bibr" target="#b18">Krishnamurthy and Kollar (2013)</ref> learned to map natural language utterances to ref- erents in an image by constructing a KB from the image and then mapping the utterance to a query over the KB. This is analogous to our process of constructing a process structure and performing QA by querying that structure. In our work, we parse questions into graph-based queries, suitable for modeling processes, using a rule-based heuris- tic. Training a statistical semantic parser that will replace the QA system is an interesting direction for future research.</p><p>Multiple choice reading comprehension tests are a natural choice for evaluating machine read- ing. <ref type="bibr" target="#b15">Hirschman et al. (1999)</ref> presented a bag-of- words approach to retrieving sentences for read- ing comprehension. <ref type="bibr" target="#b29">Richardson et al. (2013)</ref> re- cently released the MCTest reading comprehen- sion dataset that examines understanding of fic- tional stories. Their work shares our goal of ad- vancing micro-reading, but they do not focus on process understanding.</p><p>Developing programs that perform deep reason- ing over complex descriptions of processes is an important step on the road to fulfilling the higher goals of machine reading. In this paper, we present an end-to-end system for reading comprehen- sion of paragraphs which describe biological pro- cesses. This is, to the best of our knowledge, the first system to both predict a rich structured rep- resentation that includes entities, events and their relations, and utilize this structure for answering reading comprehension questions. We also created a new dataset, PROCESSBANK, which contains 200 paragraphs that are both fully-annotated with process structure, as well as accompanied by ques- tions. We empirically demonstrated that model- ing biological processes can substantially improve reading comprehension accuracy in this domain.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>"</head><label></label><figDesc>. . . Water is split, providing a source of elec- trons and protons (hydrogen ions, H + ) and giv- ing off O2 as a by-product. Light absorbed by chlorophyll drives a transfer of the electrons and hydrogen ions from water to an acceptor called NADP + . . . " Q What can the splitting of water lead to? a Light absorption b Transfer of ions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Partial example of a process, as annotated in our dataset.</figDesc><graphic url="image-1.png" coords="4,72.00,63.80,459.00,93.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Constraints for joint inference. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Reading comprehension test set accuracy. The All 

column shows overall accuracy across all questions. The first 
three columns show accuracy for each coarse type. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 : Structured prediction test set results.</head><label>5</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Error analysis results. An explanation of the vari-

ous categories are in the body of the paper. 

</table></figure>

			<note place="foot" n="1"> Lexical variability is an important problem in NLP, but is not the focus of this task.</note>

			<note place="foot" n="2"> In this work, we do not distinguish causation from facilitation, where u can help v but is not absolutely required. We instructed the annotators to ignore the inherent uncertainty in these cases and use CAUSE.</note>

			<note place="foot" n="4"> We also ran an experiment where gold triggers are given and arguments and relations are predicted. We found that this results in slightly higher performance compared to PROREAD.</note>

			<note place="foot" n="5"> The low performance of TEXTPROX and SYNTPROX on true-false questions can also be attributed to the fact that we tuned a threshold parameter on the training set, and this did not generalize well to the test set.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Luke Amuchastegui for authoring the multiple-choice questions, and also the anonymous reviewers for their constructive feedback. We thank the Allen Institute for Artificial Intelligence for assistance in funding this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Reece</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biology. Benjamin Cummings</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Betteridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Estevam</forename><forename type="middle">R</forename><surname>Hruschka</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">M</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Toward an architecture for neverending language learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Jointly combining implicit constraints improves temporal ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A semi-automatic method for annotating a biomedical proposition bank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Chi</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Tzong-Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying-Shan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Yi</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Lian</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora</title>
		<meeting>the Workshop on Frontiers in Linguistically Annotated Corpora</meeting>
		<imprint>
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Driving semantic parsing from the world&apos;s response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Roth</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An NLP Curator (or: How I Learned to Stop Worrying and Love NLP Pipelines)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint inference for event timeline construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quang</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Automatic Content Extraction (ACE) Program-Tasks, Data, and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">R</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><forename type="middle">A</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><forename type="middle">M</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Machine reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Cafarella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Paraphrase-Driven Learning for Open Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">WordNet: An electronic lexical database</title>
		<editor>Christiane Fellbaum</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep read: A reading comprehension system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynette</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Light</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Overview of BioNLP 09 shared task on event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshinobu</forename><surname>Kano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BioNLP</title>
		<meeting>BioNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Overview of BioNLP shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bossy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BioNLP</title>
		<meeting>BioNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Jointly learning to parse and perceive: Connecting natural language to the physical world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kollar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="193" to="206" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to automatically solve algebra word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">English verb classes and alternations: A preliminary investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Levin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>University of Chicago Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nomlex: A lexicon of nominalizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Macleod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Reeves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EURALEX</title>
		<meeting>EURALEX</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurence</forename><forename type="middle">A</forename><surname>Magnanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wolsey</surname></persName>
		</author>
		<title level="m">Optimal trees. Handbooks in operations research and management science</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="503" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL: System Demonstrations</title>
		<meeting>ACL: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Concise integer linear programming formulations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL/IJCNLP</title>
		<meeting>ACL/IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning constraints for consistent timeline extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cogex: A logic prover for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Maiorano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACLHLT</title>
		<meeting>NAACLHLT</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The proposition bank: An annotated corpus of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="106" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The importance of syntactic parsing and inference in semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasin</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">34</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">MCTest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Renshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fast and robust joint models for biomedical event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A linear programming formulation for global inference in natural language tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">FrameNet II: Extended theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ellsworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Miriam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">R</forename><surname>Petruck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Berkeley FrameNet Release</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning biological processes with global constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Aju Thalappillil Scaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brittany</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Harding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Brat: a web-based tool for NLP-assisted text annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Topi´ctopi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the demonstrations at EACL</title>
		<meeting>the demonstrations at EACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning for semantic parsing with statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Jointly identifying temporal relations with Markov logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsumasa</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayuki</forename><surname>Asahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL/IJCNLP</title>
		<meeting>ACL/IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of UAI</title>
		<meeting>UAI</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
