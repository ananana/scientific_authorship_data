<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieyu</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Virginia</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Virginia</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Virginia</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Virginia</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Virginia</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2979" to="2989"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Language is increasingly being used to define rich visual recognition problems with supporting image collections sourced from the web. Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora. In this work, we study data and models associated with multilabel object classification and visual semantic role labeling. We find that (a) datasets for these tasks contain significant gender bias and (b) models trained on these datasets further amplify existing bias. For example, the activity cooking is over 33% more likely to involve females than males in a training set, and a trained model further amplifies the disparity to 68% at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference. Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 47.5% and 40.5% for multilabel classification and visual semantic role labeling, respectively.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Visual recognition tasks involving language, such as captioning ( <ref type="bibr" target="#b30">Vinyals et al., 2015)</ref>, visual ques- tion answering ( <ref type="bibr" target="#b0">Antol et al., 2015)</ref>, and visual se- mantic role labeling ( <ref type="bibr" target="#b32">Yatskar et al., 2016)</ref>, have emerged as avenues for expanding the diversity of information that can be recovered from im- ages. These tasks aim at extracting rich seman- tics from images and require large quantities of la- beled data, predominantly retrieved from the web. Methods often combine structured prediction and deep learning to model correlations between la- bels and images to make judgments that otherwise would have weak visual support. For example, in the first image of <ref type="figure">Figure 1</ref>, it is possible to pre- dict a spatula by considering that it is a com- mon tool used for the activity cooking. Yet such methods run the risk of discovering and exploiting societal biases present in the underlying web cor- pora. Without properly quantifying and reducing the reliance on such correlations, broad adoption of these models can have the inadvertent effect of magnifying stereotypes.</p><p>In this paper, we develop a general framework for quantifying bias and study two concrete tasks, visual semantic role labeling (vSRL) and multil- abel object classification (MLC). In vSRL, we use the imSitu formalism ( <ref type="bibr" target="#b32">Yatskar et al., 2016</ref><ref type="bibr" target="#b31">Yatskar et al., , 2017</ref>, where the goal is to predict activities, objects and the roles those objects play within an activity. For MLC, we use MS-COCO ( <ref type="bibr" target="#b17">Lin et al., 2014;</ref><ref type="bibr" target="#b8">Chen et al., 2015)</ref>, a recognition task covering 80 object classes. We use gender bias as a running example and show that both supporting datasets for these tasks are biased with respect to a gender binary <ref type="bibr">1</ref> .</p><p>Our analysis reveals that over 45% and 37% of verbs and objects, respectively, exhibit bias to- ward a gender greater than 2:1. For example, as seen in <ref type="figure">Figure 1</ref>, the cooking activity in imSitu is a heavily biased verb. Furthermore, we show that after training state-of-the-art structured pre- dictors, models amplify the existing bias, by 5.0% for vSRL, and 3.6% in MLC.  <ref type="figure">Figure 1</ref>: Five example images from the imSitu visual semantic role labeling (vSRL) dataset. Each im- age is paired with a table describing a situation: the verb, cooking, its semantic roles, i.e agent, and noun values filling that role, i.e. woman. In the imSitu training set, 33% of cooking images have man in the agent role while the rest have woman. After training a Conditional Random Field (CRF), bias is amplified: man fills 16% of agent roles in cooking images. To reduce this bias amplification our cal- ibration method adjusts weights of CRF potentials associated with biased predictions. After applying our methods, man appears in the agent role of 20% of cooking images, reducing the bias amplification by 25%, while keeping the CRF vSRL performance unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COOKING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROLE VALUE</head><p>To mitigate the role of bias amplification when training models on biased corpora, we propose a novel constrained inference framework, called RBA, for Reducing Bias Amplification in predic- tions. Our method introduces corpus-level con- straints so that gender indicators co-occur no more often together with elements of the prediction task than in the original training distribution. For ex- ample, as seen in <ref type="figure">Figure 1</ref>, we would like noun man to occur in the agent role of the cooking as often as it occurs in the imSitu training set when evaluating on a development set. We combine our calibration constraint with the original struc- tured predictor and use Lagrangian relaxation <ref type="bibr" target="#b16">(Korte and Vygen, 2008;</ref><ref type="bibr" target="#b25">Rush and Collins, 2012)</ref> to reweigh bias creating factors in the original model. We evaluate our calibration method on imSitu vSRL and COCO MLC and find that in both in- stances, our models substantially reduce bias am- plification. For vSRL, we reduce the average mag- nitude of bias amplification by 40.5%. For MLC, we are able to reduce the average magnitude of bias amplification by 47.5%. Overall, our calibra- tion methods do not affect the performance of the underlying visual system, while substantially re- ducing the reliance of the system on socially bi- ased correlations 2 .</p><p>2 Code and data are available at https://github. com/uclanlp/reducingbias</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>As intelligence systems start playing important roles in our daily life, ethics in artificial in- telligence research has attracted significant in- terest. It is known that big-data technologies sometimes inadvertently worsen discrimination due to implicit biases in data ( <ref type="bibr" target="#b23">Podesta et al., 2014)</ref>. Such issues have been demonstrated in var- ious learning systems, including online advertise- ment systems <ref type="bibr" target="#b28">(Sweeney, 2013)</ref>, word embedding models ( <ref type="bibr" target="#b3">Bolukbasi et al., 2016;</ref><ref type="bibr" target="#b5">Caliskan et al., 2017)</ref>, online news ( <ref type="bibr" target="#b24">Ross and Carter, 2011</ref>), web search ( <ref type="bibr" target="#b15">Kay et al., 2015)</ref>, and credit score <ref type="bibr" target="#b14">(Hardt et al., 2016)</ref>. Data collection biases have been discussed in the context of creating image cor- pus ( <ref type="bibr" target="#b20">Misra et al., 2016;</ref><ref type="bibr" target="#b19">van Miltenburg, 2016)</ref> and text corpus <ref type="bibr" target="#b12">(Gordon and Van Durme, 2013;</ref><ref type="bibr" target="#b29">Van Durme, 2010</ref>). In contrast, we show that given a gender biased corpus, structured models such as conditional random fields, amplify the bias.</p><p>The effect of the data imbalance can be easily detected and fixed when the prediction task is sim- ple. For example, when classifying binary data with unbalanced labels (i.e., samples in the major- ity class dominate the dataset), a classifier trained exclusively to optimize accuracy learns to always predict the majority label, as the cost of mak- ing mistakes on samples in the minority class can be neglected. Various approaches have been pro- posed to make a "fair" binary classification <ref type="bibr" target="#b2">(Barocas and Selbst, 2014;</ref><ref type="bibr" target="#b10">Dwork et al., 2012;</ref><ref type="bibr" target="#b11">Feldman et al., 2015;</ref><ref type="bibr" target="#b33">Zliobaite, 2015)</ref>. For structured pre- diction tasks the effect is harder to quantify and we are the first to propose methods to reduce bias amplification in this context.</p><p>Lagrangian relaxation and dual decomposi- tion techniques have been widely used in NLP tasks (e.g., <ref type="bibr" target="#b27">(Sontag et al., 2011;</ref><ref type="bibr" target="#b25">Rush and Collins, 2012;</ref><ref type="bibr" target="#b7">Chang and Collins, 2011;</ref><ref type="bibr" target="#b22">Peng et al., 2015)</ref>) for dealing with instance-level constraints. Simi- lar techniques <ref type="bibr" target="#b6">(Chang et al., 2013;</ref><ref type="bibr" target="#b9">Dalvi, 2015</ref>) have been applied in handling corpus-level con- straints for semi-supervised multilabel classifica- tion. In contrast to previous works aiming for improving accuracy performance, we incorporate corpus-level constraints for reducing gender bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Visualizing and Quantifying Biases</head><p>Modern statistical learning approaches capture correlations among output variables in order to make coherent predictions. However, for real- world applications, some implicit correlations are not appropriate, especially if they are amplified. In this section, we present a general framework to analyze inherent biases learned and amplified by a prediction model.</p><p>Identifying bias We consider that prediction problems involve several inter-dependent output variables y 1 , y 2 , ...y K , which can be represented as a structure y = {y 1 , y 2 , ...y K } ∈ Y . This is a common setting in NLP applications, includ- ing tagging, and parsing. For example, in the vSRL task, the output can be represented as a structured table as shown in <ref type="figure">Fig 1.</ref> Modern tech- niques often model the correlation between the sub-components in y and make a joint prediction over them using a structured prediction model. More details will be provided in Section 4.</p><p>We assume there is a subset of output vari- ables g ⊆ y, g ∈ G that reflects demographic at- tributes such as gender or race (e.g. g ∈ G = {man, woman} is the agent), and there is another subset of the output o ⊆ y, o ∈ O that are co- related with g (e.g., o is the activity present in an image, such as cooking). The goal is to identify the correlations that are potentially amplified by a learned model. To achieve this, we define the bias score of a given output, o, with respect to a demographic variable, g, as:</p><formula xml:id="formula_0">b(o, g) = c(o, g) g ∈G c(o, g ) ,</formula><p>where c(o, g) is the number of occurrences of o and g in a corpus. For example, to analyze how genders of agents and activities are co-related in vSRL, we define the gender bias toward man for each verb b(verb, man) as:</p><formula xml:id="formula_1">c(verb, man) c(verb, man) + c(verb, woman) .<label>(1)</label></formula><p>If b(o, g) &gt; 1/G, then o is positively correlated with g and may exhibit bias.</p><p>Evaluating bias amplification To evaluate the degree of bias amplification, we propose to com- pare bias scores on the training set, b * (o, g), with bias scores on an unlabeled evaluation set of im- ages˜bages˜ages˜b(o, g) that has been annotated by a predic- tor. We assume that the evaluation set is iden- tically distributed to the training set. There- fore, if o is positively correlated with g (i.e,</p><formula xml:id="formula_2">b * (o, g) &gt; 1/G) and˜band˜and˜b(o, g) is larger than b * (o, g</formula><p>), we say bias has been amplified. For example, if b * (cooking, woman) = .66, and˜b and˜and˜b(cooking, woman) = .84, then the bias of woman toward cooking has been amplified. Fi- nally, we define the mean bias amplification as:</p><formula xml:id="formula_3">1 |O| g o∈{o∈O|b * (o,g)&gt;1/G}˜b G}˜G}˜b(o, g) − b * (o, g).</formula><p>This score estimates the average magnitude of bias amplification for pairs of o and g which exhibited bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Calibration Algorithm</head><p>In this section, we introduce Reducing Bias Amplification, RBA, a debiasing technique for calibrating the predictions from a structured pre- diction model. The intuition behind the algorithm is to inject constraints to ensure the model pre- dictions follow the distribution observed from the training data. For example, the constraints added to the vSRL system ensure the gender ratio of each verb in Eq. <ref type="formula" target="#formula_1">(1)</ref> are within a given margin based on the statistics of the training data. These constraints are applied at the corpus level, because comput- ing gender ratio requires the predictions of all test instances. As a result, a joint inference over test instances is required <ref type="bibr">3</ref> . Solving such a giant in- ference problem with constraints is hard. There- fore, we present an approximate inference algo- rithm based on Lagrangian relaxation. The advan- tages of this approach are:</p><p>• Our algorithm is iterative, and at each it- eration, the joint inference problem is de- composed to a per-instance basis. This can be solved by the original inference algo- rithm. That is, our approach works as a meta- algorithm and developers do not need to im- plement a new inference algorithm.</p><p>• The approach is general and can be applied in any structured model.</p><p>• Lagrangian relaxation guarantees the solu- tion is optimal if the algorithm converges and all constraints are satisfied.</p><p>In practice, it is hard to obtain a solution where all corpus-level constrains are satisfied. However, we show that the performance of the proposed ap- proach is empirically strong. We use imSitu for vSRL as a running example to explain our algo- rithm.</p><p>Structured Output Prediction As we men- tioned in Sec. 3, we assume the structured output y ∈ Y consists of several sub-components. Given a test instance i as an input, the inference problem is to find arg max</p><formula xml:id="formula_4">y∈Y f θ (y, i),</formula><p>where f θ (y, i) is a scoring function based on a model θ learned from the training data. The struc- tured output y and the scoring function f θ (y, i) can be decomposed into small components based on an independence assumption. For example, in the vSRL task, the output y consists of two types of binary output variables {y v } and {y v,r }. The vari- able y v = 1 if and only if the activity v is chosen. Similarly, y v,r = 1 if and only if both the activity v and the semantic role r are assigned <ref type="bibr">4</ref> . The scoring function f θ (y, i) is decomposed accordingly such that:</p><formula xml:id="formula_5">f θ (y, i) = v y v s θ (v, i) + v,r y v,r s θ (v, r, i),</formula><p>represents the overall score of an assignment, and s θ (v, i) and s θ (v, r, i) are the potentials of the sub- assignments. The output space Y contains all fea- sible assignments of y v and y v,r , which can be rep- resented as instance-wise constraints. For exam- ple, the constraint, v y v = 1 ensures only one activity is assigned to one image.</p><p>Corpus-level Constraints Our goal is to inject constraints to ensure the output labels follow a desired distribution. For example, we can set a constraint to ensure the gender ratio for each ac- tivity in Eq. <ref type="formula" target="#formula_1">(1)</ref> is within a given margin. Let y i = {y i v } ∪ {y i v,r } be the output assignment for test instance i 5 . For each activity v * , the con- straints can be written as</p><formula xml:id="formula_6">b * −γ ≤ i y i v=v * ,r∈M i y i v=v * ,r∈W + i y i v=v * ,r∈M ≤ b * + γ (2) where b * ≡ b * (v * , man)</formula><p>is the desired gender ra- tio of an activity v * , γ is a user-specified margin. M and W are a set of semantic role-values rep- resenting the agent as a man or a woman, respec- tively.</p><p>Note that the constraints in (2) involve all the test instances. Therefore, it requires a joint in- ference over the entire test corpus. In general, these corpus-level constraints can be represented in a form of A i y i − b ≤ 0, where each row in the matrix A ∈ R l×K is the coefficients of one constraint, and b ∈ R l . The constrained inference problem can then be formulated as:</p><formula xml:id="formula_7">max {y i }∈{Y i } i f θ (y i , i), s.t. A i y i − b ≤ 0,<label>(3)</label></formula><p>where {Y i } represents a space spanned by possi- ble combinations of labels for all instances. With- out the corpus-level constraints, Eq. (3) can be optimized by maximizing each instance i</p><formula xml:id="formula_8">max y i ∈Y i f θ (y i , i),</formula><p>separately.</p><p>Lagrangian Relaxation Eq. (3) can be solved by several combinatorial optimization methods. For example, one can represent the problem as an Dataset Task Images O-Type O imSitu vSRL 60,000 verb 212 MS-COCO MLC 25,000 object 66 <ref type="table">Table 1</ref>: Statistics for the two recognition prob- lems. In vSRL, we consider gender bias relating to verbs, while in MLC we consider the gender bias related to objects.</p><p>integer linear program and solve it using an off- the-shelf solver (e.g., Gurobi (Gurobi Optimiza- tion, 2016)). However, Eq. (3) involves all test in- stances. Solving a constrained optimization prob- lem on such a scale is difficult. Therefore, we con- sider relaxing the constraints and solve Eq. (3) us- ing a Lagrangian relaxation technique <ref type="bibr" target="#b25">(Rush and Collins, 2012</ref>). We introduce a Lagrangian multi- plier λ j ≥ 0 for each corpus-level constraint. The Lagrangian is</p><formula xml:id="formula_9">L(λ, {y i }) = i f θ (y i ) − l j=1 λ j A j i y i − b j ,<label>(4)</label></formula><p>where all the λ j ≥ 0, ∀j ∈ {1, . . . , l}. The solu- tion of Eq. <ref type="formula" target="#formula_7">(3)</ref> can be obtained by the following iterative procedure:</p><p>1) At iteration t, get the output solution of each instance i</p><formula xml:id="formula_10">y i,(t) = argmax y∈Y L(λ (t−1) , y)<label>(5)</label></formula><p>2) update the Lagrangian multipliers.</p><formula xml:id="formula_11">λ (t) = max 0, λ (t−1) + i η(Ay i,(t) − b)</formula><p>, where λ (0) = 0. η is the learning rate for updat- ing λ. Note that with a fixed λ (t−1) , Eq. (5) can be solved using the original inference algorithms. The algorithm loops until all constraints are satis- fied (i.e. optimal solution achieved) or reach max- imal number of iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>In this section, we provide details about the two vi- sual recognition tasks we evaluated for bias: visual semantic role labeling (vSRL), and multi-label classification (MLC). We focus on gender, defin- ing G = {man, woman} and focus on the agent role in vSRL, and any occurrence in text associ- ated with the images in MLC. Problem statistics are summarized in <ref type="table">Table 1</ref>. We also provide setup details for our calibration method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Visual Semantic Role Labeling</head><p>Dataset We evaluate on imSitu ( <ref type="bibr" target="#b32">Yatskar et al., 2016</ref>) where activity classes are drawn from verbs and roles in FrameNet ( <ref type="bibr" target="#b1">Baker et al., 1998</ref>) and noun categories are drawn from WordNet ( <ref type="bibr" target="#b18">Miller et al., 1990</ref>). The original dataset includes about 125,000 images with 75,702 for training, 25,200 for developing, and 25,200 for test. However, the dataset covers many non-human oriented activities (e.g., rearing, retrieving, and wagging), so we filter out these verbs, resulting in 212 verbs, leaving roughly 60,000 of the original 125,000 im- ages in the dataset.</p><p>Model We build on the baseline CRF released with the data, which has been shown effective compared to a non-structured prediction base- line ( <ref type="bibr" target="#b32">Yatskar et al., 2016</ref>). The model decomposes the probability of a realized situation, y, the com- bination of activity, v, and realized frame, a set of semantic (role,noun) pairs (e, n e ), given an image i as :</p><formula xml:id="formula_12">p(y|i; θ) ∝ ψ(v, i; θ) (e,ne)∈R f ψ(v, e, n e , i; θ)</formula><p>where each potential value in the CRF for subpart x, is computed using features f i from the VGG convolutional neural network (Simonyan and Zis- serman, 2014) on an input image, as follows:</p><formula xml:id="formula_13">ψ(x, i; θ) = e w T x f i +bx ,</formula><p>where w and b are the parameters of an affine transformation layer. The model explicitly cap- tures the correlation between activities and nouns in semantic roles, allowing it to learn common pri- ors. We use a model pretrained on the original task with 504 verbs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multilabel Classification</head><p>Dataset We use MS-COCO ( <ref type="bibr" target="#b17">Lin et al., 2014</ref>), a common object detection benchmark, for multi- label object classification. The dataset contains 80 object types but does not make gender distinctions between man and woman. We use the five asso- ciated image captions available for each image in this dataset to annotate the gender of people in the images. If any of the captions mention the word man or woman we mark it, removing any images that mention both genders. Finally, we filter any object category not strongly associated with hu- mans by removing objects that do not occur with man or woman at least 100 times in the training set, leaving a total of 66 objects.</p><p>Model For this multi-label setting, we adapt a similar model as the structured CRF we use for vSRL. We decompose the joint probability of the output y, consisting of all object categories, c, and gender of the person, g, given an image i as:</p><formula xml:id="formula_14">p(y|i; θ) ∝ ψ(g, i; θ) c∈y ψ(g, c, i; θ)</formula><p>where each potential value for x, is computed us- ing features, f i , from a pretrained ResNet-50 con- volutional neural network evaluated on the image,</p><formula xml:id="formula_15">ψ(x, i; θ) = e w T x f i +bx .</formula><p>We trained a model using SGD with learning rate 10 −5 , momentum 0.9 and weight-decay 10 −4 , fine tuning the initial visual network, for 50 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Calibration</head><p>The inference problems for both models are:</p><p>arg max y∈Y f θ (y, i) = log p(y|i; θ).</p><p>We use the algorithm in Sec. <ref type="formula" target="#formula_9">(4)</ref> to calibrate the predictions using model θ. Our calibration tries to enforce gender statistics derived from the training set of corpus applicable for each recognition prob- lem. For all experiments, we try to match gen- der ratios on the test set within a margin of .05 of their value on the training set. While we do adjust the output on the test set, we never use the ground truth on the test set and instead working from the assumption that it should be similarly distributed as the training set. When running the debiasing al- gorithm, we set η = 10 −1 and optimize for 100 iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Bias Analysis</head><p>In this section, we use the approaches outlined in Section 3 to quantify the bias and bias amplifi- cation in the vSRL and the MLC tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Visual Semantic Role Labeling</head><p>imSitu is gender biased In <ref type="figure">Figure 2(a)</ref>, along the x-axis, we show the male favoring bias of im- Situ verbs. Overall, the dataset is heavily biased toward male agents, with 64.6% of verbs favoring a male agent by an average bias of 0.707 (roughly 3:1 male). Nearly half of verbs are extremely bi- ased in the male or female direction: 46.95% of verbs favor a gender with a bias of at least 0.7. 6 <ref type="figure">Figure 2</ref>(a) contains several activity labels reveal- ing problematic biases. For example, shopping, microwaving and washing are biased toward a female agent. Furthermore, several verbs such as driving, shooting, and coaching are heavily biased toward a male agent.</p><p>Training on imSitu amplifies bias In <ref type="figure">Fig- ure 2(a)</ref>, along the y-axis, we show the ratio of male agents (% of total people) in predictions on an unseen development set. The mean bias ampli- fication in the development set is high, 0.050 on average, with 45.75% of verbs exhibiting ampli- fication. Biased verbs tend to have stronger am- plification: verbs with training bias over 0.7 in either the male or female direction have a mean amplification of 0.072. Several already problem- atic biases have gotten much worse. For example, serving, only had a small bias toward females in the training set, 0.402, is now heavily biased toward females, 0.122. The verb tuning, origi- nally heavily biased toward males, 0.878, now has exclusively male agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Multilabel Classification</head><p>MS-COCO is gender biased In <ref type="figure">Figure 2(b)</ref> along the x-axis, similarly to imSitu, we ana- lyze bias of objects in MS-COCO with respect to males. MS-COCO is even more heavily bi- ased toward men than imSitu, with 86.6% of ob- jects biased toward men, but with smaller average magnitude, 0.65. One third of the nouns are ex- tremely biased toward males, 37.9% of nouns fa- vor men with a bias of at least 0.7. Some prob- lematic examples include kitchen objects such as knife, fork, or spoon being more biased to- ward woman. Outdoor recreation related objects such tennis racket, snowboard and boat tend to be more biased toward men.  <ref type="table">wine glass   tennis racket  hot dog  keyboard  traffic light skis  boat  motorcycle</ref>  , along the y-axis, we show the ratio of man (% of both gender) in predictions on an un- seen development set. The mean bias amplifica- tion across all objects is 0.036, with 65.67% of nouns exhibiting amplification. Larger training bias again tended to indicate higher bias amplifi- cation: biased objects with training bias over 0.7 had mean amplification of 0.081. Again, several problematic biases have now been amplified. For example, kitchen categories already biased toward females such as knife, fork and spoon have all been amplified. Technology oriented categories initially biased toward men such as keyboard and mouse have each increased their bias toward males by over 0.100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Discussion</head><p>We confirmed our hypothesis that (a) both the im- Situ and MS-COCO datasets, gathered from the web, are heavily gender biased and that (b) mod- els trained to perform prediction on these datasets amplify the existing gender bias when evaluated on development data. Furthermore, across both datasets, we showed that the degree of bias am- plification was related to the size of the initial bias, with highly biased object and verb categories exhibiting more bias amplification. Our results demonstrate that care needs be taken in deploying such uncalibrated systems otherwise they could not only reinforce existing social bias but actually make them worse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Calibration Results</head><p>We test our methods for reducing bias amplifica- tion in two problem settings: visual semantic role labeling in the imSitu dataset (vSRL) and multil- abel image classification in MS-COCO (MLC). In all settings we derive corpus constraints using the training set and then run our calibration method in batch on either the development or testing set. Our results are summarized in <ref type="table" target="#tab_2">Table 2</ref> and <ref type="figure" target="#fig_2">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Visual Semantic Role Labeling</head><p>Our quantitative results are summarized in the first two sections of <ref type="table" target="#tab_2">Table 2</ref>. On the development set, the number of verbs whose bias exceed the original bias by over 5% decreases 30.5% (Viol.). Overall, we are able to significantly reduce bias amplification in vSRL by 52% on the develop- ment set (Amp. bias). We evaluate the under- lying recognition performance using the standard measure in vSRL: top-1 semantic role accuracy, which tests how often the correct verb was pre- dicted and the noun value was correctly assigned to a semantic role. Our calibration method results in a negligible decrease in performance (Perf.). In <ref type="figure" target="#fig_2">Figure 3</ref>(c) we can see that the overall distance to the training set distribution after applying RBA de- creased significantly, over 39%. <ref type="figure" target="#fig_2">Figure 3</ref>(e) demonstrates that across all initial training bias, RBA is able to reduce bias amplifi- cation. In general, RBA struggles to remove bias amplification in areas of low initial training bias,    likely because bias is encoded in image statistics and cannot be removed as effectively with an im- age agnostic adjustment. Results on the test set support our development set results: we decrease bias amplification by 40.5% (Amp. bias).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Multilabel Classification</head><p>Our quantitative results on MS-COCO RBA are summarized in the last two sections of <ref type="table" target="#tab_2">Table 2</ref>. Similarly to vSRL, we are able to reduce the num- ber of objects whose bias exceeds the original training bias by 5%, by 40% (Viol.). Bias amplifi- cation was reduced by 31.3% on the development set (Amp. bias). The underlying recognition sys- tem was evaluated by the standard measure: top- 1 mean average precision, the precision averaged across object categories. Our calibration method results in a negligible loss in performance. In <ref type="figure" target="#fig_2">Fig- ure 3(d)</ref>, we demonstrate that we substantially re- duce the distance between training bias and bias in the development set. Finally, in <ref type="figure" target="#fig_2">Figure 3</ref>(f) we demonstrate that we decrease bias amplification for all initial training bias settings. Results on the test set support our development results: we de- crease bias amplification by 47.5% (Amp. bias).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Discussion</head><p>We have demonstrated that RBA can significantly reduce bias amplification. While were not able to remove all amplification, we have made significant progress with little or no loss in underlying recog- nition performance. Across both problems, RBA was able to reduce bias amplification at all initial values of training bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>Structured prediction models can leverage correla- tions that allow them to make correct predictions even with very little underlying evidence. Yet such models risk potentially leveraging social bias in their training data. In this paper, we presented a general framework for visualizing and quantify- ing biases in such models and proposed RBA to calibrate their predictions under two different set- tings. Taking gender bias as an example, our anal- ysis demonstrates that conditional random fields can amplify social bias from data while our ap- proach RBA can help to reduce the bias. Our work is the first to demonstrate structured prediction models amplify bias and the first to propose methods for reducing this effect but sig- nificant avenues for future work remain. While RBA can be applied to any structured predic- tor, it is unclear whether different predictors am- plify bias more or less. Furthermore, we pre- sented only one method for measuring bias. More extensive analysis could explore the interaction among predictor, bias measurement, and bias de- amplification method. Future work also includes applying bias reducing methods in other struc- tured domains, such as pronoun reference resolu- tion <ref type="bibr" target="#b21">(Mitkov, 2014</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2: Gender bias analysis of imSitu vSRL and MS-COCO MLC. (a) gender bias of verbs toward man in the training set versus bias on a predicted development set. (b) gender bias of nouns toward man in the training set versus bias on the predicted development set. Values near zero indicate bias toward woman while values near 0.5 indicate unbiased variables. Across both dataset, there is significant bias toward males, and significant bias amplification after training on biased training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results of reducing bias amplification using RBA on imSitu vSRL and MS-COCO MLC. Figures 3(a)-(d) show initial training set bias along the x-axis and development set bias along the yaxis. Dotted blue lines indicate the 0.05 margin used in RBA, with points violating the margin shown in red while points meeting the margin are shown in green. Across both settings adding RBA significantly reduces the number of violations, and reduces the bias amplification significantly. Figures 3(e)-(f) demonstrate bias amplification as a function of training bias, with and without RBA. Across all initial training biases, RBA is able to reduce the bias amplification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Method</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Number of violated constraints, mean 
amplified bias, and test performance before and af-
ter calibration using RBA. The test performances 
of vSRL and MLC are measured by top-1 seman-
tic role accuracy and top-1 mean average preci-
sion, respectively. 

</table></figure>

			<note place="foot" n="1"> To simplify our analysis, we only consider a gender binary as perceived by annotators in the datasets. We recognize that a more fine-grained analysis would be needed for deployment in a production system. Also, note that the proposed approach can be applied to other NLP tasks and other variables such as identification with a racial or ethnic group.</note>

			<note place="foot" n="3"> A sufficiently large sample of test instances must be used so that bias statistics can be estimated. In this work we use the entire test set for each respective problem. 4 We use r to refer to a combination of role and noun. For example, one possible value indicates an agent is a woman.</note>

			<note place="foot" n="5"> For the sake of simplicity, we abuse the notations and use i to represent both input and data index.</note>

			<note place="foot" n="6"> In this gender binary, bias toward woman is 1− the bias toward man</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Vqa: Visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2425" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Berkeley framenet project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Collin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John B</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="86" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Big data&apos;s disparate impact. Available at SSRN 2477899</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Solon</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Selbst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Bolukbasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Saligrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam T</forename><surname>Kalai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Man is to computer programmer as woman is to homemaker? debiasing word embeddings</title>
	</analytic>
	<monogr>
		<title level="m">The Conference on Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<biblScope unit="page" from="4349" to="4357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantics derived automatically from language corpora contain human-like biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aylin</forename><surname>Caliskan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><forename type="middle">J</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="issue">6334</biblScope>
			<biblScope unit="page" from="183" to="186" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tractable semi-supervised learning of complex structured prediction models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sathiya Keerthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning (ECML)</title>
		<meeting>the European Conference on Machine Learning (ECML)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="176" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exact decoding of phrase-based translation models through Lagrangian relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin-Wen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="26" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Microsoft coco captions: Data collection and evaluation server</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.00325</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Constrained Semisupervised Learning in the Presence of Unanticipated Classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharat</forename><surname>Bhavana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dalvi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>Google Research</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fairness through awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toniann</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Innovations in Theoretical Computer Science Conference</title>
		<meeting>the 3rd Innovations in Theoretical Computer Science Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="214" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Certifying and removing disparate impact</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sorelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Friedler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Moeller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Venkatasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Automated Knowledge Base Construction (AKBC)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Reporting bias and knowledge extraction</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Gurobi optimizer reference manual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">Gurobi</forename><surname>Inc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Optimization</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Equality of opportunity in supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nati</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3315" to="3323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unequal representation and gender stereotypes in image search results for occupations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><forename type="middle">A</forename><surname>Munson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Factors in Computing Systems</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3819" to="3828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Combinatorial Optimization: Theory and Application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Korte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Vygen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Wordnet: An on-line lexical database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Beckwith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Lexicography</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="235" to="312" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Stereotyping and bias in the flickr30k dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Emiel Van Miltenburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MMC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Seeing through the human reporting bias: Visual classifiers from noisy humancentric labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2930" to="2939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Mitkov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dual decomposition inference for graphical models over strings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="917" to="927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Big data: Seizing opportunities and preserving values. Executive Office of the President</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Podesta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Penny</forename><surname>Pritzker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernest</forename><forename type="middle">J</forename><surname>Moniz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Holdren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jefrey</forename><surname>Zients</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Women and news: A long and winding road. Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Carter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Culture &amp; Society</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1148" to="1165" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Tutorial on Dual Decomposition and Lagrangian Relaxation for Inference in Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="305" to="362" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Introduction to dual decomposition for inference. Optimization for Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="219" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Discrimination in online ad delivery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Latanya</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Queue</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Extracting implicit knowledge from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Benjamin D Van Durme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>University of Rochester</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Commonly uncommon: Semantic sparsity in situation recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Situation recognition: Visual semantic role labeling for image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5534" to="5542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A survey on measuring indirect discrimination in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Indre Zliobaite</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.00148</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
