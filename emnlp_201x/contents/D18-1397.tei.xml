<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Study of Reinforcement Learning for Neural Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
							<email>wulijun3@mail2.sysu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Data and Computer Science</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhuang</forename><surname>Lai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data and Computer Science</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Study of Reinforcement Learning for Neural Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3612" to="3621"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3612</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent studies have shown that reinforcement learning (RL) is an effective approach for improving the performance of neural machine translation (NMT) system. However, due to its instability, successfully RL training is challenging, especially in real-world systems where deep models and large datasets are lever-aged. In this paper, taking several large-scale translation tasks as testbeds, we conduct a systematic study on how to train better NMT models using reinforcement learning. We provide a comprehensive comparison of several important factors (e.g., baseline reward, reward shaping) in RL training. Furthermore, to fill in the gap that it remains unclear whether RL is still beneficial when monolingual data is used, we propose a new method to leverage RL to further boost the performance of NMT systems trained with source/target monolingual data. By integrating all our findings, we obtain competitive results on WMT14 English-Ger-man, WMT17 English-Chinese, and WMT17 Chinese-English translation tasks, especially setting a state-of-the-art performance on WMT17 Chinese-English translation task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, neural machine translation (NMT) <ref type="bibr" target="#b1">(Bahdanau et al., 2015;</ref><ref type="bibr" target="#b8">Hassan et al., 2018;</ref><ref type="bibr" target="#b9">He et al., 2017;</ref><ref type="bibr" target="#b37">Xia et al., 2016</ref><ref type="bibr" target="#b33">Wu et al., 2018b</ref>,a) has become more and more popular given its superior performance without the demand of heavily hand-crafted engineering efforts. It is usually trained to maximize the likelihood of each token in the target sentence, by taking the source sentence and the preceding (ground-truth) target tokens as inputs. Such training approach is referred as maximum likelihood estimation (MLE) <ref type="bibr" target="#b21">(Scholz, 1985)</ref>. Although easy to implement, the token-level * This work was conducted at Microsoft Research Asia.</p><p>objective function during training is inconsisten- t with sequence-level evaluation metrics such as BLEU ( <ref type="bibr" target="#b19">Papineni et al., 2002</ref>).</p><p>To address the inconsistency issue, reinforce- ment learning (RL) methods have been adopted to optimize sequence-level objectives. For example, policy optimization methods such as REINFORCE ( <ref type="bibr" target="#b20">Ranzato et al., 2016;</ref><ref type="bibr" target="#b35">Wu et al., 2017b</ref>) and actor- critic ( <ref type="bibr" target="#b0">Bahdanau et al., 2017)</ref> are leveraged for sequence generation tasks including NMT. In ma- chine translation community, a similar method is proposed with the name 'minimum risk training' <ref type="bibr" target="#b26">(Shen et al., 2016)</ref>. All these works demonstrate the effectiveness of RL techniques for NMT mod- els ( .</p><p>However, effectively applying RL to real-world NMT systems has not been fulfilled by previous works. First, most of, if not all, previous works verified their methods based on shallow recurrent neural network (RNN) models. However, to obtain state-of-the-art (SOTA) performance, it is essential to leverage recently derived deep models <ref type="bibr" target="#b6">(Gehring et al., 2017;</ref><ref type="bibr" target="#b28">Vaswani et al., 2017)</ref>, which are much more powerful.</p><p>Second, it is not easy to make RL practically ef- fective given quite a few widely acknowledged lim- itations of RL method <ref type="bibr" target="#b11">(Henderson et al., 2018</ref>) such as high variance of gradient estimation <ref type="bibr" target="#b30">(Weaver and Tao, 2001)</ref>, and objective instability ( <ref type="bibr" target="#b15">Mnih et al., 2013</ref>). Therefore, several tricks are proposed in previous works. However, it remains unclear, and no agreement is achieved on how to use these tricks in machine translation. For example, baseline re- ward method <ref type="bibr" target="#b30">(Weaver and Tao, 2001</ref>) is suggested in ( <ref type="bibr" target="#b20">Ranzato et al., 2016;</ref><ref type="bibr" target="#b18">Nguyen et al., 2017;</ref>) but not leveraged in <ref type="bibr" target="#b10">(He and Deng, 2012;</ref><ref type="bibr" target="#b26">Shen et al., 2016)</ref>.</p><p>Third, large-scale datasets, especially monolin- gual datasets are shown to significantly improve translation quality <ref type="bibr" target="#b23">(Sennrich et al., 2015a;</ref><ref type="bibr" target="#b37">Xia et al., 2016</ref>) with MLE training, while it remains nearly empty on how to combine RL with monolingual data in NMT.</p><p>In this paper, we try to fulfill these gaps and s- tudy how to practically apply RL to obtain strong NMT systems with quite competitive, even state- of-the-art performance. Several comprehensive s- tudies are conducted on different aspects of RL training to figure out how to: 1) set efficient re- wards; 2) combine MLE and RL objectives with different weights, which aims to stabilize the train- ing procedure; 3) reduce the variance of gradient estimation.</p><p>In addition, given the effectiveness of leveraging monolingual data in improving translation quali- ty, we further propose a new method to combine the strength of both RL training and source/target monolingual data. To the best of our knowledge, this is the first work that tries to explore the power of monolingual data when training NMT model with RL method.</p><p>We obtain some useful findings through the ex- periments on WMT17 Chinese-English (Zh-En), WMT17 English-Chinese (En-Zh) and WMT14 English-German (En-De) translation tasks. For in- stance, multinomial sampling is better than beam search in reward computation, and the combination of RL and monolingual data significantly enhances the NMT model performance. Our main contribu- tions are summarized as follows.</p><p>• We provide the first comprehensive study on different aspects of RL training, such as how to setup reward and baseline reward, on top of quite competitive NMT models.</p><p>• We propose a new method that effectively leverages large-scale monolingual data, from both the source and target side, when training NMT models with RL.</p><p>• Combined with several of our findings and method, we obtain the SOTA translation quali- ty on WMT17 Zh-En translation task, surpass- ing strong baseline (Transformer big model + back translation) by nearly 1.5 BLEU points. Furthermore, on WMT14 En-De and WMT17 En-Zh translation tasks, we can also obtain strong competitive results.</p><p>We hope that our studies and findings will ben- efit the community to better understand and lever- age reinforcement learning for developing strong NMT models, especially in real-world scenarios faced with deep models and large amount of train- ing data (including both parallel and monolin- gual data). Towards this end, we open source all our codes/dataset at https://github.com/ apeterswu/RL4NMT to provide a clear recipe for performance reproduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section, we first introduce the attention- based sequence-to-sequence learning framework for neural machine translation (NMT), and then introduce the basis of applying reinforcement learn- ing to training NMT models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Neural Machine Translation</head><p>Typical NMT models are based on the encoder- decoder framework with attention mechanism. The encoder first maps a source sentence x = (x 1 , x 2 , ..., x n ) to a set of continuous represen- tations z = (z 1 , z 2 , ..., z n ). Given z, the de- coder then generates a target sentence y = (y 1 , y 2 , ..., y m ) of word tokens one by one. At each decoding step t of model training, the probability of generating a token y t is maximized conditioned on x and y &lt;t = (y 1 , ..., y t−1 ). Given N training sentence pairs</p><formula xml:id="formula_0">{x i , y i } N i=1</formula><p>, maximum likelihood es- timation (MLE) is usually adopted to optimize the model, and the training objective is defined as:</p><formula xml:id="formula_1">L mle = N i=1 log p(y i |x i ) = N i=1 m t=1 log p(y i t |y i 1 , ..., y i t−1 , x i ),<label>(1)</label></formula><p>where m is the length of sentence y i . Among all the encoder-decoder models, the re- cently proposed Transformer ( <ref type="bibr" target="#b28">Vaswani et al., 2017)</ref> architecture achieves the best translation quality so far. The main difference between Transformer and previous RNNSearch ( <ref type="bibr" target="#b1">Bahdanau et al., 2015</ref>) or ConvS2S ( <ref type="bibr" target="#b6">Gehring et al., 2017)</ref> is that Transformer relies entirely on self-attention (  to compute representations of source and target side sentences, without using recurrent or convolutional operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training NMT with Reinforcement Learning</head><p>As aforementioned, reinforcement learning (RL) is leveraged to bridge the gap between training and inference of NMT, by directly optimizing the e- valuation measure (e.g., BLEU) at training time. Specifically, NMT model can be viewed as an a- gent, which interacts with the environment (the pre- vious words y &lt;t and the context vector z available at each step t). The parameters of the agent define a policy, i.e., a conditional probability p(y t |x, y &lt;t ). The agent will pick an action , i.e., a candidate word out from the vocabulary, according to the pol- icy. A terminal reward is observed once the agent generates a complete sequencê y. The reward for machine translation is the BLEU ( <ref type="bibr" target="#b19">Papineni et al., 2002</ref>) score, denoted as R(ˆ y, y), which is defined by comparing the generatedˆygeneratedˆ generatedˆy with the ground-truth sentence y. Note that here the reward R(ˆ y, y) is the sentence-level reward, i.e., a scalar for each complete sentencê y. The goal of the RL training is to maximize the expected reward:</p><formula xml:id="formula_2">L rl = N i=1 E ˆ y∼p(ˆ y|x i ) R(ˆ y, y i ) = N i=1ˆy∈Y i=1ˆ i=1ˆy∈Y p(ˆ y|x i )R(ˆ y, y i ),<label>(2)</label></formula><p>where Y is the space of all candidate transla- tion sentences, which is exponentially large due to the large vocabulary size, making it impossi- ble to exactly maximize L rl . In practice, REIN- FORCE (Williams, 1992) is usually leveraged to approximate the above expectation via samplingˆysamplingˆ samplingˆy from the policy p(y|x), leading to the objective as maximizing:</p><formula xml:id="formula_3">ˆ L rl = N i=1 R(ˆ y i , y i ), ˆ y i ∼ p(y|x i ), ∀i ∈ [N ]. (3)</formula><p>Throughout the paper we will use REINFORCE as our policy optimization method for RL training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Strategies for RL Training</head><p>Although training NMT with RL can fill in the gap between training objectives and evaluation metrics, it is not easy to successfully put RL training into practice. A key challenge is that RL methods are highly unstable and inefficient, due to the noise in gradient estimation and reward computation. To our best knowledge, currently there is no consen- sus, or even a systematic study on how to configure different setups for RL training to avoid such prob- lems, especially for training deep NMT models on large scale datasets. We therefore aim to shed light on practical applications of RL for NMT training. For this purpose, we provide a comprehensive re- view of several important methods to stabilize RL training process in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Reward Computation</head><p>It is critical to set up appropriate rewards for RL training, i.e., the R(ˆ y, y) in Eqn. (3). There are two important aspects to consider in configuring the reward R(ˆ y, y): how to sample training instancê y and whether to use reward shaping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generatê</head><p>y There are two strategies to samplê y for computing the BLEU reward R(ˆ y, y). The first one is beam search <ref type="bibr" target="#b27">(Sutskever et al., 2014</ref>), it is a breadth-first search method that maintains a "beam" of the top-K scoring candidates (prefix hypothe- sis sentences) at each generation step. Then, for each candidate sentence in the beam, K most likely words are appended, resulting in a pool of K × K new candidates. Out from this pool, the top-K translations with largest probabilities are selected, and the beam search process continues. The second strategy is multinomial sampling <ref type="bibr" target="#b3">(Chatterjee and Cancedda, 2010)</ref>, which produces each word one by one through multinomial sampling over the mod- el's output distribution. Both sampling strategies terminate the expansion of a candidate sentence when an 'end of sentence' (&lt;EOS&gt;) token is met.</p><p>The choice of different sampling strategies re- flects the exploration-exploitation dilemma. Beam search strategy generates more accuratê y by ex- ploiting the probabilistic space output via curren- t NMT model, while multinomial sampling pays more attention to explore more diverse candidates.</p><p>Whether to Use Reward Shaping From Eqn. (3) we can see that for the entire sequencê y, there is only one terminal reward R(ˆ y, y) available for model training. Note that the agent needs to take tens of actions (with the number depending on the length ofˆyofˆ ofˆy) to generate a complete sentencê y, but only one reward is available for all those actions. Consequently, RL training is inefficient due to the sparsity of rewards, and the model updates each token in the training sentence with the same reward value without distinction. Reward shaping ( <ref type="bibr" target="#b17">Ng et al., 1999</ref>) is a strategy to overcome this shortcom- ing. In reward shaping, intermediate reward at each decoding step t is imposed and denoted as r t (ˆ y t , y). <ref type="bibr" target="#b0">Bahdanau et al. (2017)</ref> sets up the intermediate re- ward as r t (ˆ y t , y) = R(ˆ y 1...t , y) − R(ˆ y 1...t−1 , y), where R(ˆ y 1...t , y) is defined as the BLEU score ofˆyofˆ ofˆy 1...t with respect to y. Note that we have R(ˆ y, y) = m t=1 r t (ˆ y t , y), where m is the length ofˆyofˆ ofˆy. During RL training, the cumulative reward m τ =t r τ (ˆ y τ , y) is used to update the policy at time step t. It is verified that using the shaped reward r t instead of awarding the whole score R(ˆ y, y) does not change the optimal policy ( <ref type="bibr" target="#b17">Ng et al., 1999</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Variance Reduction of Gradient Estimation</head><p>As mentioned before, the REINFORCE algorithm suffers from high variance in gradient estimation, mainly caused by using single samplê y to estimate the expectation. To reduce the variance, <ref type="bibr" target="#b20">Ranzato et al. (2016)</ref> subtracts an average reward from the returned reward at each time step t, and the actual reward used to update the policy is</p><formula xml:id="formula_4">R(ˆ y, y) − ˆ r t ,<label>(4)</label></formula><p>wherê r t is the estimated average reward at step t, named as baseline reward <ref type="bibr" target="#b30">(Weaver and Tao, 2001</ref>). Together with reward shaping, the updated reward becomes m τ =t r τ (ˆ y τ , y) − ˆ r t at step t. Intuitively speaking, a baseline rewardˆrrewardˆ rewardˆr t is es- tablished, which either encourages a word choicêchoicê y t if the induced reward R satisfies R &gt; ˆ r t , or discourages it if R &lt; ˆ r t . Here R is either the terminal reward R(ˆ y, y) or the cumulative reward m τ =t r τ (ˆ y τ , y). Such estimated baseline rewardˆr rewardˆ rewardˆr t is designed to decrease the high variance of the gradient estimator.</p><p>In practice, the baseline rewardˆrrewardˆ rewardˆr t can be ob- tained through different approaches. For exam- ple, one may sample multiple sentences and use the mean terminal reward for these sentences as baseline reward. In our work, we adopt the func- tion learning approach, using simple network (e.g., multi-layer perceptron) to build the learning func- tion, which is the same as used in ( <ref type="bibr" target="#b20">Ranzato et al., 2016;</ref><ref type="bibr" target="#b0">Bahdanau et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Combine MLE and RL Objectives</head><p>The last important strategy we would like to men- tion is the combination of MLE training objective with RL objective, which is assumed to further sta- bilize RL training process ( <ref type="bibr" target="#b13">Li et al., 2017;</ref><ref type="bibr" target="#b34">Wu et al., 2017a)</ref>.</p><p>A simple way is to linearly combine the MLE (Eqn. <ref type="formula" target="#formula_1">(1)</ref>) and RL (Eqn. <ref type="formula" target="#formula_6">(3)</ref>) objectives as follows:</p><formula xml:id="formula_5">L com = α * L mle + (1 − α) * ˆ L rl ,<label>(5)</label></formula><p>where α is the hyperparamter controlling the trade- off between MLE and RL objectives. We will em- pirically evaluate how different values of α impact the final translation accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RL Training with Monolingual Data</head><p>Previous works typically conduct RL training with only bilingual data for NMT. Monolingual data has been proved to be able to significantly improve the performance of NMT systems <ref type="bibr" target="#b23">(Sennrich et al., 2015a;</ref><ref type="bibr" target="#b37">Xia et al., 2016;</ref>. It remains an open problem whether it is possible to combine the benefits of RL training and monolin- gual data such that even more competitive results can be obtained. In this section we provide several solutions for combination and will study them in next section. Note that all the settings discussed in this section are semi-supervised learning, i.e., both bilingual and monolingual data are available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">With Source-Side Monolingual Data</head><p>We first provide a solution to RL training with source-side monolingual data. As shown in Eqn.</p><p>, in RL training we need to calculate the re- ward signal R(ˆ y, y) for each generated sentencêsentencê y, and therefore the reference sentence y seems to be a must-have, which unfortunately is missing for source-side monolingual data. We tackle this challenge via generating pseu- do target reference y by bootstrapping with the model itself. Apparently, for the source-side mono- lingual data, the pseudo target reference y should have good translation quality. Therefore, for each source-side monolingual sentence, we use the N- MT model trained from the bilingual data to beam search a target sentence and treat it as the pseu- do target reference y. AfterwardsˆyAfterwardsˆ Afterwardsˆy is obtained via multinomial sampling to calculate the reward. Although multinomial sampling is usually not as good as sampling via beam search, the combination of beam search (to get the pseudo target reference sentence) and the multinomial sampling (to gener- ate the action sequence of the agent) achieves good exploration-exploitation trade-off, since the pseudo target reference exploits the accuracy of current NMT model whilê y achieves better exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">With Target-Side Monolingual Data</head><p>For a target-side monolingual sentence, its source sentence x is missing, and consequentlyˆyconsequentlyˆ consequentlyˆy is un- available since it is sampled based on x. We tackle this challenge via back translation ( <ref type="bibr" target="#b23">Sennrich et al., 2015a</ref>). We first train a reverse NMT model from the target language to the source language with bilingual data. For each target-side monolingual sentence, using the reverse NMT model, we back translate it to get its pseudo source sentence x. We then pair the target monolingual data and its back- translated sentence as a pseudo bilingual sentence pair, which can be used for RL training in the same way as the genuine bilingual sentence pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">With both Source-Side and Target-Side Monolingual Data</head><p>A natural extension of previous discussions is to combine both the source-side and target-side mono- lingual data for RL training. We consider two com- binations, the sequential method and the unified method. The former one sequentially leverages the source-side and target-side monolingual data for RL training. Specifically, we first train an MLE model using the bilingual data and source-side (or target-side) monolingual data; based on this MLE model, we then use REINFORCE for training with target-side (or source-side) monolingual data. For unified approach, we pack the paired data out from three domains together: the genuine bilingual data, the source monolingual data with its pseudo target references (introduced in subsection 4.1), and the target monolingual data with its back-translated samples (introduced in subsection 4.2). Then we treat the combined data as normal bilingual data on which the NMT model is trained via MLE or RL principles. Our goal is to investigate the model per- formance with different training data and find the best recipe of how to use these data in RL training. More details are introduced in next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we provide a systematic study on aforementioned RL training strategies and the solu- tions of leveraging monolingual data. The RL train- ing strategies are evaluated on bilingual dataset- s from three translation tasks, WMT14 English- German (En-De), WMT17 English-Chinese (En- Zh) and WMT17 Chinese-English (Zh-En), and we further conduct the experiments to leverage mono- lingual data in WMT17 Zh-En translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>For the bilingual datasets, WMT17 (Bojar et al., 2017) En-Zh 1 and WMT17 Zh-En use the same dataset, which contains about 24M sentences pairs, including CWMT Corpus 2017 and UN Parallel</head><p>Corpus V1.0. The Jieba 2 segmenter is used to per- form Chinese word segmentation. We use byte pair encoding (BPE) ( <ref type="bibr" target="#b25">Sennrich et al., 2015b</ref>) to pre- process the source and target sentences, forming source-side and target-side dictionary with 40, 000 and 37, 000 types, respectively. We use the news- dev2017 as the dev set and newstest2017 as the test set. For the WMT14 En-De dataset, it con- tains about 4.5M training pairs, newstest2012 and newstest2013 are concatenated as the dev set and newstest2014 acts as test set. Same as ( <ref type="bibr" target="#b28">Vaswani et al., 2017)</ref>, we also perform BPE to process the En-De dataset, the shared source-target vocabulary contains about 37, 000 tokens. For the monolingual dataset on Zh-En translation task, similar to ( <ref type="bibr" target="#b22">Sennrich et al., 2017)</ref>, the Chinese monolingual data comes from LDC Chinese Gi- gaword (4th edition) and the English monolingual data comes from News Crawl 2016 articles. After preprocessing (e.g., language detection and filter- ing sentences with more than 80 words), we keep 4M Chinese sentences and 7M English sentences.</p><p>We adopt the Transformer model with trans- former big setting as defined in ( <ref type="bibr" target="#b28">Vaswani et al., 2017</ref>) for Zh-En and En-Zh translations, which achieves SOTA translation quality in several oth- er datasets. For En-De translation, we utilize the transformer base v1 setting. These settings are ex- actly same as used in the original paper, except we set the layer prepostprocess dropout for Zh-En and En-Zh translation to be 0.05. The optimizer used for MLE training is Adam ( <ref type="bibr" target="#b12">Kingma and Ba, 2015</ref>) with initial learning rate is 0.1, and we fol- low the same learning rate schedule in ( <ref type="bibr" target="#b28">Vaswani et al., 2017)</ref>. During training, roughly 4, 096 source tokens and 4, 096 target tokens are paired in one mini batch. Each model is trained using 8 NVIDI- A Tesla M40 GPUs. For RL training, the model is initialized with parameters of the MLE model (trained with only bilingual data), and we continue training it with learning rate 0.0001. Same as <ref type="bibr" target="#b0">(Bahdanau et al., 2017)</ref>, to calculate the BLEU reward, we start all n-gram counts from 1 instead of 0 and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Strategy</head><p>En-De En-Zh Zh-En   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results of of RL Training Strategies</head><p>We first evaluate different strategies for RL training, based only on bilingual datasets from previously introduced three translation tasks.</p><p>Reward Computation As reviewed in subsec- tion 3.1, for reward computation, we need to con- sider how to samplê y and whether to use reward shaping.</p><p>The results are shown in <ref type="table" target="#tab_1">Table 1</ref>, where "RL" stands for RL training with the REINFORCE algo- rithm. We also report the performance of the pre- trained NMT model with the MLE loss. From the table, an interesting finding is thatˆythatˆ thatˆy sampled via beam search strategy is worse than that by multi- nomial sampling, with a gap of roughly 0.2-0.3 BLEU points on the test set (with significant test score ρ &lt; 0.05). We therefore conjecture that ex- ploration is more important than exploitation in reward computing: multinomial sampling brings more data diversity to the training of NMT mod- el, while sentences generated by beam search are usually very similar to each other. Furthermore, we find that there is no big difference between the leverage of reward shaping or terminal reward, with only slightly better performance of reward shaping. We therefore use multinomial sampling and reward shaping in later experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Strategy</head><p>En-De En-Zh Zh-En    <ref type="figure">Figure 1</ref>: Results of different weights α to combine MLE and RL objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variance Reduction of Gradient Estimation</head><p>Next we evaluate the strategies for reducing vari- ance of gradient estimation (see section3.2). We want to know whether the baseline reward is nec- essary. To compute the baseline reward, similar to ( <ref type="bibr" target="#b20">Ranzato et al., 2016;</ref><ref type="bibr" target="#b0">Bahdanau et al., 2017)</ref>, we build a two-layer MLP regressor with Relu (Nair and Hinton, 2010) activation units. The function takes the hidden states from decoder as input, and the parameters of the regressor are trained to mini- mize the mean squared loss of Eqn. (4). We first pre-train the baseline function for 20k steps/mini- batches, and then jointly train NMT model (with RL) and the baseline reward function. <ref type="table" target="#tab_3">Table 2</ref> shows that the learning of baseline re- ward does not help RL training. This contradicts with previous observations <ref type="bibr" target="#b20">(Ranzato et al., 2016)</ref>, and seems to suggest that the variance of gradient estimation in NMT is not as large as we expected. The reason might be that the probability mass on the target-side language space induced by the NMT model is highly concentrated, making the sampledˆy sampledˆ sampledˆy representative enough in terms of estimating the expectation. Therefore, for the economic perspec- tive, it is not necessary to add the additional steps of using baseline reward on RL training for NMT.</p><p>Combine MLE and RL Objectives As shown in Eqn. (5), the hyperparameter α controls the trade-off between MLE and RL objectives. For comparison, we set α to be [0, 0.1, 0.3, 0.5, 0.7, 0.9] in our experiments. The results are presented in <ref type="figure">Figure 1</ref>.</p><p>[Data] (Objective) Valid Test <ref type="table">Table 3</ref>: Results with source monolingual data. "B" de- notes bilingual data, "Ms" denotes source-side mono- lingual data, "&amp;" denotes data combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[B] (MLE) 22.32 24.29 [B] (MLE) + [B] (RL) 22.87 25.04 [B] (MLE) + [Ms] (RL) 23.03 25.22 [B &amp; Ms] (MLE) 24.31 25.31 [B &amp; Ms] (MLE) + [B &amp; Ms] (RL) 24.58 25.60</head><p>The results show that combining the MLE ob- jective with the RL objective achieves better per- formance (27.48 for En-De, 34.63 for En-Zh and 25.04 for Zh-En with α = 0.3). This indicates that MLE objective is helpful to stabilize the training and improve the model performance, as we expect- ed. However, further increasing α does not bring more gain. The best trade-off between MLE and RL objectives in our experiment is α = 0.3. There- fore, we set α = 0.3 in the following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results of RL Training with Monolingual Data</head><p>In this subsection, we report the results on both valid and test set of RL training using bilingual and monolingual data in Zh-En translation. From <ref type="table">Table 3</ref> to <ref type="table">Table 6</ref>, "RL" denotes the model trained with RL using multinomial sampling, reward shap- ing, no baseline reward, and combined objective, based on the observations in the last subsection. "B" denotes bilingual data, "Ms" denotes source- side monolingual data and "Mt" denotes target-side monolingual data, "&amp;" denotes data combination.</p><p>With Source-Side Monolingual Data As dis- cussed before, we use beam search with beam width 4 to sample the pseudo target sentence y for each monolingual sentence x. We consider sev- eral settings for RL training: 1) only source-side monolingual data; 2) the combination of bilingual and source-side monolingual data. We first train an MLE model using the augmented dataset com- bining the genuine bilingual data with the pseudo bilingual data generated from the monolingual da- ta, and then perform RL training on this combined dataset. The results are shown in <ref type="table">Table 3</ref>.</p><p>With Target-Side Monolingual Data For target-side monolingual data, we first pre-train a translation model from English to Chinese 4 , and use it to back translate target-side monolingual <ref type="bibr">4</ref> The BLEU score of the En-Zh model is 34.12.</p><p>[Data] (Objective) Valid Test <ref type="table">Table 4</ref>: Results with target monolingual data. "B" de- notes bilingual data, "Mt" denotes target-side monolin- gual data, "&amp;" denotes data combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[B] (MLE) 22.32 24.29 [B] (MLE) + [B] (RL) 22.87 25.04 [B] (MLE) + [Mt] (RL) 22.96 25.15 [B &amp; Mt] (MLE) 24.14 25.24 [B &amp; Mt] (MLE) + [B &amp; Mt] (RL) 24.41 25.58</head><p>[  <ref type="table" target="#tab_6">Table 5</ref>: Results of sequential approach for monolin- gual data. "B" denotes bilingual data, "Ms" denotes source-side monolingual data and "Mt" denotes target- side monolingual data, "&amp;" denotes data combination.</p><p>[  <ref type="table">Table 6</ref>: Results of unified approach for monolingual data. "+" means to initialize the RL model using above MLE model, which is trained on the combination of bilingual data, source-side monolingual data and target- side monolingual data.</p><p>sentence y to get pseudo source sentence x. Similarly, we consider several settings for RL training: 1) only target-side monolingual data; 2) the combination of bilingual data and target-side monolingual data. We train an MLE model using both the genuine and the generated pseudo bilingual data, and then perform RL training on this data. The results are presented in <ref type="table">Table 4</ref>.</p><p>From <ref type="table">Table 3</ref> and 4, we have several observa- tions. First, monolingual data helps RL training, improving BLEU score from 25.04 to 25.22 (ρ &lt; 0.05) in <ref type="table">Table 3</ref>. Second, when we only add mono- lingual data for RL training, the model achieves similar performance compared to MLE training with bilingual and monolingual data (e.g., 25.15 vs. 25.24 (ρ &lt; 0.05) in <ref type="table">Table 4</ref>).</p><p>With both Source-Side and Target-Side Mono- lingual Data We have two approaches to use both source-side and target-side monolingual da- ta, as described in subsection 4.3. The results are reported in <ref type="table" target="#tab_6">Table 5 and Table 6</ref>.</p><p>From  tial training of monolingual data can benefit the model performance. Taking the last three rows as an example, the BLEU score of the MLE model trained on the combination of bilingual data and target-side monolingual data is 25.24; based on this model, RL training using the source-side monolin- gual data further improves the model performance by 0.7 (ρ &lt; 0.01) BLEU points. From <ref type="table">Table 6</ref>, we can observe on top of a quite strong MLE baseline <ref type="bibr">(26.13)</ref>, through the unified RL training, we can still improve the test set by 0.6 points to 26.73 (ρ &lt; 0.01), which shows the effectiveness of combining source/target monolingual data and reinforcement learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Comparison with Other Models</head><p>At last, as a summary of our empirical result- s, we compare several representataive end-to-end NMT systems to our work in <ref type="table" target="#tab_7">Table 7</ref>, which includes the Transformer ( <ref type="bibr" target="#b28">Vaswani et al., 2017)</ref> model, with/without back-translation ( <ref type="bibr" target="#b23">Sennrich et al., 2015a</ref>) and the best NMT system in WMT17 Chinese-English translation challenge 5 (SougouKnowing-ensemble). The results clear- ly show that after combing both source-side and target-side monolingual data with RL training, we obtain the state-of-the-art BLEU score 26.73, even surpassing the best ensemble model in WMT17 Zh-En translation challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Our work is mainly related with the literature of us- ing reinforcement learning to directly optimize the evaluation measure for neural machine translation. Several representative works are (Ranzato et al., <ref type="bibr">5</ref> http://matrix.statmt.org/matrix/ systems_list/1878 2016; <ref type="bibr" target="#b26">Shen et al., 2016;</ref><ref type="bibr" target="#b0">Bahdanau et al., 2017</ref>). In ( <ref type="bibr" target="#b20">Ranzato et al., 2016)</ref>, the authors propose to train a neural translation model with the objective grad- ually shifting from maximizing token-level likeli- hood to optimizing the sentence-level BLEU score. <ref type="bibr" target="#b26">Shen et al. (2016)</ref> proposes to adopt minimum risk training <ref type="bibr" target="#b7">(Goel and Byrne, 2000</ref>) to minimize the task specific expected loss (i.e., induced by BLEU score) on NMT training data. Instead of the RE- INFORCE <ref type="bibr" target="#b31">(Williams, 1992)</ref> algorithm used in the above two works, <ref type="bibr" target="#b0">Bahdanau et al. (2017)</ref> further optimizes the policy by actor-critic algorithm.  introduces a simple RL based method to optimize the stacked LSTM model for NMT, achieving better BLEU scores on English-French translation but not on English-German. <ref type="bibr" target="#b5">Edunov et al. (2017)</ref> presents a comparative study of sev- eral classical structural prediction losses for NMT model, which also includes sequence-level loss but not exactly the same as RL.</p><p>Our work is also related with the research works that leverage monolingual data for improving N- MT models <ref type="bibr" target="#b39">(Zhang and Zong, 2016;</ref><ref type="bibr" target="#b23">Sennrich et al., 2015a;</ref><ref type="bibr" target="#b29">Wang et al., 2018;</ref><ref type="bibr" target="#b37">Xia et al., 2016;</ref>. <ref type="bibr" target="#b39">Zhang and Zong (2016)</ref> exploits the source-side monolingual data in NMT. <ref type="bibr" target="#b23">Sennrich et al. (2015a)</ref> proposes back-translation method to leverage target-side monolingual data for NMT. <ref type="bibr" target="#b37">Xia et al. (2016)</ref> formulates the machine transla- tion as a communication game, which leverages the power of two directional translation models and source/target monolingual data.  proposes a similar semi-supervised approach. How- ever, none of these works have explored the power of monolingual data in the context of training NMT model with reinforcement learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we presented a study of how to ef- fectively train NMT models using reinforcement learning. Different RL strategies were evaluated in German-English, English-Chinese and Chinese- English translation tasks on large-scale bilingual datasets. We found that (1) multinomial sampling is better than beam search, (2) several previous tricks such as reward shaping and baseline reward does not make significant difference, and (3) the combination of the MLE and RL objectives is im- portant. In addition, we explored the source/target monolingual data for RL training. By combing the power of RL and monolingual data, we achieve the state-of-the-art BLEU score on WMT17 Chinese- English translation task. We hope that our study and results can benefit the community and bring some insights on how to train deep NMT models with reinforcement learning and big data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>MLE</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>RL</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Results of different strategies for reward com-
putation. 'beam' refers to 'beam search and 'multino-
mial' to 'multinomial sampling'. While generatingˆygeneratingˆ generatingˆy 
through beam search, we use width 4. 'shaping' refers 
to using reward shaping and 'terminal' refers not. 

multiply the resulting score by the length of the 
target reference sentence. For inference, we use 
beam search with width 6. We run each setting 
for at least 5 times and report the averaged case 
sensitive BLEU scores 3 (Papineni et al., 2002) on 
test set. The test set BLEU is chosen via the best 
configuration based on the validation set. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results of variance reduction of gradient esti-
mation. 

= 0 
= 0.1 
= 0.3 
= 0.5 
= 0.7 
= 0.9 
24 

26 

28 

30 

32 

34 

36 

BLEU Score 

27.23 
27.28 
27.48 
27.37 
27.25 
27.20 

34.47 
34.50 
34.63 
34.56 
34.44 
34.40 

24.72 
24.89 
25.04 
24.87 
24.71 
24.65 

En-De 
En-Zh 
Zh-En 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 , we can observe that the sequen-</head><label>5</label><figDesc></figDesc><table>System 
Architecture 
BLEU 
Existing end-to-end NMT systems 
Vaswani et al. (2017) 
Transformer 
24.29 
Sennrich et al. (2015a) 
Transformer + Target Monolingual Data (i.e., back translation) 
25.24 
SougouKnowing 
Stacked LSTM model + Reranking 
24.00 
SougouKnowing-ensemble Stacked LSTM model + Reranking + Ensemble 
26.40 
Our end-to-end NMT 
this work 
Transformer + RL 
25.04 
Transformer + Source Monolingual Data 
25.31 
Transformer + Source Monolingual Data + RL 
25.60 
Transformer + Target Monolingual Data 
25.24 
Transformer + Target Monolingual Data + RL 
25.58 
Transformer + Source &amp; Target Monolingual Data 
26.13 
Transformer + Source &amp; Target Monolingual Data + RL 
26.73 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Comparisons of different competitive end-to-end NMT systems. SougouKnowing results come from 
http://matrix.statmt.org/matrix/systems_list/1878. 

</table></figure>

			<note place="foot" n="1"> http://www.statmt.org/wmt17/ translation-task.html 2 https://github.com/fxsjy/jieba</note>

			<note place="foot" n="3"> Calculated by SacréBLEU toolkit, which produces exactly the same evaluation result as that in WMT17 Zh-En campaign. https://github.com/awslabs/sockeye/ tree/master/contrib/sacrebleu</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An actor-critic algorithm for sequence prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philemon</forename><surname>Brakel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Findings of the 2017 conference on machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Machine Translation</title>
		<meeting>the Second Conference on Machine Translation<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="169" to="214" />
		</imprint>
	</monogr>
	<note>Shared Task Papers</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Minimum error rate training by sampling the translation lattice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samidh</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Cancedda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="606" to="615" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Semisupervised learning for neural machine translation. meeting of the association for computational linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1965" to="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Classical structured prediction losses for sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann N</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th international conference on machine learning</title>
		<meeting>the 34th international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Minimum bayes-risk automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaibhava</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="135" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Achieving human parity on automatic chinese to english news translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Aue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Chowdhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05567</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Decoding with value networks for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieyan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="178" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Maximum expected bleu training of phrase and lexicon translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="292" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning that matters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riashat</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Meger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirthy-Second AAAI Conference On Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adversarial learning for neural dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cicero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Playing atari with deep reinforcement learning. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>workshop</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th international conference on machine learning</title>
		<meeting>the 27th international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Policy invariance under reward transformations: Theory and application to reward shaping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daishi</forename><surname>Andrew Y Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="278" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Reinforcement learning for bandit neural machine translation with simulated human feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boydgraber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaremba</surname></persName>
		</author>
		<title level="m">Sequence level training with recurrent neural networks. Fourth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Maximum likelihood estimation. Encyclopedia of statistical sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">W</forename><surname>Scholz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The university of edinburgh&apos;s neural mt systems for wmt17</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Currey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Machine Translation</title>
		<meeting>the Second Conference on Machine Translation</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="389" to="399" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th</title>
		<meeting>the 54th</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Minimum risk training for neural machine translation. meeting of the association for computational linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1683" to="1692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dual transfer learning for neural machine translation with marginal distribution regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The optimal reward baseline for gradient-based reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lex</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence</title>
		<meeting>the Seventeenth conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="538" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reinforcement Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Beyond error propagation in neural machine translation: Characteristics of language also matter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhuang</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Word attention for sequence to sequence text understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhuang</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieyan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Adversarial neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhuang</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno>arX- iv:1704.06933</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhuang</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieyan</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Sequence prediction with unlabeled data by reward function learning. IJCAI-17</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3098" to="3104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Dual learning for machine translation. neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieyan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiying</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="820" to="828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deliberation networks: Sequence generation beyond one-pass decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1784" to="1794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Exploiting source-side monolingual data in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
