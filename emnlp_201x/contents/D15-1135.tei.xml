<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatically Solving Number Word Problems by Semantic Parsing and Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuehui</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Rui</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Automatically Solving Number Word Problems by Semantic Parsing and Reasoning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents a semantic parsing and reasoning approach to automatically solving math word problems. A new meaning representation language is designed to bridge natural language text and math expressions. A CFG parser is implemented based on 9,600 semi-automatically created grammar rules. We conduct experiments on a test set of over 1,500 number word problems (i.e., verbally expressed number problems) and yield 95.4% precision and 60.2% recall.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Computers, since their creation, have exceeded human beings in (speed and accuracy of) mathe- matical calculation. However, it is still a big chal- lenge nowadays to design algorithms to automat- ically solve even primary-school-level math word problems (i.e., math problems described in natural language).</p><p>Efforts to automatically solve math word prob- lems date back to the 1960s <ref type="bibr">(Bobrow, 1964a, b)</ref>. Previous work on this topic falls into two catego- ries: symbolic approaches and statistical learning methods. In symbolic approaches <ref type="bibr">(Bobrow, 1964a, b;</ref><ref type="bibr" target="#b11">Charniak, 1968;</ref><ref type="bibr" target="#b1">Bakman, 2007;</ref><ref type="bibr" target="#b30">Liguda &amp; Pfeiffer, 2012)</ref>, math problem sentences are transformed to certain structures by pattern matching or verb categorization. Equations are then derived from the structures. Statistical learn- ing methods are employed in two recent papers <ref type="bibr" target="#b23">Hosseini et al., 2014</ref>).</p><p>Most (if not all) previous symbolic approaches suffer from two major shortcomings. First, natural language (NL) sentences are processed by simply applying pattern matching and/or transformation rules in an ad-hoc manner (refer to the related work section for more details). Second, surpris- ingly, they seldom report evaluation results about the effectiveness of the methods (except for some examples for demonstration purposes). For the small percentage of work with evaluation results available, it is unclear whether the patterns and rules are specially designed for specific sentences in a test set. In this paper, we present a computer system called SigmaDolphin which automatically solves math word problems by semantic parsing and rea- soning. We design a meaning representation lan- guage called DOL (abbreviation of dolphin lan- guage) as the structured semantic representation of NL text. A semantic parser is implemented to transform math problem text into DOL trees. A reasoning module is included to derive math ex- pressions from DOL trees and to calculate final answers. Our approach falls into the symbolic cat- egory, but makes improvements over previous symbolic methods in the following ways, ______________________________________ * Work done while this author was an intern at Microsoft Research 1). One number is 16 more than another. If the smaller number is subtracted from 2/3 of the larger, the result is 1/4 of the sum of the two numbers. Find the numbers. 2). Nine plus the sum of an even integer and its square is 3 raised to the power of 4. What is the num- ber? 3). The tens digit of a two-digit number is 3 more than the units digit. If the number is 8 more than 6 times the sum of the digits, find the number. 4). If the first and third of three consecutive even in- tegers are added, the result is 12 less than three times the second integer. Find the integers.</p><p>1) We introduce a systematic way of parsing NL text, based on context-free grammar (CFG).</p><p>2) Evaluation is enhanced in terms of both data set construction and evaluation mechanisms. We split the problem set into a development set (called dev set) and a test set. Only the dev set is accessible during our algorithm design (especially in designing CFG rules and in implementing the parsing algorithm), which avoids over-tuning to- wards the test set. Three metrics (precision, recall, and F1) are employed to measure system perfor- mance from multiple perspectives, in contrast to all previous work (including the statistical ones) which only measures accuracy.</p><p>We target, in experiments, a subtype of word problems: number word problems (i.e., verbally expressed number problems, as shown in <ref type="figure" target="#fig_0">Figure  1</ref>). We hope to extend our techniques to handle general math word problems in the future.</p><p>We build a test set of over 1,500 problems and make a quantitative comparison with state-of-the- art statistical methods. Evaluation results show that our approach significantly outperforms base- line methods on our test set. Our system yields an extremely high precision of 95.4% and a reasona- ble recall of 60.2%, which shows promising appli- cation of our system in precision-critical situa- tions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Math word problem solving</head><p>Most previous work on automatic word problem solving is symbolic. STUDENT <ref type="bibr">(Bobrow, 1964a, b)</ref> handles algebraic problems by first transform- ing NL sentences into kernel sentences using a small set of transformation patterns. The kernel sentences are then transformed to math expres- sions by recursive use of pattern matching. CARPS <ref type="bibr" target="#b11">(Charniak, 1968</ref><ref type="bibr" target="#b12">(Charniak, , 1969</ref>) uses a similar ap- proach to solve English rate problems. The major difference is the introduction of a tree structure as the internal representation of the information gathered for one object. <ref type="bibr" target="#b30">Liguda &amp; Pfeiffer (2012)</ref> propose modeling math word problems with aug- mented semantic networks. Addition/subtraction problems are studied most in early research <ref type="bibr" target="#b8">(Briars &amp; Larkin, 1984;</ref><ref type="bibr" target="#b20">Fletcher, 1985;</ref><ref type="bibr" target="#b16">Dellarosa, 1986;</ref><ref type="bibr" target="#b1">Bakman, 2007;</ref><ref type="bibr" target="#b31">Ma et al., 2010)</ref>. Please re- fer to <ref type="bibr" target="#b33">Mukherjee &amp; Garain (2008)</ref> for a review of symbolic approaches before 2008.</p><p>No empirical evaluation results are reported in most of the above work. Almost all of these ap- proaches parse NL text by simply applying pattern matching rules in an ad-hoc manner. For example, as mentioned in <ref type="bibr" target="#b7">Bobrow (1964b)</ref>, due to the pat- tern "($, AND $)", the system would incorrectly divide "Tom has 2 apples, 3 bananas, and 4 pears." into two "sentences": "Tom has 2 apples, 3 bananas." and "4 pears."</p><p>WolframAlpha 1 shows some examples 2 of au- tomatically solving elementary math word prob- lems, with technique details unknown to the gen- eral public. Other examples on the web site demonstrate a large coverage of short phrase que- ries on math and other domains. By randomly se- lecting problems from our dataset and manually testing on their web site, we find that it fails to handle most problems in our problem collection.</p><p>Statistical learning methods have been pro- posed recently in two papers: <ref type="bibr" target="#b23">Hosseini et al. (2014)</ref> solve single step or multi-step homoge- nous addition and subtraction problems by learn- ing verb categories from the training data.  can solve a wide range of word problems, given that the equation systems and so- lutions are attached to problems in the training set. The method of the latter paper (referred to as KAZB henceforth) is used as one of our baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semantic parsing</head><p>There has been much work on analyzing the se- mantic structure of NL strings. In semantic role labeling and frame-semantic parsing <ref type="bibr" target="#b21">(Gildea &amp; Jurafsky, 2002;</ref><ref type="bibr" target="#b10">Carreras &amp; Marquez, 2004;</ref><ref type="bibr" target="#b32">Marquez et al., 2008;</ref><ref type="bibr" target="#b2">Baker et al., 2007;</ref><ref type="bibr" target="#b15">Das et al., 2014</ref>), predicate-argument structures are dis- covered from text as their shallow semantic repre- sentation. In math problem solving, we need a deeper and richer semantic representation from which to facilitate the deriving of math expres- sions.</p><p>Another type of semantic parsing work <ref type="bibr" target="#b39">(Zelle &amp; Mooney, 1996;</ref><ref type="bibr" target="#b40">Zettlemoyer &amp; Collins, 2005;</ref><ref type="bibr" target="#b41">Zettlemoyer &amp; Collins, 2007;</ref><ref type="bibr" target="#b38">Wong &amp; Mooney, 2007;</ref><ref type="bibr" target="#b9">Cai &amp; Yates, 2013;</ref><ref type="bibr" target="#b4">Berant et al., 2013;</ref><ref type="bibr" target="#b28">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b5">Berant &amp; Liang, 2014</ref>) maps NL text into logical forms by supervised or semi-supervised learning. Some of them are based on or related to combinatory categorial grammar (CCG) <ref type="bibr" target="#b37">(Steedman, 2000</ref>). Abstract Meaning Rep- resentation (AMR) ( <ref type="bibr" target="#b3">Banarescu et al., 2013</ref>) keeps richer semantic information than CCG and logical forms. In Section 3.1.4, we discuss the differences between DOL, AMR, and CCG, and explain why we choose DOL as the meaning representation language for math problem solving.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>Consider the first problem in <ref type="figure" target="#fig_0">Figure 1 (</ref> To automatically solve this problem, the com- puter system needs to figure out, somehow, that 1) two numbers x, y are demanded, and 2) they sat- isfy the equations below,</p><formula xml:id="formula_0">x = 16 + y (2/3)x -y = (x + y) / 4 (1) (2)</formula><p>To achieve this, reasoning must be performed based on common sense knowledge and the infor- mation provided by the source problem. Given the difficulty of performing reasoning directly on un- structured and ambiguous natural language text, it is reasonable to transform the source text into a structured, less ambiguous representation.</p><p>Our approach contains three modules: 1) A meaning representation language called DOL newly designed by us as the semantic representation of natural language text. 2) A semantic parser which transforms natu- ral language sentences of a math problem into DOL representation. 3) A reasoning module to derive math expres- sions from DOL representation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DOL: Meaning representation language</head><p>Every meaningful piece of NL text is represented in DOL as a semantic tree of various node types. <ref type="figure" target="#fig_1">Figure 2</ref> shows the DOL representation of the sec- ond problem of <ref type="figure" target="#fig_0">Figure 1</ref>. It contains two semantic trees, corresponding to the two sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Node types</head><p>Node types of a DOL tree include constants, clas- ses, and functions. Each interim node of a tree is always a function; and each leaf node can be a constant, a class, or a zero-argument function. Constants in DOL refer to specific objects in the world. A constant can be a number (e.g., 3.57), a lexical string (like "New York"), or an entity.</p><p>Classes: An entity class refers to a category of entities sharing common semantic properties. For example, all cities are represented by the class lo- cation.city; and math.number is a class for all numbers. It is clear that,</p><p>3.14159 ∈ math.number city.new_york ∈ location.city A class C1 is a sub-class (denoted by ⊆) of an- other class C2 if and only if every instance of C1 are in C2. The following holds according to com- mon sense knowledge, math.number ⊆ math.expression person.pianist ⊆ person.performer Template classes are classes with one or more parameters, just like template classes in C++. The most important template class in DOL is t.list&lt;c,m,n&gt; where c is a class; m and n are integers. Each in- stance of this class is a list containing at least m and at most n elements of type c. For example, each instance of t.list&lt;math.number,2,+∞&gt; is a list containing at least 2 numbers.</p><p>Functions are used in DOL as the major way to form larger language units from smaller ones. A function is comprised of a name, a list of core arguments, and a return type. DOL enables func- tion overloading (again borrowing ideas from pro- gramming languages). That is, one function name can have multiple core-argument specifications. Below are two specifications for fn.math.sum (which appears in the example of <ref type="figure" target="#fig_1">Figure 2</ref> Here "$1: math.expression" means the first ar- gument has type math.expression.</p><p>DOL supports three kinds of functions: noun functions, verb functions, and modifier functions.</p><p>Noun functions map entities to their properties or to other entities having specific relations with the argument(s). For example, nf.math.sum maps math expressions to their sum. Noun functions are used to represent noun phrases in natural language text. More noun functions are shown in <ref type="table">Table 1</ref>.</p><p>Among all noun functions, nf.list has a special important position due to its high frequency in DOL trees. The function is specified below, nf.list $1: class; $2: math.number return type: t.list&lt;$1&gt; return value: An entity list with cardinality $2 and element type $1</p><p>For example nf.list(math.number,5) returns a list containing 5 elements of type math.number. It is the semantic representation of "five numbers".</p><p>Pronoun functions are special zero-argument noun functions. Examples are nf.it (representing an already-mentioned entity or event) and nf.what (denoting an unknown entity or entity list).</p><p>Verb functions act as sentences or sub-sen- tences in DOL. As an example, vf.be.equ (in <ref type="figure">Fig- ure</ref>  In addition to core arguments ($1, $2, etc.), many functions can take additional extended ar- guments as their modifiers. Our last function type called modifier functions often take the role of ex- tended arguments, to modify noun functions, verb functions, or other modifier functions. Modifier functions are used in DOL as the semantic repre- sentation of adjectives, adverb phrases (including conjunctive adverb phrases), and prepositional phrases in natural languages. In the example of <ref type="figure" target="#fig_1">Figure 2</ref>, the function mf.number.even modifies the noun function nf.list as its extended argument.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Entity variables</head><p>Variables are assigned to DOL sub-trees for indi- cating the co-reference of sub-trees to entities and for facilitating the construction of logical forms and math expressions from DOL. In <ref type="figure" target="#fig_1">Figure 2</ref>, the same variable v1 (meaning a variable with ID 1) is assigned to two sub-trees in the first sentence and one sub-tree in the second sentence. Thus the three sub-trees refer to the same entity. Indicating the property of be- ing an even number <ref type="table">Table 1</ref>: Example DOL functions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Function</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Key features of DOL</head><p>DOL has some nice characteristics that are critical to building a high-precision math problem solving system. That is why we invent DOL as our mean- ing representation language instead of employing an existing one.</p><p>First, DOL is a strongly typed language. Every function has clearly defined argument types and a return type. A valid DOL tree must satisfy the type-compatibility property: For example, in <ref type="figure" target="#fig_1">Figure 2</ref>, the return type of nf.math.power is math.expression, which matches the second argument of vf.be.equ. However, the following two trees (yielded from the correspond- ing pieces of text) are invalid because they do not satisfy type-compatibility. Second, we maintain in DOL an open-domain type system. The type system contains over 1000 manually verified classes and more automatically generated ones (refer to Section 3.2.1 for more de- tails). Such a comprehensive type system makes it possible to define various kinds of functions and to perform type-compatibility checking. In con- trast, most previous semantic languages have at most 100+ types at the grammar level. In addition, by introducing template classes, we avoid main- taining a lot of potentially duplicate types and re- duce the type system management efforts. To the best of our knowledge, template classes are not available in other semantic representation lan- guages.</p><p>Third, DOL has built-in data structures like t.list and nf.list which greatly facilitate both func- tion declaration and text representation (espe- cially math text representation). For example, the two variants of nf.math.sum (refer to Section 3.</p><note type="other">1.1 for their specifications) are enough to represent the following English phrases: 3 plus 5  nf.math.sum!1(3, 5) sum of 3, 5, 7, and 9  nf.math.sum!2(nf.list(3, 5, 7, 9)) sum of ten thousand numbers  nf.math.sum!2(nf.list(math.number,10000))</note><p>Without t.list or nf.list, we would have to define a lot of overloaded functions for nf.math.sum to deal with different numbers of addends.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Comparing with other languages</head><p>Among all meaning representation languages, AMR ( <ref type="bibr" target="#b3">Banarescu et al., 2013</ref>) is most similar to DOL. Their major differences are: First, they use very different mechanisms to represent noun phrases. In AMR, a sentence (e.g., "the boy de- stroyed the room") and a noun phrase (e.g., "the boy's destruction of the room") can have the same representation. While in DOL, a sentence is al- ways represented by a verb function; and a noun phrase is always a noun function or a constant. Second, DOL has a larger type system and is stricter in type compatibility checking. Third, DOL has template classes and built-in data struc- tures like t.list and nf.list to facilitate the represen- tation of math concepts.</p><p>CCG <ref type="bibr" target="#b37">(Steedman, 2000</ref>) provides a transparent interface between syntax and semantics. In CCG, semantic information is defined on words (e.g., "λx.odd(x)" for "odd" and "λx.number(x)" for "number"). In contrast, DOL explicitly connects NL text patterns to semantic elements. For exam- ple, as shown in <ref type="table">Table 2</ref> (Section 3.2.1), one CFG grammar rule connects pattern "{$1} raised to the power of {$2}" to function nf.math.power.</p><p>Logical forms are another way of meaning rep- resentation. We choose not to transform NL text directly to logical forms for two reasons: On one hand, state-of-the-art methods for mapping NL text into logical forms typically target short, one- sentence queries in restricted domains. However, many math word problems are long and contain multiple sentences. On the other hand, variable-id assignment is a big issue in direct logical form construction for many math problems. Let's use the following problem (i.e., the first problem of <ref type="figure" target="#fig_0">Figure 1</ref>) to illustrate,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>One number is 16 more than another. If the smaller number is subtracted from 2/3 of the larger, the result is 1/4 of the sum of the two numbers. Find the numbers.</head><p>For this problem, it is difficult to determine whether "the smaller number" refers to "one num- ber" or "another" in directly constructing logical forms. It is therefore a challenge to construct a correct logical form for such kinds of problems.</p><p>Our solution to the above challenge is assigning a new variable ID (which is different from the IDs of "one number" and "another") and to delay the final variable-ID assignment to the reasoning stage. To enable this mechanism, the meaning representation language should support a lazy var- iable ID assignment and keep as much infor- mation (e.g., determiners, plurals, modifiers) from the noun phrases as possible. DOL is a language that always keeps the structure information of phrases, whether or not it has been assigned a var- iable ID.</p><p>In summary, compared with other languages, DOL has some unique features which make it more suitable for our math problem solving sce- nario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Semantic Parsing</head><p>Our parsing algorithm is based on context-free grammar (CFG) <ref type="bibr" target="#b13">(Chomsky, 1956;</ref><ref type="bibr" target="#b0">Backus, 1959;</ref><ref type="bibr" target="#b24">Jurafsky &amp; Martin, 2000</ref>), a commonly used mathematical system for modeling constituent structure in natural languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">CFG for connecting DOL and NL</head><p>The core part of a CFG is the set of grammar rules. Example English grammar rules for build- ing syntactic parsers include "S → NP VP", "NP → CD | DT NN | NP PP", etc. <ref type="table">Table 2</ref> shows some example CFG rules in our system for mapping DOL nodes to natural language word sequences. The left side of each rule is a DOL element (a function, class, or constant); and the right side is a sequence of words and arguments. The grammar rules are consumed by our parser for building DOL trees from NL text.</p><p>So far there are 9,600 grammar rules in our sys- tem. For every DOL node type, the lexicon and grammar rules are constructed together in a semi- automatic way. Math-related classes, functions, and constants and their grammar rules are manu- ally built by referring to text books and online tu-torials. About 35 classes and 200 functions are ob- tained in this way. Additional instances of each element type are constructed in the ways below.</p><p>Classes: Additional classes and grammar rules are obtained from two data sources: Freebase 3 types, and automatically extracted lexical seman- tic data. By treating Freebase types as DOL clas- ses and the mapping from types to lexical names as grammar rules, we get the first version of gram- mar for classes. To improve coverage, we run a term peer similarity and hypernym extraction al- gorithm <ref type="bibr" target="#b22">(Hearst, 1992;</ref><ref type="bibr" target="#b36">Shi et al., 2010;</ref><ref type="bibr" target="#b42">Zhang et al., 2011</ref>) on a web snapshot of 3 billion pages, and get a peer-similarity graph and a collection of is-a pairs. An is-a pair example is <ref type="bibr">(Megan Fox, actress)</ref>, where "Megan Fox" and "actress" are in- stance and type names respectively. In our peer similarity graph, "Megan Fox" and "Britney Spears" have a high similarity score. The peer similarity graph is used to clean the is-a data col- lection (with the idea that peer terms often share some common type names). Given the cleaned is- a data, we sort the type names by weight and man- ually create classes for top-1000 type names. For example, create a class person.actress and add a grammar rule "person.actress → actress". For the other 2000 type names in the top 3000, we create classes and rules automatically, in the form of "class.TN → TN", where TN is a type name. For example, create rule "class.succulent → succu- lent" for name "succulent".  <ref type="table">Table 2</ref>: Example grammar for connecting DOL and NL Functions: Additional noun functions are auto- matically created from Freebase properties and at- tribute extraction results ( <ref type="bibr" target="#b34">Pasca et al., 2006;</ref><ref type="bibr" target="#b17">Durme et al., 2008)</ref>, using a similar procedure with creating classes from Freebase types and is- a extraction results. We have over 50 manually defined math-related verb functions. Our future plan is automatically generating verb functions from databases like PropBank <ref type="bibr" target="#b26">(Kingsbury &amp; Palmer, 2002</ref>), FrameNet ( <ref type="bibr" target="#b19">Fillmore et al., 2003)</ref>, and VerbNet 4 ( <ref type="bibr" target="#b35">Schuler, 2005)</ref>. Additional modi- fier functions are automatically created from an English adjective and adverb list, in the form of "mf.adj.TN → TN" and "mf.adv.TN → TN" where TN is the name of an adjective or adverb.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.2 Parsing</head><p>Parsing for CFG is a well-studied topic with lots of algorithms invented <ref type="bibr" target="#b25">(Kasami, 1965;</ref><ref type="bibr" target="#b18">Earley, 1970)</ref>. The core idea behind almost all the algo- rithms is exploiting dynamic programming to achieve efficient search through the space of pos- sible parse trees. For syntactic parsing, a well- known serious problem is ambiguity: the appear- ance of many syntactically correct but semanti- cally unreasonable parse trees. Modern syntactic parsers reply on statistical information to reduce vf.be.equ ambiguity. They are often based on probabilistic CFGs (PCFGs) or probabilistic lexicalized CFGs trained on hand-labeled TreeBanks.</p><p>With the new set of DOL-NL grammar rules <ref type="table">(examples in Table 2</ref>) and the type-compatibility property (Section 3.1.3), ambiguity can hopefully be greatly reduced, because semantically unrea- sonable parsing often results in invalid DOL trees.</p><p>We implement a top-down parser for our new CFG of Section 3.2.1, following the Earley algo- rithm <ref type="bibr" target="#b18">(Earley, 1970)</ref>. No probabilistic information is attached in the grammar rules because no Tree- banks are available for learning statistical proba- bilities for the new CFG. <ref type="figure" target="#fig_5">Figure 3</ref> shows the parse tree returned by our parser when processing a sim- ple sentence. The DOL tree can be obtained by re- moving the dotted lines (corresponding to the non-argument part in the right side of the grammar rules). A traditional syntactic parse tree is shown in <ref type="figure" target="#fig_6">Figure 4</ref> for reference.</p><p>During parsing, a score is calculated for each DOL node. The score of a tree T is the weighted average of the scores of its sub-trees,</p><formula xml:id="formula_1">í µí±º(í µí±») = ∑ í µí±³(í µí±» í µí² ) • í µí±º(í µí±» í µí² ) í µí² í µí²=í µí¿ ∑ í µí±³(í µí±» í µí² ) í µí² í µí²=í µí¿ • í µí²(í µí±»)<label>(3)</label></formula><p>where í µí± í µí± is a sub-tree, and í µí°¿(í µí± í µí± ) is the number of words to which the sub-tree corresponds in the original text. If the type-compatibility property for T is satisfied, í µí±(í µí±)=1; otherwise í µí±(í µí±)=0. All leaf nodes are assigned a score of 1.0, ex- cept for pure lexical string nodes (which are used as named entity names). The score of a lexical string node is set to 1/(1+í µí¼n), where n is the num- ber of words in the node, and í µí¼ (=0.2 in experi- ments) is a parameter whose value does not have much impact on parsing results. Such a score function encourages interpreting a word sequence with our grammar than treating it as an entity name.</p><p>Among all candidate DOL trees yielded during parsing, we return the one with the highest score as the final parsing result. A null tree is returned if the highest score is zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Reasoning</head><p>The reasoning module is responsible for deriving math expressions from DOL trees and calculating problem answers by solving equation systems. Math expressions have different definitions in dif- ferent contexts. In some definitions, equations and inequations are excluded from math expressions. In this paper, equations and inequations (like "a=b" and "ax+b&gt;0") are called s-expressions be- cause they represent mathematical sentences, while other math expressions (like "x+5") are named n-expressions since they are essentially noun phrases. Our definition of "math expres- sions" therefore includes both n-expressions and s-expressions.</p><p>Different types of nodes may generate different types of math expressions. In most cases, s-ex- pressions are derived from verb function nodes and modifier function nodes, while n-expressions are generated from constants and noun function nodes. For example, the s-expression "9+x=314" can be derived from the DOL tree of <ref type="figure" target="#fig_5">Figure 3</ref>, if variable x represents the integer. In the same <ref type="figure">Fig- ure</ref>, The n-expression "9+x" is derived from the left sub-tree.</p><p>The pseudo-codes of our math expression deri- vation algorithm are shown in <ref type="figure" target="#fig_8">Figure 5</ref>. The algo- rithm generates the math expression for a DOL tree T by first calling the expression derivation procedure of sub-trees, and then applying the se- mantic interpretation of T. All the s-expressions derived so far are stored in an expression list named XL.  The semantic interpretation of DOL nodes plays a critical role in the algorithm. <ref type="table" target="#tab_4">Table 3</ref> shows some example interpretations of some rep- resentative DOL functions. In the table, $1, $2 etc. are function arguments, and $ ↑ for a modifier node denotes the node which the modifier modi- fies. So far the semantic interpretations are built manually. Please note that it is not necessary to make semantic interpretations for every DOL node in solving number word problems. For ex- ample, most class nodes and many adverb nodes can have null interpretations at the moment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental setup</head><p>Datasets: Our problem collection 5 contains 1,878 math number word problems, collected from two web sites: algebra.com 6 (a web site for users to post math problems and get help from tutors) and answers.yahoo.com 7 . Problems on both sites are organized into categories. For algebra.com, prob- lems are randomly sampled from the number word problems category; for answers.yahoo.com, we first randomly sample an initial set of prob- lems from the math category and then ask human annotators to manually choose number word problems from them. Math equations 8 and an- swers to the problems are manually added by hu- man annotators.</p><p>We randomly split the dataset into a dev set (for algorithm design and debugging) and a test set. More subsets are extracted to meet the require- ments of the baseline methods (see below). <ref type="table" target="#tab_6">Table  4</ref> shows the statistics of the datasets.</p><p>Baseline methods: We compare our approach with two baselines: KAZB (  and BasicSim.</p><p>KAZB is a learning-based statistical method which solves a problem by mapping it to one of the equation templates determined by the anno- tated equations in the training data. We run the ALLEQ version of their algorithm since it per- forms much better than the other two (i.e., 5EQ and 5EQ+ANS). Their codes support only linear equations and require that there are at least two problems for each equation template (otherwise an exception will be thrown). By choosing prob- lems from the collection that meet these require- ments, we build a sub-dataset called LinearT2. In the dataset of KAZB, each equation template cor- responds to at least 6 problems. So we form an- other sub-dataset called LinearT6 by removing from the test set the problems for which the asso- ciated equation template appears less than 6 times.</p><p>BasicSim is a simple statistical method which works by computing the similarities between a testing problem and those in the training set, and then applying the equations of the most similar problem. This method has similar performance with KAZB on their dataset, but does not have the two limitations mentioned above. Therefore we adopt it as the second baseline.</p><p>For both baselines, experiments are conducted using 5-fold cross-validation with the dev set al- ways included in the training data. In other words, we always use the dev set and 4/5 of the test set as training data for each fold.</p><p>Evaluation metrics: Evaluation is performed in the setting that a system can choose NOT to an- swer all problems in the test set. In other words, one has the flexibility of generating answers only when she knows how to solve it or she is confident about her answer. In this setting, the following three metrics are adopted in reporting evaluation results (assuming, in a test set of size n, a system generates answers for m problems, where k of them are correct):  </p><formula xml:id="formula_2">Precision: k/m Recall (or coverage): k/n F1: 2PR/(P+R) = 2k/(m+n</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental results</head><p>The Overall evaluation results are summarized in <ref type="table" target="#tab_8">Table 5</ref>, where "Dolphin" represents our ap- proach. The results show that our approach signif- icantly outperforms (with p&lt;&lt;0.01 according to two-tailed t-test) the two baselines on every test set, in terms of precision, recall, and F-measure. Our approach achieves a particularly high preci- sion of 95%. That means once an answer is pro- vided by our approach, it has a very high proba- bility of being correct. Please note that our grammar rules and parsing algorithm are NOT tuned for the evaluation data. Only the dev set is referred to in system building.</p><p>Since the baselines generate results for all prob- lems, the precision, recall, and F1 are all the same for each dataset.  The reason for such a high precision is that, by transforming NL text to DOL trees, the system "understands" the problem (or has structured and accurate information about quantity relations). Therefore it is more likely to generate correct re- sults than statistical methods who simply "guess" according to features. By examining the problems in the dev set that we cannot generate answers, we find that most of them are due to empty parsing results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Method Precision</head><p>On the other hand, statistical approaches have the advantage of generating answers without un- derstanding the semantic meaning of problems (as long as there are similar problems in the training data). So they are able to handle (with probably low precision) problems that are complex in terms of language and logic.</p><p>Please pay attention that our experimental re- sults reported here are on number word problems. General math word problems are much harder to our approach because the entity types, properties, relations, and actions contained in general word problems are much larger in quantity and more complex in quality. We are working on extending our approach to general math word problems. Now our DOL language and CFG grammar al- ready have a good coverage on common entity types, but the coverage on properties, relations, and actions is quite limited. As a result, our parser fails to parse many sentences in general math word problems because they contain properties, relations or actions that are unknown to our sys- tem. We also observe that sometimes we are able to parse a problem successfully, but cannot derive math expressions in the reasoning stage. This is often because some relations or actions in the problem are not modeled appropriately. As future work, we plan to extend our DOL lexicon and grammar to improve the coverage of properties, relations, and actions. We also plan to study the mechanism of modeling relations and actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We proposed a semantic parsing and reasoning approach to automatically solve math number word problems. We have designed a new meaning representation language DOL to bridge NL text and math expressions. A CFG parser is imple- mented to parse NL text to DOL trees. A reason- ing module is implemented to derive math expres- sions from DOL trees, by applying the semantic interpretation of DOL nodes. We achieve a high precision and a reasonable recall on our test set of over 1,500 problems. We hope to extend our tech- niques to handling general math word problems and to other domains (like physics and chemistry) in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Number word problem examples</figDesc><graphic url="image-1.png" coords="1,311.38,429.88,210.00,141.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: DOL example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Type-compatibility:</head><label></label><figDesc>The type of each child of a function node should match the corresponding ar- gument type of the function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>sum of 100 [unreasonable text] nf.math.sum!2(100) [invalid DOL tree] sum of 3 and Jordan [unreasonable text] nf.math.sum!2({3, "Jordan"}) [invalid tree]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>vf.be.equ($1,$2) → {$1} be equal to {$2} | {$1} equal {$2} | {$1} be {$2} vf.give($1,$2,$3) → {$1} give {$2} to {$3} | {$1} give {$3} {$2} nf.math.sum!1($1,$2) → {$1} plus {$2} | {$2} added to {$1} nf.math.sum!2($1) → sum of {$1} | addition of {$1} nf.math.power($1,$2) → {$1} raised to the {power|exponent} of {$2} nf.list($1,$2) → {$2} {$1} mf.number.even → even mf.condition.if($1) → if {$1} mf.approximately → approximately | roughly education.university → university math.number → number math.integer → integer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The DOL semantic parse tree for "Nine plus an integer is equal to 314"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A syntactic parse tree 3.2.2 Parsing Parsing for CFG is a well-studied topic with lots of algorithms invented (Kasami, 1965; Earley, 1970). The core idea behind almost all the algorithms is exploiting dynamic programming to achieve efficient search through the space of possible parse trees. For syntactic parsing, a wellknown serious problem is ambiguity: the appearance of many syntactically correct but semantically unreasonable parse trees. Modern syntactic parsers reply on statistical information to reduce</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Math expression derivation algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 : Example semantic interpretations</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>)</head><label></label><figDesc></figDesc><table>Dataset 
#problems #sentences 
(average) 

#words 
(average) 

All 
dev 
374 
1.79 
20.3 
test 
1,504 
1.75 
22.5 
Linear 
dev 
247 
1.78 
19.6 
test 
986 
1.72 
19.0 
LinearT2 dev 
172 
1.85 
18.8 
test 
669 
1.71 
17.4 
LinearT6 dev 
71 
1.96 
16.8 
test 
348 
1.80 
16.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Dataset statistics (Linear: problems with 
linear equations; T2: problems corresponding to 
template size ≥ 2) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 : Evaluation results</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://www.wolframalpha.com</note>

			<note place="foot" n="2"> https://www.wolframalpha.com/examples/ElementaryMath.html (bottom-right part)</note>

			<note place="foot" n="3"> Freebase: http://www.freebase.com/</note>

			<note place="foot" n="4"> VerbNet: http://verbs.colorado.edu/~mpalmer/projects/verbnet.html</note>

			<note place="foot" n="5"> Available from http://research.microsoft.com/en-us/projects/dolphin/ 6 http://www.algebra.com</note>

			<note place="foot" n="7"> https://answers.yahoo.com/ 8 Math equations are used in the baseline approaches as part of training data.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the annotators for their ef-forts in assigning math equations and answers to the problems in our dataset. Thanks to the anony-mous reviewers for their helpful comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The syntax and semantics of the proposed international algebraic language of the Zurich ACM-GAMM conference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Backus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Information Processing</title>
		<meeting>the International Conference on Information Processing</meeting>
		<imprint>
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Robust understanding of word problems with extraneous information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bakman</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/math/0701393.Accessed" />
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SemEval2007 Task 19: Frame semantic structure extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ellsworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Erk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval</title>
		<meeting>SemEval</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Abstract meaning representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>of the Linguistic Annotation Workshop and Interoperability with Discourse</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic Parsing via Paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Natural language input for a computer problem solving system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Bobrow</surname></persName>
		</author>
		<idno>MAC- TR-1</idno>
		<imprint>
			<date type="published" when="1964-06" />
			<pubPlace>Project MAC, MIT, Cambridge</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Natural language input for a computer problem solving system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Bobrow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964" />
			<pubPlace>MIT, Cambridge</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Mathematics</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">An integrated model of skill in solving elementary word problems. Cognition and Instruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Briars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Larkin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="245" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing via schema matching and lexicon extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2004 shared task: Semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">CARPS: a program which solves calculus word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
		<idno>MAC-TR-51</idno>
		<imprint>
			<date type="published" when="1968-07" />
			<pubPlace>MAC, MIT, Cambridge</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Computer solution of calculus word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of international joint conference on artificial intelligence</title>
		<meeting>international joint conference on artificial intelligence<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1969" />
			<biblScope unit="page" from="303" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Three models for the description of language. Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chomsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Transactions on</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="113" to="124" />
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Wide-coverage efficient statistical parsing with CCG and log-linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="493" to="552" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Frame-Semantic Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F T</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="56" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A computer simulation of children&apos;s arithmetic word problem solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dellarosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="147" to="154" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Classdriven attribute extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="921" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An efficient context-free parsing algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Earley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="94" to="102" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Background to FrameNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Petruck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Lexicography</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Understanding and solving arithmetic word problems: a computer simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Fletcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="565" to="571" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic labeling of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic Acquisition of Hyponyms from Large Text Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourteenth International Conference on Computational Linguistics</title>
		<meeting><address><addrLine>Nantes, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning to Solve Arithmetic Word Problems with Verb Categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kushman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Speech &amp; language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Pearson Education India</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">An efficient recognition and syntaxanalysis algorithm for context-free languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kasami</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965" />
			<biblScope unit="page" from="65" to="758" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">From TreeBank to PropBank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to automatically solve algebra word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Solving logic puzzles: From robust processing to precise semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Text Meaning and Interpretation. Association for Computational Linguistics</title>
		<meeting>the Workshop on Text Meaning and Interpretation. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Modeling Math Word Problems with Augmented Semantic Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liguda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pfeiffer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="247" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Frame-based calculus of solving arithmetic multistep addition and subtraction word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Workshop on Education Technology and Computer Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="476" to="479" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semantic role labeling: an introduction to the special issue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Litkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">34</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A review of methods for automatic understanding of natural language mathematical problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Garain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Organizing and searching the world wide web of facts-step one: the one-million fact extraction challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bigham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lifchits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1400" to="1405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">VerbNet: A broad-coverage, comprehensive verb lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Schuler</surname></persName>
		</author>
		<ptr target="http://reposi-tory.upenn.edu/dissertations/AAI3179808" />
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Corpus-based semantic class mining: distributional vs. pattern-based approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="993" to="1001" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">The Syntactic Process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="960" to="967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic proramming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence (UAI)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Online Learning of Relaxed CCG Grammars for Parsing to Logical Form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>EMNLP-CoNLL</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Nonlinear evidence fusion and propagation for hyponymy relation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y.</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1159" to="1168" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
