<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Nil-Aware Answer Extraction Framework for Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Souvik</forename><surname>Kundu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Nil-Aware Answer Extraction Framework for Question Answering</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Association for Computational Linguistics</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">4243</biblScope>
							<biblScope unit="page" from="4243" to="4252"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recently, there has been a surge of interest in reading comprehension-based (RC) question answering (QA). However, current approaches suffer from an impractical assumption that every question has a valid answer in the associated passage. A practical QA system must possess the ability to determine whether a valid answer exists in a given text passage. In this paper, we focus on developing QA systems that can extract an answer for a question if and only if the associated passage contains an answer. If the associated passage does not contain any valid answer, the QA system will correctly return Nil. We propose a nil-aware answer span extraction framework that is capable of returning Nil or a text span from the associated passage as an answer in a single step. We show that our proposed framework can be easily integrated with several recently proposed QA models developed for reading comprehension and can be trained in an end-to-end fashion. Our proposed nil-aware answer extraction neural network decomposes pieces of evidence into relevant and irrelevant parts and then combines them to infer the existence of any answer. Experiments on the NewsQA dataset show that the integration of our proposed framework significantly outper-forms several strong baseline systems that use pipeline or threshold-based approaches.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine comprehension (MC) systems mimic the process of reading comprehension (RC) by an- swering questions after understanding natural lan- guage text. Several datasets and resources have been developed recently. <ref type="bibr" target="#b11">Richardson et al. (2013)</ref> developed a small-scale multiple-choice question answering (QA) dataset. <ref type="bibr" target="#b3">Hermann et al. (2015)</ref> created a large cloze-style MC dataset based on CNN and Daily Mail news article summaries. However, <ref type="bibr" target="#b1">Chen et al. (2016)</ref> reported that the task is not challenging enough and hence, ad- vanced models had to be evaluated on more real- istic datasets. Subsequently, <ref type="bibr">SQuAD (Rajpurkar et al., 2016</ref>) was released, where, unlike previ- ous datasets, the answers to different questions can vary in length.</p><p>In previous datasets, questions and answers are formulated given text passages. Hence, a valid an- swer can always be found in the associated pas- sage for every question created. <ref type="bibr" target="#b18">Trischler et al. (2017)</ref> proposed a more challenging and realis- tic dataset, NewsQA, where the questions were formed using CNN article summaries without ac- cessing the original full texts. As such, some ques- tions have no valid answers in the associated pas- sages (referred to as nil questions).</p><p>Recently, several neural models for answer span extraction have been proposed ( <ref type="bibr" target="#b19">Wang and Jiang, 2017;</ref><ref type="bibr" target="#b13">Seo et al., 2017;</ref><ref type="bibr" target="#b23">Xiong et al., 2017;</ref><ref type="bibr" target="#b22">Weissenborn et al., 2017;</ref><ref type="bibr" target="#b15">Shen et al., 2017b;</ref><ref type="bibr" target="#b7">Kundu and Ng, 2018)</ref>. However, none of the models considered nil questions, although it is crucial for a practical QA system to be able to determine whether a text passage contains a valid answer for a question. In this paper, we focus on develop- ing QA systems that extract an answer for a ques- tion if and only if the associated passage contains a valid answer. Otherwise, they are expected to re- turn Nil as answer. We propose a nil-aware answer extraction framework which returns Nil or a span of text as answer, when integrated with end-to- end neural MC models. Our proposed framework is based on evidence decomposition-aggregation, where the evidence vectors derived by a higher level encoding layer are first decomposed into rel- evant and irrelevant components and later aggre- gated to infer the existence of a valid answer. In addition, we develop several baseline models with pipeline and threshold-based approaches. In a pipeline model, detection of nil questions is car- ried out separately before answer span extraction. In a threshold-based model, the answer span ex- traction model is entirely trained on questions that have valid answers, and Nil is returned based on a confidence threshold.</p><p>The contributions of this paper are as follows: (1) We propose a nil-aware answer span extraction framework to return Nil or an exact answer span to a question, in a single step, depending on the exis- tence of a valid answer. (2) Our proposed frame- work can be readily integrated with many recently proposed neural machine comprehension models. In this paper, we extend four machine comprehen- sion models, namely BiDAF ( <ref type="bibr" target="#b13">Seo et al., 2017)</ref>, R- Net ( , <ref type="bibr">DrQA (Chen et al., 2017)</ref>, and AMANDA ( <ref type="bibr" target="#b7">Kundu and Ng, 2018)</ref>, with our proposed framework, and show that they achieve significantly better results compared to the corre- sponding pipeline and threshold-based models on the NewsQA dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition</head><p>Given a passage and a question, we propose mod- els that can extract an answer if and only if the passage contains an answer. When the passage does not contain any answer, the models return Nil as the answer. A valid answer is denoted as two pointers in the passage, representing the start and end tokens of the answer span. Let P be a passage with tokens (P 1 , P 2 , . . . , P T ) and Q be a question with tokens (Q 1 , Q 2 , . . . , Q U ), where T and U are the length of the passage and question respectively. A system needs to determine whether the answer is Nil or comprises two pointers, b and e, such that 1 ≤ b ≤ e ≤ T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Framework</head><p>In this section, we first describe our proposed ev- idence decomposition-aggregation framework for nil-aware answer extraction. Then, we provide a detailed description of how we extend a state-of- the-art model AMANDA ( <ref type="bibr" target="#b7">Kundu and Ng, 2018)</ref> to NAMANDA 1 (nil-aware AMANDA). We also provide brief descriptions of how we integrate our proposed framework with the other three models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Nil-Aware Answer Extraction</head><p>Decomposition of lexical semantics over sen- tences has been successfully used in the past for sentence similarity learning ( <ref type="bibr" target="#b21">Wang et al., 2016</ref>). Most of the recently proposed machine reading comprehension models can be generalized based on a common pattern observed in their network ar- chitecture. They have a question-passage joint en- coding layer (also known as question-aware pas- sage encoding layer) followed by an evidence en- coding layer. In this work, we decompose the evidence vectors for each passage word obtained from the evidence encoding layer with respect to question-passage joint encoding vectors to derive semantically relevant and irrelevant components. We decompose the evidence vectors for each pas- sage word, because passage vectors can be par- tially supported by the corresponding question- passage joint encoding vectors, and based on the level of support, it either increases or decreases the chance of finding a valid answer. When we aggre- gate the orthogonally decomposed evidence vec- tors, it combines both the supportive and unsup- portive pieces of evidence for a particular passage word. To obtain the most impactful portions, we perform a max-pooling operation over all the ag- gregated vectors. The resulting vector is denoted as the Nil vector. As the training set contains both nil questions (with no valid answers) and non-nil questions (with valid answers), the model auto- matically learns when to pool unsupportive (for nil questions) and supportive (for non-nil questions) portions to construct the Nil vector. In this way, the model is able to induce a strong bias towards the nil pointer when there is no answer present due to the dominance of unsupportive components in the nil vector.</p><p>The proposed method in <ref type="bibr" target="#b21">Wang et al. (2016)</ref> was developed for sentence similarity learning tasks, such as answer sentence selection. They decom- pose an answer sentence with respect to a ques- tion and vice versa. The decomposed vectors are then aggregated to obtain a single vector which is used to derive the similarity score. Although our proposed method (developed for the more com- plex task of answer span extraction) is inspired from the idea of lexical decomposition and com- position, one major difference is that we decom- pose the evidence vectors with respect to question- passage joint encoding vectors. Another important advance is how it is adopted to return nil or a span of text from the passage in a single step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Nil-Aware AMANDA</head><p>The architecture of Nil-aware AMANDA (NA- MANDA) is given in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Embeddings</head><p>To obtain the embeddings, we concatenate word and character-level embedding vectors. We use pre-trained vectors from GloVe ( <ref type="bibr" target="#b8">Pennington et al., 2014</ref>) for word-level embeddings. For character embeddings, a trainable character-based lookup table is used followed by a convolutional neural network (CNN) and max-pooling <ref type="bibr" target="#b5">(Kim, 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Sequence Encoding</head><p>We use bi-directional LSTM (BiLSTM) (Hochre- iter and Schmidhuber, 1997) on the embedding vectors to incorporate contextual information. We represent the outputs as D ∈ R T ×H and Q ∈ R U ×H for passage and question respectively. H is the number of hidden units of the BiLSTMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Similarity Matrix</head><p>The similarity matrix is obtained by computing the dot product of passage and question sequence- level encoding vectors. The similarity matrix A ∈ R T ×U can be expressed as A = D Q , where A i,j is the similarity between the ith passage word and the jth question word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Question Formulation</head><p>To aggregate the most relevant parts of the ques- tion, column-wise maximum values of A are nor- malized using a softmax function to obtain k ∈ R U . Then, the question vectors in Q are aggre- gated by q ma = k Q. The question type informa- tion is incorporated via q f ∈ R 2H , by concatenat- ing the sequence-level question encoding vectors of the first wh-word q t wh and its following word q t wh +1 . It can be given as q f = q t wh || q t wh +1 , where || denotes the concatenation operation. The set of wh-words we used is {what, who, how, when, which, where, why}. The final question rep- resentation, ˜ q ∈ R H , is formulated by applying a feed-forward neural network on the concatenated representation of q ma and q f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Question-Passage Joint Encoding</head><p>In this step, we jointly encode the passage and question. We apply a row-wise softmax func- tion on A to obtain R ∈ R T ×U . Now, for all the passage words, the aggregated question rep- resentation G ∈ R T ×H is computed by G = R Q. The aggregated question vectors corre- sponding to the passage words are then concate- nated with the sequence-level passage vectors to obtain S ∈ R T ×2H . We apply another BiLSTM to obtain a combined representation V ∈ R T ×H .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.6">Evidence Decomposition-Aggregation</head><p>First, multi-factor self-attentive encoding is ap- plied to accumulate evidence from the entire pas- sage. The use of multiple factors while calculating self attention helps to obtain meaningful informa- tion from a long context with fine-grained infer- ence. If m represents the number of factors, multi- factor attention F <ref type="bibr">[1:m]</ref> ∈ R T ×m×T is formulated as:</p><formula xml:id="formula_0">F [1:m] = V W [1:m] f V ,<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">W [1:m] f</formula><p>∈ R H×m×H is a 3-way tensor. Now, to refine the evidence, a max-pooling oper- ation is performed on F <ref type="bibr">[1:m]</ref> over the number of factors, resulting in the self-attention matrix F ∈ R T ×T . We normalize F by applying a row-wise softmax function, resulting iñ F ∈ R T ×T . Now the self-attentive encoding M ∈ R T ×H can be given as M = ˜ F V. The self-attentive encoding vectors are then concatenated with the question- dependent passage word encoding vectors (V), and a feed-forward neural network-based gating is applied to control the overall impact, resulting in</p><formula xml:id="formula_2">Y ∈ R T ×2H .</formula><p>Then we decompose the evidence vector for ev- ery passage word with orthogonal decomposition. Each row of Y, y t ∈ R 2H , is decomposed into its parallel and perpendicular components with re- spect to the corresponding question-passage joint encoding (S) vector, s t ∈ R 2H . The parallel com- ponents represent the relevant parts of the accu- mulated evidence and the orthogonal components represent the irrelevant counterparts. If the paral- lel component of y t is represented as y = t ∈ R 2H and the perpendicular component is represented as</p><formula xml:id="formula_3">y ⊥ t ∈ R 2H , then y = t = y t s t s t s t s t (2) y ⊥ t = y t − y = t<label>(3)</label></formula><p>Similarly, we derive the parallel and orthogonal vectors for all the passage words. We denote par- allel components with Y = ∈ R T ×2H and perpen- dicular components with Y ⊥ ∈ R T ×2H .</p><p>In the aggregation step, the parallel and orthog- onal components are fed to a feed-forward linear layer. Y a ∈ R T ×H denotes the output of the lin- ear layer and y a t ∈ R H is its tth row:</p><formula xml:id="formula_4">y a t = tanh(y = t W a + y ⊥ t W a + b a ) ,<label>(4)</label></formula><p>where W a ∈ R 2H×H and b a ∈ R H are the weight matrix and bias vector respectively. Then we ap- ply a max-pooling operation over all the words to obtain the Nil vector representation denoted asˆn asˆ asˆn. Now we derive the score for the Nil pointer which will be shared for normalizing the begin- ning and ending pointers later. The Nil pointer score is given as:</p><formula xml:id="formula_5">n s = ˆ nw n ,<label>(5)</label></formula><p>where w n ∈ R H is a learnable weight vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.7">Nil-Aware Pointing</head><p>Two stacked BiLSTMs are used on top of Y to de- termine the beginning and ending pointers. Let the hidden unit representations of these two BiLSTMs be B ∈ R T ×H and E ∈ R T ×H . We measure the similarity scores between the previously derived question vector˜qvector˜ vector˜q and the contextual encoding vec- tors in B and E. If s b ∈ R T and s e ∈ R T are the scores for the beginning and ending pointers, then</p><formula xml:id="formula_6">s b = ˜ q B , s e = ˜ q E<label>(6)</label></formula><p>We prepend the nil score n s to s b and s e for shared normalization. The updated scoresˆsscoresˆscoresˆs b ∈ R T +1 andˆs andˆandˆs e ∈ R T +1 can be represented as:</p><formula xml:id="formula_7">ˆ s b = [n s , s b ] , ˆ s e = [n s , s e ]<label>(7)</label></formula><p>The beginning and ending pointer probability distributions for a given passage P and a question Q is given as:</p><formula xml:id="formula_8">Pr(b | P, Q) = softmax(ˆ s b ) Pr(e | P, Q) = softmax(ˆ s e )<label>(8)</label></formula><p>The joint probability distribution for answer a is given as:</p><formula xml:id="formula_9">Pr(a | P, Q) = Pr(b | P, Q) Pr(e | P, Q) (9)</formula><p>For training, we minimize the cross entropy loss summing over all training instances. During pre- diction, we select the locations in the passage for which the product of Pr(b) and Pr(e) is maxi- mized, where 1 ≤ b ≤ e ≤ T + 1. If the value of b is 1, we assign the answer as Nil.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Nil-Aware DrQA</head><p>We extend DrQA ( ) to NDrQA by integrating our proposed nil-aware answer ex- traction framework. In DrQA, the embeddings of passage tokens consist of pretrained word vec- tors from Glove, several syntactic features, and passage-question joint embedding (aligned ques- tion embedding). The syntactic features include exact match of passage words with question in sur- face, lowercase, and lemma form. They also used part-of-speech tags, named entity tags, and term frequency values for each passage word. Sub- sequently, a stack of BiLSTMs is used for en- coding. The outputs of the stacked BilSTMs are used as evidence vectors to help extract the an- swer span. We decompose those stacked BiL- STM output vectors with respect to the passage embedding and generate the nil pointer score as given in Eqs (2-5). The question vector formula- tion in DrQA is performed by applying a stack of BilSTMs on question embedding. The nil-aware pointing mechanism is the same as that given in Section 3.2.7 except an additional bi-linear term is used for each s b and s e in Eq (6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Nil-Aware R-Net</head><p>In R-Net ( , after embedding and encoding of the passage and question words, a gated recurrent network is used to obtain the question-passage joint representation. Subse- quently, a self-matching attentive encoding is used to accumulate evidence from the entire passage.</p><p>In the output layer, an answer recurrent pointer network is used to predict the boundary of an an- swer span. To extend R-Net to nil-aware R-Net (NR-Net), we decompose the output vectors of the self-matching layer with respect to the question- passage joint encoding vectors, and then aggregate them to obtain the nil pointer score as illustrated in Eqs (2-5). In the output layer, we combine the nil pointer score to the beginning and ending pointer unnormalized scores, and jointly normalize them using softmax function as given in Eqs (7-8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Nil-Aware BiDAF</head><p>In BiDAF ( <ref type="bibr" target="#b13">Seo et al., 2017)</ref>, an attention flow layer is used to jointly encode the passage and question. Then, a modeling layer is used to cap- ture the interaction among the question-aware pas- sage vectors. The output of the modeling layer serves as evidence to help extract the answer span in the output layer. To extend the BiDAF model to nil-aware BiDAF (NBiDAF), we decompose the output of the modeling layer with respect to the question-passage joint encoding vectors, and then aggregate them to derive the nil pointer score (sim- ilar to Eqs (2-5). Similar to the other nil-aware models, we concatenate the nil pointer score to the start and end pointer unnormalized scores de- rived in the output layer, and then jointly normal- ize them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Baseline Models</head><p>For comparison, we propose two types of baseline approaches for nil-aware answer extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pipeline Approach</head><p>Here, two models are used in a pipeline:</p><p>Nil detector: Given a pair of passage and ques- tion, a nil detector model determines whether a valid answer is present in the passage.</p><p>Answer span extractor: If the nil detector model predicts the presence of a valid answer, the answer span extractor then extracts the answer.</p><p>For nil detection, we developed a logistic re- gression (LR) model with manually defined fea- tures and four neural models. For the LR model, we extract four different features which capture the similarity between a passage and a question. Let P be the passage and Q be the question (con- sisting of U tokens excluding stop words). If f (P, Q i ) is the frequency of the ith question word in passage P, then the first feature η is defined as:</p><formula xml:id="formula_10">η = U i=1 log(1 + f (P, Q i ))<label>(10)</label></formula><p>The second feature is the same as η, except that the lemma form is considered for both passage and question tokens instead of the surface form. Addi- tionally, we include word overlap count features in both surface and lemma forms. We also develop several advanced neural net- work architectures for nil detection. After em- bedding (the same as Section 3.2.1), we apply sequence-level encoding with either BiLSTM or CNN. For CNN, we use equal numbers of un- igram, bigram, and trigram filters and the out- puts are concatenated to obtain the final encoding. Next, we apply either global max-pooling (MP) or attentive pooling (AP) over all the sequence vectors to obtain an aggregated vector represen- tation. Let the sequence encoding of a passage be P nd ∈ R T ×H , and p nd t be the tth row of P nd . The aggregated vector˜pvector˜ vector˜p nd ∈ R H for AP can be obtained as:</p><formula xml:id="formula_11">a nd t ∝ exp(p nd t w )<label>(11)</label></formula><formula xml:id="formula_12">˜ p nd = a nd P nd ,<label>(12)</label></formula><p>where w ∈ R H is a learnable vector. Similarly, we derive the aggregated question vector˜qvector˜ vector˜q nd . For nil detection, we compute the similarity score (s nd ) between the aggregated vectors:</p><formula xml:id="formula_13">s nd = sigmoid(˜ p nd˜qnd˜ nd˜q nd )<label>(13)</label></formula><p>We experimented with four state-of-the-art an- swer span extractor models, namely <ref type="bibr">BiDAF (Seo et al., 2017</ref>), R-Net ( ), DrQA ( , and AMANDA ( <ref type="bibr" target="#b7">Kundu and Ng, 2018)</ref>. Note that the answer extraction mod- els are trained entirely on passage-question pairs which always have valid answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Threshold-Based Approach</head><p>Here, we do not use any nil questions to train the neural answer span extraction model. This ap- proach assumes that when there is a valid answer, the probability distributions of the beginning and ending pointers will have lower entropy. This re- sults in a higher maximum joint probability of the beginning and ending pointers. In contrast, when an answer is not present in the associated passage, the output probability distributions have higher en- tropy, resulting in a lower value of maximum joint probability. We set the maximum joint probabil- ity threshold based on the best Nil F1 score on the nil questions in the development set. Now, for a given test passage and question, we first compute the maximum of all the joint probabilities associ- ated with all the answer spans. Let a span be the answer span with highest joint probability p max . We assign the final answer as follows:</p><formula xml:id="formula_14">answer = N il, if p max ≤ threshold a span , otherwise<label>(14)</label></formula><p>5 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>We use the NewsQA dataset with nil questions ( <ref type="bibr" target="#b18">Trischler et al., 2017</ref>) in our experiments. Its training, development, and test sets consist of 10,938, 638, and 632 passages respectively and every passage is associated with some questions. In each subset, there are some questions which have no answers in the corresponding associated passages (i.e., the nil questions). The detailed statistics of the dataset are given in <ref type="table">Table 1</ref>. We compute exact match (EM) and F1 score for questions with valid answers. For questions with- out any valid answers, we compute Nil precision, recall, and F1 scores as follows: All the neural network models are implemented in PyTorch 2 . We use the default hyper-parameters for all the answer span extractor models. We use the open source implementation of DrQA 3 . We use a third party implementation of R-Net 4 whose performance is very similar to the original scores. We reimplemented BiDAF <ref type="bibr">5</ref> and AMANDA 6 to easily integrate our proposed nil-aware answer ex- traction framework and make the training faster. We integrate the nil-aware answer span extraction framework with each model keeping all the hyper- parameters unchanged. For nil-detection models, we use the same settings as (N)AMANDA. We use 300 hidden units for BiLSTMs and a total of 300 filters for the CNN-based models. We use dropout ( <ref type="bibr" target="#b16">Srivastava et al., 2014</ref>) with probability 0.3 for every trainable layer. We use binary cross- entropy loss and the Adam optimizer ( <ref type="bibr" target="#b6">Kingma and Ba, 2015)</ref> for training the nil-detection models.   <ref type="table">Table 2</ref>: Performance Comparison with pipeline approaches on the NewsQA test set. <ref type="table">Tables 2 and 3</ref> compare results of the nil-aware an- swer span extractor models with several pipeline and threshold-based models, respectively. We also include the results of four standalone answer span extraction models on the test set without nil ques- tions. <ref type="table">Table 2</ref> shows that the end-to-end nil-aware models achieve the highest overall EM and F1 scores compared to all the corresponding pipeline systems. Note that the MP-BiLSTM nil detection model achieves higher Nil F1 scores compared to LR and MP-CNN. This is because BiLSTM is able to capture long-range contextual informa- tion to infer the existence of valid answers. Fur- thermore, AP-based models perform better com- pared to MP-based models as the attention mech- anism used in AP-based models inherently iden- tifies important contextual information. Due to this, the performance gap between AP-CNN and AP-BiLSTM is lower than the performance gap between MP-CNN and MP-BiLSTM. In addition to achieving higher Nil F1 score than the strong nil detection baseline systems, nil-aware models manage to achieve competitive scores compared to the corresponding standalone answer span extrac- tors on the test set where there are no nil questions. <ref type="table">Table 3</ref> shows that the nil-aware models outper- form the corresponding threshold-based models. Note that all four answer span extraction models, when used in a threshold-based approach for nil detection, produce low Nil precision and relatively higher Nil recall. The low precision significantly degrades performance on the test set without nil questions. These models often return Nil since it is critical to find suitable values for the required threshold. This is because NewsQA passages are often very long and as a result, probability distri- butions with higher entropy for answer pointer se- lection lead to irregular maximum joint probabil- ity threshold values.</p><formula xml:id="formula_15">Nil</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>We perform statistical significance tests using paired t-test and bootstrap resampling. Perfor- mances of all the nil-aware models (in terms of overall EM and F1) are significantly better (p &lt; 0.01) than the corresponding best pipeline models and threshold-based approaches.  <ref type="table">Table 3</ref>: Performance comparison with threshold-based approaches on the NewsQA test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis</head><p>For better understanding, we present further ex- periments and analysis of one of the proposed models, NAMANDA.</p><p>In addition to linear aggregation, we experiment with BiLSTM-based and CNN-based aggregation models. When we use BiLSTM aggregation, Eq. (4) is modified to y a t = h = t + h ⊥ t , where</p><formula xml:id="formula_16">h = t = BiLSTM(y = t , h = t−1 , h = t+1 ) (18) h ⊥ t = BiLSTM(y ⊥ t , h ⊥ t−1 , h ⊥ t+1 )</formula><p>We use equal numbers of unigram, bigram, and tri- gram filters for CNN-based aggregation. Similar to BiLSTM-based aggregation, we add the CNN outputs for Y = and Y ⊥ . <ref type="table" target="#tab_4">Table 4</ref> shows that linear aggregation achieves the highest overall F1 score despite using the least number of parameters. <ref type="table">Table 5</ref> shows the results of NAMANDA on the NewsQA development set when different compo- nents are removed such as character embeddings, question-passage joint encoding, and the second LSTM for the answer-ending pointer. When question-passage joint encoding is removed, self- attentive encoding is formed as well as decom- posed with respect to sequence-level passage en- coding. When we remove the second LSTM for the answer-ending pointer, a feed-forward net- work is used instead. It is clear from <ref type="table">Table 5</ref> that question-passage joint encoding has the high- est impact.    <ref type="table">Table 5</ref>: Ablation studies on the NewsQA dev set.</p><p>This is because with more information in a ques- tion, it becomes easier to detect whether the asso- ciated passage contains a valid answer. Increasing Nil F1 scores also help to improve the overall F1 scores. However, the overall F1 score degrades with increasing length of the associated passage. When the associated passage is long, it is difficult for the answer span extractor to extract an answer for a question which has a valid answer, due to the increasing amount of potentially distracting infor- mation. The Nil F1 scores remain similar for pas- sages consisting of not more than 1,200 tokens. Beyond that, the Nil F1 score degrades a little as it becomes very challenging to infer the exis- tence of a valid answer accurately with increas- ing amount of potentially distracting information present in the passage. Nil detection is itself a very challenging task. Performances of the nil-aware models are worse than the corresponding answer extractor models on the test set without nil questions as Nil pre- cision is lower than 100%. We carried out an experiment to evaluate the performance of NA- MANDA on development sets with varying num- ber of nil questions. As the proportion of nil ques- tions in a set increases, NAMANDA outperforms AMANDA by a larger margin on overall scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>In some years of the question answering track at the Text Retrieval Conference (TREC) <ref type="bibr">7</ref> , some questions were considered as nil questions for which no valid answers could be found in the en- tire corpus. Participating teams were required to return Nil as answer for those questions. Many teams used threshold-based methods to determine whether any of the retrieved answers for a given question was valid or not. If none of the answers had high confidence, Nil was returned as answer. To evaluate the performance on the nil questions, TREC used Nil precision, recall and F1 scores.</p><p>In recent years, research on question answering has witnessed substantial progress with rapid ad- vances in neural network architectures. For exam- ple, on the answer sentence selection task, where a system has to choose the correct answer sentence from a pool of candidate sentences for a given question, the introduction of attention-based neu- ral models has rapidly advanced the state of the art ( <ref type="bibr" target="#b17">Tan et al., 2015;</ref><ref type="bibr" target="#b24">Yang et al., 2016;</ref><ref type="bibr" target="#b12">dos Santos et al., 2016;</ref><ref type="bibr" target="#b21">Wang et al., 2016;</ref><ref type="bibr" target="#b0">Bian et al., 2017;</ref><ref type="bibr" target="#b14">Shen et al., 2017a)</ref>.</p><p>However, in the answer sentence selection task, the answer is always a full sentence. <ref type="bibr" target="#b10">Rajpurkar et al. (2016)</ref> released a reading comprehension- based QA dataset SQuAD, where given a pas- sage and a question, a system needs to find the exact answer span rather than a sentence. Al- though SQuAD became very popular and served as a good test set to develop advanced end-to- end neural network architectures, it does not in- clude any nil questions. In practical QA, it is crit- ical to decide whether or not a passage contains a valid answer for a given question. Subsequently, the NewsQA ( <ref type="bibr" target="#b18">Trischler et al., 2017</ref>) dataset has been released which attempts to overcome this de- ficiency. However, all the proposed models for NewsQA so far have excluded nil questions dur- ing evaluation. Contrary to prior work, we focus on developing models for nil-aware answer span extraction. Very recently, <ref type="bibr" target="#b9">Rajpurkar et al. (2018)</ref> released the SQUADRUN dataset by augmenting the SQuAD dataset with unanswerable questions. The unanswerable questions are written adversar- ially by crowdworkers to look similar to the an- swerable ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we have focused on nil-aware answer span extraction for RC-based QA. A nil-aware QA system only extracts a span of text from the as- sociated passage as an answer to a given ques- tion if and only if the passage contains a valid an- swer. We have proposed a nil-aware answer span extraction framework based on evidence decom- position and aggregation that can be easily inte- grated with several recently proposed neural an- swer span extraction models. We have also de- veloped several pipeline and threshold-based mod- els using advanced neural architectures for com- parison. Experiments on the NewsQA dataset show that our proposed framework, when inte- grated with the answer span extraction models, achieves better performance compared to all the corresponding pipeline and threshold-based mod- els. Employing such a nil-aware answer span ex- tractor in practical IR-style QA tasks will be inter- esting future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of the architecture of Nil-aware AMANDA (NAMANDA).</figDesc><graphic url="image-1.png" coords="3,151.37,62.81,294.79,263.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>precision = #Correctly predicted Nil #predicted Nil (15) Nil recall = #Correctly predicted Nil #Nil questions (16) Nil F1 = 2 × Nil precision ×Nil recall Nil precision+Nil recall (17) To compute the overall EM and F1 scores, we con- sider Nil as correct for the questions which do not have any valid answers. All evaluation scores re- ported in this paper are in %.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Answer</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 (</head><label>2</label><figDesc>a) and Figure 2(b) show the results of NAMANDA on different question (excluding the stop words) and passage lengths respectively on the NewsQA development set. With increasing question length, the Nil F1 score also improves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Results for different (a) question and (b) passage lengths on NewsQA dev set.</figDesc><graphic url="image-2.png" coords="9,72.00,68.84,108.85,84.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Extractor</head><label></label><figDesc></figDesc><table>Nil 
Detector 

Test Set 
(w/o Nil Questions) 

Test Set 
(with Nil Questions) 

EM 
F1 
Nil 
Precision 

Nil 
Recall 

Nil 
F1 

Overall 
EM 

Overall 
F1 

BiDAF 

-
42.5 
57.5 
-
-
-
36.5 
49.4 
LR 
39.6 
53.2 
33.1 
28.9 
30.9 
38.1 
49.7 
MP-BiLSTM 40.1 
54.2 
52.5 
48.3 
50.3 
41.3 
53.4 
MP-CNN 
42.3 
57.2 
73.8 
15.0 
24.9 
38.4 
51.2 
AP-BiLSTM 
40.5 
54.7 
55.3 
47.5 
51.1 
41.5 
53.7 
AP-CNN 
40.1 
54.3 
50.8 
39.9 
44.7 
40.1 
52.3 
NBiDAF 
40.8 
54.7 
48.0 
59.6 
53.2 
43.5 
55.4 

R-Net 

-
49.9 
64.0 
-
-
-
42.8 
54.8 
LR 
46.4 
58.8 
33.1 
28.9 
30.9 
43.9 
54.6 
MP-BiLSTM 47.3 
60.3 
52.5 
48.3 
50.3 
47.5 
58.6 
MP-CNN 
49.7 
63.6 
73.8 
15.0 
24.9 
44.8 
56.7 
AP-BiLSTM 
47.6 
60.7 
55.3 
47.5 
51.1 
47.6 
58.8 
AP-CNN 
47.2 
60.4 
50.8 
39.9 
44.7 
46.2 
57.5 
NR-Net 
47.0 
60.8 
53.6 
57.6 
55.5 
48.5 
60.3 

DrQA 

-
50.0 
64.0 
-
-
-
42.9 
54.8 
LR 
46.3 
58.8 
33.1 
28.9 
30.9 
43.8 
54.6 
MP-BiLSTM 47.1 
60.2 
52.5 
48.3 
50.3 
47.3 
58.5 
MP-CNN 
49.6 
63.5 
73.8 
15.0 
24.9 
44.7 
56.7 
AP-BiLSTM 
47.4 
60.6 
55.3 
47.5 
51.1 
47.4 
58.8 
AP-CNN 
47.0 
60.2 
50.8 
39.9 
44.7 
46.0 
57.3 
NDrQA 
48.5 
61.8 
53.5 
57.2 
55.3 
49.8 
61.1 

AMANDA 

-
49.2 
64.2 
-
-
-
42.2 
55.1 
LR 
45.4 
58.8 
33.1 
28.9 
30.9 
43.1 
54.5 
MP-BiLSTM 46.2 
60.2 
52.5 
48.3 
50.3 
46.5 
58.5 
MP-CNN 
48.3 
63.3 
73.8 
15.0 
24.9 
43.6 
56.5 
AP-BiLSTM 
46.3 
60.6 
55.3 
47.5 
51.1 
46.5 
58.7 
AP-CNN 
45.9 
60.0 
50.8 
39.9 
44.7 
45.1 
57.1 
NAMANDA 
48.6 
62.2 
57.1 
56.7 
56.9 
49.7 
61.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Effect of different aggregation models on 
the NewsQA dev set. 

Model 
w/o Nil 
with Nil 
EM 
(F1) 

Nil Prec/ 
Rec (F1) 

Overall 
EM (F1) 
-character 
embeddings 

46.3 
(59.2) 

51.9/54.1 
(53.0) 

47.4 
(58.5) 
-q-passage 
joint encoding 

32.5 
(43.9) 

41.4/58.8 
(48.6) 

36.1 
(45.9) 
-second 
LSTM 

47.6 
(60.3) 

56.7/51.0 
(53.7) 

48.0 
(59.0) 

NAMANDA 
47.8 
(60.5) 

51.2/57.2 
(54.0) 

49.1 
(60.0) 

</table></figure>

			<note place="foot" n="1"> Our source code is available at https://github. com/nusnlp/namanda</note>

			<note place="foot" n="2"> http://pytorch.org 3 https://github.com/facebookresearch/DrQA 4 https://github.com/HKUST-KnowComp/ MnemonicReader/blob/master/r_net.py 5 Our implementation gives 3% lower F1 score compared to the reported results in Seo et al. (2017) on the SQuAD development set. 6 Our implementation gives 0.5% higher F1 score compared to the reported scores in Kundu and Ng (2018) on the NewsQA test set.</note>

			<note place="foot" n="7"> https://trec.nist.gov/data/qa.html</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A compare-aggregate model with dynamic-clip attention for answer selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A thorough examination of the CNN / Daily Mail reading comprehension task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomás</forename><surname>Kocisk´ykocisk´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A questionfocused multi-factor attention network for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Souvik</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for SQuAD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">MCTest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Renshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cícero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.03609</idno>
		<title level="m">Attentive pooling networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inter-weighted alignment network for sentence pair modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gehui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunlun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ReasoNet: Learning to stop reading in machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">LSTM-based deep learning models for non-factoid answer selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.04108</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">NewsQA: A machine comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Representation Learning for NLP, ACL</title>
		<meeting>the 2nd Workshop on Representation Learning for NLP, ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Machine comprehension using Match-LSTM and answer pointer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gated self-matching networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sentence similarity learning by lexical decomposition and composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Making neural QA as simple as possible but not simpler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Seiffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dynamic coattention networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">aNMM: Ranking short answer texts with attention-based neural matching model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Words or characters? Fine-grained gating for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
