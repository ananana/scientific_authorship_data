<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Supervised Keyphrase Extraction as Positive Unlabeled Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Sterckx</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornelia</forename><surname>Caragea</surname></persName>
							<email>cornelia.caragea@unt.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Develder</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Ghent University -iMinds</orgName>
								<address>
									<settlement>Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of North Texas</orgName>
								<address>
									<region>Texas</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Supervised Keyphrase Extraction as Positive Unlabeled Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1924" to="1929"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The problem of noisy and unbalanced training data for supervised keyphrase extraction results from the subjectivity of keyphrase assignment , which we quantify by crowdsourc-ing keyphrases for news and fashion magazine articles with many annotators per document. We show that annotators exhibit substantial disagreement, meaning that single annotator data could lead to very different training sets for supervised keyphrase extractors. Thus, annotations from single authors or readers lead to noisy training data and poor extraction performance of the resulting supervised extractor. We provide a simple but effective solution to still work with such data by reweighting the importance of unlabeled candidate phrases in a two stage Positive Unlabeled Learning setting. We show that performance of trained keyphrase extractors approximates a classi-fier trained on articles labeled by multiple an-notators, leading to higher average F 1 scores and better rankings of keyphrases. We apply this strategy to a variety of test collections from different backgrounds and show improvements over strong baseline models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Keyphrase extraction is the task of extracting a se- lection of phrases from a text document to concisely summarize its contents. Applications of keyphrases range from summarization (D' <ref type="bibr">Avanzo et al., 2004</ref>) to contextual advertisement ( <ref type="bibr" target="#b12">Yih et al., 2006</ref>) or sim- ply as aid for navigation through large text corpora.</p><p>Existing work on automatic keyphrase extraction can be divided in supervised and unsupervised ap- proaches. While unsupervised approaches are do- main independent and do not require labeled train- ing data, supervised keyphrase extraction allows for more expressive feature design and is reported to outperform unsupervised methods on many occa- sions ( <ref type="bibr">Kim et al., 2012;</ref><ref type="bibr" target="#b1">Caragea et al., 2014)</ref>. A requirement for supervised keyphrase extractors is the availability of labeled training data. In literature, training collections for supervised keyphrase extrac- tion are generated in different settings. In these col- lections, keyphrases for text documents are either supplied by the authors or their readers. In the first case, authors of academic papers or news articles as- sign keyphrases to their content to enable fast index- ing or to allow for the discovery of their work in electronic libraries <ref type="bibr" target="#b5">(Frank et al., 1999;</ref><ref type="bibr" target="#b7">Hulth, 2003;</ref><ref type="bibr">Bulgarov and Caragea, 2015)</ref>. Other collections are created by crowdsourcing ( <ref type="bibr" target="#b8">Marujo et al., 2012</ref>) or based on explicit deliberation by a small group of readers ( <ref type="bibr" target="#b11">Wan and Xiao, 2008)</ref>. A minority of test collections provide multiple opinions per document, but even then the amount of opinions per document is kept minimal <ref type="bibr">(Nguyen and Kan, 2007</ref>).</p><p>The traditional procedure for supervised keyphrase extraction is reformulating the task as a binary classification of keyphrase candidates. Supervision for keyphrase extraction faces several shortcomings. Candidate phrases (generated in a separate candidate generation procedure), which are not annotated as keyphrases, are seen as non-keyphrase and are used as negative training data for the supervised classifiers. First, on many occasions these negative phrases outnumber true keyphrases many times, creating an unbalanced training set ( <ref type="bibr" target="#b5">Frank et al., 1999;</ref><ref type="bibr">Kim et al., 2012)</ref>. Second, as <ref type="bibr" target="#b5">Frank et al. (1999)</ref> noted: authors do not always choose keyphrases that best describe the content of their paper, but they may choose phrases to slant their work a certain way, or to maximize its chance of being noticed by searchers. Another problem is that keyphrases are inherently subjective, i.e., keyphrases assigned by one annotator are not the only correct ones <ref type="bibr">(Nguyen and Kan, 2007)</ref>. These assumptions have consequences for training, developing and evaluating supervised models. Unfortunately, a large collection of annotated documents by reliable annotators with high overlap per document is missing, making it difficult to study disagreement between annotators or the resulting influence on trained extractors, as well as to provide a reliable evaluation setting. In this paper, we address these problems by creating a large test collection of articles with many different opinions per article, evaluate the effect on extraction per- formance, and present a procedure for supervised keyphrase extraction with noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Noisy Training Data for Supervised</head><p>Keyphrase Extraction lected and managed by iMinds -Living Labs 1 ) who were trained to select a limited number of short phrases that concisely reflect the documents' con- tents. No prior limits or constraints were set on the amount, length, or form of the keyphrases. Each document was presented multiple times to different users. Each user was assigned with 140 articles, but was not required to finish the full assignment. The constructed training collections have on average six and up to ten different opinions per article. We visualize the agreement on single keyphrases in <ref type="figure" target="#fig_0">Figure 1</ref>, which shows the fraction of annotated keyphrases versus agreement by the complete set of readers. Agreement on keyphrases appears low, as a large fraction of all keyphrases assigned to doc- uments (&gt;50%) are only assigned by single annota- tors. We note that different sets of keyphrases by dif- ferent annotators are the result of the subjectiveness of the task, of different interpretations by the anno- tators of the document, but also because of seman- tically equivalent keyphrases being annotated in dif- ferent forms, e.g., "Louis Michel" vs. "Prime Min- ister Louis Michel" or "Traffic Collision" vs. "Car Accident".</p><p>The observation in <ref type="figure" target="#fig_0">Figure 1</ref> has important con- sequences for training models on keyphrases anno- tated by a single annotator, since other annotators may have chosen some among the ones that the sin-gle selected annotator did not indicate (and hence these should not be used as negative training data).</p><p>A single annotator assigning keyphrases to 100 documents results on average in a training set with 369 positive training instances and 4,981 negative training instances generated by the candidate ex- tractor. When assigning these 100 documents to 9 other annotators, the amount of positive instances in- creases to 1,258 keyphrases, which means that labels for 889 keyphrase candidates, or 17% of the original negative candidates when training on annotations by a single annotator, can be considered noise and rela- beled. As a result, ratios of positive to negative data also change drastically. We visualize the effect of using training data from multiple annotators per doc- ument in <ref type="figure">Figure 2</ref>. Classifiers trained on the aggre- gated training collection with multiple opinions (us- ing all assigned keyphrases at least once as positive training data) perform better on held-out test collec- tions containing only keyphrases of high agreement (assigned by &gt; 2 annotators). When using keyphrases from many different an- notators per document, the amount of positive can- didates increases and as a result, the Macro Average F 1 (MAF 1 ) of the corresponding classifier. We de- tail our experimental setup and supervised classifier in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Reweighting Keyphrase Candidates</head><p>Observations described in Section 2 indicate that unlabeled keyphrase candidates are not reliable as negative examples by default. A more suitable as- sumption is to treat supervised keyphrase extraction as Positive Unlabeled Learning, i.e., an incomplete set of positive examples is available as well as a set of unlabeled examples, of which some are positive and others negative. This topic has received much attention as it knows many applications ( <ref type="bibr" target="#b9">Ren et al., 2014;</ref><ref type="bibr">du Plessis et al., 2014</ref>), but has not been linked to supervised keyphrase extraction. We base our ap- proach on work by <ref type="bibr" target="#b4">Elkan and Noto (2008)</ref> and mod- ify the supervised extractor by assigning individual weights to training examples. Instead of assuming the noise to be random, we assign weights depend- ing on the document and the candidate.</p><p>By reweighting importance of training samples, we seek to mimic the case of multiple annotators, to  Positive examples are given unit weight and unla- beled examples are duplicated; one copy of each un- labeled keyphrase candidate x is made positive with weight w(x) = P (keyphrase|x, s = 0) and the other copy is made negative with weight 1 − w(x) with s indicating whether x is labeled or not.</p><p>Instead of assigning this weight as a constant fac- tor of the predictions by the initial classifier as in <ref type="bibr" target="#b4">Elkan and Noto (2008)</ref>, we found that two modifica- tions allow improving the weight estimate, w(x) ≤ 1. We normalize probabilities P (keyphrase, x, s = 0) to candidates not included in the initial set of keyphrases per document. Next to this self- predicted probability, we include a simple mea- sure indicating pairwise coreference between unla- beled candidates and known keyphrases in a func- tion Coref(candidate, keyphrase) ∈ {0, 1}, re- turning 1 if one of the binary indicator features, pre- sented in <ref type="bibr" target="#b0">(Bengtson and Roth, 2008)</ref> and shown in <ref type="table">Table 1</ref>, is present. In this description, the term head means the head noun phrase of a candidate or keyphrase and the extent is the largest noun phrase headed by the head noun phrase. The self-predicted probability is summed with the output of the coref- erence resolver and the final weight becomes:</p><formula xml:id="formula_0">w(x) =min 1, P (keyphrase|x) max (x ,s=0)∈d P (keyphrase|x )</formula><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+ max ∀keyphrase∈d</head><p>Coref(x, keyphrase)</p><p>with d being a document from the training collec- tion.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>Hasan and Ng (2010) have shown that techniques for keyphrase extraction are inconsistent and need to be tested across different test collections. Next to our collections with multiple opinions (On- line News and Lifestyle Magazines), we apply the reweighting strategy on test collections with sets of author-assigned keyphrases: two sets from Cite- Seer abstracts from the World Wide Web Conference (WWW) and Knowledge Discovery and Data Min- ing (KDD), similar to the ones used in <ref type="bibr">(Bulgarov and Caragea, 2015)</ref>. The Inspec dataset is a collec- tion of 2,000 abstracts commonly used in keyphrase extraction literature, where we use the ground truth phrases from controlled vocabulary <ref type="bibr" target="#b7">(Hulth, 2003)</ref>. Descriptive statistics of these test collections are given in <ref type="table" target="#tab_2">Table 2</ref>.</p><p>We use a rich feature set consisting of statis- tical, structural, and semantic properties for each candidate phrase, that have been reported as ef- fective in previous studies on supervised extrac- tors ( <ref type="bibr" target="#b5">Frank et al., 1999;</ref><ref type="bibr" target="#b7">Hulth, 2003;</ref><ref type="bibr">Kim and Kan, 2009</ref>): (i) term frequency, (ii) number of tokens in the phrase, (iii) length of the longest term in the phrase, (iv) number of capital letters in the phrase, (v) the phrase's POS-tags, (vi) rel- ative position of first occurrence, (vii) span (rela- tive last occurrence minus relative first occurrence), (viii) TF*IDF (IDF's trained on large background collections from the same source) and (ix) Topical Word Importance, a feature measuring the similar- ity between the word-topic topic-document distribu- tions presented in ( <ref type="bibr" target="#b10">Sterckx et al., 2015)</ref>, with topic models trained on background collections from a corresponding source of content.</p><p>As classifier we use gradient boosted decision trees implemented in the XGBoost package <ref type="bibr" target="#b2">(Chen and Guestrin, 2016)</ref>. During development, this clas- sifier consistently outperformed Naive Bayes and linear classifiers like logistic regression or support vector machines.</p><p>We compare the reweighting strategy with uni- form reweighting and strategies to counter the im- balance or noise of the training collections, such as subsampling, weighting unlabeled training data as in <ref type="bibr" target="#b4">(Elkan and Noto, 2008)</ref>, and self-training in which only confident initial predictions are used as positive and negative data. For every method, global thresh- olds are chosen to optimize the macro averaged F 1 per document (MAF 1 ). Next to the threshold sensi- tive F 1 , we report on ranking quality using the Pre- cision@5 metric.</p><p>Results are shown in <ref type="table" target="#tab_3">Table 3</ref> with five-fold cross- validation. To study the effect of reweighting, we limit training collections during folds to 100 docu- ments for each test collection. Our approach consis- tently improves on single annotator trained classi- fiers, on one occasion even outperforming a training collection with multiple opinions. Compensating for imbalance and noise tends to have less effect when the ratio of keyphrases versus candidates is high (as for Inspec) or training collection is very large. When the amount of training documents increases, the ra- tio of noisy versus true negative labels drops.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>It has been suggested that keyphrase annotation is highly subjective. We present two data sets where we purposely gathered multiple annotations of the same document, as to quantify the lim- ited overlap between keyphrases selected by differ- ent annotators. We suggest to treat non-selected phrases as unlabeled rather than negative training data. We further show that using multiple anno- tations leads to more robust automatic keyphrase extractors, and propose reweighting of single an- notator labels based on probabilities from a first- stage classifier. This reweighting approach outper- forms other single-annotator state-of-the-art auto- matic keyphrase extractors on different test collec- tions, when we normalize probabilities per docu- ment and include co-reference indicators.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: This plot shows the fraction of all keyphrases from the training set agreed upon versus the fraction of all annotators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>A</head><label></label><figDesc>Figure 2: Effect of overlap on extraction performance.</figDesc><graphic url="image-1.png" coords="2,313.20,57.82,226.79,170.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Feature</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>head keyphrase ) == head candidate Table 1: String relation features for coreference res- olution</head><label></label><figDesc>Definition Head match head keyphrase == head candidate Extent match extent keyphrase == extent candidate Substring head keyphrase substring of head candidate Alias acronym(</figDesc><table>model the uncertainty of negative keyphrase candi-
dates, based only on annotations by a single annota-
tor. In a first stage, we train a classifier on the single 
annotator data and use predictions on the negative or 
unlabeled candidates, to reweigh training instances. 
The reweighted training collection is then used to 
train a second classifier to predict a final ranking or 
the binary labels of the keyphrase candidates. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Description of test collections.</head><label>2</label><figDesc></figDesc><table>Method 
Online News 
Lifestyle Magazines 
WWW 
KDD 
Inspec 
MAF 1 
P@5 
MAF 1 
P@5 
MAF 1 
P@5 
MAF 1 
P@5 
MAF 1 
P@5 
Single Annotator 
.364 
.416 
.294 
.315 
.230 
.189 
.266 
.200 
.397 
.432 
Multiple Annotators 
.381 
.426 
.303 
.327 
/ 
/ 
/ 
/ 
/ 
/ 
Self Training 
.366 
.417 
.301 
.317 
.236 
.190 
.269 
.196 
.401 
.434 
Reweighting (Elkan and Noto, 2008) 
.364 
.417 
.297 
.313 
.238 
.189 
.275 
.201 
.401 
.429 
Reweighting +Norm +Coref 
.374 
.419 
.305 
.322 
.245 
.194 
.275 
.200 
.402 
.434 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Mean average F 1 score per document and precision for five most confident keyphrases on different 
test collections. 

</table></figure>

			<note place="foot" n="1"> https://www.iminds.be/en/ succeed-with-digital-research/ proeftuinonderzoek/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors like to thank the anonymous review-ers for their helpful comments. The research presented in this article relates to STEAMER (http://www.iminds.be/en/projects/ 2014/07/12/steamer), a MiX-ICON project facilitated by iMinds Media and funded by IWT and Innoviris.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bulgarov and Caragea2015] Florin Adrian Bulgarov and Cornelia Caragea. 2015. A comparison of supervised keyphrase extraction models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bengtson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web Companion</title>
		<meeting>the 24th International Conference on World Wide Web Companion<address><addrLine>Honolulu, Hawaii, USA; Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2008-10" />
			<biblScope unit="page" from="13" to="14" />
		</imprint>
	</monogr>
	<note>Conference on Empirical Methods in Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Citation-enhanced keyphrase extraction from research papers: A supervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Caragea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="1435" to="1446" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guestrin2016] Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<idno>abs/1603.02754</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Keyphrase extraction for summarization purposes: The LAKE system at DUC-2004</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>&amp;apos;avanzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="703" to="711" />
		</imprint>
	</monogr>
	<note>Marthinus Christoffel du Plessis, Gang Niu, and Masashi Sugiyama</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning classifiers from only positive and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Noto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Las Vegas, Nevada, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-08-24" />
			<biblScope unit="page" from="213" to="220" />
		</imprint>
	</monogr>
	<note>Elkan and Noto2008</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nevill-manning. 1999. Domain specific keyphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Joint Conference on AI</title>
		<meeting>the 16th International Joint Conference on AI</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="668" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Conundrums in unsupervised keyphrase extraction: Making sense of the state-of-the-art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ng2010] Kazi Saidul</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd COLING, COLING 2010</title>
		<meeting>the 23rd COLING, COLING 2010<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="365" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Re-examining automatic keyphrase extraction approaches in scientific articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Hulth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on multiword expressions: Identification, interpretation, disambiguation and applications</title>
		<editor>Kim et al.2012] Su Nam Kim, Olena Medelyan, MinYen Kan, and Timothy Baldwin</editor>
		<meeting>the workshop on multiword expressions: Identification, interpretation, disambiguation and applications</meeting>
		<imprint>
			<publisher>December</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="723" to="742" />
		</imprint>
	</monogr>
	<note>Automatic keyphrase extraction from scientific articles</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Supervised topical key phrase extraction of news stories using crowdsourcing, light filtering and co-reference normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Marujo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2012. ELRA. [Nguyen and Kan2007] Thuy Dung Nguyen and Min-Yen Kan</title>
		<meeting>LREC 2012. ELRA. [Nguyen and Kan2007] Thuy Dung Nguyen and Min-Yen Kan</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
	<note>Proceeding of International Conference on Asian Digital Libraries</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Positive unlabeled learning for deceptive reviews detection</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10-25" />
			<biblScope unit="page" from="488" to="498" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Topical word importance for fast keyphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sterckx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web Companion</title>
		<meeting>the 24th International Conference on World Wide Web Companion</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="121" to="122" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Single document keyphrase extraction using neighborhood knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Xiao2008] Xiaojun Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd National Conference on Artificial Intelligence</title>
		<meeting>the 23rd National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="855" to="860" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Finding advertising keywords on web pages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on World Wide Web, WWW &apos;06</title>
		<meeting>the 15th International Conference on World Wide Web, WWW &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="213" to="222" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
