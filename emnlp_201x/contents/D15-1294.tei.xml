<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic recognition of habituals: a three-way classification of clausal aspect</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annemarie</forename><surname>Friedrich</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational Linguistics</orgName>
								<orgName type="institution">Saarland University</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
							<email>{afried,pinkal}@coli.uni-saarland.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational Linguistics</orgName>
								<orgName type="institution">Saarland University</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic recognition of habituals: a three-way classification of clausal aspect</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper provides the first fully automatic approach for classifying clauses with respect to their aspectual properties as habitual, episodic or static. We bring together two strands of previous work, which address only the related tasks of the episodic-habitual and stative-dynamic distinctions, respectively. Our method combines different sources of information found to be useful for these tasks. We are the first to exhaustively classify all clauses of a text, achieving up to 80% accuracy (baseline 58%) for the three-way classification task, and up to 85% accuracy for related subtasks (baselines 50% and 60%), outperforming previous work. In addition , we provide a new large corpus of Wikipedia texts labeled according to our linguistically motivated guidelines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In order to understand the function of a clause within a discourse, we need to know the clause's aspectual properties. The distinction between dy- namic and stative lexical aspect, as in exam- ples (1a) and (1b) respectively, is fundamental <ref type="bibr" target="#b26">(Vendler, 1957)</ref>. Its automatic prediction has been addressed previously ( <ref type="bibr" target="#b21">Siegel and McKeown, 2000;</ref><ref type="bibr" target="#b30">Zarcone and Lenci, 2008;</ref><ref type="bibr" target="#b5">Friedrich and Palmer, 2014</ref>). In this work, we focus on habituality as another fundamental aspectual property. While example (1a) is an episodic sentence, i.e., a sentence ex- pressing information about a particular event, the same dynamic verb can be used to characterize the default behavior of an individual or of a kind in a certain type of situation (2).</p><p>(2) (a) Bill usually drinks coffee after lunch.</p><p>(habitual) (b) Italians drink coffee after lunch.</p><p>(habitual)</p><p>The entailment properties of episodic and ha- bitual (or characterizing) sentences differ substan- tially. Also, they have different functions in dis- course. The episodic event expressed by (1a) is typically embedded in the temporal structure of a narration. The habitual sentence (2a) can be used, e.g., as an explanation (why Bill is still sitting at the table), or in a contrastive context (today, he or- dered a grappa instead). Generic sentences with kind-referring subjects (2b) can also be habitual, generalizing at the same time over typical mem- bers of this kind and over situations in which they typically carry out some action.</p><p>Habitual sentences do not move narrative time, similar to stative clauses such as (1b). <ref type="bibr" target="#b1">Carlson (2005)</ref> considers habituals to be aspectually sta- tive. Since there are clear differences between or- dinary statives such as (1b) and habituals, we ap- ply a three-way distinction for clausal aspect in this work. We classify clauses as one of the three categories habitual, episodic and static. <ref type="bibr">1</ref> Through its impact on entailment properties and temporal discourse structure, the determination of clausal aspect is relevant to various natural lan- guage processing applications requiring text un- derstanding, such as novelty detection <ref type="bibr" target="#b23">(Soboroff and Harman, 2005</ref>), knowledge extraction from text ( <ref type="bibr" target="#b25">Van Durme, 2010</ref>) or question answering ( <ref type="bibr" target="#b13">Llorens et al., 2015)</ref>. Using aspectual informa- tion has been shown to improve temporal relation identification <ref type="bibr" target="#b2">(Costa and Branco, 2012)</ref>.</p><p>Some languages (e.g., Czech or Swahili) have systematic morphological markers of habituality <ref type="bibr" target="#b3">(Dahl, 1985)</ref>. In other languages, there are cues for habituality, such as the simple present in En- glish, and the use of certain adverbials <ref type="bibr" target="#b4">(Dahl, 1995)</ref>. The automatic recognition of habitual sen- tences for the latter languages is non-trivial. The work in this paper targets the English language; we leave recognition of habituality in other lan- guages to future work.</p><p>The only previous work on categorizing sen- tences as episodic or habitual we know of is by <ref type="bibr" target="#b16">Mathew and Katz (2009)</ref>. They do not attempt to categorize arbitrary sentences in 'free text', how- ever, but work with a corpus of selected sentences and use gold standard parse information for their experiments. In particular, they consider clauses containing lexically dynamic verbs only.</p><p>In this work, we address the task of an exhaus- tive classification of all clauses of a text into the three aspectual classes habitual, episodic, and static. Static sentences include lexically stative clauses as well as negated or modalized clauses containing a dynamic main verb. A computa- tional model for identifying episodic and habitual clauses clearly needs to address this third class as well if it is to be applied in a realistic set- ting. Linguistically, the determination of clausal aspect depends on the recognition of the verb's lexical aspectual class (stative or dynamic), and on the recognition of any aspectual markers or transformations, such as use of the perfect tense, negations or modals. Our work builds on re- sults for the related subtasks <ref type="bibr" target="#b16">(Mathew and Katz, 2009;</ref><ref type="bibr" target="#b21">Siegel and McKeown, 2000;</ref><ref type="bibr" target="#b5">Friedrich and Palmer, 2014</ref>), using both context-based and verb- type based information.</p><p>Our major contributions are: (i) We create a cor- pus of 102 Wikipedia texts whose about 10,000 clauses are annotated as episodic, static or habitual with substantial agreement. This corpus allows for studying the range of linguistic phenomena related to the clause types as defined above (compared to previous work which uses only a small set of verbs and sentences), and provides a basis for future re- search. (ii) We provide the first fully automatic ap- proach for this classification task, combining two classification tasks (lexical aspectual class and ha- bituality) that have been treated separately in pre- vious work. For an exhaustive classification of clauses of free text, these two classification tasks need to be addressed jointly. We show two dif- ferent feature sets (verb-type based features and context-based features) to have different impact on the two subtasks, and to be complementary for our full three-way task.</p><p>We reach accuracies of nearly 85% for the two subtasks of identifying static clauses and distin- guishing episodic and habitual clauses (majority class baselines are 60% and 50% respectively). A joint model for the three-way classification task reaches an accuracy of 80% (baseline 60%). In ad- dition, we show that the verb-type based linguis- tic indicator features generalize well across verb types on our tasks: for verbs unseen in the training data, accuracies drop only by 2-5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Theoretical background and annotation guidelines</head><p>In this section, we give an overview of the seman- tic theory related to habituals, at the same time introducing our annotation guidelines for marking clauses as habitual, episodic or static.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Habituality</head><p>Habitual sentences express regularities in terms of generalizations over events and activities. In se- mantic theory, habituals are formally represented using a quantifier-like operator GEN ( <ref type="bibr" target="#b11">Krifka et al., 1995)</ref>:</p><formula xml:id="formula_0">(3) GEN[s](s is an after-dinner situation &amp; Bill is involved in s; Bill drinks a coffee in s)</formula><p>In the semi-formal representation (3) of sen- tence (2a) above, GEN binds a variable s ranging over situations, the first argument restricts the sit- uation type, and the second argument provides the activity that is typically carried out by the protago- nist in the respective situations. The GEN operator is similar to the universal quantifier of predicate logic. However, habitual sentences tolerate excep- tions: (2a) is true even if Bill does not drink a cof- fee after every lunch. Also note that habituals are not restricted to what one would consider a matter of habit; they can also have inanimate subjects, as illustrated by (4). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Clausal and lexical aspectual class</head><p>Clausal aspect is dependent on the lexical aspec- tual class (stative or dynamic), but the two lev- els are essentially different. Dynamic verbs ex- press events or activities (e.g., kill, fix, walk, for- get), while stative verbs express states (e.g., be, like, know, own). The fundamental aspectual class <ref type="bibr" target="#b21">(Siegel and McKeown, 2000</ref>) of a verb in context describes whether it is used in a stative or dynamic sense before any aspectual markers or transforma- tions (such as use of the past/present perfect or modals) have been applied. It is a function of the main verb and a select group of complements (it may differ per verb which ones are important). For example, the fundamental lexical aspectual class of the verb make with the subject Mary and the object cake in <ref type="formula">(5)</ref> is dynamic. English clauses in past or present perfect such as (5) are static, as they focus on the post-state of an event rather than the event itself <ref type="bibr" target="#b9">(Katz, 2003)</ref>. Habituals with verbs of dynamic aspectual class are by far more frequent in our corpus, 2 but there are also instances of stative verbs used in a habit- ual way, as for example (6).</p><p>(6) Sloths sometimes sit on top of branches.</p><p>(habitual, stative lexical aspectual class)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Modality and negation</head><p>Modalized <ref type="formula">(7)</ref> and negated sentences (8) tend to be static: they do not express information about a particular event, but refer to actual or possible states of the world. The above definitions of habituality and stativ- ity are generally agreed upon in literature. How- ever, the interaction of these phenomena is by no means trivial <ref type="bibr" target="#b7">(Hacquard, 2009)</ref>, and required mak- ing some decisions during the design of our an- notation guidelines. Here, we explain these deci- sions, which are all motivated by a clause's entail- ment properties.</p><p>One difficult issue is how to interpret and mark negated sentences such as (9a) whose positive ver- sion (9b) is habitual. Sentence (9a) can be considered either static because of the negation (It is not the case that John smokes), or as habitual because it charac- terizes John's behavior (In any relevant situation, John does not smoke). Both decisions are possible <ref type="bibr" target="#b6">(Garrett, 1998)</ref>, we decide for the latter possibility. This decision is supported by the observation that (9a) is similar in its entailment properties to (10), which due to the frequency adverbial never clearly generalizes over relevant situations (though note that this is not a linguistic test).</p><p>(10) John never smokes. (habitual)</p><p>Likewise, we mark modalized sentences as ha- bitual if they have a strong implicature that an event has actually happened regularly <ref type="bibr" target="#b7">(Hacquard, 2009)</ref>, as in <ref type="formula">(11)</ref>. In contrast, <ref type="formula">(7)</ref> is static as it does not imply that Mary actually swims regularly.</p><p>(11) I had to eat an apple every day. (habitual)</p><p>The above example shows that modality and ha- bituality are interweaved and sometimes hard to identify. Nevertheless, we reach substantial agree- ment in the annotation of our corpus (see Sec- tion 4.2).</p><p>Finally, some habituals have a dispositional reading, indicating ability/capability <ref type="bibr">(MenéndezBenito, 2012</ref>). Example (12) can be paraphrased by <ref type="bibr">(13)</ref>, as it does not indicate that the car is ac- tually driven this fast regularly, it only states its maximum speed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related work</head><p>The task of predicting fundamental aspectual class aims to determine whether the verb is used in a stative or dynamic sense. This task predicts the aspectual class of a verb in context before any aspectual markers or transformations (such as use of the perfect or modals) have been applied. <ref type="bibr" target="#b21">Siegel and McKeown (2000)</ref> propose the use of linguis- tic indicators (explained in Section 5.2); <ref type="bibr" target="#b5">Friedrich and Palmer (2014)</ref> show the importance of us- ing context-based features in addition. <ref type="bibr" target="#b30">Zarcone and Lenci (2008)</ref> classify occurrences of 28 Italian verbs according to Vendlers classes state, process, accomplishment and achievement. <ref type="bibr" target="#b16">Mathew and Katz (2009)</ref> address the problem of 'supervised categorization for habitual versus episodic sentences' . The authors randomly select 1052 sentences for 57 verbs from the Penn Tree- Bank ( <ref type="bibr" target="#b15">Marcus et al., 1993)</ref> and manually mark them with regard to whether they are habitual or episodic. They focus on verbs that are lexically dynamic and discuss a variety of syntactic fea- tures, which they extract from gold standard parse trees. Their aim is to study the ability of syntactic features alone to identify habitual sentences.</p><p>Xue and Zhang <ref type="formula">(2014)</ref> annotate verbs with the four event types habitual event, state, on-going event and episodic event with the aim of improv- ing tense prediction for Chinese. Recent related work <ref type="bibr" target="#b28">(Williams, 2012;</ref><ref type="bibr" target="#b27">Williams and Katz, 2012)</ref> extracts typical durations (in term of actual time measures) for verb lemmas from Twitter. They distinguish episodic and habitual uses of the verbs, using the method of <ref type="bibr" target="#b16">Mathew and Katz (2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>In this section, we describe the data sets used in our experiments. <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Penn TreeBank (M&amp;K) data set</head><p>Mathew and Katz (2009) randomly select sen- tences for several verbs from the WSJ and Brown corpus sections of the Penn Treebank. They re- quire the verb to be lexically dynamic. Sentences are marked as habitual or episodic, further de- tails on the annotation guidelines are not specified. Their data set contains 2743 annotated sentences for 239 distinct verb types. Mathew and Katz re- move verb types with highly skewed distributions of labels, but their filtered data set is not available. We follow their filtering approach, but we could not replicate their filtering step. Our final data set contains 1230 sentences for 54 distinct verb types. <ref type="bibr" target="#b16">Mathew and Katz (2009)</ref> state that their data set comprises 1052 examples for 57 verb stems. We aimed at producing a similar distribution of la- bels: our data set contains 73.3% episodic cases, M&amp;K's version has 73.1%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Wikipedia corpus</head><p>We select 102 texts from a variety of domains from Wikipedia, as we expect an encyclopedia to con- tain many habitual sentences. We use the dis- course parser SPADE (Soricut and Marcu, 2003) <ref type="bibr">3</ref> All data sets are freely available from www.coli.uni-saarland. <ref type="bibr">de</ref>  <ref type="table">Table 1</ref>: Wikipedia data, distribution of labels for clausal aspect.</p><p>to automatically segment the first 70 sentences of each article into clauses. A clause is approxi- mately defined as a finite verb phrase. Each clause is then labeled as static, episodic or habitual. De- tails on our annotation scheme have been given in Section 2. Annotators are allowed to skip non- finite clauses (e.g., headlines only containing a noun phrase). This happened in about 14% of all pre-segmented clauses. The final Wikipedia data consists of 10355 labeled clauses. <ref type="table">Table 1</ref> gives statistics for the distribution of labels.</p><p>The data set was labeled by three paid annota- tors, all students of computational linguistics. An- notators were given a written manual and a short training on documents not included in the corpus. Agreement on the Wikipedia data is 0.61 in terms of Fleiss' κ, which indicates substantial agreement ( <ref type="bibr" target="#b12">Landis and Koch, 1977)</ref>. The gold standard that we use in our experiments is constructed via ma- jority voting. The gold standard contains the cases where at least two annotators agreed on the label. We found only 86 cases where all annotators dis- agree, and manual inspection shows that most of these cases are related to disagreements on the lex- ical aspectual class that coincide with an attention slip by one of the annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Method</head><p>In this section, we describe our computational models for determining clausal aspect. <ref type="table" target="#tab_2">Table 2</ref> shows the syntactic-semantic features, which we call CONTEXT-BASED as they are ex- tracted from the context of each verb occurrence that we classify. This feature set comprises the features proposed by <ref type="bibr" target="#b16">Mathew and Katz (2009)</ref> and the ones proposed by <ref type="bibr" target="#b5">Friedrich and Palmer (2014)</ref>. In addition, we use the features modal and negated. We extract these features from syn- tactic dependency parses created using the Stan- ford parser ( <ref type="bibr" target="#b10">Klein and Manning, 2002</ref>  vided by <ref type="bibr" target="#b14">Loaiciga et al. (2014)</ref>. The values of the grammatical dependents' features are the Word- Net <ref type="bibr" target="#b19">(Miller, 1995)</ref> lexical filename of the depen- dent's lemma, or, if not available, the dependent's part-of-speech tag. Quantificational adverbs are temporal modifiers such as always, occasionally or weekly. <ref type="bibr">4</ref> Specific temporal adverbs are, ac- cording to a heuristic proposed by <ref type="bibr" target="#b17">Mathew (2009)</ref>, phrase children marked with the part-of-speech tag TMP and whose child is a prepositional phrase. Noun phrases with one of the determiners the, this, that, these, those, each, every, all, as well as pos- sessives, pronouns, proper names and quantified phrases are definite. NPs with determiners a, an, many, most, some, and cases of modifying adjec- tives without determiners (e.g., few) or cardinal numbers (part-of-speech tag CD) are indefinite. Mathew (2009) describes their features in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">CONTEXT-BASED features</head><note type="other">true, false indefinite* true, false object absent* true, false bare plural* true, false definite* true, false indefinite* true, false grammatical dependents † WordNet lexname/POS sentence modal would, can,... negated true, false conditionals* presence of clause starting with if/when/ whenever temporal specific, quantificational, modifiers* including used to and would (where no if) prepositions* at / in / on (3 features, true/false)</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">TYPE-BASED features</head><p>This feature set consists of the verb-type based linguistic indicator features of Siegel and McKe- own (2000). The computation of these features is based on a large parsed, but otherwise un- annotated background corpus. For each verb type (i.e., lemma), these features count how often the verb occurs with each of the linguistic indicators as listed in <ref type="table" target="#tab_3">Table 3</ref>. Except for the frequency fea- ture, these values are normalized by the number of occurrences of the verb type. For example, if the verb type win occurs 1000 times in the parsed background corpus, of which 100 times with per- fect aspect, the value of the linguistic indicator feature perfect is 0.1 for the verb type win. For any instance whose verb's lemma is win, 0.1 will be the value of the feature perfect, in other words, all instances of the same verb type receive the same TYPE-BASED feature values. Linguis- tic indicator features have recently been applied successfully on the related task of classifying the lexical aspectual class of verbs by <ref type="bibr" target="#b5">Friedrich and Palmer (2014)</ref>, who extract the linguistic indica- tors from an automatically parsed version of the AFE and XIE parts of Gigaword. We use their database of linguistic indicator values. <ref type="bibr">5</ref> </p><note type="other">Feature Example Feature Example frequency - continuous continually present says adverb endlessly past said evaluation better future will say adverb horribly perfect had won manner furiously progressive is winning adverb patiently negated not/never temporal again particle up/in/... adverb finally no subject - in-PP in an hour for-PP for an hour</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Algorithm</head><p>In order to investigate in which circumstances the task of predicting a clause's label (habitual, episodic or static) can be addressed jointly, or whether a pipelined approach is better, we ap- ply the following methods. Our JOINT model learns the decision boundaries for the three classes jointly, i.e., as a three-way classification task. In addition, we present a CASCADED model, which uses two models learned for the two different sub- tasks: (a) identifying static clauses and (b) distin- guishing episodic and habitual clauses. First, we train a model to distinguish the static class from the other two. In this learning step, we simply map all the clauses labeled as episodic and habitual to the class non-static and learn the deci- sion boundary between the two classes static and non-static. Second, we train a model to distin- guish the episodic from the habitual class. This model is trained on the subset of examples labeled with either of these two classes.</p><p>In the CASCADED model, first, the static vs. non-static model is applied. The CASCADED model labels all instances automatically labeled as static in this first step, and then applies the second model (episodic vs. habitual) on all remaining instances.</p><p>We train Random Forest classifiers <ref type="bibr" target="#b0">(Breiman, 2001</ref>) using Weka ( <ref type="bibr" target="#b8">Hall et al., 2009</ref>) for each step and also for the JOINT model. Besides provid- ing a robust performance, Random Forest classi- fiers can easily deal with both categorical and nu- meric features. This is relevant as our CONTEXT- BASED features are categorical while the TYPE- BASED features are numeric. In our experiments, we will compare the impact of the different feature sets on each subtask and on the JOINT model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Baseline: Mathew and Katz (2009)</head><p>As a baseline, we also report results for the subset of our CONTEXT-BASED features used by <ref type="bibr" target="#b16">Mathew and Katz (2009)</ref> and call this subset MK. <ref type="bibr" target="#b16">Mathew and Katz (2009)</ref> find a J48 decision tree and a Naive Bayes classifier to work best. We replicate their results for the decision tree in Section 6.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments and discussion</head><p>This section describes our experiments. First, we reproduce the experiments of <ref type="bibr" target="#b16">Mathew and Katz (2009)</ref>, who use manually created syntactic parses, in a purely automatic setting.</p><p>The data set and experiments of Mathew and Katz (2009) focus on the episodic-habitual distinc- tion using a set of sentences selected for a small set of verbs, and their feature design focuses on syn- tactic properties of the clauses found in this an- notated data set. In the further experiments, we turn to the Wikipedia data, which contains annota- tions for full texts. We expect the Wikipedia data to cover the range of habitual and episodic expres- sions more fully, and in addition, allows for study- ing the task of separating static sentences from the other two classes. As we will show, this latter task profits from including features relevant to the stative-dynamic distinction on the lexical level.</p><p>We first present experimental results for the two subtasks (described in Section 5.3). Our CAS- CADED model first identifies static clauses, and then classifies the remaining clauses as episodic or habitual. For reasons of readability, we first report on our experiments for the episodic-habitual dis- tinction using both the M&amp;K and Wikipedia data sets. Using the Wikipedia data, we then report on the results for the static vs. non-static distinction. Finally, we turn to the full task of the three-ways distinction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental setting</head><p>We report results for 10-fold cross validation (CV) with two different settings: In the RANDOM CV setting, we randomly distribute the instances over the folds, putting all instances of one document into the same fold. In the UNSEEN VERBS CV setting, we simulate the case of not having labeled training data for a particular verb type by putting all instances of one verb type into the same fold. We compute the information retrieval statistics of precision (P), recall (R) and F1-measure per class, where F1 is the harmonic mean of P and R, F 1 = 2 * P * R P +R . Macro-average P is computed as the (unweighted) average of the P scores of the classes, and macro-average R is computed like- wise. Macro-average F1 is the harmonic mean of macro-average P and macro-average R. We use McNemar's test with p &lt; 0.01 to compute statis- tical signficance of differences in accuracies. In our tables, we indicate that two results differ sig- nificantly by marking them with the same symbols (we only show this when scores are close).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">M&amp;K data: episodic vs. habitual</head><p>We use Weka's 10-fold stratified cross validation and a J48 decision tree in the experiments reported in this section in order to replicate their experi- mental setting. Results are shown in <ref type="table">Table 4</ref>. For the sake of completeness, we also show the results as presented in the original paper. F1-scores are computed from P and R as reported in the orig- inal paper. Note that their experiments are per- formed on a different subset of the data and so these numbers are not directly comparable to ours, but our subset has a very similar class distribution (see Section 4.1). Our accuracies based on auto- matic parses rather than gold standard parses are about 3% lower when using the original feature set (MK). We conclude that our results are in the expected range. Also, we do not find any signifi- cant improvements on this data set when using any other feature sets or combinations thereof (the ta- ble shows the results for our CONTEXT-based fea- ture set); the M&amp;K feature set designed for this corpus captures its variation well.</p><p>We have used a J48 decision tree in this section for comparability with previous work. In all fol- lowing sections, we present results using Random Forest classifiers as described in Section 5.3.  <ref type="table">Table 4</ref>: Results for episodic vs. habitual, J48 decision tree, data from <ref type="bibr" target="#b16">Mathew and Katz (2009)</ref>. *Numbers from original paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Wikipedia: episodic vs. habitual</head><p>We study the classification task of distinguishing episodic and habitual sentences using the subset of the Wikipedia data having one of these two la- bels (4171 instances). This task parallels the ex- periment of Mathew and Katz (2009) described above. We conduct two experiments, once using the RANDOM CV setting and once using the UN- SEEN VERBS setting. <ref type="table" target="#tab_6">Table 5</ref> shows the results. The distribution of instances is nearly 50:50 in the gold standard (see Section 4, <ref type="table">Table 1</ref>), and the ma- jority classes in the respective training folds differ (this is the reason for the different baseline scores). For reasons of space we do not show the other scores here; macro-average F1-scores have (al- most) the same values as accuracy, the F1-scores for episodic and habitual are similar to each other in each case.</p><p>Our findings are as follows: TYPE-BASED features outperform the majority class baseline,   which means that some verbs have a preference for being used as either episodic or habitual. The CONTEXT-BASED features work remarkably well. If training data of the same verb type is available, adding the TYPE-BASED features or the lemma to the CONTEXT-BASED features results in improve- ments; this is not the case in the UNSEEN VERBS setting. The latter setting shows that the additional contextual features (compared to the MK subset) are important: our corpus indeed covers a broader range of phenomena than the M&amp;K data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Wikipedia: static vs. non-static</head><p>We evaluate the task of classifying static ver- sus non-static clauses using all 10355 instances of the Wikipedia data set. Any instance la- beled episodic or habitual receives the label non- static both in training and testing. Results of this task are shown in <ref type="table" target="#tab_7">Table 6</ref>. For this subtask, the CONTEXT-BASED features are less informa- tive than the TYPE-BASED features. Again, us- ing lemma information approximates the use of type-based information, but this is not an option in the UNSEEN VERBS setting. A combination of the CONTEXT-BASED and TYPE-BASED features achieves the best results. <ref type="bibr" target="#b5">Friedrich and Palmer (2014)</ref> find that TYPE-BASED features generalize well across verb types when predicting the aspec- tual class of verbs in context, the same is true here. They achieve small improvements by adding context-based features. Predicting the lexical as- pectual class of the clause's main verb is only part of our classification task, the static class includes not only lexically stative clauses but also clauses with lexically dynamic verbs that are stativized, e.g., modals, negation or perfect tense. Hence, as expected, in our task, adding the CONTEXT- BASED features results in a considerable perfor- mance improvement (5-7% absolute in accuracy).  <ref type="table">Table 7</ref>: Wikipedia: static vs. episodic vs. habitual. 10355 instances, 10-fold cross validation. The CASCADED model uses the best models from <ref type="table" target="#tab_7">Table 6</ref> and <ref type="table" target="#tab_6">Table 5</ref>. * † ‡ ** differences statistically significant.</p><p>It is worth noting that even for verbs not seen in the training data, high accuracies and F1-scores of almost 80% can be reached.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Wikipedia: combined task</head><p>In this section, we describe our experiments for the three-way classification task of static, episodic and habitual clauses, as in a realistic classification setting, a clause may belong to either of these three classes. We investigate whether a pipelined CAS- CADED approach is better, or whether the JOINT model profits from learning the decision bound- aries between all three classes jointly. The results for this task are presented in <ref type="table">Table 7</ref>. Both the CONTEXT-BASED and the TYPE-BASED features when used alone improve over the majority class baseline by about 10% in accuracy in the RAN- DOM CV setting, and only by about 4% in the UN- SEEN VERBS setting. In the latter setting, all fea- ture sets when used alone are ineffective for identi- fying habituals. This indicates that the CONTEXT- BASED features only 'pick up' on some type-based information in the RANDOM CV case. The best models for this JOINT classification task use both the CONTEXT-BASED and the TYPE-BASED fea- ture sets: F1-scores and accuracy increase remark- ably. Again, in the RANDOM CV setting, using the lemma results in a large performance gain, though using the TYPE-BASED features is benefi- cial, and, in the UNSEEN VERBS setting, essential.</p><p>We apply the CASCADED model as described in Section 5.3, training and testing the models for the subtasks in each fold. In the RANDOM CV set- ting, the accuracy of the CASCADED approach is not significantly better than the one of the JOINT approach, though F1-scores for the less frequent episodic and habitual classes both increase. In the UNSEEN VERBS setting, however, the differ- ence is remarkable: macro-average F1-score in- creases by almost 5% (absolute) and accuracy in- creases by 2.2%. Most notably, the F1-score for the habitual class increases from 0.31 to 0.50 (due to an increase in recall). To conclude, the CAS- CADED approach is favorable as it works more ro- bustly both for verb types seen or unseen in the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Feature ablation</head><p>In the above sections, we have compared the two major feature groups of CONTEXT-BASED and TYPE-BASED features. In addition, we ablate each single feature from the best results for each exper- iment. For all classification tasks, we found fea- tures reflecting tense and grammatical aspect to be most important, both for the CONTEXT-BASED and TYPE-BASED features. In general, we observe that no single feature has a big impact on the re- sults, accuracy drops only by at most 1-2%. This shows that our feature set is quite robust and some of the features (e.g., part-of-speech tag of the verb and tense) reflect partially redundant information. However, using only the best features results in a significant performance drop by several percent- age points in the various settings, which means that though single features may not have a large impact, overall, the models for this classification task profit from including many diverse features.</p><p>For the episodic-habitual distinction in the UNSEEN VERBS setting, the definiteness of the object was an important CONTEXT-BASED fea- ture. In the static vs. non-static task, the subject also plays an important role, as well as the TYPE- BASED feature for continuous adverbs. In the UN- SEEN VERBS setting, many TYPE-BASED features are important, including those indicating how of- ten the verb type occurs with adverbs of manner, negation and in-PPs in the background corpus. For the combined three-way task, we found the main verb's lemma and the direct object to have most impact. Of the TYPE-BASED features, the for-PP, present and temporal adverbial were most important. In the UNSEEN VERBS setting, many linguistic indicator features (among others past, progressive, negation) play a greater role, as well as information about the object, subject and tense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we have presented an approach for classifying the aspect of a clause as habitual, episodic or static. Clearly, when exhaustively classifying all clauses of a text, the static class cannot be ignored; we have shown that we can sep- arate these instances from episodic and habitual instances, most of which are lexically dynamic, with high accuracy. Our model for distinguishing episodic and habitual sentences integrates a wide range of contextual information and outperforms previous work. Previous work has only addressed the classification of lexical aspectual class and the automatic distinction of episodic and habitual sen- tences. Our work is the first bringing together two strands of work relevant to classifying clausal as- pect, and we have shown that sources of informa- tion relevant to these two underlying aspectual dis- tinctions are relevant for our three-way classifica- tion task.</p><p>We have shown that for distinguishing static sentences from the other two, TYPE-BASED and CONTEXT-BASED information is needed; for distinguishing episodic and habitual clauses, CONTEXT-BASED features are most important. Our experimental results show that the three-way classification task is most effectively approached by combining both contextual and verb-type based information. Especially for verbs unseen in the training data, we found the CASCADED approach to work better. It is hard for the JOINT approach to identify habitual clauses; while in the CASCADED approach, performance for both steps is high and adds up.</p><p>We found the overall performance of this task to be about 80% accuracy, and 75% macro-average F1-score. These scores suggest that this method may be usable as a preprocessing step for further temporal processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Future work</head><p>Our models do not yet take discourse information into account. Consider example <ref type="formula">(14)</ref> by <ref type="bibr" target="#b16">Mathew and Katz (2009)</ref>: The second sentence is habitual, but the only indicator for this is sentence-external.</p><p>(14) John rarely ate fruit. He just ate oranges.</p><p>(habitual)</p><p>In some preliminary experiments, we tried to leverage the discourse context of a clause for its classification by means of incorporating the gold standard label of the previous clause as a feature. This did not result in significant performance im- provements. However, further experiments trying to incorporate discourse information are due, and, due to our new corpus of fully annotated texts, now possible.</p><p>Another related research direction is the clas- sification of the different types of static clauses, e.g., the different senses of modality <ref type="bibr" target="#b20">(Ruppenhofer and Rehbein, 2012)</ref>. As mentioned before, a finer classification of the temporal structure of clauses is needed, among others identifying the lexical as- pectual class as well as viewpoint aspect as perfec- tive vs. imperfective <ref type="bibr" target="#b22">(Smith, 1997)</ref>.</p><p>Finally, the next steps in this line of research are to integrate the aspectual information attributed to clauses by our model into models of temporal dis- course structure, which in turn are useful for infor- mation extraction and text understanding tasks in general. <ref type="bibr" target="#b2">Costa and Branco (2012)</ref> are the first to show that aspectual information is relevant here; we hope to show in the future that temporal pro- cessing profits from integrating more fine-grained aspectual information.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 1 )</head><label>1</label><figDesc>(a) Bill drank a coffee after lunch. (dynamic) (b) Bill likes coffee. (stative)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 4 )</head><label>4</label><figDesc>Glass breaks easily. (habitual)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 5 )</head><label>5</label><figDesc>Mary has made a cake. (static)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 7 )</head><label>7</label><figDesc>Mary can swim. (static) (8) Mary didn't go swimming yesterday. (static)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>( 9 )</head><label>9</label><figDesc>(a) John does not smoke. (habitual) (b) John smokes. (habitual)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>( 12 )</head><label>12</label><figDesc>This car goes 200 kph. (13) This car can go 200 kph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>/projects/sitent. We thank Thomas A. Mathew and Graham Katz for allowing us to publish their data set.</figDesc><table>Label 
# 
% 

static 
6184 59.7 
episodic 
2114 20.4 
habitual 
2057 19.9 
total 
10355 
-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>). Tense and voice are extracted following the rules pro-</figDesc><table>Feature 

Values 
verb 
tense* † 
past, present, infinitive 
pos † 
VB, VBG, VBN, ... 
voice † 
active, passive 
aspect 
progressive* † true, false 
perfect* † 
true, false 
subject 
bare plural* 
true, false 
definite* 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>CONTEXT-BASED features. Used by: 
*Mathew and Katz (2009),  †Friedrich and Palmer 
(2014). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>TYPE-BASED feature set (linguistic indi-
cators) and examples for lexical items associated 
with each indicator, following Siegel and McKe-
own (2000). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Wikipedia: Accuracy of episodic vs ha-
bitual, 4171 instances, 10-fold cross validation, 
* † ‡differences statistically significant. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Wikipedia: static vs non-static. All 
10355 instances, 10-fold cross validation.* † ‡ dif-
ferences statistically significant. 

</table></figure>

			<note place="foot" n="1"> For clarity, we use the label static for the clausal aspect of non-episodic and non-habitual sentences. We reserve stative, which is more common in the literature, for the lexical aspectual class.</note>

			<note place="foot" n="2"> The distribution of lexical aspectual class of verbs is generally skewed towards dynamic (Friedrich and Palmer, 2014).</note>

			<note place="foot" n="4"> The complete list of quantificational adverbs used is given by Mathew (2009), page 36.</note>

			<note place="foot" n="5"> www.coli.uni-saarland.de/projects/ sitent</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers, Alexis Palmer, Alessandra Zarcone and Andrea Horbach for their helpful comments related to this work, Graham Katz for providing us with their data set, and our annotators Christine Bocionek, Kleio-Isidora Mavridou and Melissa Peate Sørensen. This research was supported in part by the Clus-ter of Excellence "Multimodal Computing and Interaction" of the German Excellence Initiative (DFG), and the first author is supported by an IBM PhD Fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Random forests. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Encyclopedia of Language and Linguistics, chapter Generics, Habituals and Iteratives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Carlson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Aspectual type and temporal relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">António</forename><surname>Branco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="266" to="275" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Tense and aspect systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">¨ Osten</forename><surname>Dahl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<pubPlace>Oxford, Blackwell</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The marking of the generic/episodic distinction in tense-aspect systems. The generic book</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">¨ Osten</forename><surname>Dahl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="412" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic prediction of aspectual class of verbs in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annemarie</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Baltimore, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On the origin of auxiliary do</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Garrett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>English Language and Linguistics</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="283" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the interaction of aspect and modal auxiliaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentine</forename><surname>Hacquard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistics and Philosophy</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="279" to="315" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The WEKA data mining software: an update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD explorations newsletter</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On the stativity of the English perfect. Perfect explorations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="205" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast exact inference with a factored model for natural language parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Genericity: An introduction. The generic book</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Krifka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlson</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pelletier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Jeffry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Ter Meulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gennaro</forename><surname>Chierchia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Godehard</forename><surname>Link</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="1" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">biometrics</title>
		<imprint>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">SemEval-2015 Task 5: QA TEMPEVAL-Evaluating Temporal Information Understanding with Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Llorens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Workshop on Semantic Evaluation</title>
		<meeting><address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">English-French Verb Phrase Alignment in Europarl</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharid</forename><surname>Loaiciga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Popescubelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Mitchell P Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Supervised categorization for habitual versus episodic sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><forename type="middle">E</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth Midwest Computational Lingustics Colloquium</title>
		<meeting><address><addrLine>Bloomington, Indiana. Indiana University</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Master&apos;s thesis, Faculty of the Graduate School of Arts and Sciences of Georgetown University</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Mathew</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Supervised categorization for habitual versus episodic sentences</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">On dispositional sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paula</forename><surname>Menéndez-Benito</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Genericity</publisher>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page">276</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Yes we can!? annotating the senses of english modal verbs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Rehbein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the 8th International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="24" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning methods to combine linguistic indicators: Improving aspectual classification and revealing linguistic insights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="595" to="628" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Parameter of Aspect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlota</forename><forename type="middle">S</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Linguistics and Philosophy</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<date type="published" when="1997" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Novelty detection: The trec experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing<address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sentence level discourse parsing using syntactic and lexical information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="149" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Extracting implicit knowledge from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Benjamin D Van Durme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>University of Rochester</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Linguistics in Philosophy, chapter Verbs and Times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeno</forename><surname>Vendler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1957" />
			<publisher>Cornell University Press</publisher>
			<biblScope unit="page" from="97" to="121" />
			<pubPlace>Ithaca, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Extracting and modeling durations for habits and events from twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="223" to="227" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Extracting fine-grained durations for verbs from twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2012 Student Research Workshop</title>
		<meeting>ACL 2012 Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="49" to="54" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Buy one get one free: Distant annotation of chinese tense, event type, and modality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC-2014</title>
		<meeting>LREC-2014<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Computational models for event type classification in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandra</forename><surname>Zarcone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
