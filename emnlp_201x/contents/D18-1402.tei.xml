<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:25+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-topic Argument Mining from Heterogeneous Sources</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="laboratory" key="lab1">Ubiquitous Knowledge Processing Lab (UKP-TUDA</orgName>
								<orgName type="laboratory" key="lab2">† Research Training Group AIPHES</orgName>
								<orgName type="institution" key="instit1">Technische Universität Darmstadt</orgName>
								<orgName type="institution" key="instit2">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tristan</forename><surname>Miller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="laboratory" key="lab1">Ubiquitous Knowledge Processing Lab (UKP-TUDA</orgName>
								<orgName type="laboratory" key="lab2">† Research Training Group AIPHES</orgName>
								<orgName type="institution" key="instit1">Technische Universität Darmstadt</orgName>
								<orgName type="institution" key="instit2">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Schiller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="laboratory" key="lab1">Ubiquitous Knowledge Processing Lab (UKP-TUDA</orgName>
								<orgName type="laboratory" key="lab2">† Research Training Group AIPHES</orgName>
								<orgName type="institution" key="instit1">Technische Universität Darmstadt</orgName>
								<orgName type="institution" key="instit2">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="laboratory" key="lab1">Ubiquitous Knowledge Processing Lab (UKP-TUDA</orgName>
								<orgName type="laboratory" key="lab2">† Research Training Group AIPHES</orgName>
								<orgName type="institution" key="instit1">Technische Universität Darmstadt</orgName>
								<orgName type="institution" key="instit2">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="laboratory" key="lab1">Ubiquitous Knowledge Processing Lab (UKP-TUDA</orgName>
								<orgName type="laboratory" key="lab2">† Research Training Group AIPHES</orgName>
								<orgName type="institution" key="instit1">Technische Universität Darmstadt</orgName>
								<orgName type="institution" key="instit2">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-topic Argument Mining from Heterogeneous Sources</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3664" to="3674"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3664</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Argument mining is a core technology for automating argument search in large document collections. Despite its usefulness for this task, most current approaches are designed for use only with specific text types and fall short when applied to heterogeneous texts. In this paper , we propose a new sentential annotation scheme that is reliably applicable by crowd workers to arbitrary Web texts. We source annotations for over 25,000 instances covering eight controversial topics. We show that integrating topic information into bidirectional long short-term memory networks outperforms vanilla BiLSTMs by more than 3 percentage points in F 1 in two-and three-label cross-topic settings. We also show that these results can be further improved by leveraging additional data for topic relevance using multi-task learning.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information retrieval and question answering are by now mature technologies that excel at answering factual queries on noncontroversial topics. How- ever, they provide no specialized support for queries where there is no single canonical answer, as with topics that are controversial or opinion-based. For such queries, the user may need to carefully assess the stance, source, and supportability for each of the answers. These processes can be supported by argument mining (AM), a nascent area of natural language processing concerned with the automatic recognition and interpretation of arguments.</p><p>In this paper, we apply AM to the task of argu- ment search-that is, searching a large document collection for arguments relevant to a given topic. Searching for and classifying relevant arguments plays an important role in decision making <ref type="bibr" target="#b37">(Svenson, 1979</ref>), legal reasoning ( <ref type="bibr" target="#b41">Wyner et al., 2010)</ref>, and the critical reading, writing, and summarization of persuasive texts <ref type="bibr" target="#b18">(Kobayashi, 2009;</ref><ref type="bibr" target="#b40">Wingate, 2012)</ref>. Automating the argument search process could ease much of the manual effort involved in these tasks, particularly if it can be made to robustly handle arguments from different text types and topics.</p><p>But despite its obvious usefulness, this sort of argument search has attracted little attention in the research community. This may be due in part to the limitations of the underlying models and training resources, particularly as they relate to heteroge- neous sources. That is, most current approaches to AM are designed for use with particular text types, faring poorly when applied to new data . Indeed, as <ref type="bibr" target="#b11">Habernal et al. (2014)</ref> observe, while there is a great diversity of perspectives on how arguments can be best charac- terized and modelled, there is no "one-size-fits-all" argumentation theory that applies to the variety of text sources found on the Web.</p><p>To approach these challenges, we propose the novel task of topic-based sentential argument min- ing. Our contributions are as follows: (1) We propose a new argument annotation scheme ap- plicable to the information-seeking perspective of argument search. We show it to be general enough for use on heterogeneous data sources, and simple enough to be applied manually by untrained annota- tors at a reasonable cost. (2) We introduce a novel corpus of heterogeneous text types annotated with topic-based arguments.1 The corpus includes over 25,000 instances covering eight controversial topics. This is the first known resource that can be used to evaluate the performance of argument mining methods across topics in heterogeneous sources. (3) We investigate different approaches for incorpo- rating topic information into neural networks and show that including the topic vector into the i i i-and c c c-gates of the LSTM cell outperforms common attention-based approaches in two-and three-label cross-topic experiments. (4) We further improve the performance of the modified LSTM cell by leveraging additional data for topic relevance in a multi-task learning setup. (5) In the more challeng- ing setup of cross-topic experiments, we show that our models yield considerably better performance than common BiLSTM models when little data of the target topic is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Most existing approaches treat argument mining at the discourse level, focusing on tasks such as segmenting argumentative discourse units <ref type="bibr" target="#b10">Goudas et al., 2014)</ref>, classifying the function of argumentative discourse units (for ex- ample, as claims or premises) <ref type="bibr" target="#b24">(Mochales-Palau and Moens, 2009;</ref><ref type="bibr" target="#b34">Stab and Gurevych, 2014)</ref>, and rec- ognizing argumentative discourse relations <ref type="bibr" target="#b26">Nguyen and Litman, 2016)</ref>. These discourse-level approaches address the identification of argumentative struc- tures within a single document but do not consider relevance to externally defined topics.</p><p>To date, there has been little research on the iden- tification of topic-relevant arguments for argument search.  present a generic argument search framework. However, it relies on already-structured arguments from debate por- tals and is not yet able to retrieve arguments from arbitrary texts. <ref type="bibr" target="#b19">Levy et al. (2014)</ref> investigate the identification of topic-relevant claims, an approach that was later extended with evidence extraction to mine supporting statements for claims ( <ref type="bibr" target="#b29">Rinott et al., 2015</ref>). However, both approaches are de- signed to mine arguments from Wikipedia articles; it is unclear whether their annotation scheme is applicable to other text types. It is also uncertain that it can be easily and accurately applied by un- trained annotators, since it requires unitizing (i.e., finding the boundaries of argument components at the token level). <ref type="bibr" target="#b16">Hua and Wang (2017)</ref> identify sentences in cited documents that have been used by an editor to formulate an argument. By contrast, we do not limit our approach to the identification of sentences related to a given argument, but rather focus on the retrieval of any argument relevant to a given topic. The fact that we are concerned with retrieval of arguments also sets our work apart from the discourse-agnostic stance detection task of <ref type="bibr" target="#b25">Mohammad et al. (2016)</ref>, which is concerned with the identification of sentences expressing support or opposition to a given topic, irrespective of whether those sentences contain supporting evidence (as opposed to mere statements of opinion).</p><p>Cross-domain AM experiments have so far been conducted only for discourse-level tasks such as claim identification , argu- mentative segment identification <ref type="bibr" target="#b1">(Al-Khatib et al., 2016)</ref>, and argumentative unit segmentation . However, the discourse-level argu- mentation models these studies employ seem to be highly dependent on the text types for which they were designed; they do not work well when applied to other text types ( ). The crucial difference between our own work and prior cross-domain experiments is that we investigate AM from heterogeneous texts across different top- ics instead of studying specific discourse-level AM tasks across restricted text types of existing corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Corpus creation</head><p>There exists a great diversity in models of argumen- tation, which differ in their perspective, complexity, terminology, and intended applications ( <ref type="bibr" target="#b3">Bentahar et al., 2010</ref>). For the present study, we propose a model which, though simplistic, is nonetheless well-suited to the argument search scenario. We define an argument as a span of text expressing evidence or reasoning that can be used to either support or oppose a given topic. An argument need not be "direct" or self-contained-it may pre- suppose some common or domain knowledge, or the application of commonsense reasoning-but it must be unambiguous in its orientation to the topic. A topic, in turn, is some matter of controversy for which there is an obvious polarity to the possible outcomes-that is, a question of being either for or against the use or adoption of something, the commitment to some course of action, etc. In some graph-based models of argumentation <ref type="bibr">(Stab, 2017, Ch. 2)</ref>, what we refer to as a topic would be part of a (major) claim expressing a positive or nega- tive stance, and our arguments would be premises with supporting/attacking consequence relations to the claim. However, unlike these models, which are typically used to represent (potentially deep or complex) argument structures at the discourse level, ours is a flat model that considers arguments in isolation from their surrounding context. A great topic sentence label nuclear energy Nuclear fission is the process that is used in nuclear reactors to produce high amount of energy using element called uranium.</p><p>non-argument nuclear energy It has been determined that the amount of greenhouse gases have decreased by almost half because of the prevalence in the utilization of nuclear power. supporting argument minimum wage A 2014 study <ref type="bibr">[. . . ]</ref> found that minimum wage workers are more likely to report poor health, suffer from chronic diseases, and be unable to afford balanced meals.</p><p>opposing argument minimum wage We should abolish all Federal wage standards and allow states and localities to set their own minimums.</p><p>non-argument <ref type="table">Table 1</ref>: Example annotations illustrating our annotation scheme.</p><p>advantage of this approach is that it allows annota- tors to classify text spans without having to read large amounts of context and without having to consider relations to other topics or arguments.</p><p>In this work, we consider only those topics that can be concisely and implicitly expressed through keywords, and those arguments that consist of indi- vidual sentences. Some examples, drawn from our dataset, are shown in <ref type="table">Table 1</ref>. Note that while the fourth example expresses opposition to the topic, under our definition it is properly classified as a non-argument because it is a mere statement of stance that provides no evidence or reasoning.</p><p>Data. For our experiments we gathered a large collection of manually annotated arguments that cover a variety of topics and that come from a variety of text types. We started by randomly se- lecting eight topics (see <ref type="table" target="#tab_1">Table 2</ref>) from online lists of controversial topics.2 For each topic, we made a Google query for the topic name, removed re- sults not archived by the Wayback Machine,3 and truncated the list to the top 50 results. This re- sulted in a set of persistent, topic-relevant, largely polemical Web documents representing a range of genres and text types, including news reports, editorials, blogs, debate forums, and encyclopedia articles. We preprocessed each document with Apache Tika ( <ref type="bibr" target="#b22">Mattmann and Zitting, 2011</ref>) to re- move boilerplate text. We then used the Stanford CoreNLP tools ( <ref type="bibr" target="#b21">Manning et al., 2014</ref>) to perform tokenization, sentence segmentation, and part-of- speech tagging on the remaining text, and removed all sentences without verbs or with less than three tokens. This left us with a raw dataset of 27,520 sentences (about 2,700 to 4,400 per topic).</p><p>Annotators classified the sentences using a browser-based interface that presents a set of in- 2https://www.questia.com/library/ controversial-topics, https://www.procon.org/ 3https://web.archive.org/ structions, a topic, a list of sentences, and a multiple- choice form for specifying whether each sentence is a supporting argument, an opposing argument, or not an argument with respect to the topic. (In pre- liminary experiments, we presented annotators with a fourth option for sentences that are ambiguous or incomprehensible. However, we found that these constituted less than 1% of the distribution and so mapped all such answers to the "no argument" class.</p><p>)</p><p>Annotation experiments. We tested the applica- bility of our annotation scheme by untrained anno- tators by performing an experiment where we had a group of "expert" annotators and a group of un- trained annotators classify the same set of sentences, and then compared the two groups' classifications. The data for this experiment consisted of 200 sen- tences randomly selected from each of our eight topics. Our expert annotators were two graduate- level language technology researchers who were fully briefed on the nature and purpose of the ar- gument model. Our untrained annotators were anonymous American workers from the Amazon Mechanical Turk (AMT) crowdsourcing platform. Each sentence was independently annotated by the two expert annotators and ten crowd workers.</p><p>Inter-annotator agreement for our two experts, as measured by Cohen's κ, was 0.721; this exceeds the commonly used threshold of 0.7 for assuming the results are reliable <ref type="bibr" target="#b4">(Carletta, 1996)</ref>. We proceeded by having the two experts resolve their disagree- ments, resulting in a set of "expert" gold-standard annotations. Similar gold standards were produced for the crowd annotations by applying the MACE denoising tool (Hovy et al., 2013); we tested various thresholds (1.0, 0.9, and 0.8) to discard instances that could be confidently assigned a gold label. We then calculated κ between the remaining instances in the expert and crowd gold standards. In order to topic docs sentences no argument support argument oppose <ref type="table" target="#tab_1">argument   abortion  50  3,929  2,427  680  822  cloning  50  3,039  1,494  706  839  death penalty  50  3,651  2,083  457  1,111  gun control  50  3,341  1,889  787  665  marijuana legalization  50  2,475  1,262  587  626  minimum wage  50  2,473  1,346  576  551  nuclear energy  50  3,576  2,118  606  852  school uniforms  50  3,</ref>   determine the relationship between inter-annotator agreement and the number of crowd workers, we performed this procedure with successively lower numbers of crowd workers, going from the original ten annotators per instance down to two. The re- sults are visualized in <ref type="figure" target="#fig_0">Fig. 1</ref>. We found that using seven annotators and a MACE threshold of 0.9 results in κ = 0.723; this gives us similar reliability as with the expert annotators without sacrificing much coverage. <ref type="table" target="#tab_3">Table 3</ref> shows the κ and percentage agreement for this setup, as well as the agreement between our expert annotators, broken down by topic.</p><p>We proceeded with annotating the remaining instances in our dataset using seven crowd work- ers each, paying a rate corresponding to the US federal minimum wage of $7.25/hour. Our total expenditure, including AMT processing fees, was $2,774.02. After MACE denoising, we were left with 25,492 gold-standard annotations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Approaches for identifying arguments</head><p>We model the identification of arguments as a sentence-level classification task. In particular, given a sentence ς ς ς with words u 1 , . . . , u n ς and a topic τ τ τ of words v 1 , . . . , v n τ (e.g., "gun control" or "school uniforms"), we aim to classify ς ς ς as a "supporting argument" or "opposing argument" if it includes a relevant reason for supporting or op- posing the τ τ τ, or as a "non-argument" if it does not include a reason or is not relevant to τ τ τ. We also investigate a two-label classification where we combine supporting and opposing arguments into a single category; this allows us to evaluate argument classification independent of stance. We focus on the challenging task of cross-topic experiments, where one topic is withheld from the training data and used for testing. Here, we denote scalars by italic lowercase letters (e.g., t), vector representa- tions by italic bold lowercase letters (e.g., c c c), and matrices as italic bold uppercase letters (e.g., W W W).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Integrating topic information</head><p>Since arguments need to be relevant to the given topic, we posit that providing topic information to the learner results in a more robust prediction capability in cross-topic setups. Below, we present two models that integrate the topic, one that uses an attention mechanism and another that includes the topic vector directly in the LSTM cell.</p><p>Outer-attention BiLSTM (outer-att). To let the model learn which parts of the sentence are relevant (or irrelevant) to the given topic, we use an attention- based neural network ( <ref type="bibr" target="#b2">Bahdanau et al., 2014</ref>) that learns an importance weighting of the input words depending on the given topic. In particular, we adopt an outer-attention mechanism similar to the one proposed by , which has achieved state-of-the-art results in related tasks such as natural language inference and recognizing textual entailment ( <ref type="bibr" target="#b30">Rocktäschel et al., 2015;</ref><ref type="bibr" target="#b39">Wang and Jiang, 2016)</ref>. We combine the attention mech- anism with a common BiLSTM model and, at time step t, determine the importance weighting for each hidden state h h h(t) as</p><formula xml:id="formula_0">m m m(t) = tanh(W W W h h h h(t) + W W W p p p p)<label>(1)</label></formula><formula xml:id="formula_1">f attention (h h h(t), p p p) = exp(w w w T m m m m(t)) t exp(w w w T m m m m(t))<label>(2)</label></formula><p>where W W W h , W W W p , and w w w m are trainable parameters of the attention mechanism and p p p is the average of all word embeddings of topic words v 1 , . . . , v n τ . Using the importance weighting, we determine the final, weighted hidden output state s s s as</p><formula xml:id="formula_2">α t ∝ f attention (h h h(t), p p p)<label>(3)</label></formula><formula xml:id="formula_3">s s s = n t=1 h h h(t)α t .<label>(4)</label></formula><p>Finally, we feed s s s into a dense layer with a softmax activation function to get predictions for our two- or three-label setups.</p><p>Contextual BiLSTM (biclstm). A more direct approach to integrating an argument's topic is the contextual LSTM (CLSTM) architecture ( <ref type="bibr" target="#b9">Ghosh et al., 2016)</ref>, where topic information is added as another term to all four gates of an LSTM cell. We, however, hypothesize that topic information is more relevant at the i i i-and c c c-gates, the former because it has the biggest impact on how a new token is processed and the latter because it is closely linked to how the sequence seen so far is to be interpreted and stored. To this end, we experimented with several modifications to the original CLSTM such as removing peepholes-i.e., removing gates' access to the cell state c c c <ref type="bibr" target="#b8">(Gers and Schmidhuber, 2000</ref>)- and removing topic information from one or more gates. Empirical results on the validation set show that topic integration at the i i i-and c c c-gates only, and removal of all peephole connections, does indeed outperform the original CLSTM on our task by 1 percentage point. Our modified CLSTM <ref type="figure" target="#fig_1">(Fig. 2)</ref> is defined as</p><formula xml:id="formula_4">i c t c t-1 x h p t-1 t x h p t-1 t h o t x h t-1 t t t h t-1 x t f t</formula><formula xml:id="formula_5">i i i t = σ(W W W x i x x x t + W W W h i h h h t−1 + b b b i + W p i p W p i p W p i p ) (5) f f f t = σ(W W W x f x x x t + W W W h f h h h t−1 + b b b f )<label>(6)</label></formula><formula xml:id="formula_6">c c c t = f f f t c c c t−1 + i i i t σ c (W W W x c x x x t + W W W h c h h h t−1 + b b b c + W p c p W p c p W p c p )<label>(7)</label></formula><formula xml:id="formula_7">o o o t = σ(W W W x o x x x t + W W W h o h h h t−1 + b b b o )<label>(8)</label></formula><formula xml:id="formula_8">h h h t = o o o t σ c (c c c t ).<label>(9)</label></formula><p>Here i i i, f f f , and o o o represent the input, forget, and output gates; c c c the cell memory; x x x t the embedded token of a sentence at timestep t; h h h t−1 the previ- ous hidden state; and b b b the bias. σ and σ c are the activation and recurrent activation functions, respectively. The novel terms for topic integration are outlined. We use this model bidirectionally, as we did with our BiLSTM network, and hence refer to it as biclstm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Leveraging additional data</head><p>As we want to classify arguments related to spe- cific topics, leveraging information that supports the classifier in the decision of topic-relation is crucial. The multi-task learning (mtl) and transfer learning (trl) models are able to make use of aux- iliary data that can potentially improve the results on the main task. Thus, we extend our previously described models by integrating them into mtl and trl setups. We also choose to integrate two corpora   For our mtl and trl approaches, we consider every possible pairing of a model (biclstm, outer-att, and the bilstm baseline we introduce in §5) with an aux- iliary corpus (DIP2016, SemEval). We formalize our datasets as S k = {(x x x k i , p p p k i , y k i )|i = 0, . . . , |S k |}, where k can be either our main dataset or an aux- iliary dataset, x x x k i denotes a single sentence as a sequence of word embeddings and y k i its corre- sponding label in k, and p p p k i represents the corre- sponding averaged topic vector.</p><p>Transfer learning (trl). For trl, we use the ap- proach of parameter transfer (Pan and Yang, 2010)- i.e., we do not modify the model used. Instead, we train the model twice: the first time, we train the model on the chosen auxiliary corpus, and the second time, we keep the trained model's weights and train it with our own corpus. For the three- label setting, we have to modify the transfer model slightly for the DIP2016 corpus, since it provides only two labels for each training sample. In this case, we simply add a layer with two neurons on top of the layer with three neurons for training with the DIP2016 corpus and remove it afterwards for training with our corpus.</p><p>4We only use 300K of the corpus's 600K samples to ease hyperparameter tuning for our computation-heavy models.</p><p>Multi-task learning (mtl). For mtl, we use a shared-private model ( <ref type="bibr" target="#b20">Liu et al., 2017)</ref>, which showed promising results for text classification and word segmentation . (We also experimented with their adversarial approach to learn topic-invariant features, but abandoned this due to low scores.) The mtl base model consists of a private recurrent neural network (RNN) for both the auxiliary dataset and our dataset, plus a shared RNN that both datasets use <ref type="figure" target="#fig_3">(Fig. 3)</ref>. The last hidden states of the RNNs are concatenated and fed through a dense layer and a softmax activation function. The model is trained in an alternating fashion-i.e., after each epoch the loss for the other dataset is minimized until each dataset has run for the set number of epochs, where the last epoch is always executed on our dataset. At prediction time, only the private RNN trained on our dataset and the shared RNN are used. The core idea is that the shared RNN learns what is relevant for both tasks, while the private ones learn only the task-specific knowledge.</p><p>For the cases of mtl+bilstm+corpus, mtl+biclstm+ corpus, and mtl+outer-att+corpus, we simply switch the RNN with our bilstm, biclstm, and outer-att, respectively. For mtl+outer-att+corpus, we add the outer attention mechanism (see §4.1), modified for use with the mtl model, after each of the private RNNs, while additionally feeding it a second topic vector-the last hidden state of the shared RNN:</p><formula xml:id="formula_9">m m m(t) = tanh(W W W r h h h r (t) + W W W s h h h s + W W W p p p p)<label>(10)</label></formula><formula xml:id="formula_10">f attention (h h h r (t), h h h s , p p p) = exp(w w w T m m m m(t)) t exp(w w w T m m m m(t))<label>(11)</label></formula><formula xml:id="formula_11">α t ∝ f attention (h h h r (t), h h h s , p p p)<label>(12)</label></formula><formula xml:id="formula_12">s s s = n t=1 h h h r (t)α t<label>(13)</label></formula><p>where W W W r , W W W s , and W W W p are trainable weight matri- ces, h h h r (t) is the hidden state of the private bilstm at timestep t, h h h s is the last hidden state of the shared model, and p p p is the average of all word embeddings of topic words v 1 , . . . , v n τ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>To evaluate the robustness of the models, we con- duct cross-topic experiments to evaluate how well the models generalize to an unknown topic. To this end, we combine training (70%) and validation two labels three labels</p><formula xml:id="formula_13">model F 1 P arg R arg F 1 P arg+ P arg− R arg+ R arg− bilstm (baseline)</formula><p>.6069 ± .0074 .7339 ± .0110 .3844 ± .0122 .3796 ± .0079 .3484 ± .0479 .4710 ± .0210 .0963 ± .0148 .2181 ± .0181 lr-uni (baseline)</p><p>.5854 ± .0131 .6519 ± .0093 .3587 ± .0264 .3821 ± .0056 .2782 ± .0293 .4217 ± .0171 .1176 ± .0165 .2119 ± .0203  <ref type="table">Table 4</ref>: Results for each model on the test sets. Bold numbers indicate the highest score in the column. data (10%) of seven topics for training and parame- ter tuning, and use the test data (20%) of the eighth topic for testing. For encoding the words of sen- tence ς ς ς and topic τ τ τ, we use 300-dimensional word embeddings trained on the Google News dataset by <ref type="bibr" target="#b23">Mikolov et al. (2013)</ref>. To handle out-of-vocabulary words, we create separate random word vectors for each.5</p><p>Since reporting single performance scores is insufficient to compare non-deterministic learn- ing approaches like neural networks <ref type="bibr" target="#b28">(Reimers and Gurevych, 2017)</ref>, we report all results as averages over ten runs with different random seeds. As eval- uation measures, we report the average macro F 1 , as well as the precision and the recall for the argument class (P arg , R arg ). For the three-label approach, we split the precision and recall for predicting support- ing (P arg+ , R arg+ ) and attacking arguments (P arg− , R arg− ). As baselines, we use a simple bidirectional LSTM <ref type="bibr" target="#b14">(Hochreiter and Schmidhuber, 1997)</ref>, as well as a logistic regression model with lowercased unigram features, which has been shown to be a strong baseline for various other AM tasks . We refer to these models as bilstm and lr-uni, re- spectively. All neural networks are trained using the Adam optimizer ( <ref type="bibr" target="#b17">Kingma and Ba, 2015)</ref> and cross-entropy loss function. For finding the best model, we run each for ten epochs and take the best model based on the lowest validation loss. In addition to that, we tune the hyperparameters of all 5Each dimension is set to a random number between −0.01 and 0.01. Digits are mapped to the same random word vector. neural networks (see Appendix A). To accelerate training, we truncate sentences at 60 words.6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results</head><p>Two-label setup. The results in <ref type="table">Table 4</ref> show that all our models outperform the baselines for two-label prediction.7 F 1 for biclstm improves by 3.5 percentage points over the bilstm baseline and by 5.6 over lr-uni. A main reason for this proves to be the substantial increase in recall for our topic-integrating models-outer-att and especially biclstm-in comparison to our baselines. These results show that knowledge of the argument's topic has a strong impact on argument prediction capa- bility. Further, we observe that integrating biclstm in a multi-task learning setup in order to draw knowledge about topic relevance from the DIP2016 corpus (mtl+biclstm+dip2016) improves F 1 by an additional 2.5 percentage points. It achieves an F 1 of 0.6662, which is 19.48 percentage points less than the human upper bound of 0.861. When using the SemEval corpus, which holds less task-relevant knowledge for our two-label approach, we are able to gain only 1 percentage point when integrating it into mtl+biclstm+corpus.</p><p>For the transfer learning models that integrate the topic (tr+biclstm+corpus and tr+outer-att+corpus), the parameter transfer is mostly ineffective. If no topic is provided (tr+bilstm+corpus), the transfer learning models are able to improve over the base- line bilstm. This shows that the parameter transfer 6Only 244 of our sentences (&lt;1%) exceed this length. 7Detailed results per topic are given in <ref type="bibr">Appendix B.</ref> itself can be of use, but confuses the model when combined with topic integration.</p><p>In general, we observe an overall lower score for trl models that use the DIP2016 corpus compared to those using the SemEval corpus. In contrast to the mtl model, for trl models all parameters are transferred to the main task, not just parameters that represent shared knowledge. Thus, we suspect the lower scores of the trl models with DIP2016 are due to overfitting on the vast number of samples which shape the parameters much more than the comparatively small SemEval corpus could.</p><p>Three-label setup. For the three-label approach, we observe overall lower scores due to the addi- tional difficulty in distinguishing supporting from opposing arguments. As already observed in the two-label setup, biclstm outperforms both the bilstm and lr-uni baselines; here, the former by 4.5 and the latter by 4.2 percentage points in F 1 . Again, this is caused by a substantial increase in recall and shows the impact that the available topic information has on the classifier's predictive power.</p><p>For transfer learning, we see similar results as for the two-label approach; both the DIP2016 and SemEval corpora have a generally negative impact when compared to the respective base models. The SemEval corpus does not provide the knowledge required to distinguish supporting from attacking arguments. We conclude that the original purpose of the SemEval task, stance recognition, is too different from our own. But in multi-task learning, where only the shared parameters are taken, we observe slight improvements when using biclstm with DIP2016; this correlates with the same model in the two-label setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Error analysis</head><p>To understand the errors of our best model, mtl- biclstm-dip, and the nature of this task, we manually analyzed 100 sentences randomly sampled from the false positive and false negative arguments of the three-label experiments (combining supporting and attacking arguments). Among the false positives, we found 48 off-topic sentences that were wrongly classified as arguments. The 52 on-topic false positives consist of non-argumentative background information or mere opinions without evidence (as with the first and fourth examples of <ref type="table">Table 1)</ref> and questions about the topic. Among the false negatives, we found 65 arguments that did not explicitly refer to the topic but to related aspects that depend on background knowledge. For instance, the model fails to establish an argumentative link between the topic "gun control" and the Second Amendment to the US Constitution. Lastly, we inspected arguments that are incorrectly classified as supporting and/or opposing a topic. We found several samples in which the term "against" is not correctly interpreted and the argument is classified as supporting a topic. Similarly, for arguments incorrectly classified as attacking, we find various samples where the word "oppose" is used not to oppose the topic but to strengthen a supporting argument, as in "There is reason even for people who oppose the use of marijuana to support its legalization. . . "</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Adapting to new topics</head><p>To evaluate the performance of the models in data- scarce scenarios, we gradually add target topic data to the training data and analyze the model performance on the target test set. <ref type="figure" target="#fig_4">Figure 4</ref> shows model performance (F 1 , P arg , and R arg ) on the "marijuana legalization" topic when adding different amounts of randomly sampled topic-specific data to the training data (x-axes).8 As the results show, the models that integrate the topic achieve higher recall when adding target topic data to the training data. For bilstm, we observe a drastic difference when compared to the other models; the recall for arguments stays at around 30% and rises only when integrating more than 60% target topic data. In strong contrast, topic-integrating models retrieve a much higher number of actual arguments at target topic augmentation levels as low as 20%. Further, and equally important, this does not come at the cost of precision; on the contrary, the precision is mostly steady and slowly rising after around 20% of target topic integration, leading to an overall higher F 1 for these models. Finally, in comparing F 1 between topic-integrating models and bilstm, we conclude that the former need much less target topic data to substantially improve their score, making them more robust in situations of data scarcity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented a new approach for searching a document collection for arguments relevant to a given topic. First, we introduced an annotation scheme suited to the information-seeking perspec- 8Each data point in the plot is the average score of ten runs with different random samples of target topic data.  tive of argument search and showed that it is cheaply but reliably applicable by untrained annotators to arbitrary Web texts. Second, we presented a new corpus, including over 25,000 instances over eight topics, that allows for cross-topic experiments us- ing heterogeneous text types. Third, we conducted cross-topic experiments and showed that integrating topic information of arguments with our contextual BiLSTM leads to better generalization to unknown topics. Fourth, by leveraging knowledge from simi- lar datasets and integrating our contextual BiLSTM into a multi-task learning setup, we were able to gain an improvement over our strongest baseline of 5.9 percentage points in F 1 in the two-label setup and 4.6 in the three-label setup. Finally, by gradu- ally adding target topic data to our training set, we showed that, when available, even small amounts of target topic data (20%) have a strong positive influence on the recall of arguments. In a separate, simultaneously written paper ( <ref type="bibr" target="#b33">Stab et al., 2018)</ref> we evaluate our models in real-world application scenarios by applying them to a large document collection and comparing the results to a manually produced gold standard. An on- line argument search engine implementing our ap- proach is now available for noncommercial use at https://www.argumentsearch.com/. Fur- thermore, we are experimenting with language adaptation and plan to extend the tool to the Ger- man language. Preliminary results are presented in <ref type="bibr" target="#b36">Stahlhut (2018)</ref>. We also intend to investigate methods for grouping similar arguments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Influence of the number of crowd annotators and different MACE thresholds on κ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecture of a CLSTM cell.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Multi-task learning architecture. The symbol denotes the concatenation operator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Model performance (y-axes) according to the amount of target topic data in the train sets (x-axes) for the "marijuana legalization" topic in the three-label setup.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Corpus size and class distribution. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 pro</head><label>2</label><figDesc>- vides statistics on the size and class distribution of the final corpus. We are releasing the gold-standard annotations for this dataset, and code for retrieving</figDesc><table>expert-expert 
crowd-expert 

% 
κ 
% 
κ 

abortion 
.884 
.651 
.834 
.660 
cloning 
.845 
.712 
.821 
.704 
death penalty 
.851 
.657 
.770 
.576 
gun control 
.907 
.783 
.796 
.638 
marijuana legalizat. .850 
.729 
.854 
.749 
minimum wage 
.885 
.779 
.858 
.745 
nuclear energy 
.809 
.686 
.889 
.825 
school uniforms 
.864 
.767 
.931 
.889 

average 
.862 
.721 
.844 
.723 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Agreement between experts, and between the 
expert and crowd gold standards. 

the original sentences from the Wayback Machine, 
under a Creative Commons licence. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>aux x main y auxp aux p main y main</head><label></label><figDesc></figDesc><table>dense &amp; 
softmax 

private 
RNN 
private 
RNN 
shared 
RNN 

dense &amp; 
softmax 

</table></figure>

			<note place="foot" n="1">https://www.ukp.tu-darmstadt.de/sent_am</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work has been supported by the German Fed-eral Ministry of Education and Research (BMBF) under the promotional reference 03VP02540 (Ar-gumenText) and the DFG-funded research training group "Adaptive Preparation of Information form Heterogeneous Sources" (AIPHES, GRK 1994/1).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unit segmentation of argumentative texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yamen</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Fan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Argument Mining</title>
		<meeting>the 4th Workshop on Argument Mining</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="118" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Crossdomain mining of argumentative text through distant supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Al-Khatib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1395" to="1404" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A taxonomy of argumentation models used for knowledge representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamal</forename><surname>Bentahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Moulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micheline</forename><surname>Bélanger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="259" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Assessing agreement on classification tasks: The kappa statistic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Carletta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="254" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adversarial multi-criteria learning for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1193" to="1203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">What is the essence of a claim? Cross-domain claim identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2045" to="2056" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural end-to-end learning for computational argumentation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="11" to="22" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recurrent nets that time and count</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks</title>
		<meeting>the IEEE-INNS-ENNS International Joint Conference on Neural Networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="189" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shalini</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">P</forename><surname>Heck</surname></persName>
		</author>
		<idno>abs/1602.06291</idno>
		<title level="m">Contextual LSTM (CLSTM) models for large scale NLP tasks. CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Argument extraction from news, blogs, and social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodosis</forename><surname>Goudas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Louizos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence: Methods and Applications</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">8445</biblScope>
			<biblScope unit="page" from="287" to="299" />
		</imprint>
	</monogr>
	<note>Georgios Petasis, and Vangelis Karkaletsis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Argumentation mining on the Web from information seeking perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Eckle-Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Processing</title>
		<meeting>the Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1341</biblScope>
			<biblScope unit="page" from="26" to="39" />
		</imprint>
		<respStmt>
			<orgName>CEUR-WS.org</orgName>
		</respStmt>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">New Collection Announcement: Focused Retrieval Over the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Sukhareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fiana</forename><surname>Raiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Shtok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Kurland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadar</forename><surname>Ronen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="701" to="704" />
		</imprint>
	</monogr>
	<note>Judit Bar-Ilan, and Iryna Gurevych</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1693" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning whom to trust with MACE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1120" to="1130" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Understanding and detecting diverse supporting arguments of diverse types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="203" to="208" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations</title>
		<meeting>the 3rd International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Comprehension of relations among controversial texts: Effects of external strategy use</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiichi</forename><surname>Kobayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Instructional Science</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="311" to="324" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Context dependent claim detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1489" to="1500" />
		</imprint>
		<respStmt>
			<orgName>Dublin City University and Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adversarial multi-task learning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Tika in Action</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">A</forename><surname>Mattmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jukka</forename><surname>Zitting</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Manning Publications</publisher>
			<pubPlace>Greenwich, CT, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Argumentation mining: The detection, classification and structure of arguments in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Mochales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Artificial Intelligence and Law</title>
		<meeting>the 12th International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="98" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SemEval-2016 Task 6: Detecting stance in tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
		<meeting>the 10th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="31" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Context-aware argumentative relation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1127" to="1137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reporting score distributions makes a difference: Performance study of LSTM-networks for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="338" to="348" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Show me your evidence-An automatic method for context dependent evidence detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lena</forename><surname>Dankin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">Alzate</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitesh</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="440" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Kočisk`y, and Phil Blunsom</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočisk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.06664</idno>
	</analytic>
	<monogr>
		<title level="m">Reasoning about entailment with neural attention</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Argumentative Writing Support by Means of Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>Technische Universität Darmstadt</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Dr.-Ing. thesis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">ArgumenText: Searching for arguments in heterogeneous sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Stahlhut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tristan</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Schiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Tauchmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations (NAACLHLT 2018)</title>
		<meeting>the 16th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations (NAACLHLT 2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="21" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Identifying argumentative discourse structures in persuasive essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Parsing argumentation structures in persuasive essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="619" to="659" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Searching arguments in German with ArgumenText</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Stahlhut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Biennial Conference on Design of Experimental Search &amp; Information Retrieval Systems</title>
		<meeting>the First Biennial Conference on Design of Experimental Search &amp; Information Retrieval Systems</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2167</biblScope>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Process descriptions of decision making. Organizational Behavior and Human Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ola</forename><surname>Svenson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="86" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Building an argument search engine for the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><forename type="middle">Al</forename><surname>Khatib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yamen</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Puschmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiani</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Dorsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viorel</forename><surname>Morari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janek</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Argument Mining</title>
		<meeting>the 4th Workshop on Argument Mining</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="49" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning natural language inference with LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1442" to="1451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Argument!&apos; Helping students understand what essay writing is about</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ursula</forename><surname>Wingate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of English for Academic Purposes</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="154" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Approaches to text mining arguments from legal cases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Wyner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Mochales-Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Milward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic Processing of Legal Texts: Where the Language of Law Meets the Law of Language</title>
		<editor>Enrico Francesconi, Simonetta Montemagni, Wim Peters, and Daniela Tiscornia</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">6036</biblScope>
			<biblScope unit="page" from="60" to="79" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
