<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Extracting Condition-Opinion Relations Toward Fine-grained Opinion Mining</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><surname>Nakayama</surname></persName>
							<email>{nakayama.y.aj@m,fujii@cs}.titech.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science Graduate School of Information Science and Engineering</orgName>
								<orgName type="institution">Tokyo Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Fujii</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science Graduate School of Information Science and Engineering</orgName>
								<orgName type="institution">Tokyo Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Extracting Condition-Opinion Relations Toward Fine-grained Opinion Mining</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A fundamental issue in opinion mining is to search a corpus for opinion units, each of which typically comprises the evaluation by an author for a target object from an aspect, such as &quot;This hotel is in a good location&quot;. However, few attempts have been made to address cases where the validity of an evaluation is restricted on a condition in the source text, such as &quot;for traveling with small kids&quot;. In this paper, we propose a method to extract condition-opinion relations from on-line reviews, which enables fine-grained analysis for the utility of target objects depending the user attribute, purpose, and situation. Our method uses supervised machine learning to identify sequences of words or phrases that comprise conditions for opinions. We propose several features associated with lexical and syntactic information , and show their effectiveness experimentally .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Reflecting the rapid growth in the use of opin- ionated texts on the Web, such as comments on news articles and customer reviews, opinion min- ing has been explored to facilitate utilizing opin- ions mainly for improving products and decision- making purposes. While in a broad sense opin- ion mining refers to a process to discover useful knowledge latent in a corpus of opinionated texts, fundamental issues involve modeling an unit of opinions and searching the corpus for those units, each of which typically comprises the evaluation by an author for a target object from an aspect. Other elements, such as when the opinion was sub- mitted, can optionally be included in an opinion unit. We take the following review sentence as an example opinionated description.</p><p>(1) I think hotel A offers a reasonable price if you take a family trip with small kids.</p><p>From the above example, existing methods ( <ref type="bibr" target="#b17">Pang and Lee, 2008;</ref><ref type="bibr" target="#b18">Seki et al., 2009;</ref><ref type="bibr" target="#b3">Jin et al., 2009;</ref><ref type="bibr" target="#b20">Zhao et al., 2010;</ref><ref type="bibr" target="#b2">He et al., 2011</ref>; Liu and Zhang, 2012; <ref type="bibr" target="#b9">Liu et al., 2013;</ref><ref type="bibr" target="#b19">Yang and Cardie, 2013;</ref><ref type="bibr" target="#b10">Liu et al., 2014</ref>) are intended to extract the following quintuple as an opinion unit. Target = "hotel A", Aspect = "price", Evaluation (Polarity) = "reasonable" (positive), Holder = "I (author)", Time = N/A Depending on the application, "Evaluation" can be any of a literal opinion word (e.g., "reasonable"), a polarity (positive/negative), or a value for multi- point scale rating. Given those standardized units extracted from a corpus, it is feasible to overview the distribu- tion of values for each element or a combination of elements. For example, those who intend to im- prove the quality of hotel A may investigate repre- sentative values for "Aspect" in the units satisfy- ing "Target=hotel A &amp; Polarity=negative", while those who look for accommodation may collect the opinion units for one or more candidate ho- tels and investigate the distribution of values for "Polarity" on an aspect-by-aspect basis.</p><p>However, in the above example (1), the evalua- tion for hotel A ("a reasonable price") is valid for "if you take a family trip with small kids", and thus it is not clear whether this evaluation is valid irre- spective of the condition. For example, the price may not be reasonable for a single customer in- tending for business purposes. In this paper, we shall call such a condition "condition for opinion (CFO)". We define CFO as a condition for which an opinion unit has a polarity.</p><p>The existing methods for opinion mining, which do not consider whether a target opinion is con- ditional, potentially overestimate or underestimate the utility of hotel A and consequently decrease the quality of opinion mining. We manually an- alyzed the first 7 000 sentences in the Rakuten Travel data, which consists of 348 564 Japanese reviews for hotels in Japan (see Section 4 for de- tails of this data) and found that 2 272 sentences are opinions, of which 630 opinions are condi- tional and thus the result for an existing method includes up to 28% (630/2272) errors.</p><p>Motivated by the above discussion, in this pa- per we propose a method to extract pairs of a CFO and its corresponding opinion unit from online re- views. This method provides two solutions to the above problem. First, a passive solution is detect- ing whether an opinion includes a CFO and, if any, isolating that opinion from the target of opinion mining. As a result, we can avoid potential errors as much as possible but the coverage is decreased.</p><p>Second, an active solution is identifying the span of each CFO in conditional opinions and classify them according to semantic categories, such as purpose, situation, and user attribute so that finer-grained opinion mining can be realized. For example, the distribution of positive and neg- ative opinions can be available on a category-by- category basis. However, in this paper we focus only on the identification for CFOs and leave the semantic classification future work.</p><p>To produce a practical model for CFOs, it is im- portant to investigate them from a grammar point of view. It can easily be predicted that a typical grammatical unit for CFOs is a conditional clause as in example (1). Additionally, restrictive mod- ifiers in general can potentially be CFOs because they restrict the validity of an opinion unit from a specific perspective. A restrictive modifier com- prises a word, phrase, or clause. The CFO in ex- ample (1), which is a dependent clause functioning as a condition, is also a restrictive modifier.</p><p>Example <ref type="formula" target="#formula_4">(2)</ref>, which has the same meaning as example (1), includes a CFO as a prepositional phrase.</p><p>(2) Hotel A offers a reasonable price for taking a family trip with small kids.</p><p>We denote CFOs and opinion words in bold and italic faces, respectively. Examples (3) and (4) also include a CFO as a prepositional phrase. Un- like example (2), the validity of "reasonable" is re- stricted from time and comparison points of view, respectively.</p><p>(3) Hotel A offers a reasonable price during this holiday season.</p><p>(4) Hotel A offers a reasonable price for a four star hotel.</p><p>In example (5), which has a similar meaning to example (1), the CFO is a dependent clause func- tioning as a reason.</p><p>(5) Hotel A offers a reasonable price because we take a family trip with small kids.</p><p>Finally, as in example <ref type="formula">(6)</ref>, an opinion holder can also be a CFO because the evaluation is restricted from a perspective of that specific person.</p><p>(6) My mother regarded hotel A as a reasonable choice.</p><p>If the restriction by a CFO is associated with a user-related perspective, we call such CFOs "user- restrictive CFOs (U-CFOs)". In other words, tar- get users to whom an opinion unit is relevant are restricted by its corresponding U-CFO, although those users may agree or disagree with the opin- ion. The CFOs in examples (1), (2), and (5) are U-CFOs because the target users are mainly those who intend to travel with their children.</p><p>The CFO in example (3) is also U-CFO be- cause the target users are those who intend to travel during a specific holiday season. The CFO in example (6) is also U-CFO because the opin- ion holder ("my mother") implies the opinion is relevant mainly to adult females. However, opin- ion holders who do not represent user-related per- spectives, such as "I" without any profile, are not U-CFOs.</p><p>The CFO in example <ref type="formula">(4)</ref> is not a U-CFO be- cause the relevance of the opinion is not restricted to specific customers. It may be argued that in ex- ample (4) the target users are restricted to those who are interested in the price. However, in exam- ple (4) the price restricts the aspect of the opinion unit, and should not be confused with U-CFOs and even CFOs, which restrict the validity of the opin- ion unit.</p><p>If we fully utilize U-CFOs, as discussed for the active solution above, we need to classify U-CFOs into semantic categories so that users can selec- tively read relevant opinions. In other words, the identification for U-CFOs facilitates predicting the review helpfulness <ref type="bibr" target="#b16">(O'Mahony and Smyth, 2010;</ref><ref type="bibr" target="#b14">Moghaddam et al., 2012)</ref>. Candidate categories include demographic and psychographic attributes for target users (e.g., age and hobby) and situations of target users (e.g., purpose, time, and place). However, we leave the classification for U-CFOs future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>As described in Section 1, the fundamental meth- ods for opinion mining include opinion extraction, which identifies elements for opinion units (i.e., target, aspect, evaluation, holder, and time) <ref type="bibr" target="#b2">(He et al., 2011;</ref><ref type="bibr" target="#b3">Jin et al., 2009;</ref><ref type="bibr" target="#b9">Liu et al., 2013;</ref><ref type="bibr" target="#b18">Seki et al., 2009;</ref><ref type="bibr" target="#b19">Yang and Cardie, 2013;</ref><ref type="bibr" target="#b20">Zhao et al., 2010)</ref>, and opinion classification, which de- termines the non-literal evaluation of each opinion unit based on bipolar categories (i.e., positive and negative) <ref type="bibr" target="#b2">(He et al., 2011;</ref><ref type="bibr" target="#b12">Meng et al., 2012</ref>) or multipoint scale categories ( <ref type="bibr" target="#b1">Fu and Wang, 2010;</ref><ref type="bibr" target="#b13">Moghaddam and Ester, 2013)</ref>. However, none of these methods intends to determine whether or not an opinion is conditional and to extract their con- dition. <ref type="bibr" target="#b15">Narayanan et al. (2009)</ref> proposed a method for sentiment classification targeting conditional sen- tences. Although a conditional opinion is a kind of conditional sentence, their research is funda- mentally different from our research. <ref type="bibr" target="#b15">Narayanan et al. (2009)</ref> targeted such a conditional sentence that comprises a single opinion as a whole, and intended to categorize its polarity into any of posi- tive, negative, or neutral. Examples (7) and (8) are such conditional sentences associated with neutral and positive categories, respectively. In example <ref type="formula">(7)</ref>, although the subordinate clause in- cludes the opinion word "reasonable", none of the subordinate clause, main clause, or entire sentence is an opinion. In example (8), the entire sentence is an unconditional opinion about the price for ho- tel A, but the main and subordinate clauses are not opinions independently. In contrast, the purpose of our research is to identify conditional opinions, in which the main and subordinate clauses are an opinion and its condition, respectively. <ref type="bibr" target="#b4">Kim and Hovy (2006)</ref> proposed a method to identify a reason for the evaluation in an opinion, such as "the service was terrible because the staff was rude". Although as discussed in Section 1 reasons can be CFOs, their purpose is to identify grounds that justify the evaluation and thus is dif- ferent from our purpose.</p><p>As discussed in Section 1, our research is related to predicting the review helpful- ness <ref type="bibr" target="#b16">(O'Mahony and Smyth, 2010;</ref><ref type="bibr" target="#b14">Moghaddam et al., 2012</ref>). The method proposed by O' <ref type="bibr">Mahony and Smyth (2010)</ref> determines the helpfulness of a product review independent of the user profile and thus cannot recommend reviews based on user- related attributes.</p><p>Moghaddam et al. <ref type="formula" target="#formula_0">(2012)</ref> used collaborative fil- tering to predict the review helpfulness. The eval- uation by a target user for past reviews is used to model the user and predict the helpfulness for unread reviews, which results in different predic- tions depending on the user. An advantage of collaborative filtering is its applicability to items whose content is usually difficult to analyze, such as videos. However, this advantage is diluted in recommending review text, from which effective features for user modeling, such as U-CFOs, can be obtained by opinion mining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed method</head><p>The task in this paper is to extract condition- opinion relations from reviews in Japanese. Cur- rently, we assume that an opinion unit and its cor- responding CFO are in the same sentence, and thus perform the extraction on a sentence-by-sentence basis. Given a sentence in reviews, we first search for an opinion unit, and if found, we also search for its corresponding CFO. Because in the first process we rely on an existing method for the opinion extraction, in this paper we focus only on the extraction for CFOs.</p><p>As discussed in Section 1, because CFOs can be different grammatical units, their length and struc- ture are not standardized. We model the extraction for CFOs as the BIO chunking, which labels each token in a sentence as being the beginning (B), in- side (I), or outside (O) of a span of interest. We use "Other" to refer to "O" to avoid confusion be- tween "O" and "0" (zero). To subdivide "B" and "I" into U-CFOs and other CFOs, we use suffixes "U" and "C", respectively, such as "BU" denoting the beginning of a U-CFO. We use "Cond" to refer to any of BU, IU, BC, or IC.</p><p>Because we use the same method for both U-CFOs and other CFOs, the above distinction only increases the number of categories to which each token is classified. If the distinction of U-CFOs is not important, the above suffixes can be omitted. We regard Japanese bunsetsu phrases, which consist of a content word and one or more postpo- sitional particles, as tokens, and extract a sequence of a BU-phrase and one or more IU-phrases, or an independent BU-phrase as a condition. The same method is used for BC/IC-phrases. However, words and phrases in an opinion unit are classified into its corresponding element. For example, an aspect phrase is classified into the aspect category.</p><p>Given an input sequence of bunsetsu phrases, x = x 1 . . . x n , our task is to predict a se- quence of labels, y = y 1 . . . y n , where y i ∈ {BU, IU, BC, IC, Other, T arget, Aspect, OpinionW ord}. However, because an opinion unit in an input sentence has been identified in advance, the task is a quinary classification with respect to y i ∈ {BU, IU, BC, IC, Other}. We use Conditional Random Fields (CRF) ( <ref type="bibr" target="#b7">Lafferty et al., 2001</ref>) to train a classifier for categorizing each bunsetsu phrase into any of the aforemen- tioned five categories. We use a combination of unigram and bigram models and calculate the con- ditional probability, p(y|x), for linear-chain CRF by Equation (1).</p><formula xml:id="formula_0">p(y|x) = 1 Z x exp ( ∑ i,k λ k ·f k (y i , x)+ ∑ i,k µ k ·g k (y i−1 , y i , x) )<label>(1)</label></formula><p>Here, Z x denotes a normalization factor, and f k and g k denote feature functions for unigram and bigram models, respectively. Let x i,v denote a feature value for x i . While in the unigram model y i depends on either x i−1,v or x i,v , in the bigram model y i depends on either a combination of x i,v and y i−1 or that of x i−1,v and y i−1 . Feature func- tions are produced for any possible combinations of the values for the variables used (x i,v , y i−1 , and y i in f k ), and take 1 if the corresponding combi- nation appears and 0 otherwise. We use the four combinations "unigram x i,v ", "unigram x i−1,v ", "bigram y i−1 x i,v ", and "bigram y i−1 x i−1,v " for feature functions.</p><p>The question here is how CFOs and U-CFOs can be modeled and what kind of features are needed. We assume characteristics of CFOs, and U-CFOs and partially exemplify their validity us- ing <ref type="figure">Figure 1</ref>, which depicts an example input sen- tence and information related to its constituent bunsetsu phrases. In the upper part of <ref type="figure">Figure 1</ref>, a rectangle and an arrow denote a bunsetstu phrase and a syntactic dependency between two phrases, respectively, and in each phrase we show Japanese words based on the Hepburn system and their En- glish translations in parentheses.</p><p>CFOs are associated with the following charac- teristics.</p><p>(a) By definition, CFOs determine the validity of the evaluation in an opinion unit, and thus syntactically modify an opinion word. Con- sequently, CFOs usually do not modify other elements in an opinion unit, such as an as- pect.</p><p>(b) Like a conjunction in a conditional clause in English, such as "if", a CFO in Japanese also includes a clue expression, which is usually a functional expression ( <ref type="bibr" target="#b11">Matsuyoshi et al., 2006</ref>) in the tail phrase, such as "ni wa ("for" in English)".</p><p>(c) The distribution for parts of speech as the head of CFOs is skewed and heads of CFOs are usually a noun or verb.</p><p>Additionally, U-CFOs are associated with the following characteristics.</p><p>(d) If a CFO is an opinion holder as in example (6) in Section 1, it is usually a U-CFO, which is the subject appearing at the beginning of a target sentence.</p><p>(e) By definition, U-CFOs include expressions related to user attributes, such as "nervosity" in <ref type="figure">Figure 1</ref>.</p><p>In this paper, we propose thirteen features to model CFOs and U-CFOs. In the bottom part of <ref type="figure">Figure 1</ref>, for each phrase we show the values of the thirteen features F1-F13 described below. These features were developed for the above five charac- teristics. F1-F5, F7-F10 and F13 are associated with (a), (b) and (c), respectively, while F6 and F11-F12 are associated with (d) and (e).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F1: Dependency distance to opinion word</head><p>CFOs, which affect the evaluation in that opinion, usually syntactically modifies the opinion word. Thus, there should be a pass of dependencies be- tween a Cond-phrase and the opinion word, and a -./&amp;0#</p><formula xml:id="formula_1">''''''''''''''''''''''''''''''''''''''''C''$%,.&amp;$%,D'!"#$%&amp;'#('$(/(#'-&amp;'$%,#.",$%,*$/'!"'$",43&amp;./'-('6(*(6"+/'.&amp;*&amp;'#,'-&amp;'*(*"6(')/.&amp;,'!&amp;*('(6(/8! ''''''''''''''''''''''''''''''''''''''''</formula><p>'''EF(-"2"+D'9'*%,#.'*%"'#(,$"'()'*+&amp;,#',$'&amp;##(3,#G'*%($"'-%('7+")"+'5/,"*'0"1&amp;/$"'()'#"+2($,*38H'  Figure 1: Example of Japanese sentence and the feature value for each constituent bunsetsu phrase phrase that leads to the opinion word via a smaller number of dependency arrows is more likely to be a Cond-phrase. We use the dependency dis- tance (i.e., the number of dependencies) between a phrase in question and the opinion word as the value for feature F1. The value for a phrase is −1 if there is no pass between that phrase and the opinion word. We use "CaboCha" ( <ref type="bibr" target="#b6">Kudo and Matsumoto, 2002</ref>) for dependency analysis purposes.</p><formula xml:id="formula_2">$%,.&amp;$%,D' !F(-"</formula><formula xml:id="formula_3">J?# I# I# &amp;$7"1*# I# I# I# I# I# (7,#,(#'-(+!# I# JA# #(*%,#G' #(*%,#G' &amp;$7"1*# #(*%,#G# #(*%,#G# #(*%,#G# #,'-&amp;# #(*%,#G# (7,#,(#'-(+!# #(*%,#G# J@# #(*%,#G# #(*%,#G# &amp;$7"1*# #(*%,#G# #(*%,#G# #(*%,#G# *(7,1# #(*%,#G# (7,#,(#'-(+!# #(*%,#G# JB# #(*%,#G# #(*%,#G# &amp;$7"1*# #,'-&amp;# #,'-&amp;# #,'-&amp;# #,'-&amp;# #(*%,#G# (7,#,(#'-(+!# #(*%,#G# J:I# #(*%,#G# #(*%,#G# &amp;$7"1*# *(7,1# *(7,1# *(7,1# *(7,1# #(*%,#G# (7,#,(#'-(+!# #(*%,</formula><p>F2: Phrase distance to opinion word F1 is not robust against errors of the dependency analysis.</p><p>To alleviate this problem, we approximate the de- pendency distance by a phrase distance. In prac- tice, we subtract the ID for a phrase in question from that for the opinion word as the value for fea- ture F2. If the opinion word consists of more than one phrase, we take the minimum difference. Be- cause in Japanese a modifier is usually followed by its modifying object, a phrase with a negative value for feature F2 is usually an Other-phrase. For example, in the last phrase in <ref type="figure">Figure 1</ref>, which cannot be a modifier for the opinion word, is an Other-phrase.</p><p>F3: Dependency pass to aspect Because a CFO rarely modifies an aspect, for the value of feature F3 we take 0 if there is a pass of dependencies between a phrase in question and an aspect and 1 otherwise.</p><p>F4: Phrase distance to aspect Similar to F1, F3 is not robust against errors of the dependency analysis. As in F2, we approximate the value of F4 by a phrase distance between a phrase including an aspect and a phrase in question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F5: Difference between values for F2 and F1 A CFO usually consists of a sequence of</head><p>Cond-phrases where each phrase modifies the next phrase, as in <ref type="figure">Figure 1</ref>. There is a tendency that as the difference of values of F1 and F2 for a phrase becomes smaller, that phrase is more likely to be a Cond-phrase. In <ref type="figure">Figure 1</ref>, the values for Cond- phrases #3-#6 are smaller than those for Other- phrases #0-#1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F6: Beginning of sentence</head><p>The subject of an opinion sentence is often its U-CFO because the evaluation is valid only from the perspective of that specific subject. For example, in "my daugh- ter was pleased with toys in the room" the positive evaluation is restricted by the daughter's perspec- tive. Thus, the value of feature F6 takes 1 for the first phrase in a sentence excluding a conjunction, and 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F7: Clue expression</head><p>Because a CFO often ends with one or more specific particles or auxiliary verbs, we use the existence of those clue expres- sions in a phrase as the value for feature F7. We use words in a dictionary of Japanese functional expressions "Tsutsuji" ( <ref type="bibr" target="#b11">Matsuyoshi et al., 2006)</ref> as the clue expressions. <ref type="table">Table 1</ref> shows exam- ples of entries for Tsutsuji. Each entry is repre- sented in a hierarchy structure with nine abstrac- tion levels. We firstly collected "Head words" in the nineteen categories (e.g., resultative condition and purpose in L2) associated with our purpose, consulting "Meaning categories". Then we col- lected "Surface forms" corresponding to the col- lected head words and identified their correspond- ing surface forms to standardize different forms. For example, for ID 1 and ID 3 in <ref type="table">Table 1</ref>, "to sure ba" and "nde" are regarded as identical to "to suru to" and "node", respectively. As a result, we col- lected 388 words, such as "ba (if)" and "ni (for)" and used their existence in a phrase in question as value for F7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F8: Semantic categories for clue expression</head><p>Because the data sparseness is a crucial problem for F7, we use the existence of semantic categories in Tsutsuji as the values of F8 for smoothing pur- poses. For example, in <ref type="table">Table 1</ref>, "to suru to" and "ba" have the same feature values "resultative con- dition". If a clue expression belongs to more than one semantic category as in "ni" of <ref type="table">Table 1</ref>, the feature value is a set of these categories.</p><p>F9: Dependency pass to phrase including clue expression (Surface form) As described in F7 above, the last phrase in a CFO often includes one or more clue expressions. In addition, a CFO often consists of more than one phrase. Given those con- ditions, a phrase that modifies a phrase contain- ing a clue expression is also likely to be a Cond- phrase. We use the existence of a dependency pass between a phrase in question and a phrase contain- ing a clue expression as the values of feature F9. F11: Restrictive words We use the existence of words that are strongly associated with U-CFO as the value for F11. We call such words re- strictive words. We automatically produced a dic- tionary of restrictive words from advertising slo- gans for hotels, which often include descriptions for target users, such as "joshikai ya kappuru ni osusume!! (Recommended to girls get-together and couples)". First, we extracted words in the ad- vertising slogan based on the following steps. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1: Example entries for Tsutsuji</head><p>Step 1: Extracting sentences that match to a regular expression "( | hito | mono | kata) ni ( | wa | mo) osusume" (i.e., "recommended to" or "rec- ommend to those who").</p><p>Step 2: Collecting a sequence of content words for each bunsetsu-phrase in the extracted sen- tences.</p><p>For the above advertising slogan, we can col- lect two restrictive words "joshikai (girls get- together)" and "kappuru (couple)" by performing those 2 steps.</p><p>Second, we collected a sequence of independent words for bunsetsu phrases which comprises U- CFO in an annotated corpus. We combined the ex- tracted words from the advertising slogans an an- notated corpora, discarded redundancy, and stan- dardized similar words, such as "kanko suru (do sightseeing) and "kanko (sightseeing)". As a re- sult, we collected 934 words.</p><p>Finally, we calculated a mutual information like score, Score(r, u), between a restrictive word r and labels u, Cond-phrases for U-CFOs (i.e., phrases labeled with either of BU or IU), by Equa- tion 2.</p><p>Score(r, u) = P (r, u) log P (r, u) P (r)P (u)</p><p>P (r, u) denotes the probability that a phrase in- cluding r is labeled with BU or IU in the annotated corpus. P (r) denotes the probability that a phrase including r appears in the annotated corpus while P (u) denotes the probability that a phrase labeled with BU or IU in the annotated corpus. If a phrase includes a restrictive word r and Score(r, u) is greater than threshold θ, the feature value is r, and "nothing" otherwise.</p><p>F12: Existence of restrictive word Because the data sparseness is a crucial problem for F11, we integrate all the restrictive words for F11 into a single category for smoothing purposes. The value for F12 is the existence (1/0) of restrictive words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F13: Part of speech for head</head><p>The likelihood that a phrase in question is a Cond-phrases par- tially depends on the part of speech for the head in that phrase. For example, in <ref type="figure">Figure 1</ref>, a phrase whose head is a noun or verb tends to be a Cond- phrase</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>To evaluate the effectiveness of our method, we used the Rakuten Travel data 1 , which consists of 348 564 Japanese reviews for hotels in Japan.</p><p>From this dataset, we selected 580 reviews and manually identified elements for opinion units.</p><p>We removed sentences consisting only of opin- ion unit such as "The location is good" from the evaluation. As a result, 3 155 sentences remained, which comprise our corpus. To evaluate the effec- tiveness for identifying CFOs, we used the man- ually annotated opinion elements as output of a pseudo automatic method. Given the above corpus, two annotators inde- pendently identified U-CFOs or CFOs, if any, for each opinion unit. For both annotations of CFOs and U-CFOs, the Kappa value for the inter- annotator agreement was 0.87, indicating strong agreement. We show the details of our corpus in <ref type="table" target="#tab_2">Table 2</ref>. Using this corpus, we performed 10-fold cross-validation and compared different methods from different perspectives. Also, we determined the threshold for Score (see Eq 2) by a develop- ment set for each fold.</p><p>To evaluate the effectiveness of extracting U- CFOs and CFOs independently, we first classified bunsetsu phrases into any of BU, IU, BC, IC, or Other. Then, for the U-CFO extraction we re- garded phrases for BU and IU as the Cond-phrases while for the CFO extraction we regarded phrases for BU, IU, BC, and IC as the Cond-phrases.</p><p>We used "Partial match" and "Exact match", which denote different criteria for the correctness of methods under evaluation. While in the partial match each method was requested to only detect whether or not a test sentence includes CFO, in the exact match each method was also requested to identify the span of each CFO. Also, we used dif- ferent evaluation measures, namely precision (P), recall (R), F-measure (F), and accuracy (A).</p><p>Rule-based method and SVM-based method are used for comparison purposes. Rule-based method first identifies a bunsetsu phrase whose de- pendency distance to the opinion word is 1 and in- cluding a clue expression (see Section 3), and also identifies a sequence of the phrases from which there is a dependency path to the above phrase as a CFO. For example, in <ref type="figure">Figure 1</ref> because phrase #6 includes a clue expression, a sequence of phrases #3-#6 is extracted as a CFO. These rules are based on features F1, F7 and F9. For the U-CFO extrac- tion task, we regarded a sequence of Cond-phrases extracted by the above method as U-CFO if that sequence includes a restrictive word. For SVM, the thirteen features F1-F13 proposed in Section 3 was used. We used LIBSVM ( <ref type="bibr" target="#b0">Chang and Lin, 2011</ref>) to train a classifier. Our method used CRF to train a classifier with the thirteen features and four patterns for feature functions. We used CRF++ 2 to train a classifier for each phrase and regularized the parameters using L2-norm. <ref type="figure" target="#fig_6">Figure 2</ref> shows the relationship between val- ues of regularization parameter and F-measure for exact match. In <ref type="figure" target="#fig_6">Figure 2</ref>, "Rule", "SVM", and "CRF" denote a rule-based method, SVM-based method, and our method, respectively. The F- measure for Rule, independent of the regulariza- tion parameter, is a constant. While the F-measure for SVM substantially varied depending on the pa- rameter value, that for CRF did not vary that much. Additionally, the F-measure for CRF was larger than that for SVM irrespective of the parameter value and matching criterion. <ref type="table">Table 3</ref> shows results obtained with the optimal value for the regularization parameter. Looking at <ref type="table">Table 3</ref>, one can see that CRF outperformed the other methods in terms of F-measure and accu- racy for both partial and exact matches. We used the two-tailed paired t-test for statistical testing and found that the differences of CRF and each of the other methods in F-measure and accuracy were statistically significant at the 1% level irrespective of the configuration. <ref type="figure">Figure 3</ref> shows the effectiveness of the pro- posed features for exact match. The horizontal axis "w/o X" denotes a method without feature X. The vertical axis denotes a ratio of each method to our method. If a method without feature X takes less than 1 for value of vertical axis, the feature X is effective for extracting CFOs. Looking at <ref type="figure">Fig- ure 3</ref>, one can see that our complete method out- performed any variation of our method in terms of        -measure. Thus, we conclude that each of our thirteen features was independently effective for extracting CFO and U-CFO in review sentences and that when used together the improvement was even greater.</p><p>For the U-CFO extraction, we analyzed the er- rors by our method. The total number of errors was 363 by condition unit. We describe causes of the errors with example sentences, translated into English by the authors. In those examples, dou- ble and single underlines denote false positive and false negative, respectively. For each cause, we show the number of errors in parentheses.</p><p>E1 (124) Errors were due to F11 and F12 with insufficient dictionary for restrictive words. Typi- cally, low frequency words (e.g., pilgrimage) and words related to miscellaneous activities during a travel (e.g., charging a battery of a mobile phone) were not included in our dictionary. While it is im- portant to increase the vocabulary size of our dic- tionary, identifying synonymous expressions with partial matching (e.g., go to sleep / go to bed) is also important. E2 (53) Errors were due to dependency anal- ysis, which often mistakenly recognizes sen- tence boundaries in an informal writing style and dependency relations in a sentence com- prising a phrase, such as "the best location for fully enjoying Asakusa". In this example, CaboCha mistakenly associated the adnominal modifier "for fully enjoying Asakusa" with "loca- tion (aspect)" instead of "best (opinion word)". As a result, F1 and F3 did not regard this modifier as a U-CFO. E3 (40) Restrictive modifiers that modify a non- opinion segment were mistakenly extracted as U-CFOs. For example, in "I used this hotel for business and the meal was good", "for busi- ness" includes the clue expression "for" but does not modifies the opinion unit. E4 (39) Similar to E3 but errors were due to restrictive words instead of clue expressions. In the example for E3, the restrict word "business" caused the error. E5 (26) U-CFOs that consist of a large num- ber of phrases were often not extracted due to F5, such as "This hotel is acceptable for one night to take the train at the Chuo station next morning". E6 (25) Errors were due to irrelevant entries in our restrictive word dictionary. E7 (11) Due to the sparseness problem for re- strictive words in the training data, U-CFOs and CFOs were not correctly distinguished.</p><p>E8 (9) Errors were due to part-of-speech tag- ging.</p><p>E9 (6) Errors were due to extracting modifiers consisting of a personal pronoun without addi- tional user-related attributes, such as "enough for me" , as U-CFOs. We need to identify whether an expression for a person is associated with user- related attributes, such as "the bed is small for a person who is tall", which indicates a physical at- tribute of a user.</p><p>Additionally, there are 65 errors for which we have not found a reason.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Although a number of methods have been pro- posed to search an opinionated corpus for opin- ion units, few attempts have so far been made at addressing cases where the validity of an evalua- tion is restricted on a condition in the source text. We proposed a method to identify such condi- tions from sentences including opinion units. Our method performs sequence labeling to determine whether each phrase is a constituent of an condi- tion for opinion. We proposed thirteen features as- sociated with lexical and syntactic information of Japanese, and showed their effectiveness using re- views for hotels. The contributions of this paper are introducing the notion of conditions for opin- ions, which is language-independent, proposing a method to extract condition-opinion relations from opinionated corpora, and giving an insight into its potential applications in opinion mining.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 7 )</head><label>7</label><figDesc>Hotel A would not have survived if the price was not reasonable. (8) If you are looking for a hotel with a reason- able price, stay at hotel A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>F10:</head><label></label><figDesc>Dependency pass to phrase including clue expression (Category) As with F8, we use the existence of semantic categories of Tsutsuji as the values of feature F10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Opinion</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Relationship between values for regularization parameter and F-measure in exact match</figDesc><graphic url="image-2.png" coords="8,93.91,247.44,194.88,126.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>3 :Figure 3 :</head><label>33</label><figDesc>Figure 3: Effectiveness of proposed features for exact match</figDesc><graphic url="image-5.png" coords="8,304.48,552.85,219.14,135.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Details of our corpus</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> https://alaginrc.nict.go.jp/resources/rakutendataset/rakuten-outline.html</note>

			<note place="foot" n="2"> http://crfpp.googlecode.com/svn/trunk/doc/index.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Professor Takenobu Toku-naga (Tokyo Institute of Technology) for his valu-able comments. This research was supported in part by Grant-in-Aid for Scientific Research (Grant No. 15H02747).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename><surname>Chih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Chinese sentencelevel sentiment classification based on fuzzy sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guohong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="312" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatically extracting polarity-bearing topics for cross-domain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harith</forename><surname>Alani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="123" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Opinionminer: A novel machine learning system for web opinion mining and extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung</forename><forename type="middle">Hay</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohini</forename><forename type="middle">K</forename><surname>Srihari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD</title>
		<meeting>the 15th ACM SIGKDD</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic identification of pro and con reasons in online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Soo-</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL</title>
		<meeting>the COLING/ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<title level="m">Main Conference Poster Sessions</title>
		<imprint>
			<biblScope unit="page" from="483" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Japanese dependency analysis using cascaded chunking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Natural Language Learning</title>
		<meeting>the 6th Conference on Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Machine Learning</title>
		<meeting>the 18th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A survey of opinion mining and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mining Text Data</title>
		<editor>C.C. Aggarwal and C.X.Zhai</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="415" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Syntactic patterns versus word alignment: Extracting opinion targets from online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1754" to="1763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Extracting opinion targets and opinion words from online reviews with graph co-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="314" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Compilation of a dictionary of Japanese functional expressions with hierarchical organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suguru</forename><surname>Matsuyoshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takehito</forename><surname>Utsuro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Processing of Oriental Languages. Beyond the Orient: The Research Challenges Ahead</title>
		<editor>Yuji Matsumoto, Richard Sproat, Kam-Fai Wong, and Min Zhang</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">4285</biblScope>
			<biblScope unit="page" from="395" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cross-lingual mixture model for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinfan</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="572" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The FLDA model for aspect-based opinion mining: Addressing the cold start problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samaneh</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on World Wide Web</title>
		<meeting>the 22nd International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="909" to="918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ETF: Extended tensor factorization model for personalizing prediction of review helpfulness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samaneh</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Jamali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Fifth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="163" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sentiment analysis of conditional sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramanathan</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Choudhary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="180" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A classificationbased review recommender. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>O&amp;apos;mahony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Smyth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="323" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Multilingual opinion holder identification using author and authority viewpoints. Information Processing and Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohei</forename><surname>Seki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noriko</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaki</forename><surname>Aono</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="189" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Joint inference for fine-grained opinion extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1640" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Jointly modeling aspects and opinions with a MaxEnt-LDA hybrid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
