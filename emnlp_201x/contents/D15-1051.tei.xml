<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Spelling Correction of User Search Queries through Statistical Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saša</forename><surname>Hasan</surname></persName>
							<email>sasa.hasan@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">eBay Inc</orgName>
								<address>
									<addrLine>2065 Hamilton Ave San Jose</addrLine>
									<postCode>95125</postCode>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carmen</forename><surname>Heger</surname></persName>
							<email>heger.carmen@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">eBay Inc</orgName>
								<address>
									<addrLine>2065 Hamilton Ave San Jose</addrLine>
									<postCode>95125</postCode>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saab</forename><surname>Mansour</surname></persName>
							<email>saamansour@ebay.com</email>
							<affiliation key="aff0">
								<orgName type="institution">eBay Inc</orgName>
								<address>
									<addrLine>2065 Hamilton Ave San Jose</addrLine>
									<postCode>95125</postCode>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Spelling Correction of User Search Queries through Statistical Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We use character-based statistical machine translation in order to correct user search queries in the e-commerce domain. The training data is automatically extracted from event logs where users reissue their search queries with potentially corrected spelling within the same session. We show results on a test set which was annotated by humans and compare against online autocorrection capabilities of three additional web sites. Overall, the methods presented in this paper outperform fully productized spellchecking and autocorrec-tion services in terms of accuracy and F1 score. We also propose novel evaluation steps based on retrieved search results of the corrected queries in terms of quantity and relevance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Spelling correction is an important feature for any interactive service that takes input generated by users, e.g. an e-commerce web site that allows searching for goods and products. Misspellings are very common with user-generated input and the reason why many web sites offer spelling cor- rection in the form of "Did you mean?" sug- gestions or automatic corrections. Autocorrec- tion increases user satisfaction by correcting ob- vious errors, whereas suggestions make it con- venient for users to accept a proposed correction without retyping or correcting the query manually. Spelling correction is not a trivial task, as search * The author is now affiliated with Lilt Inc., Stanford, CA, USA.</p><p>† The author is now affiliated with Stylight GmbH, Mu- nich, Germany. queries are often short and lack context. Mis- spelled queries might be considered correct by a statistical spelling correction system as there is ev- idence in the data through frequent occurrences.</p><p>While common successful methods (cf. Sec- tion 1.1) rely on either human-annotated data or the entire web, we wanted to use easily accessi- ble in-domain data and on top of that technology that is already available. In this work, we use user event logs from an e-commerce web site to fetch similar search query pairs within an active session. The main idea is that users issue a search query but alter it into something similar within a given time window which might be the correction of a poten- tial typo. To the best of our knowledge, the idea of collecting query corrections using user session and time information is novel. Previous work sug- gested collecting queries using information that a user clicked on a proposed correction. Our pro- posed method for collecting training data has sev- eral advantages. First, we do not rely on a pre- vious spelling correction system, but on user for- mulations. Second, for many search queries, es- pecially from the tail where search recall is gen- erally low, these misspellings yield few results, and thus, users looking for certain products are in- clined to correct the query themselves in order to find what they are looking for. We use Damerau- Levenshtein distance <ref type="bibr" target="#b3">(Damerau, 1964)</ref> on charac- ter level as similarity criterion, i.e. queries within a specific edit distance are considered to be related.</p><p>The steps proposed in this work are:</p><p>1. Extraction of similar user queries from search logs for bootstrapping training data (Sec- tion 2),</p><p>2. classification and filtering of data to remove noisy entries (Section 3), and 3. spelling correction cast into a statistical ma- chine translation framework based on charac- ter bigram sequences (Section 4).</p><p>We also evaluate the work thoroughly in Sec- tion 5 where we compare our method to three other online sites, two of them from the e-commerce domain, and present a novel approach that deter- mines quality based on retrieved search results. We show examples indicating that our method can handle both corrections of misspelled queries and queries with segmentation issues (i.e. missing whitespace delimiters). A summary can be found in Section 6.</p><p>To our knowledge, this is the first work that uses character-based machine translation technol- ogy on user-generated data for spelling correction. Moreover, it is the first to evaluate the performance in an e-commerce setting with there relevant mea- sures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>One of the more prominent papers on autocorrec- tion of misspelled input is ( <ref type="bibr" target="#b23">Whitelaw et al., 2009</ref>). The three-step approach incorporates a classifica- tion step that determines whether a word is mis- spelled, computes the most likely correction can- didate and then, again, classifies whether this can- didate is likely to be correct. An error model based after <ref type="bibr" target="#b0">(Brill and Moore, 2000</ref>) is trained on sim- ilar word pairs extracted from large amounts of web sites, and a language model is used to dis- ambiguate correction candidates based on left and right context around the current position. Our method differs in several ways. First, we consider full query pairs as training data, and do not use single words as primary mode of operation. Sec- ond, we do not train explicit error models P (w|s) for words w and observed corrections s, but use standard phrase-based machine translation model- ing to derive phrase and lexical translation mod- els. Although our level of context is shorter, es- pecially for long words, the system automatically uses cross-word level context.</p><p>The idea of using consecutive user queries from a stream of events to improve ranking of web search results was described in <ref type="bibr" target="#b19">(Radlinski and Joachims, 2005</ref>). The authors introduce the no- tion of query chains that take advantage of users reformulating their queries as a means to learn bet- ter ranking functions. The classification of query chains is performed by support vector machines, and its training data is generated in a supervised fashion by manual inspection and annotation. In contrast, we do not manually annotate any of our training data. Since our initial sets are quite noisy, we apply a couple of heuristics that try to produce a cleaner subset of the data that contains mostly misspelled queries and their potential correction candidates.</p><p>Another focus of researchers was specifically to tackle misspelled web search queries and use search engine logs for training and evaluation data ( , which differs from our work by collecting data using "click-through" enforce- ment. The user is presented with a spelling cor- rection, and if she clicks on it, they learn that the correction is valid. Our method does not need a previous spelling correction to work. In addition, our proposed method has the potential to learn cor- rections of new and rare terms that will not be pro- duced by an automatic spelling correction.</p><p>In ( <ref type="bibr" target="#b24">Zhang et al., 2006</ref>), the authors use a conventional spellchecker to correct web queries through additional reranking of its output by a ranking SVM. The training data is in part auto- matically extracted, but also contains manually an- notated pairs and, thus, is a semi-supervised ap- proach. In this paper, we use an unsupervised ap- proach to generate training data. Query spelling correction that is based on click-through data and uses a phrase-based error model is reported in ( ). Our models operate on char- acter sequences instead of words, and we do not observe issues with identity transformations (i.e. non-corrections for correctly spelled input).</p><p>In ( <ref type="bibr" target="#b2">Cucerzan and Brill, 2004</ref>), the authors inves- tigate a transformation method that corrects un- likely queries into more likely variants based on web query logs. The iterative approach transforms a search query based on word uni-and bigram decompositions, and the authors evaluate on both a large set that contains around 17% misspelled queries and a smaller set that is based on succes- sive user-reformulated similar queries, a similar setup that we use to extract our training data. They stress the importance of a good language model, as performance drops drastically going from a bi- gram to a unigram LM.</p><p>The use of character-based models in combi- nation with statistical machine translation is not novel and was proposed for spelling correction, e.g., in (Formiga and Fonollosa, 2012), ( <ref type="bibr" target="#b12">Liu et al., 2013)</ref> or ( <ref type="bibr" target="#b1">Chiu et al., 2013)</ref>. The authors compare a distance-based approach including a language model, a confusion network-based approach, a translation approach through a heuristically de- fined phrase table coding all character transfor- mations, and a character-based machine transla- tion approach using standard procedures (auto- matic word alignment and phrase extraction). The training data is manually created in contrast to our work where we automatically bootstrap train- ing data from query logs. Research has also been done for translation of closely related languages (e.g. ( <ref type="bibr" target="#b22">Vilar et al., 2007)</ref> and <ref type="bibr" target="#b14">(Nakov and Tiedemann, 2012)</ref>) and transliteration (e.g. ( <ref type="bibr" target="#b4">Deselaers et al., 2009)</ref>). An early summary paper with various spelling-related problems (non-word error detec- tion, isolated-word error correction, and context- dependent word correction) can be found in ( <ref type="bibr" target="#b10">Kukich, 1992</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Extraction of training data</head><p>We use event logs that track user interactions on an e-commerce web site. Each action of a user visiting the site is stored in a data warehouse and HDFS (Hadoop Distributed File System). We store several billion of these user records on a daily basis. The setup allows us to efficiently process large amounts of data points using a Map-Reduce framework via Hadoop <ref type="bibr">1</ref> . As part of user event tracking, all interactions on the site are stored in the database, e.g. which search terms were en- tered, which links were clicked, and what actions resulted in this (i.e. buying an item, adding it to a like or watch list, or simply advancing to the next page of search results, and so on). We focus on search terms that users enter within a given period of time.</p><p>Our hypothesis is that users that enter consecu- tive search terms are not satisfied with the results and try to modify the query until the results are ac- ceptable. We then analyze the sequence of search queries as part of each user session. We only ex- tract consecutive search queries that are similar in terms of character-level Damerau-Levenshtein edit distance which is the minimum number of character insertions, deletions, substitutions and transpositions (i.e. the swapping of two charac- ters). Note that spelling correction in this kind of environment also needs to address segmentation of queries in case of missing whitespace. It is quite common to find query terms being concatenated without the use of a space character, e.g. calvin- klein, ipadair or xboxone. Also, search queries are short in nature and often lack context, and particu- larly for the e-commerce domain largely consist of brand and product names and associated attributes (e.g. size of clothing).</p><p>Our method extracts similar search query pairs that will be used in our statistical machine trans- lation setup as training data. <ref type="table">Table 1</ref> shows ex- amples that we extract from the event logs. We use edit distance thresholds of 3 and 5 characters, where the latter is generally noisier. Noise in this context is everything that is not related to mis- spelled queries. After a closer look, we observe that many queries are simply rewrites, i.e., users either make refinements to their original query by adding more words to narrow down results, e.g., leather wallet → leather wallet men, delet- ing words to decrease specificity, e.g., gucci belt → gucci, or simply going through various related products or attributes, e.g., iphone 5 → iphone 5s → iphone 6 where they progress through different products or nike air 9 → nike air 9.5 → nike air 10 where they iterate through different sizes.</p><p>The logs on HDFS are organized as sessions where each session contains a stream of user events up to a specific time of inactivity. We use event timestamps to determine how long the users need between consecutive queries, and discard similar query pairs if they are above a threshold of 20 seconds. We use Hadoop-based mapper and reducer steps for the data extraction procedure. In the mappers, pairs of similar user search queries get emitted as per above edit distance criterion on character level, whereas the reducer simply accu- mulates all counts for identical search query pairs. Due to the size of the data, we run the Hadoop extraction jobs on 24-hour log portions, thus ob- taining separate data sets for each day. Overall, we can extract several hundred thousand to sev- eral million similar query pairs on a daily basis for edit distance thresholds of 3 and 5, respectively.</p><p>We pull several months of data from the Hadoop logs and accumulate each daily pull with unique entries for training our spelling correction system. As mentioned above, search queries that are simi- lar but where the original query is not misspelled make up a big portion of the extracted data. The following section focuses on how to filter the data to result in containing mostly query pairs that fit Search query <ref type="table" target="#tab_1">Similar consecutive query  Edit distance User correction?  nike air hurache  nike air huarache  1  Yes  jordan size 9  jordan size 9.5  2  No  galaxy s4  galaxy s5  1  No  pawer cord forplaystation 3 power cord for playstation 3  2  Yes  iphine 6  iphone 6  1  Yes  iphone 6</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Filtering non-misspelled input</head><p>We tested a heuristic approach to filtering search query pairs: a combination of regular expressions and thresholded feature scores that detect search progressions and refinements which should be re- moved from the training data as they do not repre- sent valid user corrections. The manual filtering heuristic calculates a se- quence of features for each search query pair, and as soon as a feature fires, the entry is removed. In the following, we will use the notation (x, y) for a search query pair that is extracted from the logs explained by our method in the previous sec- tion. Query x is a user search query, and query y is a similar query issued by the user in the same session within a specific time window. Exam- ple query pairs are (babydoll, baby dolls), (bike wherl, bike wheel) or (size 12 yellow dress, size 14 yellow dress). We use the following features as part of this process:</p><p>Regular expressions. We remove search query pairs (x, y) if y is a rewrite of x using search- related operators, e.g. y = "x" which adds quo- tation marks around the query (and, thus, has an edit distance of 2). Example: (bluetooth speakers, "bluetooth speakers").</p><p>LM ratio. We use an English language model trained on publicly available corpora (e.g. Eu- roparl), frequent queries and web content from the e-commerce domain to calculate log-likelihoods for each query and filter entries if the ratio is above zero, i.e. log p(x/y) = log p(x) − log p(y) &gt; 0. This step essentially removes query pairs (x, y) if the log-likelihood of query y is smaller than x which usually indicates that the correction is more perplexing than the original query. Exam- ple: (bluetooth ear phones, bluetooth ear hpones) with a log-likelihood ratio of -7.31 + 16.43 &gt; 0 is removed as a typo actually appears on the "cor- rected" side.</p><p>Edit operations. We use a simple heuristic that detects search refinements in terms of word inser- tions and deletions: a word-level edit distance cri- terion is used to remove entries where edit opera- tions indicate insertions or deletions of full words. We also detect substitutions on number tokens which are also excluded from training data. Ex- amples: (polo shirt, polo shirt xl), (nikon d700, nikon d7100).</p><p>Frequent terms. We look at queries (x, y) and use a vocabulary with relative frequencies based on the query data y to determine whether sub- stitutions on word level change a frequent token into another frequent token. Examples: (snake bat wooden, snake bat wood), (hd dvds, hd dvd) where wood/wooden and dvds/dvd are both fre- quent tokens and, thus, most likely rewrites and not corrections.</p><p>Language ID. The primary search language on US sites is English, but there is also a non- negligible mix of other languages, Spanish in par- ticular. We do not remove all queries that are not identified as English because language identifica- tion on (often short) search queries is a non-trivial Method #queries #tokens MT Acc all data 80.5M 235.6M 62.0% heuristic filter 12.6M 40.1M 65.5% <ref type="table">Table 2</ref>: Filtering training data with a heuristic set of features. Accuracies are given on DEV for MT baselines with differences only in the data setup.</p><p>task with a high error rate and filtering for only En- glish would remove a lot of valid entries. We sim- ply remove query pairs where x is identified as ei- ther Spanish or Unknown based on Google's Com- pact Language Detector 2 . Example: (accesorios cuarto, accesorios de cuarto). These heuristics help us to reduce the training data size from 80 million noisy search query pairs with around 235 million tokens to 12.5 million query pairs with roughly 40 million tokens that are of higher quality and most likely spelling correc- tions. <ref type="table">Table 2</ref> shows results of this filtering step in terms of data sizes and the accuracy on the dev set (cf. Section 4). We observe that the filter- ing scheme reduces overall training size by almost 85% and increases accuracy on the development set by 3.5% absolute. The removal of query pairs is very aggressive at this point, and overall quality of the spelling correction framework might benefit from a more careful selection. We will look into improved variants of filtering through a maximum entropy classifier trained on actual search results in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Autocorrection framework</head><p>We cast the autocorrection task into character- based statistical machine translation. For this, we prepare the data by splitting words into sequences of lowercased characters and use a special charac- ter to mark whitespace that indicates word bound- aries. Once these sequences of characters are cor- rected, i.e. translated, they are merged back to the full word forms. <ref type="table" target="#tab_1">Table 3</ref> shows an example search query being preprocessed, translated and postpro- cessed. We use bigram characters instead of single characters, as suggested in <ref type="bibr" target="#b21">(Tiedemann, 2012)</ref>, in order to improve the statistical alignment models and make them more expressive.</p><p>For training the autocorrection system we use basic methods and open-source tools for statistical machine translation. The character alignment is obtained by using GIZA++ (Och and Ney, 2003) for 4, 3 and 2 iterations of IBM Model 1, HMM, and IBM Model 3, respectively. As opposed to the standard machine translation task, we did not observe improvements from IBM Model 4 and do not use it as part of the alignment process.</p><p>We use Moses ( <ref type="bibr" target="#b9">Koehn et al., 2007</ref>) for standard phrase extraction, building KenLM language mod- els (Heafield, 2011) and tuning. The standard set of features is used, including a phrase model, word lexicon model, length penalty, jump penalty and a language model. The model weights are optimized using MERT <ref type="bibr" target="#b16">(Och, 2003)</ref>. The Moses framework allows us to easily conduct experiments with sev- eral settings and find the optimal one for our task at hand. We experiment with varying context sizes for phrase table and language model, additional features and different scoring methods, e.g. BLEU ( <ref type="bibr" target="#b18">Papineni et al., 2002</ref>) in comparison to directly maximizing accuracy on the dev set. A more de- tailed description of those experiments including results will follow in Section 5.</p><p>Evaluation data. In order to evaluate our pro- posed framework, we extracted 10,000 query pairs from a one week period not part of the training data. The initial size of 3.5M query pairs was re- duced to 10k by exponential reservoir sampling ( <ref type="bibr" target="#b17">Osborne et al., 2014</ref>) after sorting by frequency. The result is a set of representative query pairs that focuses more on frequent misspellings, but also contains rare queries from the tail of the distribu- tion.</p><p>We asked humans to create a gold reference an- notation that we can use for tuning and evaluation purposes. The guidelines were to check whether for a search query pair (x, y), the left query x is misspelled, and if so, whether the similar candi- date y is a correct correction or else provide the most likely correction. If x was not misspelled, the guidelines instructed to propagate query x to the gold reference y, i.e. for those cases, we have identity or a true negative. If query x is not En- glish, the annotators had to mark those entries and we removed them from the set. This step affected 798 queries (i.e. around 8%, mostly Spanish), and the final set contains 9202 query pairs. We split those into half to produce 4,600 queries for dev and 4,602 for test. The true negatives in those sets (i.e. entries that do not need to be corrected) are  recall over precision, as the majority of queries is usually not misspelled. Nevertheless, exponential reservoir sampling helps us to focus on the head of that distribution, and our main goal is to evaluate the capabilities of the spelling correction frame- work, not the overall system integration. A final investigation in combination with query expansion that will be evaluated in the context of the live site is left for future work. Detailed statistics on the two sets can be found in <ref type="table" target="#tab_2">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>characters character bigrams Original: hollowin custome Preprocessing: h o l l o w i n S c u s t o m e ho ol ll lo ow wi in nS Sc cu st to om me Translation: h a l l o w e e n S c o s t u m e ha al ll lo ow we ee en nS Sc co st tu um me Postprocessing: halloween costume</head><p>Additional training data. In addition to the par- allel data pull from the query logs as described in Section 2, we also take the top queries from those logs where we are sure they are most likely cor- rect and can be used as gold reference (e.g. search queries like handbags or wedding dress appear thousands of times), and generate artificially nois- ified variants based on an English keyboard layout and statistics derived from our development set.</p><p>On the dev set, we calculated a character error rate of roughly 6%, and this rate is used as a muta- tion rate for the artificially introduced noise. We also determine the following edit operation rates based on the dev set: 6% character transpositions, 18% for deletions, 33% for insertions, and 43% for substitutions. The target character for substi- tutions and insertions is based on a random Gaus- sian distribution with a distance mean 1 and stan- dard deviation of 1 around the selected character, i.e. we target neighboring keys on the keyboard. For the query wedding dress, e.g., this method in- troduces misspelled variants such as weddig dress, weedimg dress, or weddinb dreess. We run this method 10 times on a set of 688k queries and re- move all duplicates, resulting in additional 4.6M search query pairs with around 13M tokens for the training data.</p><p>As a final step, we add frequent queries from user event logs but also product titles of the live in- ventory to the language model. In total, the mono- lingual portion of the data contains roughly 31M entries with 319M tokens which are added to the target side of the bilingual training portion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we report on a series of hillclimb- ing experiments used to optimize performance. In the following, we use standard information re- trieval criteria for evaluation, namely accuracy, precision, recall, and F1 score. <ref type="figure" target="#fig_0">Figure 1</ref> depicts a natural way of how the scoring is performed. TP denotes true positives, FN false negatives, FP false positives, and TN true negatives, respec- tively. Note that for the case where the gold ref- erence demands a correction, and the speller pro- duces a wrong correction different from the source query, we have to increase both false positives FP and false negatives FN . With this, we can do stan-</p><formula xml:id="formula_0">TEST [%] Acc Prec Rec F1 online A</formula><p>68.8 84.0 64.2 72.8 online B</p><p>63.0 77.4 60.2 67.7 online C 56.3 58.6 60.7 59.7 MT (this work) 70.6 74.0 72.3 73.1 MT (alt. setup) 70.2 77.1 69.3 73.0 <ref type="table">Table 5</ref>: Comparison of accuracy, precision, recall and F1 score against other online sites on the test set.</p><p>dard calculation of accuracy as (TP + TN )/(P + N ) with P = TP + FN and N = TN + FP , pre- cision as TP /(TP + FP ), recall as TP /P , and F1 score as 2TP /(2TP + FP + FN ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Hillclimbing and performance</head><p>We compare the performance of our autocorrec- tion system with that of three other online search engines, both from the e-commerce as well as web search domain. For this, we automated entering our search terms on the corresponding sites and extracted candidates from "Did you mean..." sug- gestions or "Showing results for..." autocorrec- tions. <ref type="table">Table 5</ref> shows that our method outperforms all other systems in accuracy, recall and F1 score. We argue that recall in our setup is more impor- tant than precision because the goal is to correct as much as possible as autocorrection is usually invoked by the search backend as a result of low or null recall size.</p><p>Gradual improvements were made to the system setup and we track those on the development set. <ref type="table">Table 6</ref> gives a couple of major waypoints in the hillclimbing process. The baseline incorporates all extracted training data and uses phrases up to length 3 (i.e. up to three character bigrams for both source and target side). The baseline language model uses 6-grams. This setup is trained on very noisy data that contains a lot of search refinements that are not actual misspellings. The filtered data improves results. In general, we observe a 3-4% relative improvement across all scores when us- ing bigrams instead of single characters. We ex- periment with additional phrase features as part of the phrase table and add 5 features based on phrase pair-specific edit operations, i.e. the num- ber of insertions, deletions, substitutions, transpo- sitions and final overall edit distance, which helps to increase precision. The artificially noisified data gives additional small gains, as well as direct op- timization of accuracy instead of BLEU or WER. We did not observe significant differences when tuning on BLEU versus WER. Most of the im- provement though comes from increasing context size, i.e., 10-gram language models and lengths up to 5 bigram character spans for both source and target phrases. We also observe that iterative correction, i.e. running the speller a second time over already corrected data, further improves per- formance slightly which is in-line with findings in ( <ref type="bibr" target="#b2">Cucerzan and Brill, 2004)</ref> and <ref type="bibr" target="#b7">(Gubanov et al., 2014</ref>).</p><p>Increasing precision. We also investigated a system setup that focuses on precision over re- call in order to be more in sync with the online systems that have been most likely optimized to a more cautious correction mode. Our previous ex- periments prefer recall which is due to the 85:15 split of misspelled vs. correct queries in the dev set. For a more conservative mode that focuses on precision, we updated the dev set by automat- ically adding "mostly-correct" queries with iden- tity as correction candidate. For this, we extracted the most frequent queries with a high number of search results which can be deemed to be "al- most" correct. The dev size increased to roughly 22k queries with an approximate split of 85:15 for "correct" vs. misspelled. This is a more realistic setting if the correction is applied to all incom- ing queries, irrespective of the number of corre- sponding search results (note also that this mode is different from our initial one where we apply cor- rections only to queries with low or null results). We also found that tuning on Matthews Correla- tion Coefficient <ref type="bibr" target="#b13">(Matthews, 1975)</ref> balances better precision versus recall, especially for unbalanced classes which is the case here (i.e. 85:15 split).</p><p>In the last line of <ref type="table">Table 6</ref> we added more data extracted over several additional months. The ad- ditional data amounts to 60M queries, therefore increasing the total training size to 72M queries. This final setup, as described, improves precision but hurts recall slightly. Overall, the F1 and ac- curacy measures are still improved which is most likely due to the additional training data.</p><p>Finally, we ran a large-scale experiment and extracted the 100k most frequent unique queries (which account for 7.8M queries based on their actual frequencies). Since they represent the most common queries, some of them typed thousands of times by the users, they are deemed to be DEV  <ref type="table">Table 6</ref>: Hillclimbing on the dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query</head><p>Category distribution moto x 50% cell phones, 30% auto- motive, 5% clothing, ... tory burch fitbit 75% jewelry, 20% sports, ... madden 15 65% games, 18% toys, 7% collectibles, ... <ref type="table">Table 7</ref>: Item category distributions for queries.</p><p>"mostly" correct. We autocorrect the set through our best system which results in changed queries in &lt;0.5% of the cases after manual filtering of non-errors (e.g. segmentation differences that are handled separately by our query expansion sys- tem, e.g. rayban → ray ban which are equivalent in the search backend) and when compared against the original input set. This means that most of the queries are left unchanged and that the decod- ing process of the SMT system does a good job in classifying whether a correction is needed or not. Manual inspection of the most frequent differ- ences shows that changes actually happen on fre- quently misspelled words which are part of those top 100k queries, e.g. micheal → michael, infared → infrared, or accesories → accessories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Search evaluation</head><p>An interesting way to evaluate the performance of the autocorrection system is to look at it from a search perspective. If the goal is to improve user experience in search and retrieve more relevant re- sults, we need to compare the search result sets in terms of quantity and quality. For quantity we are mainly interested in how many queries lead to 0 search results before and after autocorrection.  the source set we improve the query behavior for 63.8% queries after autocorrection while we only decrease from non-null to null for 1.6%. A manual inspection of the 1.6% shows that those queries al- ready led to very low search results (&lt;10) even for the source. For quality, we compare the search result sets for the autocorrected queries with those of the ref- erence and get an estimate of how similar each autocorrected query behaves to the expected be- havior given by its gold correction. In particular, we extract the categories from all items which are returned as part of the search API calls (see <ref type="table">Ta- ble 7</ref>). We use Kullback-Leibler divergence <ref type="bibr" target="#b11">(Kullback and Leibler, 1951)</ref> to compute the difference between the category distributions. The KL diver- gence defines the information lost when using one distribution to approximate another:</p><formula xml:id="formula_1">D(P ||Q) = i P (i) · ln P (i) Q(i)</formula><p>In our case, we use the category distribution of the results of the reference query as the observed data P which we want to model with the category dis- tribution Q from the results of the autocorrected query. This gives us a more realistic evaluation of the method, as it is more relevant to the retrieval problem that autocorrection is trying to address. The queries perfumes for women and perfume for women, e.g., retrieve similar amounts and types of items although their strings are different (note the plural s in the first one) which is penalized when computing accuracy on string level. In order to deal with zero-probability events, we smooth both distributions such that they contain exactly the same categories. For this we add cat- egories that are present in one distribution but not  <ref type="table">Correction  adidda whatch blooto  adidas watch bluetooth  awrppstale buttin shirt  aeropostale button shirt  bangen olafsn headset  bang olufsen headset  camra exesers  camera accessory  crystal and righston cuf ring  crystal and rhinestone cuff ring  fauxfurmidcalfwesternboots  faux fur mid calf western boots  fotbool chus  football shoes  otherbooxiphon5</ref> otterbox iphone 5 womens realhairsaltandpeper womens real hair salt and pepper <ref type="table">Table 9</ref>: Examples of misspelled user search queries that the presented system is able to correct. the other with a very small probability which we subtract from the highest probability in the distri- bution so that all probabilities still sum up to 1. In the case of getting 0 search results for either the autocorrected or reference query we cannot com- pute the KL divergence and we simply mark those cases with a high number. If both queries return 0 search results we return a distance of 0. Note that with this we do not penalize queries that are misspelled and should have been corrected even if they still retrieve 0 items in search after correction. However, in this test we are only interested in the search results we get and not in the correction it- self. <ref type="table" target="#tab_4">Table 8</ref> shows that the presented method is clos- est in terms of KL divergence to category distri- butions of search results based on the gold refer- ences. Even though this is a nice and easy way to indicate quality of search results, we do not claim this method to be an in-depth analysis of relevance of search results and leave this for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Examples</head><p>The examples in <ref type="table">Table 9</ref> demonstrate the abil- ities of the presented spelling correction frame- work. We are able to handle extremely misspelled queries, e.g. due to phonetic spelling by possibly non-native speakers (camra → camera, chus → shoes), words being glued together due to missing whitespace (fauxfurmid... → faux fur mid...), or brand name confusions (righston → rhinestone).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we presented a powerful spelling correction system for the e-commerce domain us- ing statistical phrase-based machine translation based on character bigram sequences. We ex- tracted training data from event logs where users issue similar search queries within a certain pe- riod of time. Filtering through various heuristics is used to clean the initially noisy data set and re- move entries not related to spelling errors. We evaluated our system against established online search sites, both in the general and e-commerce domain, and showed favorable results in terms of recall and retrieval rates.</p><p>We plan to further invest in improving preci- sion. For this, we feel that adding full word- level models will help to overcome the somewhat limited context present in our character sequence- based models. We also plan to investigate the pro- totype directly in query expansion as part of the search backend.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Scoring schema.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Preprocessing of input data as single character or character bigram sequences. "S" denotes whitespace. After translation, postprocessing transforms back to word-level surface forms.</figDesc><table>Eval data 
DEV TEST 
#queries 
4,600 
4,602 
#tokens 
15,593 15,557 
CER[%] 
6.1 
6.0 
SER[%] 
84.2 
84.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Statistics on dev and test portions of 
the post-edited evaluation data. CER is the char-
acter error rate of the misspelled queries against 
the gold reference, SER is the sentence (i.e. here 
query-level) error rate of the sets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 8 shows</head><label>8</label><figDesc></figDesc><table>these numbers for our test set. We 
improve the rate of null results by 51.8% absolute. 
In a deeper analysis we see that out of the 81.6% in 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Search results evaluation on the test set. 
For null results, lower rates are better. For KL div. 
evaluation, higher rates are better, as they indicate 
a closer match with the category distribution from 
the gold corrections. 

</table></figure>

			<note place="foot" n="1"> http://hadoop.apache.org</note>

			<note place="foot" n="2"> https://code.google.com/p/cld2</note>

			<note place="foot">~15%. We are aware that this approach focuses on</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank the Localization team at eBay for creating gold corrections for the evaluation sets, and members of the HLT and Search teams for fruitful discussions as well as reading early drafts of this work and giving valu-able feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An improved error model for noisy channel spelling correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 38th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 38th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="286" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Chinese spelling checker based on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Cheng</forename><surname>Hsun-Wen Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Seventh SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>of the Seventh SIGHAN Workshop on Chinese Language essing<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="49" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spelling correction as an iterative process that exploits the collective 459 knowledge of web users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silviu</forename><surname>Cucerzan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>of the 2004 Conference on Empirical Methods in Natural Language essing<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="293" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A technique for computer detection and correction of spelling errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><forename type="middle">J</forename><surname>Damerau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communication of ACM</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="171" to="176" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A deep learning approach to machine transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saša</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth EACL Workshop on Statistical Machine Translation</title>
		<meeting><address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="233" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dealing with input noise in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Formiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fonollosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th International Conference on Computational Linguistics</title>
		<meeting>of the 24th International Conference on Computational Linguistics<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<publisher>Posters</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="319" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A large scale ranker-based system for search query spelling correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Micol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 23rd International Conference on Computational Linguistics</title>
		<meeting>of the 23rd International Conference on Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="358" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improved iterative correction for distant spelling errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Gubanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Galinskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Baytin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 52nd Annual Meeting of the Association for Computational Linguistics: Short Papers</title>
		<meeting>of the 52nd Annual Meeting of the Association for Computational Linguistics: Short Papers<address><addrLine>Baltimore, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="168" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">KenLM: faster and smaller language model queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation</title>
		<meeting>of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="187" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 45th Annual Meeting of the Association for Computational Linguistics: Demos and Posters</title>
		<meeting>of the 45th Annual Meeting of the Association for Computational Linguistics: Demos and Posters<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Techniques for automatically correcting words in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Kukich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="377" to="439" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On information and sufficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Solomon</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A hybrid Chinese spelling correction using language model and statistical machine translation with reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Seventh SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>of the Seventh SIGHAN Workshop on Chinese Language essing<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="54" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparison of the predicted and observed secondary structure of T4 phage lysozyme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">W</forename><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biochimica et Biophysica Acta (BBA)Protein Structure</title>
		<imprint>
			<biblScope unit="volume">405</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="442" to="451" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Combining word-level and character-level models for machine translation between closely-related languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers</title>
		<meeting>of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="301" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 41st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Exponential reservoir sampling for streaming language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Lall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="687" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Query chains: Learning to rank from implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining</title>
		<meeting>of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining<address><addrLine>Chicago, IL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="239" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning phrase-based spelling error models from clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Micol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="266" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Character-based pivot translation for under-resourced languages and domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>of the 13th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="141" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Can we translate letters?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Thorsten</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second Workshop on Statistical Machine Translation</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="33" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using the Web for language independent spellchecking and autocorrection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Whitelaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ged</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>of the 2009 Conference on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="890" to="899" />
		</imprint>
	</monogr>
	<note>Singapore</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Discriminative reranking for spelling correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pilian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 20th Pacific Asia Conference on Language, Information and Computation</title>
		<meeting>of the 20th Pacific Asia Conference on Language, Information and Computation<address><addrLine>Wuhan, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="64" to="71" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
