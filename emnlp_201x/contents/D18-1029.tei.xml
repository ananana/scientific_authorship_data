<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On the Relation between Linguistic Typology and (Limitations of) Multilingual Language Modeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Gerz</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Language Technology Lab, DTAL</orgName>
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Language Technology Lab, DTAL</orgName>
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Edoardo</roleName><forename type="first">Maria</forename><surname>Ponti</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Language Technology Lab, DTAL</orgName>
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Industrial Engineering and Management</orgName>
								<address>
									<settlement>Technion</settlement>
									<region>IIT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Language Technology Lab, DTAL</orgName>
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">On the Relation between Linguistic Typology and (Limitations of) Multilingual Language Modeling</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="316" to="327"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>316</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A key challenge in cross-lingual NLP is developing general language-independent archi-tectures that are equally applicable to any language. However, this ambition is largely hampered by the variation in structural and semantic properties, i.e. the typological profiles of the world&apos;s languages. In this work, we analyse the implications of this variation on the language modeling (LM) task. We present a large-scale study of state-of-the art n-gram based and neural language models on 50 typolog-ically diverse languages covering a wide variety of morphological systems. Operating in the full vocabulary LM setup focused on word-level prediction, we demonstrate that a coarse typology of morphological systems is predic-tive of absolute LM performance. Moreover, fine-grained typological features such as expo-nence, flexivity, fusion, and inflectional synthesis are borne out to be responsible for the proliferation of low-frequency phenomena which are organically difficult to model by statistical architectures, or for the meaning ambiguity of character n-grams. Our study strongly suggests that these features have to be taken into consideration during the construction of next-level language-agnostic LM architectures, capable of handling morphologically complex languages such as Tamil or Korean.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep learning has allowed NLP algorithms to dis- pose of manually-crafted features, and to virtually achieve language independence. However, their per- formance still varies noticeably across languages due to different underlying data distributions <ref type="bibr" target="#b3">(Bender, 2013;</ref><ref type="bibr" target="#b45">O'Horan et al., 2016)</ref>. Linguistic ty- pology, the systematic comparison of the world's languages, holds promise to explain these idiosyn- crasies and interpret statistical models in terms of variation in language structures ( <ref type="bibr" target="#b52">Ponti et al., 2017)</ref>. * Both authors equally contributed to this work.</p><p>In order to evaluate how cross-lingual structural variation hinders the design of effective general- purpose algorithms, we propose the task of lan- guage modeling (LM) as a testbed. In particular, we opt for a full-vocabulary setup where no word encountered at training time is treated as an un- known symbol, in order to a) ensure a fair compari- son across languages with different word frequency rates and b) avoid setting an arbitrary threshold on vocabulary size ( <ref type="bibr" target="#b13">Cotterell et al., 2018)</ref>.</p><p>Although there has recently been a tendency towards expanding test language samples, the datasets considered in previous works <ref type="bibr" target="#b9">(Botha and Blunsom, 2014;</ref><ref type="bibr" target="#b57">Vania and Lopez, 2017;</ref><ref type="bibr" target="#b31">Kawakami et al., 2017;</ref><ref type="bibr" target="#b13">Cotterell et al., 2018)</ref> are not entirely adequate yet to represent the typological variation and to ground cross-lingual generalisations empiri- cally. Hence, we test several LM architectures (in- cluding n-gram, neural, and character-aware mod- els) on a novel and wider set of 50 languages sam- pled according to stratification principles.</p><p>Through this large-scale multilingual analysis, we shed new light on the current limitations of standard LM models and offer support to fur- ther developments in multilingual NLP. In par- ticular, we demonstrate that the previous fixed- vocabulary assumption in fact ignores the limita- tions of language modeling for morphologically rich languages. Moreover, we find a strong corre- lation across the board between LM model per- formances and the type of morphological system adopted in each language.</p><p>To motivate this correlation we show how fine- grained typological properties interact with the fre- quency distribution <ref type="bibr" target="#b62">(Zipf, 1949)</ref> by regulating word boundaries and the proliferation of word forms; and 2) with the mapping between morphemes (here intended as character n-grams) and meaning, by possibly blurring it.</p><p>The paper is organised as follows. After provid-ing a short overview of multilingual LM and its possible setups ( §2), we describe the cross-lingual variation in morphological systems and propose a novel typologically diverse dataset for LM in §3.</p><p>We outline the data in §4 and benchmarked lan- guage models in §5. Finally, we discuss the results in light of linguistic typology in §6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Multilingual Language Modeling</head><p>A language model computes a probability distribu- tion over sequences of word tokens, and is typically trained to maximise the likelihood of word input sequences. The LM objective is expressed as:</p><formula xml:id="formula_0">P (w 1 , ...w n ) = i P (w i |w 1 , ...w i−1 ) (1)</formula><p>w i is a word token with the index i in the sequence. LM is considered a central task in NLP and lan- guage understanding, with applications in speech recognition ( <ref type="bibr" target="#b42">Mikolov et al., 2010</ref>), text summari- sation ( <ref type="bibr" target="#b19">Filippova et al., 2015;</ref><ref type="bibr" target="#b54">Rush et al., 2015)</ref>, and information retrieval <ref type="bibr" target="#b50">(Ponte and Croft, 1998;</ref><ref type="bibr" target="#b60">Zamani and Croft, 2016)</ref>. The importance of lan- guage modeling has been accentuated even more in representation learning recently, where it is used as a novel form of unsupervised pre-training (and an alternative to static word embeddings) for the ben- efit of a variety of NLP applications ( <ref type="bibr" target="#b47">Peters et al., 2018;</ref><ref type="bibr" target="#b28">Howard and Ruder, 2018</ref>  <ref type="bibr" target="#b59">Wang and Cho, 2016;</ref><ref type="bibr" target="#b43">Miyamoto and Cho, 2016;</ref><ref type="bibr" target="#b53">Press and Wolf, 2017)</ref>. For multilingual LM evaluation, Botha and Blun- som (2014) extract datasets for Czech, French, Spanish, German, and Russian from the 2013 Work- shop on Statistical Machine Translation (WMT) data <ref type="bibr" target="#b8">(Bojar et al., 2013)</ref>. <ref type="bibr" target="#b32">Kim et al. (2016)</ref> reuse these datasets and add Arabic. <ref type="bibr" target="#b37">Ling et al. (2015)</ref> evaluate on English, Portuguese, Catalan, German and Turkish datasets extracted from Wikipedia. <ref type="bibr" target="#b31">Kawakami et al. (2017)</ref> evaluate on 7 European languages using Wikipedia data, including Finnish.</p><p>To the best of our knowledge, the largest datasets used in previous work are from <ref type="bibr" target="#b44">(Müller et al., 2012;</ref><ref type="bibr" target="#b13">Cotterell et al., 2018</ref>) and amount to 21 languages from the Europarl data ( <ref type="bibr" target="#b34">Koehn, 2005)</ref>. Despite the large coverage of languages, these sets are still restricted only to the languages of the European Union. On the other hand, the most typologically diverse dataset thus far was released by <ref type="bibr" target="#b57">Vania and Lopez (2017)</ref>. It includes 10 languages represent- ing some morphological systems. This short survey of related work demonstrates a clear tendency towards extending LM evaluation to other languages, abandoning English-centric as- sumptions, and focusing on language-agnostic LM architectures. However, a comprehensive evalua- tion set that systematically covers a wide and bal- anced spectrum of typologically diverse languages is still missing. The novel dataset we discuss in this paper aims at bridging this gap (see §4).</p><p>Fixed vs. Full Vocabulary Setup. A majority of language models rely on the fixed-vocabulary as- sumption: they use a special symbol &lt;UNK&gt; that represents all words not present in the fixed vocabu- lary V , which are termed out-of-vocabulary (OOV). Selecting the set V typically slips under the radar, and can be seen as "something of a black art" de- spite its enormous impact on final LM performance ( <ref type="bibr" target="#b13">Cotterell et al., 2018</ref>). 1 Standard LM setups either fix the vocabulary V to the top n most frequent words, typically with n = 10, 000 or n = 5, 000 <ref type="bibr" target="#b42">(Mikolov et al., 2010;</ref><ref type="bibr" target="#b37">Ling et al., 2015;</ref><ref type="bibr" target="#b57">Vania and Lopez, 2017;</ref><ref type="bibr" target="#b36">Lee et al., 2017</ref>, inter alia), or include in V only words with a frequency below a certain threshold (typically 2 or 5) ( <ref type="bibr" target="#b26">Heafield et al., 2013)</ref>.</p><p>The rationale behind fixing the set V is a) to make the language model more robust to handling OOVs and to effectively bypass the problem of unreliable word estimates for low-frequency and unseen words (by ignoring them), and b) to enable direct comparisons of absolute perplexity scores across different models. However, this posits a critical challenge as cross-linguistic evaluation be- comes uneven. In fact, we witness a larger propor- tion of vocabulary words replaced by &lt;UNK&gt; in morphologically rich languages because of their higher OOV rates (see <ref type="table" target="#tab_7">Table 3</ref>). What is more, while the fixed-vocabulary assumption artificially Kreikkalaiset sijoittivat geometrian synnyn muinaiseen Egyptiin , jossa sitä tarvittiin maanmittaukseen .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FI (MIN-5)</head><p>&lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; synnyn &lt;UNK&gt; Egyptiin , jossa sitä tarvittiin &lt;UNK&gt; .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FI (10K)</head><p>&lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; , jossa sitä &lt;UNK&gt; &lt;UNK&gt; .  improves the perplexity measure, it actually makes the models less useful, especially in morphologi- cally rich languages, as exemplified in <ref type="table" target="#tab_2">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KO</head><p>Our goal is to get a clear picture on how dif- ferent typological features and the corresponding corpus frequency distributions affect LM perfor- mance, without the influence of the unrealistic fixed-vocabulary assumption. Therefore, we work in the full-vocabulary LM setup ( <ref type="bibr" target="#b0">Adams et al., 2017;</ref><ref type="bibr" target="#b23">Grave et al., 2017)</ref>. This means that we ex- plicitly decide to retain also infrequent words in the modeled data: V contains all words occurring at least once in the training set, only unseen words from test data are treated as OOVs. We believe that this setup leads to an evaluation that pinpoints the crucial limitations of standard LM architectures. <ref type="bibr">2</ref> Why Not Open Vocabulary Setup? Recent neu- ral LM architectures have also focused on han- dling large vocabularies and unseen words using character-aware modeling <ref type="bibr" target="#b38">(Luong and Manning, 2016;</ref><ref type="bibr" target="#b29">Jozefowicz et al., 2016;</ref><ref type="bibr">Kawakami et al., 2017, inter alia)</ref>. This setup is commonly referred to as the open-vocabulary setup. However, two dis- tinct approaches with crucial modeling differences are referred to by the same term in the literature. a) Word-level generation constructs word vectors for arbitrary words from constituent subword-level components, but word-level prediction is still eval- uated based on the fixed-vocabulary assumption. b) Character-level generation predicts characters instead of words.</p><p>Given that character-level prediction and word- level prediction operate on entirely different sets of symbols, their performance is hardly compara- ble. Still, <ref type="bibr" target="#b29">Jozefowicz et al. (2016)</ref> report that, in a hybrid setup which evaluates character-level pre- diction based on word-level perplexity with the <ref type="bibr">2</ref> For instance, as discussed later in §3 and validated empiri- cally in §6, the vocabularies of morphologically rich languages are inherently larger: it is simply more difficult to learn and make LM predictions in such languages.  fixed-vocabulary assumption, current state-of-the- art word-level prediction models (i.e., the ones we discuss in §5) still significantly outperform such hy- brid character-level prediction approaches. There- fore, we operate in the full-vocabulary setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Typology of Morphological Systems</head><p>Aiming for a comprehensive multilingual LM evaluation in this study, we survey all possible types of morphological systems <ref type="bibr" target="#b25">(Haspelmath and Sims, 2013</ref>), which possibly lead to different per- formances. Traditionally, languages have been grouped into the four main categories: isolating, fusional, introflexive and agglutinative, based on their position along a spectrum measuring the pref- erence on breaking up concepts in many words (on one extreme) or rather compose them into single words (on the other extreme).</p><p>The mono-dimensionality of this spectrum has recently been challenged as languages exhibit a multitude of morphological features that do not co- vary across languages <ref type="bibr" target="#b49">(Plank, 2017;</ref>). The typological database WALS <ref type="bibr" target="#b17">(Dryer and Haspelmath, 2013</ref>) documents several of them that are relevant for LM: inflectional synthesis, fusion, exponence, and flexivity. Note that the prototypes of traditional categories can be approximated in terms of these features, as shown in <ref type="table" target="#tab_4">Table 2</ref>, although more combinations are possible.</p><p>Languages specify different subsets of grammat- ical categories (such as tense for verbs, or num-ber for nouns), and for each category different val- ues are available in each language: for instance, Finnish has less tense values (it lacks a future), whereas Slovene has more number values (includ- ing a dual) compared to English. The feature in- flectional synthesis for verbs <ref type="bibr" target="#b5">(Bickel and Nichols, 2013</ref>) measures how many categories appear on the maximally inflected verb per language. More available categories enlarge the vocabulary (and consequently the OOV rate) with forms instantiat- ing all possible combinations of their values.</p><p>Another crucial aspect is how the available gram- matical categories are expressed, which can be de- scribed by fusion, exponence, and flexivity. Fusion measures the degree of connectedness between a grammatical marker to another word. The marker can be (from lower to higher fusion) a separate word, a clitic, an affix, or can affect the form of the root itself (e.g. an umlaut or a tone).</p><p>Exponence measures the number of categories (e.g., tense, number) a single morpheme tends to convey. Exponence is separative if one grammatical category is conveyed by one morpheme (1:1), and cumulative if multiple categories are grouped into one morpheme (many:1).</p><p>Flexivity indicates the possibility that the value of a grammatical category be mapped into differ- ent morphological forms (1:many). In other terms, lemmas belonging to the same part-of-speech are divided into inflectional classes (such as declension classes for nouns or conjugation classes for verbs), each characterised by a different paradigm, that is, a different set of value-to-form mappings.</p><p>The three last features are illustrated by the ex- amples Ex. (2)-Ex. (5), all uttering the sentence "I will guard the doors and I will not open (them)". 3 </p><formula xml:id="formula_1">non NEG apr-irò open-FUT.1SG (Italian) (5) 'e-šmor 1SG-guard.FUT 'al on ha-d'lat-ót DEF-door-PL v'-lo and-NEG 'e-ftach 1SG-wait.FUT otán them (Hebrew)</formula><p>In particular, consider how tense and person are expressed on verbs. Vietnamese in Ex. (2) puts two particles tôi and s˜es˜e before the verb, which are distinct (separate exponence), autonomous from the root (no fusion), and fixed (absence of flexiv- ity). Turkish in Ex. (3) attaches suffixes: -acak-for tense and -ım for person. These are distinct (sepa- rate exponence), joined to the roots (concatenative fusion), and (phonologically determined variants of) the same morpheme (1:1 flexivity). Italian in Ex. (4) uses affixes -erò and -irò: they are concate- nated to the root with respect to fusion, convey both tense and person (cumulative exponence), and are dissimilar (presence of flexivity). Finally, in Ex. <ref type="formula">(5)</ref> for Hebrew the consonant pattern of the verb š-m-r is interdigitated by the vowel -o-for tense, and preceded by a prefix 'e-for person. The first phenomenon alters the root itself (introflexive fusion), is distinct from the second (separate ex- ponence), and changes its realisation based on the verb's lemma (presence of flexivity).</p><p>The above evidence strongly motivates us, as well as recent previous work <ref type="bibr" target="#b57">(Vania and Lopez, 2017;</ref><ref type="bibr" target="#b31">Kawakami et al., 2017;</ref><ref type="bibr" target="#b13">Cotterell et al., 2018)</ref>, to approach LM with models that are aware of the inner structure of their input words, and to bench- mark these modeling choices on a typologically diverse range of languages, as shown in §4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>Selection of Languages. Our selection of test languages is guided by the following goals: a) we have to ensure the coverage of typological prop- erties from §3, and b) we want to analyse a large set of languages which extends and surpasses other work in the LM literature (see §2).</p><p>Since cross-lingual NLP aims at modeling extant languages rather than possible languages (includ- ing, e.g., extinct ones), creating a balanced sample is challenging. In fact, attested languages, intended as a random variable, are extremely sparse and not independent-and-identically-distributed ( <ref type="bibr" target="#b12">Cotterell and Eisner, 2017)</ref>. First, available and reliable data exist only for a fraction of the world's languages. Second, these data are biased because their features may not stem from the underlying distribution, i.e., from what is naturally possible/frequent, but rather can be inherited by genealogical relatedness or bor- rowed by areal proximity <ref type="bibr" target="#b2">(Bakker, 2010)</ref>. To mit- igate these biases, theoretical works resorted to stratification approaches, where each subgroup of related languages is sampled independently. maxi- mizing their diversity <ref type="bibr">(Dryer, 1989, inter alia)</ref>. We perform our selection in the same spirit.</p><p>We start from the Polyglot Wikipedia (PW) project (Al-</p><note type="other">Rfou et al., 2013) which provides cleaned and tokenised Wikipedia data in 40 lan- guages. However, the majority of the PW lan- guages are similar from the perspective of geneal- ogy (26/40 are Indo-European), geography (28/40 are Western European), and typology (26/40 are fusional). Consequently, the PW set is not a repre- sentative sample of the world's languages.</note><p>To amend this limitation, we source additional languages with the data coming from the same domain, Wikipedia, considering candidates in de- scending order of corpus size cleaned and prepro- cessed by the Polyglot tokeniser (Al- <ref type="bibr" target="#b1">Rfou et al., 2013)</ref>. Since fusional languages are already repre- sented in the PW, we add new languages from other morphological types: isolating (Min Nan, Burmese, Khmer), agglutinative (Basque, Georgian, Kan- nada, Tamil, Mongolian, Javanese), and introflex- ive languages (Amharic).</p><p>Partition. We construct datasets for all 50 lan- guages by extracting the first 40K sentences for each language, and split them into train (34K), vali- dation (3K), and test (3K). This choice has been mo- tivated by the following observations: a) we require similarly-sized datasets from the same domain for all languages; b) the size of the datasets has to be similar to the standard English PTB dataset <ref type="bibr" target="#b40">(Marcus et al., 1993</ref>) which has been utilised to guide LM development in English for more than 20 years. The final list of 50 languages along with their lan- guage codes (ISO 639-1), morphological type (i.e., isolating, fusional, introflexive, agglutinative), and corpus statistics is provided in <ref type="table" target="#tab_7">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Models and Experimental Setup</head><p>Benchmarked Language Models. The avail- ability of LM evaluation sets in a large number of diverse languages, as described in §4, gives an opportunity to conduct a full-fledged multilin- gual analysis of representative LM architectures for word-level prediction. First, we evaluate a state- of-the-art model from the n-gram family of models <ref type="bibr" target="#b22">(Goodman, 2001</ref>) from the KenLM package. <ref type="bibr">4</ref> It is based on 5-grams with extended Kneser-Ney smoothing <ref type="bibr" target="#b33">(Kneser and Ney, 1995;</ref><ref type="bibr" target="#b26">Heafield et al., 2013)</ref>. We refer to this model as KN5.</p><p>Modern LM architectures are almost exclusively based on recurrent neural networks (RNNs), and especially on Long-Short-Term Memory networks (LSTMs). ( <ref type="bibr" target="#b42">Mikolov et al., 2010;</ref><ref type="bibr" target="#b56">Sundermeyer et al., 2015;</ref><ref type="bibr" target="#b11">Chen et al., 2016</ref>, inter alia). They map a sequence of input words to embedding vectors us- ing a look-up matrix and then perform word-level prediction by passing the vectors to the LSTM.</p><p>Finally, we also evaluate a character-aware vari- ant of the neural LSTM LM architecture. We use the Char-CNN-LSTM model ( <ref type="bibr" target="#b32">Kim et al., 2016)</ref> due to its public availability and strong perfor- mance in several languages. In this model, each character is embedded and passed through a convo- lutional neural network with max-over-time pool- ing ( <ref type="bibr" target="#b35">LeCun et al., 1989)</ref>, followed by a highway network transformation ( <ref type="bibr" target="#b55">Srivastava et al., 2015</ref>) to build word representations from their constituent characters. By resorting to character-level informa- tion, the model is able to provide better parame- ter estimates for lower-frequency words, which is particularly important for morphologically rich lan- guages. The CNN-based word representations are then processed in a sequence by a regular LSTM network to obtain word-level predictions.</p><p>Evaluation Setup. We report perplexity scores (Jurafsky and Martin, 2017, chapter 4.2.1) using the full vocabulary for each respective LM dataset. This means that we explicitly decide to retain also infrequent words in the data and analyse the diffi- culty of modeling such words in morphologically rich languages (see §2 for the discussion).</p><p>In the full-vocabulary setup, the set V comprises all words occurring at least once in the training set. Unseen test words are mapped to one &lt;UNK&gt; vector, sampled from the the space of trained word vectors relying on a normal distribution and the same fixed random seed for all models. On the other hand, KN5 by design has a slightly different way of handling unseen test words: they are regarded as outliers and assigned low-probability estimates.</p><p>Training Setup and Parameters. For LSTM and Char-CNN-LSTM language models, we re- produce the standard LM setup of <ref type="bibr" target="#b61">Zaremba et al. (2015)</ref> and parameter choices of <ref type="bibr" target="#b32">Kim et al. (2016)</ref>. Batch size is 20 and a sequence length is 35, where one step corresponds to one word token. The max- imum word length is chosen dynamically based on the longest word in the corpus. The corpus is processed continuously; the RNN hidden states re- set at the beginning of each epoch. Parameters are optimised with SGD, and the gradient is averaged over the batch size and sequence length. We then scale the averaged gradient by the sequence length (=35) and clip to 5.0 for more stable training. The learning rate is 1.0, decayed by 0.5 after each epoch if the validation perplexity does not improve. All models are trained for 15 epochs, which is typically sufficient for model convergence. Finally, KN5 is trained relying on the suggested parameters from the KenLM package.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head><p>In this section, we present our main empirical find- ings on the connection between LM performance and corpus statistics emerging from different ty- pological profiles (see §3). Before proceeding, we stress that the absolute perplexity scores across dif- ferent languages are not directly comparable, but their values provide evidence on the difficulty and limitations of language modeling in each language, considering the fact that all language models were trained on similarly-sized datasets. The results for all three benchmarked language models on all 50 languages are summarised in <ref type="table" target="#tab_7">Table 3</ref>.</p><p>Comparison of Language Models. A quick in- spection of the results from <ref type="table" target="#tab_7">Table 3</ref> reveals that the Char-CNN-LSTM model is the best-performing model overall. We report the best results with that model for 48/50 languages and across all traditional morphological types. Gains over the simpler recur- rent LM architecture (i.e., the LSTM model) are present for all 50/50 languages. In short, this means that character-level information on the input side of neural architectures, in addition to leading to fewer parameters, is universally beneficial for the final performance of word-level prediction, as also sug- gested by <ref type="bibr" target="#b32">Kim et al. (2016)</ref> on a much smaller set of languages. By relying on character-level knowl- edge, Char-CNN-LSTM model provides better es- timates for lower-frequency words.</p><p>Moreover, the results show that KN5 is a compet- itive baseline for several languages (e.g., <ref type="bibr">Kannada, Thai, Amharic)</ref>. This further highlights the impor- tance of testing models on a typologically diverse set of languages: despite the clear superiority of neural LM architectures such as Char-CNN-LSTM in a large number of languages, the results and the marked outliers still suggest that there is currently no "one-size-fits-all" model.</p><p>In general, large perplexity scores for certain languages (e.g., agglutinative languages such as Finnish, Korean, Tamil, or introflexive languages), especially when compared to performance on En- glish on a similarly-sized dataset, clearly point at the limitations of all the "language-agnostic" LM architectures. As suggested by <ref type="bibr" target="#b29">Jozefowicz et al. (2016)</ref>, LM performance in English can be boosted by simply collecting more data and working with large vocabularies (e.g., reducing the number of relevant OOVs). However, this solution is certainly not applicable to a majority of the world's lan- guages <ref type="bibr" target="#b7">(Bird, 2011;</ref><ref type="bibr" target="#b20">Gandhe et al., 2014;</ref><ref type="bibr" target="#b0">Adams et al., 2017)</ref>, see later in §6: Further Discussion.</p><p>Frequency Analysis and Traditional Morpho- logical Types. We now analyse all languages in our collection according to word-level frequency properties also listed in <ref type="table" target="#tab_7">Table 3</ref> for all 50 lan- guages. We report: 1) the vocabulary size (i.e., the total number of vocabulary words in each training dataset); 2) the total number of test words not occur- ring in the corresponding training data; 3) the total number of tokens in both training and test data; and finally 4) type-to-token ratios (TTR) in train- ing data. We also plot absolute perplexity scores of Char-CNN-LSTM ( <ref type="bibr" target="#b32">Kim et al., 2016)</ref>, the best- performing model overall (see §6), in relation to TTR ratios in <ref type="figure" target="#fig_2">Figure 1</ref>.   In isolating and some fusional languages (e.g., Vietnamese, Thai, English) the TTR tends to be small: we have a comparatively low number of infrequent words. Agglutinative languages such as Finnish, Estonian, and Korean are on the other side of the spectrum. Introflexive and fusional lan- guages, typically over-represented in prior work (see the discussion in §3), are found in the middle.</p><note type="other">Catalan (ca) 61033 2562 788K 59.4K 0.08 358 318 241 Czech (cs) 86783 4300 641K 49.6K 0.14 1658 2200 1252 Danish (da) 72468 3618 663K 50.3K 0.11 668 710 466 German (de) 80741 4045 682K 51.3K 0.12 930 903 602 Greek (el) 76264 3767 744K 56.5K 0.10 607 538 405 English (en) 55521 2480 783K 59.5K 0.07 533 494 371 Spanish (es) 60196 2721 781K 57.2K 0.08 415 366 275 Estonian (et) 94184 3907 556K 38.6K 0.17 1609 2564 1478 Basque (eu) 81177 3365 647K 47.3K 0.13 560 533 347 Farsi (fa) 52306 2041 738K 54.2K 0.07 355 263 208 Finnish (fi) 115579 6489 585K 44.8K 0.20 2611 4263 2236 French (fr) 58539 2575 769K 57.1K 0.08 350 294 231 × Hebrew (he) 83217 3862 717K 54.6K 0.12 1797 2189 1519 Hindi (hi) 50384 2629 666K 49.1K 0.08 473 426 326 Croatian (hr) 86357 4371 620K 48.1K 0.14 1294 1665 1014 Hungarian (hu) 101874 5015 672K 48.7K 0.15 1151 1595 929 £ Indonesian (id) 49125 2235 702K 52.2K 0.07 454 359 286 Italian (it) 70194 2923 787K 59.3K 0.09 567 493 349 Japanese (ja) 44863 1768 729K 54.6K 0.06 169 156 136 Javanese (jv) 65141 4292 622K 52K 0.10 1387 1443 1158 Georgian (ka) 80211 3738 580K 41.1K 0.14 1370 1827 1097 £ Khmer (km) 37851 1303 579K 37.4K 0.07 586 637 522 Kannada (kn) 94660 4604 434K 29.4K 0.22 2315 5310 2558 Korean (ko) 143794 8275 648K 50.6K 0.</note><p>This emerges clearly in <ref type="figure" target="#fig_2">Figure 1</ref>, grouping isolat- ing languages to the left side of the x-axis, followed by fusional languages (Germanic and Romance first to the left, and then Balto-Slavic to the right), and placing agglutinative languages towards the far right. Crucially, TTR is an excellent predictor of LM performance. To measure the correlation between this corpus statistics variable and absolute LM performance, we compute their Pearson's r cor- relation. We find a strong positive correlation, with a value of r = 0.83 and significance p &lt; 0.001.</p><p>We do observe a strong link between each lan- guage's morphological type, and the correspond- ing perplexity score. A transition in terms of the spectrum of morphological systems (see §3) can be traced again on the y-axis of <ref type="figure" target="#fig_2">Figure 1</ref>, roughly following the reported LM performance: from iso- lating, over fusional and introflexive to agglutina- tive languages. In fact, a correlation exists also between traditional morphological types and LM performance. We assessed its strength with the one- way ANOVA statistical test, obtaining a value of η 2 = 0.37 and a significance of p &lt; 0.001.</p><p>Finally, it should be noted that the choice of TTP over other corpus statistics such as vocabulary size is motivated by the fact that the corpora are compa- rable, and not parallel. Because of this, the variation of V may stem from the contents rather than the intrinsic linguistic properties. As a counter-check, the correlation between V and LM performance is in fact milder, with r = 0.64. Yet, notwithstanding the stronger correlation, TTP is unable to explain the results entirely. Only through finer-grained ty- pological features it becomes possible to justify several outliers, as shown in the next subsection.</p><p>Fine-Grained Typological Analysis. Among the relevant typological features (see §3 and <ref type="table" target="#tab_4">Table  2</ref>), fusion and inflectional synthesis have the largest impact on word-level predictions. In fact, the for- mer determines the word boundaries, whereas the latter regulates the amount of possible morpheme combinations. Consider their effect on the fre- quency distribution of words, expressed as follows <ref type="bibr" target="#b62">(Zipf, 1949)</ref>:</p><formula xml:id="formula_2">f = 1 k s V n=1 1 n s (6)</formula><p>f is the frequency, k the rank, and s ≥ 0 the expo- nent characteristic of the distribution. If high, both typological features enlarge V and s, assigning less probability mass to each word.</p><p>Low fusion means a preference for separate words (as in isolating languages such as Viet- namese and Chinese), leading to a smaller vocab- ulary with less (but more frequent) words. This property, additionally boosted by low inflectional synthesis, facilitates statistical language modeling in isolating languages. Vice versa, high fusion re- sults in preference for concatenation of morphemes or introflection, and consequently sparser vocabu- laries. Yet, this distinction cannot justify the figures by itself, as it equates agglutinative languages and traditional fusional languages. Here, inflectional synthesis is also at play. Through the statistical test of one-way ANOVA, we found a weak effect of η 2 = 0.09 for fusion and a medium effect of η 2 = 0.21 for inflection synthesis.</p><p>On the other hand, the fine-grained typological features of exponence and flexivity play a role in the ambiguity of the mapping between morphemes and meanings or grammatical functions. This turns out to be especially relevant for character-aware models. The intuition is that if the mapping is straightforward, injecting character information is more advantageous. To validate this claim, we eval- uate the ANOVA between exponence of nouns and verbs and the difference in perplexity between LSTM and Char-CNN-LSTM. <ref type="bibr">5</ref> We report a weak, although existent, correlation with value η 2 = 0.07 and η 2 = 0.04, respectively.</p><p>Further Discussion. Importantly, our large- scale multilingual LM study strongly indicates that due to diverse typological profiles, certain lan- guages and language groups are inherently more complex to language-model when relying on es- tablished statistical models, even when such mod- els are constructed as widely applicable and (ar- guably) language-agnostic. This finding supports preliminary results from prior work <ref type="bibr" target="#b9">(Botha and Blunsom, 2014;</ref><ref type="bibr" target="#b0">Adams et al., 2017;</ref><ref type="bibr" target="#b13">Cotterell et al., 2018)</ref>, and is also backed by insights from linguis- tic theory on variance of language complexity in general and variance of morphological complexity in specific <ref type="bibr" target="#b41">(McWhorter, 2001;</ref><ref type="bibr" target="#b18">Evans and Levinson, 2009</ref>). More broadly and along the same line, earlier research in statistical machine translation (SMT) has also shown that typological factors such as the amount of reordering, the morphological complexity, as well as genealogical relatedness of languages are crucial in predicting success in SMT ( <ref type="bibr" target="#b6">Birch et al., 2008;</ref><ref type="bibr" target="#b46">Paul et al., 2009;</ref><ref type="bibr" target="#b15">Daiber, 2018)</ref>.</p><p>Our results indicate that the artificial fixed-vocabulary assumption from prior work produces overly optimistic perplexity scores, and its limita- tion is even more pronounced in morphologically rich languages, which inherently contain a large number of infrequent words due to their productive morphological systems. The typical solution to col- lect more data ( <ref type="bibr" target="#b29">Jozefowicz et al., 2016;</ref><ref type="bibr" target="#b31">Kawakami et al., 2017)</ref> mitigates this effect to a certain extent, but stills suffers from the Zipfian hypothesis <ref type="bibr">(1949)</ref>, and it cannot be guaranteed for resource-poor lan- guages where obtaining sufficient monolingual data is also a challenge ( <ref type="bibr" target="#b0">Adams et al., 2017)</ref>. Therefore, another solution is to resort to other sources of information which are not purely contex- tual/distributional. For instance, a promising line of current and future research is to (learn to) exploit subword-level patterns captured in an unsupervised manner <ref type="bibr" target="#b48">(Pinter et al., 2017;</ref><ref type="bibr" target="#b27">Herbelot and Baroni, 2017)</ref> or integrate existing morphological genera- tion and inflection tools and regularities <ref type="bibr" target="#b14">(Cotterell et al., 2015;</ref><ref type="bibr" target="#b4">Bergmanis et al., 2017)</ref> into language models to reduce data sparsity, and improve language modeling for morphologi- cally rich languages. For instance, a recent enhance- ment of the Char-CNN-LSTM language model that enforces similarity between parameters of morpho- logically related words leads to large perplexity gains across a large number of languages, with the most prominent gains reported for morphologically complex languages <ref type="bibr" target="#b21">(Gerz et al., 2018</ref>).</p><p>Given the recent success and improved perfor- mance with LM-based pre-training methodology <ref type="bibr" target="#b47">(Peters et al., 2018;</ref><ref type="bibr" target="#b28">Howard and Ruder, 2018)</ref> across a wide variety of syntactic and semantic NLP tasks in English, improving language models for other languages might have far-reaching con- sequences for multilingual NLP in general. Typo- logical information coded in typological databases (  offer invaluable support to lan- guage modeling (e.g., knowledge on word ordering, morphological regularities), but such typologically- informed LM architectures are still non-existent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we have run a large-scale study on Language Modeling (LM) across several architec- tures and a collection of 50 typologically diverse languages. We have demonstrated that typological properties of languages, such as their morphologi- cal systems, have an enormous impact on the per- formance of allegedly "language-agnostic" models.</p><p>We have found that the corpus statistics most pre- dictive of LM performance is type-to-token ratio (TTR), as demonstrated by their strong Pearson's correlation. In turn, the value of TTR is motivated by fine-grained typological features that define the type of morphological system within a language. In fact, such features affect the word boundaries and the number of morphemes per word, affecting the word frequency distribution for each language.</p><p>We have also observed that injecting character in- formation into word representations is always ben- eficial because this mitigates the above-mentioned sparsity issues. However, the extent of the gain in perplexity partly depends on some typological properties that regulate the ambiguity of the map- ping between morphemes (here modeled as charac- ter n-grams) and their meaning.</p><p>We hope that NLP/LM practitioners will find the datasets for 50 languages put forth in this work along with benchmarked LMs useful for fu- ture developments in (language-agnostic as well as typologically-informed) multilingual language modeling. This study calls for next-generation so- lutions that will additionally leverage typological knowledge for improved language modeling. Code and data are available at: http://people.ds. cam.ac.uk/dsg40/lmmrl.html.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FI</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc>2) tôi I ss FUT bbo guard v cca door và and tôi I ss FUT không NEG mm open (Vietnamese) (3) kapı-lar-ı door-PL-ACC koruy-aca˘ g-ım guard-FUT-1SG ve and aç-may-aca˘ g-ım open-NEG-FUT-1SG (Turkish) (4) sorvegli-erò guard-FUT.1SG le DEF port-e door-PL e and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Perplexity scores with the Char-CNNLSTM language model (Kim et al., 2016) on PTBsized language modeling data in 50 languages as a function of type-to-token ratios in training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples from Finnish and Korean LM datasets after applying the standard fixed-vocabulary 
assumption. MIN=5: only words with corpus frequency above 5 are retained in the final fixed vocabulary 
V ; 10K: V comprises the 10k most frequent words. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Traditional morphological types described 
in terms of selected features from WALS. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Test perplexities for 50 languages (ISO 639-1 codes sorted alphabetically) in the full-vocabulary 
prediction LM setup; Left: Basic statistics of LM evaluation data (see  §4 and  §5). Right: Results with all 
three language models in our comparison. Best absolute perplexity scores for each language are in bold, 
but note that the absolute scores in the KN5 column are not directly comparable to the scores obtained 
with neural models due to a different handling of OOVs at test time (see  §5). 

</table></figure>

			<note place="foot" n="1"> For instance, Vania and Lopez (2017) report perplexity scores of ≈20 for Finnish when V is fixed to the 5k most frequent words. The same model in the full-vocabulary setup obtains perplexity scores of ≈2,000.</note>

			<note place="foot" n="3"> All morphological glosses follow the Leipzig glossing rules, listed at https://www.eva.mpg.de/lingua/ resources/glossing-rules.php</note>

			<note place="foot" n="4"> https://github.com/kpu/kenlm</note>

			<note place="foot" n="5"> Unfortunately no values are available in WALS for the feature of flexivity besides a limited domain.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is supported by the ERC Consolidator Grant LEXICAL (no 648909). The authors would like to thank the anonymous reviewers for their helpful suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cross-lingual word embeddings for low-resource language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Makarucha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="937" to="947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Polyglot: Distributed word representations for multilingual NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dik</forename><surname>Bakker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Oxford handbook of linguistic typology</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="100" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Linguistic fundamentals for natural language processing: 100 essentials from morphology and syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Training data augmentation for low-resource morphological inflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toms</forename><surname>Bergmanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="31" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Inflectional Synthesis of the Verb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balthasar</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johanna</forename><surname>Nichols</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>Leipzig</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Max Planck Institute for Evolutionary Anthropology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Predicting success in machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="745" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bootstrapping the language archive: New prospects for natural language processing in preserving linguistic heritage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistic Issues in Language Technology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<title level="m">Proceedings of the 8th Workshop on Statistical Machine Translation</title>
		<meeting>the 8th Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="44" />
		</imprint>
	</monogr>
	<note>Findings of the 2013 Workshop on Statistical Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Compositional morphology for word representations and language modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1899" to="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">One billion word benchmark for measuring progress in statistical language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciprian</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERPSEECH</title>
		<meeting>INTERPSEECH</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2635" to="2639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">CUED-RNNLM: An open-source toolkit for efficient training and evaluation of recurrent neural network language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xunying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanmin</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip C</forename><surname>Gales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Woodland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="6000" to="6004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Probabilistic typology: Deep generative models of vowel inventories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1182" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Are all languages equally hard to language-model?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><forename type="middle">J</forename><surname>Mielke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Labeled morphological segmentation with semi-Markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="164" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Typologically Robust Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Daiber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>University of Amsterdam</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Large linguistic areas and language sampling. Studies in Language. International Journal sponsored by the Foundation &quot;Foundations of Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dryer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="257" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">WALS Online. Max Planck Institute for Evolutionary Anthropology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">S</forename><surname>Dryer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Haspelmath</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>Leipzig</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The myth of language universals: Language diversity and its importance for cognitive science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">C</forename><surname>Levinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="429" to="448" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sentence compression by deletion with LSTMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">A</forename><surname>Colmenares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="360" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural network language models for low resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Gandhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Metze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2615" to="2619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Language modeling for morphologically rich languages: Character-aware modeling for wordlevel prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Gerz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Edoardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Ponti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the ACL</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="451" to="465" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A bit of progress in language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">T</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="403" to="434" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unbounded cache model for online language modeling with open vocabulary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cissé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6044" to="6054" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Practical solutions to the problem of diagonal dominance in kernel document clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padraig</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Understanding morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Haspelmath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Sims</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Scalable modified Kneser-Ney language model estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Pouzyrevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="690" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">High-risk learning: acquiring new word vectors from tiny data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelie</forename><surname>Herbelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="304" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Exploring the limits of language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<title level="m">Speech and Language Processing</title>
		<imprint>
			<publisher>Pearson</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning to create and reuse words in openvocabulary neural language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Character-aware neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2741" to="2749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Improved backing-off for M-gram language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Kneser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="181" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Machine Translation Summit</title>
		<meeting>the 10th Machine Translation Summit</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Handwritten digit recognition with a back-propagation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donnie</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">E</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="396" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Recurrent additive networks. CoRR, abs/1705.07393</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Finding function in form: Compositional character models for open vocabulary word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Luís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luís</forename><surname>Marujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramón</forename><forename type="middle">Fernández</forename><surname>Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1520" to="1530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Achieving open vocabulary neural machine translation with hybrid word-character models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1054" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning word vectors for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">E</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="142" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The world&apos;s simplest grammars are Creole grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mcwhorter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistic Typology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="66" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2010-01" />
			<biblScope unit="page" from="1045" to="1048" />
		</imprint>
	</monogr>
	<note>Cernock`Cernock`y, and Sanjeev Khudanpur</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Gated word-character recurrent language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasumasa</forename><surname>Miyamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1992" to="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A comparative investigation of morphological language modeling for the languages of the European Union</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="386" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Survey on the use of typological information in natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yevgeni</forename><surname>Helen O&amp;apos;horan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vuli´cvuli´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1297" to="1308" />
		</imprint>
	</monogr>
	<note>Roi Reichart, and Anna Korhonen</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On the importance of pivot language selection for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirofumi</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="221" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Mimicking word embeddings using subword RNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Pinter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Guthrie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="102" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Split morphology: How agglutination and flexion mix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frans</forename><surname>Plank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistic Typology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="62" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A language modeling approach to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Modeling language variation and universals: A survey on typological linguistics for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Edoardo Maria Ponti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yevgeni</forename><surname>O&amp;apos;horan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Poibeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Shutova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Korhonen</surname></persName>
		</author>
		<idno>abs/1807.00914</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Decoding sentiment from distributed representations of sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Edoardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Ponti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of *SEM</title>
		<meeting>*SEM</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Using the output embedding to improve language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A neural attention model for abstractive sentence summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="379" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Highway networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh Kumar</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICML Deep Learning Workshop</title>
		<meeting>the ICML Deep Learning Workshop</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">From feedforward to recurrent LSTM neural networks for language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schluter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="517" to="529" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">From characters to words to in between: Do we capture morphology?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Vania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2016" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Morph-fitting: Fine-tuning word vector spaces with simple language-specific rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´cmrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ó</forename><surname>Diarmuid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="56" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Larger-context language modelling with recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1319" to="1329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Embeddingbased query language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICTIR</title>
		<meeting>ICTIR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="147" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Recurrent neural network regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR (Conference Papers)</title>
		<meeting>ICLR (Conference Papers)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Human behavior and the principle of least effort: An introduction to human ecology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kingsley Zipf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
