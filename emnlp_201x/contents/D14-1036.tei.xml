<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:30+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Incremental Semantic Role Labeling with Tree Adjoining Grammar</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="department" key="dep2">Cluster of Excellence Multimodal Computing and Interaction</orgName>
								<orgName type="institution" key="instit1">University of Edinburgh</orgName>
								<orgName type="institution" key="instit2">Saarland University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="department" key="dep2">Cluster of Excellence Multimodal Computing and Interaction</orgName>
								<orgName type="institution" key="instit1">University of Edinburgh</orgName>
								<orgName type="institution" key="instit2">Saarland University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vera</forename><surname>Demberg</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="department" key="dep2">Cluster of Excellence Multimodal Computing and Interaction</orgName>
								<orgName type="institution" key="instit1">University of Edinburgh</orgName>
								<orgName type="institution" key="instit2">Saarland University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="department" key="dep2">Cluster of Excellence Multimodal Computing and Interaction</orgName>
								<orgName type="institution" key="instit1">University of Edinburgh</orgName>
								<orgName type="institution" key="instit2">Saarland University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Incremental Semantic Role Labeling with Tree Adjoining Grammar</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="301" to="312"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce the task of incremental semantic role labeling (iSRL), in which semantic roles are assigned to incomplete input (sentence prefixes). iSRL is the semantic equivalent of incremental parsing , and is useful for language model-ing, sentence completion, machine translation , and psycholinguistic modeling. We propose an iSRL system that combines an incremental TAG parser with a semantically enriched lexicon, a role propagation algorithm, and a cascade of classi-fiers. Our approach achieves an SRL F-score of 78.38% on the standard CoNLL 2009 dataset. It substantially outper-forms a strong baseline that combines gold-standard syntactic dependencies with heuristic role assignment, as well as a baseline based on Nivre&apos;s incremental dependency parser.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Humans are able to assign semantic roles such as agent, patient, and theme to an incoming sentence before it is complete, i.e., they incrementally build up a partial semantic representation of a sentence prefix. As an example, consider:</p><p>(1)</p><p>The athlete realized [her goals] PATIENT/THEME were out of reach.</p><p>When reaching the noun phrase her goals, the hu- man language processor is faced with a semantic role ambiguity: her goals can either be the PA- TIENT of the verb realize, or it can be the THEME of a subsequent verb that has not been encoun- tered yet. Experimental evidence shows that the human language processor initially prefers the PA- TIENT role, but switches its preference to the theme role when it reaches the subordinate verb were. Such semantic garden paths occur because human language processing occurs word-by-word, and are well attested in the psycholinguistic litera- ture (e.g., <ref type="bibr" target="#b20">Pickering et al., 2000</ref>).</p><p>Computational systems for performing seman- tic role labeling (SRL), on the other hand, proceed non-incrementally. They require the whole sen- tence (typically together with its complete syntac- tic structure) as input and assign all semantic roles at once. The reason for this is that most features used by current SRL systems are defined globally, and cannot be computed on sentence prefixes.</p><p>In this paper, we propose incremental SRL (iSRL) as a new computational task that mimics human semantic role assignment. The aim of an iSRL system is to determine semantic roles while the input unfolds: given a sentence prefix and its partial syntactic structure (typically generated by an incremental parser), we need to (a) identify which words in the input participate in the seman- tic roles as arguments and predicates (the task of role identification), and (b) assign correct seman- tic labels to these predicate/argument pairs (the task of role labeling). Performing these two tasks incrementally is substantially harder than doing it non-incrementally, as the processor needs to com- mit to a role assignment on the basis of incom- plete syntactic and semantic information. As an example, take (1): on reaching athlete, the proces- sor should assign this word the AGENT role, even though it has not seen the corresponding predicate yet. Similarly, upon reaching realized, the pro- cessor can complete the AGENT role, but it should also predict that this verb also has a PATIENT role, even though it has not yet encountered the argu- ment that fills this role. A system that performs SRL in a fully incremental fashion therefore needs to be able to assign incomplete semantic roles, unlike existing full-sentence SRL models.</p><p>The uses of incremental SRL mirror the applica- tions of incremental parsing: iSRL models can be used in language modeling to assign better string probabilities, in sentence completion systems to provide semantically informed completions, in any real time application systems, such as dia- log processing, and to incrementalize applications such as machine translation (e.g., in speech-to- speech MT). Crucially, any comprehensive model of human language understanding needs to com- bine an incremental parser with an incremental se- mantic processor <ref type="bibr" target="#b18">(Padó et al., 2009;</ref><ref type="bibr" target="#b10">Keller, 2010)</ref>.</p><p>The present work takes inspiration from the psycholinguistic modeling literature by proposing an iSRL system that is built on top of a cogni- tively motivated incremental parser, viz., the Psy- cholinguistically Motivated Tree Adjoining Gram- mar parser of <ref type="bibr" target="#b4">Demberg et al. (2013)</ref>. This parser includes a predictive component, i.e., it predicts syntactic structure for upcoming input during in- cremental processing. This makes PLTAG par- ticularly suitable for iSRL, allowing it to predict incomplete semantic roles as the input string un- folds. Competing approaches, such as iSRL based on an incremental dependency parser, do not share this advantage, as we will discuss in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Most SRL systems to date conceptualize seman- tic role labeling as a supervised learning prob- lem and rely on role-annotated data for model training. Existing models often implement a two-stage architecture in which role identification and role labeling are performed in sequence. Su- pervised methods deliver reasonably good perfor- mance with F-scores in the low eighties on stan- dard test collections for English <ref type="bibr" target="#b1">Björkelund et al., 2009)</ref>.</p><p>Current approaches rely primarily on syntactic features (such as path features) in order to iden- tify and label roles. This has been a mixed bless- ing as the path from an argument to the predi- cate can be very informative but is often quite complicated, and depends on the syntactic formal- ism used. Many paths through the parse tree are likely to occur infrequently (or not at all), result- ing in very sparse information for the classifier to learn from. Moreover, as we will discuss in Sec- tion 4.4, such path information is not always avail- able when the input is processed incrementally. There is previous SRL work employing Tree Ad- joining Grammar, albeit in a non-incremental set- ting, as a means to reduce the sparsity of syntax- based features. <ref type="bibr" target="#b12">Liu and Sarkar (2007)</ref> extract a rich feature set from TAG derivations and demon- strate that this improves SRL performance.</p><p>In contrast to incremental parsing, incremental semantic role labeling is a novel task. Our model builds on an incremental Tree Adjoining Gram- mar parser ) which predicts the syntactic structure of upcoming input. This al- lows us to perform incremental parsing and incre- mental SRL in tandem, exploiting the predictive component of the parser to assign (potentially in- complete) semantic roles on a word-by-word ba- sis. Similar to work on incremental parsing that evaluates incomplete trees <ref type="bibr" target="#b21">(Sangati and Keller, 2013)</ref>, we evaluate the incomplete semantic struc- tures produced by our model. <ref type="bibr" target="#b4">Demberg et al. (2013)</ref> introduce Psycholin- guistically Motivated Tree Adjoining Grammar (PLTAG), a grammar formalism that extends stan- dard TAG <ref type="bibr" target="#b9">(Joshi and Schabes, 1992</ref>) in order to enable incremental parsing. Standard TAG as- sumes a lexicon of elementary trees, each of which contains at least one lexical item as an an- chor and at most one leaf node as a foot node, marked with A * . All other leaves are marked with A↓ and are called substitution nodes. Elementary trees that contain a foot node are called auxiliary trees; those that do not are called initial trees. Ex- amples for TAG elementary trees are given in <ref type="figure">Fig- ure 1a</ref>-c. To derive a TAG parse for a sentence, we start with the elementary tree of the head of the sen- tence and integrate the elementary trees of the other lexical items of the sentence using two oper- ations: adjunction at an internal node and substi- tution at a substitution node (the node at which the operation applies is the integration point). Stan- dard TAG derivations are not guaranteed to be in- cremental, as adjunction can happen anywhere in a sentence, possibly violating left-to-right process- ing order. PLTAG addresses this limitation by in- troducing prediction trees, elementary trees with- out a lexical anchor. These can be used to predict syntactic structure anchored by words that appear later in an incremental derivation. The use of pre- diction trees ensures that fully connected prefix trees can be built for every prefix of the input sen- tence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Psycholinguistically Motivated TAG</head><p>Each node in a prediction tree carries mark- ers to indicate that this node was predicted, rather than being anchored by the current sentence pre- fix. An example is <ref type="figure">Figure 1d</ref>, which contains a prediction tree with marker "1". In PLTAG, mark- ers are eliminated through a new operation called verification, which matches them with the nodes    of non-predictive elementary trees. An example of a PLTAG derivation is given in <ref type="figure" target="#fig_7">Figure 2</ref>. In step 1, a prediction tree is introduced through sub- stitution, which then allows the adjunction of an adverb in step 2.</p><p>Step 3 involves the verification of the marker introduced by the prediction tree against the elementary tree for open.</p><p>In order to efficiently parse PLTAG, <ref type="bibr" target="#b4">Demberg et al. (2013)</ref> introduce the concept of fringes. Fringes capture the fact that in an incremental derivation, a prefix tree can only be combined with an elementary tree at a limited set of nodes. For instance, the prefix tree in <ref type="figure" target="#fig_3">Figure 3</ref> has two substi- tution nodes, for B and C. However, only substi- tution into B leads to a valid new prefix tree; if we substitute into C, we obtain the tree in <ref type="figure" target="#fig_3">Figure 3b</ref>, which is not a valid prefix tree (i.e., it represents a non-incremental derivation).</p><p>The parsing algorithm proposed by <ref type="bibr" target="#b4">Demberg et al. (2013)</ref> exploits fringes to tabulate interme- diate results. It manipulates a chart in which each cell (i, f ) contains all the prefix trees whose first i leaves are the first i words and whose current fringe is f . To extend the prefix trees for i to the prefix trees for i + 1, the algorithm retrieves all current fringes f such that the chart has entries in the cell (i, f ). For each such fringe, it needs to determine the elementary trees in the lexicon that can be combined with f using substitution or adjunction. In spite of the large size of a typi- cal TAG lexicon, this can be done efficiently, as it only requires matching the current fringes. For each match, the parser then computes the new pre-    <ref type="bibr" target="#b14">Marcus et al., 1993)</ref> into TAG for- mat by enriching it with head information and argument/modifier information from Propbank ( <ref type="bibr" target="#b19">Palmer et al., 2005</ref>). This makes it possible to decompose the Treebank trees into elementary trees as proposed by <ref type="bibr" target="#b25">Xia et al. (2000)</ref>. Predic- tion trees can be learned from the converted Tree- bank by calculating the connection path ( <ref type="bibr" target="#b16">Mazzei et al., 2007)</ref> at each word in a tree. Intuitively, a prediction tree for word w n contains the struc- ture that is necessary to connect w n to the prefix tree w 1 . . . w n−1 , but is not part of any of the ele- mentary trees of w 1 . . . w n−1 . Using this lexicon, a probabilistic model over PLTAG operations can be estimated following Chiang (2000).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Problem Formulation</head><p>In a typical semantic role labeling scenario, the goal is to first identify words that are predicates in the sentence and then identify and label all the arguments for each predicate. This translates into spotting specific words in a sentence that repre- sent the predicate's arguments, and assigning pre- defined semantic role labels to them. Note that in this work we focus on verb predicates only. The output of a semantic role labeler is a set of seman- tic dependency triples l, a, p, with l ∈ R , and a, p ∈ w, where R is a set of semantic role labels denoting a specific relationship between a predi- cate and an argument (e.g., ARG0, ARG1, ARGM in Propbank), w is the list of words in the sentence, l denotes a specific role label, a the argument, and p the predicate. An example is shown in <ref type="figure" target="#fig_5">Figure 4</ref>.</p><p>As discussed in the introduction, standard se- mantic role labelers make their decisions based on evidence from the whole sentence. In contrast, our aim is to assign semantic roles incrementally, i.e.,   we want to produce a set of (potentially incom- plete) semantic dependency triples for each prefix of the input sentence. Note that not every word is an argument to a predicate, therefore the set of triples will not necessarily change at every input word. Furthermore, the triples themselves may be incomplete, as either the predicate or the argu- ment may not have been observed yet (predicate- incomplete or argument-incomplete triples).</p><p>Our iSRL system relies on PLTAG, using a se- mantically augmented lexicon. We parse an in- put sentence incrementally, applying a novel in- cremental role propagation algorithm (IRPA) that creates or updates existing semantic triple candi- dates whenever an elementary (or prediction) tree containing role information is attached to the ex- isting prefix tree. As soon as a triple is completed we apply a two-stage classification process, that first identifies whether the predicate/argument pair is a good candidate, and then disambiguates role labels in case there is more than one candidate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Semantic Role Lexicon</head><p>Recall that Propbank is used to construct the PLTAG treebank, in order to distinguish between arguments and modifiers, which result in elemen- tary trees with substitution nodes, and auxiliary trees, i.e., trees with a foot node, respectively (see <ref type="figure">Figure 1</ref>). Conveniently, we can use the same in- formation to also enrich the extracted lexicon with the semantic role annotations, following the pro- cess described by <ref type="bibr" target="#b22">Sayeed and Demberg (2013)</ref>. <ref type="bibr">1</ref> For arguments, annotations are retained on the substitution node in the parental tree, while for modifiers, the role annotation is displayed on the foot node of the auxiliary tree. Note that we dis- play role annotation on traces that are leaf nodes, which enables us to recover long-range dependen- cies (third and fifth tree in <ref type="figure">Figure 5a</ref>). Likewise, we annotate prediction trees with semantic roles, which enables our system to predict upcoming in- complete triples.</p><p>Our annotation procedure unavoidably intro- duces some role ambiguity, especially for fre- quently occurring trees. This can give rise to two problems when we generate semantic triples incre- mentally: IRPA tends to create many spurious can- didate semantic triples for elementary trees that correspond to high frequency words (e.g., preposi- tions or modals). Secondly, a semantic triple may be identified correctly but is assigned several role labels. (See the elementary tree for refuse in Fig- ure 5a.) We address these issues by applying clas- sifiers for role label disambiguation at every pars- ing operation (substitution, adjunction, or verifica- tion), as detailed in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Incremental Role Propagation Algorithm</head><p>The main idea behind IRPA is to create or up- date existing semantic triples as soon as there is available role information during parsing. Our al- gorithm (lines 1-6 in Algorithm 1) is applied af- ter every PLTAG parsing operation, i.e., when an elementary or prediction tree T is adjoined to a particular integration point node π ip of the prefix tree of the sentence, via substitution or adjunction (lines 3-4). <ref type="bibr">2</ref> In case an elementary tree T v verifies a prediction tree T pr (lines 5-6), the same method- ology applies, the only difference being that we have to tackle multiple integration point nodes T pr,ip , one for each prediction marker of T pr that matches the corresponding nodes in T v .</p><p>For simplicity of presentation, we will use a concrete example, see <ref type="figure">Figure 5</ref>. <ref type="figure">Figure 5a</ref> shows the lexicon entries for the words of the sentence</p><p>Banks refused to open. Naturally, some nodes in the lexicon trees might have multiple candidate role labels. For example, the substitution NP node of the second tree takes two labels, namely A0 and A1. These stem from different role signatures when the same elementary tree occurs in differ- ent contexts during training (A1 only on the NP; A0 on the NP and A1 on S). For simplicity's sake, we collapse different signatures, and let a classi- fier labeller to disambiguate such cases (see Sec- tion 4.4).</p><p>Algorithm 1 Incremental Role Propagation Alg.</p><formula xml:id="formula_0">1: procedure IRPA(π ip , T , T pr ) 2: Σ ← ∅ Σ is a dictionary of (π ip , l, a, p) pairs 3:</formula><p>if parser operation is substitution or adjunction then 4:</p><formula xml:id="formula_1">CREATE-TRIPLES(π ip , T ) 5:</formula><p>else if parser operation is verification then 6:</p><formula xml:id="formula_2">CREATE-TRIPLES-VERIF(π ip , T , T pr )</formula><p>return set of triples l, a, p for prefix tree π</p><formula xml:id="formula_3">7: procedure CREATE-TRIPLES(π ip , T ) 8:</formula><p>if HAS-ROLES(π ip ) then 9:</p><formula xml:id="formula_4">UPDATE-TRIPLE(π ip , T ) 10:</formula><p>else if HAS-ROLES(T ) then 11:</p><p>T ip ← substitution or foot node of T 12:</p><formula xml:id="formula_5">ADD-TRIPLE(π ip , T ip , T ) 13:</formula><p>for all remaining nodes n ∈ T with roles do pred ← find dep ∈ Σ with matching π ip 42:</p><p>SET-PREDICATE(dep, pred) 43:</p><formula xml:id="formula_6">Σ ← (π ip , dep)</formula><p>Once we process Banks, the prefix tree becomes the lexical entry for this word, see the first col- umn of <ref type="figure">Figure 5b</ref>. Next, we process refused: the parser substitutes the prefix tree into the ele- mentary tree T of refused; 3 the integration point π ip on the prefix tree is the topmost NP. Since the operation is a substitution (line 3), we create triples between T and π ip via CREATE-TRIPLES (lines 7-12). π ip does not have any role infor- mation (line 8), so we proceed to add a new se- mantic triple between the role-labeled integration point T ip , i.e., substitution NP node of T , and π ip , via ADD-TRIPLE (lines 30-43). First, we create an incomplete semantic triple with all roles from T ip (line 31). Then we set the predicate to the an- chor of T to be the word refused, and the argu- ment to be the head word of the prefix tree, Banks (lines 34-35). Note that predicate identification is a trivial task based on part-of-speech information in the elementary tree. <ref type="bibr">4</ref> Then, we add the pair (NP → {A0,A1},Banks, refused) to a dictionary (line 43). Storing the in- tegration point along with the semantic triple is essential, to be able to recover incomplete triples in later stages of the algorithm. Finally, we re- peat this process for all remaining nodes on T that have roles, in our example the substitution node S (lines <ref type="bibr">[13]</ref><ref type="bibr">[14]</ref>. This outputs an incomplete triple, {A1},nil,refused.</p><p>Next, the parser decides to substitute a predic- tion tree (third tree in <ref type="figure">Figure 5a</ref>) into the substitu- tion node S of the prefix tree. Since the integration point is on the prefix tree and has role information (line 8), the corresponding triple should already be present in our dictionary. Upon retrieving it, we set the nil argument to the anchor of the incoming tree. Since it is a prediction tree, we set it to the root of the tree, namely S 2 (phrase labels in triples are denoted by italics), but mark the triple as yet incomplete. This distinction allows us to fill in the correct lexical information once it becomes avail- able, i.e, when the tree gets verified. We also add an incomplete triple for the trace t in the subject position of the prediction tree, as described above. Note that this triple contains multiple roles; this is expected given that prediction trees are unlexical- ized and occur in a wide variety of contexts.</p><p>When the next verb arrives, the parser success- fully verifies it against the embedded prediction IRPA MaltParser Banks - - refused {A0,A1},Banks,refused, A1,S 2 ,refused, {A0,A1,A2},t,nil A0,Banks,refused  <ref type="table">Table 1</ref>: Complete and incomplete semantic triple generation, comparing IRPA and a system that maps gold-standard role labels onto MaltParser in- cremental dependencies for <ref type="figure" target="#fig_5">Figure 4</ref>.</p><formula xml:id="formula_7">to - - open A1,</formula><p>tree within the prefix tree (last step of <ref type="figure">Figure 5b</ref>). Our algorithm first cycles through all nodes that match between the verification tree T v and the pre- diction tree T pr and will complete or create new triples via CREATE-TRIPLES (lines 18-20). In our example, the second semantic triple gets com- pleted by replacing S 2 with the head of the sub- tree rooted in S. Normally, this would be the verb open, but in this case the verb is followed by the infinitive marker to, hence we heuristically set it to be the argument of the triple instead, following Carreras and M` arquez (2005). For the last triple, we set the predicate to the anchor of T v open, and now are able to remove the excess role labels A0 and A2. This illustrated how the lexicalized veri- fication tree disambiguates the semantic informa- tion stored in the prediction tree. Finally, trace t is set to the closest NP head that is below the same phrase subtree, in this case Banks. Note that Banks is part of two triples as shown in the last tree of <ref type="figure">Figure 5b</ref>: it is either an A0 or an A1 for refused and an A1 for open.</p><p>We are able to create incomplete semantic triples after the prediction of the upcoming verb at step 2, as shown in <ref type="figure">Figure 5b</ref>. This is not possible using an incremental dependency parser such as MaltParser ( <ref type="bibr" target="#b17">Nivre et al., 2007</ref>) that lacks a predic- tive component. <ref type="table">Table 1</ref> illustrates this by compar- ing the output of IRPA for <ref type="figure">Figure 5b</ref> with the out- put of a baseline system that maps role labels onto the syntactic dependencies in <ref type="figure" target="#fig_5">Figure 4</ref>, generated incrementally by MaltParser (see Section 5.3 for a description of the MaltParser baseline). Malt- Parser has to wait for the verb open before out- putting the relevant semantic triples. In contrast, IRPA outputs incomplete triples as soon as the in- formation is available, and later on updates its de- cision. (MaltParser also incorrectly assigns A0 for the Banks-open pair.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Argument Identification and Role Label Disambiguation</head><p>IRPA produces semantic triples for every role an- notation present in the lexicon entries, which will often overgenerate role information. Furthermore, some triples have more than one role label at- tached to them. During verification, we are able to filter out the majority of labels in the correspond- ing prediction trees; However, most triples are cre- ated via substitution and adjunction. In order to address these problems we adhere to the following classification and ranking strategy: after each semantic triple gets completed, we per- form a binary classification that evaluates its suit- ability as a whole, given bilexical and syntactic in- formation. If the triple is identified as a good can- didate, then we perform multi-class classification over role labels: we feed the same bilexical and syntactic information to a logistic classifier, and get a ranked list of labels. We then use this list to re-rank the existing ambiguous role labels in the semantic triple, and output the top scoring ones.</p><p>The identifier is a binary L2-loss support vec- tor classifier, and the role disambiguator an L2- regularized logistic regression classifier, both im- plemented using the efficient LIBLINEAR frame- work of <ref type="bibr" target="#b5">Fan et al. (2008)</ref>. The features used are based on <ref type="bibr" target="#b1">Björkelund et al. (2009)</ref> and <ref type="bibr" target="#b12">Liu and Sarkar (2007)</ref>, and are listed in <ref type="table" target="#tab_4">Table 2</ref>.</p><p>The bilexical features are: predicate POS tag, predicate lemma, argument word form, argument POS tag, and position. The latter indicates the po- sition of the argument relative to the predicate, i.e., before, on, or after. The syntactic features are: the predicate and argument elementary trees with- out the anchors (to avoid sparsity), the category of the integration point node on the prefix tree where the elementary tree of the argument attaches to, an alphabetically ordered set of the categories of the fringe nodes of the prefix tree after attaching the argument tree, and the path of PLTAG opera- tions applied between the argument and the pred- icate. Note that most of the original features used by <ref type="bibr" target="#b1">Björkelund et al. (2009)</ref> and others are not ap- plicable in our context, as they exploit information that is not accessible incrementally. For example, sibling information to the right of the word is not available. Furthermore, our PLTAG parser does not compute syntactic dependencies, hence these cannot serve as features (and in any case not all dependencies are available incrementally, see <ref type="figure" target="#fig_5">Fig- ure 4)</ref>. To counterbalance this, we use local syn- tactic information stored in the fringe of the pre-   fix tree. We also store the series of operations ap- plied by our parser between argument and predi- cate, in an effort to emulate the effect of recover- ing longer-range patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">PLTAG and Classifier Training</head><p>We extracted the semantically-enriched lexicon and trained the PLTAG parser by converting the Wall Street Journal part of Penn Treebank to PLTAG format. We used Propbank to retrieve semantic role annotation, as described in Sec- tion 4.2. We trained the PLTAG parser according to <ref type="bibr" target="#b4">Demberg et al. (2013)</ref> and evaluated the parser on section 23, on sentences with 40 words or less, given gold POS tags for each word, and achieved a labeled bracket F 1 score of 79.41. In order to train the argument identification and role label disambiguation classifiers, we used the English portion of the <ref type="bibr">CoNLL 2009</ref><ref type="bibr">Shared Task (Hajič et al., 2009</ref><ref type="bibr" target="#b23">Surdeanu et al., 2008)</ref>. It consists of the Penn Treebank, automatically con- verted to dependencies following <ref type="bibr" target="#b8">Johansson and Nugues (2007)</ref>, accompanied by semantic role la- bel annotation for every argument pair. The latter is converted from Propbank based on <ref type="bibr" target="#b2">Carreras and M` arquez (2005)</ref>. We extracted the bilexical fea- tures for the classifiers directly from the gold stan- dard annotation of the training set. The syntactic features were obtained as follows: for every sen- tence in the training set we applied IRPA using the trained PLTAG parser, with gold standard lexicon entries for each word of the input sentence. This ensures near perfect parsing accuracy. Then for each semantic triple predicted incrementally, we extracted the relevant syntactic information in or- der to construct training vectors. If the identified predicate-argument pair was in the gold standard then we assigned a positive label for the identifi- cation classifier, otherwise we flagged it as nega- tive. For those pairs that are not identified by IRPA but exist in the gold standard (false negatives), we extracted syntactic information from already iden- tified similar triples, as follows: We first look for correctly identified arguments, wrongly attached to a different predicate and re-create the triple with correct predicate/argument information. If no ar- gument is found, we then pick the argument in the list of identified arguments for a correct predicate with the same POS-tag as the gold-standard argu- ment. In the case of the role label disambigua- tion classifier we just assign the gold label for ev- ery correctly identified pair, and ignore the (possi- bly ambiguous) predicted one. After tuning on the development set, the argument identifier achieved an accuracy of 92.18%, and the role label disam- biguation classifier, 82.37%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation</head><p>The focus of this paper is to build a system that is able to output semantic role labels for predicate- argument pairs incrementally, as soon as they be- come available. In order to properly evaluate such a system, we need to measure its performance in- crementally. We propose two different cumulative scores for assessing the (possibly incomplete) se- mantic triples that have been created so far, as the input is processed from left to right, per word. The first metric is called Unlabeled Prediction Score (UPS) and gets updated for every identified argu- ment or predicate, even if the corresponding se- mantic triple is incomplete. Note that UPS does not take into account the role label, it only mea- sures predicate and argument identification. In this respect it is analogous to unlabeled dependency accuracy reported in the parsing literature. We ex- pect a model that is able to predict semantic roles to achieve an improved UPS result compared to a system that does not do prediction, as illustrated in <ref type="table">Table 1</ref>. Our second score, Combined Incremental SRL Score (CISS), measures the identification of complete semantic role triples (i.e., correct predi- cate, predicate sense, argument, and role label) per word; by the end of the sentence, CISS coincides with standard combined SRL accuracy, as reported in CoNLL 2009 SRL-only task. This score is anal- ogous to labeled dependency accuracy in parsing.</p><p>Note that conventional SRL systems such as <ref type="bibr" target="#b1">Björkelund et al. (2009)</ref> typically assume gold standard syntactic information. In order to emu- late this, we give our parser gold standard lexicon entries for each word in the test set; these contain all possible roles observed in the training set for a given elementary tree (and all possible senses for each predicate). This way the parser achieves a syntactic parsing F 1 score of 94.24, thus ensur- ing the errors of our system can be attributed to IRPA and the classifiers. Also note that we evalu- ate on verb predicates only, therefore trivially re- ducing the task of predicate identification to the simple heuristic of looking for words in the sen- tence with a verb-related POS tag and excluding auxiliaries and modals. Likewise, predicate sense disambiguation on verbs presumably is trivial, as we observed almost no ambiguity of senses among lexicon entries of the same verb (we adhered to a simple majority baseline, by picking the most fre- quent sense, given the lexeme of the verb, in the few ambiguous cases). It seems that the syntactic information held in the elementary trees discrimi- nates well among different senses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">System Comparison</head><p>We evaluated three configurations of our system. The first configuration (iSRL) uses all seman- tic roles for each PLTAG lexicon entry, applies the PLTAG parser, IRPA, and both classifiers to perform identification and disambiguation, as de- scribed in Section 4. The second one (Majority- Baseline), solves the problem of argument identifi- cation and role disambiguation without the classi- fiers. For the former we employ a set of heuristics according to <ref type="bibr" target="#b11">Lang and Lapata (2014)</ref>, that rely on gold syntactic dependency information, sourced from CoNLL input. For the latter, we choose the most frequent role given the gold standard depen- dency relation label for the particular argument. Note that dependencies have been produced in view of the whole sentence and not incrementally.   The UPS results in <ref type="figure">Figure 6</ref> clearly show that our system (iSRL) outperforms both baselines on unlabeled argument and predicate prediction, across all four sentence lengths. Furthermore, we note that the iSRL system achieves a near- constant performance for all sentence prefixes. Our PLTAG-based prediction/verification archi- tecture allows us to correctly predict incomplete semantic role triples, even at the beginning of the sentence. Both baselines perform worse than the iSRL system in general. Moreover, the Malt- Baseline performs badly on the initial sentence prefixes (up to word 10), presumably as it does not benefit from syntactic prediction, and thus can- not generate incomplete triples early in the sen- tence, as illustrated in <ref type="table">Table 1</ref>. The Majority- Baseline also does not do prediction, but it has ac- cess to gold-standard syntactic dependencies, and thus outperforms the Malt-Baseline on initial sen- tence prefixes. Note that due to prediction, our system tends to over-generate incomplete triples in the beginning of sentences, compared to non- incremental output, which may inflate UPS for the first words. However, this cancels out later in the sentence if triples are correctly completed; failure to do so would decrease UPS. The near- constant performance of our output illustrates this phenomenon. Finally, the iSRL-Oracle outper- forms all other systems, as it benefits from correct role labels and correct PLTAG syntax, thus provid- ing an upper limit on performance.</p><p>The CISS results in <ref type="figure" target="#fig_11">Figure 7</ref> present a simi- lar picture. Again, the iSRL system outperforms both baselines at all sentence lengths. In addition, it shows particularly strong performance (almost at the level of the iSRL-Oracle) at the beginning of the sentence. This presumably is due to the fact that our system uses prediction and is able to identify correct semantic role triples earlier in the sentence. The baselines also show higher perfor- mance early in the sentence, but to a lesser degree. <ref type="table" target="#tab_6">Table 3</ref> reports traditional combined SRL scores for full sentences over all sentence lengths, as defined for the CoNLL task. Our iSRL system outperforms the Majority-Baseline by almost 15 points, and the Malt-Baseline by 25 points. It re- mains seven points below the iSRL-Oracle upper limit.</p><p>Finally, in order to test the effect of syntactic parsing on our system, we also experimented with a variant of our iSRL system that utilizes all lex- icon entries for each word in the test set. This is similar to performing the CoNLL 2009 joint task, which is designed for systems that carry out both syntactic parsing and semantic role labeling. This variant achieved a full sentence F-score of 68.0%, i.e., around 10 points lower than our iSRL system. This drop in score correlates with the difference in syntactic parsing F-score between the two ver- sions of PLTAG parser (94.24 versus 79.41), and is expected given the high ambiguity of the lex- icon entries for each word. Note, however, that the full-parsing version of our system still outper- forms Malt-Baseline by 15 points. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper, we introduced the new task of incre- mental semantic role labeling and proposed a sys- tem that solves this task by combining an incre- mental TAG parser with a semantically enriched lexicon, a role propagation algorithm, and a cas- cade of classifiers. This system achieved a full- sentence SRL F-score of 78.38% on the standard CoNLL dataset. Not only is the full-sentence score considerably higher than the Majority- Baseline (which is a strong baseline, as it uses gold-standard syntactic dependencies), but we also observe that our iSRL system performs well incrementally, i.e., it predicts both complete and incomplete semantic role triples correctly early on in the sentence. We attributed this to the fact that our TAG-based architecture makes it possible to predict upcoming syntactic structure together with the corresponding semantic roles.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 1: PLTAG lexicon entries: (a) and (b) initial trees, (c) auxiliary tree, (d) prediction tree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The current fringe (dashed line) indicates where valid substitutions can occur. Other substitutions result in an invalid prefix tree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Banks</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Syntactic dependency graph with semantic role annotation and the accompanying semantic triples, for Banks refused to open today.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>NP</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Incremental parse for Banks rarely open using the operations substitution (with a prediction tree), adjunction, and verification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>14: ADD-TRIPLE(π ip , n, T ) incomplete triples 15: procedure CREATE-TRIPLES-VERIF(π ip , T v , T pr ) 16: if HAS-ROLES(T v ) then 17: anchor ← lexeme of T v 18: for all T ip ← node in T v with role do 19: T pr,ip ← matching node of T ip in T pr 20: CREATE-TRIPLES(T pr,ip , T v ) Process the rest of covered nodes in T pr with roles 21: for all remaining T pr,ip ← node in T pr with role do 22: UPDATE-TRIPLE(T pr,ip , T pr ) 23: function UPDATE-TRIPLE(π ip , T ) 24: dep ← FIND-INCOMPLETE(Σ, T ip ) 25: anchor ← lexeme of T 26: if anchor of T is predicate then 27: SET-PREDICATE(dep, anchor) 28: else if anchor of T is argument then 29: SET-ARGUMENT(dep, anchor) return dep 30: procedure ADD-TRIPLE(π ip , T ip , T ) 31: dep ← [roles of T ip ], nil, nil 32: anchor ← lexeme of T 33: if anchor of T is predicate then 34: SET-PREDICATE(dep, anchor) 35: SET-ARGUMENT(dep, head of π ip ) 36: else if anchor of T is argument then 37: if T is auxiliary then adjunction 38: SET-ARGUMENT(dep, anchor) 39: else substitution: arg is head of prefix tree 40: SET-ARGUMENT(dep, head of T ip ) 41:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Figure 5: Incremental Role Propagation Algorithm application for the sentence Banks refused to open.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>System</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 :</head><label>7</label><figDesc>Figure 6: Unlabeled Prediction Score (UPS)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>refused to open today</head><label></label><figDesc></figDesc><table>A0 

A1 A1 

A1 
AM-TMP 

nsbj 
aux 

xcomp 

tmod 

A0,Banks,refused 
A1,to,refused 
A1,Banks,open 
AM-TMP,today,open 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>NP NNS Banks S VP S↓ {A1} VP</head><label></label><figDesc></figDesc><table>VBD 

refused 

NP↓ 
{A0,A1} 

S 2 

VP 2 

2 

VB 2 

2 

NP 2 

1 

t 1 

1 

{A0,A1,A2} 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Features for argument identification and 
role label disambiguation. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 3 : Full-sentence combined SRL score</head><label>3</label><figDesc></figDesc><table>This gives the baseline a considerable advantage 
especially in case of longer range dependencies. 
The third configuration (iSRL-Oracle), is identical 
to iSRL, but uses the gold standard roles for each 
PLTAG lexicon entry, and thus provides an upper-
bound for our methodology. Finally, we evalu-
ated against Malt-Baseline, a variant of Majority-
Baseline that uses the MaltParser of Nivre et al. 
(2007) to provide labeled syntactic dependencies 
MaltParser is a state-of-the-art shift-reduce depen-
dency parser which uses an incremental algorithm. 
Following Beuck et al. (2011), we modified the 
parser to provide intermediate output at each word 
by emitting the current state of the dependency 
graph before each shift step. We trained Malt-
Parser using the arc-eager algorithm (which out-
performed the other parsing algorithms available 
with MaltParser) on the CoNLL dataset, achiev-
ing a labeled dependency accuracy of 89.66% on 
section 23. 

6 Results 

Figures 6 and 7 show the results on the incremen-
tal SRL task. We plot the F 1 for Unlabeled Predic-
tion Score (UPS) and Combined Incremental SRL 
Score (CISS) per word, separately for sentences 
of lengths 10, 20, 30, and 40 words. The task gets 
harder with increasing sentence length, hence we 
can only meaningfully compare the average scores 
for sentence of the same length. (This approach 
was proposed by Sangati and Keller 2013 for eval-
uating the performance of incremental parsers.) 
</table></figure>

			<note place="foot" n="1"> Contrary to Sayeed and Demberg (2013) we put role label annotations for PPs on the preposition rather than their NP child, following of the CoNLL 2005 shared task (Carreras and M` arquez, 2005).</note>

			<note place="foot" n="2"> Prediction tree T pr in our algorithm is only used during verification, so it set to nil for substitution and adjunction operations.</note>

			<note place="foot" n="3"> PLTAG parsing operations can occur in two ways: An elementary tree can be substituted into the substitution node of the prefix tree, or the prefix tree can be substituted into a node of an elementary tree. The same holds for adjunction. 4 Most predicates can be identified as anchors of nonmodifier auxiliary trees. However, there are exceptions to this rule, i.e., modifier auxiliary trees and non-modifier nonauxiliary trees being also verbs in our lexicon, hence the use of the more reliable POS tags.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>EPSRC support through grant EP/I032916/1 "An integrated model of syntactic and semantic predic-tion in human language processing" to FK and ML is gratefully acknowledged.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Incremental parsing and the evaluation of partial dependency analyses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niels</forename><surname>Beuck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Khn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Menzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Conference on Dependency Linguistics. Depling</title>
		<meeting>the 1st International Conference on Dependency Linguistics. Depling</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multilingual semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Love</forename><surname>Hafdell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task. Association for Computational Linguistics</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning: Shared Task. Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA, CoNLL &apos;09</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2005 shared task: Semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Conference on Computational Natural Language Learning. Association for Computational Linguistics</title>
		<meeting>the Ninth Conference on Computational Natural Language Learning. Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA, CONLL &apos;05</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="152" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Statistical parsing with an automatically-extracted tree adjoining grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 38th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="456" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Incremental, predictive parsing with psycholinguistically motivated treeadjoining grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vera</forename><surname>Demberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1025" to="1066" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang-Rui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Antònia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Stěpánek</surname></persName>
		</author>
		<imprint>
			<publisher>Pavel</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Straňák</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference on Computational Natural Language Learning (CoNLL-2009)</title>
		<meeting>the 13th Conference on Computational Natural Language Learning (CoNLL-2009)<address><addrLine>Boulder, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Extended constituent-to-dependency conversion for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
		<editor>Joakim Nivre, Heiki-Jaan Kalep, Kadri Muischnek, and Mare Koit, editors</editor>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="105" to="112" />
		</imprint>
		<respStmt>
			<orgName>NODALIDA 2007 Proceedings. University of Tartu</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tree adjoining grammars and lexicalized grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Schabes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tree Automata and Languages</title>
		<editor>Maurice Nivat and Andreas Podelski</editor>
		<meeting><address><addrLine>North-Holland, Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="409" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cognitively plausible models of human language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Companion</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics, Companion<address><addrLine>Uppsala</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="60" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Similaritydriven semantic role induction via graph partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics Accepted</title>
		<imprint>
			<biblScope unit="page" from="1" to="62" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Experimental evaluation of LTAG-based features for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yudong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<title level="m">Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<imprint>
			<publisher>EMNLP-CoNLL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Mary Ann Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semantic Role Labeling: An Introduction to the Special Issue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">C</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Litkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="159" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamic TAG and lexical dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Mazzei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzo</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Sturt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research on Language and Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="309" to="332" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Maltparser: A language-independent system for data-driven dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atanas</forename><surname>Chanev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gülsen</forename><surname>Eryigit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetoslav</forename><surname>Marinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="95" to="135" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A probabilistic model of semantic plausibility in sentence processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrike</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Crocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="794" to="838" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The proposition bank: An annotated corpus of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="106" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ambiguity resolution in sentence processing: Evidence against frequency-based accounts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">J</forename><surname>Pickering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Traxler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Crocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="475" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Incremental tree substitution grammar for parsing and word prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Sangati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="111" to="124" />
			<date type="published" when="2013-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The semantic augmentation of a psycholinguisticallymotivated syntactic formalism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asad</forename><surname>Sayeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vera</forename><surname>Demberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Annual Workshop on Cognitive Modeling and Computational Linguistics (CMCL). Association for Computational Linguistics</title>
		<meeting>the Fourth Annual Workshop on Cognitive Modeling and Computational Linguistics (CMCL). Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="57" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference on Computational Natural Language Learning</title>
		<meeting>the 12th Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The zero-frequency problem: estimating the probabilities of novel events in adaptive text compression. Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">C</forename><surname>Bell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1085" to="1094" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A uniform method of grammar extraction and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora</title>
		<meeting>the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="53" to="62" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
