<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Human Judgment Corpus and a Metric for Arabic MT Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houda</forename><surname>Bouamor</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanan</forename><surname>Alshikhabobakr</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behrang</forename><surname>Mohit</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kemal</forename><surname>Oflazer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Human Judgment Corpus and a Metric for Arabic MT Evaluation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="207" to="213"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a human judgments dataset and an adapted metric for evaluation of Arabic machine translation. Our medium-scale dataset is the first of its kind for Ara-bic with high annotation quality. We use the dataset to adapt the BLEU score for Arabic. Our score (AL-BLEU) provides partial credits for stem and morphological matchings of hypothesis and reference words. We evaluate BLEU, METEOR and AL-BLEU on our human judgments corpus and show that AL-BLEU has the highest correlation with human judgments. We are releasing the dataset and software to the research community.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Evaluation of Machine Translation (MT) contin- ues to be a challenging research problem. There is an ongoing effort in finding simple and scal- able metrics with rich linguistic analysis. A wide range of metrics have been proposed and evaluated mostly for European target languages <ref type="bibr">(CallisonBurch et al., 2011;</ref><ref type="bibr" target="#b16">Macháček and Bojar, 2013)</ref>. These metrics are usually evaluated based on their correlation with human judgments on a set of MT output. While there has been growing interest in building systems for translating into Arabic, the evaluation of Arabic MT is still an under-studied problem. Standard MT metrics such as BLEU <ref type="bibr" target="#b18">(Papineni et al., 2002</ref>) or TER ( <ref type="bibr" target="#b22">Snover et al., 2006</ref>) have been widely used for evaluating Arabic MT <ref type="bibr" target="#b8">(El Kholy and Habash, 2012</ref>). These metrics use strict word and phrase matching between the MT output and reference translations. For morpholog- ically rich target languages such as Arabic, such criteria are too simplistic and inadequate. In this paper, we present: (a) the first human judgment dataset for Arabic MT (b) the Arabic Language BLEU (AL-BLEU), an extension of the BLEU score for Arabic MT evaluation.</p><p>Our annotated dataset is composed of the output of six MT systems with texts from a diverse set of topics. A group of ten native Arabic speakers an- notated this corpus with high-levels of inter-and intra-annotator agreements. Our AL-BLEU met- ric uses a rich set of morphological, syntactic and lexical features to extend the evaluation beyond the exact matching. We conduct different exper- iments on the newly built dataset and demonstrate that AL-BLEU shows a stronger average correla- tion with human judgments than the BLEU and METEOR scores. Our dataset and our AL-BLEU metric provide useful testbeds for further research on Arabic MT and its evaluation. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Several studies on MT evaluation have pointed out the inadequacy of the standard n-gram based eval- uation metrics for various languages <ref type="bibr">(CallisonBurch et al., 2006</ref>). For morphologically complex languages and those without word delimiters, sev- eral studies have attempted to improve upon them and suggest more reliable metrics that correlate better with human judgments <ref type="bibr" target="#b6">(Denoual and Lepage, 2005;</ref><ref type="bibr" target="#b11">Homola et al., 2009)</ref>.</p><p>A common approach to the problem of mor- phologically complex words is to integrate some linguistic knowledge in the metric. ME- TEOR ( <ref type="bibr" target="#b5">Denkowski and Lavie, 2011</ref>), TER- Plus ( <ref type="bibr" target="#b23">Snover et al., 2010</ref>) incorporate limited lin- guistic resources. Popovi´c <ref type="bibr" target="#b19">Popovi´c and Ney (2009)</ref> showed that n-gram based evaluation metrics calculated on POS sequences correlate well with human judg- ments, and recently designed and evaluated MPF, a BLEU-style metric based on morphemes and POS tags <ref type="bibr" target="#b20">(Popovi´cPopovi´c, 2011</ref>). In the same direc-tion, <ref type="bibr" target="#b2">Chen and Kuhn (2011)</ref> proposed AMBER, a modified version of BLEU incorporating re- call, extra penalties, and light linguistic knowl- edge about English morphology. <ref type="bibr" target="#b15">Liu et al. (2010)</ref> propose TESLA-M, a variant of a metric based on n-gram matching that utilizes light-weight lin- guistic analysis including lemmatization, POS tag- ging, and WordNet synonym relations. This met- ric was then extended to TESLA-B to model phrase synonyms by exploiting bilingual phrase tables <ref type="bibr" target="#b4">(Dahlmeier et al., 2011</ref>). <ref type="bibr" target="#b25">Tantug et al. (2008)</ref> presented BLEU+, a tool that implements various extension to BLEU computation to allow for a better evaluation of the translation perfor- mance for Turkish.</p><p>To the best of our knowledge the only human judgment dataset for Arabic MT is the small cor- pus which was used to tune parameters of the ME- TEOR metric for Arabic ( <ref type="bibr" target="#b5">Denkowski and Lavie, 2011</ref>). Due to the shortage of Arabic human judg- ment dataset, studies on the performance of eval- uation metrics have been constrained and limited. A relevant effort in this area is the upper-bound es- timation of BLEU and METEOR scores for Ara- bic MT output <ref type="bibr" target="#b7">(El Kholy and Habash, 2011</ref>). As part of its extensive functionality, the AMEANA system provides the upper-bound estimate by an exhaustive matching of morphological and lexical features between the hypothesis and the reference translations. Our use of morphological and lex- ical features overlaps with the AMEANA frame- work. However, we extend our partial matching to a supervised tuning framework for estimating the value of partial credits. Moreover, our human judgment dataset allows us to validate our frame- work with a large-scale gold-standard data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Human judgment dataset</head><p>We describe here our procedure for compiling a diverse Arabic MT dataset and annotating it with human judgments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data and systems</head><p>We annotate a corpus composed of three datasets: (1) the standard English-Arabic NIST 2005 cor- pus, commonly used for MT evaluations and com- posed of news stories. We use the first English translation as the source and the single corre- sponding Arabic sentence as the reference. (2) the MEDAR corpus ( <ref type="bibr" target="#b17">Maegaard et al., 2010</ref>) that con- sists of texts related to the climate change with four Arabic reference translations. We only use the first reference in this study. (3) a small dataset of Wikipedia articles (WIKI) to extend our cor- pus and metric evaluation to topics beyond the commonly-used news topics. This sub-corpus consists of our in-house Arabic translations of seven English Wikipedia articles. The articles are: Earl Francis Lloyd, Western Europe, Citizenship, Marcus Garvey, Middle Age translation, Acadian, NBA. The English articles which do not exist in the Arabic Wikipedia were manually translated by a bilingual linguist. <ref type="table">Table 1</ref> gives an overview of these sub-corpora characteristics.</p><p>NIST MEDAR WIKI # of Documents 100 4 7 # of Sentences 1056 509 327 <ref type="table">Table 1</ref>: Statistics on the datasets.</p><p>We use six state-of-the-art English-to-Arabic MT systems. These include four research-oriented phrase-based systems with various morphological and syntactic features and different Arabic tok- enization schemes and also two commercial off- the-shelf systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Annotation of human judgments</head><p>In order conduct a manual evaluation of the six MT systems, we formulated it as a ranking prob- lem. We adapt the framework used in the WMT 2011 shared task for evaluating MT metrics on European language pairs <ref type="bibr" target="#b1">(Callison-Burch et al., 2011</ref>) for Arabic MT. We gather human ranking judgments by asking ten annotators (each native speaker of Arabic with English as a second lan- guage) to assess the quality of the English-Arabic systems, by ranking sentences relative to each other, from the best to the worst (ties are allowed).</p><p>We use the Appraise toolkit (Federmann, 2012) designed for manual MT evaluation. The tool dis- plays to the annotator, the source sentence and translations produced by various MT systems. The annotators received initial training on the tool and the task with ten sentences. They were presented with a brief guideline indicating the purpose of the task and the main criteria of MT output evaluation.</p><p>Each annotator was assigned to 22 ranking tasks. Each task included ten screens. Each screen involveed ranking translations of ten sentences. In total, we collected 22, 000 rankings for 1892 sen-tences (22 tasks×10 screens×10 judges). In each annotation screen, the annotator was shown the source-language (English) sentences, as well as five translations to be ranked. We did not provide annotators with the reference to avoid any bias in the annotation process. Each source sentence was presented with its direct context. Rather than at- tempting to get a complete ordering over the sys- tems, we instead relied on random selection and a reasonably large sample size to make the compar- isons fair <ref type="bibr" target="#b1">(Callison-Burch et al., 2011</ref>).</p><p>An example of a source sentence and its five translations to be ranked is given in <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Annotation quality and analysis</head><p>In order to ensure the validity of any evaluation setup, a reasonable of inter-and intra-annotator agreement rates in ranking should exist. To mea- sure these agreements, we deliberately reassigned 10% of the tasks to second annotators. More- over, we ensured that 10% of the screens are re- displayed to the same annotator within the same task. This procedure allowed us to collect reliable quality control measure for our dataset.  <ref type="table">Table 3</ref>: Inter-and intra-annotator agreement scores for our annotation compared to the aver- age scores for five English to five European lan- guages and also English-Czech <ref type="bibr" target="#b1">(Callison-Burch et al., 2011</ref>).</p><p>We measured head-to-head pairwise agreement among annotators using Cohen's kappa (κ) <ref type="bibr" target="#b3">(Cohen, 1968</ref>), defined as follows:</p><formula xml:id="formula_0">κ = P (A) − P (E) 1 − P (E)</formula><p>where P(A) is the proportion of times annotators agree and P(E) is the proportion of agreement by chance. <ref type="table">Table 3</ref> gives average values obtained for inter- annotator and intra-annotator agreement and com- pare our results to similar annotation efforts in WMT-13 on different European languages. Here we compare against the average agreement for En- glish to five languages and also from English to one morphologically rich language (Czech). <ref type="bibr">4</ref> Based on <ref type="bibr" target="#b13">Landis and Koch (1977)</ref> κ interpre- tation, the κ inter value (57%) and also compar- ing our agreement scores with WMT-13 annota- tions, we believe that we have reached a reliable and consistent annotation quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">AL-BLEU</head><p>Despite its well-known shortcomings <ref type="bibr">(CallisonBurch et al., 2006</ref>), BLEU continues to be the de-facto MT evaluation metric. BLEU uses an exact n-gram matching criterion that is too strict for a morphologically rich language like Arabic. The system outputs in <ref type="table">Table 2</ref> are examples of how BLEU heavily penalizes Arabic. Based on BLEU, the best hypothesis is from Sys 5 which has three unigram and one bigram exact matches with the reference. However, the sentence is the 4 th ranked by annotators. In contrast, the output of Sys 3 (ranked 1 st by annotators) has only one ex- act match, but several partial matches when mor- phological and lexical information are taken into consideration.</p><p>We propose the Arabic Language BLEU (AL- BLEU) metric which extends BLEU to deal with Arabic rich morphology. We extend the matching to morphological, syntactic and lexical levels with an optimized partial credit. AL-BLEU starts with the exact matching of hypothesis tokens against the reference tokens. Furthermore, it considers the following: (a) morphological and syntactic feature matching, (b) stem matching. Based on Arabic lin- guistic intuition, we check the matching of a sub- set of 5 morphological features: (i) POS tag, (ii) gender (iii) number (iv) person (v) definiteness. We use the MADA package ( <ref type="bibr" target="#b10">Habash et al., 2009)</ref> to collect the stem and the morphological features of the hypothesis and reference translation. <ref type="figure">Figure 1</ref> summarizes the function in which we consider partial matching (m(t h , t r )) of a hypoth- esis token (t h ) and its associated reference token (t r ). Starting with the BLEU criterion, we first check if the hypothesis token is same as the ref- erence one and provide the full credit for it. If the exact matching fails, we provide partial credit for matching at the stem and morphological level. The value of the partial credits are the sum of the stem weight (w s ) and the morphological fea-  <ref type="table">Table 2</ref>: Example of ranked MT outputs in our gold-standard dataset. The first two rows specify the English input and the Arabic reference, respectively. The third row of the table lists the different MT system as ranked by annotators, using BLEU scores (column 4) and AL-BLEU (column 6). The differ- ent translation candidates are given here along with their associated Bucklwalter transliteration. 3 This example, shows clearly that AL-BLEU correlates better with human decision.</p><formula xml:id="formula_1">m(t h , t r ) =        1, if t h = t r w s + 5 i=1</formula><p>w f i otherwise <ref type="figure">Figure 1</ref>: Formulation of our partial matching.</p><p>ture weights (w f i ). Each weight is included in the partial score, if such matching exist (e.g., stem match). In order to avoid over-crediting, we limit the range of weights with a set of constraints. Moreover, we use a development set to optimize the weights towards improvement of correlation with human judgments, using a hill-climbing al- gorithm <ref type="bibr" target="#b21">(Russell and Norvig, 2009)</ref>.  Following the BLEU-style exact matching and scoring of different n-grams, AL-BLEU updates the n-gram scores with the partial credits from non-exact matches. We use a minimum partial credit for n-grams which have tokens with dif- ferent matching score. The contribution of a partially-matched n-gram is not 1 (as counted in BLEU), but the minimum value that individual to- kens within the bigram are credited. For exam- ple, if a bigram is composed of a token with exact matching and a token with stem matching, this bi- gram receives a credit equal to a unigram with the stem matching (a value less than 1). While par- tial credits are added for various n-grams, the fi- nal computation of the AL-BLEU is similar to the original BLEU based on the geometric mean of the different matched n-grams. We follow BLEU in using a very small smoothing value to avoid zero n-gram counts and zero score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and results</head><p>An automatic evaluation metric is said to be suc- cessful if it is shown to have high agreement with human-performed evaluations <ref type="bibr" target="#b24">(Soricut and Brill, 2004</ref>). We use Kendall's tau τ ( <ref type="bibr" target="#b12">Kendall, 1938)</ref>, a coefficient to measure the correlation between the system rankings and the human judgments at the sentence level. Kendall's tau τ is calculated as follows:</p><formula xml:id="formula_2">τ = # of concordant pairs -# of discordant pairs total pairs</formula><p>where a concordant pair indicates two translations of the same sentence for which the ranks obtained from the manual ranking task and from the corre- sponding metric scores agree (they disagree in a discordant pair  are concordant). Thus, an automatic evaluation metric with a higher τ value is making predic- tions that are more similar to the human judgments than an automatic evaluation metric with a lower τ . We calculate the τ score for each sentence and average the scores to reach the corpus-level cor- relation. We conducted a set of experiments to compare the correlation of AL-BLEU against the state-of-the art MT evaluation metrics. For this we use a subset of 900 sentences extracted from the dataset described in Section 3.1. As mentioned above, the stem and morphological features in AL- BLEU are parameterized each by weights which are used to calculate the partial credits. We op- timize the value of each weight towards correla- tion with human judgment by hill climbing with 100 random restarts using a development set of 600 sentences. The 300 remaining sentences (100 from each corpus) are kept for testing. The de- velopment and test sets are composed of equal portions of sentences from the three sub-corpora (NIST, MEDAR, WIKI). As baselines, we measured the correlation of BLEU and METEOR with human judgments col- lected for each sentence. We did not observe a strong correlation with the Arabic-tuned ME- TEOR. We conducted our experiments on the stan- dard METEOR which was a stronger baseline than its Arabic version. In order to avoid the zero n- gram counts and artificially low BLEU scores, we use a smoothed version of BLEU. We follow <ref type="bibr" target="#b14">Liu and Gildea (2005)</ref> to add a small value to both the matched n-grams and the total number of n-grams (epsilon value of 10 −3 ). In order to reach an op- timal ordering of partial matches, we conducted a set of experiments in which we compared differ- ent orders between the morphological and lexical matchings to settle with the final order which was presented in <ref type="figure">Figure 1</ref>. <ref type="table" target="#tab_2">Table 4</ref> shows a comparison of the average cor- relation with human judgments for BLEU, ME- TEOR and AL-BLEU. AL-BLEU shows a strong improvement against BLEU and a competitive im- provement against METEOR both on the test and development sets. The example in <ref type="table">Table 2</ref> shows a sample case of such improvement. In the ex- ample, the sentence ranked the highest by the an- notator has only two exact matching with the ref- erence translation (which results in a low BLEU score). The stem and morphological matching of AL-BLEU, gives a score and ranking much closer to human judgments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented AL-BLEU, our adaptation of BLEU for the evaluation of machine translation into Ara- bic. The metric uses morphological, syntactic and lexical matching to go beyond exact token match- ing. We also presented our annotated corpus of human ranking judgments for evaluation of Ara- bic MT. The size and diversity of the topics in the corpus, along with its relatively high annota- tion quality (measured by IAA scores) makes it a useful resource for future research on Arabic MT. Moreover, the strong performance of our AL- BLEU metric is a positive indicator for future ex- ploration of richer linguistic information in evalu- ation of Arabic MT.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2 il- lustrates these various samples of partial matching highlighted in different colors. ‫الطارئة‬ ‫االسيان‬ ‫قمة‬ ‫حضور‬ ‫تعتزم‬ ‫فرنسا‬ ‫لألسيان‬ ‫الطارئة‬ ‫القمة‬ ‫لحضور‬ ‫تخطط‬ ‫فرنسا‬ REF: HYP: SRC: France Plans To Attend ASEAN Emergency Summit</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An MT example with exact matchings (blue), stem and morphological matching (green), stem only matching (red) and morphological-only matching (pink).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Source France plans to attend ASEAN emergency summit. Reference frnsaA tEtzm HDwr qmp AaAlaAsyaAn AaAlTaAr}ip Hypothesis Systems RankAnnot BLEU RankBLEU AL-BLEU RankAL</head><label></label><figDesc></figDesc><table>−BLEU 
Sys1 
2 
0.0047 
2 
0.4816 
1 















wtxTaT frnsaA lHDwr qmp AaAl-syaAn AaAlTaAr}ip 

Sys2 
3 
0.0037 
3 
0.0840 
3 













wtxTaT frnsaA lHDwr qmp AaAlOasyaAn 

Sys3 
1 
0.0043 
4 
0.0940 
2 














frnsaA txTaT lHDwr AaAlqmp AaAlTaAr}ip lalOasyaAn 
Sys4 
5 
0.0043 
4 
0.0604 
5 














xTaT frnsaA lHDwr qmp -syaAn AaAlTwaAri} 
Sys5 
4 
0.0178 
1 
0.0826 
4 












frnsaA lHDwr qmp AaAlaAsyaAn xTaT AaAlTwaAri} 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Comparison of the average Kendall's τ 
correlation. 

</table></figure>

			<note place="foot" n="1"> The dataset and the software are available at: http://nlp.qatar.cmu.edu/resources/ AL-BLEU</note>

			<note place="foot" n="4"> We compare against the agreement score for annotations performed by WMT researchers which are higher than the WMT annotations on Mechanical Turk.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>We thank Michael Denkowski, Ahmed El Kholy, Francisco Guzman, Nizar Habash, Alon Lavie, Austin Matthews, Preslav Nakov for their com-ments and help in creation of our dataset. We also thank our team of annotators from CMU-Qatar. This publication was made possible by grants YSREP-1-018-1-004 and NPRP-09-1140-1-177 from the Qatar National Research Fund (a member of the Qatar Foundation). The statements made herein are solely the responsibility of the au-thors.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Re-evaluating the Role of BLEU in Machine Translation Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Conference of the European Chapter</title>
		<meeting>the 11th Conference of the European Chapter<address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Findings of the 2011 Workshop on Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Zaidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">AMBER: A Modified BLEU, Enhanced Ranking Metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="71" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weighted Kappa: Nominal Scale Agreement Provision for Scaled Disagreement or Partial Credit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">213</biblScope>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">TESLA at WMT 2011: Translation Evaluation and Tunable Metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="78" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Meteor 1.3: Automatic Metric for Reliable Optimization and Evaluation of Machine Translation Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP 2011 Workshop on Statistical Machine Translation</title>
		<meeting>the EMNLP 2011 Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BLEU in Characters: Towards Automatic MT Evaluation in Languages Without Word Delimiters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Denoual</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Lepage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Joint Conference on Natural Language Processing</title>
		<meeting>the Second International Joint Conference on Natural Language Processing<address><addrLine>Jeju Island, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic Error Analysis for Morphologically Rich Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">El</forename><surname>Kholy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the MT Summit XIII</title>
		<meeting>the MT Summit XIII<address><addrLine>Xiamen, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Orthographic and Morphological Processing for EnglishArabic Statistical Machine Translation. Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">El</forename><surname>Kholy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="25" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Appraise: an OpenSource Toolkit for Manual Evaluation of MT Output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Prague Bulletin of Mathematical Linguistics</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="35" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mada+ Tokan: A Toolkit for Arabic Tokenization, Diacritization, Morphological Disambiguation, POS Tagging, Stemming and Lemmatization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Arabic Language Resources and Tools (MEDAR)</title>
		<meeting>the Second International Conference on Arabic Language Resources and Tools (MEDAR)<address><addrLine>Cairo, Egypt</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Simple Automatic MT Evaluation Metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Homola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladislav</forename><surname>Kuboň</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Statistical Machine Translation</title>
		<meeting>the Fourth Workshop on Statistical Machine Translation<address><addrLine>Athens, Greece, March</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A New Measure of Rank Correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Maurice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<date type="published" when="1938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Measurement of Observer Agreement for Categorical Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Syntactic Features for Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">TESLA: Translation Evaluation of Sentences with Linear-Programming-Based Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and Metrics (MATR)</title>
		<meeting>the Joint Fifth Workshop on Statistical Machine Translation and Metrics (MATR)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="354" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Results of the WMT13 Metrics Shared Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matouš</forename><surname>Macháček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Statistical Machine Translation</title>
		<meeting>the Eighth Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="45" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cooperation for Arabic Language Resources and Tools-The MEDAR Project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bente</forename><surname>Maegaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Attia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Krauwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Yaseen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC<address><addrLine>Valetta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BLEU: A Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Syntaxoriented Evaluation Measures for Machine Translation Output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Statistical Machine Translation</title>
		<meeting>the Fourth Workshop on Statistical Machine Translation<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="29" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Morphemes and POS Tags for n-gram Based Evaluation Metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="104" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Artificial Intelligence: A Modern Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Norvig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Prentice Hall Englewood Cliffs</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Study of Translation Edit Rate with Targeted Human Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AMTA</title>
		<meeting>AMTA<address><addrLine>Boston, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">TER-Plus: Paraphrase, Semantic, and Alignment Enhancements to Translation Edit Rate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Unified Framework For Automatic Evaluation Using 4-Gram Cooccurrence Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="613" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">BLEU+: a Tool for Fine-Grained BLEU Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cüneyd</forename><surname>Tantug</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kemal</forename><surname>Oflazer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilknur Durgar</forename><surname>Elkahlout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th edition of the Language Resources and Evaluation Conference</title>
		<meeting>the 6th edition of the Language Resources and Evaluation Conference<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
