<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:25+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semantic Role Labeling with Neural Network Factors</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Fitzgerald</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Washington † Google</orgName>
								<address>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Washington † Google</orgName>
								<address>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Washington † Google</orgName>
								<address>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Washington † Google</orgName>
								<address>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semantic Role Labeling with Neural Network Factors</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a new method for semantic role labeling in which arguments and semantic roles are jointly embedded in a shared vector space for a given predicate. These embeddings belong to a neural network, whose output represents the potential functions of a graphical model designed for the SRL task. We consider both local and structured learning methods and obtain strong results on standard PropBank and FrameNet corpora with a straightforward product-of-experts model. We further show how the model can learn jointly from PropBank and FrameNet annotations to obtain additional improvements on the smaller FrameNet dataset.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic role labeling (SRL) is the task of iden- tifying the semantic arguments of a predicate and labeling them with their semantic roles. A key chal- lenge in this task is sparsity of labeled data: a given predicate-role instance may only occur a handful of times in the training set. Most existing SRL systems model each semantic role as an atomic unit of meaning, ignoring finer-grained semantic similarity between roles that can be leveraged to share context between similar labels, both within and across annotation conventions.</p><p>Low-dimensional embedding representations have been shown to be successful in overcoming sparsity and representing label similarity across a wide range of tasks <ref type="bibr" target="#b37">(Weston et al., 2011;</ref><ref type="bibr" target="#b29">Srikumar and Manning, 2014;</ref><ref type="bibr" target="#b14">Hermann et al., 2014;</ref><ref type="bibr" target="#b18">Lei et al., 2015)</ref>. In this paper, we present a new model for SRL that embeds candidate arguments and semantic roles (in context of a predicate frame) in a shared vector space. A feed-forward neural * Work carried out during an internship at <ref type="bibr">Google.</ref> network is learned to capture correlations of the re- spective embedding dimensions to create argument and role representations. The similarity of these two representations, as measured by their dot prod- uct, is used to score possible roles for candidate arguments within a graphical model. This graphical model jointly models the assignment of semantic roles to all arguments of a predicate, subject to structural linguistic constraints.</p><p>Our model has several advantages. Compared to linear multiclass classifiers used in prior work, vector embeddings of the predictions overcome the assumption of modeling each semantic role as a discrete label, thus capturing fine-grained label sim- ilarity. Moreover, since predictions and inputs are embedded in the same vector space, and features extracted from inputs and outputs are decoupled, our approach is amenable to joint learning of multi- ple annotation conventions, such as PropBank and FrameNet, in a single model. Finally, as with other neural network approaches, our model obviates the need to manually engineer feature conjunctions.</p><p>Our underlying inference algorithm for SRL follows <ref type="bibr">Täckström et al. (2015)</ref>, who presented a dynamic program for structured SRL; it is tar- geted towards the prediction of full argument spans. Hence, we present empirical results on three span- based SRL datasets: CoNLL 2005 and 2012 data annotated with PropBank conventions, as well as FrameNet 1.5 data. We also evaluate our system on the dependency-based CoNLL 2009 shared task by assuming single word argument spans, that rep- resent semantic dependencies, and limit our ex- periments to English. On all datasets, our model performs on par with a strong linear model base- line that uses hand-engineered conjunctive features. Due to random parameter initialization and stochas- ticity in the online learning algorithm used to train our models, we observed considerable variance in performance across datasets. To resolve this vari- ance, we adopt a product-of-experts model that John stole my car .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>steal.V</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theft</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Perpetrator Goods</head><p>Mary lifted a purse .</p><formula xml:id="formula_0">lift.V Theft Perpetrator Goods (a)</formula><p>John stole my car .</p><p>steal.V steal.01</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A0 A1</head><p>Mary lifted a purse .</p><p>lift.V lift.02</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A0 A1</head><p>(b) <ref type="figure">Figure 1</ref>: FrameNet (a) and PropBank (b) annota- tions for two sentences.</p><p>combines multiple randomly-initialized instances of our model to achieve state-of-the-art results on the CoNLL 2009 and FrameNet datasets, while coming close to the previous best published results on the other two. Finally, we present even stronger results for FrameNet data (which is scarce) by jointly training the model with PropBank-annotated data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section, we briefly describe the SRL task and discuss relevant prior work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Semantic Role Labeling</head><p>SRL annotations rely on a frame lexicon containing frames that could be evoked by one or more lexical units. A lexical unit consists of a word lemma con- joined with its coarse-grained part-of-speech tag. 1 Each frame is further associated with a set of pos- sible core and non-core semantic roles which are used to label its arguments. This description of a frame lexicon covers both PropBank and FrameNet conventions, but there are some differences out- lined below. See <ref type="figure">Figure 1</ref> for example annotations. PropBank defines frames that are essentially sense distinctions of a given lexical unit. The set of PropBank roles consists of seven generic core roles (labeled A0-A5 and AA) that assume different se- mantics for different frames, each associating with a subset of the core roles. In addition, there are 21 non-core roles that encapsulate further arguments of a frame, such as temporal (AM-TMP) and locative (AM-LOC) adjuncts. The non-core roles are shared between all frames and assume similar meaning. In contrast, a FrameNet frame often associates with multiple lexical units and the frame lexicon <ref type="bibr">1</ref> We borrow the term "lexical unit" from the frame seman- tics literature. The CoNLL 2005 dataset is restricted to verbal lexical units, while the CoNLL 2009 and 2012 datasets con- tains both verbal and nominal lexical units. FrameNet has lexical units of several coarse syntactic categories. contains several hundred core and non-core roles that are shared across frames. For example, the FrameNet frame Theft could be evoked by the verbs steal, pickpocket, or lift, while PropBank has dis- tinct frames for each of them. The Theft frame also contains the core roles Goods and Perpetrator that additionally belong to the Commercial_transaction and Committing_crime frames respectively.</p><p>A typical SRL dataset consists of sentence-level annotations that identify (possibly multiple) target predicates in each sentence, a disambiguated frame for each predicate, and the associated argument spans (or single word argument heads) labeled with their respective semantic roles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Related Work</head><p>SRL using PropBank conventions <ref type="bibr" target="#b22">(Palmer et al., 2005</ref>) has been widely studied. There have been two shared tasks at <ref type="bibr">CoNLL 2004</ref><ref type="bibr">CoNLL -2005</ref> to identify the phrasal arguments of verbal predicates <ref type="bibr" target="#b3">(Carreras and Màrquez, 2004;</ref><ref type="bibr" target="#b4">Carreras and Màrquez, 2005</ref>). The CoNLL 2008-2009 shared tasks in- troduced a variant where semantic dependencies are annotated rather than phrasal arguments <ref type="bibr" target="#b31">(Surdeanu et al., 2008;</ref><ref type="bibr" target="#b13">Hajič et al., 2009</ref>). Similar approaches ( <ref type="bibr" target="#b14">Hermann et al., 2014</ref>) have been applied to frame-semantic parsing us- ing FrameNet conventions ( <ref type="bibr" target="#b0">Baker et al., 1998</ref>). We treat PropBank and FrameNet annotations in a com- mon framework, similar to <ref type="bibr" target="#b14">Hermann et al. (2014)</ref>.</p><p>Most prior work on SRL rely on syntactic parses provided as input and use locally estimated classi- fiers for each span-role pair that are only combined at prediction time. 2 This is done by picking the highest scoring role for each span, subject to a set of structural constraints, such as avoiding overlap- ping arguments and repeated core roles. Typically, these constraints have been enforced by integer lin- ear programming (ILP), as in <ref type="bibr" target="#b26">Punyakanok et al. (2008)</ref>. <ref type="bibr">Täckström et al. (2015)</ref> interpreted this as a graphical model with local factors for each span-role pair, and global factors that encode the structural constraints. They derived a dynamic pro- gram (DP) that enforces most of the constraints proposed by Punyakanok et al. and showed how the DP can be used to take these constraints into account during learning. Here, we use an identical graphical model, but extend the model of Täck- ström et al. by replacing its linear potential func-tions with a multi-layer neural network. A similar use of non-linear potential functions in a structured model was proposed by <ref type="bibr" target="#b9">Do and Artières (2010)</ref> for speech recognition, and by <ref type="bibr" target="#b11">Durrett and Klein (2015)</ref> for syntactic phrase-structure parsing.</p><p>Feature-based approaches to SRL employ hand- engineered linguistically-motivated feature tem- plates to represent the semantic structure. Some recent work has focused on low-dimensional repre- sentations that reduce the need for intensive feature engineering and lead to better generalization in the face of data sparsity. <ref type="bibr" target="#b18">Lei et al. (2015)</ref> employ low-rank tensor factorization to induce a compact representation of the full cross-product of atomic features; akin to this work, they represent seman- tic roles as real-valued vectors, but use a different scoring formulation for modeling potential argu- ments. Moreover, they restrict their experiments to CoNLL 2009 semantic dependencies. <ref type="bibr" target="#b28">Roth and Woodsend (2014)</ref> improve on the state-of-the-art feature-based system of <ref type="bibr" target="#b1">Björkelund et al. (2010)</ref> by adding distributional word representations trained on large unlabeled corpora as features. <ref type="bibr" target="#b6">Collobert and Weston (2007)</ref> use a neural net- work and do not rely on syntactic parses as input. While they use non-standard evaluation, they report accuracy similar to the ASSERT system ( <ref type="bibr" target="#b24">Pradhan et al., 2005</ref>), to which we compare in <ref type="table" target="#tab_5">Table 4</ref>. Very recently, <ref type="bibr" target="#b41">Zhou and Xu (2015)</ref> proposed a deep bidi- rectional LSTM model for SRL that does not rely on syntax trees as input; their approach achieves the best results on CoNLL 2005 and 2012 corpora to date, but unlike this work, they do not report re- sults on FrameNet and CoNLL 2009 dependencies and do not investigate joint learning approaches involving multiple annotation conventions.</p><p>For FrameNet-style SRL, <ref type="bibr" target="#b16">Kshirsagar et al. (2015)</ref> recently proposed the use of PropBank- based features, but their system performance falls short of the state of the art. <ref type="bibr" target="#b27">Roth and Lapata (2015)</ref> proposed another approach exploring linguistically motivated features tuned towards the FrameNet lex- icon, but their performance metrics are significantly worse than our best results.</p><p>The inspiration behind our approach stems from recent work on bilinear models <ref type="bibr" target="#b20">(Mnih and Hinton, 2007)</ref>. There have been several recent studies representing input observations and output labels with distributed representations, for example, in the WSABIE model for image annotation <ref type="bibr" target="#b37">(Weston et al., 2011</ref>), in models for embedding labels in struc- tured graphical models <ref type="bibr" target="#b29">(Srikumar and Manning, 2014)</ref>, and in techniques to learn joint embeddings of predicate words and their semantic frames in a vector space ( <ref type="bibr" target="#b14">Hermann et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>Our model for SRL performs inference separately for each marked predicate in a sentence. It assumes that the predicate has been automatically disam- biguated to a semantic frame drawn from a frame lexicon, and the semantic roles of the frame are used for labeling the candidate arguments in the sentence. Formally, we are given a sentence x in which a predicate t, with lexical unit , has been marked. Assuming that the semantic frame f of the predicate has already been identified (see §4.2 for this step), we seek to predict the set of spans that correspond to its overt semantic arguments and to label each argument with its semantic role. Specif- ically, we model the problem as that of assigning each span s ∈ S, from an over-generated set of can- didate argument spans S, to a semantic role r ∈ R. The set of semantic roles R includes the special null role ∅, which is used to represent non-overt arguments. Thus, our algorithm performs the SRL task in one step for a single predicate frame. For the span-based SRL task, in a sentence of n words, there could be O(n 2 ) potential arguments. For sta- tistical and computational reasons we prune the set of spans S using a set of syntactically-informed heuristics from prior work (see §4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Graphical Model</head><p>We make use of a graphical model that represents global assignment of arguments to their semantic roles, subject to linguistic constraints ( <ref type="bibr" target="#b26">Punyakanok et al., 2008;</ref><ref type="bibr" target="#b32">Täckström et al., 2015)</ref>. Under this graphical model, we assume a parameterized po- tential function that assigns a real-valued com- patibility score g(s, r; θ) to each span-role pair (s, r) ∈ S × R, where θ denotes the model param- eters. Below, we consider two types of potential functions. As a baseline, similar to most prior work, one could use a simple linear function of discrete input features g L (s, r; θ) = θ · φ(r, s, x, t, , f ), where φ(·) denotes a feature function. In this work, we instead propose a multi-layer feed-forward neu- ral network potential function, specified in §3.2. Given these local factors, we employ the dynamic program of Täckström et al. to enforce global con- straints on the inferred output. </p><formula xml:id="formula_1">e s e f e r v s v (f,r) g NN (s, r; ✓)</formula><p>Figure 2: Neural network architecture.</p><p>Let R |S| denote the set of all possible assign- ments of semantic roles to argument spans (s i , r i ) for s i ∈ S that satisfy the constraints. Given a potential function g(s, r) g(s, r; θ), the proba- bility of a joint assignment r ∈ R |S| , subject to the constraints, is given by</p><formula xml:id="formula_2">p(r | x, t, , f ) = exp   s i ∈S g(s i , r i ) − A(S)   ,<label>(1)</label></formula><p>where the log-partition function A(S) sums over all satisfying joint role assignments:</p><formula xml:id="formula_3">A(S) = log r ∈R |S| exp   s i ∈S g(s i , r i )   . (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Neural Network Potentials</head><p>Our approach replaces the standard linear poten- tial function g L (s, r; θ) with the real-valued output of a feed forward neural network with non-linear hidden units. The network structure is outlined in <ref type="figure">Figure 2</ref>. The frame f and role r are initially en- coded using a one-hot encoding as i f and i r . In other words, i f and i r have all zeros except for one position at f and r respectively. These are passed through fully connected linear layers to give e f and e r . We call these linear layers the embedding layers since i f selects the embedding of the frame f and i r for r. Next, e f and e r are passed through a fully connected rectified linear layer <ref type="bibr" target="#b21">(Nair and Hinton, 2010)</ref>, to obtain the final frame-role repre- sentation v (f,r) . For the candidate span, the process is similar. Atomic features φ(s, x, t, ) for the ar- gument span s are extracted first. (These features are the non-conjoined features used in the linear</p><p>• first word of s • tag of the first word of s • last word of s</p><p>• tag of the last word of s • head word of s</p><p>• tag of the head word of s • bag of words in s</p><p>• bag of tags in s • cluster of s's head</p><p>• linear distance of s from t • t's children words</p><p>• word cluster of s's head • dependency path between s's head and t • subcategorization frame of s • position of s w.r.t. t (before, after, overlap or same)</p><p>• predicate use voice (active, passive, or unknown)</p><p>• whether the subject of t is missing (missingsubj) • position of s w.r.t. t (before, after, overlap or same)</p><p>• word, tag, dependency label and cluster of the words immediately to the left and right of s <ref type="table">Table 1</ref>: Span features φ(s, x, t, ) in <ref type="figure">Figure 2</ref>.</p><p>model of Täckström et al.; see <ref type="table">Table 1</ref> for the list). These are next passed through a fully-connected linear embedding layer to get the span embedding e s , which is subsequently passed through a fully connected rectified linear layer to obtain v s , the final span representation. The final output is the dot product of v s and v (f,r) :</p><formula xml:id="formula_4">g NN (s, r; θ) = v s · v (f,r) .<label>(3)</label></formula><p>The weights of all the layers constitute the param- eters θ of the neural network. We initialize θ ran- domly, with the exception of embedding parame- ters corresponding to words, which are initialized from pre-trained word embeddings (see §4.4 for details). We train the network as described in §3.3. 3 Note that unlike typical linear models, the atomic span features are not explicitly conjoined with each other, the frame or the role. Instead the hidden layers learn to emulate span feature conjunctions and frame and role feature conjunctions in paral- lel. <ref type="bibr">4</ref> Moreover, note that span v s and frame-role v (f,r) representations are decoupled in this model. This decoupling is important as it allows us to train a single model in a multitask setting. We demon- strate this by successfully combining PropBank and FrameNet training data, as described in §5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter Estimation</head><p>We consider two methods for parameter estimation.</p><p>Local Estimation In local estimation, we treat each span-role assignment pair (s, r) ∈ S×R as an individual binary decision problem and maximize the corresponding log-likelihood of the training set. 5 Denote by z s,r ∈ {0, 1} the decision vari- able, such that z s,r = 1 iff span s is assigned role</p><note type="other">r. By passing the potential g NN (s, r; θ) through the logistic function, we obtain the log-likelihood l(z s,r ; θ) log p(z s,r | x, t, , f ) of an individual training example. Here, p(z s,r | x, t, , f ) =    1 1+e −g NN (s,r;θ) if z s,r = 1 e −g NN (s,r;θ) 1+e −g NN (s,r;θ) if z s,r = 0</note><p>Thus, the gold role for a given span according to the training data serves as the positive example, while all the other potential roles serve as negatives.</p><p>To maximize the log-likelihood, we use Adagrad ( <ref type="bibr" target="#b10">Duchi et al., 2011</ref>). This requires the gradient of the log-likelihood with respect to the parameters θ, which can be derived using the chain rule.</p><p>Structured Estimation In structured estimation, we instead learn a globally normalized probabilis- tic model that takes the structural constraints into account during training. This method is closely related to the linear approach of <ref type="bibr">Täckström et al. (2015)</ref>, as well as to the fine-tuning of a neural CRF described by <ref type="bibr" target="#b9">Do and Artières (2010)</ref>. We train the model by maximizing the log- likelihood of the training data, again using Adagrad. From Equation (1), we have that the log-likelihood l(r; θ) log p(r | x, t, , f ) of a single (struc- tured) training example (r, S, x) is given by</p><formula xml:id="formula_5">l(r; θ) = s i ∈S g(s i , r i ) − A(S) .<label>(4)</label></formula><p>By application of the chain rule, the gradient of the log-likelihood factorizes as</p><formula xml:id="formula_6">∂l(r; θ) ∂θ = ∂l(r; θ) ∂g NN ∂g NN ∂θ ,<label>(5)</label></formula><p>where we have used the shorthand g NN for brevity. It is easy to show that the first term ∂l(r; θ)/∂g NN factors into the marginals over edges in the DP lattice, which can be computed with the forward- backward algorithm (recall that the potentials are in <ref type="bibr">5</ref> An alternate way to locally train the neural network would be to treat the scores as potentials in a multiclass logistic regression model and optimize log-likelihood, as is done with the locally-trained linear model from <ref type="bibr">Täckström et al. (2015)</ref>, but we did not investigate this alternative in this work. simple correspondence with the edge scores in the DP lattice, see <ref type="bibr">Täckström et al. (2015, §4</ref>) for de- tails). Again, the chain rule can be used to compute the gradient ∂g NN /∂θ with respect to the parame- ters of each layer in the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Product of Experts</head><p>As we will observe in <ref type="table" target="#tab_6">Tables 2 to 5</ref>, random initial- ization of the neural network parameters θ causes variance in the performance over different runs. We found that using a straightforward product-of- experts (PoE) model <ref type="bibr" target="#b15">(Hinton, 2002</ref>) at inference time reduces this variance and results in signifi- cantly higher performance. This PoE model is a very simple ensemble, being the factor-wise sum of the potential functions from K independently trained neural networks:</p><formula xml:id="formula_7">g PoE (s, r; θ) = K j=1 g (j) NN (s, r, θ) .<label>(6)</label></formula><p>where g</p><p>NN (s, r, θ) is the score from model j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>In this section we describe the datasets used, the re- quired preprocessing steps, the baselines compared to and the details of our experimental setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Significance Testing</head><p>We evaluate our approach on four standard datasets. For span-based SRL using PropBank conventions We use the standard evaluation scripts for each task and use a paired bootstrap test <ref type="bibr" target="#b12">(Efron and Tibshirani, 1994)</ref> to assess the statistical significance of the results. For brevity, we only give the p-values for the observed differences between our best and second best models on each of the test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Preprocessing and Frame Identification</head><p>All datasets are preprocessed with a part-of-speech tagger and a syntactic dependency parser, both trained on the CoNLL 2012 training split, after converting the constituency trees to Stanford-style dependencies <ref type="bibr" target="#b8">(De Marneffe and Manning, 2013)</ref>. The tagger is based on a second-order conditional random field ( <ref type="bibr" target="#b17">Lafferty et al., 2001</ref>) with standard emission and transition features; for parsing, we use a graph-based parser with structural diversity and cube-pruning ( <ref type="bibr" target="#b39">Zhang and McDonald, 2014</ref>).</p><p>On the WSJ development set (section 22), the la- beled attachment score of the parser is 90.9% while the part-of-speech tagger achieves an accuracy of 97.2%. On the CoNLL 2012 development set, the corresponding scores are 90.2% and 97.3%. Both the tagger and the parser, as well as the SRL mod- els use word cluster features (see <ref type="table">Table 1</ref>). Specif- ically, we use the clusters with 1000 classes from <ref type="bibr" target="#b34">Turian et al. (2010)</ref>, which are induced with the Brown algorithm ( <ref type="bibr" target="#b2">Brown et al., 1992)</ref>. To gener- ate the candidate arguments S (see §3.2) for the CoNLL 2005 and 2012 span-based datasets, we follow <ref type="bibr">Täckström et al. (2015)</ref> and adapt the algo- rithm of <ref type="bibr" target="#b38">Xue and Palmer (2004)</ref> to use dependency syntax. For the dependency-based CoNLL 2009 experiments, we modify our approach to assume single length spans and treat every word of the sen- tence as a candidate argument. For FrameNet, we follow the heuristic of <ref type="bibr" target="#b14">Hermann et al. (2014)</ref>.</p><p>As mentioned in §3, we automatically disam- biguate the predicate frames. For FrameNet, we use an embedding-based model described by <ref type="bibr" target="#b14">Hermann et al. (2014)</ref>. For PropBank, we use a multi- class log-linear model, since Hermann et al. did not observe better results with the embedding model.</p><p>To ensure a fair comparison with the closest lin- ear model baseline, we ensured that the prepro- cessing steps, the argument candidate generation algorithm for the span-based datasets and the frame identification methods are identical to <ref type="bibr">Täckström et al. (2015, §3.2, §6</ref>.2- §6.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baseline Systems</head><p>In addition to comparing to <ref type="bibr">Täckström et al. (2015)</ref>, whose setup is closest to ours, we also compare to prior state-of-the-art systems from the literature.</p><p>For CoNLL 2005, we compare to the best non- ensemble and ensemble systems of <ref type="bibr" target="#b30">Surdeanu et al. (2007)</ref>, <ref type="bibr" target="#b26">Punyakanok et al. (2008)</ref> and <ref type="bibr" target="#b33">Toutanova et al. (2008)</ref>. The ensemble variants of these systems use multiple parses and multiple SRL systems to leverage diversity. In contrast to these ensemble systems, our product-of-experts model uses only a single architecture and one syntactic parse; the con- stituent models differ only in random initialization. We also compare with the recent deep bidirectional LSTM model of <ref type="bibr" target="#b41">Zhou and Xu (2015)</ref>.</p><p>For CoNLL 2012, we compare to <ref type="bibr" target="#b25">Pradhan et al. (2013)</ref>, who report results with the (non-ensemble) ASSERT system ( <ref type="bibr" target="#b24">Pradhan et al., 2005)</ref>, and to the model of <ref type="bibr" target="#b41">Zhou and Xu (2015)</ref>.</p><p>For CoNLL 2009, we compare to the top system from the shared task ( <ref type="bibr" target="#b40">Zhao et al., 2009</ref>), two state-of-the-art systems that employ a reranker ( <ref type="bibr" target="#b1">Björkelund et al., 2010;</ref><ref type="bibr" target="#b28">Roth and Woodsend, 2014)</ref>, and the recent tensor-based model of <ref type="bibr" target="#b18">Lei et al. (2015)</ref>. We also trained the linear model of Täckström et al. on this dataset (their work omitted this experiment), as a baseline.</p><p>Finally, for the FrameNet experiments, we com- pare to the state-of-the-art system of <ref type="bibr" target="#b14">Hermann et al. (2014)</ref>, which combines a frame-identification model based on WSABIE <ref type="bibr" target="#b37">(Weston et al., 2011</ref>) with a log-linear role labeling model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Hyperparameters and Initialization</head><p>There are several hyperparameters in our model ( §3.2). First, the span embedding dimension of e s was fixed to 300 to match the dimension of the pre- trained GloVe word embeddings from <ref type="bibr" target="#b23">Pennington et al. (2014)</ref> that we use to initialize the embed- dings of the word-based features in φ(s, x, t, ). Preliminary experiments showed random initial- ization of the word-based embeddings to be in- ferior to pre-trained embeddings. The remain- ing model parameters were randomly initialized. The frame embedding dimension was chosen from {100, 200, 300, 500}, while the hidden layer di- mension was chosen from {300, 500}. For Prop- Bank, we fixed the role embedding dimension to 27, which is the number of semantic roles in PropBank datasets (ignoring the AA role, that ap- pears with negligible frequency). For FrameNet, the role embedding dimension was chosen from {100, 200, 300, 500}. In the Adagrad algorithm, the mini-batch size was fixed to 100 for local esti- mation ( §3.3). For structured estimation ( §3.3), a batch size of one was used, since each structured in- stance contains multiple local factors. The learning rate was chosen from {0.1, 0.2, 0.5, 1.0} for local learning and from {0.01, 0.02, 0.05, 0.1} for struc-</p><formula xml:id="formula_9">965 WSJ Dev WSJ Test Brown Test Method P R F1 Comp. P R F1 Comp. P R F1 Comp.</formula><p>Surdeanu <ref type="table" target="#tab_3">(Single)  - - - - 79.7  74.9  77.2  52.0  - - - - Surdeanu (Ensemble)  - - - - 87.5</ref>    <ref type="table">Table 2</ref>: PropBank-style SRL results on CoNLL 2005 data. Bold font indicates the best system using a single or no syntactic parse, while the best scores among all systems are underlined. Results from prior work are taken from the respective papers, and '-' indicates performance metrics missing in the original publication. Statistical significance was assessed for F1 and Comp. on the WSJ and Brown test sets with p &lt; 0.01 ( * ) and p &lt; 0.05 ( * *  <ref type="table" target="#tab_4">Table 3</ref>: PropBank-style semantic dependency SRL results (labeled F1) on the CoNLL 2009 data set. Bold font indicates the best system. Statistical significance was assessed with p &lt; 0.01 ( * ). tured learning. 6 All hyperparameters were tuned on the respective development sets for each dataset with a straightforward grid-search procedure. In the product-of-experts setup, we train K = 10 models, each with a different random seed, and combine them at inference time (see Equation <ref type="formula" target="#formula_7">(6)</ref>). <ref type="table">Table 2</ref> shows results on the CoNLL 2005 devel- opment set and the WSJ and Brown test sets. Our individual neural network models are on par with the best linear single-system baselines that use care- fully chosen feature combinations, but has variance across reruns. On the WSJ test set, the product- <ref type="bibr">6</ref> We observed a strong interaction between learning rate and mini-batch size. Since the number of factors per frame structure is much larger than 100, lower learning rates are better suited for structured estimation. of-experts model featuring neural networks trained with structured learning achieves higher F 1 -score than all non-ensemble baselines, except the LSTM model of Zhou and Xu. It is on par and at times better than ensemble baselines that use diverse syn- tactic parses. The PoE model outperforms all base- lines on the Brown test set, exhibiting its gener- alization power on out-of-domain text. Overall, using structured learning improves recall at a slight expense of precision when compared to local learn- ing, leading to an increase in the complete argu- ment structure accuracy (Comp. in the tables).   <ref type="table" target="#tab_5">Table 4</ref> shows the results on the span-based CoNLL 2012 data. The trends observed on the CoNLL 2005 data hold here as well, with struc- tured training yielding an increase in precision at the cost of a small drop in recall. This leads to im- provements in both F 1 score and complete structure accuracy. The product-of-experts model trained with structured learning here yields results better than the ASSERT system ( <ref type="bibr" target="#b25">Pradhan et al., 2013)</ref>, but akin to CoNLL 2005, our system falls short in comparison to Zhou and Xu's F 1 -score. In contrast to the smaller CoNLL 2005 data, even our sin- gle (non-PoE) model outperforms the linear model of <ref type="bibr">Täckström et al. (2015)</ref> on the CoNLL 2012 data. We hypothesize that the relative abundance of the latter counteracts the risk for overfitting of the larger number of parameters in our model. Finally,  <ref type="table" target="#tab_6">Table 5</ref>: Joint frame and argument identification results for FrameNet. Statistical significance was assessed for F1 and Comp. on the test set with p &lt; 0.01 ( * ) and p &lt; 0.05 ( * * ).</p><note type="other">80.1 74.8 77.4 50.7 82.3 76.8 79.4 53.8 73.4 62.9 67.8 32.3 Täckström (Local) 81.3 74.8 77.9 52.4 82.6 76.4 79.3 54.3 74.0 66.8 70.2 38.4 Täckström (Struct.) 81.2 76.2 78.6 54.4 82.3 77.6 79.9 56.0 74.3 68.6 71.3 39.8 Zhou 79.7 79.4 79.6 - 82.9 82.8 82.8 - 70.7 68.2 69.4</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Empirical Results</head><p>drop in performance. Our locally-trained neural network model performs comparably to the linear model of <ref type="bibr">Täckström et al. (2015)</ref>. However we achieve significant improvements in both F 1 -score and full structure accuracy by training our model with a dataset composed of both FrameNet and CoNLL 2005 data. <ref type="bibr">7</ref> The ability to train in this mul- titask setting is a unique capability of our approach, and yields state-of-the-art results for FrameNet. <ref type="figure" target="#fig_2">Figure 4</ref> shows the effect of adding increasing amount of CoNLL 2005 data to supplement the FrameNet training corpus in this multitask setting. The Y -axis plots F 1 -score on the development data averaged across runs for the local non-PoE model. With increasing amount of PropBank data, perfor- mance increases in small steps, and peaks when all the data is added. This shows that with more PropBank data we could further improve perfor- mance on the FrameNet task; we leave further ex- ploration of multitask learning of predicate argu- ment structures, including multilingual settings, to future work. </p><note type="other">Figure 3:</note><p>Two- dimensional t-SNE projections <ref type="bibr" target="#b35">(Van der Maaten and Hinton, 2008)</ref> of joint Prop- Bank and FrameNet (boxed) embeddings of frames (a) and frame-role pairs (b).  <ref type="figure">Figure 3</ref> shows example embeddings from the model trained jointly on FrameNet and PropBank annotations. <ref type="figure">Figure 3a</ref> shows the proximity of the learned embeddings e f of frames from both FrameNet and PropBank. <ref type="figure">Figure 3b</ref> shows the em- beddings for frame-role pairs v (f,r) (the output of the hidden rectified linear layer). Here, we fix the FrameNet frame Travel and the similar PropBank frames commute.01, tour.01 and travel.01 are visual- ized along with their semantic roles. We observe that the model learns very similar embeddings for the semantically related roles across both datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Qualitative Analysis of Embeddings</head><p>Note that there is a clear separation of the agentive roles from the others for both conventions and how the FrameNet and PropBank counterparts of each type of role are proximate in vector space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented a neural network model for seman- tic role labeling that learns to embed both inputs and outputs in the same vector space. We consid- ered both local and structured training methods for the network parameters from supervised SRL data. Empirically, our approach achieves state-of-the-art results on two standard datasets with a product of experts model, while approaching the performance of a recent deep recurrent neural network model on two other datasets. By training the model jointly on both FrameNet and PropBank data, we achieve the best result to date on the FrameNet test set. Fi- nally, qualitative analysis indicates that the model represents semantically similar annotations with proximate vector-space embeddings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: F 1 score on the FrameNet development data averaged over runs versus the percentage of CoNLL 2005 data used to append the FrameNet training corpus. For this plot, we used the locally trained non-PoE model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>-</head><label></label><figDesc></figDesc><table>This work (Local) 
81.4 75.6 78.4 53.7 82.3±0.4 76.8±0.5 79.4±0.1 55.1±0.6 74.1±0.6 68.0±0.7 70.9±0.3 39.1±0.8 
This work (Struct.) 
80.7 76.1 78.3 54.1 81.8±0.5 77.3±0.3 79.4±0.2 55.6±0.5 73.8±0.7 68.8±0.6 71.2±0.3 40.5±0.8 
This work (Local, PoE) 82.0 76.6 79.2 55.2 82.9 
77.8 
80.3  *  
56.7 
75.2 
69.1 
72.0 
40.8 
This work (Struct., PoE) 81.2 76.7 78.9 55.1 82.5 
78.2 
80.3  *  
57.3  *  
74.5 
70.0 
72.2  *  *  
41.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>Excluding predicate senses 
Including predicate senses 

WSJ Dev 
WSJ Test 
Brown Test 
WSJ Test 
Brown Test 

CoNLL-2009 1st place 
-
82.1 
69.8 
86.2 
74.6 
Björkelund et al., 2010 + reranking 
80.5 
82.9 
70.9 
86.9 
75.7 
Roth and Woodsend, 2014 + reranking 
-
82.1 
71.1 
86.3 
75.9 
Lei et al. 2015 
81.0 
82.5 
70.8 
86.6 
75.6 
Täckström et al. 2015 (Local) 
81.4 
83.0 
71.2 
86.9 
74.8 
Täckström et al. 2015 (Struct.) 
82.4 
83.7 
72.3 
87.3 
75.5 

This work (Local) 
81.2±0.2 
82.7±0.3 
71.9 ±0.4 
86.7±0.2 
75.2 ±0.3 
This work (Struct) 
82.3±0.1 
83.6±0.1 
71.9 ±0.3 
87.3±0.1 
75.2 ±0.2 
This work (Local, PoE) 
82.4 
83.8 
72.8 
87.5 
75.9 
This work (Struct., PoE) 
83.0  *  
84.3  *  
72.4 
87.8  *  
75.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 shows</head><label>3</label><figDesc>results on the CoNLL 2009 task. Following Lei et al. (2015), we present results us- ing the official evaluation script, along with addi- tional metrics that do not count frame predictions. Note that the linear baseline of Täckström et al.</figDesc><table>966 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>PropBank-style SRL results on the 
CoNLL 2012 development and test sets. Results 
from prior work are taken from the respective pa-
pers, and '-' indicates performance metrics miss-
ing in the original publication. Significance was 
assessed for F1 and Comp. on the test set with 
p &lt; 0.01 ( * ). 

outperforms most prior work, including ones that 
employs rerankers, except on the Brown test set. 
Our neural network model performs even better, 
achieving state-of-the-art results on all metrics. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 5 shows</head><label>5</label><figDesc>the results on FrameNet data, which is very small in size. Here, structured learning does not help and in fact leads to a small</figDesc><table>FrameNet Development 

Method 
P 
R 
F1 
Comp. 

Hermann 
78.3 
64.5 
70.8 
-
Täckström (Local) 
80.7 
62.9 
70.7 
31.2 
Täckström (Struct.) 
79.6 
64.1 
71.0 
33.3 

This work (Local) 
78.6 
64.6 
70.9 
32.0 
This work (Struct.) 
79.6 
63.9 
70.9 
31.8 
This work (Local, PoE) 
79.0 
65.0 
71.3 
33.1 
This work (Struct., PoE) 
79.0 
64.4 
71.0 
32.3 
This work (Local, PoE, Joint) 79.4 
65.8 
72.0 
34.5 
This work (Struct., PoE, Joint) 78.8 
65.4 
71.5 
33.5 

FrameNet Test 

Method 
P 
R 
F1 
Comp. 

Hermann 
74.3 
66.0 
69.9 
-
Täckström (Local) 
76.1 
64.9 
70.1 
33.0 
Täckström (Struct.) 
75.4 
65.8 
70.3 
33.8 

This work (Local) 
73.9±0.6 66.4±0.4 69.9±0.3 33.4±0.6 
This work (Struct.) 
74.8±0.2 65.5±0.2 69.9±0.1 33.0±0.3 
This work (Local, PoE) 
74.3 
66.9 
70.4 
33.9 
This work (Struct., PoE) 
74.6 
66.3 
70.2 
33.3 
This work (Local, PoE, Joint) 75.0 
67.3 
70.9  *  *  35.4  *  
This work (Struct., PoE, Joint) 74.2 
67.2 
70.5 
34.2 

</table></figure>

			<note place="foot" n="2"> Some recent work have successfully proposed joint models for syntactic parsing and SRL instead of a pipeline approach (Lewis et al., 2015).</note>

			<note place="foot" n="3"> Various other network structures are worth investigating, such as concatenating the span, frame and role representations and passing them through fully connected layers. This treatment, for example, has been used by Chen and Manning (2014) for syntactic parsing. We leave these explorations to future work. 4 We found that adding feature conjunctions to the network&apos;s input layer did not improve performance in practice.</note>

			<note place="foot" n="7"> The joint model does not improve results for PropBank. This is likely due to the much larger CoNLL 2005 training set, compared to the FrameNet data (39,832 training sentences in the former as opposed to 3,256 sentences in the latter).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Tom Kwiatkowski, Slav Petrov and Fer-nando Pereira for comments on early drafts. We are also thankful to Mike Lewis, Mark Yatskar and Luke Zettlemoyer for valuable feedback. Finally, we thank the three anonymous reviewers for sug-gestions that enriched the final version of the paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Berkeley FrameNet project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Collin</forename><forename type="middle">F</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">B</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A high-performance syntactic and semantic dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Love</forename><surname>Hafdell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCL: Demonstrations</title>
		<meeting>ICCL: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Classbased n-gram models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenifer C</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="479" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2004 shared task: Semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2005 shared task: Semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A fast and accurate dependency parser using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast semantic extraction using a novel neural network architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Frame-semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><forename type="middle">F T</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="56" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Stanford typed dependencies manual</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trinh-Minh-Tri</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Artières</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AISTATS</title>
		<meeting>AISTATS</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural CRF parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">An introduction to the bootstrap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Antònia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Štěpánek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semantic frame identification with distributed word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Frame-semantic role labeling with heterogeneous annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meghana</forename><surname>Kshirsagar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">High-order lowrank tensors for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Márquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Alessandro Moschitti, and Regina Barzilay</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Joint A* CCG parsing and semantic role labelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Three new graphical models for statistical language modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted Boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Proposition Bank: An annotated corpus of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="106" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Support vector learning for semantic argument classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kadri</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerie</forename><surname>Hacioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><surname>Krugler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="11" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards robust linguistic analysis using OntoNotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The importance of syntactic parsing and inference in semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasin</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="287" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient inference and structured learning for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="449" to="460" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Composition of word representations improves semantic role labelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Woodsend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning distributed representations for structured output prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Combination strategies for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="105" to="151" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Xavier Carreras, and Pere Comas</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Efficient inference and structured learning for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="29" to="41" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A global joint model for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="191" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Word representations: a simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">85</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">OntoNotes: A large training corpus for enhanced processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Belvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Natural Language Processing and Machine Translation</title>
		<editor>J. Olive, C. Christianson, and J. McCary</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">WSABIE: Scaling up to large vocabulary image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Calibrating features for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Enforcing structural diversity in cube-pruned dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multilingual dependency learning: A huge feature engineering method to semantic dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">End-to-end learning of semantic role labeling using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
