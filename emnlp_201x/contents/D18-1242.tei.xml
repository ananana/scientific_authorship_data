<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Knowledge Base Question Answering via Encoding of Complex Query Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kangqi</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengli</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xusheng</forename><surname>Luo</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenny</forename><forename type="middle">Q</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Knowledge Base Question Answering via Encoding of Complex Query Graphs</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2185" to="2194"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2185</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Answering complex questions that involve multiple entities and multiple relations using a standard knowledge base is an open and challenging task. Most existing KBQA approaches focus on simpler questions and do not work very well on complex questions because they were not able to simultaneously represent the question and the corresponding complex query structure. In this work, we encode such complex query structure into a uniform vector representation, and thus successfully capture the interactions between individual semantic components within a complex question. This approach consistently outper-forms existing methods on complex questions while staying competitive on simple questions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The knowledge-based question answering (KBQA) is a task which takes a natural lan- guage question as input and returns a factual answer using structured knowledge bases such as Freebase ( <ref type="bibr" target="#b6">Bollacker et al., 2008)</ref>, <ref type="bibr">YAGO (Suchanek et al., 2007)</ref> and DBpe- dia ( <ref type="bibr" target="#b1">Auer et al., 2007)</ref>. One simple example is a question like this: "What's the capital of the United States?" A common answer to such ques- tion is to identify the focus entity and the main relation predicate (or a sequence) in the question, and map the question to a triple fact query (U S, capital, ?) over KB. The object answers are returned by executing the query. The mapping above is typically learned from question-answer pairs through distant supervision.</p><p>While the above question can be answered by querying a single predicate or predicate sequence in the KB, many other more complex questions cannot, e.g. the question in <ref type="figure">Figure 1</ref>. To answer the question "What is the second longest river in United States", we need to infer several semantic clues: 1) the answer is contained by United States; 2) the answer is a river; 3) the answer ranks second by its length in descending order. Thus, multiple predicates are required to constrain the answer set, and we call such questions "complex questions" throughout this paper.</p><p>For answering complex questions, it's more im- portant to understand the compositional semantic meanings of the question. As a classic branch of KBQA solutions, semantic parsing (SP) technique <ref type="bibr" target="#b4">(Berant et al., 2013;</ref><ref type="bibr" target="#b26">Yih et al., 2015;</ref><ref type="bibr" target="#b13">Hu et al., 2018</ref>) aims at learning semantic parse trees or equivalent query graphs 1 for repre- senting semantic structures of the questions. For example in <ref type="figure">Figure 1</ref>, the query graph forms a tree shape. The answer node A, serving as the root of the tree, is the variable vertex that represents the real answer entities. The focus nodes (US, river, 2nd) are extracted from the mentions of the ques- tion, and they constrain the answer node via predi- cate sequences in the knowledge base. Recently, neural network (NN) models have shown great promise in improving the performance of KBQA systems, and SP+NN techniques become the state- of-the-art on several KBQA datasets ( <ref type="bibr" target="#b17">Qu et al., 2018;</ref><ref type="bibr" target="#b2">Bao et al., 2016)</ref>. According to the discus- sion above, our work extends the current research in the SP+NN direction.</p><p>The common step of SP-based approaches is to first collect candidate query graphs us- ing bottom up parsing <ref type="bibr" target="#b4">(Berant et al., 2013;</ref><ref type="bibr" target="#b9">Cai and Yates, 2013)</ref> or staged query generation methods ( <ref type="bibr" target="#b26">Yih et al., 2015;</ref><ref type="bibr" target="#b2">Bao et al., 2016)</ref>, then predict the best graph mainly based on the se- mantic similarity with the given question. Ex- isting NN-based methods follow an encode-and- compare framework for answering simple ques- tions, where both the question and the predicate sequence are encoded as semantic vectors in a common embedding space, and the semantic sim- ilarity is calculated by the cosine score between vectors. In order to define the similarity func- tion between one question and a complex query graph, an intuitive solution is to split the query graph into multiple semantic components, as the predicate sequences separated by dashed boxes in <ref type="figure">Figure 1</ref>. Then previous methods can be applied for modeling the similarity between the question and each part of the graph. However, such ap- proach faces two limitations. First, each seman- tic component is not directly comparable with the whole question, since it conveys only partial in- formation of the question. Second, and more im- portantly, the model encodes different components separately, without learning the representation of the whole graph, hence it's not able to capture the compositional semantics in a global perspective. In order to attack the above limitations, we pro- pose a neural network based approach to improve the performance of semantic similarity measure- ment in complex question answering. Given can- didate query graphs generated from one question, our model embeds the question surface and pred- icate sequences into a uniform vector space. The main difference between our approach and previ- ous methods is that we integrate hidden vectors of various semantic components and encode their interaction as the hidden semantics of the entire query graph. In addition, to cope with different semantic components of a query graph, we lever- age dependency parsing information as a comple- mentary of sentential information for question en- coding, which makes the model better align each component to the question. The contribution of this paper is summarized below.</p><p>• We propose a light-weighted and effective neural network model to solve complex KBQA task. To the best of our knowledge, this is the first attempt to explicitly encode the complete semantics of a complex query graph (Section 2.2);</p><p>• We leverage dependency parsing to enrich question representation in the NN model, and conduct thorough investigations to verify its effectiveness (Section 2.2.2);</p><p>• We propose an ensemble method to enrich entity linking from a state-of-the-art linking tool, which further improves the performance of the overall task (Section 2.3);</p><p>• We perform comprehensive experiments on multiple QA datasets, and our proposed method consistently outperforms previous approaches on complex questions, and pro- duces competitive results on datasets made up of simple questions (Section 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>In this section, we present our approach for solv- ing complex KBQA. First, we generate candidate query graphs by staged generation method (Sec- tion 2.1). Second, we measure the semantic simi- larities between the question and each query graph using deep neural networks (Section 2.2). Then we introduce an ensemble approach for entity link- ing enrichment (Section 2.3), Finally, we discuss the prediction and parameter learning step of this task (Section 2.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Query Graph Generation</head><p>We illustrate our staged candidate generation method in this section. Compared to previous methods, such as <ref type="bibr" target="#b2">Bao et al. (2016)</ref>, we employ a more effective candidate generation strategy, which takes advantage of implicit type informa- tion in query graphs and time interval information in the KB. In our work, we take 4 kinds of seman- tic constraints into account: entity, type, time and ordinal constraints. <ref type="figure" target="#fig_2">Figure 2</ref> shows a concrete ex- ample of our candidate generation. For simplicity of discussion, we assume Freebase as the KB in this section.</p><p>Step 1: Focus linking. We extract possible (mention, focus node) pairs from the question. Fo- cus nodes are the starting points of various se- mantic constraints, refer to <ref type="figure" target="#fig_2">Figure 2</ref>(a). For en- tity linking, we generate (mention, entity) pairs using the state-of-the-art entity linking tool S- MART ( <ref type="bibr" target="#b23">Yang and Chang, 2015)</ref>. For type linking, we brutally combine each type with all uni-, bi-   and tri-gram mentions in the question, and pick top-10 (mention, type) pairs with the highest word embedding similarities of each pair. For time link- ing, we extract time mentions by simply matching year regex. For ordinal linking, we leverage a pre- defined superlative word list 2 and recognize men- tions by matching superlative words, or the "or- dinal number + superlative" pattern. The ordinal node is an integer representing the ordinal number in the mention.</p><p>Step 2: Main path generation. We build dif- ferent main paths by connecting the answer node to different focus entities using 1-hop or 2-hop- with-mediator 3 predicate sequence. <ref type="figure" target="#fig_2">Figure 2</ref>(b) shows one of the main paths. Further constraints are attached by connecting an anchor node x to an unused focus node through predicate sequences, where the anchor node x is a non-focus node in the main path (A or v 1 in the example).</p><p>Step 3: Attaching entity constraints. We ap- ply a depth-first search to search for combinations of multiple entity constraints to the main path through 1-hop predicate. <ref type="figure" target="#fig_2">Figure 2</ref>(c) shows a valid entity constraint, (v 1 , basic title, president). The advantage of depth-first search is that we can involve unlimited number of entities in a query graph, which has a better coverage than template-based methods.</p><p>Step 4: Type constraint generation. Type constraints can only be applied at the answer node using IsA predicate. Our improvement in this step is to filter type constraints using implicit types of the answer, derived from the outgoing predi- cates of the answer node. For example in Fig- ure 2(c), the domain type of the predicate gov- ernment position is politician, which becomes the implicit type of the answer. Thus we can filter type constraints which are irrelevant to the im- plicit types, preventing semantic drift and speed- ing up the generation process. To judge whether two types in Freebase are relevant or not, we adopt the method in <ref type="bibr" target="#b15">Luo et al. (2015)</ref> to build a rich type hierarchy of Freebase. Focus types are discarded, if they are not the super-or sub-types of any im- plicit types of the answer.</p><p>Step 5: Time and ordinal constraint gener- ation. As shown in <ref type="figure" target="#fig_2">Figure 2</ref>(d), the time con- straint is represented as a 2-hop predicate se- quence, where the second is a virtual predicate determined by the preposition before the focus time, indicating the time comparing operation, like "before", "after" and "in". Similarly, the ordinal constraint also forms a 2-hop predicate sequence, where the second predicate represents descending (MaxAtN) or ascending order (MinAtN).</p><p>For the detail of time constraint, while exist- ing approaches <ref type="bibr" target="#b26">(Yih et al., 2015;</ref><ref type="bibr" target="#b2">Bao et al., 2016)</ref> link the focus time with only single time predi- cate, our improvement is to leverage paired time predicates for representing a more accurate time constraint. In Freebase, paired time predicates are used to represent facts within certain time inter- vals, like f rom and to 4 in <ref type="figure" target="#fig_2">Figure 2</ref>(d). For time comparing operation "in", we link the time focus to the starting time predicate, but use both predi-cates in SPARQL query, restricting that the focus time lies in the time interval of the paired predi- cates.</p><p>After finishing all these querying stages, we translate candidate graphs into SPARQL query, and produce their final output answers. Finally, we discard query graphs with zero outputs, or us- ing overlapped mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">NN-based Semantic Matching Model</head><p>The architecture of the proposed model is shown in <ref type="figure">Figure 3</ref>. We first replace all entity (or time) mentions used in the query graph by dummy to- kens E (or T m). To encode the complex query structure, we split it into predicate sequences start- ing from answer to focus nodes, which we call semantic components. The predicate sequence doesn't include the information of focus nodes, except for type constraints, where we append the focus type to the IsA predicate, resulting in the predicate sequence like {IsA, river}. We intro- duce in detail the encoding methods for questions and predicate sequences, and how to calculate the semantic similarity score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Semantic Component Representation</head><p>To encode a semantic component p, we take the se- quence of both predicate ids and predicate names into consideration. As the example shown in <ref type="figure">Fig- ure 3</ref>, the id sequence of the first semantic com- ponent is {contained by}, and the predicate word sequence is the concatenation of canonical names for each predicate, that is {"contained", "by"}.</p><p>Given the word sequence {p</p><formula xml:id="formula_0">(w) 1 , . . . , p<label>(w)</label></formula><p>n }, we first use a word embedding matrix E w ∈ R |Vw|×d to convert the original sequence into word em- beddings {p</p><formula xml:id="formula_1">(w) 1 , . . . , p (w)</formula><p>n }, where |V w | denotes the vocabulary size of natural language words, and d denotes the embedding dimension. Then we rep- resent the word sequence using word averaging:</p><formula xml:id="formula_2">p (w) = 1 n i p (w)</formula><p>i . For the id sequence {p</p><formula xml:id="formula_3">(id) 1 , . . . , p (id)</formula><p>m }, we sim- ply take it as a whole unit, and directly translate it into vector representation using the embedding matrix E p ∈ R |Vp×d| at path level, where |V p | is the vocabulary size of predicate sequences. There are two reasons for using such path embedding: 1) the length of id sequence is not larger than two, based on our generation method; 2) the number of distinct predicate sequences is roughly the same as the number of distinct predicates. We get the fi- nal vector of the semantic component by element- wise addition: p = p (w) + p (id) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Question Representation</head><p>We encode the question in both global and lo- cal level, which captures the semantic information with respect to each component p.</p><p>The global information takes the token se- quence as the input. We use the same word embed- ding matrix E w to convert the token sequence into vectors {q</p><formula xml:id="formula_4">(w) 1 , . . . , q (w)</formula><p>n }. Then we encode the to- ken sequence by applying bidirectional GRU net- work ( <ref type="bibr" target="#b10">Cho et al., 2014</ref>). The representation of the token sequence is the concatenation of the last for- ward and backward hidden states through the Bi- GRU layer,</p><formula xml:id="formula_5">q (tok) = [ ← − h (w) 1 ; − → h (w) n ].</formula><p>To encode the question at local level, we lever- age dependency parsing to represent long-range dependencies between the answer and the focus node in p. Since the answer is denoted by the wh- word in the question, we extract the dependency path from the answer node to the focus mention in the question. Similar with <ref type="bibr" target="#b22">Xu et al. (2016)</ref>, we treat the path as the concatenation of words and dependency labels with directions. For example, the dependency path between "what" and "United States" is {what, −−−→ nsubj, is, − − → prep, in, − − → pobj, E}. We apply another bidirectional GRU layer to pro- duce the vector representation at dependency level q (dep) p , capturing both syntactic features and local semantic features. Finally we combine global and local representation by element-wise addition, re- turning the representation of the question with re- spect to the semantic component,</p><formula xml:id="formula_6">q p = q (tok) + q (dep) p .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Semantic Similarity Calculation</head><p>Given the query graph with multiple semantic components, G = {p (1) , . . . , p (N ) }, now all its semantic components have been projected into a common vector space, representing hidden fea- tures in different aspects. We apply max pooling over the hidden vectors of semantic components, and get the compositional semantic representation of the entire query graph. Similarly, we perform max pooling for the question vectors with respect to each semantic component. Finally, we compute the semantic similarity score between the graph and question: Based on this framework, our proposed method ensures the vector spaces of the question and the entire query graph are comparable, and captures complementary semantic features from different parts of the query graph. It's worth mention- ing that the semantic matching model is agnostic to the candidate generation method of the query graphs, hence it can be applied to the other exist- ing semantic parsing frameworks.</p><formula xml:id="formula_7">S sem (q, G) = cos(max i p (i) , max i q (i) p ).<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Entity Linking Enrichment</head><p>The S-MART linker is a black box for our system, which is not extendable and tend to produce high precision but low recall linking results. To seek a better balance at entity linking, we propose an en- semble approach to enrich linking results. We first build a large lexicon by collecting all (mention, en- tity) pairs from article titles, anchor texts, redirects and disambiguation pages of Wikipedia. Each pair is associated with statistical features, such as link- ing probability, letter-tri-gram jaccard similarity and popularity of the entity in Wikipedia. For the pairs found in S-MART results, we take the above features as the input to a 2-layer linear regression model fitting their linking scores. Thus we learn a pseudo linking score for every pair in the lexi- con, and for each question, we pick top-K highest pairs to enrich S-MART linking results, where K is a hyperparameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training and Prediction</head><p>To predict the best query graph from candidates, we calculate the overall association score S(q, G) between the question q and each candidate G, which is the weighted sum of features over entity linking, semantic matching and structural level. <ref type="table" target="#tab_1">Table 1</ref> lists the detail features.</p><p>During training step, we adopt hinge loss to maximize the margin between positive graphs G + and negative graphs G − :</p><formula xml:id="formula_8">loss = max{0, λ − S(q, G + ) + S(q, G − )}. (2)</formula><p>For each question, we pick a candidate graph as positive data, if the F 1 score of its answer is larger than a threshold (set to 0.1 in our work). We ran- domly sample 20 negative graphs G − from the candidate set whose F 1 is lower than the corre- sponding G + .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category Description</head><p>Entity Sum of S-MART scores of all entities; Number of entities from S-MART; Number of entities from enriched lexicon; Semantics Semantic similarity score Ssem(q, G); Structural Number of each kind of constraints in G;</p><p>Whether a kind of constraints is used in G;</p><p>Whether the main path is one-hop; Number of output answers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section, we introduce the QA datasets and state-of-the-art systems that we compare. We show the end-to-end results of the KBQA task, and perform detail analysis to investigate the impor- tance of different modules used in our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>QA datasets: We conduct our experiments on ComplexQuestions ( <ref type="bibr" target="#b2">Bao et al., 2016</ref>), We-bQuestions ( <ref type="bibr" target="#b4">Berant et al., 2013)</ref> and SimpleQues- tions ( <ref type="bibr" target="#b7">Bordes et al., 2015</ref>). We use CompQ, WebQ and SimpQ as abbreviations of the above datasets, respectively. CompQ contains 2,100 complex questions collected from Bing search query log, and the dataset is split into 1,300 training and 800 testing questions. WebQ contains 5,810 questions collected from Google Suggest API, and is split into 3,778 training and 2,032 testing QA pairs. Each question is manually labeled with at least one answer entity in both datasets. SimpQ consists of more than 100K questions, and the gold answer of each question is a gold focus entity paired with a single predicate. This dataset is designed mainly for answering simple questions, and we use it for complementary evaluation.</p><p>Knowledge bases: For experiments on both CompQ and WebQ, we follow the settings of Be- rant et al. <ref type="formula" target="#formula_7">(2013)</ref> and <ref type="bibr" target="#b22">Xu et al. (2016)</ref> to use the full Freebase dump 5 as the knowledge base, which contains 46M entities and 5,323 predicates. We host the knowledge base with Virtuoso engine <ref type="bibr">6</ref> . For the experiments on SimpQ, the knowledge base we use is FB2M, which is a subset of Free- base provided with the dataset, consisting 2M en- tities and 10M triple facts.</p><p>Implementation detail: For all experiments in this section, we initialize word embeddings us- ing GloVe ( <ref type="bibr" target="#b16">Pennington et al., 2014</ref>) word vectors with dimensions set to 300, and the size of Bi- GRU hidden layer is also set to 300. We tune the margin λ in {0.1, 0.2, 0.5}, the ensemble thresh- old K in {1, 2, 3, 5, 10, +INF}, and the batch size B in {16, 32, 64}. All the source codes, QA datasets, and detail results can be downloaded from http://202.120.38.146/CompQA/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">End-to-End Results</head><p>Now we perform KBQA experiments on WebQ and CompQ. We use the average F 1 score over all questions as our evaluation metric. The offi- cial evaluation script 7 measures the correctness of output entities at string level. While in CompQ, the annotated names of gold answer entities don't match the case of their names in Freebase, thus we follow <ref type="bibr" target="#b2">Bao et al. (2016)</ref> to lowercase both anno- tated names and the output answer names before calculating the F 1 score. We set λ = 0.5, B = 32, K = 3 for WebQ and K = 5 for CompQ, as reaching the highest average F 1 on the validation set of each dataset.</p><p>We report the experimental results in <ref type="table" target="#tab_3">Table 2</ref>. The result of <ref type="bibr" target="#b26">Yih et al. (2015)</ref> on CompQ is re- ported by <ref type="bibr" target="#b2">Bao et al. (2016)</ref> as their implemented result. Our approach outperforms existing ap- proaches on CompQ dataset, and ranks 2nd on WebQ among a long list of state-of-the-art works. Jain (2016) achieves highest F 1 score on WebQ using memory networks, which is not semantic parsing based, and thus less interpretable. We point out that <ref type="bibr" target="#b22">Xu et al. (2016)</ref> uses Wikipedia texts as the external community knowledge for veri- fying candidate answers, and achieves a slightly higher F 1 score (53.3) than our model, but the performance decreases to 47.0 if this step is re- moved. Besides, <ref type="bibr" target="#b26">Yih et al. (2015)</ref> and <ref type="bibr" target="#b2">Bao et al. (2016)</ref> used ClueWeb dataset for learning more accurate semantics, while based on the ablation test of Yih, the F 1 score of WebQ drops by 0.9 if ClueWeb information is removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>CompQ  Our results show that entity enrichment method improves the results on both datasets by a large margin (0.8), which is a good help to our ap- proach. We argue that the enriched results are directly comparable with other approaches, as S- MART itself is learned from semi-structured in- formation in Wikipedia, such as anchor texts, redi- rect links and disambiguation pages, the enrich- ment step does not bring extra knowledge into our system. In addition, the improvements of the can- didate generation step also show a positive effect. If we remove our implicit type filtering in Step 4 and time interval constraints in Step 5, the F 1 of CompQ slightly drops from 42.84 to 42.37. Al-though these improvements mainly concern time- related questions (around 25% in CompQ), we be- lieve these strategies can be useful tricks in the fur- ther researches.</p><p>As a complementary evaluation, we perform se- mantic matching experiments on SimpQ. Given the gold entity of each question, we recognize the entity mention in the question, replace it with E, then predict the correct predicate. <ref type="table" target="#tab_5">Table 3</ref> shows the experimental results. The best result is from <ref type="bibr" target="#b17">Qu et al. (2018)</ref>, which learns the semantic similarity through both attentive RNN and sim- ilarity matrix based CNN. <ref type="bibr" target="#b29">Yu et al. (2017)</ref> pro- posed another approach using multi-layer BiL- STM with residual connections. Our semantic matching model performs slightly below these two systems, since answering simple questions is not the main goal of this paper. Comparing with these approaches, our semantic matching model is light- weighted, with a simpler structure and fewer pa- rameters, thus is easier to tune and remains effec- tive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Relation  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Study</head><p>In this section, we explore the contributions of var- ious components in our system. Semantic component representation: We first evaluate the results on CompQ and WebQ under different path encoding methods. Recap that the encoding result of a semantic component is the summation of its word and id path representations (Section 2.2.1), thus we compare encoding meth- ods by multiple combinations. For encoding pred- icate word sequence, we use BiGRU (the same setting as encoding question word sequence) as the alternative of average word embedding. For encoding predicate id sequence, we use average predicate embedding as the alternative of the cur- rent path-level embedding (P athEmb).</p><p>The experimental results are shown in <ref type="table" target="#tab_7">Table 4</ref>. The encoding method N one means that we don't encode the id or word sequence, and simply take the result of the other sequence as the represen- tation of the whole component. we observe that the top three combination settings, ignoring either word or id sequence, perform worse than the bot- tom three settings. The comparison demonstrates that predicate word and id representation can be complementary to each other. The performance gain is not that large, mainly because predicate id features are largely covered by their word name features.</p><p>For the encoding of id sequences, P athEmb works better than average embedding, consistently boosting F 1 by 0.65 on both datasets. The former method treats the whole sequence as a single unit, which is more flexible and can potentially learn diverse representations of id sequences that share the same predicates. For the encoding of word sequences, the average word embedding method outperforms BiGRU on CompQ, and the gap be- comes smaller when running on WebQ. This is mainly because the training set of WebQ is about 3 times larger than that of CompQ, making it easier for training a more complex model.  Semantic composition and question repre- sentation: To demonstrate the effectiveness of se- mantic composition, we construct a straightfor- ward baseline, where we remove the max pool- ing operation in Eq. <ref type="formula">(2)</ref>, and instead calculate the semantic similarity score as the summation of individual cosine similarities:</p><formula xml:id="formula_9">S sem (q, G) = i cos(p (i) , q (i) p ).</formula><p>For methods of question encod- ing, we setup ablations by turning off either sen- tential encoding or dependency encoding. <ref type="table" target="#tab_9">Table 5</ref> shows the ablation results on CompQ and WebQ. When dependency path information is augmented with sentential information, the perfor- mance boosts by 0.42 on average. Dependency paths focus on hidden features at syntactic and functional perspective, which is a good comple- mentary to sentential encoding results. However, performances drop by 2.17 if only dependency in- formation is used, we find that under certain de- pendency structures, crucial words (bolded) are not in the path between the answer and the fo- cus mention (underlined), for example, "who did draco malloy end up marrying" and "who did the philippines gain independence from". While we observe about 5% of such questions in WebQ, it's hard to predict the correct query graph without crucial words.</p><p>In terms of semantic composition, Our max pooling based method consistently outperforms the baseline method. The improvement on WebQ is smaller than on CompQ, largely due to the fact that 85% questions in WebQ are simple ques- tions ( <ref type="bibr" target="#b2">Bao et al., 2016)</ref>. As a result of com- bination, our approach significantly outperforms the vanilla SP+NN approach on CompQ by 1.28, demonstrating the effectiveness of our approach. Theoretically, the pooling outcome may lead to worse end-to-end result when there are too many semantic components in one graph, because the pooling layer takes too many vectors as input, different semantic features between similar query graphs become indistinguishable. In our task, only 0.5% of candidate graphs have more than 3 seman- tic components, so pooling is a reasonable way to aggregate semantic components in this scenario.  To further explain the advantage of semantic composition, we take the following question as an example: "who is gimli's father in the hob- bit". Two query graphs are likely to be the fi- nal answer: 1) (?, children, gimli person); 2) (?, f ictional children, gimli character) ∧ (?, appear in, hobbit). If observing semantic com- ponents individually, the predicate children is most likely to be the correct one since "'s father" is highly related and with plenty of positive training data. Both f ictional children and appear in get a much lower similarity compared with children, hence the baseline method prefer the first query graph. In the meantime, our proposed method learns the hidden semantics of the second candi- date by absorbing salient features from both pred- icates, and such compositional representation is closer to the semantics of the entire question than a simple "children" predicate. That's why our method manages to answer it correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Composition</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Error Analysis</head><p>We randomly analyzed 100 questions from CompQ where no correct answers are returned. We list the major causes of errors as follows:</p><p>Main path error (10%): This type of error oc- curred when the model failed to understand the main semantics when facing some difficult ques- tions (e.g. "What native american sports heroes earning two gold medals in the 1912 Olympics");</p><p>Constraint missing (42%): These types of ques- tions involve implicit constraints, for example, the question "Who was US president when Traicho Kostov was teenager" is difficult to answer be- cause it implies an implicit time constraint "when Traicho Kostov was teenager";</p><p>Entity linking error (16%): This error occurs due to the highly ambiguity of mentions. For ex- ample, the question "What character did Robert Pattinson play in Harry Potter" expects the film "Harry Potter and the Goblet of Fire" as the focus, while there are 7 movies in Harry Potter series;</p><p>Miscellaneous (32%): This error class contains questions with semantic ambiguity or not reason- able. For example, the question "Where is Byron Nelson 2012" is hard to understand, because "By- ron Nelson" died in 2006 and maybe this question wants to ask where did he die.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Knowledge Base Question Answering(KBQA) has been a hot research top in recent years. Gen- erally speaking, the most popular methods for KBQA can be mainly divided into two classes: in- formation retrieval and semantic parsing.</p><p>Information retrieval based system tries to ob- tain target answer directly from question in- formation and KB knowledge without explicit considering interior query structure. There are various methods <ref type="bibr" target="#b25">(Yao and Van Durme, 2014;</ref><ref type="bibr" target="#b7">Bordes et al., 2015;</ref><ref type="bibr" target="#b12">Dong et al., 2015;</ref><ref type="bibr" target="#b22">Xu et al., 2016</ref>) to select candidate answers and to rank re- sults.</p><p>Semantic parsing based approach focuses on constructing a semantic parsing tree or equivalent query structure that represents the semantic mean- ing of the question. In terms of logical representa- tion of natural language questions, many methods have been tried, such as query graph <ref type="bibr" target="#b27">(Yih et al., 2014</ref><ref type="bibr" target="#b26">(Yih et al., , 2015</ref> or RDF query language <ref type="bibr" target="#b21">(Unger et al., 2012;</ref><ref type="bibr" target="#b11">Cui et al., 2017;</ref><ref type="bibr" target="#b13">Hu et al., 2018)</ref>.</p><p>Recently, as the development of deep learn- ing, NN-based approaches have been combined into the KBQA task ( <ref type="bibr" target="#b8">Bordes et al., 2014</ref>), show- ing promising result. These approaches tries to use neural network models to encode both ques- tions and answers (or query structures) into the vector space. Subsequently, similarity functions are used to select the most appropriate query struc- ture to generate the final answer. For exam- ple, <ref type="bibr" target="#b8">Bordes et al. (2014)</ref> focuses on embedding the subgraph of the candidate answer; <ref type="bibr" target="#b28">Yin et al. (2016)</ref> uses character-level CNN and word-level CNN to match different information; <ref type="bibr" target="#b29">Yu et al. (2017)</ref> introduces the method of hierarchical residual RNN to compare questions and relation names; <ref type="bibr" target="#b17">Qu et al. (2018)</ref> proposes the AR-SMCNN model, which uses RNN to capture semantic-level correlation and employs CNN to extract literal- level words interaction.</p><p>Belonging to NN-based semantic parsing cat- egory, our approach employs a novel encod- ing structure method to solve complex questions. Previous works such as <ref type="bibr" target="#b26">Yih et al. (2015)</ref> and <ref type="bibr" target="#b2">Bao et al. (2016)</ref> require a recognition of a main relation and regard other constraints as variables added to this main relation. Unlike their ap- proaches, our method encodes multiple relations (paths) into a uniform query structure representa- tion (semantic composition), which allows more flexible query structures.</p><p>There are also some works can't be simply clas- sified in to IR based methods or SP based meth- ods. Jain (2016) introduces Factual Memory Net- work, which tries to encode KB and questions in same word vector space, extract a subset of ini- tial candidate facts, then try to employ multi-hop reasoning and refinement to find a path to answer entity. , <ref type="bibr" target="#b0">Abujabal et al. (2017)</ref>, and <ref type="bibr" target="#b11">Cui et al. (2017)</ref> try to interpret question in- tention by templates, which learned from KB or QA corpora. <ref type="bibr" target="#b20">Talmor and Berant (2018)</ref> attempts to answering complex questions by decomposing them into a sequence of simple questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>To the best of our knowledge, this is the first work to handle complex KBQA task by explic- itly encoding the complete semantics of a com- plex query graph using neural networks. We stud- ied different methods to further improve the per- formance, mainly leveraging dependency parse and the ensemble method for linking enrichment. Our model becomes the state-of-the-art on Com- plexQuestions dataset, and produces competitive results on other simple question based datasets. Possible future work includes supporting more complex semantics like implicit time constraints.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: Running example of complex question.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Running example of candidate generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 3: Overview of proposed semantic matching model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Full set of features. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Average F1 scores on CompQ and WebQ datasets.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 : Accuracy on the SimpleQuestions dataset.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Ablation results on path representation. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Ablation results on question representation and 

compositional strategy. 

</table></figure>

			<note place="foot" n="1"> The term &quot;query graph&quot; is interchangeable with &quot;query structure&quot; and &quot;semantic parsing tree&quot; throughout this paper.</note>

			<note place="foot" n="2"> ~20 superlative words, such as largest, highest, latest. 3 Mediator is a kind of auxiliary nodes in Freebase maintaining N-ary facts.</note>

			<note place="foot" n="4"> Short for governmental position held.f rom and governmental position held.to respectively.</note>

			<note place="foot" n="5"> detail information of the Freebase dump is available at https://github.com/syxu828/QuestionAnsweringOverFB/. 6 http://virtuoso.openlinksw.com/ 7 The evaluation script is available at http://wwwnlp.stanford.edu/software/sempre/.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>Kenny Q. Zhu is the contact author and was sup-ported by NSFC grants 91646205 and 61373031. Thanks to the anonymous reviewers for their valu-able feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automated template generation for question answering over knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdalghani</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirek</forename><surname>Riedewald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1191" to="1200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Dbpedia: A nucleus for a web of open data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ives</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Constraint-based question answering with knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Wei</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2503" to="2514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">More accurate question answering on freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Bast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Haussmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1431" to="1440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Imitation learning of agenda-based semantic parsers. Transactions of the Association for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="545" to="558" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02075</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Open question answering with weakly supervised embedding models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="165" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing via schema matching and lexicon extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="423" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the properties of neural machine translation: Encoder-decoder approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SSST-8</title>
		<meeting>SSST-8</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Kbqa: learning question answering over qa corpora and knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanyun</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghua</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haixun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seung-Won</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="565" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Question answering over freebase with multicolumn convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="260" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Answering natural language questions by subgraph matching over knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">Xu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haixun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="824" to="837" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Question answering over knowledge base using factual memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarthak</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Student Research Workshop</title>
		<meeting>the NAACL Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="109" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Inferring binary relation schemas for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kangqi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xusheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenny</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="555" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Question answering over freebase via attentive rnn with similarity matrix based cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingqi</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinfeng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03317</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Transforming dependency structures to logical forms for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="127" to="140" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Yago: a core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Fabian M Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The web as a knowledge-base for answering complex questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Template-based question answering over rdf data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenz</forename><surname>Bühmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Question answering on freebase via relation extraction and textual evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2326" to="2336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">S-mart: Novel tree-based structured learning algorithms applied to tweet entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="504" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Lean question answering over freebase from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="66" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Information extraction over structured data: Question answering with freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="956" to="966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semantic parsing via staged query graph generation: Question answering with knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1321" to="1331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semantic parsing for single-relation question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="643" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Simple question answering by attentive convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1746" to="1756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improved neural relation detection for knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazi</forename><surname>Saidul Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="571" to="581" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
