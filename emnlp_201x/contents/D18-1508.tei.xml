<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interpretable Emoji Prediction via Label-Wise Attention LSTMs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Barbieri</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Large Scale Text Understanding Systems Lab</orgName>
								<orgName type="institution" key="instit1">TALN</orgName>
								<orgName type="institution" key="instit2">UPF</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Espinosa-Anke</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Informatics</orgName>
								<orgName type="institution">Cardiff University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Camacho-Collados</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Informatics</orgName>
								<orgName type="institution">Cardiff University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Schockaert</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Informatics</orgName>
								<orgName type="institution">Cardiff University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Saggion</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Large Scale Text Understanding Systems Lab</orgName>
								<orgName type="institution" key="instit1">TALN</orgName>
								<orgName type="institution" key="instit2">UPF</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Interpretable Emoji Prediction via Label-Wise Attention LSTMs</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="4766" to="4771"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>4766</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Human language has evolved towards newer forms of communication such as social media , where emojis (i.e., ideograms bearing a visual meaning) play a key role. While there is an increasing body of work aimed at the computational modeling of emoji semantics, there is currently little understanding about what makes a computational model represent or predict a given emoji in a certain way. In this paper we propose a label-wise attention mechanism with which we attempt to better understand the nuances underlying emoji prediction. In addition to advantages in terms of interpretability, we show that our proposed architecture improves over standard baselines in emoji prediction, and does particularly well when predicting infrequent emojis.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Communication in social media differs from more standard linguistic interactions across a wide range of dimensions. Immediacy, short text length, the use of pseudowords like #hashtags or @mentions, and even metadata such as user in- formation or geolocalization are essential compo- nents of social media messages. In addition, the use of emojis, small ideograms depicting objects, people and scenes <ref type="bibr" target="#b5">(Cappallo et al., 2015)</ref>, are be- coming increasingly important for fully modeling the underlying semantics of a social media mes- sage, be it a product review, a tweet or an Insta- gram post. Emojis are the evolution of character- based emoticons <ref type="bibr" target="#b15">(Pavalanathan and Eisenstein, 2015)</ref>, and are extensively used, not only as senti- ment carriers or boosters, but more importantly, to express ideas about a myriad of topics, e.g., mood ( ), food ( ), sports ( ) or scenery ( ).</p><p>Emoji modeling and prediction is, therefore, an important problem towards the end goal of properly capturing the intended meaning of a so- cial media message. In fact, emoji prediction, i.e., given a (usually short) message, predict its most likely associated emoji(s), may help to im- prove different NLP tasks <ref type="bibr">(Novak et al., 2015</ref>), such as information retrieval, generation of emoji- enriched social media content or suggestion of emojis when writing text messages or sharing pic- tures online. It has furthermore proven to be useful for sentiment analysis, emotion recognition and irony detection <ref type="bibr" target="#b7">(Felbo et al., 2017)</ref>. The prob- lem of emoji prediction, albeit recent, has already seen important developments. For example, <ref type="bibr" target="#b1">Barbieri et al. (2017)</ref> describe an LSTM model which outperforms a logistic regression baseline based on word vector averaging, and even human judge- ment in some scenarios.</p><p>The above contributions, in addition to emoji similarity datasets ( <ref type="bibr" target="#b4">Barbieri et al., 2016;</ref><ref type="bibr" target="#b19">Wijeratne et al., 2017)</ref> or emoji sentiment lexicons <ref type="bibr">(Novak et al., 2015;</ref><ref type="bibr" target="#b18">Wijeratne et al., 2016;</ref><ref type="bibr" target="#b9">Kimura and Katsurai, 2017;</ref><ref type="bibr" target="#b16">Rodrigues et al., 2018)</ref>, have paved the way for better understanding the seman- tics of emojis. However, our understanding of what exactly the neural models for emoji predic- tion are capturing is currently very limited. What is a model prioritizing when associating a message with, for example, positive ( ), negative ( ) or patriotic ( ) intents? A natural way of assessing this would be to implement an attention mecha- nism over the hidden states of LSTM layers. At- tentive architectures in NLP, in fact, have recently received substantial interest, mostly for sequence- to-sequence models (which are useful for machine translation, summarization or language modeling), and a myriad of modifications have been proposed, including additive ( <ref type="bibr" target="#b0">Bahdanau et al., 2015)</ref>, multi- plicative ( <ref type="bibr" target="#b12">Luong et al., 2015</ref>  <ref type="figure">Figure 1</ref>: A classic attention network (top), and our attentive label-wise network (bottom), with a specific attention module for each label.</p><p>tant for the overall prediction distribution. While emoji prediction has predominantly been treated as a multi-class classification problem in the lit- erature, it would be more informative to analyze which text fragments are considered important for each individual emoji. With this motivation in mind, in this paper we put forward a label-wise mechanism that operates over each label during training. The resulting architecture intuitively be- haves like a batch of binary mini-classifiers, which make decisions over one single emoji at a time, but without the computational burden and risk of over- fitting associated with learning separate LSTM- based classifiers for each emoji. Our contribution in this paper is twofold. First, we use the proposed label-wise mechanism to an- alyze the behavior of neural emoji classifiers, ex- ploiting the attention weights to uncover and in- terpret emoji usages. Second, we experimentally compare the effect of the label-wise mechanism on the performance of an emoji classifier. We ob- served a performance improvement over compet- itive baselines such as FastText (FT) ( <ref type="bibr" target="#b8">Joulin et al., 2017) and</ref><ref type="bibr">Deepmoji (Felbo et al., 2017)</ref>, which is most noticeable in the case of infrequent emojis. This suggests that an attentive mecha- nism can be leveraged to make neural architec- tures more sensitive to instances of underrepre- sented classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Our base architecture is the Deepmoji model <ref type="bibr" target="#b7">(Felbo et al., 2017)</ref>, which is based on two stacked word-based bi-directional LSTM recurrent neural networks with skip connections between the first and the second LSTM. The model also includes an attention module to increase its sensitivity to indi- vidual words during prediction. In general, atten- tion mechanisms allow the model to focus on spe- cific words of the input ( <ref type="bibr" target="#b20">Yang et al., 2016)</ref>, instead of having to memorize all the important features in a fixed-length vector. The main architectural dif- ference with respect to the typical attention is il- lustrated in <ref type="figure">Figure 1</ref>.</p><p>In <ref type="bibr" target="#b7">Felbo et al. (2017)</ref>, attention is computed as follows:</p><formula xml:id="formula_0">z i = w a h i + b a α i = e z i N j=1 e z j s = N j=1 α j h j</formula><p>Here h i ∈ R d is the hidden representation of the LSTM corresponding to the i th word, with N the total number of words in the sentence. The weight vector w a ∈ R d and bias term b a ∈ R map this hidden representation to a value that reflects the importance of this state for the considered clas- sification problem. The values z 1 , ..., z n are then normalized using a softmax function, yielding the attention weights α i . The sentence representation s is defined as a weighted average of the vectors h i . The final prediction distribution is then defined as follows:</p><formula xml:id="formula_1">β l = w f,l s + b f,l p l = e β l L r=1 e βr</formula><p>where w f,l ∈ R d and b f,l define a label-specific linear transformation, with β l reflecting our confi- dence in the l th label and L is the total number of labels. The confidence scores β l are then normal- ized to probabilities using another softmax oper- ation. However, while the above design has con- tributed to better emoji prediction, in our case we are interested in understanding the contribution of the words of a sentence for each label (i.e., emoji), and not in the whole distribution of the target la- bels. To this end, we propose a label-wise atten- tion mechanism. Specifically, we apply the same type of attention, but repeating it |L| (number of labels) times, where each attention module is re- served for a specific label l:</p><formula xml:id="formula_2">z i,l = w a,l h i + b a,l α i,l = e z i,l N j=1 e z j,l s l = N j=1 α j,l h j β l = w f,l s l + b f,l p l = e β l L r=1 e βr</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>This section describes the main experiment w.r.t the performance of our proposed attention mech- anism, in comparison with existing emoji predic- tion systems. We use the data made available in the context of the SemEval 2018 Shared Task on Emoji Prediction ( . Given a tweet, the task consists of predicting an associated emoji from a predefined set of 20 emoji labels. We evaluate our model on the English split of the official task dataset. We also show results from additional experiments in which the label space ranged from 20 to 200 emojis. These extended experiments are performed on a corpus of around 100M tweets geolocalized in the United States and posted between October 2015 and May 2018.</p><p>Models. In order to put our proposed label- wise attention mechanism in context, we com- pare its performance with a set of baselines: <ref type="formula">(1</ref>  Results. <ref type="table">Table 1</ref> shows the results of our model and the baselines in the emoji prediction task for the different evaluation splits. The evaluation met- rics used are: F1, Accuracy@k (A@k, where k ∈ {1, 5}), and Coverage Error (CE 1 ) ( <ref type="bibr">Tsoumakas et al., 2009</ref>). We note that the latter metric is not normally used in emoji prediction settings. How- ever, with many emojis being "near synonyms" (in the sense of being often used almost interchange- ably), it seems natural to evaluate the performance of an emoji prediction system in terms of how far we would need to go through the predicted emo- jis to recover the true label. The results show that our proposed 2-BiLSTMs l method outperforms all baselines for F1 in three out of four settings, and for CE in all of them. In the following section we shed light on the reasons behind this perfor- mance, and we try to understand how these pre- dictions were made. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis</head><p>By inspecting the predictions of our model, we found that the label-wise attention mechanism tends to be less heavily biased towards the most frequent emojis. This is reflected in the lower coverage error results in all settings, and becomes more noticeable as the number of labels grows. We verified this by computing the average differ- ence between ranked predictions of the two atten- tive models in the 200-label setting <ref type="figure" target="#fig_0">(Figure 2)</ref>. We can observe a sudden switch at more or less the median emoji, after which the label-wise attention model becomes increasingly accurate (relative to the standard attention model). This can be ex- plained by the fact that infrequent emojis tend to be more situational (used in specific contexts and leaving less room for ambiguity or interchange- ability), which the label-wise attention mechanism can take advantage of, as it explicitly links emojis with highly informative words. Let us illustrate this claim with a case in which the label-wise at- tention model predicts the correct emoji, unlike its single-attention counterpart: a friendship is built over time , but sister- hood is given automatically. Gold:</p><p>For the above example 2 , the predictions of the sin- gle attention model were all linked to the general meaning of the message, that is love and friend- ship, leading it to predict associated emojis ( , and ), failing to capture the most relevant bit of information. On the other hand, our proposed model "picks on" the word sisterhood, and with Single Att. Pred: 0.709 , 0.126 , 0.017 praying we have a snow day tomorrow Multi Att. Pred: 0.510 , 0.153 , 0.027 praying we have a snow day tomorrow ( ) praying we have a snow day tomorrow ( ) praying we have a snow day tomorrow ( ) Let us explore what we argue are interesting cases of emoji usage (ranging from highly explicit to figurative or situtational intent). <ref type="figure" target="#fig_2">Figure 3</ref> shows how the word (praying) and emojis such as and are strongly correlated. In addition, the bond between the word snow and the emoji is also indisputable. However, a perhaps more surpris- ing example is displayed in <ref type="figure">Figure 4</ref>, which is a negative example. Here, the emoji was pre- dicted with rank 1, and we see it being strongly associated with the ordinal second, suggesting that the model assumed this was some kind of "ticked enumeration" of completed tasks, which is indeed regular practice in Twitter. Finally, we found it re- markable that the ambiguous nature of the word boarding is also reflected in two different emojis being predicted with high probability ( and ), each of them showcasing one of the word's senses.</p><p>As an additional exploratory analysis, we com- puted statistics on those words with the highest av- erage attention weights associated with one single emoji. One interesting example is the emoji, which shows two clear usage patterns: one lit- eral (a tree) and one figurative (christmas and hol- idays). Finally, as a final (and perhaps thought- provoking) finding, the highest attention weights associated to the emoji were given to the words game, boys and football, in that order. In other words, the model relies more on the word boys than on the actual description of the emoji. This is in line with a previous study that showed how the current usage of emojis in Twitter is in some cases associated with gender stereotypes ).</p><p>Single Att. Pred: 0.565 , 0.260 , 0.019 second day snowboarding ever and i decided to try night boarding ... what an experience ! Multi Att. Pred: 0.156 , 0.131 , 0.108 second day snowboarding ever and i decided to try night boarding ... what an experience ! ( ) second day snowboarding ever and i decided to try night boarding ... what an experience ! ( ) second day snowboarding ever and i decided to try night boarding ... what an experience ! ( ) <ref type="figure">Figure 4</ref>: Attention weights α and α l of single and label-wise attentive models. Gold: .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we have presented a neural archi- tecture for emoji prediction based on a label-wise attention mechanism, which, in addition to im- proving performance, provides a degree of inter- pretability about how different features are used for predictions, a topic of increasing interest in NLP ( <ref type="bibr" target="#b11">Linzen et al., 2016;</ref><ref type="bibr" target="#b14">Palangi et al., 2017</ref>). As we experimented with sets of emoji labels of dif- ferent sizes, our proposed label-wise attention ar- chitecture proved especially well-suited for emojis which were infrequent in the training data, making the system less biased towards the most frequent. We see this as a first step to improve the robustness of recurrent neural networks in datasets with un- balanced distributions, as they were shown not to perform better than well-tuned SVMs on the emoji predicion task (C ¸ ¨ oltekin and Rama, 2018). As for future work, we plan to apply our label- wise attention mechanism to understand other in- teresting linguistic properties of human-generated text in social media, and other multi-class or multi- label classification problems.</p><p>Finally, code to reproduce our experiments and additional examples of label-wise atten- tion weights from input tweets can be down- loaded at https://fvancesco.github. io/label_wise_attention/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>stacked Bi-LSTMs ( 2 -</head><label>2</label><figDesc>BiLSTMs) without atten- tion; and (3) 2 stacked Bi-LSTMs with standard attention (2-BiLSTMs a ) (Felbo et al., 2017). Fi- nally, we denote as 2-BiLSTMs l our proposed label-wise attentive Bi-LSTM architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Difference in rank distributions. The x-axis represents emoji labels, ranked from most to least frequent. Lower scores indicate a higher average rank predicted by our proposed label-wise attention mechanism.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Attention weights α and α l of single and label-wise attentive models. Gold: .</figDesc><graphic url="image-8.png" coords="4,77.42,62.81,207.07,118.11" type="bitmap" /></figure>

			<note place="foot" n="1"> CE is computed as the average number of labels that need to be in the predictions for all true labels to be predicted.</note>

			<note place="foot" n="2"> The highlights show the α l attention weights of .</note>

			<note place="foot" n="3"> Which is among the 10% most infrequent emojis in the dataset.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>F. Barbieri and H. Saggion acknowledge support from the TUNER project (TIN2015-65308-C5-5-R, MINECO/FEDER, UE). Luis Espinosa-Anke, Jose Camacho-Collados and Steven Schockaert have been supported by ERC Starting Grant 637277.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Are emojis predictable?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Saggion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="105" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">How gender and skin tone modifiers affect emoji semantics in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Camacho-Collados</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the Seventh Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="101" to="106" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SemEval-2018 Task 2: Multilingual Emoji Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Ronzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Espinosa-Anke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Saggion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Workshop on Semantic Evaluation (SemEval-2018)</title>
		<meeting>the 12th International Workshop on Semantic Evaluation (SemEval-2018)<address><addrLine>New Orleans, LA, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">What does this emoji mean? a vector space skip-gram model for Twitter emojis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Ronzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Saggion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC</title>
		<meeting>of LREC</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image2emoji: Zero-shot emoji prediction for visual media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spencer</forename><surname>Cappallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Cees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM international conference on Multimedia</title>
		<meeting>the 23rd ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1311" to="1314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tübingenoslo at semeval-2018 task 2: Svms perform better than rnns in emoji prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grı C ¸ ¨ Oltekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taraka</forename><surname>Rama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 12th International Workshop on Semantic Evaluation</title>
		<meeting>The 12th International Workshop on Semantic Evaluation<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="32" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjarke</forename><surname>Felbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sune</forename><surname>Iyad Rahwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1615" to="1625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bag of tricks for efficient text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Chapter of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic construction of an emoji sentiment lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayu</forename><surname>Kimura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Katsurai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</title>
		<meeting>the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1033" to="1036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cicero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Assessing the ability of lstms to learn syntaxsensitive dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Linzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Dupoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="521" to="535" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Effective approaches to attentionbased neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Borut Sluban, and Igor Mozetič. 2015. Sentiment of emojis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petra</forename><forename type="middle">Kralj</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasmina</forename><surname>Smailovi´csmailovi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">144296</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Smolensky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08432</idno>
		<title level="m">Deep learning of grammaticallyinterpretable representations through questionanswering</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umashanthi</forename><surname>Pavalanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.08480</idno>
		<title level="m">Emoticons vs. emojis on Twitter: A causal inference approach</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Lisbon emoji and emoticon database (leed): Norms for emoji and emoticons in seven evaluative dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marília</forename><surname>Prada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Gaspar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Margarida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diniz</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Behavior research methods</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="392" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mining multi-label data</title>
	</analytic>
	<monogr>
		<title level="m">Grigorios Tsoumakas, Ioannis Katakis, and Ioannis Vlahavas</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="667" to="685" />
		</imprint>
	</monogr>
	<note>Data mining and knowledge discovery handbook</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Emojinet: Building a machine readable sense inventory for emoji</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lakshika</forename><surname>Sanjaya Wijeratne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Balasuriya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Social Informatics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="527" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A semantics-based measure of emoji similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lakshika</forename><surname>Sanjaya Wijeratne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Balasuriya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Web Intelligence</title>
		<meeting>the International Conference on Web Intelligence</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="646" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hierarchical attention networks for document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
