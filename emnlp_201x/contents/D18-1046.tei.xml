<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bootstrapping Transliteration with Constrained Discovery for Low-Resource Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
							<email>shyamupa@seas.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Pennsylvania Philadelphia</orgName>
								<orgName type="institution" key="instit2">University of Pennsylvania Philadelphia</orgName>
								<orgName type="institution" key="instit3">University of Pennsylvania Philadelphia</orgName>
								<address>
									<region>PA, PA, PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Kodner</surname></persName>
							<email>jkodner@seas.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Pennsylvania Philadelphia</orgName>
								<orgName type="institution" key="instit2">University of Pennsylvania Philadelphia</orgName>
								<orgName type="institution" key="instit3">University of Pennsylvania Philadelphia</orgName>
								<address>
									<region>PA, PA, PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
							<email>danroth@seas.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Pennsylvania Philadelphia</orgName>
								<orgName type="institution" key="instit2">University of Pennsylvania Philadelphia</orgName>
								<orgName type="institution" key="instit3">University of Pennsylvania Philadelphia</orgName>
								<address>
									<region>PA, PA, PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bootstrapping Transliteration with Constrained Discovery for Low-Resource Languages</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="501" to="511"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>501</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Generating the English transliteration of a name written in a foreign script is an important and challenging step in multilingual knowledge acquisition and information extraction. Existing approaches to transliteration generation require a large (&gt;5000) number of training examples. This difficulty contrasts with transliteration discovery, a somewhat easier task that involves picking a plausible translit-eration from a given list. In this work, we present a bootstrapping algorithm that uses constrained discovery to improve generation, and can be used with as few as 500 training examples , which we show can be sourced from annotators in a matter of hours. This opens the task to languages for which large number of training examples are unavailable. We evaluate transliteration generation performance itself , as well the improvement it brings to cross-lingual candidate generation for entity linking, a typical downstream task. We present a comprehensive evaluation of our approach on nine languages, each written in a unique script. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Transliteration is the process of transducing names from one writing system to another (e.g., ओबामा in Devanagari to Obama in Latin script) while preserving their pronunciation <ref type="bibr" target="#b26">(Knight and Graehl, 1998;</ref><ref type="bibr" target="#b22">Karimi et al., 2011</ref>). In particu- lar, back-transliteration from foreign languages to English has applications in multilingual knowl- edge acquisition tasks including named entity recognition <ref type="bibr" target="#b9">(Darwish, 2013)</ref> and information re- trieval ( <ref type="bibr" target="#b41">Virga and Khudanpur, 2003)</ref>. Two tasks feature prominently in the transliteration literature: generation ( <ref type="bibr" target="#b26">Knight and Graehl, 1998</ref>) which in- volves producing an appropriate transliteration for a given word in an open-ended way, and discov- ery <ref type="bibr" target="#b36">(Sproat et al., 2006</ref>; Klementiev and Roth, <ref type="bibr">1</ref> code at github.com/shyamupa/hma-translit.</p><p>2008) which involves selecting an appropriate transliteration for a word from a list of candidates. This work develops transliteration generation ap- proaches for low-resource languages.</p><p>Existing transliteration generation models re- quire supervision in the form of source-target name pairs (≈5-10k), which are often collected from names in Wikipedia inter-language links <ref type="bibr" target="#b17">(Irvine et al., 2010)</ref>. However, most languages that use non-Latin scripts are under-represented in terms of such resources. <ref type="table" target="#tab_1">Table 1</ref> illustrates this issue, and the extra coverage one can achieve by extending to low-resource languages. A model that requires 50k name pairs as supervision can only support 6 languages, while one that just needs 500 could sup- port 56. For a model to be widely applicable, it must function in low-resource settings.  Wikipedia inter-language links. While previous approaches for transliteration generation were applicable to only 24 lan- guages (spanning 15 scripts), our approach is applicable to 56 languages (23 scripts). When counting scripts we exclude variants (e.g., all Cyrillic scripts and variants count as one).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Previous Work</head><p>We propose a new bootstrapping algorithm that uses a weak generation model to guide discov- ery of good transliterations, which in turn aids fu- ture bootstrapping iterations. <ref type="bibr">2</ref> By carefully con- trolling the interaction of discovery and the gen- eration model via constrained inference, we show how to bootstrap a generation model using a dic- tionary of names in English, a list of words in the foreign script, and little initial supervision (≈500 name pairs). To the best of our knowledge, ours is the first work to accomplish transliteration genera- tion in such a low-resource setting.</p><p>We demonstrate the practicality of our approach in truly low-resource scenarios and downstream applications through two case studies. First, in §8.1 we show that one can obtain the initial super- vision from a single human annotator within a few hours for two languages -Armenian and Punjabi. This is a realistic scenario where language access is limited to a single native informant. Second, in §8.2 we show that our approach benefits a typical downstream application, namely candidate genera- tion for cross-lingual entity linking, by improving recall on two low-resource languages -Tigrinya and Macedonian. We also present an analysis ( §7) of the inherent challenges of transliteration, and the trade-off between native (i.e., source) and for- eign (i.e., target) vocabulary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>We briefly review the limitations of existing gen- eration and discovery approaches, and provide an overview of how our work addresses them. <ref type="bibr" target="#b15">(Haizhou et al., 2004;</ref><ref type="bibr" target="#b19">Jiampojamarn et al., 2009;</ref><ref type="bibr" target="#b35">Ravi and Knight, 2009;</ref><ref type="bibr" target="#b20">Jiampojamarn et al., 2010;</ref><ref type="bibr" target="#b12">Finch et al., 2015</ref>, inter alia) requires generous amount of name pairs (≈5-10k) in order to learn to map words in the source script to the target script. While some approaches <ref type="bibr" target="#b17">(Irvine et al., 2010;</ref><ref type="bibr" target="#b39">Tsai and Roth, 2018)</ref> use Wikipedia inter-language links to identify name pairs for supervision, a truly low- resource language (like Tigrinya) is likely to have limited Wikipedia presence as well. <ref type="bibr" target="#b36">(Sproat et al., 2006;</ref><ref type="bibr" target="#b2">Chang et al., 2009</ref>) is considerably easier than gen- eration, owing to the smaller search space. How- ever, discovery often uses features derived from resources that are unavailable for low-resource lan- guages, like comparable corpora ( <ref type="bibr" target="#b36">Sproat et al., 2006;</ref><ref type="bibr" target="#b25">Klementiev and Roth, 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transliteration Generation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transliteration Discovery</head><p>A key limitation of discovery is the assumption that the correct transliteration(s) is in the list of can- didates N . Since discovery models always pick something from N , they can produce false posi- tives, if no correct transliteration is present in N .</p><p>To overcome this, it is prudent to develop genera- tion models which can handle input for which the transliteration does not belong in N .</p><p>Our Work We show that a weak generation model can be iteratively improved using con- strained discovery. In particular, our work uses a weak generation model to discover new train- ing pairs, using constraints to drive the bootstrap- ping. Our generation model is inspired by the success of sequence to sequence generation mod- els ( <ref type="bibr" target="#b37">Sutskever et al., 2014;</ref><ref type="bibr" target="#b1">Bahdanau et al., 2015)</ref> for string transduction tasks like inflection and derivation generation <ref type="bibr" target="#b11">(Faruqui et al., 2016;</ref><ref type="bibr" target="#b8">Cotterell et al., 2017;</ref><ref type="bibr" target="#b0">Aharoni and Goldberg, 2017;</ref><ref type="bibr" target="#b29">Makarov et al., 2017)</ref>. Our bootstrapping frame- work can be viewed as an instance of constraint driven learning ( <ref type="bibr" target="#b3">Chang et al., 2007</ref><ref type="bibr" target="#b4">Chang et al., , 2012</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Transliteration Generation with Hard Monotonic Attention -Seq2Seq(HMA)</head><p>We view generation as a string transduction task and use a sequence to sequence (Seq2Seq) gen- eration model that uses hard monotonic atten- tion <ref type="bibr" target="#b0">(Aharoni and Goldberg, 2017)</ref>, henceforth referred to as Seq2Seq(HMA). During genera- tion, Seq2Seq(HMA) directly models the mono- tonic source-to-target sequence alignments, using a pointer that attends to a single input character at a time. Monotonic attention is a natural fit for transliteration because even though the num- ber of characters needed to represent a sound in the source and target language vary, the sequence of sounds is presented in the same order. <ref type="bibr">3</ref> We re- view Seq2Seq(HMA) below, and describe how it can be applied to transliteration generation.</p><p>Encoding Input Word Let Σ f be the source al- phabet and Σ e be the English alphabet.  Hard Monotonic Attention, or Seq2Seq(HMA). The figure shows how decoding proceeds for transliterating "थनोस" to "thanos". During decoding, the model attends to a source char- acter (e.g.,थ shown in blue) and outputs target characters (t, h, a) until a step action is generated, which moves the attention position forward by one character (to न), and so on. If the gen- erated action is step, the decoder increments the attention position by one. This ensures that the de- coding is monotonic, as the attention position can only move forward or stay at the same position dur- ing generation. We use Inference(G, x) to refer to the above decoding process for a trained gener- ation model G and input word x.</p><formula xml:id="formula_0">Let x = (x 1 , x 2 , · · · , x n ) denote an input</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monotonic Decoding with Hard Attention</head><p>Training requires the oracle action sequence {s i } for input x 1:n that generates the correct transliteration y 1:m . The oracle sequence is gener- ated using the train name pairs and Algorithm 1 in <ref type="bibr" target="#b0">Aharoni and Goldberg (2017)</ref>, with the character- level alignment between x 1:n and y 1:m being gen- erated using the algorithm in <ref type="bibr" target="#b7">Cotterell et al. (2016)</ref>.</p><p>Inference Strategies We describe an uncon- strained and a constrained inference strategy to se- lect the best transliterationˆytransliterationˆ transliterationˆy from a beam</p><formula xml:id="formula_1">{y i } k i=1</formula><p>of transliteration hypotheses, sorted in descending order by likelihood. The constrained strategy use a name dictionary N , to guide the inference. These strategies are applicable to any generation model.</p><p>• Unconstrained (U) selects the most likely item y 1 in the beam asˆyasˆ asˆy.</p><p>• Dictionary-Constrained (DC) selects the highest scoring hypothesis that is present in N , and defaults to y 1 if none are in N .</p><p>It is tempting to disallow the model from gen- erating hypotheses which are not in the dictionary N . However, dictionaries are always incomplete, and restricting the search to generate from N in- evitably leads to incorrect predictions if the correct transliteration is not in N . This is essentially the same as the problem inherent to discovery models.</p><p>Other Strategies in Previous Work A related constrained inference strategy was proposed by <ref type="bibr" target="#b28">Lin et al. (2016)</ref>, who use a entity linking sys- tem ( <ref type="bibr" target="#b12">Wang et al., 2015</ref>) to correct and re-rank hy- potheses, using any available context to aid hypoth- esis correction. Our constrained inference strategy is much simpler, requiring only a name dictionary N . We experimentally show that our approach out- performs that of <ref type="bibr" target="#b28">Lin et al. (2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Low-Resource Bootstrapping</head><p>Low-resource languages will have a limited num- ber of name pairs for training a generation model. To learn a good generation model in this setting, we propose a new bootstrapping algorithm, that uses constrained discovery to mine name pairs to re-train the generation model. Our algorithm re- quires a small (≈500) seed list of name pairs S for supervision, a dictionary N containing names in English, and a list of words V f in the foreign script.</p><p>Below we describe our algorithm and the con- straints used to guide discovery of new name pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Bootstrapping Algorithm</head><p>Algorithm 1 shows the pseudo-code of the boot- strapping procedure. We initialize a weak gener- ation model G 0 using a seed list of name pairs S (line 1). At iteration t, the current generation model G t produces the top-k transliteration hy- potheses {y i } k i=1 for each word x ∈ V f (line 5). A source word and hypothesis pair (x, y i ), is added to the set of mined name pairs B if they satisfy a set of discovery constraints (described below) (line 8). A new generation model G t+1 is trained for the next iteration using the union of the seed list S and the mined name pairs B (line 12). B is purged after ev- ery iteration (line 3) to prevent G t+1 from being in- fluenced by possibly incorrect name pairs mined in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Bootstrapping a Transliteration Generation Model via Constrained Discovery</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input:</head><p>English name dictionary N ; Seed training pairs S; Vocabulary in the target language V f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-parameters:</head><p>initial minimum length threshold L min 0 ; minimum likelihood threshold δ min ; length ratio tolerance ϵ. Output:</p><formula xml:id="formula_2">Generation model GT 1: G0 = train(S) ▷ init. generation model. 2: while not converged do 3: B = ∅ ▷ purge mined set. 4: for x in V f do 5: {yi} k i=1 = argtop k Inference(Gt,x) 6: for yi in {yi} k i=1 do 7:</formula><p>if (x, yi) satisfies constraints in §4.2 then 8:</p><formula xml:id="formula_3">B = B ∪ {(x, yi)} ▷ add to mined set. 9:</formula><p>end if 10:</p><p>end for 11:</p><p>end for 12:</p><formula xml:id="formula_4">Gt+1 = train (S ∪ B) 13: L min t+1 = L min t − 1 ▷ reduce length threshold. 14: t = t + 1 ▷ track iteration 15: end while</formula><p>earlier iterations. The algorithm converges when accuracy@1 stops increasing on a development set. We note that our bootstrapping approach is applica- ble to any transliteration generation model.</p><p>To ensure that high quality name pairs are added to the mined set B during bootstrapping, we use the following discovery constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Discovery Constraints</head><p>A word-transliteration pair (x, y) is added to the set of mined pairs B, only if all the following con- straints are satisfied, 1. y ∈ N . i.e., y belongs in the dictionary.</p><p>2. P(y | x) &gt; δ min . The model is sufficiently confident about the transliteration.</p><p>3. The ratio of lengths |y| |x| should be close to the average ratio estimated from S (Matthews, 2007). We encode this using the constraint</p><formula xml:id="formula_5">| |y| |x| − r(S)| ≤ ϵ,</formula><p>where ϵ is a tunable toler- ance and r(S) is the average ratio in S.</p><formula xml:id="formula_6">4. |y| &gt; L min t</formula><p>. We found that false positives were more likely to be short hypotheses in early iterations. As the model improves with each iteration, L min t is lowered to allow more new pairs to be mined.</p><p>We note that our bootstrapping algorithm can be formulated as an instance of constraint driven learning ( <ref type="bibr" target="#b3">Chang et al., 2007</ref><ref type="bibr" target="#b4">Chang et al., , 2012</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>Unless otherwise specified, we evaluate all gener- ation models using the best model predictionˆypredictionˆ predictionˆy us- ing acc@1 against the reference transliteration y * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and Evaluation Dataset</head><p>We use the train and development sets from the Named Entities Workshop 2015 ( <ref type="bibr" target="#b10">Duan et al., 2015</ref>) (NEWS2015) for Hindi (hi), Kannada (kn), Ben- gali (bn), Tamil (ta) and Hebrew (he) as our train and evaluation set. <ref type="bibr">4</ref> The size of the train set was ∼12k, 10k, 14k, 10k and 10k respectively, and all evaluation sets were ∼1k.</p><p>For the low resource experiments, we sub- sample 500 examples from each train set in the NEWS2015 dataset using five random seeds and report the averaged results. We also set aside a 1k name pairs from the corresponding NEWS2015 train set of each language as development data. The foreign script portion of the remaining train data is used as V f in the bootstrapping algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model and Tuning Details</head><p>We implemented Seq2Seq(HMA) using PyTorch. <ref type="bibr">5</ref> We used 50 di- mensional character embeddings, and single layer GRU ( <ref type="bibr" target="#b6">Cho et al., 2014</ref>) encoder with 20 hidden states for all experiments. The Adam ( <ref type="bibr" target="#b24">Kingma and Ba, 2014</ref>) optimizer was used with default hyper- parameters, a learning rate of 0.001, a batch size of 1, and maximum of 20 iterations in all experi- ments. Beam search used a width of 10. For low- resource experiments, all bootstrapping parame- ters were tuned on the development data set aside above. L min 0 is chosen from {10, 15, 20, 25}.</p><p>Name Dictionary We use a name dictionary of 1.05 million names constructed from the English Wikipedia (dump dated 05/20/2017) by taking the list of title tokens in Wikipedia sorted by frequency, and removing tokens which appears only once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Comparisons</head><p>We compare with the following generation models: P&amp;R (Pasternack and Roth, 2009) A prob- abilistic transliteration generation approach that learns latent alignments between substrings in the source and the target words. The model is trained to score all possible segmentation and their align- ments, using an EM-like algorithm. <ref type="figure" target="#fig_1">(Jiampojamarn et al., 2009)</ref> A HMM-like discriminative string transduction model that predicts the output transliteration using many-to-many alignments between the source word and target transliteration. Following <ref type="bibr" target="#b19">Jiampojamarn et al. (2009)</ref>, we use the m2m- aligner ( <ref type="bibr" target="#b21">Jiampojamarn et al., 2007</ref>) to generate the many-to-many alignments, and the public implementation of DirecTL+ to train models. <ref type="bibr">6</ref>  <ref type="figure" target="#fig_0">(Lin et al., 2016)</ref> A transliteration ap- proach that uses a language-independent entity linking system ( <ref type="bibr" target="#b12">Wang et al., 2015</ref>) to jointly cor- rect and re-rank the hypotheses produced by the generation model. We compare to both the uncon- strained inference (U) approach and the entity link- ing constrained inference (+EL) approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DirecTL+</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RPI-ISI</head><p>Seq2Seq w/ Att A sequence to sequence gener- ation model which uses soft attention as described in ( <ref type="bibr" target="#b1">Bahdanau et al., 2015)</ref>. This model does not enforce monotonicity at inference time, and serves as direct comparison for Seq2Seq(HMA).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>This section aims to analyze: (a) how effective is Seq2Seq(HMA) for transliteration generation when provided all available supervision ( §6.1)? and (b) how effective is the bootstrapping algo- rithm in the low-resource setting when only 500 examples are available ( §6.2)?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Full Supervision Setting</head><p>We compare Seq2Seq(HMA) with previous ap- proaches when provided all available supervision, to see how it fares under standard evaluation.</p><p>Results in the unconstrained inference (U) set- ting <ref type="table" target="#tab_4">(Table 2</ref> top 5 rows) shows Seq2Seq(HMA), denoted by "Ours", outperforms previous ap- proaches on Hindi, Kannada, and Bengali, with al- most 3-4% gains. Improvements over the Seq2Seq with Attention (Seq2Seq w/ Att) model demon- strate the benefit of imposing the monotonicity constraint in the generation model. On Tamil and Hebrew, Seq2Seq(HMA) is at par with the best approaches, with negligible gap (∼0.3) in scores. Overall, we see that Seq2Seq(HMA) can achieve better (and sometimes competitive) scores than state-of-the-art approaches in full supervision set- tings. When comparing approaches which use con- strained inference (  that using dictionary-constrained inference (as in Ours(DC)) is more effective than using a entity- linking model for re-ranking (RPI-ISI + EL).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Low-Resource Setting</head><p>In <ref type="table" target="#tab_4">Table 2</ref> (rows under "Low-Resource Setting"), we evaluate different models in a low-resource set- ting when provided only 500 name pairs as supervi- sion. Results are averaged over 5 different random sub-samples of 500 examples.</p><p>The results clearly demonstrate that all gener- ation models suffer a drop in performance when provided limited training data. Note that models like Seq2Seq with Attention suffer a larger drop than those which enforce monotonicity, suggesting that incorporating monotonicity into the inference step in the low-resource setting is essential. After bootstrapping our weak generation model using Al- gorithm 1, the performance improves substantially (last row in <ref type="table" target="#tab_4">Table 2</ref>). On almost all languages, the generation model improves by at least 6%, with performance for Hindi and Bengali improving by more than 10%. Bootstrapping results for the lan- guages are within 2-4% of the best model trained with all available supervision.</p><p>To better analyze the progress of the transliter- ation model during bootstrapping, we plot the ac- curacy@1 of the current transliteration model af- ter each bootstrapping iteration for each of the lan- guages (solid lines in <ref type="figure" target="#fig_1">Figure 2</ref>). For reference, we also show the best performance for a gener- ation model using all available supervision from §6.1 (dotted horizontal lines in <ref type="figure" target="#fig_1">Figure 2</ref>). From <ref type="figure" target="#fig_1">Figure 2</ref>, we can see that almost after 5 bootstrap- ping iterations, the generation model attains com- petitive performance to respective state-of-the-art models trained with full supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Error Analysis</head><p>Though our model is state of the art, it does present a few weaknesses. We have found that the dictionary sometimes misleads the model dur- ing constrained inference. For example, the cor- rect transliteration "vidyul" of the Hindi ववु ल, is not present in the dictionary, but another hypothe- sis "vidul" is. Another issue comes from the pro- portion of native (i.e., from the source language) and foreign (i.e., from English or other languages) names in the training data. It is usually not the case that the source and target scripts have the same transliteration rules. For example, य in Hindi might represent ya in English or Hindi names, but ja in German. Similarly, while अ should be a in Hindi names, it could be any of a few vowels in English. The NEWS2015 dataset does not report a native/foreign ratio, but by our estimation, it is about 70/30 for each language. This native and foreign names dichotomy are some of the inherent challenges in transliteration, that we discuss in de- tail in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Challenges Inherent to Transliteration</head><p>The fact that all models in <ref type="table" target="#tab_4">Table 2</ref> perform well or poorly on the same languages suggests that most of the observed performance variation is the result of factors intrinsic to the specific languages. Here we analyze some challenges that are inherent to the transliteration task, and explain why the per- formance ceiling is well under 100% for all lan- guages, and lower for languages like Tamil and He- brew than the others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Source and Target-Specific Issues</head><p>Source-Driven Some transliteration errors are due to ambiguities in the source scripts. For in- stance, the Tamil script uses a single character to denote {ta, da, tha, dha}, a single character for {ka, ga, kha, gha}, etc., while the rest of the Indian scripts have unique characters for each of these. Thus, names like Hartley and Hardley are entirely indistinguishable in Tamil but are distinguishable in the other scripts. We illustrate this problem by transliterating back and forth between Tamil and Hindi. When transliterating Hindi→Tamil, the model achieves an accuracy of 31%, which drops to 15% when transliterating Tamil→Hindi, sug- gesting that the Tamil script is more ambiguous. The Hebrew script also introduces error because it tends to omit vowels or write them ambigu- ously, leaving the model to guess between plau- sible choices. For example, the word ‫מלך‬ could be transliterated melech "king" just as easily as malach "he ruled." When Hebrew does write vow- els, it reuses consonant letters, again ambiguously. For example, ‫ה‬ can be used to express a or e, so ‫שמונה‬ can be either shmona or shmone "eight mas- culine/feminine". The script also does not reliably distinguish b from v or p from f, among others.</p><p>All languages run into problems when they are faced with writing sounds that they do not natively distinguish. For example, Hindi does not make a distinction between w and v, so both vest and west are written as वे ेट in its script.</p><p>These script-specific deficiencies explains why all models struggle on Tamil and Hebrew relative to the others. These issues cannot be completely resolved without memorizing individual source- target pairs and leveraging context.</p><p>Target-Driven Some errors arise from the chal- lenges presented by target script (here Latin script for English). To handle English's notoriously con- voluted orthography, a model has to infer silent let-  ters, decide whether to use f or ph for /f/; use k, c, ck, ch, or q for /k/, and so on. The problem is made worse because English is not the only language that uses Latin script. For example, German names like Schmidt should be written with sch instead of sh, and for French names like Margot and Margeau (which are pronounced the same), we have to re- sort to memorization. The arbitrariness extends into borrowings from the source languages as well.</p><p>For example, the Indian name Bangalore is writ- ten with a silent-e, and the name Lakshadweep con- tains ee, instead of the expected i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Disparity between Native and Foreign</head><p>All these issues come together to create a per- formance disparity between native names, which are well-integrated into the source language ety- mologically (Indian names like Jasodhara or Ra- manathan for Hindi), and foreign names (French Grenoble or Japanese Honshu for Hindi), which are not. The above datasets include an unspecified mix of native and foreign names. This is a prob- lem since any model must learn essentially sepa- rate transliteration schemes for each.</p><p>To quantify the effect of this, we annotate na- tive and foreign names in the test split of the four Indian languages, and evaluate performance for both categories. <ref type="table" target="#tab_7">Table 3</ref> shows that our model performs significantly better on native names for all the languages. A possible reason for is that the source scripts were designed for writing na- tive names (e.g., Tamil script lacks separate {ta, da, tha, dha} characters because the Tamil lan- guage does not distinguish these sounds). Further- more, foreign names have a wide variety of origins with their own conventions as discussed in §7.1. The performance gap is proportionally greatest for Tamil, likely due to its script.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Case Studies</head><p>In this section, we evaluate the practical utility of our approach in low-resource settings and for downstream applications through two case studies.</p><p>We first show that obtaining an adequate seed list is possible with a few hours of manual annotation ( §8.1) from a single human annotator. We then show the positive impact that our approach has on a downstream task, by evaluating its contribution to candidate generation for Tigrinya and Macedo- nian entity linking ( §8.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head><p>Monolingual  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Manual Annotation</head><p>The manual annotation exercises simulate a low- resource setting with only a single human annota- tor is available. We judge the usability of the anno- tations by training models on them and evaluating the models on test sets of 1000 names each, ob- tained from Wikipedia inter-language links. For bootstrapping experiments, we use the corpora shown in <ref type="table" target="#tab_9">Table 4</ref> to obtain foreign vocabulary V f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Languages Studied</head><p>We investigate perfor- mance on two languages: Armenian and Punjabi. Spoken in Armenia and Turkey, Armenian is an Indo-European language with no close relatives. It has Eastern and Western dialects with different spelling conventions. Armenian Wikipedia is pri- marily written in the Eastern dialect, while our an- notator was a native Western speaker. <ref type="bibr">7</ref> Punjabi is an Indic language from Northwest In- dia and Pakistan that is closely related to Hindi. Our annotator grew up primarily speaking Hindi.</p><p>Annotation Guidelines Annotators were given two tasks. First, they were asked to write two names and their English transliterations for each letter in the source script: one beginning with the letter and another containing it elsewhere. (e.g. "Julia" and "Benjamin" for the letter "j" if the source were English). The is done to ensure good coverage over the alphabet. Next, annotators were shown a list of English words and were asked to  provide plausible transliteration(s) into the target script. The list had a mix of recognizable foreign (e.g., Clinton, Helsinki) and native names (e.g., Sarkessian, Yerevan for Armenian).</p><p>We collected about 600 and 500 annotated pairs respectively for Armenian and Punjabi. <ref type="table" target="#tab_11">Table 5</ref> shows that the performance of the models trained on the annotated data is comparable to that on the standard test corpora for other languages. This show that our approach is robust to human incon- sistencies and regional spelling variations, and that obtaining an adequate seed list is possible with just a few hours of manual annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Candidate Generation (CG)</head><p>Since transliteration is an intermediate step in many downstream multilingual information extrac- tion tasks <ref type="bibr" target="#b9">(Darwish, 2013;</ref><ref type="bibr" target="#b23">Kim et al., 2012;</ref><ref type="bibr" target="#b18">Jeong et al., 1999;</ref><ref type="bibr" target="#b41">Virga and Khudanpur, 2003;</ref><ref type="bibr" target="#b5">Chen et al., 2006</ref>), it is possibly to gauge its performance extrinsically by the impact it has on such tasks. We use the task of candidate generation (CG), which is a key step in cross-lingual entity linking.</p><p>The goal of cross-lingual entity linking <ref type="bibr" target="#b31">(McNamee et al., 2011;</ref><ref type="bibr" target="#b38">Tsai and Roth, 2016;</ref><ref type="bibr" target="#b40">Upadhyay et al., 2018</ref>) is to ground spans of text written in any language to an entity in a knowledge base (KB). For instance, grounding <ref type="bibr">[Chicago]</ref> in the fol- lowing German sentence to Chicago_(band). 8</p><p>[Chicago] wird in Woodstock aufzutreten.</p><p>The role of CG in cross-lingual entity linking is to create a set of plausible entities given a string while ensuring the correct KB entity belongs to that set. For the above German sentence, it would provide a list of possible KB entities for the string Chicago: Chicago_(band), Chicago_(city), Chicago_(font), etc., so that entity linking can select the band. Foreign scripts pose an additional challenge for CG because they must be transliter- 8 Translation: Chicago will perform at Woodstock. ated before they are passed on to candidate gener- ation. For instance, any mention of "Chicago" in Amharic must first be transliterated from ሺካጎ.</p><p>Most approaches for CG use Wikipedia inter- language links to generate the lists of candi- dates <ref type="bibr" target="#b38">(Tsai and Roth, 2016)</ref>. While recent ap- proaches such as <ref type="bibr" target="#b39">Tsai and Roth (2018)</ref> have re- sorted to name translation for CG, they require over 10k examples for languages written in non- Latin scripts, which is prohibitive for low-resource languages with little Wikipedia presence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Candidate Generation with Transliteration</head><p>We evaluate the extent to which our approach im- proves recall of a naive CG baseline that generates candidates by performing exact name match. For each span of text to be linked (or query mention), we first check if the naive name matching strategy finds any candidates in the KB. If none are found, the query mention is back-transliterated to English, and at most 20 candidates are generated using a inverted-index from English names to KB entities. The evaluation metric is recall@20, i.e., if the gold KB entity is in the top 20 candidates. We use Tigrinya and Macedonian as our test languages.</p><p>Tigrinya is a South Semitic language related to Amharic, written in the Ethiopic script, and spo- ken primarily in Eritrea and northern Ethiopia. The Tigrinya Wikipedia has &lt;200 articles, so we use inter-language links (∼7.5k) from the Amharic Wikipedia instead to extract 1k name pairs for the seed set. We use the monolingual corpus in <ref type="table" target="#tab_9">Ta- ble 4</ref> for bootstrapping and evaluate on the unse- questered set provided under the NIST LoReHLT evaluation, containing 4,630 query mentions.</p><p>The Ethiopic script is an alphasyllabary, where each character is consonant-vowel pair. For exam- ple, the character መ is mä, ሚ with a tail is mi, and ሞ with a line is mo. With 26 consonants and 8 vow- els, this leads to a set of &gt;200 characters creating a sparsity problem since each character has its own Unicode code point. However, the code points are organized so that they can be automatically split <ref type="bibr">9</ref> into unique consonant and vowel codes without ex- plicitly understanding the script. We assign arbi- trary ASCII codes to each consonant and vowel so that መ/mä becomes "D 1" and ሞ/mo becomes "D 6." This consonant-vowel splitting (CV-split) re- duces the number of unique input characters to 55.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach Recall@20</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tigrinya</head><p>Name match (baseline) 31.   <ref type="table" target="#tab_9">Table 4</ref> is used for bootstrapping. <ref type="table" target="#tab_13">Table 6</ref> shows the results for the two languages. For Tigrinya, candidate generation with transliteration improves on the baseline by 4.2%. Splitting the characters (CV-split) gives another 5.7%, and adding boot- strapping gives 4.9% more. Our approach yields an overall 14.8% improvement in recall over the baseline, showing that we can effectively exploit the little available supervision by bootstrapping. Macedonian yields more dramatic results, where transliteration provides 38.6% improvement (more than double the baseline), with bootstrapping pro- viding another 4.6%. The differences between Tigrinya and Macedonian is likely due both to their test sets, corpora and writing systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Candidate Generation Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion and Future Work</head><p>We presented a new transliteration generation model, namely Seq2Seq(HMA), and a new boot- strapping algorithm that can iteratively improve a weak generation model using constrained discov- ery. The model presented here achieves state-of- the-art results on typical training set sizes, and more importantly, works well in a low-resource setting with the aid of the bootstrapping algorithm.</p><p>The key benefit of the bootstrapping approach is that it can "recover" most of the performance lost in the low-resource setting when little supervision is available by training with a smaller seed set, an English name dictionary, and a list of unannotated words in the target script. Additionally, our boot- strapping algorithm admits any generation model, giving it wide applicability. Through case studies, we showed that collecting an adequate seed list is practical with a few hours of annotation. The ben- efit of incorporating our transliteration approach in a downstream task, namely candidate genera- tion, was also demonstrated. Finally, we discussed some of the inherent challenges of learning translit- eration and the deficits of existing training sets. There are several interesting directions for fu- ture work. Performing model combination, either by developing hybrid transliteration models <ref type="bibr" target="#b33">(Nicolai et al., 2015)</ref> or by ensembling ( <ref type="bibr" target="#b13">Finch et al., 2016)</ref>, can further improve low resource translit- eration. Jointly leveraging similarities between re- lated languages, such as writing systems or pho- netic properties ( <ref type="bibr" target="#b27">Kunchukuttan et al., 2018)</ref>, also shows promise for low-resource settings. Our anal- ysis suggests value in revisiting "transliteration in context" approaches ( <ref type="bibr" target="#b14">Goto et al., 2003;</ref><ref type="bibr" target="#b16">Hermjakob et al., 2008)</ref>, especially for languages like Hebrew. We would also like to expand on the analyses pro- vided in §7 which uncover challenges inherent to the transliteration task, particularly the impact of the native/foreign distinction in the train and test data, the difficulties posed by specific scripts or pairs of scripts, and how these impact both back- and forward-transliteration. Recent work from Merhav and Ash (2018) suggests many useful anal- yses that we would like to incorporate.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Transliteration using Seq2Seq transduction with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Plot showing acc@1 after each bootstrapping iteration for Hindi, Kannada, Bengali, Tamil and Hebrew, starting with only 500 training pairs as supervision. For comparison, the acc@1 of a model trained with all available supervision is also shown (respective dashed lines, marked X-Full).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 : Cumulative number of person name pairs in</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Σ f . The characters are first en- coded using a embedding matrix W ∈ R |Σ f |×d to get character embeddings x 1 , x 2 , · · · , x n where each x i ∈ R d . These embeddings are fed into a bidirectional RNN encoder to generate encoded vectors h 1 , h 2 , · · · , h n where each h i ∈ R 2k , and k is the size of output vector of the forward (and backward) encoder. The encoded vectors h 1 , h 2 , · · · , h n are then fed into the decoder.0 h 1 h 2 h 3 h 4 h 5</head><label></label><figDesc></figDesc><table>word where each 
character x i ∈ Bidirectional LSTM 

h step t 
h a 
n 

step t 
h 
a 

sos 

sos 

n 

sos 
eos 

थ न 
स 
◌ो 

o 

o 
s 

s 

t 
h a 
n 
o 
s 

step 
step 
step 
step 

step 
step 
step 
step eos 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>1 , s 2 , · · · }, such that each s i ∈ Σ e ∪ {step}. The step ac- tion controls an attention position a, attending on input character x a , with encoded vector h a . Each action s i is embedded into s i ∈ R d using</head><label></label><figDesc></figDesc><table>Fig-
ure 1 illustrates the decoding process. The decoder 
RNN generates a sequence of actions {s a output 
embedding matrix A ∈ R (|Σe|+1)×d . At any time 
during decoding, the decoder uses its last hidden 
state, the embedding of the previous action s i and 
the encoded vector h a of the current attended po-
sition to generate the next action s i+1 . </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 ,</head><label>2</label><figDesc></figDesc><table>rows 6 and 7), we see 

6 https://code.google.com/p/directl-p 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Comparing different approaches on the NEWS 2015 

dataset using acc@1 as the evaluation metric. "Ours" denotes 
the Seq2Seq(HMA) model, with (.) denoting the inference 
strategy. Numbers for RPI-ISI are from Lin et al. (2016). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 3 : Acc@1 for native and foreign words for four lan-</head><label>3</label><figDesc></figDesc><table>guages ( §7.2). Ratio is native performance relative to foreign. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Corpora used for obtaining foreign vocabulary V f 

for bootstrapping in the case studies in  §8.1 and  §8.2. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Acc@1 using human annotated seed set and boot-

strapping the Seq2Seq(HMA) model. Both languages per-
form well relative to the other languages investigated so far. 
Both annotation sub-tasks took roughly the same time. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>4</head><label>4</label><figDesc></figDesc><table>Ours 
35.6 
Ours (CV-split) 
41.3 
Ours (CV-split) + Bootstrapping 
46.2 

Macedonian 

Name match (baseline) 
33.6 

Ours 
72.2 
Ours + Bootstrapping 
76.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Comparing candidate recall@20 for different ap-

proaches on Tigrinya and Macedonian. CV-split refers to 
consonant-vowel splitting. Using our transliteration genera-
tion model with bootstrapping yields the highest recall, im-
proving significantly over a name match baseline. 

Macedonian is a South Slavic language closely 
related to the languages of the former Yugoslavia 
and written in a local variant of the Cyrillic alpha-
bet similar to Serbian's. We use the Macedonian 
test set constructed by McNamee et al. (2011) con-
taining 1956 query mentions. A seed set of 1k 
name pairs was obtained from the inter-language 
Wikipedia links for Macedonian, and the monolin-
gual corpus from </table></figure>

			<note place="foot" n="2"> All generative approaches are also capable of discovery, by using the posterior P(y | x) to select the most likely candidate transliteration, while the opposite is not true.</note>

			<note place="foot" n="3"> Many Indic scripts, that sometimes write vowels before the consonants they are pronounced after, seem to violate this claim, but Unicode representations of these scripts actually preserve the consonant-vowel order.</note>

			<note place="foot" n="4"> Test set was not available since shared task concluded. 5 github.com/pytorch</note>

			<note place="foot" n="7"> The annotator produced Western Armenian which was mechanically mapped to &quot;Eastern&quot; by swapping five Armenian character pairs: դ/տ, պ/բ , ք/կ , ձ/ծ, ճ/ջ</note>

			<note place="foot" n="9"> Consonant = Unicode / 8; Vowel = Unicode % 8</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Mitch Marcus, Snigdha Chaturvedi, Stephen Mayhew, Nitish Gupta, Dan Deutsch, and the anonymous reviewers for their useful comments. We are grateful to the Armenian and Punjabi annotators for help with the case studies.</p><p>This work was supported under DARPA LORELEI by Contract HR0011-15-2-0025, Agreement HR0011-15-2-0023 with DARPA, and an NDSEG fellowship for the second author. Ap-proved for Public Release, Distribution Unlimited. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Morphological Inflection Generation with Hard Monotonic Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roee</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised Constraint Driven Learning For Transliteration Discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuancheng</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Guiding Semi-Supervision with Constraint-Driven Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Structured Learning with Constrained Conditional Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="399" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Translating-Transliterating Named Entities for Multilingual Information Access</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Cheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Hao</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning Phrase Representations using RNN EncoderDecoder for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Fethi Bougares, Holger Schwenk, and Yoshua Bengio</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The SIGMORPHON 2016 Shared TaskMorphological Reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 14th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
		<meeting>of the 14th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Jason Eisner, and Mans Hulden</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Paradigm Completion for Derivational Morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kareem</forename><surname>Darwish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><forename type="middle">E</forename><surname>Banchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumaran</surname></persName>
		</author>
		<title level="m">Proc. of the Fifth Named Entity Workshop</title>
		<meeting>of the Fifth Named Entity Workshop</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Morphological Inflection Generation Using Character Sequence to Sequence Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural Network Transduction Models in Transliteration Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Finch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lemao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Fifth Named Entity Workshop</title>
		<meeting>of the Fifth Named Entity Workshop</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Target-Bidirectional Neural Models for Machine Transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Finch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lemao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Sixth Named Entity Workshop</title>
		<meeting>of the Sixth Named Entity Workshop</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Transliteration Considering Context Information based on the Maximum Entropy Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isao</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoto</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noriyoshi</forename><surname>Uratani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terumasa</forename><surname>Ehara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of MT-Summit IX</title>
		<meeting>of MT-Summit IX</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">125132</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Joint Source-Channel Model for Machine Transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Haizhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Jian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Name Translation in Statistical Machine Translation-Learning When to Transliterate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-HLT</title>
		<meeting>of ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transliterating from All Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AMTA</title>
		<meeting>of AMTA</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic Identification and Back-Transliteration of Foreign Words for Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung-Hyon</forename><surname>Kil Soon Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><forename type="middle">Sung</forename><surname>Myaeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K-S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="523" to="540" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">DirecTL: A Language-Independent Approach to Transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Sittichai Jiampojamarn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2009 Named Entities Workshop: Shared Task on Transliteration</title>
		<meeting>of the 2009 Named Entities Workshop: Shared Task on Transliteration</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Transliteration Generation and Mining with Limited Training Resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sittichai</forename><surname>Jiampojamarn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mi-Young</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2010 Named Entities Workshop</title>
		<meeting>of the 2010 Named Entities Workshop</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Applying Many-to-Many Alignments and Hidden Markov Models to Letter-to-Phoneme Conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Sittichai Jiampojamarn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarek</forename><surname>Kondrak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sherif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarvnaz</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Falk</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Turpin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Transliteration Survey. ACM Computing Surveys</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungchul</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Named Entity Transliteration and Discovery in Multilingual Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Klementiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning Machine Translation</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Machine Transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Graehl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="599" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Leveraging Orthographic Similarity for Multilingual Neural Transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Kunchukuttan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitesh</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gurneet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Leveraging Entity Linking and Related Language Projection to Improve Name Transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliya</forename><surname>Deri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Sixth Named Entity Workshop</title>
		<meeting>of the Sixth Named Entity Workshop</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Align and Copy: UZH at SIGMORPHON 2017 Shared Task for Morphological Reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Makarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Ruzsics</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection</title>
		<meeting>of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Machine Transliteration of Proper Names</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Matthews</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<pubPlace>Edinburgh, United Kingdom</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">CrossLanguage Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David S</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IJCNLP</title>
		<meeting>of IJCNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Design Challenges in Named Entity Transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Merhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Ash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multiple System Combination for Transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrett</forename><surname>Nicolai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Hauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Salameh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>St Arnaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Fifth Named Entity Workshop</title>
		<meeting>of the Fifth Named Entity Workshop</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning Better Transliterations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Pasternack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning Phoneme Mappings for Transliteration without Parallel Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Named Entity Transliteration with Comparable Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Sproat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING-ACL</title>
		<meeting>of COLING-ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Cross-lingual Wikification Using Multilingual Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning Better Name Translation for Cross-Lingual Wikification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AAAI</title>
		<meeting>of AAAI</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Joint Multilingual Supervision for Cross-lingual Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Transliteration of Proper Names in Cross-lingual Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Virga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop on Multilingual and Mixed-Language Named Entity Recognition</title>
		<meeting>of the Workshop on Multilingual and Mixed-Language Named Entity Recognition</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
