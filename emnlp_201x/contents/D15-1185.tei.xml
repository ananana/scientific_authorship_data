<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recognizing Textual Entailment Using Probabilistic Inference</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Sha</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingsong</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Recognizing Textual Entailment Using Probabilistic Inference</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recognizing Text Entailment (RTE) plays an important role in NLP applications including question answering, information retrieval, etc. In recent work, some research explore &quot;deep&quot; expressions such as discourse commitments or strict logic for representing the text. However, these expressions suffer from the limitation of inference inconvenience or translation loss. To overcome the limitations, in this paper, we propose to use the predicate-argument structures to represent the discourse commitments extracted from text. At the same time, with the help of the YAGO knowledge , we borrow the distant supervision technique to mine the implicit facts from the text. We also construct a probabilistic network for all the facts and conduct inference to judge the confidence of each fact for RTE. The experimental results show that our proposed method achieves a competitive result compared to the previous work.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For the natural language, a common phenomenon is that there exist a lot of ways to express the same or similar meaning. To discover such dif- ferent expressions, the Recognising Textual En- tailment (RTE) task is proposed to judge whether the meaning of one text (denoted as H) can be in- ferred (entailed) from the other one (T )( <ref type="bibr">Dagan et al., 2006</ref>). For many natural language processing applications like question answering, information retrieval which involve the diversity of natural lan- guage, recognising textual entailments is a critical step.</p><p>PASCAL Recognizing Textual Entailment (RTE) Challenges ( <ref type="bibr">Dagan et al., 2006</ref>) have witnessed a variety of excellent systems which intend to recognize the textual entailment in- stances. These systems mainly employ "shallow" techniques, including heuristics, term overlap, syntactic dependencies( <ref type="bibr" target="#b6">Vanderwende et al., 2006</ref>; Jijkoun and de <ref type="bibr">Rijke, 2005;</ref><ref type="bibr">Malakasiotis and Androutsopoulos, 2007;</ref><ref type="bibr">Haghighi et al., 2005</ref>). As Hickl (2008) stated, the shallow approaches do not work well for long sentences for the missing of underlying information which needs to be mined from the surface level expression.</p><p>Recently, some deep techniques are developed to mine the facts latent in the text. <ref type="bibr">Hickl (2008)</ref> proposed the concept of discourse commitments which can be seen as the set of propositions in- ferred from the text, and used a series of syntax- level and semantic-level rules to extract the com- mitments from the T -H pairs. Then the RTE task is reduced to the identification of the commitments from T which are most likely to support the infer- ence of the commitments from H. From the work of <ref type="bibr">Hickl (2008)</ref>, we can see that a deep under- standing of text is critical to the RTE performance and discourse commitments can serve a good me- dia to understanding text. However, the limitation of Hickl (2008)'s work is, the extracted discourse commitments are still from the original text and do not explore the implicit meaning latent behind the text.</p><p>Another kind of deep methods involves first transferring natural language to logic represen- tation and then conducting strict logic inference based on the logic representations ( <ref type="bibr">de Salvo Braz et al., 2006</ref>; <ref type="bibr" target="#b5">Tatu and Moldovan, 2006;</ref><ref type="bibr" target="#b8">Wotzlaw and Coote, 2013)</ref>. Through logic inference, some implicit knowledge behind the text can be mined. However, it is not easy to translate the natural lan- guage text into formal logic expressions and the translation process inevitably suffer from great in- formation loss.</p><p>Through analysis above, in our work, we pro- 1620  Ayrton Senna was married to a doctor who lives in Austin, the capital of Texas, in 1998.</p><p>We translate this example into the predicate- argument structures such as bemarried(Senna, doctor), livein(doctor, Austin), captial(Austin, Texas). Then through distant supervision, we can get some new facts livein(Senna, Austin), livein(Senna, Texas).</p><p>To judge the confidence of the new facts, we construct a probabilistic network with all the facts and adopt the Markov Logic Network (MLN) to calculate the probability of each new fact, which can be further used to recognize text entailments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our RTE System</head><p>To make full use of the underlying information in sentences and lessen the effect brought by natu- ral language's vagueness, we design a RTE sys- tem which is composed of three stages, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>First, we decompose the sentences in T -H pair to a series of discourse commitments as Hickl (2008) did. Since the syntax of these commit- ments are very simple, we can directly transform them to predicates (or 3-arg tuples). Then we use YAGO, a large semantic database including sev- eral thousands relations, to provide distant super- vision. The predicates in T are matched to YAGO facts due to some metrics. At last, we use the Markov Logic Network(MLN) ( <ref type="bibr" target="#b3">Richardson and Domingos, 2006</ref>) to infer the correctness of the predicates in H. The MLN is constructed us- ing the inference rules ("soft" rules) generated by AMIE system (Galárraga et al., 2013) on YAGO. Each rule has a weight which should be trained by real world facts. Using this framework, we can ap- ply the "soft" logic to the textual entailment recog- nition task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Extracting Predicates from Sentences</head><p>Discourse commitment is our baseline system pro- posed by <ref type="bibr">Hickl (2008)</ref> which can decompose one sentence to a series of shorter and simpler sen- tences which completely contain the origin sen- tence's information. One of the advantages of discourse commitments is that it can use a lot of syntax-level and semantic level rules to extract the underlying information of one sentence. For ex- ample, the following T -H pair can be decomposed as <ref type="figure">Figure 2</ref>. The discourse commitments of T con- tains the information: Ayrton Senna married in 1998, which is not easy to be captured by "shal- low" methods.</p><p>T : Ayrton Senna was married to a doctor who lives in Austin, the capital of Texas, in 1998.</p><p>H : Ayrton Senna lives in Texas.</p><p>Since we need to infer new facts using the ex- tracted commitments, we transfer all the commit-Text: Ayrton Senna was married to a doctor who lives in Austin, the capital of Texas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T1. Ayrton Senna was married to a doctor</head><p>T2.</p><p>[The] doctor lives in Austin</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T3. Austin [is] the capital of Texas</head><p>Hypothesis: Ayrton Senna lives in Texas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2: Text Commitments Example</head><p>Text: Ayrton Senna was married to a doctor who lives in Austin, the capital of Texas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T1. bemarriedTo(Ayrton Senna,Doctor)</head><p>T2. livein(Doctor, Austin) T3. beCapitalof(Austin, Texas)</p><p>Hypothesis: Ayrton Senna lives in Texas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H1. livein(Ayrton Senna, Texas)</head><p>Figure 3: Text Predicates Example ments to predicates. For example, the commit- ments in <ref type="figure">Figure 2</ref> can be transformed to the pred- icates (or triples) shown in <ref type="figure">Figure 3</ref>. We use RE- VERB <ref type="bibr">(Fader et al., 2011</ref>) to extract the triples (predicate + 2 Arguments). To make the infer- ence process in the next section more convenient, we order that all of the arguments should be NPs. Therefore, we check if the arguments in the triples contain or have overlap with any of the NPs, re- place it with that NP, and the predicates are suc- cessfully extracted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Distant supervision with YAGO</head><p>The goal of distant supervision is to use the knowl- edge of YAGO ( <ref type="bibr" target="#b0">Mahdisoltani et al., 2014</ref>) to help the textual entailment recognition task. The facts in YAGO have various type of connections with each other. We think this connection is very useful for RTE. Therefore, the predicates in the T -H pair should be matched to the YAGO facts for making advantage of the connection information. Since YAGO is very large, the common predi- cates can easily matched to YAGO facts in most cases. However, YAGO cannot contain every predicate in T . We run DIRT ( <ref type="bibr">Lin and Pantel, 2001</ref>) system on 1GB text random sampled from Gigaword corpus and for each predicate we choose the top-10 similar predicates as its synony- mous predicate. If the origin predicate cannot be found in YAGO, we instead check for the top-10 similar predicates. If we still cannot find a match, that means this predicate has very little connection with other predicates and cannot be supervised by YAGO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Probabilistic Inference</head><p>The goal of MLN ( <ref type="bibr" target="#b3">Richardson and Domingos, 2006</ref>) is to implement the probabilistic inference, or "soft" logic inference. MLN is constructed by an inference rule base. Each rule has a weight which needs to be well trained by real word facts. We use AMIE to mine inference rules from YAGO. AMIE 1 ( <ref type="bibr">Galárraga et al., 2013</ref>) is a state-of- the-art inference rule mining system. The motiva- tion of AMIE is that KBs themselves often already contain enough information to derive and add new facts. If, for example, a KB contains the fact that a child has a mother, then the mother's husband is most likely the father.</p><formula xml:id="formula_0">motherOf (m, c)∧marriedT o(m, f ) ⇒ f atherOf (f, c)</formula><p>AMIE can mine such inference rules from large KBs. The inference rules can be directly used for constructing Markov logic network in the next sec- tion. In addition, the process of mining inference rules is quite efficient so that it is very helpful for our RTE task.</p><p>We use AMIE only to extract the inference rules. After the inference rules are prepared, we can construct a MLN. We give the related facts in YAGO to the MLN, then the weights of each infer- ence rule can tune to a best fit for these facts. After the weights of each inference rule are well trained, the MLN is well prepared to use. Given the pred- icates in T , we first select all the related rules to construct a simple MLN, and then give the MLN some facts. After that, the MLN will calculate the probabilities of the unknown new facts. The ar- guments of the new facts are the permutations of all the ground atoms (or entities). For example, if we give the facts "hasChild (Cliton, Chelsea)" and "IsMarriedto (Cliton, Hillary)", the MLN will out- put the probability of "hasChild (Cliton, Hillary)", "hasChild (Hillary, Chelsea)", "IsMarriedto (Cli- ton, Chelsea)", etc. Obviously, the probability of "hasChild (Hillary, Chelsea)" may be the highest, so that it is most likely to be true. The MLN constructing and inferring can be implemented by Approach Accuracy Term overlap ( <ref type="bibr" target="#b9">Zanzotto and Moschitti, 2006)</ref> 67.50% Graph Matching ( <ref type="bibr">MacCartney et al., 2006)</ref> 65.33% Classification-Based ( <ref type="bibr">Hickl et al., 2006)</ref> 77.00% Discourse Commitment <ref type="bibr">(Hickl, 2008)</ref> 84.93% Strict logic ( <ref type="bibr" target="#b5">Tatu and Moldovan, 2006)</ref> 71.59% Our Framework 85.16% <ref type="table">Table 1</ref>: Performance of Inference based RTE Alchemy 2 , which provides a series of algorithms for statistical relational learning and probabilistic logic inference, based on the Markov logic repre- sentation.</p><p>After the new facts are inferred, we check if these facts can cover the predicates in H. If so, we decide T entails H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head><p>We evaluate the performance of our framework for RTE on the PASCAL RTE-2 3 and RTE-3 4 datasets, which has 1600 examples. We use the YAGO2 for aligning predicates and mining infer- ence rules. YAGO2 contains more than 940K facts and about 470K entities. We run the AMIE sys- tem on YAGO2 for only one time to get all infer- ence rules (about more than 1.8K in total). For each T -H pair, we only choose a portion of re- lated inference rules to construct MLN. The cho- sen rules must contain at least one predicate which occurred in the predicates of T -H pair. We only use the MLN to infer when the discourse commit- ment paraphrasing cannot identify a T -H pair as "Entailment", which is a back-off method.</p><p>We compare our result with 5 baseline systems: (1) <ref type="bibr" target="#b9">Zanzotto and Moschitti (2006</ref>  <ref type="table">Table 1</ref>. Since we only need to judge "Yes" or "No" for the 1600 examples, the precision is equal to the recall, so that we only report the precision.</p><p>According to the <ref type="table">Table 1</ref>, the performance of our framework is higher than Hickl (2008)'s base- line, which is significant (Wilcoxon signed-rank test, p &lt; 0.05). The reason is that we have added the inference portion to <ref type="bibr">Hickl (2008)</ref>'s method. Therefore, some T -H pairs which had to be judged by semantic reasoning can be corrected by our framework. For instance, T is "Hughes loved his wife, Gracia, and was absolutely ob- sessed with his little daughter Elicia." and H is "Gracia's daughter is Elicia." It is not easy for the former baselines to recognize this entailment, but our framework can easily recognize it to be "true". In this way, our framework has achieved a higher result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related work</head><p>Textual Entailment Recognizing (RTE) task has been widely studied by many previous works. Firstly, the method based on similarity and over- lap ( <ref type="bibr">Malakasiotis and Androutsopoulos, 2007</ref>; Ji- jkoun and de <ref type="bibr">Rijke, 2005;</ref><ref type="bibr" target="#b7">Wan et al., 2006</ref>). This kind of methods can help solve the paraphrase recognition problem, which is a subset of RTE. Another important similarity-based method is tree kernel ( <ref type="bibr" target="#b9">Zanzotto and Moschitti, 2006</ref>), which rely on the cross-pair similarity between two pairs (T , H ) and (T , H ).</p><p>Secondly, some approaches extract the knowl- edge in T -H pair and check if the knowledge in T contains the knowledge in H. <ref type="bibr">Hickl (2008)</ref> trans- formed the T -H pair into discourse commitments, reducing the RTE task to the identification of the commitments from a T which support the infer- ence of the H. Other works map the text to logical meaning representations, and then strict logic en- tailment methods, possibly by invoking theorem provers.</p><p>Thirdly, some works make use of statistical classifiers which leverages a wide variety of fea- tures. The language expression of each T -H pair are represented by a feature vector</p><formula xml:id="formula_1">f 1 , f 2 · · · f m .</formula><p>The feature vector contains the scores of different similarity measures applied to the pair, and possi- bly other features.</p><p>There are also other works based on predicate- argument representations with Markov Logic for RTE, such as <ref type="bibr" target="#b4">Rios et al. (2014)</ref> and <ref type="bibr">Beltagy et al. (2013)</ref>. However, they did not use discourse com- mitments to extract predicate-argument triples, which may lead to severe information loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper introduced a new framework to solve the Textual Entailment Recognizing task. This framework makes full use of Markov logic net- work for probabilistic inference. We hold that probabilistic inference is better than strict logic method since transforming from language form to strict logic form could lose a lot of informa- tion. Therefore it is extremely hard for the theo- rem provers to perform well.</p><p>In addition, we use YAGO database for distant supervision. The predicates extracted from T -H pair are first aligned with YAGO. If it succeeds, the inference procedure of MLN will become much more accurate. In addition, the inference rules for constructing MLN are also extracted from YAGO database using AIME system. This framework can correctly recognize the en- tailment T -H pairs which must be judged using inference. This is our improvement over the pre- vious work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Framework of our RTE system</figDesc><graphic url="image-40.png" coords="2,190.16,163.18,141.44,67.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>)'s simple term- overlap measure, (2) MacCartney et al. (2006)'s semantic graph-mapping approach, (3) Hickl et al. (2006)'s classification-based term alignment ap- proach. (4) Hickl (2008)'s discourse commitment based Alignment, (5) Tatu and Moldovan (2006)'s strict logic based method. The comparison of the 5 baselines and our framework is shown in</figDesc></figure>

			<note place="foot" n="1"> http://www.mpi-inf.mpg.de/departments/databases-andinformation-systems/research/yago-naga/amie/</note>

			<note place="foot" n="2"> http://alchemy.cs.washington.edu/ 3 http://pascallin.ecs.soton.ac.uk/Challenges/RTE2/ 4 http://pascallin.ecs.soton.ac.uk/Challenges/RTE3/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Yago3: A knowledge base from multilingual wikipedias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farzaneh</forename><surname>Mahdisoltani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th Biennial Conference on Innovative Data Systems Research. CIDR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning textual entailment using svms and string similarity measures</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</title>
		<meeting>the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="42" to="47" />
		</imprint>
		<respStmt>
			<orgName>Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
	<note>Prodromos Malakasiotis and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Markov logic networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="107" to="136" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Statistical relational learning to recognise textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Mitkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="330" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A logicbased semantic approach to recognizing textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL on Main conference poster sessions</title>
		<meeting>the COLING/ACL on Main conference poster sessions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="819" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Microsoft research at rte-2: Syntactic contributions in the entailment task: an implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second PASCAL Challenges Workshop</title>
		<meeting>the Second PASCAL Challenges Workshop</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Arul Menezes, and Rion Snow</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using dependency-based features to take the para-farce out of paraphrase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cécile</forename><surname>Paris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian Language Technology Workshop</title>
		<meeting>the Australasian Language Technology Workshop</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A logicbased approach for recognizing textual entailment supported by ontological background knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Wotzlaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Coote</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.4938</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic learning of textual entailments with cross-pair similarities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Massimo</forename><surname>Zanzotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on computational linguistics and the 44th Annual meeting of the Association for computational linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
