<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recall Error Analysis for Coreference Resolution</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
							<affiliation key="aff0">
								<address>
									<postCode>69118</postCode>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
							<affiliation key="aff0">
								<address>
									<postCode>69118</postCode>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Recall Error Analysis for Coreference Resolution</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2070" to="2081"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a novel method for coreference resolution error analysis which we apply to perform a recall error analysis of four state-of-the-art English coreference resolution systems. Our analysis highlights differences between the systems and identifies that the majority of recall errors for nouns and names are shared by all systems. We characterize this set of common challenging errors in terms of a broad range of lexical and semantic properties.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Coreference resolution is the task of determining which mentions in a text refer to the same entity. State-of-the-art approaches include both learning- based <ref type="bibr" target="#b9">(Fernandes et al., 2012;</ref><ref type="bibr" target="#b4">Björkelund and Farkas, 2012;</ref><ref type="bibr" target="#b8">Durrett and Klein, 2013</ref>) and de- terministic models ( <ref type="bibr" target="#b12">Lee et al., 2013;</ref><ref type="bibr" target="#b15">Martschat, 2013)</ref>. These approaches achieve state-of-the-art performance mainly relying on morphosyntactic and lexical factors. However, consider the follow- ing example.</p><p>In order to improving the added value of oil products, the second phase project of the Qinghai Petroleum Bureau's Ge'ermu oil refinery has been put into production. This will further improve the factory's oil products structure.</p><p>Due to the lack of any string overlap, most state-of-the-art systems will miss the link between the factory and the Qinghai Petroleum Bureau's Ge'ermu oil refinery. The information that factory is a hypernym of refinery, however, may be useful to resolve such links.</p><p>The aim of this paper is to quantify and char- acterize such recall errors made by state-of-the- art coreference resolution systems. By doing so, we provide a solid foundation for work on em- ploying knowledge sources for improving recall for coreference resolution ( <ref type="bibr" target="#b19">Ponzetto and Strube, 2006;</ref><ref type="bibr" target="#b24">Rahman and Ng, 2011;</ref><ref type="bibr" target="#b25">Ratinov and Roth, 2012;</ref><ref type="bibr" target="#b2">Bansal and Klein, 2012</ref>, inter alia). In par- ticular, we make the following contributions:</p><p>We present a novel framework for coreference resolution error analysis. This yields a formal foundation for previous work on link-based error analysis <ref type="bibr" target="#b29">(Uryupina, 2008;</ref><ref type="bibr" target="#b15">Martschat, 2013)</ref> and complements work on transformation-based error analysis ( <ref type="bibr" target="#b10">Kummerfeld and Klein, 2013)</ref>.</p><p>We apply the method proposed in this paper to perform a recall error analysis of four state-of- the-art systems, encompassing deterministic and learning-based approaches. In particular, we iden- tify and characterize a set of challenging errors common to all systems, and discuss strengths and weaknesses of each system regarding specific er- ror types. We also present a brief precision error analysis.</p><p>A toolkit which implements the framework pro- posed in this paper is available for download. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Link-Based Analysis Framework</head><p>In this section we discuss challenges in corefer- ence resolution error analysis and devise an error analysis framework to overcome these challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Motivation</head><p>Suppose a document contains the entity BARACK OBAMA, which is referenced by four mentions in the following order: Obama, he, the president and his. A typical output of a current system not equipped with world knowledge will consist of two entities: {Obama, he} and {the president, his} Obviously, the system made a recall error. But, due to the complex nature of the coreference reso- lution task, it is not clear how to represent the re-    Figure 1: (a) a reference entity r, represented as a complete one-directional graph, (b) a set S of three system entities, (c) the partition r S , (d) a spanning tree for r.</p><p>call error: is it missing the link between the pres- ident and Obama? Can the error be attributed to deficiencies in pronoun resolution?</p><p>Linguistically motivated error representations would facilitate both understanding of current challenges and make system development faster and easier. The aim of this section is to devise such representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Formalizing Coreference Resolution</head><p>To start with, we give a formal description of the coreference resolution task following the termi- nology used for the ACE ( <ref type="bibr" target="#b16">Mitchell et al., 2004</ref>) and OntoNotes ( <ref type="bibr" target="#b32">Weischedel et al., 2013</ref>) projects. A mention is a linguistic realization of a reference to an entity. Two mentions corefer if they refer to the same entity. Hence, coreference is reflexive, symmetric and transitive, and therefore an equiva- lence relation. The task of coreference resolution is to predict equivalence classes of mentions in a document according to the coreference relation.</p><p>In order to extract errors, we need to compare the reference equivalence classes, given by the annotation, with the system equivalence classes obtained from system output. The key question now is how we represent these equivalence classes of mentions. Adapting common terminology, we also refer to the equivalence classes as entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Representing Entities</head><p>The most straightforward entity representation ig- nores any structure and models an entity as a set of mentions. This representation was utilized for error analysis by <ref type="bibr" target="#b10">Kummerfeld and Klein (2013)</ref>, who extract errors by transforming reference into system entities. In this set-based representation, we can only extract whether two mentions corefer at all. More fine-grained information, for example about antecedent information, is not accessible.</p><p>We therefore propose to employ a structured en- tity representation, which explicitly models links established by the coreference relation between mentions. This leads to a link-based error repre- sentation which formalizes the methods presented in <ref type="bibr" target="#b29">Uryupina (2008) and</ref><ref type="bibr" target="#b15">Martschat (2013)</ref>.</p><p>We employ for representation a complete one- directional graph. That is, we represent an en- tity e over mentions {m 1 , . . . , m n } as a graph e = (N, A), where N = {m 1 , . . . , m n } and A = {(m k , m j ) | k &gt; j}. The indices respect the mention ordering. Mentions earlier in the text have a lower index. An example graph for an en- tity over four mentions m 1 , . . . , m 4 (such as the BARACK OBAMA entity) is depicted in <ref type="figure">Figure 1a</ref>. In this graph, we express all coreference relations between all pairs of mentions. <ref type="bibr">2</ref> Using this representation, we can represent a set of entities as a set of graphs. In particular, given a document we consider the set of reference entities R given by the annotation, and the set of system entities S, given by the system output. In order to extract errors, we compare the graphs in R with the graphs in S.</p><p>In the following, we discuss how to compute re- call errors for a reference entity r ∈ R with respect to the system entities S. For computing precision errors, we just switch the roles of R and S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Comparing Reference and System Entities</head><p>As we represent entities as sets of links between mentions, errors can be quantified as differences in the links. For example, if an edge (representing a link) from some reference entity r ∈ R is missing in all system entities in S, this is a recall error. In order to formalize this, we employ the notion of a partition of an entity. Let r ∈ R be some ref- erence entity, and let S be a set of system entities. The partition of r by S, written r S , is obtained by taking all edges in r that also appear in S. r S consists of all connected components of r (we will refer to these as subentities) that are also in S. All edges in r that are not in r S are candidates for re- call errors, as these were not in any entity in S. <ref type="figure">Figure 1b</ref> shows a set S of three system entities: two consist of two mentions, one of three men- tions. In our running example, this corresponds to the system output {Obama, he} and {the pres- ident, his} plus some spurious mentions, which are colored gray. The graph r S for our example is shown in <ref type="figure">Figure 1c</ref>. The two edges correspond to the correctly recognized links (he, Obama) and (his, the president). All edges in r <ref type="figure">(Figure 1a</ref>) missing from this graph are candidates for errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Spanning Trees</head><p>However, taking all edges in r missing in r S as er- rors leads to unintuitive results. In the BARACK OBAMA example, this would lead to four errors being extracted: (the president, Obama), (his, Obama), (the president, he) and (his, he). But, in order to correctly predict the BARACK OBAMA entity, a coreference resolution system only needs to predict three correct links, i.e. it has to provide a spanning tree of the entity's graph representation.</p><p>Therefore, to extract errors, we compute a span- ning tree T r of r, and take all edges in T r that do not appear in r S as errors. <ref type="figure">Figure 1d</ref> shows an ex- ample spanning tree for the running example en- tity r. The dashed edge, which corresponds to the link (the president, Obama), does not appear in r S and is therefore extracted as an error.</p><p>The strategies for computing a spanning tree may differ for recall and precision errors. Hence, our extraction algorithm is parametrized by two procedures ST rec (e, P ) and ST prec (e, P ) which, given an entity e and a set of entities P , output a spanning tree T e of e. The whole algorithm for error extraction is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Spanning Tree Algorithms</head><p>In the last section we presented a framework for link-based error analysis, which extracts errors by comparing entity spanning trees to entity parti- tions. Therefore we can accommodate different Algorithm 1 Error Extraction from a Corpus Input: A corpus C, algorithms ST rec , ST prec for computing spanning trees.</p><formula xml:id="formula_0">function ERRORS(C, ST rec , ST prec ) recall errors = [ ] precision errors = [ ] for d ∈ C do</formula><p>Let R d be the reference entities and S d be the system entities of document d.</p><formula xml:id="formula_1">for r ∈ R d do Add all edges in ST rec (r, S d ) not in r S d to recall errors. for s ∈ S d do Add all edges in ST prec (s, R d ) not in s R d to precision errors.</formula><p>Output: recall errors, precision errors notions of errors by varying the algorithm for com- puting spanning trees. We now present some span- ning tree algorithms for extracting recall and pre- cision errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Recall Errors</head><p>We first observe that for error extraction, the struc- ture of the spanning trees of the subentities appear- ing in r S does not play a role. Edges present in r S are not candidates for errors, since they appear in both the reference entity r and the system output S. Therefore, it does not matter which edges from the subentities are in the spanning tree. Hence, to build the spanning tree, we first choose arbitrary spanning trees for the subentities in the partition. We choose the remaining edges according to the spanning tree algorithm.</p><p>Having settled on this, we only have to decide which edges to choose that connect the trees rep- resenting the subentities. There are many possible choices for this. For example, the graph in Fig- ure 1c has four candidate edges which connect the trees for the subentities.</p><p>We can reduce the number of candidate edges by only considering the first mention (with respect to textual order) in a subentity as the source of an edge to be added. This makes sense since all other mentions in that subentity were correctly re- solved to be coreferent with some preceding men- tion. We still have to decide on the target of the edge. In <ref type="figure">Figure 1c</ref>, we have two choices for edges: (m 3 , m 1 ) and (m 3 , m 2 ). We now present two methods for choosing edges.</p><p>Choosing Edges by Distance. The most straight-forward way to decide on an edge is to take the edge with smallest mention distance between source and target. This is the approach taken by <ref type="bibr" target="#b15">Martschat (2013)</ref>.</p><p>Choosing Edges by Accessibility. However, the distance-based approach may lead to unintuitive results. Let us consider again the BARACK OBAMA example from <ref type="figure">Figure 1</ref>. When choosing edges by distance, we would extract the error (the president, he). However, such links with a non- pronominal anaphor and a pronominal antecedent are difficult to process and considered unreliable ( <ref type="bibr" target="#b17">Ng and Cardie, 2002;</ref><ref type="bibr" target="#b3">Bengtson and Roth, 2008)</ref>. On the other hand, the missed link (the president, Obama) constitutes a well-defined hyponymy re- lation which can be found in knowledge bases and is easily interpretable by humans.</p><p>Uryupina <ref type="bibr" target="#b28">(Uryupina, 2007;</ref><ref type="bibr" target="#b29">Uryupina, 2008</ref>) presents a recall error analysis where she takes the "intuitively easiest" missing link to analyze <ref type="bibr">(Uryupina, 2007, p. 196)</ref>. How can we formal- ize such an intuition? We will employ a no- tion grounded in accessibility theory <ref type="bibr" target="#b0">(Ariel, 1988)</ref>. Names and nouns refer to less accessible entities than pronouns do. For such anaphors, we prefer descriptive (name/nominal) antecedents. Inspired by Ariel's degrees of accessibility, we choose a target for a given anaphor m i as follows:</p><p>• If m i is a pronoun, choose the closest preced- ing mention.</p><p>• If m i is not a pronoun, choose the closest preceding proper name. If no such mention exists, choose the closest preceding common noun. If no such mention exists, choose the closest preceding mention. Applied to the example from <ref type="figure">Figure 1</ref>, this algo- rithm extracts the error (the president, Obama). <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Precision Errors</head><p>Virtually all approaches to coreference resolu- tion obtain entities by outputting pairs of anaphor and antecedent, subject to the constraint that one anaphor has at most one antecedent.</p><p>We use this information to build spanning trees for system entities: these spanning trees con- sist of exactly the edges which correspond to anaphor/antecedent pairs in the system output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data and Systems</head><p>We now discuss data and coreference resolution systems which we will employ for our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>We analyze the errors of the systems on the En- glish development data of the CoNLL'12 shared task on multilingual coreference resolution <ref type="bibr" target="#b21">(Pradhan et al., 2012</ref>). This corpus contains 343 docu- ments, spanning seven genres: bible texts, broad- cast conversation, broadcast news, magazine texts, news wire, telephone conversations and web logs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Systems</head><p>State-of-the-art approaches to coreference resolu- tion encompass various paradigms, ranging from deterministic pairwise systems to learning-based structured prediction models. Hence, we want to conduct our analysis on a representative sample of the state of the art, which should be publicly avail- able. Therefore, we decided on two deterministic and two learning-based systems:</p><p>• <ref type="formula">StanfordSieve</ref>  For Multigraph, we modified the system described in Martschat (2013) slightly to allow for the in- corporation of distance (similar to <ref type="bibr" target="#b5">Cai and Strube (2010)</ref>). Inspired by <ref type="bibr" target="#b11">Lappin and Leass (1994)</ref>, we add salience weights for subjects and objects to the model to improve third-person pronoun reso- lution. We also extended the feature set by a sub- string feature. Furthermore, motivated by Chen and Ng <ref type="formula">(2012)</ref>, we added a lexicalized feature for non-pronominal mentions that were coreferent in at least 50% of the cases in the training data. StanfordSieve was run with its standard CoNLL shared task settings. The learning-based sys- tems were trained on the CoNLL'12 training data. We trained IMSCoref with its standard settings, and trained BerkeleyCoref with the final feature set from <ref type="bibr" target="#b8">Durrett and Klein (2013)</ref> for twenty it- erations. We evaluate the systems on English CoNLL'12 development data and compare it with the winning system of the CoNLL'12 shared task <ref type="bibr" target="#b9">(Fernandes et al., 2012</ref>) and with Martschat (2013) in <ref type="table">Table 1</ref>, using the reference implementation v7 of the CoNLL scorer ( <ref type="bibr" target="#b22">Pradhan et al., 2014</ref>).</p><p>BerkeleyCoref performs best according to all metrics, followed by Multigraph. StanfordSieve is the worst performing system: the gap to Berke- leyCoref is five points in average score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>Although we analyze recent systems on a recently published coreference data set, we believe that the results of our analysis will have implications for coreference in general. The data set is the largest and most genre-diverse coreference corpus so far. The systems we investigate represent major di- rections in coreference resolution model research, and make use of large and diverse feature sets pro- posed in the literature (Ng, 2010).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">A Comparative Analysis</head><p>The coreference resolution systems presented in the previous section are a representative sample of the state of the art. Therefore, by analyzing the errors they make, we can learn about remaining challenges in coreference resolution and analyze the qualitative differences between the systems. The results of such an analysis will deepen our understanding of coreference resolution and will suggest promising directions for further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>Previous studies identified the presence of recall errors as a main bottleneck for improving per- formance ( <ref type="bibr" target="#b23">Raghunathan et al., 2010;</ref><ref type="bibr" target="#b8">Durrett and Klein, 2013;</ref><ref type="bibr" target="#b10">Kummerfeld and Klein, 2013)</ref>. This is also evidenced by the CoNLL shared tasks on coreference resolution <ref type="bibr" target="#b20">(Pradhan et al., 2011;</ref><ref type="bibr" target="#b21">Pradhan et al., 2012)</ref>, where most competitive systems had higher precision than recall. This indicates that an analysis of recall errors helps to understand and improve the state of the art. Hence, we focus on analyzing recall errors, and complement this by a brief analysis of precision errors.</p><p>We analyze errors of the four systems presented in the previous section on the CoNLL'12 English development data. To extract recall errors we em- ploy the spanning tree algorithm which chooses edges by accessibility. We obtain precision errors from the pairwise output of the systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">A Recall Error Analysis of StanfordSieve</head><p>Since StanfordSieve is currently the most-widely used coreference resolution system, it serves as a good starting point for our analysis. Remember that we represent each error as a pair of anaphor and antecedent. For an initial analysis, we cate- gorize each error by mention type, distinguishing between proper name, common noun, pronoun, demonstrative pronoun and verb. <ref type="bibr">8</ref> StanfordSieve makes 5245 recall errors. To put this number into context, we compare it with the maximum number of recall errors a system can make. This count is obtained by extracting recall errors from the output of a system that puts each mention in its own entity, which yields 14609 er- rors. In <ref type="table" target="#tab_2">Table 2</ref> we present a detailed analysis. For each pair of mention type of anaphor and an-Name Noun Pron. Dem. Verb <ref type="table" target="#tab_2">Name  Errors  1006  181  43  0  0  Maximum  3578  206  56  2  0  Noun  Errors  517  1127  46  14  91  Maximum  742  2063  51  14</ref>   tecedent, the table displays the number of recall errors and of maximum errors possible. StanfordSieve gets almost none of the links in- volving verbal or demonstrative mentions correct. This is due to the system not attempting to handle event coreference, and performing very poorly for demonstratives. On the other hand, recall for pro- noun resolution is quite good, at least when con- sidering non-verbal antecedents. While Stanford- Sieve makes 1885 recall errors when the anaphor is a pronoun, it successfully resolves most of such links present in the corpus. Finally, let us consider the links involving only proper names and com- mon nouns. In total, these amount to 6589 links in the corpus (around 45% of all links). Stanford- Sieve misses 2831 of these links. Pairs of proper names seem to be easier to resolve than pairs of common nouns. Links between a common noun and a proper name are less frequent, but much more difficult: most of the links are missing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis of the Other Systems</head><p>In the previous section we identified various char- acteristics of the errors made by StanfordSieve: only (comparatively) few errors are made for pro- noun resolution and name coreference, while other types of nominal anaphora and coreference of demonstrative/verbal mentions pose a challenge for the system. Do the other systems in our study also have these characteristics? In order to answer  this question, we repeated the analysis for the three other systems described in Section 4. We summa- rize the results in <ref type="table" target="#tab_4">Table 3</ref>. We only report num- bers for pronoun resolution and name/noun coref- erence, as all systems do not resolve verbal men- tions and perform poorly for demonstratives. StanfordSieve makes the most recall errors, closely followed by IMSCoref.</p><p>Multigraph and BerkeleyCoref make around 600 errors less. While the total number of errors differs between the systems, the distributions are similar. In par- ticular, around 55% of recall errors made involve only proper names and common nouns. The num- ber is a bit higher for IMSCoref. We conclude that, despite variations in performance, both de- terministic and learning-based state-of-the-art sys- tems have similar weaknesses regarding recall.</p><p>The results displayed in <ref type="table" target="#tab_4">Table 3</ref> suggest vari- ous opportunities for future research. In this pa- per, we will focus on analyzing name/noun recall errors, as these constitute a large fraction of all re- call errors. Future work should address the pro- noun resolution errors and a characterization of the verbal/demonstrative errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Analysis of the Name/Noun Recall Errors</head><p>We now turn towards a fine-grained analysis of the name/noun recall errors. <ref type="table" target="#tab_6">Table 4</ref> displays the number of such recall errors made by each system, according to the mention types of anaphor and antecedent. We are interested in errors common to all systems, and in qualitative differences of errors between the systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Common Errors</head><p>Let us first analyze the errors common to all sys- tems. Our analysis is driven by the question how these can be characterized, and which knowledge is missing to resolve such links. We discuss the errors depending on the mention types of anaphor and antecedent. The lower part of <ref type="table" target="#tab_6">Table 4</ref> displays the number of common errors for each category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Recall Errors (Anaphor-Antecedent)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description</head><p>Name-Name Noun-Name Name-Noun Noun- <ref type="table" target="#tab_2">Noun   StanfordSieve  1006  517  181  1127  Multigraph  753  501  189  1152  IMSCoref  1082  500  188  1264  BerkeleyCoref  910  456  171</ref>    <ref type="table">Table 5</ref>: Distribution of top five named entity types of common name-name recall errors and all possible name-name recall errors.</p><p>Furthermore, in order to assess the impact of mention detection, the table shows the number of common errors where boundaries for both men- tions were identified correctly by some system. We can see that boundary identification is a diffi- cult problem, especially for proper name pairs: for 48% of such errors, no system found the correct boundaries of both mentions participating in the error. The number of errors where correct bound- aries could be found drops significantly after ex- cluding IMSCoref. This is due to the mention ex- traction strategy of IMSCoref: the other systems in our study discard the shorter mention when two mentions have the same head, IMSCoref keeps both mentions. Hence, the system is able to cor- rectly identify some mentions even in the presence of parsing or preprocessing errors. However, as a result, IMSCoref has to process many spurious mentions, which makes learning more difficult.</p><p>We conclude that mention detection still consti- tutes a challenge. We now proceed to a detailed analysis of errors common to all systems. In pass- ing we will discuss difficulties in mention detec- tion with regard to specific error types.</p><p>Errors between Pairs of Proper Names. The systems share 475 recall errors between pairs of proper names. In <ref type="table">Table 5</ref>, we compare the distri- bution of gold named entity types of these errors with the distribution of gold named entity types of all possible errors (obtained via a singleton sys- tem). We see that especially difficult classes of links are pairs with type ORG or DATE.</p><p>Let us now consider lexical features of the er- rors. <ref type="bibr">9</ref> In 154 errors, the strings match completely, but the correct resolution was mostly prevented by annotation inconsistencies (e.g. China instead of China's) or propagated parsing and NER errors, which lead to deficiencies in mention extraction.</p><p>For 217 errors, at least one token appears in both mention strings, as in the "Cole" and the "USS Cole". This shows the insufficiency of the features which hint to alias relations, may it be heuristics or learned lexical similarities (for 109 of the 217 er- rors, both mention boundaries were identified cor- rectly by at least one system). Disambiguation with respect to knowledge bases could provide a principled way to identify name variations.</p><p>We classified the remaining 104 errors manu- ally, see <ref type="table" target="#tab_7">Table 6</ref>. For a couple of categories such as identifying acronyms, spelling variations and aliases, disambiguation could also help. Many er- rors happen for date mentions, which suggests the use of temporal tagging features.</p><p>Errors for Noun-Name Pairs. We now inves- tigate the errors where the anaphor is a common noun and the antecedent is a proper name. 371 er- rors are common to all systems. The high fraction of common errors shows that this is an especially challenging category. We again start by investigat- ing how the distribution of the named entity type  <ref type="table">Table 7</ref>: Distribution of top five named entity types of common noun-name recall errors and all possible noun-name recall errors.</p><note type="other">Description Occ. Example Acronyms 20 National Ice Hockey League and NHL Alias 24 Florida and the Sunshine State Annotation 2 Annotation errors (pronoun as name) Context 2 Paula Coccoz and juror number ten Date 29 1989 and last year's Metonymy 12 South Afria and Pretoria Roles 8 Al Gore and the Vice President Spelling 7 Hsiachuotzu and Hsiachuotsu</note><p>of the antecedent differs when we compare com- mon errors to all possible errors. The results are shown in <ref type="table">Table 7</ref>. Links with a proper name an- tecedent of type PERSON are especially difficult. They constitute 22% of the common errors, but only 18% of all possible errors. Most mentions are in a hyponymy relation, like the prime minister and Mr. Papandreou. This con- firms that harnessing such relations could improve coreference resolution ( <ref type="bibr" target="#b24">Rahman and Ng, 2011;</ref><ref type="bibr" target="#b27">Uryupina et al., 2011</ref>). For 65 of the errors (18%) there is lexical overlap: the head of the anaphor is contained in the proper name antecedent, as in the entire park and the Ocean Park.</p><p>When categorizing all common errors accord- ing to the head of the anaphor, we observe 204 dif- ferent heads. 142 heads appear only once, but the top ten heads make up 88 of the 371 errors. The <ref type="table">Table 8</ref>: Comparison of noun-name recall errors. Entries are errors made by the system in the row, while the participating mentions are coreferent ac- cording to the the system in the column.</p><p>Errors between Pairs of Common Nouns. 835 errors between pairs of common nouns are shared by all systems. For 174 of these, the anaphor is an indefinite noun phase, which makes resolution a lot harder, since most coreference resolution sys- tems classify these as non-anaphoric and therefore do not attempt resolution.</p><p>For further analysis, we split all 835 errors in two categories, distinguishing whether the head matches between the mentions or not. In 341 cases the heads match. For many of these cases, parsing errors propagate and prevent the systems from rec- ognizing the correct mention boundaries.</p><p>In order to get a better understanding of the er- rors for nouns with different heads, we randomly extracted 50 of the 494 pairs and investigated the relation that holds between the heads. In 23 cases, the heads were related via hyponymy. In 10 cases they were synonyms. The remaining 17 cases involve many different phenomena, for example meronymy. This confirms findings from previous research <ref type="bibr" target="#b30">(Vieira and Poesio, 2000</ref>).</p><p>Hence, looking up lexical relations, especially hyponymy, might be helpful to solve these cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Differences between the Systems</head><p>In order to analyze differences between the sys- tems, we compare the recall errors they make. The information how recall errors differ between systems will enable us to understand individual strengths and weaknesses.</p><p>Exemplarily, we will have a look at the differ- ences in the errors when the anaphor is a common noun and the antecedent is a proper name. By sys- tem design and by the total error numbers <ref type="table" target="#tab_6">(Table  4)</ref> we expect the learning-based systems to have a slight advantage over the deterministic systems.</p><p>In <ref type="table">Table 8</ref> we compare noun-name recall errors made by each system. Entries are errors made by <ref type="bibr">Number and Proportion of Precision Errors (Anaphor-Antecedent)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description</head><p>Name-Name Noun-Name Name-Noun Noun-Noun  <ref type="table">Table 9</ref>: Name/Noun precision errors for all systems. The percentages are the proportion of precision errors with respect to all decision of the system in that category.</p><p>the system in the row, while the participating men- tions are coreferent according to the the system in the column. The numbers confirm our hypothesis, but also show that the deterministic systems are able to recover a few links missed by the learning- based systems.</p><p>For example, BerkeleyCoref recovers 60 links that could not be found by Multigraph, including 34 links without any common token, such as the airline and Pan Am. Multigraph recovers only 42 links not found by BerkeleyCoref, 21 without any common token. Qualitatively, StanfordSieve and Multigraph are able to resolve a few links thanks to their engineered substring match, such as the judge and Dallas District Judge Jack Hampton.</p><p>We also conducted similar investigations for common noun and proper name pairs. For com- mon nouns, the trends are similar: the learning- based systems have an advantage over the deter- ministic systems. However, only few relations be- tween nouns with different heads are learned - compared to StanfordSieve, BerkeleyCoref recov- ers only 11 such pairs, such as the man and an expert in the law. Recall of the deterministic sys- tems is further hampered by their strict checks for modifier agreement, which they employ to keep precision high. Both systems miss for example the link from the anaphor the Milosevic regime to the regime, since the nominal modifier of the anaphor does not appear in the antecedent.</p><p>For proper names, Multigraph employs so- phisticated alias heuristics which help to resolve matches such as Marshall Ye Ting's and his grand- father Ye Ting. This explains the corresponding low number in <ref type="table" target="#tab_6">Table 4</ref>. The lexicalized features of Multigraph, IMSCoref and BerkeleyCoref help to learn aliases when there is no string match, es- pecially for the bible part of the corpus (resolving links such as Jesus and the Son of Man).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Precision Errors</head><p>In the above analysis we identified common name/noun recall errors and discussed strengths and weaknesses of each system. Let us comple- ment this analysis by a brief discussion of corre- sponding precision errors. <ref type="table">Table 9</ref> gives an overview. It displays the num- ber of precision errors for each category, and the proportion of these errors compared to all deci- sions in that category. We can see some general trends from this table: first, more decisions lead to a higher proportion of errors. This shows the dif- ficulty of balancing recall and precision. Second, proper name coreference seems much easier than common noun coreference. Coreference involving different mention types is a lot harder -the sys- tems only attempt few decisions, most of them are wrong. This confirms findings from our recall er- ror analysis. Third, the fraction of common errors is very low, which indicates that precisions errors stem from various sources, which are handled dif- ferently by each system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>We now discuss related work in coreference res- olution error analysis and in the related field of coreference resolution evaluation metrics.</p><p>Error Analysis. While many papers on coref- erence resolution briefly discuss errors made and resolved by the system under consideration, only few concentrate on error analysis. <ref type="bibr" target="#b29">Uryupina (2008)</ref> presents a manual error analysis on the small MUC-7 test set; Martschat (2013) performs an automatic coarse-grained error classification on CoNLL data. By extending and formalizing the approach of Martschat (2013), we are able to per- form a large-scale investigation of recall errors made by state-of-the-art systems. <ref type="bibr" target="#b10">Kummerfeld and Klein (2013)</ref> devise a method to extract errors from transformations of reference to system entities. They apply this method to a variety of systems and aggregate errors over these systems. By aggregating, they are not able to ana- lyze differences. They furthermore focus on de- scribing many different error classes, instead of closely investigating particular phenomena.</p><p>Evaluation Metrics. We extract recall and pre- cision errors. How does our error analysis frame- work relate to coreference resolution evaluation metrics, which quantify recall and precision er- rors? We first observe a fundamental difference: evaluation metrics deal with scoring coreference chains, they provide no means of extracting recall or precision errors. Therefore our analysis com- plements insights obtained via evaluation metrics.</p><p>We follow <ref type="bibr" target="#b7">Chen and Ng (2013)</ref> and distinguish between linguistically agnostic metrics, which do not employ linguistic information during scoring, and linguistically informed metrics, which employ linguistic information similar as we do when com- puting spanning trees.</p><p>We limit the discussion of linguistically ag- nostic metrics to the three most popular evalua- tion metrics whose average constitutes the official score in the CoNLL shared tasks on coreference resolution: MUC ( <ref type="bibr">Vilain et al., 1995)</ref>, B 3 (Bagga and <ref type="bibr" target="#b1">Baldwin, 1998)</ref> and CEAF e ( <ref type="bibr" target="#b13">Luo, 2005</ref>). <ref type="bibr">10</ref> Our framework bears most similarities to the MUC metric, as both are based on the same link- based entity representation. In particular, when we divide the number of errors extracted from an en- tity by the size of a spanning tree for that entity, we obtain a score linearly related 11 to the MUC score for that entity (recall for reference entities, preci- sion for system entities). B 3 and CEAF e are not founded on a link-based structure. B 3 computes recall by computing the relative overlap of refer- ence and system entity for each reference mention, and then normalizes by the number of mentions. CEAF e computes an optimal entity alignment with respect to the relative overlap, and then normalizes by the number of entities. As the metrics are not link-based, they do not provide means to extract link-based errors. We leave determining whether the framework of these metrics exhibits a useful notion of errors to future work. <ref type="bibr">10</ref> These are linguistically agnostic since they do not differ between different mention or entity types when evaluating. 11 via the transformation x → 1 − x Recent work considered devising evaluation metrics which take linguistic information into account. <ref type="bibr" target="#b7">Chen and Ng (2013)</ref> inject linguis- tic knowledge into existing evaluation metrics by weighting links in an entity representation graph. Tuggener (2014) devises scoring algorithms tai- lored for particular applications by redefining the notion of a correct link. While both of these works focus on scoring, they weight or explicitly define links in the reference and system entities, thereby they in principle allow error extraction. However, the authors do not attempt this and it is not clear whether the errors extracted that way are useful for analysis and system development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We presented a novel link-based framework for coreference resolution error analysis, which ex- tends and complements previous work. We ap- plied the framework to analyze recall errors of four state-of-the-art systems on a large English bench- mark dataset. Concentrating on errors involving only proper names and common nouns, we identi- fied a core set of challenging errors common to all systems in our study.</p><p>We characterized the common errors among a broad range of properties. In particular, our anal- ysis highlights and quantifies the usefulness of world knowledge. Furthermore, by comparing the recall errors made by each system, we identified individual strengths and weaknesses. A brief pre- cision error analysis highlighted the hardness of resolving noun-name and noun-noun links.</p><p>The presented method and findings help to iden- tify challenges in coreference resolution and to in- vestigate ways to overcome these challenges.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Number of StanfordSieve's recall er-
rors according to mention type, compared to the 
maximum possible number of errors. Rows are 
anaphors, columns antecedents. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Recall error numbers for all systems. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>1072</head><label>1072</label><figDesc></figDesc><table>Common errors 
475 
371 
147 
835 
Correct boundaries idenfified 
257 
273 
108 
563 
excl. IMSCoref 
156 
222 
97 
475 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Name/Noun recall errors for all systems. 

Common 
All 

Type 
% Type 
% 

ORG 
25% PERSON 26% 
PERSON 19% GPE 
26% 
GPE 
16% ORG 
20% 
DATE 
14% NONE 
14% 
NONE 
9% DATE 
6% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Classification of common name-name re-
call errors without common tokens. 

Common 
All 

Type 
% Type 
% 

ORG 
28% ORG 
27% 
PERSON 22% GPE 
22% 
GPE 
19% PERSON 18% 
NONE 
7% NONE 
11% 
DATE 
5% DATE 
5% 

</table></figure>

			<note place="foot" n="1"> http://smartschat.de/software</note>

			<note place="foot" n="2"> We could also use an undirected instead of a onedirectional graph, but using a one-directional graph conveniently models sequential information, which simplifies notation and the algorithms we will present.</note>

			<note place="foot" n="3"> A similar procedure was used by Ng and Cardie (2002) to extract meaningful antecedents when training a coreference resolution system.</note>

			<note place="foot" n="4"> Part of Stanford CoreNLP, available at http://nlp. stanford.edu/software/corenlp.shtml. We use version 3.4. 5 http://smartschat.de/software 6 http://www.ims.uni-stuttgart.de/ forschung/ressourcen/werkzeuge/IMSCoref. en.html. We use the CoNLL 2012 system. 7 http://nlp.cs.berkeley.edu/ berkeleycoref.shtml</note>

			<note place="foot" n="8"> We obtain the type from the part-of-speech tag of the mention&apos;s head. Furthermore, we treat every mention whose head has a NER label in the data as a proper name.</note>

			<note place="foot" n="9"> When computing these, we ignored case and ignored all tokens with part-of-speech tag DT or POS.</note>

			<note place="foot">most frequent heads are company (15), group (12), government, country and nation (each 9). This suggests that even with few reliable hyponymy relations recall could be significantly improved. We observe similar trends when the anaphor is a proper name and the antecedent is a noun. Reference System System</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been funded by the Klaus Tschira Foundation, Heidelberg, Germany. The first au-thor has been supported by a HITS Ph.D. scholar-ship.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Referring and accessibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mira</forename><surname>Ariel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Linguistics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="87" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Algorithms for scoring coreference chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Breck</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Conference on Language Resources and Evaluation</title>
		<meeting>the 1st International Conference on Language Resources and Evaluation<address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-05-30" />
			<biblScope unit="page" from="563" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Coreference semantics from web features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="389" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Understanding the value of features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bengtson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Waikiki, Honolulu, Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-10" />
			<biblScope unit="page" from="294" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Datadriven multilingual coreference resolution using resolver stacking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richárd</forename><surname>Farkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning</title>
		<meeting>the Shared Task of the 16th Conference on Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="49" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">End-to-end coreference resolution via hypergraph partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-08" />
			<biblScope unit="page" from="143" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Combining the best of two worlds: A hybrid approach to multilingual coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning</title>
		<meeting>the Shared Task of the 16th Conference on Computational Natural Language Learning<address><addrLine>Jeju Island</addrLine></address></meeting>
		<imprint>
			<publisher>Korea</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="56" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Linguistically aware coreference evaluation metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Joint Conference on Natural Language Processing</title>
		<meeting>the 6th International Joint Conference on Natural Language Processing<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1366" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Easy victories and uphill battles in coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Wash.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1971" to="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Latent structure perceptron with feature induction for unrestricted coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eraldo</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruy</forename><surname>Cícero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Milidiú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning</title>
		<meeting>the Shared Task of the 16th Conference on Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Errordriven analysis of challenges in coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Wash.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="265" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An algorithm for pronominal anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shalom</forename><surname>Lappin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><forename type="middle">J</forename><surname>Leass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="535" to="561" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deterministic coreference resolution based on entity-centric, precision-ranked rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Peirsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="885" to="916" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On coreference resolution performance metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference and the 2005 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Human Language Technology Conference and the 2005 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Vancouver, B.C., Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06-08" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A multigraph model for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Broscheit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Eva Mújdricza-Maydt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning</title>
		<meeting>the Shared Task of the 16th Conference on Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="100" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multigraph clustering for unsupervised coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">51st Annual Meeting of the Association for Computational Linguistics: Proceedings of the Student Research Workshop</title>
		<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shudong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramez</forename><surname>Zakhary</surname></persName>
		</author>
		<title level="m">ACE 2004 multilingual training corpus. LDC2005T09</title>
		<meeting><address><addrLine>Philadelphia, Penn</addrLine></address></meeting>
		<imprint>
			<publisher>Linguistic Data Consortium</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving machine learning approaches to coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia<address><addrLine>Penn</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Supervised noun phrase coreference research: The first fifteen years</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="1396" to="1411" />
		</imprint>
	</monogr>
	<note>Sweden</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Simone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ponzetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>New York, N.Y.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06" />
			<biblScope unit="page" from="192" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">CoNLL-2011 Shared Task: Modeling unrestricted coreference in OntoNotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task of the 15th Conference on Computational Natural Language Learning</title>
		<meeting>the Shared Task of the 15th Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
	<note>Portland</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">CoNLL2012 Shared Task: Modeling multilingual unrestricted coreference in OntoNotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning</title>
		<meeting>the Shared Task of the 16th Conference on Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scoring coreference partitions of predicted mentions: A reference implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Md</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="30" to="35" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A multipass sieve for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Karthik Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Sudarshan Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Cambridge, Mass</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="492" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Coreference resolution with world knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Altaf</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Portland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2011-06-24" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="814" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning-based multi-sieve co-reference resolution with knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing and Natural Language Learning</title>
		<meeting>the 2012 Conference on Empirical Methods in Natural Language Processing and Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1234" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Coreference resolution evaluation for higher level applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><surname>Tuggener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04-30" />
			<biblScope unit="page" from="231" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Disambiguation and filtering methods in using web knowledge for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Giuliano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Tymoshenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Florida Artificial Intelligence Research Society Conference</title>
		<meeting>the 24th International Florida Artificial Intelligence Research Society Conference<address><addrLine>Palm Beach, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1820-05" />
			<biblScope unit="page" from="317" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Knowledge acquisition for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Uryupina</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<pubPlace>Saarbrücken, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Saarland University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Error analysis for learningbased coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Uryupina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Language Resources and Evaluation</title>
		<meeting>the 6th International Conference on Language Resources and Evaluation<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An empirically-based system for processing definite descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renata</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="539" to="593" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dennis Connolly, and Lynette Hirschman. 1995. A modeltheoretic coreference scoring scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Vilain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Aberdeen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Message Understanding Conference (MUC-6)</title>
		<meeting>the 6th Message Understanding Conference (MUC-6)<address><addrLine>San Mateo, Cal</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<biblScope unit="page" from="45" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Kaufman</surname></persName>
		</author>
		<title level="m">OntoNotes release 5.0. LDC2013T19</title>
		<editor>Michelle Franchini, Mohammed El-Bachouti, Robert Belvin, and Ann Houston</editor>
		<meeting><address><addrLine>Philadelphia, Penn</addrLine></address></meeting>
		<imprint>
			<publisher>Linguistic Data Consortium</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
