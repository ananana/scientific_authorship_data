<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Extracting Aspect Specific Opinion Expressions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Laddha</surname></persName>
							<email>laddhaabhishek11@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">IIT Delhi * New Delhi</orgName>
								<address>
									<postCode>110016</postCode>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Houston</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Extracting Aspect Specific Opinion Expressions</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="627" to="637"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Opinionated expression extraction is a central problem in fine-grained sentiment analysis. Most existing works focus on either generic subjective expression or aspect expression extraction. However, in opinion mining, it is often desirable to mine the aspect specific opinion expressions (or aspect-sentiment phrases) containing both the aspect and the opinion. This paper proposes a hybrid generative-discriminative framework for extracting such expressions. The hybrid model consists of (i) an unsupervised gener-ative component for modeling the semantic coherence of terms (words/phrases) based on their collocations across different documents, and (ii) a supervised discriminative sequence modeling component for opinion phrase extraction. Experimental results using Amazon .com reviews demonstrate the effectiveness of the approach that significantly outper-forms several state-of-the-art baselines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Aspect based sentiment analysis is one of the main frameworks in opinion mining ( <ref type="bibr" target="#b19">Liu and Zhang, 2012</ref>). Most of the websites only display the ag- gregated ratings of products but people are more in- terested in fine-grained opinions that capture aspect specific properties in reviews. Therefore, it is desir- able to have a holistic approach to mine aspect spe- cific opinion expressions containing both aspect and * Research performed during author's internship at Univer- sity of Houston opinion terms within the sentence context as a com- posite aspect-sentiment phrase (e.g., "had to flash firmware everyday", "clear directions in voice" etc.) and further group them under coherent aspect cate- gories. Apart from knowing the key issues in prod- ucts that are often expressed via aspect-sentiment phrases, they are also useful in applications such as comparing similar products and summarizing their important features where it is more conve- nient to have the aspect-sentiment phrases rather than generic aspect/sentiment words lacking the nat- ural aspect opinion correspondence in the right con- text. They can also be applied to the various tasks such as sentiment classification, comparative aspect evaluations, aspect rating prediction, etc.</p><p>The thread of research in <ref type="bibr" target="#b2">(Brody and Elhadad, 2010;</ref><ref type="bibr" target="#b27">Titov and McDonald, 2008;</ref><ref type="bibr" target="#b36">Zhao et al., 2010;</ref><ref type="bibr" target="#b21">Mei et al., 2007;</ref><ref type="bibr" target="#b11">Jo and Oh, 2011</ref>) focus on extract- ing and grouping aspect and opinion words via gen- erative models but lack the natural aspect opinion correspondence (e.g., in the manner they appear in sentences). ( <ref type="bibr" target="#b29">Wang et al., 2016;</ref><ref type="bibr" target="#b8">Fei et al., 2016)</ref> can discover aspect specific opinion unigrams but does not focus on phrases. The thread on fine grained opinion expressions ( <ref type="bibr" target="#b5">Choi et al., 2006;</ref><ref type="bibr" target="#b1">Breck et al., 2007</ref>) focus on subjective expres- sion extraction which are generic instead of aspect specific. Formally, the task can be stated as follows:</p><p>Given a set of reviews, for each sentence, s = (w 1 , . . . w n ), with the head aspect (HA), w HA=i , i ∈ <ref type="bibr">[1, n]</ref>, discover a sub-sequence (w p , . . . w q ) where p ≤ i ≤ q that best describes the aspect-sentiment phrase containing the head aspect. We refer head aspect to the word describing fine-grained property of product. Further, group these phrases under relevant aspect categories. The examples below show labeled aspect-sentiment phrases within <ref type="bibr">[[ ]]</ref> with the head aspect (HA) italicized:</p><p>• I've been very happy with it so far done a [[firmware update without a hitch]].</p><p>• After less than two years, the [[signal became spotty]].</p><p>In this paper, we propose a novel hybrid model to solve the problem. We call this Phrase Senti- ment Model (PSM). PSM is capable of extracting a myriad of expression types covering: verb phrases ("screen has poor viewability"), noun, adjective or adverbial phrase ("recurrent black screen of death", "quite stable and fast connection"), implied positive ("voice activated directions"), implied negative ("re- quires reboot every few hours") etc. The hybrid framework facilitates holistic modeling that caters for varied expression types (leveraging its discrim- inative sequence model) and also grouping them un- der relevant aspect categories with context (exploit- ing its generative framework). Our approach is also context and polarity independent facilitating generic aspect-sentiment phrase extraction in any domain. Further, we propose a novel sampling scheme based on Generalized Pólya urn models that opti- mizes phrasal collocations to improve coherence. To the best of our knowledge, a hybrid framework has not been attempted before for opinion phrase ex- traction. Additionally, the paper produced a labeled dataset of aspect specific opinion phrases across 4 domains containing more than 5200 sentences coded with phrase boundaries across both positive and neg- ative polarities which will be released to serve as a language resource. Experimental evaluation shows that our approach outperformed the baselines by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Subjective expression extraction ( <ref type="bibr" target="#b4">Choi et al., 2005</ref>) has traditionally used sequence models (e.g., CRFs). Various parsing, syntactic, lexical and dictionary based features <ref type="bibr" target="#b13">(Kim and Hovy, 2006;</ref><ref type="bibr" target="#b10">Jakob and Gurevych, 2010;</ref><ref type="bibr" target="#b14">Kobayashi et al., 2007</ref>) have been used for subjective expression extraction. In <ref type="bibr" target="#b34">(Yang and Cardie, 2013;</ref><ref type="bibr" target="#b12">Johansson and Moschitti, 2011</ref>) dependency relations were also used for opinion ex- pression extraction. <ref type="bibr" target="#b26">Sauper et al., (2011)</ref> employs an HMM over words and model the latent topics as states in an HMM to discover the product properties (often aspects) and its associated attributes (pos/neg) polarities separately. In <ref type="bibr" target="#b33">Yang and Cardie, (2012)</ref> a semi-CRF based approach is used which allow sequence labeling at segment level and ( <ref type="bibr" target="#b35">Yang and Cardie, 2014</ref>) employed semi-CRF for opinion ex- pression intensity and polarity classification. How- ever, all the above works focus on generic subjective expressions as opposed to aspect specific opinion- sentiment phrases.</p><p>In ( <ref type="bibr" target="#b5">Choi et al., 2006;</ref><ref type="bibr" target="#b34">Yang and Cardie, 2013</ref>) joint models were proposed for identifying opin- ion holders and expression, relations among them in news articles. In ( <ref type="bibr" target="#b12">Johansson and Moschitti, 2011</ref>) a re-ranking approach was used on the output of a sequence model to improve opinion expression extraction. In ( <ref type="bibr" target="#b17">Li et al., 2015;</ref><ref type="bibr" target="#b24">Mukherjee, 2016</ref>) subjective expressions implying a negative opin- ion were discovered using sequence models and markov networks; while in <ref type="bibr" target="#b0">(Berend, 2011)</ref> super- vised keyphrase extraction was used for phrase ex- traction. These works mostly relied on word level features under the first-order Markov assumption. Above works are tailored for only expression extrac- tion and do not group coherent phrases under rele- vant aspect categories.</p><p>Another thread of research involves topic phrase mining. <ref type="bibr" target="#b28">Wang et al., (2007)</ref> proposes a Topical n- gram model (TNG) that mines phrases based on sta- tistical collocation. <ref type="bibr" target="#b18">Lindsey et al., (2012)</ref> employ hierarchical Pitman-Yor process to model phrases. In <ref type="bibr" target="#b7">Fei et al., (2014)</ref>, Generalized Pólya urn model (LDA-P-GPU) was used to group the candidate noun phrases. In <ref type="bibr" target="#b6">(El-Kishky et al., 2014;</ref>, frequency based information were used for mining phrases that are good for generic phrases but can- not model relevant yet longer phrases due to their infrequency. Thus, they are unable to capture long phrases containing both aspect and opinion. The models TNG and LDA-P-GPU are closest to our task as they can discover relevant aspect expressions that can contain opinions and are considered as base- lines.</p><p>Next there are works that generate phrasal , a dataset was produced that had annotations for aspect phrases.</p><p>The focus was on aspect phrases as opposed to aspect-sentiment phrases. The MPQA 2.0 corpus ( ) has some labeled opinion ex- pressions, but they are generic subjective expres- sions as opposed to aspect-sentiment phrases (see Section 1) we find in reviews. <ref type="bibr" target="#b37">Zhao et al., (2011)</ref> extracts topical phrase in tweets using relevance and interestingness. <ref type="bibr" target="#b32">Wu et al., (2009)</ref> proposed a phrase dependency parsing approach to extract product feature (aspect expres- sion) and opinion expression and the relation be- tween them. They considered all noun and verb phrases (NPs, VPs) as product features and its sur- rounding dictionary opinion words as opinions. Fea- tures were constructed using phrase dependency tree to extract relation among all product features and opinions that were later used in aspect and opinion expression extraction. Although, <ref type="bibr" target="#b32">Wu et al., (2009)</ref> doesn't discover aspect specific opinion phrases, its use of NPs in extracting candidate opinion phrases is similar to <ref type="bibr" target="#b7">Fei et al., (2014)</ref> which is considered as a baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Phrase Sentiment Model (PSM)</head><p>PSM is a hybrid between generative and discrimina- tive modeling that combines the best of both worlds. Its generative modeling lays the foundation for emis- sion of aspects and aspect specific opinion phrases in documents, while its discriminative sequence mod- eling component (via an embedded CRF) facilitates aspect specific opinion phrase extraction.</p><p>As noted in <ref type="bibr" target="#b27">Titov and McDonald (2008)</ref>, model- ing entire reviews as documents tend to correspond to the global properties of a product (e.g., brand, name, etc.) resulting in rather overlapping aspects. To avoid this, we perform sentence level model- ing that helps improve aspect sharpness. A review sentence s d of N words, is denoted as w d,s,j = {w d,s,1 , w d,s,2 . . . w d,s,N } where each w d,s,j is one of the V words in the vocabulary. There can be ex- ponential number of phrase sequence possible for each sentence s d i.e. w d,s,j j=st+len−1 j=st of arbi- trary length len(len = 1 for words; len &gt; 1 for phrases) starting at an index st ∈ [0, |s d |]. We observed that most of opinion expression are cen- tered around the head aspect thereby causing the space of potential opinion expressions to be quite sparse. We took advantage of following observa- tion and trained a sequence model (e.g., CRF) for phrase sequence tagging as described in the next subsection. We generated M = 5 best sequence labelings of each sentence</p><formula xml:id="formula_0">s d (s m∈1...M d</formula><p>) via for- ward Viterbi and backward A * search 1 . Hence, our vocabulary is the union of unigrams and n-grams discovered by CRF over M best sequence label- ing, i.e., the model's vocabulary,</p><formula xml:id="formula_1">V = {w d,s,j } ∪ {{w d,s m d ,j j=st+len−1 j=st } ∀d, s, j, len, st, m.</formula><p>In PSM, for each aspect a, we model its aspect specific terms (words/phrases) distributions and as- pect background word distributions using multino- mials ϕ A a and ϕ B a , drawn from Dir(β) over the vo-</p><formula xml:id="formula_2">cabulary v 1...V . For each domain d, we first draw a domain specific aspect distribution θ d ∼ Dir(α). Next, for each review sentence (document), s d of a domain, d we draw an aspect, z d,s ∼ M ult(θ d ).</formula><p>We assume that each sentence evaluates one as- pect which mostly holds true in the review do- main. We associate a latent switch variable for each word r , we first set the switch variables for the sentence,</p><formula xml:id="formula_3">s d via the discriminative CRF model, i.e. r d,s m d ,j j=|s d | j=1 ← 1 Z exp j k λ k f k (r j−1 , r j , w j )</formula><p>by fitting a previously trained CRF model. The switch vari- ables, r ∈ {1, 0} for a particular tagging s m d of 1 Value of M was tuned via pilot experiments using the CRF++ toolkit <ref type="bibr" target="#b15">(Kudo, 2009)</ref> sentence s d span over all its words and take val- ues r = 1 for words being part of an aspect spe- cific opinion phrase or r = 0 for aspect background words, upon observing all words in s d . Finally, de- pending upon the aspect, z d,s and the switch vari- able r d,s,j , we emit (unigram) terms in the sentence as follows:</p><formula xml:id="formula_4">w d,s,j ∼ M ult(ϕ A z d,s ) if r d,s,j = 1 M ult(ϕ B z d,s ) if r d,s,j = 0<label>(1)</label></formula><p>and for phrasal terms (i.e., when</p><formula xml:id="formula_5">r d,s m d ,j j=st+len−1 j=1 = 1∀ valid st and len), we emitw d,s m d ,j j=st+len−1 j=st ∼ M ult(ϕ A z d,s</formula><p>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Inference</head><p>We employ MCMC Gibbs sampling for posterior in- ference. As latent variables z and r belong to differ- ent levels, we hierarchically sample z and then r for each sweep of a Gibbs iteration as follows:</p><formula xml:id="formula_6">p(z d,s = a|Z ¬d,s , R ¬d,s , W ¬d,s ) ∝ (n s d,a ) ¬d,s +α (n s d,(·) ) ¬d,s +Aα × V v=1 Γ(n A a,v +β) Γ((n A a,v ) ¬d,s +β) / Γ(n A a,(·) +V β) Γ((n A a,(·) ) ¬d,s +V β) × V v=1 Γ(n B a,v +β) Γ((n B a,v ) ¬d,s +β) / Γ(n B a,(·) +V β) Γ((n B a,(·) ) ¬d,s +V β)<label>(2)</label></formula><p>Samplers for r consist of three cases: (i) individual aspect-specific opinion words, (ii) individual back- ground words, and (iii) phrasal opinion:</p><formula xml:id="formula_7">p(r d,s,j = 1|z d,s = a, w d,s,j = v, . . .) ∝ (n A a,v ) ¬d,s,j +β) (n A a,(·) ) ¬d,s,j +V β) × p CRF (r d,s,j−1 , r d,s,j = 1|v) (3) p(r d,s,j = 0|z d,s = a, w d,s,j = v, . . .) ∝ (n B a,v ) ¬d,s,j +β) (n B a,(·) ) ¬d,s,j +V β) × p CRF (r d,s,j−1 , r d,s,j = 0|v) (4) p(r d,s,j = 1 j=st+len−1 j=st |z d,s = a, w d,s,j = v j=st+len−1 j=st , . . .) ∝ (n A a,v ) ¬d,s,j +β) (n A a,(·) ) ¬d,s,j +V β) × p CRF (r d,s,j=st−1 , r d,s,j=st = 1, r d,s,j=st+1 = 1, . . . r d,s,j=st+len−1 = 1|v</formula><p>) (5) where n s d,a denotes the # of sentences in domain d assigned to aspect a, n A a,v , n B a,v denote the # of times term v was assigned to aspect a in the aspect specific opinion, and aspect specific background language models respectively. A count variable with subscript (·) signifies the marginalized sum over the latter in- dex and ¬ denotes the discounted counts. The sam- pler in (5) computes the likelihood of a sequence of contiguous terms, r d,s,j = 1 j=st+len−1 j=st form- ing an aspect (z d,s = a) specific opinion phrase, v starting at index j = st and of length len, where</p><formula xml:id="formula_8">v = w d,s,j j=st+len−1 j=st .</formula><p>The sequence probabili- ties, p CRF in equations (3, 4, 5) can be obtained as follows.</p><p>Let w = (w t=1 . . . w t=T ) denote the sequence of observed words in a sentence, and let each obser- vation w t have a label y t ∈ Y indicating whether w t is part of a aspect specific opinion phrase, where Y = {1, 0}. We consider a first order Markov linear-chain CRF in our hybrid model. We define the Markovian transition and forward-backward variables of our embedded CRF as follows:</p><formula xml:id="formula_9">ψ t (j, i, w) = p(y t = j|y t−1 = i)p(w t = w|y t = j) (6) α t (j) = i∈Y ψ t (j, i, w t )α t−1 (i)<label>(7)</label></formula><formula xml:id="formula_10">β t (j) = j∈Y ψ t+1 (j, i, w t+1 )β t+1 (j)</formula><p>(8) where α 1 (j) = ψ 1 (j, y 0 , w 1 ) and β T (i) = 1. This lays the foundation for expressing the sequence probabilities, p CRF in closed form as follows: <ref type="formula">(9)</ref> is used for computing the sequence proba- bilities for individual opinion/background words for samplers in eq. (3, 4) while eq. (10) and its exten- sions are used for computing the sequence probabil- ities in the phrase samplers in eq. (5). The values for ψ t , α t , β t are obtained from a previously trained CRF model upon fitting to the current sentence s d for which sampling is being performed.</p><formula xml:id="formula_11">p CRF (y t−1 , y t |w) ∝ α t−1 (y t−1 )ψ t (y t , y t−1 , w t )β t (y t ) (9) p CRF (y t−2 , y t−1 , y t |w) ∝ α t−2 (y t−2 )ψ t−1 (y t−1 , y t−2 , w t−1 )ψ t (y t , y t−1 , w t )β t (y t ) (10) Eq.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Embedded CRF Training</head><p>We employ linear-chain CRFs ( <ref type="bibr" target="#b16">Lafferty et al., 2001</ref>) for modeling phrases. While word (W) and Part-Of- Speech (POS) tag features are effective in various sequence modeling tasks <ref type="bibr" target="#b35">(Yang and Cardie, 2014;</ref><ref type="bibr" target="#b33">Yang and Cardie, 2012)</ref>, in our problem context, (W+POS) features are insufficient as they do not consider the head aspect (HA) and its relevant posi- tional/contextual features, i.e., how do different POS tags, syntactic units (chunks), polar sentiments ap- pear in proximity to the head aspect? Hence, center- ing on the HA, we propose a set of pivot features to model context. </p><note type="other">, etc. Category Feature Template Example of feature apperaing in a sentence 1 st order features</note><formula xml:id="formula_12">W i+j ; −4 ≤ j ≤ 4 W ∈ {T, C, P, S, SP } SP i+j SP i−1 = N EG;</formula><p>previous term of HA is of NEG polarity,. . . have this terrible voice on the . . . S i+j S i−2 = ing; suffix of 2 nd previous term of head aspect is "ing", . . . kept dropping the signal . . . . . .</p><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. . 2 nd order features</head><formula xml:id="formula_13">W i+j , Y i+j ; −4 ≤ j ≤ 4 W, Y ∈ {T, C, P, S, SP } T i+j , T i+j T i−2 = JJ, T i−1 = V BZ, · · · frequently drops connection. . . T i+j , C i+j T i+2 = RB, C i+3 = ADJP ; . . . screen clarity is good. . . . . . . . . 3 rd order features W i+j , Y i+j , Z i+j ; −4 ≤ j ≤ 4 W, Y, Z ∈ {T, C, P, S, SP } T i+j , S i+j , T i+j</formula><p>T i+2 = JJ, P i+4 = un, T i+4 = JJ; . . . screen is blank and unresponsive. . . . . .</p><p>. . .  <ref type="table" target="#tab_0">Table 1</ref> details the templates for features pivoting on the head aspect. Various fea- tures from these templates coupled with the value of the current sequence tag at y t or a combination of current and previous labels y t , y t−1 serve as our linear chain features (LCF), f (y i−1 , y i , w). Further, the index i for LCF can refer to any word in the sen- tence and not necessarily the head aspect, yielding us a very rich feature space. Learning the CRF λs: Given a set of training ex- amples {w i , y t } where y t are the correct sequence tags, we estimate the CRF Λ = {λ k }parameters by minimizing the negative log-likelihood (NLL), The training set for learning the embedded CRF models λs is detailed in <ref type="table" target="#tab_3">Table 3</ref> (col 1, 2).</p><formula xml:id="formula_14">Λ = argmin Λ (C i log(p(y t |w i , Λ)) + k λ 2 k )<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Optimizing Phrasal Collocations</head><p>Topic models can be described in terms of a simple Pólya urn (SPU) sampling schemes in the sense that when a particular term (word or phrase) is drawn from a topic, count of that term is incremented in that topic. This enforces the topic distribution to tend towards these terms over time as frequency of them increases. Therefore, the posterior of gen- erative topic models often favors terms with high frequency e.g., unigrams, while phrasal terms are ranked lower due to their lower frequencies. This is undesirable for phrase extraction.</p><p>In contrast, Generalized P˝ olya urn (GPU) model differs from SPU in its sampling process. When a certain term is drawn, the count of that term in- creases as well as it also increases the count of terms which are similar to drawn word/phrases via pseudo- counts for promotion. Thus, GPU caters for promo- tion of others terms in a principled manner. It has been previously used for unigram topic modeling in <ref type="bibr" target="#b22">(Mimno et al., 2011</ref>). In this work we leverage it for phrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Proposed PSM-GPU model</head><p>We optimize the collocations of relevant aspect words and phrases in the GPU framework in two ways:</p><p>Word to phrase: Intuitively, if an aspect word is as- signed to a topic then that topic should represent that aspect and to all other phrases in that aspect's phrase set (i.e., phrases containing that aspect) should be- long to the same topic. Thus, when an aspect word is assigned to a topic then each phrase in its aspect set is promoted with a small count in that topic. Phrase to word: When a phrase w d,s,j j=st+len−1 j=st is assigned to a topic, each component word w d,s,j where j ∈ [st, st+len−1] in it is also promoted with a certain small count, i.e., each word of that phrase is also assigned to that topic by a certain amount.</p><p>We now define the term promotion matrix, A for the GPU framework. Every element of A, A w,w refers to the promotion pseudocount, i.e., whenever a w was seen in an urn, we increment the count by A w,w of w . w, w can be word or phrases.</p><formula xml:id="formula_15">A w,w =                1 if w = w σ if w is an aspect word, w</formula><p>is a phrase ∈ Phrase set of w δ w is a word ∈ Phrase w 0 otherwise</p><p>To improve the ranking of phrases, the value of σ is kept greater than δ. Empirically values are given section 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">PSM-GPU Inference</head><p>Accounting the GPU process above, the approxi- mate Gibbs samplers for z and r take the following form:</p><formula xml:id="formula_17">p(z d,s = a|Z ¬d,s , R ¬d,s , W ¬d,s ) ∝ (n s d,a ) ¬d,s +α) (n s d,(·) ) ¬d,s +Aα) ×   V v=1 Γ( V w =1 (A v,w * n A a,w )+β) Γ( V w =1 (A v,w * n A a,w ) ¬d,s +β)     Γ( V v=1 V w =1 (A v,w * n A a,w )+V β) Γ( V v=1 V w =1 (A v,w * n A a,w ) ¬d,s +V β)   × V v=1 Γ(n B a,v +β) Γ((n B a,v ) ¬d,s +β) / Γ(n B a,(·) +V β) Γ((n B a,(·) ) ¬d,s +V β) (13) p(r d,s,j = 1|z d,s = a, w d,s,j = v, . . .) ∝ V w =1 (A v,w * n A a,w ) ¬d,s,j +β) V v=1 V w =1 (A v,w * n A a,w ) ¬d,s,j +V β × p CRF (r d,s,j−1 , r d,s,j = 1|v) (14)</formula><p>Similarly, phrasal opinion switch variable can be de- rived. The sampler for individual background words remains unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Evaluation</head><p>In this section, we evaluate our proposed models. We first detail our dataset, followed by baselines and results.  Dataset Statistics: For CRF training, we created a phrase labeled dataset of aspect opinion phrases using product reviews from Amazon across 4 do- mains each spanning 4 head aspects. In this work, head aspects for a domain are known a priori ei- ther directly using unsupervised topic induction or guided by domain knowledge (e.g. using aspect models such as ( <ref type="bibr" target="#b36">Zhao et al., 2010;</ref><ref type="bibr" target="#b3">Chen et al., 2013;</ref><ref type="bibr" target="#b23">Mukherjee and Liu, 2012)</ref>). Our focus is on phrase extraction and grouping. We labeled the positive and negative opinion phrases spans <ref type="table" target="#tab_3">(Table 3</ref>; col 2, 3) in the reviews following the annotation schemes in ( ) for embedded CRF training in PSM. <ref type="table" target="#tab_3">Table 3</ref> details our labeled data for CRF train- ing. This phrase boundary labeled dataset <ref type="table" target="#tab_3">(Table 3;</ref> col 2, 3) is "orthogonal" or disjoint from the data where the PSM model was fit and evaluated <ref type="table" target="#tab_3">(Table  3</ref>, col 4, 5). This avoids overfitting and makes a fair case for all the experiments of PSM. Preprocessing and Parameter Setting: We re- moved the stopwords, punctuation, special charac- ters and words appearing less than 5 times in each domain. For all models, posterior estimates of la- tent variables were taken with a sampling lag of 50 iterations post burn-in phase (of 200 iterations) with 2,000 iterations in total. Dirichlet priors were set to α = 50/K, where K is the number of topics (em- pirically set to 10 via pilot) and β = 0.1. The CRF parameters C = 1 and GPU parameters σ = 0.05 and δ = 0.01 were estimated using cross validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset and Parameter Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baselines</head><p>We consider the following relevant phrase extraction models as our baselines: PSM-GPU sMC-GPU LDA-P-GPU Router→Connection:"updating firmware secure connection", "dropping connection", "con- nection excellent", "instability wireless connection", "crashes entire connection", "updating", "kills current connection in- cluding downloads", "affected plugged connection","cable radio frequency connection", "halfway" Router→Connection:"connection big time", "signal weak time connection", "connection time sta- ble", "lose connection", "internet connection speed dropped", "stop working lot connection", "started dropping internet connection", "started dropping connection", "drop wireless connection drops wired connection", "connection dropping problems" Router→Connection:"drops", "times day internet connection", "internet connection multiple times", "internet connection times", "internet connection minutes", "dropping internet connection", "broadband internet connection", "extremely slow internet connection", "lost internet connection","internet connection couple" GPS→Screen:"poor screen con- trast daylight", "direction screen missing poor screen contrast", "slow screen size makes useless", "screen turned", "turn", "nothing screen", "night screen bit bright", "screen unpredictable directions", "lacks faster screen refresh rate", "smoother screen refresh"</p><p>GPS→Screen:"bright", "excellent nice touch screen", "touch screen n't", "nice big touch screen", "touch screen big size", "smaller", "touch screen but nice", "screen accurate spoken direction", "touch screen nice", "nice slim touch screen"</p><p>GPS→Screen:"smaller screen but dont", "wide screen", "nothing but screen", "ok but screen", "screen but normal", "screen size", "large screen", "better traffic features cons touch screen", "screen real estate than", "than years screen" <ref type="table">Table 2</ref>: Example aspect specific opinion phrases (comma delimited in order) discovered by PSM-GPU, sMC-GPU, LDA-P-GPU. Errors are italicized and marked in red.</p><p>LDA with phrases (LDA-P): As aspect-sentiment phrases are often noun phrases, a basic approach is to include the noun phrases (extracted using a parser) as separate terms in the corpus. Topical N-gram (TNG): The TNG model in ( <ref type="bibr" target="#b28">Wang et al., 2007</ref>) extends LDA to model n-grams of arbi- trary length. As aspects often appear close to their opinion in the sentence, topical n-grams for each as- pect form a natural baseline. We used the authors original implementation in the MALLET toolbox. LDA-P with GPU (LDA-P-GPU): This model is due to <ref type="bibr" target="#b7">(Fei et al., 2014</ref>) and is tailored for phrase extraction in opinion mining. It employs LDA with noun phrases in the GPU framework to rank the as- pect phrases higher in their topics. Our implemen- tations of LDA-P and LDA-P-GPU use the noun phrases discovered by the Stanford Parser. semi-Markov CRF with GPU(sMC-GPU): This model builds over the model of <ref type="bibr" target="#b33">(Yang and Cardie, 2012</ref>) that used dependency tree features and semi- CRF to model the arbitrarily long expressions. We used these expression spans as multiword in vocab- ulary. Then we employ GPU based sampling with LDA proposed by <ref type="bibr" target="#b7">(Fei et al., 2014</ref>) to collocate opin- ion expressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Qualitative Analysis</head><p>To assess the quality of extracted expressions, we la- beled the topics following instructions in <ref type="bibr" target="#b22">(Mimno et al., 2011</ref>). First, each topic was labeled as coher- ent or incoherent and an aspect name was given if the topic was coherent. Each topic was presented as a list of top 45 terms in descending order of their probabilities under that topic. A topic was consid- ered coherent if the terms in the topic were semanti- cally related to each other.</p><p>Next, for coherent topics, their terms were labeled as correct (if the terms semantics was relevant to the topic) or incorrect (otherwise). Two human judges were used in the annotation. Agreements being high (κ &gt; 0.78), disagreements were resolved upon con- sensus among judges. <ref type="table">Table 2</ref> reports the top 10 terms(words/phrases) for aspect 'connection' (Router domain) and aspect 'screen'(GPS domain) across PSM-GPU, sMC-GPU and LDA-P-GPU (the two closest competitor). We note that PSM-GPUs phrases are more expressive compared to sMC-GPU because sMC-GPU is prone to have longer phrases due to segment features but PSM's switch variable captured more relevant aspect specific opinion expressions. sMC-GPU has better </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain</head><p>PSM-GPU PSM sMC-GPU LDA-P-GPU TNG LDA-P P R F Ac. P R F Ac. P R F Ac. P R F Ac. P R F Ac. P R F Ac.  phrases compared to LDA-P-GPU because the lat- ter only considers noun phrases which may not al- ways be semantically coherent under an aspect. The qualitative results of other baselines TNG and LDA- P were worse than that of LDA-P-GPU and hence omitted due to space constraints. However, the sub- sequent experiments compare all models quantita- tively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Quantitative Analysis</head><p>We consider the following metrics and tasks: Average Precision: <ref type="figure" target="#fig_3">Figure 2</ref> shows the average Precision@n (p@n) for n = 15, 30, 45 of all coher- ent topics for each model in each domain. We note that PSM-GPU achieves the highest precision for all domains significantly (p &lt; 0.01) outperforming its closest competitor sMC-GPU. sMC-GPU tends to discover longer phrases due to segment features in semi-CRF and combined with GPU gains the max- imum strength among other baselines. Next in or- der are LDA-P-GPU, PSM, and TNG. We have not shown the result of LDA-P as its top terms didn't contain enough phrases and its precision scores were quite lower compared to other models. But it is worthwhile to note that PSM outperforms LDA-P- GPU (2nd best competitor) at lower ranks which is more important (e.g., in majority domains for p@15) and shows its effectiveness. It is a bit unfair to compare PSM with sMC-GPU because PSM is lack- ing phrase rank optimization whereas sMC-GPU en- forces it, and the p@n metric uses rank position as its goodness criterion. However, we will see that in an actual application task, both PSM and PSM-GPU does better than sMC-GPU. Also, we observed that p@45 is higher compare to p@15 or p@30. The reason is even though we are promoting the phrases using GPU it is not able to remove some aspect opin- ion words from top 15 terms due to their high occur- rence in phrases. For e.g. <ref type="table">Table 2</ref> has opinion words like "updating", "turn" which are considered incor- rect because of non-phrasal terms. # of coherent topics: <ref type="figure" target="#fig_3">Figure 2</ref> (rightmost chart) shows the number of coherent topics produced by each model. A model that can discover more co- herent topics is better. We find that PSM-GPU can discover more coherent topics with phrases than its baselines across all domains. The trends of other models are similar to p@n and can be analogously explained.</p><p>We note that the Topic Coherence (TC) metric in ( <ref type="bibr" target="#b22">Mimno et al., 2011</ref>) which is often used to approx- imate coherence in unigram topic models as it cor- relates with human notions of coherence, uses co- document frequency of individual words in topics.</p><p>However, in our problem as phrases are sparse, their co-document frequency is far lower than words. Hence, the TC metric is not directly applicable. Our measure of coherence is based on human judgment (achieves high agreements, κ &gt; 0.78 see Section 5.3) and from <ref type="table">Table 2</ref> we can see the discovered phrases do reflect coherence. Hence, to evaluate the phrases quantitatively, we employ an actual senti- ment classification task that uses the posterior of our models (top phrases) as features. This is reasonable because the estimated topics (when used as features) improve sentiment classification, it shows that they are meaningful and capable of capturing latent sen- timent that govern polarities. Sentiment Classification: For this task, instead of using all the words as features, we used the poste- rior on ϕ A (top 50 terms of ϕ A ) as features. For all models, all possible n-grams of top 50 terms are also considered as features. We trained SVMs 3 (using the SVMLight toolkit) with the features described above. Evaluation for this task employed 5-fold cross validation on the data in <ref type="table" target="#tab_3">Table 3</ref> (col 4, 5). For each test fold, the features were induced upon fitting the aspect extraction models on the training data of that fold. <ref type="table" target="#tab_5">From Table 4</ref> we note that both PSM-GPU and PSM outperform all competitors on average F1 across all domains. More specifically, we note that PSM alone that uses no rank optimization performs better than sMC-GPU employing phrasal rank op- timization under GPU scheme. We believe this is due to PSM's switching component that can dis- cover correct aspect/sentiment terms (sufficient for polarity classification) and rank it higher based on frequency even though the expressive aspect specific phrases remain ranked lower. sMC-GPU tends to have longer phrases so it does well, however, under GPU, longer phrases may not be promoted well as they lack anchor aspect terms under a relevant topic. LDA-P-GPU uses standard (Noun Phrases) NPs for phrases with rank optimization and hence is the next in performance order as NPs may not capture opin- ion well. TNG does not perform as well as it relies on multiword collocation as opposed to NP/VP for phrase extraction. LDA-P's performance is lowest as it cannot rank the relevant NPs high. PSM-GPU has the right balance of phrase boundary span and phrasal rank optimization via GPU that makes it sig- nificantly outperform (p &lt; 0.01) all competitors.  Sequence Model Sensitivity: To assess the robust- ness of the hybrid framework, we evaluate the sensi- tivity of the embedded CRF model via domain abla- tion. We choose the best performer PSM-GPU and ablate each domain during its CRF training. We re- peat the previous experiment on sentiment classifi- cation using the ablated model. From the results in <ref type="table" target="#tab_7">Table 5</ref>, we note that the reduction in precision is relatively more than that of recall. However, the F1 score does not drop significantly (compared to <ref type="table" target="#tab_5">Table  4</ref>) for any domain showing the robustness of the hy- brid framework. We note that even with some skew- ness in the labeled data <ref type="table" target="#tab_3">(Table 3)</ref>, CRF is not over- fitting here and the proposed pivot features <ref type="table" target="#tab_0">(Table  1)</ref> are powerful enough to learn the phrasal structure across domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper presented a novel hybrid framework for aspect specific opinion expression extraction. Two models PSM and PSM-GPU were proposed that employ CRF discriminative sequence modeling for phrase boundary extraction and generative modeling for grouping relevant terms under a topic. PSM- GPU further optimized the aspect coherence using the generalized Pólya urn sampling scheme. Ex- perimental results showed that the proposed hybrid models can extract more coherent aspect specific opinion expressions significantly outperforming all competitors across all domains and are robust in cross-domain knowledge transfer.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Plate Notation of PSM datasets. In SemEval 2015, Aspect based Sentiment Analysis Task (Pontiki et al., 2015), a dataset was produced that had annotations for aspect phrases. The focus was on aspect phrases as opposed to aspect-sentiment phrases. The MPQA 2.0 corpus (Wiebe et al., 2005) has some labeled opinion expressions, but they are generic subjective expressions as opposed to aspect-sentiment phrases (see Section 1) we find in reviews. Zhao et al., (2011) extracts topical phrase in tweets using relevance and interestingness. Wu et al., (2009) proposed a phrase dependency parsing approach to extract product feature (aspect expression) and opinion expression and the relation between them. They considered all noun and verb phrases (NPs, VPs) as product features and its surrounding dictionary opinion words as opinions. Features were constructed using phrase dependency tree to extract relation among all product features and opinions that were later used in aspect and opinion expression extraction. Although, Wu et al., (2009) doesn't discover aspect specific opinion phrases, its use of NPs in extracting candidate opinion phrases is similar to Fei et al., (2014) which is considered as a baseline.</figDesc><graphic url="image-1.png" coords="3,72.00,57.83,233.99,139.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>d,s,j and each phrase r d,s m d ,j j=st+len−1 j=st of vocabulary where each switch variable r ∈ {0, 1}. To generate each term w d,s m d ,j j=st+len−1 j=st of the labeled sequence s m∈{1...M } d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Pivot Features: We consider five feature families: POS Tags (T): DT, IN, JJ, MD, NN, RB, VB, etc. Phrase Chunks (C): ADJP, ADVP, NP, PP, VP, etc. Prefixes (P): anti, in, mis, non, pre, sub, un</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Charts from left to right are Topical words Precision@15, Precision@30, Precision@45 of coherent topics of each model and last one is number of coherent topics of each model.</figDesc><graphic url="image-2.png" coords="8,72.00,57.83,468.00,101.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Pivot Templates: Subscript i denotes the index of the head aspect, HA (italicized). Subscript j denotes the 
index relative to i 

Suffixes (S): able, est, ful, ic, ing, ive, ness etc. 
Word Sentiment Polarity (SP): POS, NEG, NEU 
Pivoting on the head aspect, we look forward and 
backward to generate a family of binary features de-
fined by a specific template (see Table 1). Each tem-
plate generates several features that capture various 
positional context around the HA. Additionally, we 
consider up to 3 rd order pivot features allowing us to 
model various dependencies as features. For polar-
ity, we used the opinion lexicon 2 derived from (Hu 
and Liu, 2004). 
Feature Templates: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : Statistics of dataset of four domain</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Sentiment classification: Precision, Recall, F1 and accuracy from top to down for each domain and each 
model 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Domain ablation result on polarity classification 

</table></figure>

			<note place="foot" n="3"> Using an RBF kernel (C = 10, g = 0.01) which performed best upon tuning various SVM parameters via cross validation.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work was supported in part by NSF 1527364.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Opinion expression mining by exploiting keyphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Berend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1162" to="1170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Identifying expressions of opinion in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2683" to="2688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An unsupervised aspect-sentiment model for online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noemie</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="804" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploiting domain knowledge in aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meichun</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malu</forename><surname>Castellanos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riddhiman</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1655" to="1667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Identifying sources of opinions with conditional random fields and extraction patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing</title>
		<meeting>the conference on Human Language Technology and Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="355" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Joint extraction of entities and relations for opinion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="431" to="439" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Scalable topical phrase mining from text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>El-Kishky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanglei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="305" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Review topic discovery with phrases using the pólya urn model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geli</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="667" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discovering correspondence of sentiment words and aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geli</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Brett Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 17th International Conference on Intelligent Text Processing and Computational Linguistics</title>
		<meeting>the 17th International Conference on Intelligent Text Processing and Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Extracting opinion targets in a single-and cross-domain setting with conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niklas</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 conference on empirical methods in natural language processing</title>
		<meeting>the 2010 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1035" to="1045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Aspect and sentiment unification model for online review analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohan</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth ACM international conference on Web search and data mining</title>
		<meeting>the fourth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="815" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Extracting opinion expressions and their polarities: exploration of pipelines and joint models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="101" to="106" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extracting opinions, opinion holders, and topics expressed in online news media text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Soo-</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Sentiment and Subjectivity in Text</title>
		<meeting>the Workshop on Sentiment and Subjectivity in Text</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Extracting aspect-evaluation and aspect-of relations in opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nozomi</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1065" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Crf++: Yet another crf toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Extracting verb expressions implying negative opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huayi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2411" to="2417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A phrase-discovering topic model using hierarchical pitman-yor processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">P</forename><surname>Lindsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename><surname>Headden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stipicevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="214" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A survey of opinion mining and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mining text data</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="415" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mining quality phrases from massive text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2015 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1729" to="1744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Topic sentiment mixture: modeling facets and opinions in weblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Wondra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on World Wide Web</title>
		<meeting>the 16th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optimizing semantic coherence in topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edmund</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Talley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Leenders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="262" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Aspect extraction through semi-supervised modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="339" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Extracting aspect specific sentiment expres-sions implying negative opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 17th International Conference on Intelligent Text Processing and Computational Linguistics</title>
		<meeting>the 17th International Conference on Intelligent Text Processing and Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 12: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="486" to="495" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics, Denver, Colorado</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Content models with attitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Sauper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="350" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Modeling online reviews with multi-grain topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th international conference on World Wide Web</title>
		<meeting>the 17th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Topical n-grams: Phrase and topic discovery, with an application to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuerui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="702" />
		</imprint>
	</monogr>
	<note>Data Mining, 2007. ICDM</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mining aspect-specific opinion using a holistic lifelong topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web</title>
		<meeting>the 25th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity in phrase-level sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on human language technology and empirical methods in natural language processing</title>
		<meeting>the conference on human language technology and empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="347" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Phrase dependency parsing for opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lide</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1533" to="1541" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Extracting opinion expressions with semi-markov conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1335" to="1345" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Joint inference for fine-grained opinion extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1640" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Joint modeling of opinion expression extraction and attribute classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="505" to="516" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Jointly modeling aspects and opinions with a maxent-lda hybrid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Topical keyphrase extraction from twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Palakorn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ee-Peng</forename><surname>Achananuparp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="379" to="388" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
