<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Reinforcement Learning with a Combinatorial Action Space for Predicting Popular Reddit Threads</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>He</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
							<email>{jvking, ostendor}@uw.edu †</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<postCode>98195</postCode>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Reinforcement Learning with a Combinatorial Action Space for Predicting Popular Reddit Threads</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1838" to="1848"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce an online popularity prediction and tracking task as a benchmark task for reinforcement learning with a combinatorial, natural language action space. A specified number of discussion threads predicted to be popular are recommended, chosen from a fixed window of recent comments to track. Novel deep reinforcement learning architectures are studied for effective modeling of the value function associated with actions comprised of interdependent sub-actions. The proposed model, which represents dependence between sub-actions through a bi-directional LSTM, gives the best performance across different experimental configurations and domains, and it also generalizes well with varying numbers of recommendation requests.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper is concerned with learning policies for sequential decision-making tasks, where a system takes actions given options characterized by natu- ral language with the goal of maximizing a long- term reward. More specifically, we consider tasks with a combinatorial action space, where each ac- tion is a set of multiple interdependent sub-actions. The problem of a combinatorial natural language ac- tion space arises in many applications. For example, in real-time news feed recommendation, a user may want to read diverse topics of interest, and an ac- tion (i.e. recommendation) from the computer agent would consist of a set of news articles that are not all similar in topics ( <ref type="bibr" target="#b42">Yue and Guestrin, 2011</ref>). In adver- tisement placement, an action is a selection of sev- eral ads to display, and bundling with complemen- tary products might receive higher click-through- rate than displaying all similar popular products.</p><p>In this work, we consider Reddit popularity pre- diction, which is similar to newsfeed recommenda- tion but different in two respects. First, our goal is not to make recommendations based on an indi- vidual's preferences, but instead based on the antic- ipated long-term interest level of a broad group of readers from a target community. Second, we try to predict rather than detect popularity. Unlike individ- ual interests, community interest level is not often immediately clear; there is a time lag before the level of interest starts to take off. Here, the goal is for the recommendation system to identify and track writ- ten documents (e.g. news articles, comments in dis- cussion forum threads, or scientific articles) in real time -attempting to identify hot updates before they become hot to keep the reader at the leading edge. The premise is that the user's bandwidth is limited, and only a limited number of things can be recom- mended out of several possibilities. In our experi- mental work, we use discussion forum text, where the recommendations correspond to recent posts or comments, assessing interest based on community response as observed in "likes" or other positive re- actions to those comments. For training purposes, we can use community response measured at a time much later than the original post or publication. This problem is well-suited to the reinforcement learn- ing paradigm, since the reward (the level of com- munity uptake or positive response) is not immedi- ately known, so the system needs to learn a mecha- nism for estimating future reactions. Different from typical reinforcement learning, the action space is combinatorial since an action corresponds to a set of comments (sub-actions) chosen from a larger set of candidates. A sub-action is a written comment (or document, for another variant of this task).</p><p>Two challenges associated with this problem in- clude the potentially high computational complexity of the combinatorial action space and the develop- ment of a framework for estimating the long-term reward (the Q-value in reinforcement learning) from a combination of sub-actions characterized by nat- ural language. Here, we focus on the second prob- lem, exploring different deep neural network archi- tectures in an effort to efficiently account for the po- tential redundancy and/or temporal dependency of different sub-actions in relation to the state space. We sidestep the computational complexity issue (for now) by working with a task where the number of combinations is not too large and by further reduc- ing costs by random sampling.</p><p>There are two main contributions in this paper. First, we propose a novel reinforcement learning task with both states and combinatorial actions de- fined by natural language, 1 which is introduced in section 2. This task, which is based on comment popularity prediction using data from the Reddit dis- cussion forum, can serve as a benchmark in social media recommendation and trend spotting. The sec- ond contribution is the development of a novel deep reinforcement learning architecture for handling a combinatorial action space associated with natural language. Prior work related to both the task and deep reinforcement learning is reviewed in section 3, Details for the new models and baseline architec- tures are described in section 4. Experimental re- sults in section 5 show the proposed methods outper- form baseline models and that a bidirectional LSTM is effective for characterizing the combined utility of sub-actions. A brief summary of findings and open questions are in section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Popularity Prediction and Tracking</head><p>Our experiments are based on Reddit 2 , one of the world's largest public discussion forums. On Red- 1 Simulator code and Reddit discussion identifiers are re- leased at https://github.com/jvking/reddit-RL- simulator 2 http://www.reddit.com dit, registered users initiate a post and people re- spond with comments, either to the original post or one of its associated comments. Together, the com- ments and the original post form a discussion tree, which grows as new comments are contributed. It has been show that discussions tend to have a hier- archical topic structure <ref type="bibr" target="#b39">(Weninger et al., 2013</ref>), i.e. different branches of the discussion reflect narrow- ing of higher level topics. Reddit discussions are grouped into different domains, called subreddits, according to different topics or themes. Depending on the popularity of the subreddit, a post can receive hundreds of comments. Comments (and posts) are associated with posi- tive and negative votes (i.e., likes and dislikes) from registered users that are combined to get a karma score, which can be used as a measure for popularity. An example of the top of a Reddit discussion tree is given in <ref type="figure" target="#fig_0">Figure 1</ref>. The scores in red boxes mark the current karma (popularity) of each comment, and it is quite common that a lower karma comment (e.g. "Yeah, politics aside, this one looks much cooler", compared to "looks more like zom-bama") will lead to more children and popular comments in the fu- ture (e.g. "true dat"). Note that the karma scores are dynamic, changing as readers react to the evolv- ing discussion and eventually settling down as the discussion trails off. In a real-time comment recom- mendation system, the eventual karma of a comment is not immediately available, so prediction of pop- ularity is based on the text in the comment in the context of prior comments in the subtree and other comments in the current time window.</p><p>Popularity prediction and tracking in the Reddit setting is used in this paper for studying reinforce- ment learning to model long-term rewards in a com- binatorial action space. At each time step, the state corresponds to the collection of comments previ- ously recommended. The system aims at automat- ically picking a few lines of the discussion to follow from the new set of comments in a given window, which is a combinatorial action. Thread popular- ity tracking can be thought of as a proxy task for news or scientific article recommendation. It has the advantages that "documents" (comments) are rela- tively short and that the long-term reward can be characterized by Reddit voting scores, which makes this task easier to work with for algorithm develop- ment than these larger related tasks.</p><p>In this work, we only consider new comments as- sociated with the threads of the discussion that we are currently following to limit the number of pos- sible sub-actions at each time step and with the as- sumption that prior context is needed to interpret the comments. In other words, the new recommendation should focus on comments that are in the subtrees of previously recommended comments. (A variant re- laxing this restriction is suggested in the conclusion section.) Typically, one would expect some inter- dependencies between comments made in the same window if they fall under the same subtree, because they correspond to a reply to the same parent. In addition, there may be some temporal dependency, since one sub-action may be a comment on the other. These dependencies will affect the combined utility of the sub-actions.</p><p>According to our experiments, the performance is significantly worse when we learn a myopic policy compared to reinforcement learning with the same feature set. This shows that long-term dependency indeed matters, as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. This serves as a justification that reinforcement learning is an appropriate approach for modeling popularity of a discussion thread.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>There is a large body of work on reinforcement learning. Among those of most interest here are deep reinforcement learning methods that leverage neural networks because of their success in handling large discrete state/action spaces. Early work such as TD-gammon used a neural network to approxi- mate the state value function <ref type="bibr" target="#b36">(Tesauro, 1995)</ref>. Re- cent advances in deep learning ( <ref type="bibr" target="#b18">LeCun et al., 2015;</ref><ref type="bibr" target="#b5">Deng and Yu, 2014;</ref><ref type="bibr" target="#b15">Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b31">Sordoni et al., 2015</ref>) inspired significant progress by combining deep learning with reinforce- ment learning <ref type="bibr" target="#b23">(Mnih et al., 2015;</ref><ref type="bibr" target="#b6">Duan et al., 2016)</ref>. In natu- ral language processing, reinforcement learning has been applied successfully to dialogue systems that generate natural language and converse with a hu- man user ( <ref type="bibr" target="#b28">Scheffler and Young, 2002;</ref><ref type="bibr" target="#b30">Singh et al., 1999;</ref><ref type="bibr" target="#b38">Wen et al., 2016)</ref>. There has also been in- terest in mapping text instructions to sequences of executable actions and extracting textual knowledge to improve game control performance <ref type="bibr" target="#b2">(Branavan et al., 2009;</ref><ref type="bibr" target="#b3">Branavan et al., 2011</ref>).</p><p>Recently, Narasimhan et al. (2015) studied the task of text-based games with a deep Q-learning framework. <ref type="bibr" target="#b11">He et al. (2016)</ref> proposed to use a sepa- rate deep network for handling natural language ac- tions and to model Q-values via state-action interac- tion. <ref type="bibr" target="#b26">Nogueira and Cho (2016)</ref> have also proposed a goal-driven web navigation task for language- based sequential decision making. <ref type="bibr" target="#b25">Narasimhan et al. (2016)</ref> applied reinforcement learning for acquir- ing and incorporating external evidence to improve information extraction accuracy. The study that we present with Reddit popularity tracking differs from these other text-based reinforcement learning tasks in that the language in both state and action spaces is unconstrained and quite rich. <ref type="bibr" target="#b7">Dulac-Arnold et al. (2016)</ref> also investigated a problem of large discrete action spaces. A Wolper- tinger architecture is proposed to reduce computa- tional complexity of evaluating all actions. While a combinatorial action space can be large and discrete, their method does not directly apply in our case, be- cause the possible actions are changing over differ- ent states. In addition, our work differs in that its fo- cus is on modeling the combined action-value func- tion rather than on reducing computational com- plexity. Other work that targets a structured action space includes: an actor-critic algorithm, where ac- tions can have real-valued parameters <ref type="bibr" target="#b10">(Hausknecht and Stone, 2016)</ref>; and the factored Markov Decision Process (MDP) ( <ref type="bibr" target="#b9">Guestrin et al., 2001;</ref><ref type="bibr" target="#b27">Sallans and Hinton, 2004)</ref>, with certain independence assump- tions between a next-state component and a sub- action. As for a bandits setting, Yue and Guestrin (2011) considered diversification of multi-item rec- ommendation, but their methodology is limited to using linear approximation with hand-crafted fea- tures.</p><p>The task explored in our paper -detecting and tracking popular threads in a discussion -is some- what related to topic detection and tracking <ref type="bibr" target="#b0">(Allan, 2012;</ref><ref type="bibr" target="#b22">Mathioudakis and Koudas, 2010)</ref>, but it dif- fers in that the goal is not to track topics based on frequency, but rather based on reader response. Thus, our work is more closely related to popu- larity prediction for social media and online news. These studies have explored a variety of definitions (or measurements) of popularity, including: the vol- ume of comments in response to blog posts ( <ref type="bibr" target="#b41">Yano and Smith, 2010)</ref> and news articles ( <ref type="bibr" target="#b34">Tasgkias et al., 2009;</ref><ref type="bibr" target="#b35">Tatar et al., 2011</ref>), the number of Twitter shares of news articles ( <ref type="bibr" target="#b1">Bandari et al., 2012)</ref>, the number of reshares on Facebook ( <ref type="bibr" target="#b4">Cheng et al., 2014</ref>) and retweets on Twitter ( <ref type="bibr" target="#b32">Suh et al., 2010;</ref><ref type="bibr" target="#b13">Hong et al., 2011;</ref><ref type="bibr" target="#b33">Tan et al., 2014;</ref><ref type="bibr" target="#b43">Zhao et al., 2015)</ref>, the rate of posts related to a source rumor <ref type="bibr" target="#b21">(Lukasik et al., 2015)</ref>, and the difference in the number of reader up and down votes on posts and comments in Reddit discussion forums ( <ref type="bibr" target="#b16">Lakkaraju et al., 2013;</ref><ref type="bibr" target="#b14">Jaech et al., 2015</ref>). An advantage of working with the Red- dit data is that both positive and negative reactions are accounted for in the karma score. Of the prior work on Reddit, the task explored here is most simi- lar to <ref type="bibr" target="#b14">(Jaech et al., 2015</ref>) in that it involves choosing relatively high karma comments (or threads) from a time-limited set rather than directly predicting com- ment (or post) karma. Prior work on popularity prediction used supervised learning; this is the first work that frames tracking hot topics in social media with deep reinforcement learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Characterizing a combinatorial action space 4.1 Notation</head><p>In this sequential decision making problem, at each time step t, the agent receives a text string that de- scribes the state s t ∈ S (i.e., "state-text") and picks a text string that describes the action a t ∈ A (i.e., "action-text"), where S and A denote the state and action spaces, respectively. Here, we assume a t is chosen from a set of given candidates. In our case both S and A are described by natural language. Given the state-text and action-texts, the agent aims to select the best action in order to maximize its long-term reward. Then the environment state is up- dated s t+1 = s according to a probability p(s |s, a), and the agent receives a reward r t+1 for that partic- ular transition. We define the action-value function (i.e. the Q-function) Q(s, a) as the expected return starting from s and taking the action a:</p><formula xml:id="formula_0">Q(s, a) = E +∞ l=0 γ l r t+1+l |s t = s, a t = a</formula><p>where γ ∈ (0, 1) denotes a discount factor. The Q-function associated with an optimal policy can be found by the Q-learning algorithm ( <ref type="bibr" target="#b37">Watkins and Dayan, 1992)</ref>:</p><formula xml:id="formula_1">Q(s t , a t ) ← Q(s t , a t )+ η t · r t+1 + γ · max a Q(s t+1 , a) − Q(s t , a t )</formula><p>where η t is a learning rate parameter. The set of comments that are being tracked at time step t is denoted as M t . All previously tracked com- ments, as well as the post (root node of the tree), is considered as state s t (s t = {M 0 , M 1 , · · · , M t }), and we initialize s 0 = M 0 to be the post. An action is taken when a total of N new comments {c t,1 , c t,2 , · · · , c t,N } appear as nodes in the subtree of M t , and the agent picks a set of K comments to be tracked in the next time step t + 1. Thus we have:</p><formula xml:id="formula_2">a t = {c 1 t , c 2 t , · · · , c K t }, c i t ∈ {c t,1 , c t,2 , · · · , c t,N } and c i t = c j t if i = j<label>(1)</label></formula><p>and M t+1 = a t . At the same time, by taking ac- tion a t at state s t , the reward r t+1 is the accumulated karma scores, i.e. sum over all comments in M t+1 . Note that the reward signal is used in online train- ing, while at model deployment (testing stage), the scores are only used as an evaluation metric. Following the reinforcement learning tradition, we call tracking of a single discussion tree from start (root node post) to end (no more new comments ap- pear) an episode. We also randomly partition all discussion trees into separate training and testing sets, so that texts seen by the agent in training and testing are from the same domain but different dis- cussions. For each episode, depending on whether training/testing, the simulator randomly picks a dis- cussion tree, and presents the agent with the current state and N new comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Q-function alternatives</head><p>With the real-time setting, it is clear that action a t will affect the next state s t+1 and furthermore the future expected reward. The action a t consists of K comments (sub-actions), making modeling Q-values Q(s t , a t ) difficult. To handle a large state space, Our baseline models include Linear, PA- DQN and DRRN. We concatenate the K sub- actions/comments to form the action representation. The Linear and PA-DQN <ref type="figure" target="#fig_2">(Figure 2(a)</ref>) take as input a concatenation of state and action representations, and model a single Q-value Q(s t , a t ) using linear or DNN function approximations. The DRRN consists of a pair of DNNs, one for the state-text embedding and the other for action-text embeddings, which are then used to compute Q(s t , a t ) via a pairwise interaction function <ref type="figure" target="#fig_2">(Figure 2(b)</ref>).</p><p>One simple alternative approach by utilizing this combinatorial structure is to compute an embedding for each sub-action c i t . We can then model the value in picking a particular sub-action, Q(s t , c i t ), through a pairwise interaction between the state and this sub- action. Q(s t , c i t ) represents the expected accumu- lated future rewards by including this sub-action. The agent then greedily picks the top-K sub-actions with highest values to achieve the highest Q(s t , a t ). In this approach, we are assuming the long-term re- wards associated with sub-actions are independent of each other. More specifically, greedily picking the top-K sub-actions is equivalent to maximizing the following action-value function:</p><formula xml:id="formula_3">Q(s t , a t ) = K i=1 Q(s t , c i t )<label>(2)</label></formula><p>while satisfying (1). We call this proposed method DRRN-Sum, and its architecture is shown in <ref type="figure" target="#fig_2">Figure  2</ref>(c). Similarly as in DRRN, we use two networks to embed state and actions separately. However, for different sub-actions, we keep the network param- eters tied. We also use the same top layer dimen- sion and the same pairwise interaction function for all sub-actions.</p><p>In the case of a linear additive interaction, such as an inner product or bilinear operation, Equation <ref type="formula" target="#formula_3">(2)</ref> is equivalent to computing the interaction be- tween the state embedding and an action embed- ding, where the action embedding is obtained lin- early by summing over K sub-action embeddings. When sub-actions have strong correlation, this in- dependence assumption is invalid and can result in a poor estimation of Q(s t , a t ). For example, most people are interested in the total information stored in the combined action a t . Due to content redun- dancy in the sub-actions c 1 t , c 2 t , · · · , c K t , we expect Q(s t , a t ) to be smaller than i Q(s t , c i t ). To come up with a general model for handling a combinatorial action-value function, we further pro- pose the DRRN-BiLSTM <ref type="figure" target="#fig_2">(Figure 2(d)</ref>). In this ar- chitecture, we use a DNN to generate an embedding for each comment. Then a Bidirectional Long Short- Term Memory ( <ref type="bibr" target="#b8">Graves and Schmidhuber, 2005</ref>) is used to combine a sequence of K comment embed- dings. As the Bidirectional LSTM has a larger ca- pacity due to its nonlinear structure, we expect it will capture more details on how the embeddings for the sub-actions combine into an action embedding. Note that both of our proposed methods (DRRN- Sum and DRRN-BiLSTM) can handle a varying value of K, while for the DQN and DRRN baselines, we need to use a fixed K in training and testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Experimental Configurations</head><p>Our data consists of 5 subreddits (askscience, askmen, todayilearned, worldnews, nfl) with diverse  In our experiments, in order to have long enough discussion threads, we filter out discussion trees with fewer than 100 comments. For each subreddit, we randomly partition 90% of the data for online training, and 10% of the data for test- ing (deployment). The basic subreddit statistics are shown in <ref type="table">Table 1</ref>. We report the random policy per- formances and heuristic upper bound performances (averaged over 10,000 episodes) in <ref type="table" target="#tab_2">Table 2</ref> and Ta- ble 3. <ref type="bibr">3</ref> The upper bound performances are obtained using stabilized karma scores and offline constructed tree structure. The mean and standard deviation are obtained by 5 independent runs. In all our experiments we set N = 10. Explicitly representing all N -choose-K actions requires a lot of memory and does not scale up. We therefore use a variant of Q-learning: when taking the max over <ref type="bibr">3</ref> Upper bounds are estimated by greedily searching through each discussion tree to find K max karma discussion threads (overlapped comments are counted only once). This upper bound may not be attainable in a real-time setting.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subreddit</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random</head><p>Upper bound 2 201.0 (2.1) 1991.3 (2.9) 3</p><p>321.3 (7.0) 2109.0 (16.5) 4 447. <ref type="bibr">1 (10.8)</ref> 2206.6 (8.2) 5 561.3 (18.8) 2298.0 (29.1) <ref type="table">Table 3</ref>: Mean and standard deviation of random and upper- bound performance on askscience, with N = 10 and K = 2, 3, 4, 5.</p><p>possible next-actions, we instead randomly subsam- ple m actions and take the max over them. We set m = 10 throughout our experiments. This heuristic technique works well in our experiments.</p><p>For text preprocessing we remove punctuation and lowercase capital letters. For each state s t and comment c i t , we use a bag-of-words representation with the same vocabulary in all networks. The vo- cabulary contains the most frequent 5,000 words; the out-of-vocabulary rate is 7.1%.</p><p>In terms of the Q-learning agent, fully-connected neural networks are used for text embeddings. The network has L = 2 hidden layers, each with 20 nodes, and model parameters are initialized with small random numbers. -greedy is used for exploration-exploitation, and we keep = 0.1 throughout online training and testing. We pick the discount factor γ = 0.9. During online training, we use experience replay <ref type="bibr" target="#b20">(Lin, 1992)</ref> and the memory size is set to 10,000 tuples of (s t , a t , r t+1 , s t+1 ). For each experience replay, 500 episodes are generated and stored in a first-in-first-out fashion, and multi- ple epochs are trained for each model. Minibatch stochastic gradient descent is implemented with a batch size of 100. The learning rate is kept constant:</p><formula xml:id="formula_4">η t = 0.000001.</formula><p>The proposed methods are compared with three baseline models: Linear, per-action DQN (PA- DQN), and DRRN. For both Linear and PA-DQN, the state and comments are concatenated as an in- put. For the DRRN, the state and comments are sent through two separate deep neural networks. How- ever, in our baselines, we do not explicitly model how values associated with each comment are com- bined to form the action value. For the DRRN baseline and proposed methods (DRRN-Sum and DRRN-BiLSTM), we use an inner product as the pairwise interaction function. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Results</head><p>In <ref type="figure" target="#fig_3">Figure 3</ref> we provide learning curves of differ- ent models on the askscience subreddit during on- line learning. In this experiment, we set N = 10, K = 3. Each curve is obtained by averaging over 3 independent runs, and the error bars are also shown. All models start with random performance, and converge after approximately 15 experience re- plays. The DRRN-Sum converges as fast as baseline models, with better converged performance. DRRN- BiLSTM converges slower than other methods, but with the best converged performance. After we train all the models on the training set, we fix the model parameters and apply (deploy) on the test set, where the models predict which action to take but no reward is shown until evaluation. The test performance is averaged over 1000 episodes, and we report mean and standard deviation over 5 independent runs.</p><p>On askscience, we try multiple settings with N = 10, K = 2, 3, 4, 5 and the results are shown in Ta- ble 4. Both DRRN-Sum and DRRN-BiLSTM con- sistently outperform baseline methods. The DRRN- BiLSTM performs better with larger K, probably due to the greater chance of redundancy in combin- ing more sub-actions.</p><p>We also perform online training and test across different subreddits. With N = 10, K = 3, the test performance gains over the linear baseline are shown in <ref type="figure" target="#fig_4">Figure 4</ref>. Again, the test performance is</p><formula xml:id="formula_5">K Linear PA-DQN DRRN DRRN-Sum DRRN-BiLSTM 2</formula><p>553.3 (2.8) 556.8 (14.5) 553.0 (17.5) 569.6 (18.4) 573.2 (12.9) 3 656.2 (22.5) 668.3 (19.9) 694.9 <ref type="bibr">(15.5)</ref> 704.3 (20.1) 711.1 (8.7) 4 812.5 (23.4) 818.0 (29.9) 828.2 <ref type="bibr">(27.5)</ref> 829.9 (13.2) 854.7 (16.0) 5 861.6 (28.3) 884.3 (11.4) 921.8 (10.7) 942.3 (19.1) 980.9 (21.1)    In actual model deployment, a possible scenario is that users may have different requests. For exam- ple, a user may ask the agent to provide K = 2 dis- cussion threads on one day, due to limited reading time, and ask the agent to provide K = 5 discus- sion threads on the other day. For the baseline mod- els (Linear, PA-DQN, DRRN), we will need to train separate models for different K's. The proposed methods (DRRN-Sum and DRRN-BiLSTM), on the other hand, can easily handle a varying K. To test whether the performance indeed generalizes well, we train proposed models on askscience with N = 10, K = 3 and test them with N = 10, K ∈ 2, 4, 5, as shown in <ref type="table" target="#tab_5">Table 5</ref>. Compared to the proposed models that are specifically trained for these K's <ref type="table" target="#tab_3">(Table 4)</ref>, the generalized test performance indeed degrades, as expected. However, in many cases, our proposed methods still outperform all three base- lines (Linear, PA-DQN and DRRN) that are trained specifically for these K's. This shows that the pro- posed methods can generalize to varying K's even if it is trained on a particular value of K.</p><p>In <ref type="table">Table 6</ref>, we show an anecdotal example with state and sub-actions. The two sub-actions are strongly correlated and have redundant information. By combining the second sub-action compared to choosing just the first sub-action alone, DRRN-Sum and DRRN-BiLSTM predict 86% and 26% relative increase in action-value, respectively. Since these two sub-actions are highly redundant, we hypothe- size DRRN-BiLSTM is better than DRRN-Sum at capturing interdependency between sub-actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we introduce a new reinforcement learning task associated with predicting and tracking popular threads on Reddit. The states and actions State text (partially shown) Are there any cosmological phenomena that we strongly suspect will occur, but the universe just isn't old enough for them to have happened yet? Comments (sub-actions) (partially shown) <ref type="bibr">[1]</ref> White dwarf stars will eventually stop emitting light and become black dwarfs. <ref type="bibr">[2]</ref> Yes, there are quite a few, such as: White dwarfs will cool down to black dwarfs. <ref type="table">Table 6</ref>: An example state and its sub-actions are all described by natural language so the task is useful for language studies. We then develop novel deep Q-learning architectures to better model the state-action value function with a combinatorial ac- tion space. The proposed DRRN-BiLSTM method not only performs better across different experimen- tal configurations and domains, but it also general- izes well for scenarios where the user can request changes in the number tracked.</p><p>This work represents a first step towards address- ing the popularity prediction and tracking problem. While performance of the system beats several base- lines, it still falls far short of the oracle result. Prior work has shown that timing is an important factor in predicting popularity ( <ref type="bibr" target="#b17">Lampe and Resnick, 2004;</ref><ref type="bibr" target="#b14">Jaech et al., 2015)</ref>, and all the proposed models would benefit from incorporating this information. Another variant might consider short-term reactions to a comment, if any, in the update window. It would also be of interest to explore implementations of backtracking in the sub-action space (incurring a cost), in order to recommend comments that were not selected earlier but have become highly popular. Lastly, it will be important to study principled solu- tions for handling the computational complexity of the combinatorial action space.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A snapshot of the top of a Reddit discussion tree, where karma scores are shown in red boxes.</figDesc><graphic url="image-1.png" coords="2,330.61,57.90,192.10,150.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Mnih et al.</head><label></label><figDesc>(2015) proposed a Deep Q-Network (DQN). In case of a large action space, we may use both state and action representations as input to a deep neural network. It is shown that the Deep Reinforcement Relevance Network (DRRN, Figure 2(b)), i.e. two separate deep neural networks for modeling state embedding and action embedding, performs better than per-action DQN (PA-DQN in Figure 2(a)), as well as other DQN variants for deal- ing with natural language action spaces (He et al., 2016).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Different deep Q-learning architectures</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Learning curves of baselines and proposed methods on "askscience"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Average karma score gains over the linear baseline and standard deviation across different subreddits (with N = 10, K = 3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Mean and standard deviation of random and upper-

bound performance (with N = 10, K = 3) across different 

subreddits. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 : On askscience, average karma scores and standard deviation of baselines and proposed methods (with N = 10)</head><label>4</label><figDesc></figDesc><table>0 

20 

40 

60 

80 

100 

120 

140 

askscience 
askmen 
todayilearned 
worldnews 
nfl 
Average reward (Karma scores) 

Linear 
PA-DQN 
DRRN 
DRRN-Sum 
DRRN-BiLSTM 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>On askscience, average karma scores and standard de-

viation of proposed methods trained with K = 3 and test with 

different K's 

averaged over 1000 episodes, and we report mean 
and standard deviation over 5 independent runs. The 
findings are consistent with those for askscience. 
Since different subreddits may have very different 
karma scores distributions and language style, this 
suggests the algorithms apply to different text gen-
res. 
</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Topic detection and tracking: eventbased information organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The pulse of news in social media: forecasting popularity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roja</forename><surname>Bandari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sitaram</forename><surname>Asur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Huberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. AAAI Conf. Web and Social Media (ICWSM)</title>
		<meeting>Int. AAAI Conf. Web and Social Media (ICWSM)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Reinforcement learning for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R K</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP</title>
		<meeting>of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009-08" />
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to win by reading manuals in a Monte-Carlo framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="268" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Can cascades be predicted?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lada</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Alex</forename><surname>Dow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. World Wide Web</title>
		<meeting>Int. Conf. World Wide Web</meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep learning: Methods and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="197" to="387" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Benchmarking deep reinforcement learning for continuous control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Machine Learning (ICML)</title>
		<meeting>the 33rd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dulac-Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Van Hasselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sunehag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hunt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.07679</idno>
		<title level="m">Deep reinforcement learning in large discrete action spaces</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional LSTM and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multiagent planning with factored MDPs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Parr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1523" to="1530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning in parameterized action space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning with a natural language action space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu. Meeting Assoc. for Computational Linguistics (ACL)</title>
		<meeting>Annu. Meeting Assoc. for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predicting popular messages in Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangjie</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ovidiu</forename><surname>Dan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. World Wide Web (WWW)</title>
		<meeting>Int. Conf. World Wide Web (WWW)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="57" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Talking to the crowd: What do people react to in online discussions?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jaech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zayats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>of the Conference on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="2026" to="2031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">What&apos;s in a name? Understanding the interplay between titles, content, and communities in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himabindu</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. AAAI Conf. Web and Social Media (ICWSM)</title>
		<meeting>Int. AAAI Conf. Web and Social Media (ICWSM)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Slash(dot) and burn: distributed moderation in a large online conversation space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lampe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Resnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="543" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Continuous control with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Self-improving reactive agents based on reinforcement learning, planning and teaching. Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L-J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="293" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Point process modelling of rumour dynamics in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu. Meeting Assoc. for Computational Linguistics (ACL)</title>
		<meeting>Annu. Meeting Assoc. for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Twittermonitor: trend detection over the twitter stream</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathioudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Koudas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGMOD International Conference on Management of data</title>
		<meeting>the 2010 ACM SIGMOD International Conference on Management of data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1155" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Language understanding for text-based games using deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>of the 2015 Conference on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Improving information extraction by acquiring external evidence with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.07954</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Webnav: A new largescale task for natural language based sequential decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02261</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reinforcement learning with factored states and actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sallans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1063" to="1088" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Scheffler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the second International Conference on Human Language Technology Research</title>
		<meeting>of the second International Conference on Human Language Technology Research</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="12" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mastering the game of Go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lanctot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Reinforcement learning for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="956" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Want to be retweeted? Large scale analytics on factors impacting retweet in twitter network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pirolli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Inter. Conf. on Social Computing (SocialCom)</title>
		<meeting>IEEE Inter. Conf. on Social Computing (SocialCom)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The effect of wording on message propagation: Topic-and author-controlled natural experiments on Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu. Meeting Assoc. for Computational Linguistics (ACL)</title>
		<meeting>Annu. Meeting Assoc. for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Predicting the volume of comments on online news stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manos</forename><surname>Tasgkias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wouter</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1765" to="1768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Predicting the polularity of online articles based on user comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru</forename><surname>Tatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremie</forename><surname>Leguay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panayotis</forename><surname>Antoniadis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Limbourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcelo</forename><surname>Dias De Amorim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Fdida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Inter. Conf. on Web Intelligence, Mining and Semantics (WIMS)</title>
		<meeting>Inter. Conf. on Web Intelligence, Mining and Semantics (WIMS)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="1" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Temporal difference learning and TDgammon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="58" to="68" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Q-learning. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="279" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">A network-based end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.04562</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An exploration of discussion threads in social news sites: A case study of the reddit community</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weninger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">A</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Social Networks Analysis and Mining</title>
		<imprint>
			<publisher>ASONAM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page">2013</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<title level="m">IEEE/ACM International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="579" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">What&apos;s worthy of comment? Content and comment volume in political blogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae</forename><surname>Yano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. AAAI Conf. Weblogs and Social Media (ICWSM)</title>
		<meeting>Int. AAAI Conf. Weblogs and Social Media (ICWSM)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Linear submodular bandits and their application to diversified retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2483" to="2491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">SEISMIC: A self-exciting point process model for predicting Tweet popularity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyuan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Murat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Erdogdu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGKDD Conf. Knowledge Discovery and Data Mining</title>
		<meeting>ACM SIGKDD Conf. Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
