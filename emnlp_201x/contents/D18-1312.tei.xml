<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Framework for Understanding the Role of Morphology in Universal Dependency Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018. 2864</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Dehouck</surname></persName>
							<email>mathieu.dehouck@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR 9189 -CRIStAL Magnet Team</orgName>
								<orgName type="institution" key="instit1">Univ. Lille</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria Lille</orgName>
								<address>
									<addrLine>59650 Villeneuve d&apos;Ascq</addrLine>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Denis</surname></persName>
							<email>pascal.denis@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution">Inria Lille</orgName>
								<address>
									<addrLine>59650 Villeneuve d&apos;Ascq</addrLine>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Framework for Understanding the Role of Morphology in Universal Dependency Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2864" to="2870"/>
							<date type="published">October 31-November 4, 2018. 2018. 2864</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents a simple framework for characterizing morphological complexity and how it encodes syntactic information. In particular , we propose a new measure of morpho-syntactic complexity in terms of governor-dependent preferential attachment that explains parsing performance. Through experiments on dependency parsing with data from Universal Dependencies (UD), we show that representations derived from morphological attributes deliver important parsing performance improvements over standard word form embeddings when trained on the same datasets. We also show that the new morpho-syntactic complexity measure is predictive of the gains provided by using morphological attributes over plain forms on parsing scores, making it a tool to distinguish languages using morphology as a syntactic marker from others.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While word embedding has proven a good solution to reduce data sparsity in parsing ( <ref type="bibr" target="#b11">Koo et al., 2008)</ref>, treating word forms as atomic units is at odds with the fact that words have a potentially complex in- ternal structure. Furthermore, it makes parameters estimation difficult for morphologically rich lan- guages (MRL) in which the number of possible forms a word can take can be very large <ref type="bibr">1</ref> .</p><p>Recently, researchers have started to work on morphologically informed word embeddings <ref type="bibr" target="#b4">(Cao and Rei, 2016;</ref><ref type="bibr" target="#b3">Botha and Blunsom, 2014</ref>), aiming at better capturing both lexical, syntactic and mor- phological information. But encoding lexicon and morphology in the same space makes it difficult to distinguish the role of each in syntactic tasks such <ref type="bibr">1</ref> A typical English noun has 2 forms while a Finnish one may have more than 30. This shows in data as English lemmas have 1.39 forms on average while Finnish ones have 2.19, as measured on UD data ( <ref type="bibr" target="#b16">Nivre et al., 2016).</ref> as dependency parsing. Furthermore, morpholog- ically rich languages for which we hope to see a real impact from those morphologically aware rep- resentations, might not all rely to the same extent on morphology for syntax encoding. Some might benefit mostly from reducing data sparsity while others, for which paradigm richness correlate with freer word order <ref type="bibr" target="#b6">(Comrie, 1981)</ref>, will also benefit from morphological information encoding.</p><p>This paper aims at characterizing the role of morphology as a syntax encoding device for vari- ous languages. Using simple word representations, we measure the impact of morphological informa- tion on dependency parsing and relate it to two measures of language morphological complexity: the basic form per lemma ratio and a new measure (HPE) defined in terms of head attachment prefer- ence encoded by its morphological attributes. We show that this new measure is predictive of parsing result differences observed when using different word representations and that it allows one to dis- tinguish amongst morphologically rich languages, those that use morphology for syntactic purpose from those using morphology as a more semantic marker. To the best of our knowledge, this work is the first attempt at systematically measuring the syntactic content of morphology in a multi-lingual environment.</p><p>Section 2 presents the representation learning method and the dependency parsing model. It also defines two measures of morphological complex- ity. Section 3 describes the experimental setting and analyses parsing results in terms of the pre- viously defined morphological complexity mea- sures. Section 4 gives some conclusions and future work perspectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Framework</head><p>This section details: (i) our method for learn- ing lexical and morphological representations, (ii) how these can be used for graph-based dependency parsing, and (iii) how to measure morphological complexity. Our representation learning and pars- ing techniques are purposely very simple in order to let us separate lexical and morphological infor- mation and weight the role of morphology in de- pendency parsing of MRL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Word Representation</head><p>We construct separate vectorial representations for lemmas, forms and morphological attributes, ei- ther learned via dimension reduction of their own cooccurrence count matrices or represented as raw one-hot vectors.</p><p>Let V be a vocabulary (it can be lemmas or forms or morphological attributes (incl. values for POS, number, case, tense, mood...)) for a given lan- guage. Correspondingly, let C be the set of con- texts defined over elements of V. That is, lem- mas appear in the context of other lemmas, forms in the context of forms, and attributes in the con- text of attributes. Then, given a corpus annotated with lemmas and morphological information, we can gather the cooccurrence counts in the matrix M ∈ N |V|×|C| , such that M ij is the frequency of lemma (form or morphological attributes) V i ap- pearing in context C j in the corpus. Here, we con- sider plain sequential contexts (i.e. surrounding bag of "words") of length 1, although we could extend them to more structured contexts ( <ref type="bibr" target="#b1">Bansal et al., 2014</ref>). Those cooccurrence matrices are then reweighted by unshifted Positive Point-wise Mu- tual Information (PPMI) and reduced via Singular Value Decomposition (SVD). For more informa- tion on word embedding via matrix factorization, please refer to ( <ref type="bibr" target="#b14">Levy et al., 2015)</ref>.</p><p>Despite its apparent simplicity, this model is as expressive as more popular state of the art em- bedding techniques. Indeed, <ref type="bibr" target="#b12">Goldberg and Levy (2014)</ref> have shown that the SkipGram objective with negative sampling of Mikolov's Word2vec (2013) can be framed as the factorization of a shifted PMI weighted cooccurrence matrix.</p><p>This matrix reduction procedure gives us vectors for lemmas, forms and morphological attributes, noted R. Note that while a word has only one lemma and one form, it will often realize several morphological attributes. We tackle this issue by simply summing over all the attributes of a word (noted M orph(w)). If we note r w the vectorial representation of word w we have:</p><formula xml:id="formula_0">r w = a∈M orph(w) R a .</formula><p>Simple additive models have been shown to be very efficient for compositionally derived embed- dings ( <ref type="bibr" target="#b0">Arora et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dependency Parsing</head><p>We work with graph-based dependency parsing, which offers very competitive parsing models as recently re-emphasized by <ref type="bibr" target="#b8">Dozat et al. (2017)</ref> in the CONLL 2017 shared-task on dependency pars- ing ( <ref type="bibr" target="#b18">Zeman et al., 2017)</ref>.</p><p>Let x = (w 1 , w 2 , ..., w n ) be a sentence, T x be the set of all possible trees over it, ˆ y the tree that we predict for x, and Score(•, •) a scoring function over sentence-tree pairs :</p><formula xml:id="formula_1">ˆ y = argmax t∈Tx Score(x, t).</formula><p>We use edge factorization to make the inference problem tractable. A tree score is thus the sum of its edges scores. We use a simple linear model:</p><formula xml:id="formula_2">Score(x, t) = e∈t θ · φ(x, e),</formula><p>where φ(x, e) is a feature vector representing edge e in sentence x, and θ ∈ R m is a parameter vector to be learned.</p><p>The vector representation of an edge e ij whose governor is the i-th word w i and dependent is the j-th word w j , is defined by the outer product of their respective representations in context. Let ⊕ note vector concatenation, ⊗ the outer product and w k±1 be the word just before/after w k , then:</p><formula xml:id="formula_3">v i = w i−1 ⊕ w i ⊕ w i+1 , v j = w j−1 ⊕ w j ⊕ w j+1 and φ(x, e ij ) = vec(v i ⊗ v j ) ∈ R 9d 2 .</formula><p>Recall that w i of length d V is a vector from R.</p><p>We use the averaged Passive-Aggressive on- line algorithm for structured prediction <ref type="bibr" target="#b7">(Crammer et al., 2006</ref>) for learning the model θ. Given a score for each edge, we use Eisner algorithm <ref type="bibr" target="#b9">(Eisner, 1996</ref>) to retrieve the best projective spanning tree. Even though some languages display a fair amount of non-projective edges, on average Eisner algorithm scores higher than Chu-Liu-Edmonds algorithm ( <ref type="bibr" target="#b5">Chu and Liu, 1965</ref>) in our setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Measuring Morpho-Syntactic Complexity</head><p>Some languages use morphological cues to encode syntactic information while other encode more se- mantic information with them. For example, the Case feature (especially core cases) is of prime syntactic importance, for it encodes the type of re- lation words have with each other. On the contrary, the Possessor feature (in Hungarian for example) is more semantic in nature and need not impact sen- tence structure. This remark would support differ- ent treatment for each language. However, those languages tend to be treated equally in works deal- ing with MRL.</p><p>Form to Lemma Ratio A basic measure of mor- phological complexity is the form per lemma ratio, we note it F/L. It captures the tendency of words to inflect in a given language. Because some word classes tend not to inflect and not all forms are equally productive, we note F/iL the ratio of form per inflected lemma. Given a language l with a lemma vocabulary V l and a form counting func- tion c : V l → N that returns the number of forms a lemma can take, we have:</p><formula xml:id="formula_4">F /L(l) = 1 |V l | w∈V l c(w), F /iL(l) = 1 |V l i | w∈V l i c(w), V l i = {w ∈ V l |c(w) &gt; 1}</formula><p>F/L and F/iL do not measure the informative con- tent of morphology, but simply its productivity. <ref type="bibr" target="#b2">Bentz et al. (2016)</ref> compared five different mea- sures of morphological complexity amongst which word entropy and the micro-averaged version of F/L (they call it TTR) and showed that they all have high positive correlation given enough data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Head POS Entropy</head><p>In order to compare the morpho-syntactic complexity of different lan- guages, we introduce a new measure called Head Part-of-speech Entropy or HPE. The HPE of a to- ken t represents the amount of information t has about the part-of-speech of its governor. More formally, let P OS(Gov(t)) be the set of parts- of-speech that t can depend on, and let π t (p) be the probability of t actually depending on part-of- speech p, then the HPE is defined as:</p><formula xml:id="formula_5">HP E(t) = p∈P OS(Gov(t)) −π t (p)log 2 (π t (p)).</formula><p>This is a measure of a token preferencial attach- ment to its head. A token with a low HPE tends to attach often to the same part-of-speech, while a to- ken with a high HPE will attach to many different parts-of-speech. Thus a language with a low HPE will tend to encode a lot of syntactic information in the morphology, rather than in word order say. For example, a noun can attach to another noun like a genitive, or to a verb as a subject or object, or even to an adjective in the case of transitive ad- jective. French nouns do not inflect for case, thus attachment to another noun or verb can only be in- fered from words relative positions. On the con- trary, Gothic nouns do inflect for case, thus mak- ing verb or noun attachment clear directly from the morphological analysis.</p><p>We compute the HPE of a language as the aver- aged HPE of its attributes sets over a given corpus. Likewise, we use the empirical counts as a surro- gate for c in F/L and F/iL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In order to test the hypothesis that morphologi- cal representations contain syntactic information crucial for dependency parsing of morphologically rich languages, but that this information is not equally distributed across MRL, we run experi- ments on data from the Universal Dependencies (Nivre et al., 2016) project.</p><p>Data Description For conciseness, we focused on eleven languages that display varying degrees of morphological complexity and belong to four dif- ferent language families. Basque (eu) is an isolate and it is an ergative language. English (en), Gothic (got), Danish (da) and Swedish (sv) are Germanic languages, and French (fr) and Romanian (ro) are Romance languages (Indo-European). Finnish (fi), Estonian (et) and Hungarian (hu) are Finno-Ugric languages. Hebrew (he) is a Semitic language. Ba- sic statistics are provided in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Settings</head><p>For the experiments we use the train/dev/test data provided by UD 2.0. Basic statistics about the data are reported in the appendix. Lemmas and forms are embedded in 150 dimensions, while Morphological attributes are embedded in 50 dimensions, because they are much less numerous (less than 100). All embed- dings are induced on their language respective train set only using a context window of size 1 (i.e. the <ref type="table" target="#tab_1">da  en  et  eu  fi  fr  got  he  hu  ro  sv  Train 4383 12543 2263 5396 12217 14553 3387 5241 910 8043 4303  POS  17  17  16  16  15  17  14  16  16  17  16  Feats  44  35  58  69  88  36  40  48  73  59</ref>   directly preceding and following words).</p><p>Parsers are trained for 10 iterations using ei- ther lemma, form or morphological representa- tions, and we pick the best iteration on the basis of UAS on the development set.</p><p>While we used gold lemmas as provided in the corpora, we ran two experiments for morpholog- ical attributes, one with gold attributes and one with predicted attributes. Morphological attributes are predicted with a simple multinomial logistic regression per attribute (POS, Tense, Case, Gen- der...), where we add a special undef value (ex- cept for POS) to represent the lack of an attribute (e.g., nouns have no Tense in English). The mod- els predict attribute values for the center word of trigrams represented by feature vectors encoding word prefixes and suffixes of length 1, 2 and 3, word length and capitalization. We used the lo- gistic regression implemented in the Scikit-Learn ( <ref type="bibr" target="#b17">Pedregosa et al., 2011</ref>) library with the default set- tings. It can output an argmaxed decision or a soft- maxed decision, thus we tried both as input to the parser. The argmaxed decision gives a vector of ze- ros and ones, while the softmaxed decision gives a continuous vector with each each attributes sum- ming to one (the probability assigned to each pos- sible value for Gender like Masculine, Feminine, Neuter and Undef must sum to one). Then those vectors are used unchanged for the one-hot repre- sentation or passed through an embedding matrix for the embedding representation.</p><p>Results For clarity, we focus on comparing re- sults using form embeddings and gold morpholog- ical representations. They are given in <ref type="table" target="#tab_1">Table 2</ref>. Be- cause the analysis carries to the labeled case, we stick to unlabeled scores (UAS) for the analysis. A more complete table is provided in the appendix as well as a complete labeled accuracy score (LAS) table. Morphological complexity measures are also reported.</p><p>One-hot gold morphological attributes consis- tently outerperform form embeddings. This is ex- pected since forms embedding were trained on much fewer data than usually considered neces- sary. However, improvements are not consistent across languages, ranging from 1.14 point for En- glish to 15.20 points for Finnish. While those dif- ferences are not explained by morphological pro- ductivity alone <ref type="figure">(Figure 1a)</ref>, a measure of prefer- ential attachment gives a good account of them <ref type="figure">(Figure 1b)</ref>. Those inconsistencies become even more striking, considering results using predicted attributes. We notice that despite a general drop of performance of 5-12 points, predicted attributes  <ref type="figure">Figure 1</ref>: Accuracy differences (y-axis) between parsers using form embeddings and parsers using one- hot attributes, with respect to morphological complexity (x-axis). Red dots represent the gold attributes scores and blue squares the predicted attributes scores.</p><p>still perform significantly better than form em- beddings for those morphologically rich languages that have an HPE lower than 0.65 as depicted on <ref type="figure">Figure 1b</ref>.</p><p>Figures 1a and 1b plot the differences in parsing scores. For each language, the red dot corresponds to the score difference between using form embed- dings and gold attributes one-hot representations, and the blue square corresponds to the score differ- ence between using the same form embeddings and predicted attributes softmax representations (the complete scores are given in the appendix). But while the F/iL plot suffers outliers (Hungarian, Estonian and Romanian), the HPE plot shows a clear boundary between languages benefiting fully from morphological information (even predicted) and those benefiting primarily from reducing data sparsity. While Hebrew seems to be an outlier, it might be due to its annotation style, where attached prepositions, articles and possessive markers are treated as independent words rather than morpho- logical inflection as other languages do, thus artifi- cially increasing the parsing accuracy with a lot of trivial dependencies.</p><p>This shows that indeed, HPE is a good measure of the syntactic informativeness of a language mor- phology, and that it can help deciding between en- coding morphological information or just reducing data sparsity. Furthermore, it seems to be link to the distinction that <ref type="bibr" target="#b10">Kibort and Corbett (2010)</ref> do between morphosyntax and morphosemantic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We have contributed a new measure of morpho- syntactic complexity (HPE) that helps distinguish- ing languages that use morphology for syntactic purpose from languages that use morphology to encode more semantic information. We showed that this measure correlates much more with differ- ences in parsing results using morphological rep- resentations than the simple form per lemma ratio. It could thus be used to help designing language specific word representations.</p><p>It is worth mentioning that we focused here on dependent marked head selection. It would be interesting to have a similar measure for head- marking situations with dependencies marked on the governor. We leave it for future work.    <ref type="table">Table 5</ref>: LAS scores for parsers using predicted morpho-syntactic attributes. First row is LAS using form representation. Rows 2 to 5 are LAS using morphological representation, either one-hot or embedding and either hard decisions or soft decisions. <ref type="table" target="#tab_3">Table 3</ref> reports results for the predicted attributes experiment. The POS and averaged attributes pre- diction accuracies are given. Are also reported, scores for the four representation regimes of pre- dicted attributes. Predictions can be either prob- ability distributions (Soft) or argmax (Hard) and either used as such (OH) or passed through an em- bedding (Emb). <ref type="table" target="#tab_4">Table 4</ref> reports all the labeled accuracy scores for parsers using either gold lemmas, forms or gold attributes, either as one-hot vectors or as dense embeddings. <ref type="table">Table 5</ref> reports results for the predicted at- tributes experiment. Are also reported, scores for the four representation regimes of predicted at- tributes as in table 4. Predictions can be either probability distributions (Soft) or argmax (Hard) and either used as such (OH) or passed through an embedding (Emb).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgement</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A: Supplementary Tables</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figures 1a and 1b plot the differences in parsing scores. For each language, the red dot corresponds to the score difference between using form embeddings and gold attributes one-hot representations, and the blue square corresponds to the score difference between using the same form embeddings and predicted attributes softmax representations (the complete scores are given in the appendix). Figure 1a plots those differences with regard to the form per inflected lemma ratio (F/iL) and Figure 1b plots those differences with regard to the head POS entropy (HPE). Both Figures show trends. Score differences seem to increase with F/iL and decrease with HPE. But while the F/iL plot suffers outliers (Hungarian, Estonian and Romanian), the HPE plot shows a clear boundary between languages benefiting fully from morphological information (even predicted) and those benefiting primarily from reducing data sparsity. While Hebrew seems to be an outlier, it might be due to its annotation style, where attached prepositions, articles and possessive markers are treated as independent words rather than morphological inflection as other languages do, thus artificially increasing the parsing accuracy with a lot of trivial dependencies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>UAS scores for parsers using lemmas (Lem), word forms (Form) or morphological attributes 
(Morph) representations as features. For each type, we report results using one-hot representation (OH) 
and results using embeddings (Emb). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>98.02 97.74 96.20 97.56 97.09 97.60 96.00 97.84 92.76 97.76 96.88 Form Emb 70.64 75.13 57.36 65.64 60.38 76.05 68.72 72.68 55.06 73.21 72.72</figDesc><table>This work was supported by ANR Grant GRASP 
No. ANR-16-CE33-0011-01 and Grant from 
CPER Nord-Pas de Calais/FEDER DATA Ad-
vanced data science and technologies 2015-2020. 
We also thank the reviewers for their valuable feed-
back. da 
en 
et 
eu 
fi 
fr 
got 
he 
hu 
ro 
sv 
POS 
87.37 87.24 84.49 86.09 86.14 90.60 90.44 90.93 88.43 90.64 89.23 
Attributes Morph 
Hard OH 
64.69 69.32 57.16 64.51 64.33 72.82 69.94 71.60 61.80 71.36 67.99 
Soft OH 
65.43 71.36 58.76 67.02 66.84 73.29 70.86 72.75 61.91 72.03 69.48 
Hard Emb 64.19 69.51 55.53 64.10 62.58 72.28 69.29 71.51 59.62 70.86 67.82 
Soft Emb 65.33 70.75 57.24 66.18 65.04 73.18 70.46 71.85 60.64 71.34 68.60 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 :</head><label>3</label><figDesc>UAS scores for parsers using predicted morphological attributes. The two first rows are POS and averaged attributes prediction accuracy. The third row reports UAS using form representations for comparison purpose. Rows 4 to 7 give UAS using morphological representations, either one-hot or em- bedding. Regressors output a probability distribution per morphological feature, we either use those soft decision as input for the parser (Soft) or apply argmax first (Hard).</figDesc><table>da 
en 
et 
eu 
fi 
fr 
got 
he 
hu 
ro 
sv 

Lem 
OH 48.09 57.09 25.30 45.96 40.78 64.88 46.85 54.91 27.80 56.89 48.61 
Emb 62.47 70.95 48.17 62.52 59.34 65.62 61.37 64.41 41.59 64.76 65.70 

Form 
OH 45.12 54.97 21.29 40.53 34.59 61.95 45.19 55.82 25.60 53.83 45.00 
Emb 65.09 71.20 45.79 57.42 52.67 70.81 59.35 66.92 44.30 65.13 64.93 

Morph 
OH 69.19 72.32 64.06 68.19 71.00 73.92 71.04 72.66 64.31 68.94 69.97 
Emb 68.71 72.22 62.81 67.30 68.70 73.96 70.41 71.77 63.45 68.76 69.69 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>LAS scores for parsers using lemmas (Lem), forms (Form) or morphosyntactic attributes (Morph) 
representations as features. Representations are either embeddings or one-hot. 

da 
en 
et 
eu 
fi 
fr 
got 
he 
hu 
ro 
sv 
Form Emb 65.09 71.20 45.79 57.42 52.67 70.81 59.35 66.92 44.30 64.13 65.93 

Morph 
hard OH 
58.33 62.64 43.80 55.81 54.42 66.66 59.73 63.74 52.41 62.10 60.29 
soft OH 
59.68 65.59 47.05 59.43 58.74 67.39 62.36 66.25 53.63 63.26 62.44 
hard Emb 57.72 62.73 42.22 55.06 52.79 66.25 59.14 63.57 49.99 61.67 60.03 
soft Emb 
59.13 64.97 45.64 58.25 56.51 67.00 62.02 65.33 52.61 62.65 61.47 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Simple but Tough-to-Beat Baseline for Sentence Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Tailoring continuous word representations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="809" to="815" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A comparison between morphological complexity measures: typological data vs. language corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bentz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatyana</forename><surname>Ruzsics</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Koplenig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Samardzic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on computational linguistics for linguistic complexity (cl4lc)</title>
		<meeting>the workshop on computational linguistics for linguistic complexity (cl4lc)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="142" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Compositional morphology for word representations and language modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<idno>abs/1405.4273</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A joint model for word embedding and word morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
		<idno>abs/1606.02601</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the shortest arborescence of a directed graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Sinica</title>
		<imprint>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Language universals and linguistic typology : syntax and morphology / Bernard Comrie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Comrie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
			<pubPlace>Blackwell, Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Shai Shalev-Shwartz, and Yoram Singer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Keshet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="551" to="585" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Online passive-aggressive algorithms</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stanford&apos;s graph-based neural dependency parser at the conll 2017 shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="20" to="30" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Three new probabilistic models for dependency parsing: An exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 16th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>COLING</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Features: perspective on a key notion in linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kibort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Corbett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Simple semi-supervised dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="595" to="603" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL-08: HLT</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Neural word embedding as implicit matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2177" to="2185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving distributional similarity with lessons learned from word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held</title>
		<meeting><address><addrLine>Lake Tahoe, Nevada, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-12-05" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Universal dependencies v1: A multilingual treebank collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Silveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">shared task: Multilingual parsing from raw text to universal dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhani</forename><surname>Luotolahti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Badmaeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Memduh</forename><surname>Gokirmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Nedoluzhko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvie</forename><surname>Cinkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajic Jr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaroslava</forename><surname>Hlavacova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Václava</forename><surname>Kettnerová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zdenka</forename><surname>Uresova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenna</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stina</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Missilä</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dima</forename><surname>Taji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Simi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Kanayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valeria</forename><surname>Depaiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Droganova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Çağrı</forename><surname>Héctor Martínez Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Çöltekin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<editor>Kayadelen, Mohammed Attia, Ali Elkahky, Zhuoran Yu, Emily Pitler, Saran Lertpradit, Michael Mandl, Jesse Kirchner, Hector Fernandez Alcalde, Jana Strnadová, Esha Banerjee, Ruli Manurung, Antonio Stella, Atsuko Shimada, Sookyoung Kwak, Gustavo Mendonca, Tatiana Lando, Rattima Nitisaroj, and Josie Li</editor>
		<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Umut Sulubacak, Hans Uszkoreit, Vivien Macketanz, Aljoscha Burchardt, Kim Harris, Katrin Marheinecke, Georg Rehm, Tolga; Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
