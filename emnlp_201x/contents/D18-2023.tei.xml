<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CytonMT: an Efficient Neural Machine Translation Open-source Toolkit Implemented in C++</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Advanced Translation Research and Development Promotion Center National Institute of Information and Communications Technology</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Advanced Translation Research and Development Promotion Center National Institute of Information and Communications Technology</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Advanced Translation Research and Development Promotion Center National Institute of Information and Communications Technology</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CytonMT: an Efficient Neural Machine Translation Open-source Toolkit Implemented in C++</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations)</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations) <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="133" to="138"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>133</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents an open-source neural machine translation toolkit named CytonMT 1. The toolkit is built from scratch only using C++ and NVIDIA&apos;s GPU-accelerated libraries. The toolkit features training efficiency, code simplicity and translation quality. Benchmarks show that CytonMT accelerates the training speed by 64.5% to 110.8% on neural networks of various sizes, and achieves competitive translation quality.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural</head><p>Machine Translation (NMT) has made remarkable progress over the past few years ( <ref type="bibr" target="#b11">Sutskever et al., 2014;</ref><ref type="bibr" target="#b0">Bahdanau et al., 2014;</ref><ref type="bibr" target="#b15">Wu et al., 2016)</ref>. Just like Moses ( <ref type="bibr" target="#b5">Koehn et al., 2007</ref>) does for statistic machine translation (SMT), open-source NMT toolkits contribute greatly to this progress, including but not limited to,</p><p>• RNNsearch-LV ( <ref type="bibr">Jean et al., 2015) 2</ref> • Luong-NMT ( <ref type="bibr" target="#b6">Luong et al., 2015a)</ref>  <ref type="bibr">3</ref> • DL4MT by Kyunghyun Cho et al. <ref type="bibr">4</ref> • BPE-char ( <ref type="bibr">Chung et al., 2016)</ref>  <ref type="bibr">5</ref> • Nematus ( <ref type="bibr" target="#b9">Sennrich et al., 2017)</ref>  <ref type="bibr">6</ref> • OpenNMT ( <ref type="bibr" target="#b4">Klein et al., 2017)</ref>  <ref type="bibr">7</ref> • Seq2seq ( <ref type="bibr">Britz et al., 2017)</ref>  <ref type="bibr">8</ref> • ByteNet ( <ref type="bibr">Kalchbrenner et al., 2016)</ref>  <ref type="bibr">9</ref> • ConvS2S ( <ref type="bibr">Gehring et al., 2017)</ref>  <ref type="bibr">10</ref> • Tensor2Tensor ( <ref type="bibr" target="#b13">Vaswani et al., 2017)</ref>  <ref type="bibr">11</ref> • Marian ( <ref type="bibr">Junczys-Dowmunt et al., 2018)</ref>  <ref type="bibr">12</ref> These open-source NMT toolkits are undoubt- edly excellent software. However, there is a com- mon issue -they are all written in script languages with dependencies on third-party GPU platforms (see <ref type="table">Table 1</ref>) except Marian, which is developed simultaneously with our toolkit.</p><p>Using script languages and third-party GPU platforms is a two-edged sword. On one hand, it greatly reduces the workload of coding neural networks. On the other hand, it also causes two problems as follows,</p><p>• The running efficiency drops, and profiling and optimization also become difficult, as the direct access to GPUs is blocked by the lan- guage interpreters or the platforms. NMT systems typically require days or weeks to train, so training efficiency is a paramount concern. Slightly faster training can make the difference between plausible and impossible experiments ( <ref type="bibr" target="#b4">Klein et al., 2017</ref>).</p><p>• The researchers using these toolkits may be constrained by the platforms. Unex- plored computations or operations may be- come disallowed or unnecessarily inefficient on a third-party platform, which lowers the chances of developing novel neural network techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Toolkit</head><p>Language <ref type="table" target="#tab_1">Platform  RNNsearch-LV Python  Theano,GroundHog  Luong-NMT  Matlab  Matlab  DL4MT  Python  Theano  BPE-char  Python  Theano  Nematus  Python  Theano  OpenNMT  Lua  Torch  Seq2seq  Python  Tensorflow  ByteNet  Python  Tensorflow  ConvS2S  Lua  Torch  Tensor2Tensor  Python  Tensorflow  Marian  C++  - CytonMT  C++  -  Table 1</ref>: Languages and Platforms of Open-source NMT toolkits.</p><p>CytonMT is developed to address this issue, in hopes of providing the community an attractive alternative. The toolkit is written in C++ which is the genuine official language of NVIDIA -the manufacturer of the most widely-used GPU hard- ware. This gives the toolkit an advantage on effi- ciency when compared with other toolkits.</p><p>Implementing in C++ also gives CytonMT great flexibility and freedom on coding. The researchers who are interested in the real calculations inside neural networks can trace source codes down to kernel functions, matrix operations or NVIDIA's APIs, and then modify them freely to test their novel ideas.</p><p>The code simplicity of CytonMT is compara- ble to those NMT toolkits implemented in script languages. This owes to an open-source general- purpose neural network library in C++, named Cy- tonLib, which is shipped as part of the source code. The library defines a simple and friendly pattern for users to build arbitrary network archi- tectures in the cost of two lines of genuine C++ code per layer.</p><p>CytonMT achieves competitive translation quality, which is the main purpose of NMT toolkits. It implements the popular framework of attention-based RNN encoder-decoder. Among the reported systems of the same architecture, it ranks at top positions on the benchmarks of both WMT14 and WMT17 English-to-German tasks.</p><p>The following of this paper presented the details of CytonMT from the aspects of method, imple- mentation, benchmark, and future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>The toolkit approaches to the problem of ma- chine translation using the attention-based RNN encoder-decoder proposed by <ref type="bibr" target="#b0">Bahdanau et al. (2014)</ref> and <ref type="bibr" target="#b6">Luong et al. (2015a)</ref>. trates the architecture. The conditional probability of a translation given a source sentence is formu- lated as,</p><formula xml:id="formula_0">log p (y|x) = m X j=1 log( p (yj|H j o ) = m X j=1 log(softmaxy j (tanh(WoH j o + Bo))) (1) H j o = Fatt(Hs, H j t ),<label>(2)</label></formula><p>where x is a source sentence; y=(y 1 , . . . , y m ) is a translation; H s is a source-side top-layer hidden state; H j t is a target-side top-layer hidden state; H j o is a state generated by an attention model F att ; W o and B o are the weight and bias of an output embedding.</p><p>The toolkit adopts the multiplicative attention model proposed by <ref type="bibr" target="#b6">Luong et al. (2015a)</ref>, because it is slightly more efficient than the additive variant proposed by <ref type="bibr" target="#b0">Bahdanau et al. (2014)</ref>. This issue is addressed in <ref type="bibr">Britz et al. (2017)</ref> and <ref type="bibr" target="#b13">Vaswani et al. (2017)</ref>. <ref type="figure" target="#fig_1">Figure 2</ref> illustrates the model, formulated as ,</p><formula xml:id="formula_1">a ij st = softmax(Fa(H i s , H j t )) = e Fa(H i s ,H j t ) P n i=1 e Fa(H i s ,H j t ) ,<label>(3)</label></formula><formula xml:id="formula_2">Fa(H i s , H j t ) = H i s ⊤ WaH j t ,<label>(4)</label></formula><formula xml:id="formula_3">C j s = n X i=1 a ij st H i s ,<label>(5)</label></formula><formula xml:id="formula_4">C j st = [C s ; H j t ],<label>(6)</label></formula><formula xml:id="formula_5">H j o = tanh(WcC j st ),<label>(7)</label></formula><p>where F a is a scoring function for alignment; W a is a matrix for linearly mapping target-side hidden </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Implementation</head><p>The toolkit consists of a general purpose neural network library, and a neural machine translation system built upon the library. The neural network library defines a class named Network to facili- tate the construction of arbitrary neural networks. Users only need to inherit the class, declare com- ponents as data members, and write down two lines of codes per component in an initialization function. For example, the complete code of the attention network formulated by the equations 3 to 7 is presented in <ref type="figure">Figure 3</ref>. This piece of code fulfills the task of building a neural network as fol- lows,</p><p>• The class of Variable stores numeric values and gradients. Through passing the pointers of Variable around, component are connected together.</p><p>• The data member of layers collects all the components. The base class of Network will call the functions forward, backward and cal- culateGradient of each component to per- form the actual computation.</p><p>The codes of actual computation are organized in the functions forward, backward and calculate- Gradient for each type of component. <ref type="figure" target="#fig_2">Figure 4</ref> presents some examples. Note that these codes have been slightly simplified for illustration.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Benchmarks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Settings</head><p>CytonMT is tested on the widely-used bench- marks of the WMT14 and WMT17 English- to-German tasks ( <ref type="bibr">Bojar et al., 2017</ref>) (Ta- ble 2). Both datasets are processed and con- verted using byte-pair encoding <ref type="bibr">(Gage, 1994;</ref><ref type="bibr" target="#b8">Schuster and Nakajima, 2012</ref>) with a shared source-target vocabulary of about 37000 to- kens. The WMT14 corpora are processed by the scripts from <ref type="bibr" target="#b13">Vaswani et al. (2017)</ref>  <ref type="bibr">13</ref> . The CytonMT is run with the hyperparameters set- tings presented by <ref type="table" target="#tab_2">Table 3</ref> unless stated otherwise. The settings provide both fast training and com- petitive translate quality according to our experi- ments on a variety of translation tasks. Dropout is applied to the hidden states between non-top re- current layers R s , R t and output H o according to ( <ref type="bibr" target="#b14">Wang et al., 2017)</ref>. Label smoothing estimates the marginalized effect of label-dropout during training, which makes models learn to be more un- sure ( <ref type="bibr" target="#b12">Szegedy et al., 2016)</ref>. This improved BLEU scores ( <ref type="bibr" target="#b13">Vaswani et al., 2017)</ref>. Length penalty is applied using the formula in ( <ref type="bibr" target="#b15">Wu et al., 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison on Training Speed</head><p>Four baseline toolkits and CytonMT train mod- els using the settings of hyperparameters in Ta- ble 3. The number of layers and the size of embed- dings and hidden states varies, as large networks are often used in real-world applications to achieve higher accuracy at the cost of more running time. <ref type="table" target="#tab_4">Table 4</ref> presents the training speed of differ- ent toolkits measured in source tokens per sec- ond. The results show that the training speed of CytonMT is much higher than the baselines. <ref type="bibr">13</ref> https://github.com/tensorflow/tensor2tensor 14 https://github.com/marian-nmt/marian- examples/tree/master/wmt2017-uedin <ref type="table" target="#tab_1">Source  Target  WMT14  Train.(standard)  4,500,966 113,548,249 107,259,529  Dev. (tst2013)  3,000  64,807  63,412  Test (tst2014)  3,003  67,617  63,078  WMT17  Train.(standard)</ref> 4,590,101 118,768,285 112,009,072 Train.(back trans.) 10,000, <ref type="bibr">000 190,611,668 149,198</ref>  OpenNMT is the fastest baseline, while CytonMT achieves a speed up versus it by 64.5% to 110.8%. Moreover, CytonMT shows a consistent tendency to speed up more on larger networks.   entropy of the development set is monitored ev- ery 1 12 epoch on WMT14 and every 1 36 epoch on WMT17, approximately 400K sentence pairs. If the entropy has not decreased by max(0.01 × learning rate, 0.001) in 12 times, learning rate decays by 0.7 and the training restarts from the previous best model. The whole training proce- dure terminates when no improvement is made during two neighboring decays of learning rate. The actual training took 28 epochs on WMT14 and 12 epochs on WMT17. <ref type="table" target="#tab_3">Table 5</ref> shows that CytonMT achieves the com- petitive BLEU points on both benchmarks. On WMT14, it is only outperformed by Google's pro- duction system ( <ref type="bibr" target="#b15">Wu et al., 2016)</ref>, which is very much larger in scale and much more demanding on hardware. On WMT17, it achieves the same level of performance with Marian, which is high among the entries of WMT17 for a single sys- tem. Note that the start-of-the-art scores on these benchmarks have been recently pushed forward by novel network architectures such as <ref type="bibr">Gehring et al. (2017)</ref>, <ref type="bibr" target="#b13">Vaswani et al. (2017)</ref> and  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Set # Sent. # Words</head><note type="other">,444 Dev. (tst2016) 2,999 64,513 62,362 Test (tst2017) 3,004 64,776 60,963</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison on Translation Quality</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper introduces CytonMT -an open- source NMT toolkit -built from scratch only using C++ and NVIDIA's GPU-accelerated li- braries. CytonMT speeds up training by more than 64.5%, and achieves competitive BLEU points on WMT14 and WMT17 corpora. The source code of CytonMT is simple because of CytonLib -an open-source general purpose neural network li- brary -contained in the toolkit. Therefore, Cy- tonMT is an attractive alternative for the research community. We open-source this toolkit in hopes of benefiting the community and promoting the field. We look forward to hearing feedback from the community.</p><p>The future work of CytonMT will be contin- ued in two directions. One direction is to fur- ther optimize the code for GPUs, such support- ing multi-GPU. The problem we used to have is that GPUs proceed very fast in the last few years. For example, the microarchitectures of NVIDIA GPUs evolve twice during the development of Cy- tonMT, from Maxwell to Pascale, and then to Volta. Therefore, we have not explored cutting- edge GPU techniques as the coding effort may be outdated quickly. Multi-GPU machines are com- mon now, so we plan to support them.</p><p>The other direction is to support latest NMT ar- chitectures such <ref type="bibr">ConvS2S (Gehring et al., 2017)</ref> and <ref type="bibr">Transformer (Vaswani et al., 2017)</ref>. In these architectures, recurrent structures are replaced by convolution or attention structures. Their high per- formance indicates that the new structures suit the translation task better, so we also plan to support them in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 Figure 1 :</head><label>11</label><figDesc>Figure 1: Architecture of CytonMT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecure of Attention Model.</figDesc><graphic url="image-13.pbm" coords="3,100.07,101.37,164.12,64.49" type="bitmap" mask="true" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Codes of Performing Actual Computation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>WMT17 corpora are processed by the scripts from Junczys-Dowmunt et al. (2018) 14 , which includes 10 million back-translated sentence pairs for training. The benchmarks were run on an Intel Xeon CPU E5-2630 @ 2.4Ghz and a GPU Quadro M4000 (Maxwell) that had 1664 CUDA cores @ 773 MHz, 2,573 GFLOPS . The software is CentOS 6.8, CUDA 9.1 (driver 387.26), CUDNN 7.0.5, Theano 1.0.1, Tensorflow 1.5.0. Netmaus, Torch and OpenNMT are the latest version in De- cember 2017. Marian is the last version in May 2018.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>WMT English-to-German corpora. 

Hyperparameter 
Value 
Embedding Size 
512 
Hidden State Size 
512 
Encoder/Decoder Depth 2 
Encoder 
Bidirectional 
RNN Type 
LSTM 
Dropout 
0.2 
Label Smooth. 
0.1 
Optimizer 
SGD 
Learning Rate 
1.0 
Learning Rate Decay 
0.7 
Beam Search Size 
10 
Length Penalty 
0.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 : Hyperparameter Settings.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 compares the BLEU of</head><label>5</label><figDesc></figDesc><table>CytonMT with 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Training Speed Measured in Source To-
kens per Second. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 : Comparing BLEU with Public Records.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> https://github.com/arthurxlw/cytonMt 2 https://github.com/sebastien-j/LV groundhog 3 https://github.com/lmthang/nmt.hybrid 4 https://github.com/nyu-dl/dl4mt-tutorial</note>

			<note place="foot" n="9"> https://github.com/paarthneekhara/byteNet-tensorflow (unofficial) and others. 10 https://github.com/facebookresearch/fairseq 11 https://github.com/tensorflow/tensor2tensor 12 https://github.com/marian-nmt/marian</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>References Dzmitry Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations</title>
		<meeting>the 3rd International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Dwojak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<editor>Alham Fikri Aji, Nikolay Bogoychev, Andr F. T</editor>
		<imprint>
			<pubPlace>Tom Neckermann, Frank Seide, Ulrich Germann</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Marian: Fast neural machine translation in c++</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Birch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.00344</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Aäron van den Oord, Alex Graves, and Koray Kavukcuoglu. 2016. Neural machine translation in linear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<idno>abs/1610.10099</idno>
		<imprint>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Opennmt: Open-source toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL, System Demonstrations</title>
		<meeting>ACL, System Demonstrations<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="67" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL, Interactive Poster and Demonstration Sessions</title>
		<meeting>ACL, Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Effective approaches to attentionbased neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Addressing the rare word problem in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Japanese and korean voice search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisuke</forename><surname>Nakajima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="5149" to="5152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Nematus: a toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Hitschler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jozef</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Mokry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nadejde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="65" to="68" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Outrageously large neural networks: The sparsely-gated mixture-of-experts layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azalia</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Maziarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1701.06538</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Empirical study of dropout scheme for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Machine Translation Summit</title>
		<meeting>the 16th Machine Translation Summit</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
	</analytic>
	<monogr>
		<title level="m">Bridging the gap between human and machine translation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep recurrent models with fast-forward connections for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="371" to="383" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
