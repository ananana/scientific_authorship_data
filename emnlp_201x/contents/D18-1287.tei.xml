<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mapping Instructions to Actions in 3D Environments with Visual Goal Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipendra</forename><surname>Misra</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Cornell Tech</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<postCode>10044</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Bennett</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Cornell Tech</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<postCode>10044</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valts</forename><surname>Blukis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Cornell Tech</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<postCode>10044</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyvind</forename><surname>Niklasson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Cornell Tech</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<postCode>10044</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Shatkhin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Cornell Tech</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<postCode>10044</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Cornell Tech</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<postCode>10044</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Mapping Instructions to Actions in 3D Environments with Visual Goal Prediction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2667" to="2678"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose to decompose instruction execution to goal prediction and action generation. We design a model that maps raw visual observations to goals using LINGUNET, a language-conditioned image generation network , and then generates the actions required to complete them. Our model is trained from demonstration only without external resources. To evaluate our approach, we introduce two benchmarks for instruction following: LANI, a navigation task; and CHAI, where an agent executes household instructions. Our evaluation demonstrates the advantages of our model decomposition, and illustrates the challenges posed by our new benchmarks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Executing instructions in interactive environments requires mapping natural language and observa- tions to actions. Recent approaches propose learn- ing to directly map from inputs to actions, for ex- ample given language and either structured obser- vations ( <ref type="bibr" target="#b28">Mei et al., 2016;</ref><ref type="bibr" target="#b41">Suhr and Artzi, 2018)</ref> or raw visual observations ( <ref type="bibr" target="#b29">Misra et al., 2017;</ref><ref type="bibr" target="#b45">Xiong et al., 2018)</ref>. Rather than using a combination of models, these approaches learn a single model to solve language, perception, and planning chal- lenges. This reduces the amount of engineering required and eliminates the need for hand-crafted meaning representations. At each step, the agent maps its current inputs to the next action using a single learned function that is executed repeatedly until task completion.</p><p>Although executing the same computation at each step simplifies modeling, it exemplifies cer- tain inefficiencies; while the agent needs to de- cide what action to take at each step, identifying its goal is only required once every several steps or even once per execution. The left instruction in <ref type="figure" target="#fig_0">Figure 1</ref> illustrates this. The agent can compute its After reaching the hydrant head towards the blue fence and pass towards the right side of the well.</p><p>Put the cereal, the sponge, and the dishwashing soap into the cupboard above the sink. goal once given the initial observation, and given this goal can then generate the actions required. In this paper, we study a new model that explic- itly distinguishes between goal selection and ac- tion generation, and introduce two instruction fol- lowing benchmark tasks to evaluate it.</p><p>Our model decomposes into goal prediction and action generation. Given a natural language in- struction and system observations, the model pre- dicts the goal to complete. Given the goal, the model generates a sequence of actions.</p><p>The key challenge we address is designing the goal representation. We avoid manually designing a meaning representation, and predict the goal in the agent's observation space. Given the image of the environment the agent observes, we generate a probability distribution over the image to highlight the goal location. We treat this prediction as image generation, and develop LINGUNET, a language conditioned variant of the U-NET image-to-image architecture <ref type="bibr" target="#b38">(Ronneberger et al., 2015)</ref>. Given the visual goal prediction, we generate actions using a recurrent neural network (RNN).</p><p>Our model decomposition offers two key advan- tages. First, we can use different learning methods as appropriate for the goal prediction and action generation problems. We find supervised learning more effective for goal prediction, where only a limited amount of natural language data is avail- able. For action generation, where exploration is critical, we use policy gradient in a contextual ban- dit setting ( <ref type="bibr" target="#b29">Misra et al., 2017)</ref>. Second, the goal distribution is easily interpretable by overlaying it on the agent observations. This can be used to in- crease the safety of physical systems by letting the user verify the goal before any action is executed. Despite the decomposition, our approach retains the advantages of the single-model approach. It does not require designing intermediate represen- tations, and training does not rely on external re- sources, such as pre-trained parsers or object de- tectors, instead using demonstrations only.</p><p>We introduce two new benchmark tasks with different levels of complexity of goal prediction and action generation. LANI is a 3D navigation environment and corpus, where an agent navigates between landmarks. The corpus includes 6,000 sequences of natural language instructions, each containing on average 4.7 instructions. CHAI is a corpus of 1,596 instruction sequences, each in- cluding 7.7 instructions on average, for CHALET, a 3D house environment ( <ref type="bibr" target="#b46">Yan et al., 2018)</ref>. In- structions combine navigation and simple manipu- lation, including moving objects and opening con- tainers. Both tasks require solving language chal- lenges, including spatial and temporal reasoning, as well as complex perception and planning prob- lems. While LANI provides a task where most in- structions include a single goal, the CHAI instruc- tions often require multiple intermediate goals.</p><p>For example, the household instruction in Fig- ure 1 can be decomposed to eight goals: opening the cupboard, picking each item and moving it to the cupboard, and closing the cupboard. Achiev- ing each goal requires multiple actions of differ- ent types, including moving and acting on objects. This allows us to experiment with a simple varia- tion of our model to generate intermediate goals.</p><p>We compare our approach to multiple recent methods. Experiments on the LANI navigation task indicate that decomposing goal prediction and action generation significantly improves in- struction execution performance. While we ob- serve similar trends on the CHAI instructions, re- sults are overall weaker, illustrating the complex- ity of the task. We also observe that inherent ambiguities in instruction following make exact goal identification difficult, as demonstrated by imperfect human performance. However, the gap to human-level performance still remains large across both tasks. Our code and data are available at github.com/clic-lab/ciff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Technical Overview</head><p>Task Let X be the set of all instructions, S the set of all world states, and A the set of all actions. An instruction ¯ x 2 X is a sequence hx 1 , . . . , x n i, where each x i is a token. The agent executes instructions by generating a sequence of actions, and indicates execution completion with the spe- cial action STOP.</p><p>The sets of actions A and states S are domain specific. In the navigation domain LANI, the ac- tions include moving the agent and changing its orientation. The state information includes the po- sition and orientation of the agent and the differ- ent landmarks. The agent actions in the CHALET house environment include moving and changing the agent orientation, as well as an object interac- tion action. The state encodes the position and ori- entation of the agent and all objects in the house. For interactive objects, the state also includes their status, for example if a drawer is open or closed. In both domains, the actions are discrete. The do- mains are described in Section 6. Model The agent does not observe the world state directly, but instead observes its pose and an RGB image of the environment from its point of view. We define these observations as the agent context˜scontext˜ context˜s. An agent model is a function from an agent context˜scontext˜ context˜s to an action a 2 A. We model goal prediction as predicting a probability distri- bution over the agent visual observations, repre- senting the likelihood of locations or objects in the environment being target positions or objects to be acted on. Our model is described in Section 4. Learning We assume access to training data with N examples {(¯ x (i) , s</p><formula xml:id="formula_0">(i) 1 , s (i) g )} N i=1</formula><p>, where ¯ x (i) is an instruction, s g is the goal state. We decompose learning; training goal prediction using supervised learning, and action generation using oracle goals with policy gradient in a contextual bandit setting. We assume an in- strumented environment with access to the world state, which is used to compute rewards during training only. Learning is described in Section 5. Evaluation We evaluate task performance on a test set {(¯ x (i) , s</p><formula xml:id="formula_1">(i) 1 , s (i) g )} M i=1</formula><p>, where ¯ x (i) is an in-struction, s</p><p>1 is a start state, and s <ref type="bibr">(i)</ref> g is the goal state. We evaluate task completion accuracy and the distance of the agent's final state to s </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Mapping instruction to action has been studied extensively with intermediate symbolic represen- tations (e.g., <ref type="bibr" target="#b6">Chen and Mooney, 2011;</ref><ref type="bibr" target="#b16">Kim and Mooney, 2012;</ref><ref type="bibr" target="#b3">Artzi and Zettlemoyer, 2013;</ref><ref type="bibr" target="#b2">Artzi et al., 2014;</ref><ref type="bibr" target="#b31">Misra et al., 2015</ref><ref type="bibr" target="#b30">Misra et al., , 2016</ref>. Recently, there has been growing interest in direct mapping from raw visual observations to actions <ref type="bibr" target="#b29">(Misra et al., 2017;</ref><ref type="bibr" target="#b45">Xiong et al., 2018;</ref><ref type="bibr" target="#b1">Anderson et al., 2018;</ref><ref type="bibr" target="#b9">Fried et al., 2018)</ref>. We propose a model that enjoys the benefits of such direct mapping, but ex- plicitly decomposes that task to interpretable goal prediction and action generation. While we focus on natural language, the problem has also been studied using synthetic language <ref type="bibr" target="#b5">(Chaplot et al., 2018;</ref><ref type="bibr" target="#b12">Hermann et al., 2017)</ref>.</p><p>Our model design is related to hierarchical re- inforcement learning, where sub-policies at differ- ent levels of the hierarchy are used at different fre- quencies ( <ref type="bibr" target="#b42">Sutton et al., 1998</ref>). <ref type="bibr" target="#b35">Oh et al. (2017)</ref> uses a two-level hierarchy for mapping synthetic language to actions. Unlike our visual goal rep- resentation, they use an opaque vector representa- tion. Also, instead of reinforcement learning, our methods emphasize sample efficiency.</p><p>Goal prediction is related to referring expres- sion interpretation <ref type="bibr" target="#b26">(Matuszek et al., 2012a;</ref><ref type="bibr" target="#b20">Krishnamurthy and Kollar, 2013;</ref><ref type="bibr" target="#b15">Kazemzadeh et al., 2014;</ref><ref type="bibr" target="#b19">Kong et al., 2014;</ref><ref type="bibr" target="#b47">Yu et al., 2016;</ref><ref type="bibr" target="#b25">Mao et al., 2016;</ref><ref type="bibr" target="#b18">Kitaev and Klein, 2017</ref>). While our model solves a similar problem for goal prediction, we focus on detecting visual goals for actions, includ- ing both navigation and manipulation, as part of an instruction following model. Using formal goal representation for instruction following was stud- ied by <ref type="bibr" target="#b23">MacGlashan et al. (2015)</ref>. In contrast, our model generates a probability distribution over im- ages, and does not require an ontology.</p><p>Our data collection is related to existing work. LANI is inspired by the HCRC Map Task <ref type="bibr" target="#b0">(Anderson et al., 1991)</ref>, where a leader directs a fol- lower to navigate between landmarks on a map. We use a similar task, but our scalable data collec- tion process allows for a significantly larger cor- pus. We also provide an interactive navigation environment, instead of only map diagrams. Un- like Map Task, our leaders and followers do not interact in real time. This abstracts away inter- action challenges, similar to how the SAIL nav- igation corpus was collected ( <ref type="bibr" target="#b24">MacMahon et al., 2006</ref>). CHAI instructions were collected using scenarios given to workers, similar to the ATIS collection process ( <ref type="bibr" target="#b11">Hemphill et al., 1990;</ref><ref type="bibr" target="#b7">Dahl et al., 1994)</ref>. Recently, multiple 3D research envi- ronments were released. LANI has a significantly larger state space than existing navigation envi- ronments ( <ref type="bibr" target="#b12">Hermann et al., 2017;</ref><ref type="bibr" target="#b5">Chaplot et al., 2018)</ref>, and CHALET, the environment used for CHAI, is larger and has more complex manipu- lation compared to similar environments ( <ref type="bibr" target="#b10">Gordon et al., 2018;</ref><ref type="bibr" target="#b8">Das et al., 2018)</ref>. In addition, only synthetic language data has been released for these environment. An exception is the Room-to-Room dataset ( <ref type="bibr" target="#b1">Anderson et al., 2018</ref>) that makes use of an environment of connected panoramas of house settings. Although it provides a realistic vision challenge, unlike our environments, the state space is limited to a small number of panoramas and ma- nipulation is not possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>We model the agent policy as a neural network. The agent observes the world state s t at time t as an RGB image I t . The agent context˜scontext˜ context˜s t , the infor- mation available to the agent to select the next ac- tion a t , is a tuple (¯ x, I P , h(I 1 , p 1 ), . . . , (I t , p t )i), where ¯ x is the natural language instructions, I P is a panoramic view of the environment from the starting position at time t = 1, and h(I 1 , p 1 ), . . . , (I t , p t )i is the sequence of observa- tions I t and poses p t up to time t. The panorama I P is generated through deterministic exploration by rotating 360 to observe the environment at the beginning of the execution. <ref type="bibr">1</ref> The model includes two main components: goal prediction and action generation. The agent uses the panorama I P to predict the goal location l g . At each time step t, a projection of the goal location into the agent's current view M t is given as input to an RNN to generate actions. The probability of an action a t at time t decomposes to:</p><formula xml:id="formula_3">P (at | ˜ st) = X lg ⇣ P (lg | ¯ x, IP ) P (at | lg, (I1, p1), . . . , (It, pt)) ⌘ ,</formula><p>where the first term puts the complete distribution mass on a single location (i.e., a delta function). <ref type="figure">Figure 2</ref> illustrates the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Goal Distribution P g &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 9 h v m 1 b r w P v d e S 5 u v J g 4 N X p 6 g w Y = " &gt; A A A C O n i c b V D P a x N B G J 2 t W u t a N d G j H g a D 0 F P Y F U G P g R b s M U L T B L J L m J 3 9 k g y Z H 8 v M t 2 p Y 9 t K / p l d 7 7 j / S a 2 + l 1 / 4 B n U 1 y 0 M Q H A 4 / 3 v m / e z M s K K R x G 0 U 2 w 9 + T p s / 3 n B y / C l 4 e v X r 9 p t d + e O 1 N a D g N u p L G j j D m Q Q s M A B U o Y F R a Y y i Q M s 8 V x 4 w 9 / g n X C 6 D N c F p A q N t N i K j h D L 0 1 a H x K E 3 1 h 9 N 0 z S E x 9 n R V Y 2 D q 3 7 k 9 m k 1 Y m 6 0 Q p 0 l 8 Q b 0 i E b 9 C f t Y D / J D S 8 V a O S S O T e O o w L T i l k U X E I d J q W D g v E F m 8 H Y U 8 0 U u L R a f a O m n 7 y S 0 6 m x / m i k K / X v j Y o p 5 5 Y q 8 5 O K 4 d x t e 4 3 4 X y 9 3 z Y V b 6 T j 9 l l Z C F y W C 5 u v w a S k p G t r 0 R H N h g a N c e s K 4 F f 7 9 l M + Z Z R x 9 m 2 G Y W N D w i x u l m M 6 r h N f j O K 2 q x C r a i e s 6 9 M 3 F 2 z 3 t k v P P 3 T j q x j + + d H r R p s M D 8 p 5 8 J E c k J l 9 J j 5 y S P h k Q T i 7 I J f l D r o L r 4 D a 4 C + 7 X o 3 v B Z u c d + Q f B w y M k U a y W &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 9 h v m 1 b r w P v d e S 5 u v J g 4 N X p 6 g w Y = " &gt; A A A C O n i c b V D P a x N B G J 2 t W u t a N d G j H g a D 0 F P Y F U G P g R b s M U L T B L J L m J 3 9 k g y Z H 8 v M t 2 p Y 9 t K / p l d 7 7 j / S a 2 + l 1 / 4 B n U 1 y 0 M Q H A 4 / 3 v m / e z M s K K R x G 0 U 2 w 9 + T p s / 3 n B y / C l 4 e v X r 9 p t d + e O 1 N a D g N u p L G j j D m Q Q s M A B U o Y F R a Y y i Q M s 8 V x 4 w 9 / g n X C 6 D N c F p A q N t N i K j h D L 0 1 a H x K E 3 1 h 9 N 0 z S E x 9 n R V Y 2 D q 3 7 k 9 m k 1 Y m 6 0 Q p 0 l 8 Q b 0 i E b 9 C f t Y D / J D S 8 V a O S S O T e O o w L T i l k U X E I d J q W D g v E F m 8 H Y U 8 0 U u L R a f a O m n 7 y S 0 6 m x / m i k K / X v j Y o p 5 5 Y q 8 5 O K 4 d x t e 4 3 4 X y 9 3 z Y V b 6 T j 9 l l Z C F y W C 5 u v w a S k p G t r 0 R H N h g a N c e s K 4 F f 7 9 l M + Z Z R x 9 m 2 G Y W N D w i x u l m M 6 r h N f j O K 2 q x C r a i e s 6 9 M 3 F 2 z 3 t k v P P 3 T j q x j + + d H r R p s M D 8 p 5 8 J E c k J l 9 J j 5 y S P h k Q T i 7 I J f l D r o L r 4 D a 4 C + 7 X o 3 v B Z u c d + Q f B w y M k U a y W &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 9 h v m 1 b r w P v d e S 5 u v J g 4 N X p 6 g w Y = " &gt; A A A C O n i c b V D P a x N B G J 2 t W u t a N d G j H g a D 0 F P Y F U G P g R b s M U L T B L J L m J 3 9 k g y Z H 8 v M t 2 p Y 9 t K / p l d 7 7 j / S a 2 + l 1 / 4 B n U 1 y 0 M Q H A 4 / 3 v m / e z M s K K R x G 0 U 2 w 9 + T p s / 3 n B y / C l 4 e v X r 9 p t d + e O 1 N a D g N u p L G j j D m Q Q s M A B U o Y F R a Y y i Q M s 8 V x 4 w 9 / g n X C 6 D N c F p A q N t N i K j h D L 0 1 a H x K E 3 1 h 9 N 0 z S E x 9 n R V Y 2 D q 3 7 k 9 m k 1 Y m 6 0 Q p 0 l 8 Q b 0 i E b 9 C f t Y D / J D S 8 V a O S S O T e O o w L T i l k U X E I d J q W D g v E F m 8 H Y U 8 0 U u L R a f a O m n 7 y S 0 6 m x / m i k K / X v j Y o p 5 5 Y q 8 5 O K 4 d x t e 4 3 4 X y 9 3 z Y V b 6 T j 9 l l Z C F y W C 5 u v w a S k p G t r 0 R H N h g a N c e s K 4 F f 7 9 l M + Z Z R x 9 m 2 G Y W N D w i x u l m M 6 r h N f j O K 2 q x C r a i e s 6 9 M 3 F 2 z 3 t k v P P 3 T j q x j + + d H r R p s M D 8 p 5 8 J E c k J l 9 J j 5 y S P h k Q T i 7 I J f l D r o L r 4 D a 4 C + 7 X o 3 v B Z u c d + Q f B w y M k U a y W &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 9 h v m 1 b r w P v d e S 5 u v J g 4 N X p 6 g w Y = " &gt; A A A C O n i c b V D P a x N B G J 2 t W u t a N d G j H g a D 0 F P Y F U G P g R b s M U L T B L J L m J 3 9 k g y Z H 8 v M t 2 p Y 9 t K / p l d 7 7 j / S a 2 + l 1 / 4 B n U 1 y 0 M Q H A 4 / 3 v m / e z M s K K R x G 0 U 2 w 9 + T p s / 3 n B y / C l 4 e v X r 9 p t d + e O 1 N a D g N u p L G j j D m Q Q s M A B U o Y F R a Y y i Q M s 8 V x 4 w 9 / g n X C 6 D N c F p A q N t N i K j h D L 0 1 a H x K E 3 1 h 9 N 0 z S E x 9 n R V Y 2 D q 3 7 k 9 m k 1 Y m 6 0 Q p 0 l 8 Q b 0 i E b 9 C f t Y D / J D S 8 V a O S S O T e O o w L T i l k U X E I d J q W D g v E F m 8 H Y U 8 0 U u L R a f a O m n 7 y S 0 6 m x / m i k K / X v j Y o p 5 5 Y q 8 5 O K 4 d x t e 4 3 4 X y 9 3 z Y V b 6 T j 9 l l Z C F y W C 5 u v w a S k p G t r 0 R H N h g a N c e s K 4 F f 7 9 l M + Z Z R x 9 m 2 G Y W N D w i x u l m M 6 r h N f j O K 2 q x C r a i e s 6 9 M 3 F 2 z 3 t k v P P 3 T j q x j + + d H r R p s M D 8 p 5 8 J E c k J l 9 J j 5 y S P h k Q T i 7 I J f l D r o L r 4 D a 4 C + 7 X o 3 v B Z u c d + Q f B w y M k U a y W &lt; / l a t e x i t &gt;</head><p>Panorama Image I p </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 3 5 G c e G C y b 6 G c r B D k n T t J 5 5 c X D k I = " &gt; A A A C Q H i c b V A 9 b 9 R A E F 0 n E B L z d Y E y z S o n J K q T j Z B C G S k N 6 Q 6 J S y K d r d N 4 P S a r 7 I e 1 O 4 a c V u 7 5 N b R Q 8 y / 4 B + k Q L R X r y x V w Y a S V n t 6 b m T f 7 q l Z J T 1 n 2 I 9 n a v n d / 5 8 H u X v r w 0 e M n T 0 f 7 z 8 6 8 7 Z z A m b D K u o s K P C p p c E a S F F 6 0 D k F X C s + r q 5 N B P / + I z k t r 3 t O y x V L D B y M b K Y A i t R g d F o T X F K Z g r A M N / D T q y P t C A 1 1 W T T j t F + 1 i N M 4 m 2 a r 4 X Z C v w Z i t a 7 r Y T 3 a K 2 o p</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Turn left and go to the red oil drum</head><p>Instruction ¯ x</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z F q o L X Y V 7 s i d P X V 0 C Z J W Q z V e 7 i 4 = " &gt; A A A C O H i c b V D B a h s x E N W m S Z p s 2 s Z p b + l F x A R 6 C G Y 3 B J q j o Z f 2 l k K c G L y L 0 W r H s b C k X a T Z x k Y s 9 G t 6 b c / 9 k 9 5 y C 7 3 2 C 6 J 1 9 t D Y e T D w e G 9 G o 3 l Z K Y X F K P o T b L z Y 3 N p + u b M b 7 r 1 6 / W a / c / D 2 y h a V 4 T D g h S z M M G M W p N A w Q I E S h q U B p j I J 1 9 n s U + N f f w N j R a E v c V F C q t i N F h P B G X p p 3 D l M E O b o v m i L p u K N R u s k Y 8 b N 6 3 G n G / W i J e g 6 i V v S J S 0 u x g f B d p I X v F K g k U t m 7 S i O S k w d M y i 4 h D p M K g s l 4 z N 2 A y N P N V N g U 7 c 8 o q b H X s n p p D C + N N K l + v + E Y 8 r a h c p 8 p 2 I 4 t a t e I z 7 r 5 b Z 5 c G U 7 T s 5 T J 3 R Z I W j + u H x S S Y o F b V K i u T D A U S 4 8 Y d w I / 3 / K p 8 w w j j 7 L M E w M a L j l h V J M 5 y 7 h 9 S h O n U u M o t 2 4 r k O f X L y a 0 z q 5 O u 3 F U S / + e t b t n 7 Q Z 7 p D 3 5 I h 8 I D H 5 S P r k M 7 k g A 8 L J d / K D / C S / g t / B X X A f / H 1 s 3 Q j a m X f k C Y J / D 6 Q r r G g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z F q o L X Y V 7 s i d P X V 0 C Z J W Q z V e 7 i 4 = " &gt; A A A C O H i c b V D B a h s x E N W m S Z p s 2 s Z p b + l F x A R 6 C G Y 3 B J q j o Z f 2 l k K c G L y L 0 W r H s b C k X a T Z x k Y s 9 G t 6 b c / 9 k 9 5 y C 7 3 2 C 6 J 1 9 t D Y e T D w e G 9 G o 3 l Z K Y X F K P o T b L z Y 3 N p + u b M b 7 r 1 6 / W a / c / D 2 y h a V 4 T D g h S z M M G M W p N A w Q I E S h q U B p j I J 1 9 n s U + N f f w N j R a E v c V F C q t i N F h P B G X p p 3 D l M E O b o v m i L p u K N R u s k Y 8 b N 6 3 G n G / W i J e g 6 i V v S J S 0 u x g f B d p I X v F K g k U t m 7 S i O S k w d M y i 4 h D p M K g s l 4 z N 2 A y N P N V N g U 7 c 8 o q b H X s n p p D C + N N K l + v + E Y 8 r a h c p 8 p 2 I 4 t a t e I z 7 r 5 b Z 5 c G U 7 T s 5 T J 3 R Z I W j + u H x S S Y o F b V K i u T D A U S 4 8 Y d w I / 3 / K p 8 w w j j 7 L M E w M a L j l h V J M 5 y 7 h 9 S h O n U u M o t 2 4 r k O f X L y a 0 z q 5 O u 3 F U S / + e t b t n 7 Q Z 7 p D 3 5 I h 8 I D H 5 S P r k M 7 k g A 8 L J d / K D / C S / g t / B X X A f / H 1 s 3 Q j a m X f k C Y J / D 6 Q r r G g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z F q o L X Y V 7 s i d P X V 0 C Z J W Q z V e 7 i 4 = " &gt; A A A C O H i c b V D B a h s x E N W m S Z p s 2 s Z p b + l F x A R 6 C G Y 3 B J q j o Z f 2 l k K c G L y L 0 W r H s b C k X a T Z x k Y s 9 G t 6 b c / 9 k 9 5 y C 7 3 2 C 6 J 1 9 t D Y e T D w e G 9 G o 3 l Z K Y X F K P o T b L z Y 3 N p + u b M b 7 r 1 6 / W a / c / D 2 y h a V 4 T D g h S z M M G M W p N A w Q I E S h q U B p j I J 1 9 n s U + N f f w N j R a E v c V F C q t i N F h P B G X p p 3 D l M E O b o v m i L p u K N R u s k Y 8 b N 6 3 G n G / W i J e g 6 i V v S J S 0 u x g f B d p I X v F K g k U t m 7 S i O S k w d M y i 4 h D p M K g s l 4 z N 2 A y N P N V N g U 7 c 8 o q b H X s n p p D C + N N K l + v + E Y 8 r a h c p 8 p 2 I 4 t a t e I z 7 r 5 b Z 5 c G U 7 T s 5 T J 3 R Z I W j + u H x S S Y o F b V K i u T D A U S 4 8 Y d w I / 3 / K p 8 w w j j 7 L M E w M a L j l h V J M 5 y 7 h 9 S h O n U u M o t 2 4 r k O f X L y a 0 z q 5 O u 3 F U S / + e t b t n 7 Q Z 7 p D 3 5 I h 8 I D H 5 S P r k M 7 k g A 8 L J d / K D / C S / g t / B X X A f / H 1 s 3 Q j a m X f k C Y J / D 6 Q r r G g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z F q o L X Y V 7 s i d P X V 0 C Z J W Q z V e 7 i 4 = " &gt; A A A C O H i c b V D B a h s x E N W m S Z p s 2 s Z p b + l F x A R 6 C G Y 3 B J q j o Z f 2 l k K c G L y L 0 W r H s b C k X a T Z x k Y s 9 G t 6 b c / 9 k 9 5 y C 7 3 2 C 6 J 1 9 t D Y e T D w e G 9 G o 3 l Z K Y X F K P o T b L z Y 3 N p + u b M b 7 r 1 6 / W a / c / D 2 y h a V 4 T D g h S z M M G M W p N A w Q I E S h q U B p j I J 1 9 n s U + N f f w N j R a E v c V F C q t i N F h P B G X p p 3 D l M E O b o v m i L p u K N R u s k Y 8 b N 6 3 G n G / W i J e g 6 i V v S J S 0 u x g f B d p I X v F K g k U t m 7 S i O S k w d M y i 4 h D p M K g s l 4 z N 2 A y N P N V N g U 7 c 8 o q b H X s n p p D C + N N K l + v + E Y 8 r a h c p 8 p 2 I 4 t a t e I z 7 r 5 b Z 5 c G U 7 T s 5 T J 3 R Z I W j + u H x S S Y o F b V K i u T D A U S 4 8 Y d w I / 3 / K p 8 w w j j 7 L M E w M a L j l h V J M 5 y 7 h 9 S h O n U u M o t 2 4 r k O f X L y a 0 z q 5 O u 3 F U S / + e t b t n 7 Q Z 7 p D 3 5 I h 8 I D H 5 S P r k M 7 k g A 8 L J d / K D / C S / g t / B X X A f / H 1 s 3 Q j a m X f k C Y J / D 6 Q r r G g = &lt; / l a t e x i t &gt;</head><p>Instruction Representation ¯ x     Goal Prediction To predict the goal location we generate a probability distribution P g over a feature map F 0 generated using convolutions from the initial panorama observation I P Each element in the probability distribution P g corre- sponds to an area in I P Given the instruction ¯ x and panorama I P we first generate their rep- resentations From the panorama I P we gener- ate a feature map F 0 = [CNN 0 (I P ); F p ] where CNN 0 is a two-layer convolutional neural net- work (CNN; LeCun et al 1998) with rectified linear units (ReLU; Nair and Hinton 2010) and F p are positional embeddings <ref type="bibr">2</ref> The concatena- tion is along the channel dimension The instruc- tion ¯ x = hx 1 , · · · x n i is mapped to a sequence of hidden states l = LSTM x ( x (x ), l 1 ) i = 1, . . . , n using a learned embedding function x and a long short-term memory (LSTM; Hochre- iter and Schmidhuber 1997) RNN LSTM x The instruction representation is ¯ x = l n We generate the probability distribution P g over pixels in The instruction representation ¯ x is split evenly into m vectors {¯ x j } m j=1 each is used to create a 1 ⇥ 1 kernel K j = AFF NE j (¯ x j ) where each AFF NE j is an affine transformation followed by normalizing and reshaping For each F j we apply a 2D 1 ⇥ 1 convolution using the text ker- nel K j to generate a text-conditioned feature map G j = CONVOLVE(K j , F j ) where CONVOLVE convolves the kernel over the feature map We then perform m deconvolutions to generate a se- quence of feature maps H m H 1 :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>o S y s v I / + m t 6 p W d u / S e 9 t c 6 y l d q l T 7 L 8 9 O Z 5 Z v y K R k l H S f I j G q y t P 9 l 4 u v k s f v 7 i 5 a u t 4 f b r M 1 e 3 V u B E 1 K q 2 F w V 3 q K T B C U l S e N F Y 5 L p Q e F 5 c H / X 1 8 x u 0 T t b m M 8 0 b z D W / N L K S g l O Q Z s P d j P C W / I l x Z F v R a + w T h g 4 O D S 0 s r M s 0 p 6 u i 8 l n B r b / t u t l w l I y T B d h j k i 7 J C J Y 4 n W 1 H G 1 l Z i 1 a H n k J x 5 6 Z p 0 l D u u S U p F H Z x 1 j p s u L j m l z g N 1 H C N L v e L z 3 X s X V B K V t U 2 H E N s o f 7 9 w n P t 3 F w X w d k v 6 l Z r v f j f W u n 6 h i v T q T r I v T R N S 2 j E w / C q V Y x q 1 q f H S m l R k J o H w o W V Y X 8 m r r j l g k L G c Z x Z N P h F 1 F p z U / p M d N M 0 9 z 6 z m o 3 S r o t D c u l q T o / J 2 e 4 4 T c b p x 7 3 R 4 Y d l h p v w F n b g P a S w D 4 d w D K c w A Q F f 4 R v c w f f o P v o Z / R p E D 9 Y / N 7 y B f z C I f w M 1 C r U T &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x 2 P F w / g X w U P L F a A H 8 V a k C x O P U p 4 = " &gt; A A A C U H i c b V B N T 9 w w E J 0 s l N L 0 g 6 U 9 9 m K x q t R D t U o Q E h y R u M C N V l 1 A 2 k Q r x 5 m A h e 1 E 9 o S y s v I / + m t 6 p W d u / S e 9 t c 6 y l d q l T 7 L 8 9 O Z 5 Z v y K R k l H S f I j G q y t P 9 l 4 u v k s f v 7 i 5 a u t 4 f b r M 1 e 3 V u B E 1 K q 2 F w V 3 q K T B C U l S e N F Y 5 L p Q e F 5 c H / X 1 8 x u 0 T t b m M 8 0 b z D W / N L K S g l O Q Z s P d j P C W / I l x Z F v R a + w T h g 4 O D S 0 s r M s 0 p 6 u i 8 l n B r b / t u t l w l I y T B d h j k i 7 J C J Y 4 n W 1 H G 1 l Z i 1 a H n k J x 5 6 Z p 0 l D u u S U p F H Z x 1 j p s u L j m l z g N 1 H C N L v e L z 3 X s X V B K V t U 2 H E N s o f 7 9 w n P t 3 F w X w d k v 6 l Z r v f j f W u n 6 h i v T q T r I v T R N S 2 j E w / C q V Y x q 1 q f H S m l R k J o H w o W V Y X 8 m r r j l g k L G c Z x Z N P h F 1 F p z U / p M d N M 0 9 z 6 z m o 3 S r o t D c u l q T o / J 2 e 4 4 T c b p x 7 3 R 4 Y d l h p v w F n b g P a S w D 4 d w D K c w A Q F f 4 R v c w f f o P v o Z / R p E D 9 Y / N 7 y B f z C I f w M 1 C r U T &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x 2 P F w / g X w U P L F a A H 8 V a k C x O P U p 4 = " &gt; A A A C U H i c b V B N T 9 w w E J 0 s l N L 0 g 6 U 9 9 m K x q t R D t U o Q E h y R u M C N V l 1 A 2 k Q r x 5 m A h e 1 E 9 o S y s v I / + m t 6 p W d u / S e 9 t c 6 y l d q l T 7 L 8 9 O Z 5 Z v y K R k l H S f I j G q y t P 9 l 4 u v k s f v 7 i 5 a u t 4 f b r M 1 e 3 V u B E 1 K q 2 F w V 3 q K T B C U l S e N F Y 5 L p Q e F 5 c H / X 1 8 x u 0 T t b m M 8 0 b z D W / N L K S g l O Q Z s P d j P C W / I l x Z F v R a + w T h g 4 O D S 0 s r M s 0 p 6 u i 8 l n B r b / t u t l w l I y T B d h j k i 7 J C J Y 4 n W 1 H G 1 l Z i 1 a H n k J x 5 6 Z p 0 l D u u S U p F H Z x 1 j p s u L j m l z g N 1 H C N L v e L z 3 X s X V B K V t U 2 H E N s o f 7 9 w n P t 3 F w X w d k v 6 l Z r v f j f W u n 6 h i v T q T r I v T R N S 2 j E w / C q V Y x q 1 q f H S m l R k J o H w o W V Y X 8 m r r j l g k L G c Z x Z N P h F 1 F p z U / p M d N M 0 9 z 6 z m o 3 S r o t D c u l q T o / J 2 e 4 4 T c b p x 7 3 R 4 Y d l h p v w F n b g P a S w D 4 d w D K c w A Q F f 4 R v c w f f o P v o Z / R p E D 9 Y / N 7 y B f z C I f w M 1 C r U T &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x 2 P F w / g X w U P L F a A H 8 V a k C x O P U p 4 = " &gt; A A A C U H i c b V B N T 9 w w E J 0 s l N L 0 g 6 U 9 9 m K x q t R D t U o Q E h y R u M C N V l 1 A 2 k Q r x 5 m A h e 1 E 9 o S y s v I / + m t 6 p W d u / S e 9 t c 6 y l d q l T 7 L 8 9 O Z 5 Z v y K R k l H S f I j G q y t P 9 l 4 u v k s f v 7 i 5 a u t 4 f b r M 1 e 3 V u B E 1 K q 2 F w V 3 q K T B C U l S e N F Y 5 L p Q e F 5 c H / X 1 8 x u 0 T t b m M 8 0 b z D W / N L K S g l O Q Z s P d j P C W / I l x Z F v R a + w T h g 4 O D S 0 s r M s 0 p 6 u i 8 l n B r b / t u t l w l I y T B d h j k i 7 J C J Y 4 n W 1 H G 1 l Z i 1 a H n k J x 5 6 Z p 0 l D u u S U p F H Z x 1 j p s u L j m l z g N 1 H C N L v e L z 3 X s X V B K V t U 2 H E N s o f 7 9 w n P t 3 F w X w d k v 6 l Z r v f j f W u n 6 h i v T q T r I v T R N S 2 j E w / C q V Y x q 1 q f H S m l R k J o H w o W V Y X 8 m r r j l g k L G c Z x Z N P h F 1 F p z U / p M d N M 0 9 z 6 z m o 3 S r o t D c u l q T o / J 2 e 4 4 T c b p x 7 3 R 4 Y d l h p v w F n b g P a S w D 4 d w D K c w A Q F f 4 R v c w f f o P v o Z / R p E D 9 Y / N 7 y B f z C I f w M 1 C r U T &lt; / l a t e x i t &gt;</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Softmax</head><formula xml:id="formula_4">= " H G k Y r D n U 4 w 9 h N J l r L x v H u N 2 z S d s = " &gt; A A A C L X i c b V D L S s N A F J 3 4 r P H R q k s 3 g 0 V w V R I R d C m 4 c S F S w a r Q h D K Z 3 N b B m U m Y u V F L y J e 4 1 b V f 4 0 I Q t / 6 G 0 9 q F V g 9 c O J x z X 5 w k l 8 J i E L x 5 M 7 N z 8 w u L t S V / e W V 1 r d 5 Y 3 7 i 0 W W E 4 d H g m M 3 O d M A t S a O i g Q A n X u Q G m E g l X y e 3 x y L + 6 A 2 N F p i 9 w m E O s 2 E C L v u A M n d R r 1 C O E B y x P h R 5 0 z g C r X q M Z t I I x 6 F 8 S T k i T T N D u r X s L U Z r x Q o F G L p m 1 3 T D I M S 6 Z Q c E l V H 5 U W M g Z v 2 U D 6 D q q m Q I b l + P P K 7 r j l J T 2 M + N K I x 2 r P y d K p q w d q s R 1 K o Y 3 d t o b i f 9 6 q R 0 t n L q O / c O 4 F D o v E D T / P t 4 v J M W M j q K h q T D A U Q 4 d Y d w I 9 z / l N 8 w w j i 5 A 3 4 8 M a L j n m V J M p 2 X E q 2 4 Y l 2 V k F G 2 G V e W 7 5 M L p n P 6 S y 7 1 W G L T C 8 / 3 m U T D J s E a 2 y D b Z J S E 5 I E f k h L R J h 3 B S k E f y R J 6 9 F + / V e / c + v l t n v M n M J v k F 7 / M L g 7 e n Q Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H G k Y r D n U 4 w 9 h N J l r L x v H u N 2 z S d s = " &gt; A A A C L X i c b V D L S s N A F J 3 4 r P H R q k s 3 g 0 V w V R I R d C m 4 c S F S w a r Q h D K Z 3 N b B m U m Y u V F L y J e 4 1 b V f 4 0 I Q t / 6 G 0 9 q F V g 9 c O J x z X 5 w k l 8 J i E L x 5 M 7 N z 8 w u L t S V / e W V 1 r d 5 Y 3 7 i 0 W W E 4 d H g m M 3 O d M A t S a O i g Q A n X u Q G m E g l X y e 3 x y L + 6 A 2 N F p i 9 w m E O s 2 E C L v u A M n d R r 1 C O E B y x P h R 5 0 z g C r X q M Z t I I x 6 F 8 S T k i T T N D u r X s L U Z r x Q o F G L p m 1 3 T D I M S 6 Z Q c E l V H 5 U W M g Z v 2 U D 6 D q q m Q I b l + P P K 7 r j l J T 2 M + N K I x 2 r P y d K p q w d q s R 1 K o Y 3 d t o b i f 9 6 q R 0 t n L q O / c O 4 F D o v E D T / P t 4 v J M W M j q K h q T D A U Q 4 d Y d w I 9 z / l N 8 w w j i 5 A 3 4 8 M a L j n m V J M p 2 X E q 2 4 Y l 2 V k F G 2 G V e W 7 5 M L p n P 6 S y 7 1 W G L T C 8 / 3 m U T D J s E a 2 y D b Z J S E 5 I E f k h L R J h 3 B S k E f y R J 6 9 F + / V e / c + v l t n v M n M J v k F 7 / M L g 7 e n Q Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H G k Y r D n U 4 w 9 h N J l r L x v H u N 2 z S d s = " &gt; A A A C L X i c b V D L S s N A F J 3 4 r P H R q k s 3 g 0 V w V R I R d C m 4 c S F S w a r Q h D K Z 3 N b B m U m Y u V F L y J e 4 1 b V f 4 0 I Q t / 6 G 0 9 q F V g 9 c O J x z X 5 w k l 8 J i E L x 5 M 7 N z 8 w u L t S V / e W V 1 r d 5 Y 3 7 i 0 W W E 4 d H g m M 3 O d M A t S a O i g Q A n X u Q G m E g l X y e 3 x y L + 6 A 2 N F p i 9 w m E O s 2 E C L v u A M n d R r 1 C O E B y x P h R 5 0 z g C r X q M Z t I I x 6 F 8 S T k i T T N D u r X s L U Z r x Q o F G L p m 1 3 T D I M S 6 Z Q c E l V H 5 U W M g Z v 2 U D 6 D q q m Q I b l + P P K 7 r j l J T 2 M + N K I x 2 r P y d K p q w d q s R 1 K o Y 3 d t o b i f 9 6 q R 0 t n L q O / c O 4 F D o v E D T / P t 4 v J M W M j q K h q T D A U Q 4 d Y d w I 9 z / l N 8 w w j i 5 A 3 4 8 M a L j n m V J M p 2 X E q 2 4 Y l 2 V k F G 2 G V e W 7 5 M L p n P 6 S y 7 1 W G L T C 8 / 3 m U T D J s E a 2 y D b Z J S E 5 I E f k h L R J h 3 B S k E f y R J 6 9 F + / V e / c + v l t n v M n M J v k F 7 / M L g 7 e n Q Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H G k Y r D n U 4 w 9 h N J l r L x v H u N 2 z S d s = " &gt; A A A C L X i c b V D L S s N A F J 3 4 r P H R q k s 3 g 0 V w V R I R d C m 4 c S F S w a r Q h D K Z 3 N b B m U m Y u V F L y J e 4 1 b V f 4 0 I Q t / 6 G 0 9 q F V g 9 c O J x z X 5 w k l 8 J i E L x 5 M 7 N z 8 w u L t S V / e W V 1 r d 5 Y 3 7 i 0 W W E 4 d H g m M 3 O d M A t S a O i g Q A n X u Q G m E g l X y e 3 x y L + 6 A 2 N F p i 9 w m E O s 2 E C L v u A M n d R r 1 C O E B y x P h R 5 0 z g C r X q M Z t I I x 6 F 8 S T k i T T N D u r X s L U Z r x Q o F G L p m 1 3 T D I M S 6 Z Q c E l V H 5 U W M g Z v 2 U D 6 D q q m Q I b l + P P K 7 r j l J T 2 M + N K I x 2 r P y d K p q w d q s R 1 K o Y 3 d t o b i f 9 6 q R 0 t n L q O / c O 4 F D o v E D T / P t 4 v J M W M j q K h q T D A U Q 4 d Y d w I 9 z / l N 8 w w j i 5 A 3 4 8 M a L j n m V J M p 2 X E q 2 4 Y l 2 V k F G 2 G V e W 7 5 M L p n P 6 S y 7 1 W G L T C 8 / 3 m U T D J s E a 2 y D b Z J S E 5 I E f k h L R J h 3 B S k E f y R J 6 9 F + / V e / c + v l t n v M n M J v k F 7 / M L</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a t e x i t s h a 1 _ b a s e 6 4 = " 9 1 g H T s / K b c m 7 q 6 3 Z D T F 3 k r + U L N 8 = " &gt; A A A C K H i c b V D L S s N A F J 3 4 r P F Z X b o Z L I K r k o i g S 8 G N y w p W h S a U y e S 2 D s 4 j z N y o J e Q 3 3 O r a r 3 E n b v 0 S p 7 U L r R 6 4 c D j n v j h Z I Y X D K P o I 5 u Y X F p e W G y v h 6 t r 6 x u Z W c / v K m d J y 6 H I j j b 3 J m A M p N H R R o I S b w g J T m Y T r 7 O 5 s 7 F / f g 3 X C 6 E s c F Z A q N t R i I D h D L y U J w i N W H e P A 1 f 2 t V t S O J q B / S T w l L T J F p 9 8 M l p L c 8 F K B R i 6 Z c 7 0 4 K j C t m E X B J d R h U j o o G L 9 j Q + h 5 q p k C l 1 a T p 2 u 6 7 5 W c D o z 1 p Z F O 1 J 8 T F V P O j V T m O x X D W z f r j c V / v d y N F 8 5 c x 8 F J W g l d l A i a f x 8 f l J K i o e N U a C 4 s c J Q j T x i 3 w v 9 P + S 2 z j K P P L g w T C x o e u F G K 6 b x K e N 2 L 0 6 p K r K K t u K 5 D n 1 w 8 m 9 N f c n X Y j q N 2 f H H U O o 2 m G T b I L t k j B y Q m x + S U n J M O 6 R J O C v J E n s l L 8 B q 8 B e / B x 3 f r X D C d 2 S G / E H x + A d R 3 p f Y = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 1 g H T s / K b c m 7 q 6 3 Z D T F 3 k r + U L N 8 = " &gt; A A A C K H i c b V D L S s N A F J 3 4 r P F Z X b o Z L I K r k o i g S 8 G N y w p W h S a U y e S 2 D s 4 j z N y o J e Q 3 3 O r a r 3 E n b v 0 S p 7 U L r R 6 4 c D j n v j h Z I Y X D K P o I 5 u Y X F p e W G y v h 6 t r 6 x u Z W c / v K m d J y 6 H I j j b 3 J m A M p N H R R o I S b w g J T m Y T r 7 O 5 s 7 F / f g 3 X C 6 E s c F Z A q N t R i I D h D L y U J w i N W H e P A 1 f 2 t V t S O J q B / S T w l L T J F p 9 8 M l p L c 8 F K B R i 6 Z c 7 0 4 K j C t m E X B J d R h U j o o G L 9 j Q + h 5 q p k C l 1 a T p 2 u 6 7 5 W c D o z 1 p Z F O 1 J 8 T F V P O j V T m O x X D W z f r j c V / v d y N F 8 5 c x 8 F J W g l d l A i a f x 8 f l J K i o e N U a C 4 s c J Q j T x i 3 w v 9 P + S 2 z j K P P L g w T C x o e u F G K 6 b x K e N 2 L 0 6 p K r K K t u K 5 D n 1 w 8 m 9 N f c n X Y j q N 2 f H H U O o 2 m G T b I L t k j B y Q m x + S U n J M O 6 R J O C v J E n s l L 8 B q 8 B e / B x 3 f r X D C d 2 S G / E H x + A d R 3 p f Y = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 1 g H T s / K b c m 7 q 6 3 Z D T F 3 k r + U L N 8 = " &gt; A A A C K H i c b V D L S s N A F J 3 4 r P F Z X b o Z L I K r k o i g S 8 G N y w p W h S a U y e S 2 D s 4 j z N y o J e Q 3 3 O r a r 3 E n b v 0 S p 7 U L r R 6 4 c D j n v j h Z I Y X D K P o I 5 u Y X F p e W G y v h 6 t r 6 x u Z W c / v K m d J y 6 H I j j b 3 J m A M p N H R R o I S b w g J T m Y T r 7 O 5 s 7 F / f g 3 X C 6 E s c F Z A q N t R i I D h D L y U J w i N W H e P A 1 f 2 t V t S O J q B / S T w l L T J F p 9 8 M l p L c 8 F K B R i 6 Z c 7 0 4 K j C t m E X B J d R h U j o o G L 9 j Q + h 5 q p k C l 1 a T p 2 u 6 7 5 W c D o z 1 p Z F O 1 J 8 T F V P O j V T m O x X D W z f r j c V / v d y N F 8 5 c x 8 F J W g l d l A i a f x 8 f l J K i o e N U a C 4 s c J Q j T x i 3 w v 9 P + S 2 z j K P P L g w T C x o e u F G K 6 b x K e N 2 L 0 6 p K r K K t u K 5 D n 1 w 8 m 9 N f c n X Y j q N 2 f H H U O o 2 m G T b I L t k j B y Q m x + S U n J M O 6 R J O C v J E n s l L 8 B q 8 B e / B x 3 f r X D C d 2 S G / E H x + A d R 3 p f Y = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 1 g H T s / K b c m 7 q 6 3 Z D T F 3 k r + U L N 8 = " &gt; A A A C K H i c b V D L S s N A F J 3 4 r P F Z X b o Z L I K r k o i g S 8 G N y w p W h S a U y e S 2 D s 4 j z N y o J e Q 3 3 O r a r 3 E n b v 0 S p 7 U L r R 6 4 c D j n v j h Z I Y X D K P o I 5 u Y X F p e W G y v h 6 t r 6 x u Z W c / v K m d J y 6 H I j j b 3 J m A M p N H R R o I S b w g J T m Y T r 7 O 5 s 7 F / f g 3 X C 6 E s c F Z A q N t R i I D h D L y U J w i N W H e P A 1 f 2 t V t S O J q B / S T w l L T J F p 9 8 M l p L c 8 F K B R i 6 Z c 7 0 4 K j C t m E X B J d R h U j o o G L 9 j Q + h 5 q p k C l 1 a T p 2 u 6 7 5 W c D o z 1 p Z F O 1 J 8 T F V P O j V T m O x X D W z f r j c V / v d y N F 8 5 c x 8 F J W g l d l A i a f x 8 f l J K i o e N U a C 4 s c J Q j T x i 3 w v 9 P + S 2 z j K P P L g w T C x o e u F G K 6 b x K e N 2 L 0 6 p K r K K t u K 5 D n 1 w 8 m 9 N f c n X Y j q N 2 f H H U O o 2 m G T b I L t k j B y Q m x + S U n J M O 6 R J O C v J E n s l L 8 B q 8 B e / B x 3 f r X D C d 2 S G / E H x + A d R 3 p f Y = &lt; / l a t e x i t &gt;</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Goal Masks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>t e x i t s h a 1 _ b a s e 6 4 = " K i B Q V 7 1 N 2 b L 5 0 J j 1 u T a c U W v C E J Q = " &gt; A A A C K H i c b V B N S 8 N A F N x U r R q / q h 6 9 L A b B U 0 l E 0 G N B E I 8 K V g t N K J v N i 1 2 6 u w m 7 G 6 W E / A 2 v e v b X e B O v / h I 3 N Q d t H V g Y Z t 7 b N 0 y c c 6 a N 7 3 8 6 r a X l l f b q 2 r q 7 s b m 1 v d P Z 3 b v T W a E o 9 G n G M z W I i Q b O J P Q N M x w G u Q I i Y g 7 3 8 e S i 9 u 8 f Q W m W y V s z z S E S 5 E G y l F F i r B S G g p h x n J a X 1 c g f d T y / 6 8 + A F 0 n Q E A 8 1 u B 7 t O u 0 w y W g h Q B r K i d b D w M 9 N V B J l G O V Q u W G h I S d 0 Q h 5 g a K k k A n R U z k J X + M g q C U 4 z Z Z 8 0 e K b + 3 i i J 0 H o q Y j t Z h 9 T z X i 3 + 6 y W 6 / n D u u k n P o 5 L J v D A g 6 c / x t O D Y Z L h u B S d M A T V 8 a g m h i t n 8 m I 6 J I t T Y 7 l w 3 V C D h i W Z C E J m U I a 2 G Q V S W o R L Y C 6 r K t c 0 F 8 z 0 t k r u T b u B 3 g 5 t T r + c 3 H a 6 h A 3 S I j l G A z l A P X a F r 1 E c U 5 e g Z v a B X 5 8 1 5 d z 6 c z 5 / R l t P s 7 K M / c L 6 + A e j f p W 4 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K i B Q V 7 1 N 2 b L 5 0 J j 1 u T a c U W v C E J Q = " &gt; A A A C K H i c b V B N S 8 N A F N x U r R q / q h 6 9 L A b B U 0 l E 0 G N B E I 8 K V g t N K J v N i 1 2 6 u w m 7 G 6 W E / A 2 v e v b X e B O v / h I 3 N Q d t H V g Y Z t 7 b N 0 y c c 6 a N 7 3 8 6 r a X l l f b q 2 r q 7 s b m 1 v d P Z 3 b v T W a E o 9 G n G M z W I i Q b O J P Q N M x w G u Q I i Y g 7 3 8 e S i 9 u 8 f Q W m W y V s z z S E S 5 E G y l F F i r B S G g p h x n J a X 1 c g f d T y / 6 8 + A F 0 n Q E A 8 1 u B 7 t O u 0 w y W g h Q B r K i d b D w M 9 N V B J l G O V Q u W G h I S d 0 Q h 5 g a K k k A n R U z k J X + M g q C U 4 z Z Z 8 0 e K b + 3 i i J 0 H o q Y j t Z h 9 T z X i 3 + 6 y W 6 / n D u u k n P o 5 L J v D A g 6 c / x t O D Y Z L h u B S d M A T V 8 a g m h i t n 8 m I 6 J I t T Y 7 l w 3 V C D h i W Z C E J m U I a 2 G Q V S W o R L Y C 6 r K t c 0 F 8 z 0 t k r u T b u B 3 g 5 t T r + c 3 H a 6 h A 3 S I j l G A z l A P X a F r 1 E c U 5 e g Z v a B X 5 8 1 5 d z 6 c z 5 / R l t P s 7 K M / c L 6 + A e j f p W 4 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K i B Q V 7 1 N 2 b L 5 0 J j 1 u T a c U W v C E J Q = " &gt; A A A C K H i c b V B N S 8 N A F N x U r R q / q h 6 9 L A b B U 0 l E 0 G N B E I 8 K V g t N K J v N i 1 2 6 u w m 7 G 6 W E / A 2 v e v b X e B O v / h I 3 N Q d t H V g Y Z t 7 b N 0 y c c 6 a N 7 3 8 6 r a X l l f b q 2 r q 7 s b m 1 v d P Z 3 b v T W a E o 9 G n G M z W I i Q b O J P Q N M x w G u Q I i Y g 7 3 8 e S i 9 u 8 f Q W m W y V s z z S E S 5 E G y l F F i r B S G g p h x n J a X 1 c g f d T y / 6 8 + A F 0 n Q E A 8 1 u B 7 t O u 0 w y W g h Q B r K i d b D w M 9 N V B J l G O V Q u W G h I S d 0 Q h 5 g a K k k A n R U z k J X + M g q C U 4 z Z Z 8 0 e K b + 3 i i J 0 H o q Y j t Z h 9 T z X i 3 + 6 y W 6 / n D u u k n P o 5 L J v D A g 6 c / x t O D Y Z L h u B S d M A T V 8 a g m h i t n 8 m I 6 J I t T Y 7 l w 3 V C D h i W Z C E J m U I a 2 G Q V S W o R L Y C 6 r K t c 0 F 8 z 0 t k r u T b u B 3 g 5 t T r + c 3 H a 6 h A 3 S I j l G A z l A P X a F r 1 E c U 5 e g Z v a B X 5 8 1 5 d z 6 c z 5 / R l t P s 7 K M / c L 6 + A e j f p W 4 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K i B Q V 7 1 N 2 b L 5 0 J j 1 u T a c U W v C E J Q = " &gt; A A A C K H i c b V B N S 8 N A F N x U r R q / q h 6 9 L A b B U 0 l E 0 G N B E I 8 K V g t N K J v N i 1 2 6 u w m 7 G 6 W E / A 2 v e v b X e B O v / h I 3 N Q d t H V g Y Z t 7 b N 0 y c c 6 a N 7 3 8 6 r a X l l f b q 2 r q 7 s b m 1 v d P Z 3 b v T W a E o 9 G n G M z W I i Q b O J P Q N M x w G u Q I i Y g 7 3 8 e S i 9 u 8 f Q W m W y V s z z S E S 5 E G y l F F i r B S G g p h x n J a X 1 c g f d T y / 6 8 + A F 0 n Q E A 8 1 u B 7 t O u 0 w y W g h Q B r K i d b D w M 9 N V B J l G O V Q u W G h I S d 0 Q h 5 g a K k k A n R U z k J X + M g q C U 4 z Z Z 8 0 e K b + 3 i i J 0 H o q Y j t Z h 9 T z X i 3 + 6 y W 6 / n D u u k n P o 5 L J v D A g 6 c / x t O D Y Z L h u B S d M A T V 8 a g m h i t n 8 m I 6 J I t T Y 7 l w 3 V C D h i W Z C E J m U I a 2 G Q V S W o R L Y C 6 r K t c 0 F 8 z 0 t k r u T b u B 3 g 5 t T r + c 3 H a 6 h A 3 S I j l G A z l A P X a F r 1 E c U 5 e g Z v a B X 5 8 1 5 d z 6 c z 5 / R l t P s 7 K M / c L 6 + A e j f p W 4 = &lt; / l a t e x i t &gt;</head><formula xml:id="formula_5">Hm = DECONVm(DROPOUT(Gm)) Hj = DECONVj( Hj+1 Gj )</formula><p>DROPOUT is dropout regularization (Srivastava et al 2014) and each DECONV j is a decon- volution operation followed a leaky ReLU non- linearity and instance norm 3 Finally we gener- ate P g by applying a softmax to H 1 and an ad- ditional learned scalar bias term b g to represent events where the goal is out of sight For example when the agent already stands in the goal position and therefore the panorama does not show it We use P g to predict the goal position in the environment We first select the goal pixel in F 0 as the pixel corresponding to the highest probability element in P g We then identify the corresponding 3D location l g in the environment using backward camera projection which is computed given the DECONV1 does deconvo u on on y camera parameters and p 1 , the agent pose at the beginning of the execution. Action Generation Given the predicted goal l g , we generate actions using an RNN. At each time step t, given p t , we generate the goal mask M t , which has the same shape as the observed image I t . The goal mask M t has a value of 1 for each element that corresponds to the goal location l g in I t . We do not distinguish between visible or oc- cluded locations. All other elements are set to 0. We also maintain an out-of-sight flag o t that is set to 1 if (a) l g is not within the agent's view; or (b) the max scoring element in P g corresponds to b g , the term for events when the goal is not visible in I P . Otherwise, o t is set to 0. We compute an ac- tion generation hidden state y t with an RNN:</p><formula xml:id="formula_6">yt = LSTMA (AFFINEA([FLAT(Mt); ot]), yt1) ,</formula><p>where FLAT flattens M t into a vector, AFFINE A is a learned affine transformation with ReLU, and LSTM A is an LSTM RNN. The previous hidden state y t1 was computed when generating the pre- vious action, and the RNN is extended gradually during execution. Finally, we compute a probabil- ity distribution over actions:</p><formula xml:id="formula_7">P (at | lg, (I1, p1), . . . , (It, pt)) = SOFTMAX(AFFINEp([yt; T (t)])) ,</formula><p>where T is a learned embedding lookup table for the current time <ref type="bibr" target="#b5">(Chaplot et al., 2018)</ref> and AFFINE p is a learned affine transformation. Model Parameters The model parameters ✓ in- clude the parameters of the convolutions CNN 0 and the components of LINGUNET: CNN j , AFFINE j , and DECONV j for j = 1, . . . , m.</p><p>In addition we learn two affine transformations AFFINE A and AFFINE p , two RNNs LSTM x and LSTM A , two embedding functions x and T , and the goal distribution bias term b g . In our ex- periments (Section 7), all parameters are learned without external resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Learning</head><p>Our modeling decomposition enables us to choose different learning algorithms for the two parts. While reinforcement learning is commonly de- ployed for tasks that benefit from exploration (e.g., <ref type="bibr" target="#b36">Peters and Schaal, 2008;</ref><ref type="bibr" target="#b32">Mnih et al., 2013</ref>), these methods require many samples due to their high sample complexity. However, when learning with natural language, only a relatively small number of samples is realistically available. This problem was addressed in prior work by learning in a con- textual bandit setting ( <ref type="bibr" target="#b29">Misra et al., 2017)</ref> or mix- ing reinforcement and supervised learning <ref type="bibr" target="#b45">(Xiong et al., 2018)</ref>. Our decomposition uniquely offers to tease apart the language understanding prob- lem and address it with supervised learning, which generally has lower sample complexity. For action generation though, where exploration can be au- tonomous, we use policy gradient in a contextual bandit setting ( <ref type="bibr" target="#b29">Misra et al., 2017)</ref>. We assume access to training data with N ex- amples {(¯ x (i) , s</p><formula xml:id="formula_8">(i) 1 , s (i) g )} N i=1 , where ¯ x (i) is an in- struction, s (i)</formula><p>1 is a start state, and s g . We update the model parameters using Adam ( <ref type="bibr" target="#b17">Kingma and Ba, 2014)</ref>.</p><p>We train action generation by maximizing the expected immediate reward the agent observes while exploring the environment. The objective for a single example i and time stamp t is:</p><formula xml:id="formula_9">J = X a2A ⇡(a | ˜ st)R (i) (st, a) + H(⇡(. | ˜ st)) ,</formula><p>where R (i) : S ⇥ A ! R is an example-specific reward function, H(·) is an entropy regularization term, and is the regularization coefficient. The reward function R (i) details are described in de- tails in Appendix B. Roughly speaking, the re- ward function includes two additive components: a problem reward and a shaping term ( <ref type="bibr" target="#b34">Ng et al., 1999</ref>). The problem reward provides a positive re- ward for successful task completion, and a nega- tive reward for incorrect completion or collision. The shaping term is positive when the agent gets closer to the goal position, and negative if it is moving away. The gradient of the objective is:</p><formula xml:id="formula_10">rJ = X a2A ⇡(a | ˜ st)r log ⇡(a | ˜ st)R(st, a) +rH(⇡(. | ˜ st) .</formula><p>We approximate the gradient by sampling an ac- tion using the policy <ref type="bibr" target="#b44">(Williams, 1992)</ref>, and use the gold goal location computed from s  6 Tasks and Data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">LANI</head><p>The goal of LANI is to evaluate how well an agent can follow navigation instructions. The agent task is to follow a sequence of instructions that specify a path in an environment with multiple landmarks. <ref type="figure" target="#fig_0">Figure 1</ref> (left) shows an example instruction. The environment is a fenced, square, grass field. Each instance of the environment con- tains between 6-13 randomly placed landmarks, sampled from 63 unique landmarks. The agent can take four types of discrete actions: FORWARD, TURNRIGHT, TURNLEFT, and STOP. The field is of size 50⇥50, the distance of the FORWARD ac- tion is 1.5, and the turn angle is 15 . The en- vironment simulator is implemented in Unity3D. At each time step, the agent performs an action, observes a first person view of the environment as an RGB image, and receives a scalar reward. The simulator provides a socket API to control the agent and the environment.</p><p>Agent performance is evaluated using two met- rics: task completion accuracy, and stop distance error. A task is completed correctly if the agent stops within an aerial distance of 5 from the goal.</p><p>We collect a corpus of navigation instructions using crowdsourcing. We randomly generate en- vironments, and generate one reference path for each environment. To elicit linguistically interest- ing instructions, reference paths are generated to pass near landmarks. We use Amazon Mechanical Turk, and split the annotation process to two tasks. First, given an environment and a reference path, a worker writes an instruction paragraph for fol- lowing the path. The second task requires another worker to control the agent to perform the instruc- tions and simultaneously mark at each point what part of the instruction was executed. The record- ing of the second worker creates the final data of segmented instructions and demonstrations. The generated reference path is displayed in both tasks. The second worker could also mark the paragraph as invalid. Both tasks are done from an over- head view of the environment, but workers are in- structed to provide instructions for a robot that ob- Go around the pillar on the right hand side and head towards the boat, circling around it clockwise. When you are facing the tree, walk towards it, and the pass on the right hand side, and the left hand side of the cone. Circle around the cone, and then walk past the hydrant on your right, and the the tree stump. Circle around the stump and then stop right behind it.</p><p>Circle around the statue counter clockwise on the right hand side, then head towards the barrel. Go past the barrel on the right hand side and head towards the bench, passing the bench on the right side, stopping right before you get to the white fence.  serves the environment from a first person view. <ref type="figure" target="#fig_12">Figure 3</ref> shows a reference path and the written instruction. This data can be used for evaluating both executing sequences of instructions and sin- gle instructions in isolation. <ref type="table" target="#tab_1">Table 1</ref> shows the corpus statistics. <ref type="bibr">4</ref> Each para- graph corresponds to a single unique instance of the environment. The paragraphs are split into train, test, and development, with a 70% / 15% / 15% split. Finally, we sample 200 single devel- opment instructions for qualitative analysis of the language challenge the corpus presents <ref type="table" target="#tab_2">(Table 2)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">CHAI</head><p>The CHAI corpus combines both navigation and simple manipulation in a complex, simulated household environment. We use the CHALET sim- ulator ( <ref type="bibr" target="#b46">Yan et al., 2018)</ref>, a 3D house simulator that provides multiple houses, each with multi- ple rooms. The environment supports moving be- tween rooms, picking and placing objects, and opening and closing cabinets and similar contain- ers. Objects can be moved between rooms and in and out of containers. The agent observes the world in first-person view, and can take five ac- tions: FORWARD, TURNLEFT, TURNRIGHT, STOP, and INTERACT. The INTERACT action acts on ob- jects. It takes as argument a 2D position in the agent's view. Agent performance is evaluated with two metrics: (a) stop distance, which measures the distance of the agent's final state to the final an- notated position; and (b) manipulation accuracy, which compares the set of manipulation actions <ref type="table" target="#tab_1">Count  Category  LANI CHAI Example  Spatial relations  between locations  123  52</ref> LANI: go to the right side of the rock CHAI: pick up the cup next to the bathtub and place it on . . <ref type="table" target="#tab_7">.  Conjunctions of two  more locations  36  5</ref> LANI: fly between the mushroom and the yellow cone CHAI: . . . set it on the table next to the juice and milk. Temporal coordination of sub-goals 65 68 LANI: at the mushroom turn right and move forward towards the statue CHAI: go back to the kitchen and put the glass in the sink. Constraints on the shape of trajectory 94 0 LANI: go past the house by the right side of the apple</p><p>Co-reference 32 18 LANI: turn around it and move in front of fern plant CHAI: turn left, towards the kitchen door and move through it. Comparatives 2 0 LANI: . . . the small stone closest to the blue and white fences stop  to a reference set. When measuring distance, to consider the house plan, we compute the minimal aerial distance for each room that must be visited. <ref type="bibr" target="#b46">Yan et al. (2018)</ref> provides the full details of the simulator and evaluation. We use five different houses, each with up to six rooms. Each room contains on average 30 objects. A typical room is of size 6⇥6. We set the distance of FORWARD to 0.1, the turn angle to 90 , and divide the agent's view to a 32⇥32 grid for the INTERACT action. We collected a corpus of navigation and ma- nipulation instructions using Amazon Mechanical Turk. We created 36 common household scenar- ios to provide a familiar context to the task. <ref type="bibr">5</ref> We use two crowdsourcing tasks. First, we provide workers with a scenario and ask them to write in- structions. The workers are encouraged to explore the environment and interact with it. We then seg- ment the instructions to sentences automatically. In the second task, workers are presented with the segmented sentences in order and asked to execute them. After finishing a sentence, the workers re- <ref type="bibr">5</ref> We observed that asking workers to simply write instruc- tions without providing a scenario leads to combinations of repetitive instructions unlikely to occur in reality. quest the next sentence. The workers do not see the original scenario. <ref type="figure" target="#fig_13">Figure 4</ref> shows a scenario and the written segmented paragraph. Similar to LANI, CHAI data can be used for studying com- plete paragraphs and single instructions. <ref type="table" target="#tab_1">Table 1</ref> shows the corpus statistics. <ref type="bibr">6</ref> The para- graphs are split into train, test, and development, with a 70% / 15% / 15% split. <ref type="table" target="#tab_2">Table 2</ref> shows qual- itative analysis of a sample of 200 instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Setup</head><p>Method Adaptations for CHAI We apply two modifications to our model to support interme- diate goal for the CHAI instructions. First, we train an additional RNN to predict the se- quence of intermediate goals given the instruc- tion only.</p><p>There are two types of goals: NAVIGATION, for action sequences requiring movement only and ending with the STOP action; and INTERACTION, for sequence of movement ac- tions that end with an INTERACT action. For ex- ample, for the instruction pick up the red book and go to the kitchen, the sequence of goals will be hINTERACTION, NAVIGATION, NAVIGATIONi. This indicates the agent must first move to the object to pick it up via interaction, move to the kitchen door, and finally move within the kitchen. The process of executing an instruction starts with predicting the sequence of goal types. We call our model (Section 4) separately for each goal type. The execution concludes when the final goal is completed. For learning, we create a separate ex- ample for each intermediate goal and train the ad- ditional RNN separately. The second modification is replacing the backward camera projection for inferring the goal location with ray casting to iden-   Evaluation Metrics We evaluate using the met- rics described in Section 6: stop distance (SD) and task completion (TC) for LANI, and stop distance (SD) and manipulation accuracy (MA) for CHAI. To evaluate the goal prediction, we report the real distance of the predicted goal from the annotated goal and the percentage of correct predictions. We consider a goal correct if it is within a distance of 5.0 for LANI and 1.0 for CHAI. We also report human evaluation for LANI by asking raters if the generated path follows the instruction on a Likert- type scale of 1-5. Raters were shown the gener- ated path, the reference path, and the instruction. Parameters We use a horizon of 40 for both domains. During training, we allow additional 5 steps to encourage learning even after errors. When using intermediate goals in CHAI, the hori- zon is used for each intermediate goal separately. All other parameters and detailed in Appendix D. <ref type="table" target="#tab_6">Tables 3 and 4</ref> show development and test re- sults.   the challenges of both tasks, and shows the tasks are robust to simple biases. On LANI, our ap- proach outperforms CHAPLOT18, improving task completion (TC) accuracy by 5%, and both meth- ods outperform MISRA17. On CHAI, CHAP- LOT18 and MISRA17 both fail to learn, while our approach shows an improvement on stop dis- tance (SD). However, all models perform poorly on CHAI, especially on manipulation (MA). To isolate navigation performance on CHAI, we limit our train and test data to instructions that in- clude navigation actions only. The STOP baseline on these instructions gives a stop distance (SD) of 3.91, higher than the average for the entire data as these instructions require more movement. Our approach gives a stop distance (SD) of 3.24, a 17% reduction of error, significantly better than the 8% reduction of error over the entire corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Results</head><p>We also measure human performance on a sam- ple of 100 development examples for both tasks. On LANI, we observe a stop distance error (SD) of 5.2 and successful task completion (TC) 63% of the time. On CHAI, the human distance er- ror (SD) is 1.34 and the manipulation accuracy is 100%. The imperfect performance demonstrates the inherent ambiguity of the tasks. The gap to human performance is still large though, demon- strating that both tasks are largely open problems.</p><p>The imperfect human performance raises ques- tions about automated evaluation. In general, we observe that often measuring execution qual- ity with rigid goals is insufficient. We conduct a human evaluation with 50 development exam- ples from LANI rating human performance and our approach. <ref type="figure" target="#fig_15">Figure 5</ref> shows a histogram of the ratings. The mean rating for human followers is 4.38, while our approach's is 3.78; we observe a similar trend to before with this metric. Using  <ref type="table">Table 6</ref>: Mean goal prediction error for LANI instruc- tions with and without the analysis categories we used in <ref type="table" target="#tab_2">Table 2</ref>. The p-values are from two-sided t-tests comparing the means in each row. judgements on our approach, we correlate the hu- man metric with the SD measure. We observe a Pearson correlation -0.65 (p=5e-7), indicating that our automated metric correlates well with human judgment. <ref type="bibr">7</ref> This initial study suggests that our au- tomated evaluation is appropriate for this task.</p><p>Our ablations <ref type="table">(Table 3</ref>) demonstrate the impor- tance of each of the components of the model. We ablate the action generation RNN (w/o RNN), completely remove the language input (w/o Lan- guage), and train the model jointly (w/joint Learn- ing). 8 On CHAI especially, ablations results in models that display ineffective behavior. Of the ablations, we observe the largest benefit from decomposing the learning and using supervised learning for the language problem.</p><p>We also evaluate our approach with access to oracle goals <ref type="table">(Table 3)</ref>. We observe this im- proves navigation performance significantly on both tasks. However, the model completely fails to learn a reasonable manipulation behavior for CHAI. This illustrates the planning complexity of this domain. A large part of the improvement in measured navigation behavior is likely due to eliminating much of the ambiguity the automated metric often fails to capture.</p><p>Finally, on goal prediction <ref type="table" target="#tab_7">(Table 5)</ref>, our ap- proach outperforms the method of <ref type="bibr" target="#b14">Janner et al. (2018)</ref>. <ref type="figure">Figure 6</ref> and Appendix <ref type="figure">Figure 7</ref> show ex- ample goal predictions. In <ref type="table">Table 6</ref>, we break down LANI goal prediction results for the analysis cate- <ref type="bibr">7</ref> We did not observe this kind of clear anti-correlation comparing the two results for human performance (Pearson correlation of 0.09 and p=0.52). The limited variance in hu- man performance makes correlation harder to test.</p><p>8 Appendix C provides the details of joint learning.</p><p>curve around big rock keeping it to your left .</p><p>walk over to the cabinets and open the cabinet doors up <ref type="figure">Figure 6</ref>: Goal prediction probability maps P g overlaid on the corresponding observed panoramas I P . The top example shows a result on LANI, the bottom on CHAI.</p><p>gories we used in <ref type="table" target="#tab_2">Table 2</ref> using the same sample of the data. Appendix E includes a similar table for CHAI. We observe that our approach finds instruc- tions with temporal coordination or co-reference challenging. Co-reference is an expected limita- tion; with single instructions, the model can not resolve references to previous instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Discussion</head><p>We propose a model for instruction following with explicit separation of goal prediction and action generation. Our representation of goal prediction is easily interpretable, while not requiring the de- sign of logical ontologies and symbolic represen- tations. A potential limitation of our approach is cascading errors. Action generation relies com- pletely on the predicted goal and is not exposed to the language otherwise. This also suggests a second related limitation: the model is unlikely to successfully reason about instructions that in- clude constraints on the execution itself. While the model may reach the final goal correctly, it is unlikely to account for the intermediate trajectory constraints. As we show <ref type="table" target="#tab_2">(Table 2)</ref>, such instruc- tions are common in our data. These two limita- tions may be addressed by allowing action genera- tion access to the instruction. Achieving this while retaining an interpretable goal representation that clearly determines the execution is an important direction for future work. Another important open question concerns automated evaluation, which re- mains especially challenging when instructions do not only specify goals, but also constraints on how to achieve them. Our resources provide the plat- form and data to conduct this research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example instructions from our two tasks: LANI (left) and CHAI (right). LANI is a landmark navigation task, and CHAI is a corpus of instructions in the CHALET environment.</figDesc><graphic url="image-1.png" coords="1,311.55,222.54,98.39,98.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>F</head><label></label><figDesc>gure 2 An us ra on for our arch ec ure (Sec on 4) for he ns ruc on urn e and go o he red o drum w h a L NGUNET dep h of m = 4 The ns ruc on ¯ x s mapped o ¯ x w h an RNN and he n a panorama observa on I P o F 0 w h a CNN L NGUNET genera es H 1 a v sua represen a on of he goa F rs a sequence of convo u ons maps he mage fea ures F 0 o fea ure maps F 1 F 4 The ex represen a on ¯ x s used o genera e he kerne s K 1 K 4 wh ch are convo ved o genera e he ex -cond oned fea ure maps G 1 G 4 These fea ure maps are de-convo ved o H 1 H 4 The goa probab y d s r bu on P g s compu ed from H 1 The goa oca on s he nferred from he max of P g G ven g and p t he pose a s ep t he goa mask M t s compu ed and passed n o an RNN ha ou pu s he ac on o execu e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>F 0 using L NGUNET The architecture of L NGUNET is inspired by the U-NET image generation method (Ronneberger et al 2015) ex- cept that the reconstruction phase is conditioned on the natural language instruction L NGUNET first applies m convolutional layers to generate a sequence of feature maps F j = CNN j (F j1 ) We gene a e F p by c ea ng a channe o each de e m n s c obse va on used o c ea e he pano ama and se ng a he p xe s co espond ng o ha obse va on oca on n he pano ama o 1 and a o he s o 0 The numbe o obse va ons depends on he agen s came a ang e j = 1 . . . m where each CNN j is a convolutional layer with leaky ReLU non-linearities (Maas et al 2013) and instance normalization (Ulyanov et al 2016)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>g</head><label></label><figDesc>is the goal state. We train the goal prediction component by minimizing the cross-entropy of the predicted dis- tribution with the gold-standard goal distribution. The gold-standard goal distribution is a determin- istic distribution with probability one at the pixel corresponding to the goal location if the goal is in the field of view, or probability one at the extra out-of-sight position otherwise. The gold location is the agent's location in s (i)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>[</head><label></label><figDesc>Go around the pillar on the right hand side] [and head towards the boat, circling around it clockwise.] [When you are facing the tree, walk towards it, and the pass on the right hand side,] [and the left hand side of the cone. Circle around the cone,] [and then walk past the hydrant on your right,] [and the the tree stump.] [Circle around the stump and then stop right behind it.]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Segmented instructions in the LANI domain. The original reference path is marked in red (start) and blue (end). The agent, using a drone icon, is placed at the beginning of the path. The follower path is coded in colors to align to the segmented instruction paragraph.</figDesc><graphic url="image-10.png" coords="6,323.53,235.26,185.70,104.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Scenario and segmented instruction from the CHAI corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>3 :</head><label>3</label><figDesc>Performance on the development data. tify INTERACTION goals, which are often objects that are not located on the ground. Baselines We compare our approach against the following baselines: (a) STOP: Agent stops im- mediately; (b) RANDOMWALK: Agent samples actions uniformly until it exhausts the horizon or stops; (c) MOSTFREQUENT: Agent takes the most frequent action in the data, FORWARD for both datasets, until it exhausts the horizon; (d) MISRA17: the approach of Misra et al. (2017); and (e) CHAPLOT18: the approach of Chaplot et al. (2018). We also evaluate goal prediction and compare to the method of Janner et al. (2018) and a CENTER baseline, which always predict the cen- ter pixel. Appendix C provides baseline details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Likert rating histogram for expert human follower and our approach for LANI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 : Summary statistics of the two corpora.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Qualitative analysis of the LANI and CHAI corpora. We sample 200 single development instructions from 
each corpora. For each category, we count how many examples of the 200 contained it and show an example. 

Scenario 
You have several hours before guests begin to arrive for 
a dinner party. You are preparing a wide variety of meat 
dishes, and need to put them in the sink. In addition, 
you want to remove things in the kitchen, and bathroom 
which you don't want your guests seeing, like the soaps 
in the bathroom, and the dish cleaning items. You can 
put these in the cupboards. Finally, put the dirty dishes 
around the house in the dishwasher and close it. 
Written Instructions 
[In the kitchen, open the cupboard above the sink.] [Put 
the cereal, the sponge, and the dishwashing soap into the 
cupboard above the sink.] [Close the cupboard.] [Pick 
up the meats and put them into the sink.] [Open the dish-
washer, grab the dirty dishes on the counter, and put the 
dishes into the dishwasher.] 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Performance on the held-out test dataset. 

LANI 
CHAI 
Method 
Dist 
Acc 
Dist Acc 
CENTER 
12.0 19.51 3.41 19.0 
Janner et al. (2018) 9.61 30.26 2.81 28.3 
Our Approach 
8.67 35.83 2.12 40.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Development goal prediction performance. 
We measure distance (Dist) and accuracy (Acc). 

</table></figure>

			<note place="foot" n="1"> The panorama is a concatenation of deterministic observations along the width dimension. For simplicity, we do not include these deterministic steps in the execution.</note>

			<note place="foot" n="4"> Appendix A provides statistics for related datasets.</note>

			<note place="foot" n="6"> The number of actions per instruction is given in the more fine-grained action space used during collection. To make the required number of actions smaller, we use the more coarse action space specified.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by NSF (CRII-1656998), Schmidt Sciences, and cloud com-puting credits from Microsoft. We thank John Langford, Claudia Yan, Bharath Hariharan, Noah Snavely, the Cornell NLP group, and the anony-mous reviewers for their advice.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v Y 1 N x R x 3 v O U w S B j h i B o S g e 7 W 0 M Y = " &gt; A A A C K H i c b V B N S 8 N A F N z 4 W e N X 1 a O X x S B 4 K o k I e i x 4 0 K O C r Y U m l M 3 m R R d 3 N 2 F 3 o 5 S Q v + F V z / 4 a b 9 K r v 8 R N m 4 O 2 D i w M M + / t G y b O O d P G 9 y f O 0 v L K 6 t p 6 a 8 P d 3 N r e 2 W 3 v 7 f d 1 V i g K P Z r x T A 1 i o o E z C T 3 D D I d B r o C I m M N 9 / H R Z + / f P o D T L 5 J 0 Z 5 x A J 8 i B Z y i g x V g p D Q c x j n J Z X 1 e h s 1 P b 8 j j 8 F X i R B Q z z U 4 G a 0 5 6 y F S U Y L A d J Q T r Q e B n 5 u o p I o w y i H y g 0 L D T m h T + Q B h p Z K I k B H 5 T R 0 h Y + t k u A 0 U / Z J g 6 f q 7 4 2 S C K 3 H I r a T d U g 9 7 9 X i v 1 6 i 6 w / n r p v 0 I i q Z z A s D k s 6 O p w X H J s N 1 K z h h C q j h Y 0 s I V c z m x / S R K E K N 7 c 5 1 Q w U S X m g m B J F J G d J q G E R l G S q B v a C q X N t c M N / T I u m f d g K / E 9 y e e V 2 / 6 b C F D t E R O k E B O k d d d I 1 u U A 9 R l K N X 9 I b e n Q / n 0 / l y J r P R J a f Z O U B / 4 H z / A P F / p X M = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v Y 1 N x R x 3 v O U w S B j h i B o S g e 7 W 0 M Y = " &gt; A A A C K H i c b V B N S 8 N A F N z 4 W e N X 1 a O X x S B 4 K o k I e i x 4 0 K O C r Y U m l M 3 m R R d 3 N 2 F 3 o 5 S Q v + F V z / 4 a b 9 K r v 8 R N m 4 O 2 D i w M M + / t G y b O O d P G 9 y f O 0 v L K 6 t p 6 a 8 P d 3 N r e 2 W 3 v 7 f d 1 V i g K P Z r x T A 1 i o o E z C T 3 D D I d B r o C I m M N 9 / H R Z + / f P o D T L 5 J 0 Z 5 x A J 8 i B Z y i g x V g p D Q c x j n J Z X 1 e h s 1 P b 8 j j 8 F X i R B Q z z U 4 G a 0 5 6 y F S U Y L A d J Q T r Q e B n 5 u o p I o w y i H y g 0 L D T m h T + Q B h p Z K I k B H 5 T R 0 h Y + t k u A 0 U / Z J g 6 f q 7 4 2 S C K 3 H I r a T d U g 9 7 9 X i v 1 6 i 6 w / n r p v 0 I i q Z z A s D k s 6 O p w X H J s N 1 K z h h C q j h Y 0 s I V c z m x / S R K E K N 7 c 5 1 Q w U S X m g m B J F J G d J q G E R l G S q B v a C q X N t c M N / T I u m f d g K / E 9 y e e V 2 / 6 b C F D t E R O k E B O k d d d I 1 u U A 9 R l K N X 9 I b e n Q / n 0 / l y J r P R J a f Z O U B / 4 H z / A P F / p X M = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v Y 1 N x R x 3 v O U w S B j h i B o S g e 7 W 0 M Y = " &gt; A A A C K H i c b V B N S 8 N A F N z 4 W e N X 1 a O X x S B 4 K o k I e i x 4 0 K O C r Y U m l M 3 m R R d 3 N 2 F 3 o 5 S Q v + F V z / 4 a b 9 K r v 8 R N m 4 O 2 D i w M M + / t G y b O O d P G 9 y f O 0 v L K 6 t p 6 a 8 P d 3 N r e 2 W 3 v 7 f d 1 V i g K P Z r x T A 1 i o o E z C T 3 D D I d B r o C I m M N 9 / H R Z + / f P o D T L 5 J 0 Z 5 x A J 8 i B Z y i g x V g p D Q c x j n J Z X 1 e h s 1 P b 8 j j 8 F X i R B Q z z U 4 G a 0 5 6 y F S U Y L A d J Q T r Q e B n 5 u o p I o w y i H y g 0 L D T m h T + Q B h p Z K I k B H 5 T R 0 h Y + t k u A 0 U / Z J g 6 f q 7 4 2 S C K 3 H I r a T d U g 9 7 9 X i v 1 6 i 6 w / n r p v 0 I i q Z z A s D k s 6 O p w X H J s N 1 K z h h C q j h Y 0 s I V c z m x / S R K E K N 7 c 5 1 Q w U S X m g m</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>t p 6 a 8 P d 3 N r e 2 W 3 v 7 f d 1 V i g K P Z r x T A 1 i o o E z C T 3 D D I d B r o C I m M N 9 / H R Z + / f P o D T L 5 J 0 Z 5 x A J 8 i B Z y i g x V g p D Q c x j n J Z X 1 e h s 1 P b 8 j j 8 F X i R B Q z z U 4 G a 0 5 6 y F S U Y L A d J Q T r Q e B n 5 u o p I o w y i H y g 0 L D T m h T + Q B h p Z K I k B H 5 T R 0 h Y + t k u A 0 U / Z J g 6 f q 7 4 2 S C K 3 H I r a T d U g 9 7 9 X i v 1 6 i 6 w / n r p v 0 I i q Z z A s D k s 6 O p w X H J s N 1 K z h h C q j h Y 0 s I V c z m x / S R K E K N 7 c 5 1 Q w U S X m g m</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>h y 1 0 g A 7 R M S L o D F 2 g a 3 S D u o i h H L 2 g V / T m v X s f 3 q c 3 m Y 0 2 v P n O P v o F 7 + s b 7 F S l c A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " a i 7 / g 5 L 8 U P D b t a X / L T 5 9 o J d W T v 4 = " &gt; A A A C K H i c b V B N S w M x F M x W r X X 9 1 q O X Y B E 8 l Y 0 I e h Q 8 6 F H B V q G 7 l G z 2 r Q 1 N s k u S V c q y f 8 O r n v 0 1 3 q R X f 4 n Z t g e t D g S G m f f y h o l z w Y 0 N g o n X W F p e a a 6 2 1 v z 1 j c 2 t 7 Z 3 d v Z 7 J C s 2 g y z K R 6 Y e Y G h B c Q d d y K + A h 1 0 B l L O A + H l 3 W / v 0 T a M M z d W f H O U S S P i q e c k a t k 8 J Q U j u M 0 / K q G p D B T j v o B F P g v 4 T M S R v N c T P Y 9 Z p h k r F C g r J M U G P 6 J M h t V F J t O R N Q + W F h I K d s R B + h 7 6 i i E k x U T k N X + M g p C U 4 z 7 Z 6 y e K r + 3 C i p N G Y s Y z d Z h z S L X i 3 + 6 y W m / n D h u k 3 P o 5 K r v L C g 2 O x 4 W g h s M 1 y 3 g h O u g V k x d o Q y z V 1 + z I Z U U 2 Z d d 7 4 f a l D w z D I p q U r K k F V 9 E p V l q C V u k 6 r y X X N k s a e / p H f S I U G H 3 J 6 2 L 4 J 5 h y 1 0 g A 7 R M S L o D F 2 g a 3 S D u o i h H L 2 g V / T m v X s f 3 q c 3 m Y 0 2 v P n O P v o F 7 + s b 7 F S l c A = = &lt; / l a t e x i t &gt; H 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b K 6 S y s y o 0 z W n L 8 d t S f O h y h h e d f I = " &gt; A A A C K H i c b V B N S w M x F M z 6 7 f r V 6 t F L s A i e y k Y E P R a 8 9 F j B t k J 3 K d n s W w 0 m 2 S X J K m X Z v + F V z / 4 a b + L V X 2 K 2 7 U F b B w L D z H t 5 w 8 S 5 4 M Y G w Z e 3 s r q 2 v r G 5 t e 3 v 7 O 7 t H z S a h w O T F Z p B n 2 U i 0 3 c x N S C 4 g r 7 l V s B d r o H K W M A w f r y u / e E T a M M z d W s n O U S S 3 i u e c k a t k 8 J Q U v s Q p 2 W 3 G p N x o x W 0 g y n w M i F z 0 k J z 9 M Z N b y N M M l Z I U J Y J a s y I B L m N S q o t Z w I q P y w M 5 J Q 9 0 n s Y O a q o B B O V 0 9 A V P n V K g t N M u 6 c s n q q / N 0 o q j Z n I 2 E 3 W I c 2 i V 4 v / e o m p P 1 y 4 b t O r q O Q q L y w o N j u e F g L b D N e t 4 I R r Y F Z M H K F M c 5 c f s w e q K b O u O 9 8 P N S h 4 Z p m U V C V l y K o R i c o y 1 B K 3 S F X 5 r j m y 2 N M y G Z y 3 S d A m N x e t T j D v c A s d o x N 0 h g i 6 R B 3 U R T 3 U R w z l 6 A W 9 o j f v 3 f v w P r 2 v 2 e i K N 9 8 5 Q n / g f f 8 A 7 h C l c Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b K 6 S y s y o 0 z W n L 8 d t S f O h y h h e d f I = " &gt; A A A C K H i c b V B N S w M x F M z 6 7 f r V 6 t F L s A i e y k Y E P R a 8 9 F j B t k J 3 K d n s W w 0 m 2 S X J K m X Z v + F V z / 4 a b + L V X 2 K 2 7 U F b B w L D z H t 5 w 8 S 5 4 M Y G w Z e 3 s r q 2 v r G 5 t e 3 v 7 O 7 t H z S a h w O T F Z p B n 2 U i 0 3 c x N S C 4 g r 7 l</head><p>Goa Locat on g</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Anne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><forename type="middle">Gurman</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Bard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gwyneth</forename><surname>Boyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Garrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacqueline</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kowtko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcallister</surname></persName>
		</author>
		<title level="m">The HCRC map task corpus. Language and Speech</title>
		<meeting><address><addrLine>Jim Miller, Catherine Sotillo, Henry S. Thompson, and Regina Weinert</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visionand-language navigation: Interpreting visuallygrounded navigation instructions in real environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Teney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>Sünderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Van Den Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning compact lexicons for CCG semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Towards a dataset for human computer communication via grounded language acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Workshop on Symbiotic Cognitive Systems</title>
		<meeting>the AAAI Workshop on Symbiotic Cognitive Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Gatedattention architectures for task-oriented language grounding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devendra</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kanthashree</forename><forename type="middle">Mysore</forename><surname>Sathyendra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Kumar Pasumarthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeraj</forename><surname>Rajagopal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to interpret natural language navigation instructions from observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on Artificial Intelligence</title>
		<meeting>the National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Expanding the scope of the ATIS task: The ATIS-3 corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madeleine</forename><surname>Deborah A Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hunicke-Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Pallett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Pao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Rudnicky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shriberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on Human Language Technology</title>
		<meeting>the workshop on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Embodied question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samyak</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Speaker-follower models for vision-and-language navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronghang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volkan</forename><surname>Cirik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno>abs/1806.02724</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Iqa: Visual question answering in interactive environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The ATIS spoken language systems pilot corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">T</forename><surname>Hemphill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">J</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">R</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the DARPA speech and natural language workshop</title>
		<meeting>the DARPA speech and natural language workshop</meeting>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Chris Apps, Demis Hassabis, and Phil Blunsom</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fumin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Faulkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Szepesvari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Teplyashin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Wainwright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Grounded language learning in a simulated 3D world. CoRR, abs/1706.06551</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Representation learning for grounded spatial reasoning. Transactions of the Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Janner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Referitgame: Referring to objects in photographs of natural scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahar</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Matten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised PCFG induction for grounded language learning with highly ambiguous supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joohyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Where is misty? interpreting spatial descriptors by modeling regions in space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Kitaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">What are you talking about? text-to-image coreference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Raquel Urtasun, and Sanja Fidler</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Jointly learning to parse and perceive: Connecting natural language to the physical world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kollar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew L Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Awni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on machine learning</title>
		<meeting>the international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Grounding english commands to reward functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Macglashan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Babes-Vroman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Arumugam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Walk the talk: Connecting language, knowledge, action in route instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Macmahon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Stankiewics</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Kuipers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on Artificial Intelligence</title>
		<meeting>the National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generation and Comprehension of Unambiguous Object Descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhua</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oana</forename><surname>Camburu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A joint model of language and perception for grounded attribute learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liefeng</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to parse natural language commands to a robot control system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Experimental Robotics</title>
		<meeting>the International Symposium on Experimental Robotics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">What to talk about and how? selective generation using lstms with coarse-to-fine alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Matthew</forename><surname>Walter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mapping instructions and visual observations to actions with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipendra</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Tell me dave: Contextsensitive grounding of natural language to manipulation instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dipendra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaeyong</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Environment-driven lexicon induction for high-level instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kejia</forename><surname>Kumar Dipendra Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Playing atari with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">A</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on machine learning</title>
		<meeting>the international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Policy invariance under reward transformations: Theory and application to reward shaping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daishi</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Zero-shot task generalization with multi-task deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhyuk</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Satinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on machine learning</title>
		<meeting>the international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Reinforcement learning of motor skills with policy gradients. Neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schaal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Hogwild: A lock-free approach to parallelizing stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Conference on Medical image computing and computerassisted intervention</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Highdimensional continuous control using generalized advantage estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno>abs/1506.02438</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Situated mapping of sequential instructions to actions with single-step reward observation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alane</forename><surname>Suhr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Intra-option learning about temporally abstract actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satinder</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on machine learning</title>
		<meeting>the international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Instance normalization: The missing ingredient for fast stylization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">S</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno>abs/1607.08022</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Scheduled policy optimization for natural language communication with intelligent agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conferences on Artificial Intelligence</title>
		<meeting>the International Joint Conferences on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Chalet: Cornell house agent learning environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipendra</forename><forename type="middle">Kumar</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Walsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<idno>abs/1801.07357</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Modeling context in referring expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Licheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Poirson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
