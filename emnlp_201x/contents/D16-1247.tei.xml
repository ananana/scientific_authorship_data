<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Insertion Position Selection Model for Flexible Non-Terminals in Dependency Tree-to-Tree Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
							<email>nakazawa@pa.jst.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Japan Science and Technology Agency</orgName>
								<address>
									<addrLine>5-3, Chiyoda-ku</addrLine>
									<postCode>102-8666</postCode>
									<settlement>Yonbancho, Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Richardson</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<addrLine>Yoshida-honmachi, Sakyo-ku</addrLine>
									<postCode>606-8501</postCode>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<addrLine>Yoshida-honmachi, Sakyo-ku</addrLine>
									<postCode>606-8501</postCode>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Insertion Position Selection Model for Flexible Non-Terminals in Dependency Tree-to-Tree Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2271" to="2277"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Dependency tree-to-tree translation models are powerful because they can naturally handle long range reorderings which is important for distant language pairs. The translation process is easy if it can be accomplished only by replacing non-terminals in translation rules with other rules. However it is sometimes necessary to adjoin translation rules. Flexible non-terminals have been proposed as a promising solution for this problem. A flexible non-terminal provides several insertion position candidates for the rules to be adjoined , but it increases the computational cost of decoding. In this paper we propose a neu-ral network based insertion position selection model to reduce the computational cost by selecting the appropriate insertion positions. The experimental results show the proposed model can select the appropriate insertion position with a high accuracy. It reduces the decoding time and improves the translation quality owing to reduced search space.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Tree-to-tree machine translation models currently receive limited attention. However, we believe that using target-side syntax is important to achieve high- quality translations between distant language pairs which require long range reorderings. Especially, using dependency trees on both source and tar- get sides is promising for this purpose <ref type="bibr" target="#b11">(Menezes and Quirk, 2007;</ref><ref type="bibr" target="#b13">Nakazawa and Kurohashi, 2010;</ref><ref type="bibr" target="#b16">Richardson et al., 2014</ref>). Tree-based translation models naturally realize word reorderings using the non-terminals or anchors for the attachment in the translation rules: therefore they do not need a re- ordering model which string-based models require. For example, suppose we have a translation rule with the word alignment shown in <ref type="figure" target="#fig_0">Figure 1</ref>, it is easy to translate a new input sentence which has " (library)" instead of " (park)" because we can accomplish it by simply substituting "library" for the target word "park" without considering the reorder- ing. In this case, the source word "" and target word "park" work as the non-terminals.</p><p>On the other hand, it is problematic when we need to adjoin a subtree which is not presented in train- ing sentences, which we call floating subtree in this paper. The floating subtrees are not necessarily ad- juncts, but any words or phrases. For example, sup- pose the Japanese input sentence in <ref type="figure" target="#fig_0">Figure 1</ref> has " (suddenly)", but the training corpus provides only a translation rule without the word. In this case we cannot directly use the rule for the translation be- cause it does not know where to insert the translation of the floating word in the output. As another exam- ple, there is no context information available for the children of the OOV word in the input sentence, so we need some special process to translate them.</p><p>Previous work deals with this problem by us- ing glue rules <ref type="bibr" target="#b1">(Chiang, 2005</ref>) or limiting the de- pendency structures to be well-formed <ref type="bibr" target="#b19">(Shen et al., 2008)</ref>. <ref type="bibr" target="#b17">Richardson et al. (2016)</ref> introduces the con- cept of flexible non-terminals. It provides multiple possible insertion positions for the floating subtree rather than fixed insertion positions. A possible in- sertion position must satisfy the following condi- tions:</p><p>• it must be a child of the aligned word of the parent of the floating subtree</p><p>• it must not violate the projectivity of the depen- dency tree</p><p>For example, possible insertion positions for the floating word "" are shown in gray arrows in <ref type="figure" target="#fig_0">Figure 1</ref>. Since "" is a child of "", and the translation of "" is "called", insertion positions must be a child of "called". Also, insertion positions do not violate the projectivity of the tar- get tree. Flexible non-terminals are analogous to the auxiliary tree of the tree adjoining grammars (TAG) <ref type="bibr" target="#b6">(Joshi, 1985)</ref>, which is successfully adopted in ma- chine translation <ref type="bibr" target="#b4">(DeNeefe and Knight, 2009)</ref>. The difference is that TAG is defined on the constituency trees rather than the dependency trees. Flexible non-terminals are powerful to handle floating subtrees and it achieve better translation quality. However the computational cost of decod- ing becomes high even though they are compactly represented in the lattice form <ref type="bibr" target="#b3">(Cromieres and Kurohashi, 2014</ref>). In our experiments, using flexible non- terminals causes the decoding to be 3 to 6 times slower than when they are not used. Flexible non- terminals increase the number of translation rules because the insertion positions are selected during the decoding. However, we think it is possible to re- strict possible insertion positions or even select only one insertion position by looking at the tree struc- tures on both sides.</p><p>In this paper, we propose a method to select the appropriate insertion position before decoding. This can not only reduce the decoding time but also improve the translation quality because of reduced search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Insertion Position Selection</head><p>We assume that correct insertion positions can be determined before decoding, using the word to be inserted (I) with the context on the source side and the context of the insertion positions on the target side. On the source side, we use the parent of I (P s ) and the distance of I from P s (D s ). On the target side, we use the previous (S p ) and next (S n ) sibling of the insertion position, the parent of the insertion position (P t ) and the distance of the insertion posi- tion from P t (D t ). The distances are calculated on the siblings rather than the words in the sentence, and it is a positive or negative value if the insertion  position is to the left or to the right of the parent re- spectively.</p><p>Taking the insertion position between "park" and "yesterday" in <ref type="figure" target="#fig_0">Figure 1</ref> as an example, I = "", P s = "", D s = +2, S p = "park", S n = "yes- terday", P t = "called" and D t = -3. In cases where S p or S n is empty, we use special words "</p><formula xml:id="formula_0">[[LEFT- START]]", "[[LEFT-END]]", "[[RIGHT-START]]" and "[[RIGHT-END]]</formula><p>". In the case of "yesterday" in <ref type="figure" target="#fig_0">Figure 1</ref>, S p = "in" and S n = "[[RIGHT-END]]". These clues are fed into the neural network model to solve the insertion position selection problem. <ref type="figure" target="#fig_2">Figure 2</ref> shows the neural network model for the in- sertion position selection. Given an insertion posi- tion candidate with an index k, the words (I, P s , S k p , S k n , P t ) are first converted into vector represen- tations through the same three embedding layers: surface form embedding (200 dimensions.), part- of-speech embedding (10 dimensions) and depen- dency type (or phrase category) embedding (10 di- mensions), and they are concatenated to create the 220-dimension vectors. The word embedding is a randomly initialized transformation from an one-hot vector to a 200 or 10-dimensional vector, and it is learned during the whole network training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Neural Network Model</head><p>Using these words and the distances, we create source and target context vectors c k s and c k t which represent the information of source and target sides, respectively. The distances (integer values) are di- rectly inputted to the network. Then the context vec-   tor of the given insertion position c k i is created using c k s and c k t . Finally we get the score of the given in- sertion position s k from c k i . These vectors are calcu- lated as follows:</p><formula xml:id="formula_1">c k s = tanh(W cs [I; P s ; D s ]) c k t = tanh(W ct [S p ; S n ; P t ; D k t ]) c k i = tanh(W c i [c k s ; c k t ]) s k = W s c k i</formula><p>where ";" means concatenation of the vectors. The size of c k s , c k t and c k i is 100 in our experiments. The same network is applied to all the other in- sertion positions and get their scores. Finally the scores are normalized by the softmax function, and the loss is calculated by the softmax cross-entropy as the loss function. All the links between layers are fully-connected. We use dropout (50%) to avoid overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training Data Generation</head><p>The data for training the neural network model can be automatically generated from the word-aligned parallel corpus with dependency parses in both sides by Algorithm 1. The ALIGNMENT function returns the aligned word in the target tree for the given source word 1 , and the ISPARENTCHILD function re- turns TRUE if P t is the parent of C t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Training Data Generation for NN</head><p>for all Ps ∈ words in source tree do Pt = ALIGNMENT(Ps) for all Cs ∈ CHILDREN(Ps) do Ct = ALIGNMENT(Cs) if ISPARENTCHILD(Pt, Ct) then GENERATEDATA(Ps, The GENERATEDATA function generates one in- stance of training data to predict the position of C t from P s , C s and P t with their contexts by removing C t in the target tree. The position where C t exists is regarded as the correct insertion position, and others as incorrect insertion positions. Note that C s corre- sponds to I in <ref type="figure" target="#fig_2">Figure 2</ref>.</p><note type="other">Cs, Pt, Ct) end if end for end for Ja ↔ En Ja ↔ Zh Training 2,020,106 667,520 Development 1,789 2,115 Test 1,812 2,174</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Insertion Position Selection in Translation</head><p>Once the neural network model is trained, it can be applied to select the most appropriate insertion po- sitions in the translation rules for the given float- ing subtree by looking at the score of each inser- tion position. Translation rules only contain part of the original parallel sentence in most of the cases. This means that the context used for selecting the in- sertion position is different from that in the training data for the neural network. For example, if the in- put sentence does not have " (in the park)" in <ref type="figure" target="#fig_0">Figure 1</ref>, the number of possible insertion positions is 6 and we do not use "in" as the context. How- ever, this is not so problematic because similar or same context may appear in the different part of the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We conducted two kinds of experiments: the in- sertion position selection and translation. We used ASPEC (  as the dataset and the numbers of the sentences of the corpus are shown in <ref type="table" target="#tab_2">Table 1</ref>. The Japanese morphological ana- lyzer (  and dependency parser (  are used for Japanese Ja → En En → Ja Ja → Zh Zh → Ja  sentences. English sentences are first parsed by nl- parser <ref type="bibr" target="#b0">(Charniak and Johnson, 2005</ref>) and then con- verted into word dependency trees using Collins' head percolation table <ref type="bibr" target="#b2">(Collins, 1999)</ref>. We used Chi- nese word segmenter <ref type="bibr">KKN (Shen et al., 2014</ref>) and dependency parser SKP ( <ref type="bibr" target="#b20">Shen et al., 2012</ref>) for Chi- nese sentences. The supervised word alignment Nile ( <ref type="bibr" target="#b18">Riesa et al., 2011</ref>) was used.</p><p>We used a state-of-the-art dependency tree-to-tree decoder ( <ref type="bibr" target="#b16">Richardson et al., 2014</ref>) with the default settings. The neural network is constructed and trained using the Chainer ( <ref type="bibr" target="#b22">Tokui et al., 2015</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Insertion Position Selection</head><p>The training, development and test data for the neu- ral network is automatically generated by the proce- dure explained in Section 2.2. The size of the gen- erated data from the ASPEC and the average num- ber of insertion positions for each floating subtree are shown in <ref type="table" target="#tab_4">Table 2</ref>. We trained the model for 100 epochs and used the best model on the development data for testing. The vocabulary size for the surface form was 50,000.</p><p>For comparison, we also tried the logistic regres- sion to predict the correct insertion positions. Be- cause our training data is huge, we used Multi-core LIBLINEAR 2 with L2-regularized logistic regres- sion (primal) solver. The format of training in- stances are: one-hot (binary) vectors for surface form, POS and dependency type, and distances scaled to <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. We first find the best value for the C parameter, then train the model. The best insertion position is selected using the estimated probabilities for each insertion position.</p><p>The experimental results are also shown in <ref type="table" target="#tab_4">Table 2</ref>. We evaluated the results by the mean loss of the model and the accuracy on the test data. The re- sult shows that our model can select the correct in- sertion position with very high accuracy for every language pair while the classical logistic regression model cannot. This supports our claim stated in the beginning of Section 2. X → Ja is easier and achieved slightly better ac- curacy than the reverse direction because Japanese is a head-final language and all children are gener- ally put on the left of their parents. There are some cases judged as incorrect but acceptable insertion positions, and hence the true accuracies are higher than the ones reported above. We also investigated the top-2 accuracy and found that it is above 99.0% for Ja → X and 99.5% for X → Ja. <ref type="table" target="#tab_6">Table 3</ref> shows the detailed result of Ja rightarrow En experiment.</p><p>The number of insertion-position is at least 2 (left/right of the parent) and it is easy to solve (more than 99% accuracy). 3 is a situation where the parent has one child, and it is still not so difficult (97-98% accuracy). About 70% of the test data have only 2 or 3 insertion-positions. Difficult cases are the sentences which have many adjuncts as in <ref type="figure" target="#fig_0">Figure 1</ref>, but we used the scientific paper corpora, where not so many adjuncts appear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Translation</head><p>We conducted translation experiment using the AS- PEC in 3 settings:</p><p>• No Flexible: not using the flexible non- terminals and using simple glue rules as in the baseline model of ( <ref type="bibr">Richardson et al., 2016) 3</ref> • Baseline: using the flexible non-terminals without the insertion position selection</p><p>• Proposed: using only the most appropriate in- sertion position for the flexible non-terminals</p><p>We also report the translation quality of conven- tional models for comparison: phrase-based SMT (PBSMT) and hierarchical phrase-based SMT (Hi- ero). We used the default settings of Moses except -distortion-limit=20 for PBSMT.   2002) and RIBES ( <ref type="bibr" target="#b5">Isozaki et al., 2010</ref>) with the sig- nificance testing by bootstrap resampling <ref type="bibr" target="#b7">(Koehn, 2004)</ref>. RIBES is more sensitive to word order than BLEU, so we expect an improvement in RIBES. We also investigated relative decoding time compared to the No Flexible setting. Note that we used the word "decoding" for only exploring the search space, and it does not include constructing the search space (as the table lookup in Phrase-based SMT). Our whole translation process is:</p><p>1. translation rule extraction 2. insertion-position selection 3. decoding At the time of the second step, we have all the trans- lation rules applicable to the input sentence. The computation time for each step is 3 ≫ 1 ≫ 2 so we only focus on the time for step 3 in the experiments (the computation time for step 2 is negligibly small).</p><p>The results are shown in <ref type="table" target="#tab_7">Table 4</ref>. The Proposed method achieved significantly better automatic eval- uation scores than the Baseline for all the language pairs except the BLEU score of En → Ja direction. Also, the decoding time is reduced by about 60% relative to that of the Baseline.</p><p>Our tree-based model is better than the conven- tional models except C → J, where the accuracy of Chinese parsing for the input sentences has a bad ef- fect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper we have proposed a neural network based insertion position selection model to reduce the computational cost of the decoding for de- pendency tree-to-tree translation with flexible non- terminals. The model successfully finds the appro- priate insertion position from the candidates and it leads to faster translation speed and better transla- tion quality due to the reduced search space.</p><p>Currently, we use only words as the context but it seems promising to use subtrees as well. For ex- ample, using the information of the subtree "in the park" is more informative than using only "in" in <ref type="figure" target="#fig_0">Figure 1</ref>. This is especially important for Japanese as the target language because children of verbs are often case markers and they do not provide enough information when selecting the appropriate insertion position. It is possible to adopt existing models of creating vector representation of dependency sub- trees such as the model using recursive neural net- works ( <ref type="bibr" target="#b10">Liu et al., 2015)</ref> and convolutional neural networks ( <ref type="bibr" target="#b12">Mou et al., 2015</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of an input sentence and a translation rule. We want to insert " (suddenly)" which is not in the translation rule. The possible insertion positions in the target sentence are shown in gray arrows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>220</head><label>220</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The neural network for the insertion position selection. The numbers inside the boxes show the dimensions of the vectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>The number of sentences in ASPEC used in our exper-

iments. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc>The statistics of the data and results of the insertion position selection experiments.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Detailed Ja → En insertion position selection experimental result. 

Ja → En 
En → Ja 
Ja → Zh 
Zh → Ja 
BLEU RIBES Time BLEU RIBES Time BLEU RIBES Time BLEU RIBES Time 
PBSMT 
18.45 64.51 -27.48 68.37 -27.96 78.90 -34.65 77.25 -
Hiero 
18.72 65.11 -30.19 73.47 -27.71 80.91 -35.43 81.04 -
No Flexible 20.28 65.08 1.00 28.77 75.21 1.00 24.85 66.60 1.00 30.51 73.08 1.00 
Baseline 
21.61 69.82 6.28 30.57 76.13 3.30 28.79 78.11 5.16 34.32 77.82 5.28 
Proposed 22.07 † 70.49 † 2.25 30.50 76.69 † 1.27 29.83 † 79.73 † 2.21 34.71 † 79.25 † 1.89 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 : The results of the translation experiments. † means the Proposed method achieved significantly better score than the</head><label>4</label><figDesc></figDesc><table>Baseline (p &lt; 0.01). 

</table></figure>

			<note place="foot" n="1"> In case of the multiple word alignment, we only use the root word of them in both source and target sides.</note>

			<note place="foot" n="2"> https://www.csie.ntu.edu.tw/∼cjlin/libsvmtools/multicoreliblinear/</note>

			<note place="foot" n="3"> 52.5% of all the translation rules require glue rule, but it is applied to 22.6% of the rules actually used in the translation.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Coarse-tofine n-best parsing and maxent discriminative reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A hierarchical phrase-based model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Head-Driven Statistical Models for Natural Language Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Translation rules with right-hand side lattices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Cromieres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="577" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Synchronous tree adjoining machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Deneefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="727" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic evaluation of translation quality for distant language pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsutomu</forename><surname>Hirao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuhito</forename><surname>Sudoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajime</forename><surname>Tsukada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="944" to="952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tree adjoining grammars: How much context-sensitivity is required to provide reasonable structural descriptions?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Parsing: Psychological, Computational, and Theoretical Perspectives</title>
		<editor>D. R. Dowty, L. Karttunen, and A. M. Zwicky</editor>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1985" />
			<biblScope unit="page" from="206" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical significance tests for machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2004</title>
		<editor>Dekang Lin and Dekai Wu</editor>
		<meeting>EMNLP 2004<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="388" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A syntactic analysis method of long Japanese sentences based on the detection of conjunctive structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Nagao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="507" to="534" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improvements of Japanese morphological analyzer JUMAN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihisa</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Nagao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The International Workshop on Sharable Natural Language</title>
		<meeting>The International Workshop on Sharable Natural Language</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="22" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A dependency-based neural network for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Houfeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="285" to="290" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<title level="m">Proceedings of the Second Workshop on Statistical Machine Translation, chapter Using Dependency Order Templates to Improve Generality in Translation</title>
		<meeting>the Second Workshop on Statistical Machine Translation, chapter Using Dependency Order Templates to Improve Generality in Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Discriminative neural sentence modeling by tree-based convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2315" to="2325" />
		</imprint>
	</monogr>
	<note>Portugal, September. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fully syntactic ebmt system of kyoto team in ntcir-8</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th NTCIR Workshop Meeting on Evaluation of Information Access Technologies (NTCIR-8)</title>
		<meeting>the 8th NTCIR Workshop Meeting on Evaluation of Information Access Technologies (NTCIR-8)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ASPEC: Asian scientific paper excerpt corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Yaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyotaka</forename><surname>Uchimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitoshi</forename><surname>Isahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05" />
			<biblScope unit="page" from="2204" to="2208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Kyotoebmt: An example-based dependency-to-dependency translation framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Fabiencromì Eres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="79" to="84" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Flexible non-terminals for dependency tree-to-tree reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Cromierès</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Feature-rich language-independent syntax-based alignment for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Riesa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="497" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A new string-to-dependency machine translation algorithm with a target dependency language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph M</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A reranking approach for dependency parsing with variable-sized subtree features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 26th Pacific Asia Conference on Language Information and Computing</title>
		<meeting>26th Pacific Asia Conference on Language Information and Computing</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="308" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Chinese morphological analysis with character-level pos tagging (short paper)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL2014)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL2014)<address><addrLine>Baltimore, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Chainer: a next-generation open source framework for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiya</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenta</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shohei</forename><surname>Hido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Clayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Machine Learning Systems (LearningSys) in The Twenty-ninth Annual Conference on Neural Information Processing Systems (NIPS)</title>
		<meeting>Workshop on Machine Learning Systems (LearningSys) in The Twenty-ninth Annual Conference on Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
