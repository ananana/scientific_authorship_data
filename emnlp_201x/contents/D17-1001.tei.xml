<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Monolingual Phrase Alignment on Parse Forests</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><surname>Arase</surname></persName>
							<email>arase@ist.osaka-u.ac.jp, j-tsujii@aist.go.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Artificial Intelligence Research Center (AIRC)</orgName>
								<orgName type="institution">Osaka University</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">AIST</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junichi</forename><surname>Tsujii</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">NaCTeM</orgName>
								<orgName type="department" key="dep2">School of Computer Science</orgName>
								<orgName type="institution">University of Manchester</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Monolingual Phrase Alignment on Parse Forests</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1" to="11"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose an efficient method to conduct phrase alignment on parse forests for paraphrase detection. Unlike previous studies, our method identifies syntactic paraphrases under linguistically motivated grammar. In addition, it allows phrases to non-compositionally align to handle paraphrases with non-homographic phrase correspondences. A dataset that provides gold parse trees and their phrase alignments is created. The experimental results confirm that the proposed method conducts highly accurate phrase alignment compared to human performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Paraphrase detection is crucial in various applica- tions, which has been actively studied for years. Due to difficulties caused by the non-homographic nature of phrase correspondences, the units of cor- respondence in previous studies are defined as se- quences of words like in ( <ref type="bibr" target="#b33">Yao et al., 2013)</ref> and not syntactic phrases. On the other hand, syn- tactic structures are important in modeling sen- tences, e.g., their sentiments and semantic simi- larities ( <ref type="bibr" target="#b25">Socher et al., 2013;</ref><ref type="bibr" target="#b27">Tai et al., 2015)</ref>.</p><p>In this paper, we present an algorithm to align syntactic phrases in a paraphrased pair of sen- tences. We show that (1) the problem of identify- ing a legitimate set of syntactic paraphrases under linguistically motivated grammar is formalized, (2) dynamic programing a la CKY <ref type="bibr" target="#b8">(Cocke, 1969;</ref><ref type="bibr">Kasami, 1965;</ref><ref type="bibr" target="#b35">Younger, 1967</ref>) makes phrase alignment computationally feasible, (3) alignment quality of phrases can be improved using n-best parse forests instead of 1-best trees, and (4) non- compositional alignment allows non-homographic correspondences of phrases. Motivated by recent Source: Whenever I go to the ground floor for a smoke, I always come face to face with them. Target: Whenever I go down to smoke a cigarette, I come face to face with one of them. findings that syntax is important for phrase embed- ding ( <ref type="bibr" target="#b25">Socher et al., 2013</ref>) in which phrasal para- phrases allow semantic similarity to be replicated ( <ref type="bibr" target="#b31">Wieting et al., 2016</ref><ref type="bibr" target="#b30">Wieting et al., , 2015</ref>, we focus on the syn- tactic paraphrase alignment. <ref type="figure" target="#fig_0">Fig. 1</ref> shows a real example of phrase align- ments produced by our method. Alignment pro- ceeds in a bottom-up manner using the compo- sitional nature of phrase alignments. First, word alignments are given. Then, phrase alignments are recursively identified by supporting relations be- tween phrase pairs. Non-compositional alignment is triggered when the compositionality is violated, which is common in paraphrasing.</p><p>For systematic research on syntactic phrase alignment in paraphrases, we constructed a gold standard dataset of paraphrase sentences with phrase alignment (20, 678 phrases in 201 para- phrasal sentences). This dataset will be made pub- lic for future research on paraphrase alignment. The experiment results show that our method achieves 83.64% and 78.91% in recall and preci- sion in terms of alignment pairs, which are 92% and 89% of human performance, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Due to the large amount of sentence-level para- phrases collected <ref type="bibr" target="#b11">(Dolan et al., 2004;</ref><ref type="bibr" target="#b9">Cohn et al., 2008;</ref><ref type="bibr" target="#b14">Heilman and Smith, 2010;</ref><ref type="bibr" target="#b34">Yin and Schütze, 2015;</ref><ref type="bibr" target="#b1">Biran et al., 2016)</ref>, researchers can identify phrasal correspondences for natural language in- ferences ( <ref type="bibr" target="#b17">MacCartney et al., 2008;</ref><ref type="bibr" target="#b28">Thadani et al., 2012;</ref><ref type="bibr" target="#b33">Yao et al., 2013)</ref>. Current methods extend word alignments to phrases in accordance with the methods in statistical machine translation. How- ever, phrases are defined as a simple sequence of words, which do not conform to syntactic phrases. PPDB ( <ref type="bibr" target="#b13">Ganitkevitch et al., 2013</ref>) provides syntac- tic paraphrases similar to synchronous context free grammar (SCFG). As discussed below, SCFG cap- tures only a fraction of paraphrasing phenomenon.</p><p>In terms of our approach, parallel parsing is a relevant area. <ref type="bibr" target="#b24">Smith and Smith (2004)</ref> re- lated monolingual parses in different languages using word alignments, while <ref type="bibr" target="#b5">Burkett and Klein (2008)</ref> employed phrase alignments. Moreover, <ref type="bibr" target="#b10">Das and Smith (2009)</ref> proposed a model that gen- erates a paraphrase of a given sentence using quasi-synchronous dependency grammar <ref type="bibr" target="#b23">(Smith and Eisner, 2006</ref>). Since they used phrase align- ments simply as features, there is no guarantee that the output alignments are legitimate.</p><p>Synchronous rewriting in parallel parsing <ref type="bibr" target="#b15">(Kaeshammer, 2013;</ref><ref type="bibr">Maillette de Buy Wenniger and Sima'an, 2013</ref>) derives parse trees that conform to discontinuous word alignments. In contrast, our method respects parse trees derived by linguis- tically motivated grammar while handling non- monotonic phrase alignment.</p><p>The synchronous assumption in parallel parsing has been argued to be too rigid to handle parallel sentence pairs or even paraphrasal sentence pairs. <ref type="bibr" target="#b4">Burkett et al. (2010)</ref> proposed weakly synchro- nized parallel parsing to tackle this problem. Al- though this model increases the flexibility, the ob- tainable alignments are restricted to conform to in- version transduction grammar (ITG) <ref type="bibr" target="#b32">(Wu, 1997)</ref>. Similarly, <ref type="bibr" target="#b7">Choe and McClosky (2015)</ref> used de- pendency forests of paraphrasal sentence pairs and allowed disagreements to some extent. However, alignment quality was beyond their scope. <ref type="bibr" target="#b29">Weese et al. (2014)</ref> extracted SCFG from paraphrase cor- pora. They showed that parsing was only success- ful in 9.1% of paraphrases, confirming that a sig- nificant amount of transformations in paraphrases do not conform to compositionality or ITG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Explanation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>s, t</head><p>Source and target sentences τ Phrase in the parse tree τ R , τ ∅ τ R is a phrase of a root node; τ ∅ is a special phrase with the null span that exists in every parse tree φ Phrase aligned to τ ∅ ·, ·· Pair of entities; a pair itself can be regarded as an entity {·} Set of entities m(·)</p><p>Derive the mother node of a phrase l(·), r(·) Derive the left and right child nodes, respectively ds(·)</p><p>Derive descendants of a node in-</p><formula xml:id="formula_0">cluding self; τ ∈ ds(τ ) lca(·, ·)</formula><p>Derive the lowest common ancestor (LCA) of two phrases <ref type="table">Table 1</ref>: Notation summary</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Formulation of Phrase Alignment</head><p>In this study, we formalize the problem of legiti- mate phrase alignment. For simplicity, we discuss tree alignment instead of forests using <ref type="figure" target="#fig_2">Fig. 2</ref> as a running example. <ref type="table">Table 1</ref> describes the notation used in this pa- per. We call a paraphrased pair source sentence s and the other as target t. Superscripts of s and t represent the source and the target, respectively. Specifically, τ s , τ t is a pair of source and target phrases. We represent</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notation</head><formula xml:id="formula_1">f 1 /f 2 / · · · /f i (·) to abbre- viate f i (· · · f 2 (f 1 (·)) · · · )</formula><p>as an intuitive illustra- tion. It should be noted that the order of the func- tion symbols is reversed, e.g., l/r(τ ) (= r(l(τ ))) derives the right-child of the left-child node of τ , and l/ds(τ ) derives the left descendants of τ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Definition of a Legitimate Alignment</head><p>A possible parse tree alignment of s and t is represented as a set of aligned pairs of phrases {{τ s i , τ t i }. τ s i and τ t i are the source and the target phrases that constitute the i-th alignment, respec- tively. Either τ s i or τ t i can be τ ∅ when a phrase does not correspond to another sentence, which is called a null-alignment. Each phrase alignment can have support relations as:  </p><formula xml:id="formula_2">l/ds(τ s i ), l/ds(τ t i ), r/ds(τ s i ), r/ds(τ t i ) or l/ds(τ s i ), r/ds(τ t i ), r/ds(τ s i ), l/ds(τ t i )</formula><p>exists. Pre-terminal phrases are supported by the corresponding word alignments.</p><p>Support relations are denoted using ⇒ or</p><formula xml:id="formula_3">R = ⇒ that represent the order of support phrases. Specif- ically, l(τ s i ), l(τ t i ), r(τ s i ), r(τ t i ) ⇒ h i is straight while l(τ s i ), r(τ t i ), r(τ s i ), l(τ t i ) R = ⇒ h i is inverted. In Fig. 2, τ s m , τ t m , τ s n , τ t n ⇒ h i , where τ s m = l/ds(τ s i )</formula><p>and τ s n = r/ds(τ s i ). The number of all possible alignments in s and t, which is denoted as H, is exponential to the length. However, only its fraction constitutes le- gitimate parse tree alignments. For example, a subset in which the same phrase in s is aligned with multiple phrases in t, called competing align- ments, is not legitimate as a parse tree alignment. The relationships among phrases in parse trees im- pose constraints on a subset to provide legitimacy.</p><p>Given word alignments W that provide the ba- sis for the phrase alignment, its legitimate set W L ⊂ W should be 1-to-1 alignments. Start- ing with W L , a legitimate set of phrase alignments H L (⊂ H) with an accompanying set of support re- lations, ∆ L (⊂ ∆) is constructed. A legitimate set of alignments H L , ∆ L can be enlarged only by adding h i to H L with either the support relation ⇒ or R = ⇒ added to ∆ L . These assume competing alignments among the child phrases, thus cannot co-exist in the same legitimate set.</p><p>h i can be supported by more than one pair of descendant alignments in ∆ L , i.e., {{h m , ··} ⇒</p><formula xml:id="formula_4">h i or {{h m , ··} R = ⇒ h i exists. For H m = {h m }, we define the relationship ≤ for alignments, i.e., h p ≤ h q meaning that τ s p ∈ ds(τ s q ) ∧ τ t p ∈ ds(τ t q ). For example, in Fig. 2, h m ≤ h i and h n ≤ h i . Theorem 3.1. There always exist the maximum pair h M ∈ H m where ∀h m ∈ H m , h m ≤ h M .</formula><p>H L , ∆ L should satisfy the conditions in Def- inition 3.2 to be legitimate as a whole. We denote</p><formula xml:id="formula_5">h i * − → h j when a chain exists in ∆ L , which con- nects h i to h j regardless of straight or inverted di- rections of intermediate supports, e.g., (h i , ·· ⇒ h i+1 ), (h i+1 , ·· R = ⇒ h i+2 ), . . ., (h j−1 , ·· ⇒ h j ). Note h i * − → h i is always true. Definition 3.2. H L , ∆ L should satisfy: 1. Root-Pair Containment: τ s R , τ t R ∈ H L 2. Same-Tree: {τ s i | τ s i , τ t i ∈ H L }</formula><p>are subsets of phrases in the same complete parse tree of s (same for t).</p><formula xml:id="formula_6">3. Relevance: ∀h i ∈ H L , h i * − → τ s R , τ t R ∈ ∆ L 4. Consistency: In H L , a phrase ( = τ ∅ ) in the</formula><p>source tree is aligned with at most one phrase ( = τ ∅ ) in the target tree, and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Monotonous: For τ</head><formula xml:id="formula_7">s i , τ t i , τ s j , τ t j ∈ H L , τ s i ∈ ds(τ s j ) iff τ t i ∈ ds(τ t j ). 6. Maximum Set: H L is the maximum legiti- mate set, in the sense that ∀∀τ s , τ t ∈ (H \ H L ), {{τ s , τ t } ∪ H L cannot be a legitimate set with any ∆.</formula><p>The Same-Tree condition is required to con- duct an alignment on forests that consist of mul- tiple trees in a packed representation. The Consis- tency condition excludes competing alignments. The Monotonous condition is a consequence of compositionality. The Maximum Set means if h m , h n ∈ H L are in positions of a parse tree that can support h i , h i and the support relation should be added to H L , ∆ L . Such a strict local- ity of compositionality is often violated in prac- tice as discussed in Sec. 2. To tackle this issue, we add another operation to align phrases in a non- compositional way in Sec. 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Lowest Common Ancestor</head><p>The same aligned pair can have more than one sup- port of descendant alignments because there are numerous descendant node combinations. How- ever, the Monotonous and the Maximum Set con- ditions allow ∆ L to be further restricted so that each of aligned pairs in H L has only one support.</p><p>Let us assume that alignment h i is supported by more than one pair of descendant alignments  <ref type="figure">Figure 3</ref>: Inside probability depends on support alignments and paths to reach an LCA.</p><formula xml:id="formula_8">in ∆ L , i.e., ∆ L ⊇ ({{h m , h n } ⇒ h i ) 1 .</formula><p>We de- note H m = {h m } and H n = {h n }. For each h m ∈ H m and h n ∈ H n , we remove all support relations from ∆ L except for the maximum pairs or the pre-terminal alignments. The resultant set ∆ L satisfies: <ref type="figure" target="#fig_2">Fig. 2</ref>, τ s i is the lowest common ancestor (LCA) of τ s m and τ s n , and τ t i is the LCA of τ t m and τ t n . Theorem 3.2 constitutes the basis for the dy- namic programming (DP) in our phrase alignment algorithm (Sec. 4.2).</p><formula xml:id="formula_9">Theorem 3.2. For all (h m , h n ⇒ h i ) ∈ ∆ L , τ s i = lca(τ s m , τ s n ) and τ t i = lca(τ t m , τ t n ) are true. In</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Modeling of Phrase Alignment</head><p>We formally model the phrase alignment process as illustrated in <ref type="figure">Fig. 3</ref>, where h i is aligned from descendant alignments, i.e., h m and h n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Probabilistic Model</head><p>Similar to the probabilistic context free grammar (PCFG), the inside probability α i of h i is deter- mined by the inside probabilities, α m and α n , of the support pairs, together with the probability of the rule, i.e., the way by which h m and h n are combined to support h i as shown in <ref type="figure">Fig. 3</ref> (τ t n to τ t i ). Each path consists of a set of null-aligned phrases φ ∈ φ, τ ∅ and their mothers, e.g., the path π s m,i in <ref type="figure">Fig. 3</ref> is a set of φ s 1 , m(φ s 1 ), φ s 2 , m(φ s 2 ), and φ s 3 , m(φ s 3 ). We assume that each occurrence of a null-alignment is indepen- 1 ⇒ and R = ⇒ are not distinguished here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>í µíµí µíµ 3 í µíµí µíµ 4 í µíµí µíµ 5 í µí»¼í µí»¼ 1 , í µíµí µíµ 3 , í µíµí µíµ 4 í µíµí µíµ 1 = í µí¼í µí¼ 1 í µí± í µí±</head><p>, í µí¼í µí¼ 1 í µí±¡í µí±¡ í µíµí µíµ 2 = í µí¼í µí¼ 2 í µí± í µí± , í µí¼í µí¼ 2 í µí±¡í µí±¡ { í µí»¼í µí»¼ í µí±í µí± , í µíµí µíµ í µí±í µí± , í µíµí µíµ í µí±í µí± í µí±í µí± } í µí±í µí± í µí»¼í µí»¼ 2 ′ , í µíµí µíµ 6 , í µíµí µíµ 7 í µí»¼í µí»¼ 1 ′ , í µíµí µíµ 5 , í µíµí µíµ 3 í µí»¼í µí»¼ 2 , �,� í µí»¼í µí»¼ 3 , �,� í µíµí µíµ 6 í µíµí µíµ 7</p><p>Figure 4: Alignment pairs and packed supports dent. Thus, its probability β s m,i is computed as:</p><formula xml:id="formula_10">β s m,i = Π φ s k ∈π s m,i P r (φ s k , τ ∅ ).</formula><p>β s n,i , β t m,i , and β t n,i are computed in the same man- ner. We abbreviate γ s m,n,i = β s m,i β s n,i , likewise γ t m,n,i = β t m,i β t n,i . Finally, α i can be represented as a simple relation:</p><formula xml:id="formula_11">α i = α m α n P r (τ s i , τ t i )γ s m,n,i γ t m,n,i .<label>(1)</label></formula><p>P r (·, ·) is the alignment probability parameterized in Sec. 5. Since we assume that the structures of parse trees of s and t are determined by a parser, the values of γ s m,n,i and γ t m,n,i are fixed. There- fore, by traversing the parse tree in a bottom- up manner, we can identify an LCA (i.e., τ i ) for phrases τ m and τ n while simultaneously comput- ing γ m,n,i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Alignment Algorithm</head><p>Algorithm 4.1 depicts our algorithm. Given word alignments W = {{w s i , w t i }, it constructs legit- imate sets of aligned pairs in a bottom-up man- ner. Like the CKY algorithm, Algorithm 4.1 uses DP to efficiently compute all possible legitimate sets and their probabilities in parallel. In addi- tion, null-alignments are allowed when aligning an LCA supported by aligned descendant nodes.</p><p>A <ref type="bibr">[·]</ref> is indexed by phrases in the parse tree of s and maintains a list of all possible aligned pairs. Furthermore, to deal with non-monotonic align- ment (Sec. 4.3), it keeps all competing hypotheses of support relations using packed representations. Specifically, h i is accompanied by its packed sup- port list as illustrated in <ref type="figure">Fig. 4</ref>; h 1 = τ s 1 , τ t 1 is aligned with supports of {{α j , h m , h n } like α 1 , h 3 , h 4 . Depending on the support align- ments, h i has different inside probabilities, i.e., α 1 , α 2 , and α 3 . Since the succeeding process of alignment only deals with the LCA's of τ s 1 and τ t 1 that are independent of the support alignment, all Algorithm 4.1 Phrase Alignment 1: LCAs and γ in parse trees of s and t are com- puted and stored in Lca</p><formula xml:id="formula_12">s [·][·] and Lca t [·][·]. 2: set A[τ s ] ← ∅</formula><note type="other">for all τ s 3: for all w s , w t ∈ W do 4: Find τ s and τ t covering w s and w t 5: Compute α i of τ s , τ t using Eq. (1) 6: PACK(τ s , τ t , α i , ∅∅, A) 7: for all τ s m , τ s n do Trace the source tree from the bottom to top 8: for all τ s i , γ s m,n,i ∈ Lca s [τ s m ][τ s n ] do 9: ALIGN(τ s m , τ s n , τ s i , γ s m,n,i , A) 10: function ALIGN(τ s m , τ s n , τ s i , γ s , A) 11: for all h m = τ s m , τ t m ∈ A[τ s m ] do 12:</note><p>for all h n = τ s n , τ t n ∈ A[τ s n ] do 13:</p><formula xml:id="formula_13">τ t i , γ t ← Lca t [τ t m ][τ t n ] 14:</formula><p>Compute α i using Eq. <ref type="formula" target="#formula_11">(1)</ref> 15: </p><formula xml:id="formula_14">PACK(τ s i , τ t i , α i , h m , h n , A) 16: function PACK(τ s , τ t , α, h m , h n , A) 17: if τ s , τ t ∈ A[τ s ] then 18: A[τ s ] ← A[τ s ] ∪ α,</formula><formula xml:id="formula_15">A[τ s ] ← (τ s , τ t , α, h m , h n )</formula><p>support relations are packed as a support list 2 by the PACK function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Non-Compositional Alignment</head><p>A monotonic alignment requires τ t m ∈ h m and τ t n ∈ h n to have an LCA, which adheres to the compositionality in language. However, previous studies declared that the compositionality is vio- lated in a monolingual phrase alignment <ref type="bibr" target="#b4">(Burkett et al., 2010;</ref><ref type="bibr" target="#b29">Weese et al., 2014</ref>). Heilman and Smith (2010) discuss complex phrase reordering is prevalent in paraphrases and entailed text.</p><p>A non-monotonic alignment occurs when cor- responding phrases have largely different orders, i.e., one of them (e.g., τ t m ) is an ancestor of another (e.g., τ t n ) or the same phrase. Such a case could be exceptionally compatible, when τ t m has null- alignments and all the aligned phrases of τ t n fit in these null-alignments. A new alignment τ s i , τ t i (= τ t m ) would be non-monotonically formed. <ref type="figure" target="#fig_3">Fig. 5</ref> shows a real example of non-compositional align- ment produced by our method. The target phrase τ t n ("through the spirit of teamwork") is null-</p><formula xml:id="formula_16">Algorithm 4.2 Non-Compositional Alignment 1: function TRACE(τ n , τ m ) τ n ∈ ds(τ m ) 2: V ← ∅ 3: for all [τ m ] i do 4: if τ n ∈ ds(φ) for ∃φ ∈ Φ [τm] i then 5: V ← V ∪ Ψ [τm] i ∪ τ n , (Φ [τm] i \ φ)∪ GAP(τ n , φ) 6:</formula><p>else if τ n ∈ ds(ψ) for ∃ψ ∈ Ψ [τm] i then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>V ← V ∪ TRACE(τ n , ψ) 8:</p><formula xml:id="formula_17">else 9: for all [τ n ] j do 10: V ← V ∪ DOWN([τ n ] j , [τ m ] i ) 11: return V ;</formula><p>alignment when aligning τ s m and τ t m , but then the alignment to τ s n ("Relying on team spirit") is al- lowed by non-compositional alignment of τ s i . Unlike monotonous alignment, we have to ver- ify whether the internal structures of τ t m and τ t n are compatible. Since the internal structures of τ t m and τ t n depend on their supporting alignments, their packed representations in A have to be unpacked, and each pair of supporting alignments for h m and h n must be checked to confirm compatibility. Fur- thermore, since the aligned phrases inside τ t m and τ t n have their own null-alignments, we need to un- pack deeper supporting alignments as well.</p><p>Algorithm 4.2 checks if target phrases τ m and τ n ∈ ds(τ m ) are compatible. We use the following notations: [τ m ] i and [τ n ] j represent the phrases of τ m and τ n with the i-th and j-th sets of supporting alignments, respectively. For τ t 2 in <ref type="figure">Fig. 4</ref> </p><formula xml:id="formula_18">Φ [τm] i = {φ [τm] i l } ([τ n ] j is similar).</formula><p>For each [τ m ] i , if τ n fits in its null-alignment like in <ref type="figure" target="#fig_3">Fig. 5</ref>, the alignment information is updated at line 5, where GAP function takes two phrases and returns a set of null-alignments on a path be- tween them. If τ n is a descendant of a support of τ m , the compatibility is recursively checked (line 7). Otherwise, the compatibility of the supports of τ n and τ m are recursively checked in DOWN func- tion in a similar manner (line 10).</p><p>When TRACE function returns a set of {{Ψ k , Φ k }, all ψ ∈ Ψ k are aligned with phrases in the source and their inside probabilities are stored in A. Thus we can compute the inside prob- ability for each Ψ k , Φ k , which is stored in A to-Source: Relying on team spirit, expedition members defeated difficulties. Target: Members of the scientific team overcame difficulties through the spirit of teamwork.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Forest Alignment</head><p>Although we have discussed using trees for clarity, the alignment is conducted on forests. The align- ment process is basically the same. The only dif- ference is that the same pair has multiple LCAs. Hence, we need to verify if the sub-trees can be on the same tree when identifying their LCAs since multiple nodes may cover the same span with different derivations. This is critical for non- compositional alignment because whether the in- ternal structures are on the same tree must be con- firmed while unpacking them. Our alignment process corresponds to re- ranking of forests and may derive a different tree from the 1-best, which may resolve ambiguity in parsing. We use a parser trained beforehand be- cause joint parsing and alignment is computation- ally too expensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Parameterization</head><p>Next, we parameterize the alignment probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Feature-enhanced EM Algorithm</head><p>We apply the feature-enhanced EM <ref type="bibr">(BergKirkpatrick et al., 2010)</ref> due to its ability to use dependent features without an irrational indepen- dence assumption. This is preferable because the attributes of phrases largely depend on each other.</p><p>Our method is computationally heavy since it handles forests and involves unpacking in the non- compositional alignment process. Thus, we use Viterbi training <ref type="bibr" target="#b2">(Brown et al., 1993</ref>) together with a beam search of size µ b ∈ N on the feature- enhanced EM. Also, mini-batch training <ref type="bibr" target="#b16">(Liang and Klein, 2009</ref>) is applied. Such an approxima- tion for efficiency is common in parallel parsing <ref type="bibr" target="#b5">(Burkett and Klein, 2008;</ref><ref type="bibr" target="#b4">Burkett et al., 2010)</ref>.</p><p>In addition, an alignment supported by distant descendants tends to fail to reach a root-pair align- ment. Thus, we restrict the generation gap be- tween a support alignment and its LCA to be less than or equal to µ g ∈ N.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Features</head><p>In feature-enhanced EM, the alignment probabil- ity in Eq. <ref type="formula" target="#formula_11">(1)</ref> is parameterized using features:</p><formula xml:id="formula_19">P r (τ s i , τ t i ) . = exp(w · F(a s i , a t i )) τ s j ,τ t j ,τ s i =τ s j exp(w · F(a s j , a t j )) ,</formula><p>where a . = (a 0 , · · · , a n ) consists of n attributes of τ . F(·, ·) and w are vectors of feature functions and their weights, respectively.</p><p>In a parse tree, the head of a phrase determines its property. Hence, a lemmatized lexical head a lex ∈ a combined with its syntactic category a cat ∈ a is encoded as a feature 3 as shown be- low. We use semantic (instead of syntactic) heads to encode semantic relationships in paraphrases.</p><formula xml:id="formula_20">1: 1(a s lex = ·, a s cat = ·, a t lex = ·, a t cat = ·) 2: 1(SurfaceSim(a s lex = ·, a t lex = ·)) 3: 1(WordnetSim(a s lex = ·, a t lex = ·)) 4: 1(EmbeddingSim(a s lex = ·, a t lex = ·)) 5: 1(IsPrepositionPair(a s lex = ·, a t lex = ·)) 6: 1(a s cat = ·, a t cat = ·) 7: 1(IsSameCategory(a s cat = ·, a t cat = ·))</formula><p>The first feature is an indicator invoked only at specific values. On the other hand, the rest of the features are invoked across multiple values, allow- ing general patterns to be learned. The second fea- ture is invoked if two heads are identical or a head is a substring of another. The third feature is in- voked if two heads are synonyms or derivations that are extracted from the WordNet 4 . The fourth feature is invoked if the cosine similarity between word embeddings of two heads is larger than a threshold. The fifth feature is invoked when the heads are both prepositions to capture their differ- ent natures from the content words. The last two features are for categories; the sixth one is invoked at each category pair, while the seventh feature is invoked if the input categories are the same.</p><p>To avoid generating a huge number of features, we reduce the number of syntactic categories; for contents (N, V, ADJ, and ADV), prepositions, co- ordinations, null (i.e., for τ ∅ ), and others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Penalty Function</head><p>Since our method allows null-alignments, it has a degenerate maximum likelihood solution ( <ref type="bibr" target="#b16">Liang and Klein, 2009</ref>) that makes every phrase null- alignment. Similarly, a degenerate solution overly conducts non-compositional alignment.</p><p>To avoid these issues, a penalty is incorporated:</p><formula xml:id="formula_21">P e (τ s i , τ t i ) =            exp{−(|τ s i | φ + |τ t i | φ + µ c + 1) µn } (non-compositional alignment) exp{−(|τ s i | φ + |τ t i | φ + 1) µn } (otherwise)</formula><p>where | · | φ computes the span of internal null- alignments, and µ n ≥ 1.0 and µ c ∈ R + con- trol the strength of the penalties of the null- alignment and the non-compositional alignment, respectively. The penalty function is multiplied by Eq.</p><p>(1) as a soft-constraint for re-ranking align- ment pairs in Algorithm 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Combination with Parse Probability</head><p>Following the spirit of parallel parsing that si- multaneously parses and aligns sentences, we lin- early interpolate the alignment probability with the parsing probability once the parameters are tuned by EM. When aligning a node pair τ s i , τ t i , the overall probability is computed as:</p><formula xml:id="formula_22">(1 − µ p )α i + µ p (τ s i )(τ t i )</formula><p>, where (·) gives the marginal probability in pars- ing and µ p ∈ [0, 1] balances these probabilities. <ref type="bibr">4</ref> http://wordnet.princeton.edu</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>As discussed in Sec. 2, previous studies have not conducted syntactic phrase alignment on parse trees. A direct metric does not exist to compare paraphrases that cover different spans, i.e., our syntactic paraphrases and paraphrases of n-grams. Thus, we compared the alignment quality to that of humans as a realistic way to evaluate the per- formance of our method.</p><p>We also evaluated the parsing quality. Similar to the alignment quality, differences in phrase struc- tures disturb the comparisons ( <ref type="bibr" target="#b22">Sagae et al., 2008)</ref>. Our method applies an HPSG parser Enju (  to derive parse forests due to its state-of-the-art performance and ability to provide rich properties of phrases. Hence, we compared our parsing quality to the 1-best parses of Enju.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Language Resources</head><p>We used reference translations to evaluate ma- chine translations <ref type="bibr">5</ref> as sentential paraphrases <ref type="bibr" target="#b29">(Weese et al., 2014</ref>). The reference translations of 10 to 30 words were extracted and paired, giving 41K pairs as a training corpus.</p><p>We use different kinds of dictionaries to obtain word alignments W as well as to compute fea- ture functions. First, we extract synonyms and words with derivational relationship using Word- Net. Then we handcraft derivation rules (e.g., create, creation, creator) and extract potentially derivational words from the training corpus. Fi- nally, we use prepositions defined in <ref type="bibr" target="#b26">(Srikumar and Roth, 2013)</ref> as a preposition dictionary to compute the feature function.</p><p>In addition, we extend W using word embed- dings; we use the MVLSA word embeddings ( <ref type="bibr" target="#b20">Rastogi et al., 2015)</ref> given the superior perfor- mance in word similarity tasks. Specifically, we compute the cosine similarity of embeddings; words with a higher similarity value than a thresh- old are determined as similar words. The threshold is empirically set as the 100th highest similarity value between words in the training corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Gold-Standard Data</head><p>Since no annotated corpus provides phrase align- ments on parse trees, we created one through two- phase manual annotation. First, a linguistic expert with rich experience on annotating HPSG trees annotated gold-trees to paraphrasal sentence pairs sampled from the training corpus. To diversify the data, only one reference pair per sentence of a source language was annotated. Consequently, 201 paraphrased pairs with gold-trees (containing 20, 678 phrases) were obtained.</p><p>Next, three professional English translators identified paraphrased pairs including null- alignments given sets of phrases extracted from the gold-trees. These annotators independently annotated the same set, yielding 14, 356 phrase alignments where at least one annotator regarded as a paraphrase. All the annotators agreed that 77% of the phrases were paraphrases.</p><p>We used 50 sentence pairs for development and another 151 for testing. These pairs were excluded from the training corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Evaluation Metric</head><p>Alignment Quality Alignment quality was evaluated by measuring the extent that the au- tomatic alignment results agree with those of humans. Specifically, we evaluated how gold- alignments can be replicated by automatic align- ment (called recall) and how automatic alignments overlap with alignments that at least an annotator aligned (called precision) as:</p><formula xml:id="formula_23">Recall = |{h|h ∈ H a ∧ h ∈ G ∩ G }| |G ∩ G | , Precision = |{h|h ∈ Ha ∧ h ∈ G ∪ G }| |Ha| ,</formula><p>where Ha is a set of alignments, while G and G are the ones that two of annotators produce, re- spectively. The function of | · | counts the elements in a set. There are three combinations for G and G because we had three annotators. The final pre- cision and recall values are their averages.</p><p>Parsing Quality The parsing quality was evalu- ated using the CONLL-X ( <ref type="bibr" target="#b3">Buchholz and Marsi, 2006</ref>) standard. Dependencies were extracted from the output HPSG trees, and evaluated using the official script 6 . Due to this conversion, the accuracy on the relation labels is less important. Thus, we reported only the unlabeled attachment score (UAS) <ref type="bibr">7</ref> . The development and test sets pro- vide 2, 371 and 6, 957 dependencies, respectively.</p><p>Roles of hyper-parameters µ n Control penalty for null-alignment µ c Control penalty for non-compositional alignment µ p Balance alignment and parsing prob. µ b Beam size at alignment µ g Generation gap to reach an LCA  Since all metrics were computed in a set, the approximate randomization <ref type="bibr" target="#b19">(Noreen, 1989;</ref><ref type="bibr" target="#b21">Riezler and Maxwell, 2005</ref>) (B = 10K) was used for significance testing. It has been shown to be more conservative than using bootstrap resam- pling ( <ref type="bibr" target="#b21">Riezler and Maxwell, 2005</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Results and Discussion</head><p>Overall Results <ref type="table" target="#tab_6">Table 2</ref> summarizes the hyper- parameters, which were tuned to maximize UAS in the development set using the Bayesian opti- mization. For efficiency, we used 2K samples from the training corpus and set the mini-batch size in feature-enhanced EM to 200 similar to "rapid training" in <ref type="bibr" target="#b5">(Burkett and Klein, 2008)</ref>. We also set µ b = 50 during EM training to manage the training time. <ref type="table" target="#tab_7">Table 3</ref> shows the performance on the test set for variations of our method and that of the human annotators. The last column shows the percentage of pairs where a root pair is reached to be aligned, called reachability. Our method is denoted as Pro- posed, while its variations include a method with only monotonic alignment (monotonic), without EM (w/o EM), and a method aligning only 1-best trees (1-best tree).</p><p>The performance of the human annotators was assessed by considering one annotator as the test and the other two as the gold-standard, and then taking the averages, which is the same setting as our method. We regard this as the pseudo inter-annotator agreement, since the conventional inter- annotator agreement is not directly applicable due to variations in aligned phrases.</p><p>Our method significantly outperforms the oth- ers as it achieved the highest recall and precision for alignment quality. Our recall and precision reach 92% and 89% of those of humans, respec- tively. Non-compositional alignment is shown to contribute to alignment quality, while the feature- enhanced EM is effective for both the alignment and parsing quality. Comparing our method and the one aligning only 1-best trees demonstrates that the alignment of parse forests largely con- tributes to the alignment quality. Although we confirmed that aligning larger forests slightly im- proved recall and precision, the improvements were statistically insignificant. The parsing qual- ity was not much affected by phrase alignment, which is further investigated in the following.</p><p>Finally, our method achieved 98% reachabil- ity, where 2% of unreachable cases were due to the beam search. While understanding that the reachability depends on experimental data, ours is notably higher than that of SCFG, reported as 9.1% in ( <ref type="bibr" target="#b29">Weese et al., 2014</ref>). These results show the ability of our method to accurately align para- phrases with divergent phrase correspondences.</p><p>Effect of Mini-Batch Size We investigated the effect of the mini-batch size in EM training using the entire training corpus (41K pairs). When in- creasing the mini-batch size from 200 to 2K, re- call, precision, and UAS values are fairly stable. In addition, they are insensitive against the amount of training corpus, showing the comparable values against the model trained on 2K samples. These results demonstrate that our method can be trained with a moderate amount of data.</p><p>Observations Previous studies show that paral- lel parsing improves parsing quality, while such an effect is insignificant here. We examine causes through manual observations. The evaluation script indicated that our method corrected 34 errors while introducing 41 new er- rors <ref type="bibr">8</ref> . We further analyzed these 75 cases; 12 cases are ambiguous as both the gold-standard and the output are correct. In addition, 8 cases are due to erroneous original sentences that should be disre- garded, e.g., " For two weeks ago,..." and "Accord-ing to the source, will also meet...". Consequently, our method corrected 32 errors while introducing 23 errors in reality for 446 errors in 1-best trees, which achieves a 2.5% error reduction.</p><p>These are promising results for our method to improve parsing quality, especially on the PP- attachment (159 errors in 1-best), which contained 14 of the 32 corrected errors. <ref type="figure" target="#fig_0">Fig. 1</ref> shows a real example; the phrase of "for a smoke" in the source was mistakenly attached to "ground floor" in the 1-best tree. This error was corrected as depicted. <ref type="bibr" target="#b12">Duan et al. (2016)</ref> showed that paraphrases ar- tificially generated using n-best parses improved the parsing quality. One reason for limited im- provement in our experiments may be because structural changes in our natural paraphrases are more dynamic than the level useful to resolve am- biguities. We will further investigate this in future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We propose an efficient method for phrase align- ment on parse forests of paraphrased sentences. To increase the amount of collected paraphrases, we plan to extend our method to align compara- ble paraphrases that are partially paraphrasal sen- tences. In addition, we will apply our method to parallel parsing and other grammar, e.g., projec- tive dependency trees. Furthermore, we will apply such syntactic paraphrases to phrase embedding.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of phrase alignments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Alignment pair and its supports</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Example of a non-compositional alignment</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>.</head><label></label><figDesc></figDesc><table>It is 
characterized by four paths, π s 
m,i (the path from 
τ s 
m to τ s 
i ), π s 
n,i (τ s 
n to τ s 
i ), π t 
m,i (τ t 
m to τ t 
i ), and π t 

n,i 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Summary of the hyper-parameters 

Method 
Recall 
Prec. 
UAS 
% 
Human 
90.65 
88.21 
-
-
Proposed 
83.64 78.91 93.49 
98 
Monotonic 82.86  *  77.97  *  93.49 
98 
w/o EM 
81.33  *  75.09  *  92.91  *  
86 
1-best tree 80.11  *  73.26  *  93.56 100 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Evaluation results on the test set, where  *  
represents p-value &lt; 0.05 against our method. 

</table></figure>

			<note place="foot" n="2"> This is true except for a non-compositional alignment where the packed representation must be unpacked.</note>

			<note place="foot" n="3"> We also tried features based on the configurations of the source and target sub-trees similar to (Das and Smith, 2009) as well as features based on the spans of null-alignments. However, none of them contributed to alignment quality.</note>

			<note place="foot" n="5"> NIST OpenMT corpora: LDC2010T14, LDC2010T17, LDC2010T21, LDC2010T23, LDC2013T03</note>

			<note place="foot" n="6"> http://ilk.uvt.nl/conll/software.html 7 Although omitted, the labeled attachment score showed the same tendency as UAS.</note>

			<note place="foot" n="8"> Alignments were obtained by the model trained using the entire corpus with the 1K mini-batch size.</note>

			<note place="foot" n="9"> http://www-bigdata.ist.osaka-u.ac.jp/ arase/pj/phrase-alignment/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Professor Issei Sato for permission to use their package for Bayesian optimization. Spe-cial thanks also to Dr. Yuka Tateishi for her contri-bution to HPSG tree annotation. Advice and com-ments given by Professor Takuya Matsuzaki and Professor Yusuke Miyao have been a great help in applying Enju parser for this project. We appre-ciate the anonymous reviewers for their insight-ful comments and suggestions to improve the pa-per. This project is funded by Microsoft Research Asia and the Kayamori Foundation of Informa-tional Science Advancement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Material</head><p>The supplemental material is available at our web site 9 that provides proofs of the theorems, pseudo-codes of the algorithms, and more experiment re-sults with examples.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Painless unsupervised learning with features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Bouchard-Côté</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT)</title>
		<meeting>the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT)<address><addrLine>Los Angeles, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="582" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mining paraphrasal typed templates from a plain text corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terra</forename><surname>Or Biran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Blevins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1913" to="1923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">Della</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">CoNLL-X shared task on multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the Conference on Natural Language Learning (CoNLL)</title>
		<meeting>eesings of the Conference on Natural Language Learning (CoNLL)<address><addrLine>New York City</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="149" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Joint parsing and alignment with weakly synchronized grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Burkett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)<address><addrLine>Los Angeles, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="127" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Two languages are better than one (for syntactic parsing)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Burkett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>eesings of the Conference on Empirical Methods in Natural Language essing (EMNLP)<address><addrLine>Honolulu, Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="877" to="886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A formal characterization of parsing word alignments by synchronous grammars with empirical evidence to the ITG hypothesis</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST)</title>
		<editor>Gideon Maillette de Buy Wenniger and Khalil Sima&apos;an</editor>
		<meeting>the Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST)<address><addrLine>Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="58" to="67" />
		</imprint>
	</monogr>
	<note>Atlanta</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Parsing paraphrases with joint inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kook</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing (ACL-IJCNLP)</title>
		<meeting>the Joint Conference of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing (ACL-IJCNLP)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1223" to="1233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Programming Languages and Their Compilers: Preliminary Notes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Cocke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<publisher>Courant Institute of Mathematical Sciences</publisher>
			<pubPlace>New York University</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Constructing corpora for the development and evaluation of paraphrase systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="597" to="614" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Paraphrase identification as probabilistic quasi-synchronous recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing (ACLIJCNLP)</title>
		<meeting>the Joint Conference of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing (ACLIJCNLP)<address><addrLine>Suntec, Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="468" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the International Conference on Computational Linguistics (COLING)</title>
		<meeting>eesings of the International Conference on Computational Linguistics (COLING)<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="350" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generating disambiguating paraphrases for structurally ambiguous sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjuan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Linguistic Annotation Workshop (LAW)</title>
		<meeting>the Linguistic Annotation Workshop (LAW)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="160" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">PPDB: The paraphrase database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="758" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Tree edit models for recognizing textual entailments, paraphrases, and answers to questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT)</title>
		<meeting>the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT)<address><addrLine>Los Angeles, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1011" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tadao Kasami. 1965. An efficient recognition and syntax-analysis algorithm for context-free languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Kaeshammer</surname></persName>
		</author>
		<idno>AFCRL-65-758</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST)</title>
		<meeting>the Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST)<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="68" to="77" />
		</imprint>
		<respStmt>
			<orgName>Air Force Cambridge Research Lab</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Scientific report</note>
	<note>Synchronous linear context-free rewriting systems for machine translation</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Online EM for unsupervised models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="611" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A phrase-based alignment model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>eesings of the Conference on Empirical Methods in Natural Language essing (EMNLP)<address><addrLine>Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="802" to="811" />
		</imprint>
	</monogr>
	<note>Honolulu</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Feature forest models for probabilistic HPSG parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="80" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Computer-Intensive Methods for Testing Hypotheses: An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">W</forename><surname>Noreen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiview LSA: Representation learning via generalized CCA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpendre</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="556" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On some pitfalls in automatic evaluation and significance testing for MT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">T</forename><surname>Maxwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Challenges in mapping of syntactic representations for frameworkindependent parser evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Automated Syntatic Annotations for Interoperable Language Resources</title>
		<meeting>the Workshop on Automated Syntatic Annotations for Interoperable Language Resources</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Quasisynchronous grammars: Alignment by soft projection of syntactic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Statistical Machine Translation (WMT)</title>
		<meeting>the Workshop on Statistical Machine Translation (WMT)<address><addrLine>New York City</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bilingual parsing with factored estimation: Using English to parse Korean</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>eesings of the Conference on Empirical Methods in Natural Language essing (EMNLP)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>eesings of the Conference on Empirical Methods in Natural Language essing (EMNLP)<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Modeling semantic relations expressed by prepositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association of Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="231" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Improved semantic representations from tree-structured long short-term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai Sheng</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1556" to="1566" />
			<pubPlace>Beijing, China</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A joint phrasal and dependency model for paraphrase alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kapil</forename><surname>Thadani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the International Conference on Computational Linguistics (COLING)</title>
		<meeting>eesings of the International Conference on Computational Linguistics (COLING)<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1229" to="1238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">PARADIGM: Paraphrase diagnostics through grammar matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Weese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callisonburch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the Conference of the European Chapter of the Association for Computational Linguistics (EACL)<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="192" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">From paraphrase database to compositional paraphrase model and back</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association of Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="345" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Towards universal paraphrastic sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>eesings of the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Stochastic inversion transduction grammars and bilingual parsing of parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="403" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semi-Markov phrasebased monolingual alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callisonburch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>eesings of the Conference on Empirical Methods in Natural Language essing (EMNLP)<address><addrLine>Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="590" to="600" />
		</imprint>
	</monogr>
	<note>Seattle</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Discriminative phrase embedding for paraphrase identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1368" to="1373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Recognition and parsing of context-free languages in time n 3. Information and Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Younger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1967" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="189" to="208" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
