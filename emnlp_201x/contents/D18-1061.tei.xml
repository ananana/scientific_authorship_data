<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distant Supervision from Disparate Sources for Low-Resource Part-of-Speech Tagging</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
							<email>bplank@itu.dk, zeag@itu.dk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen Rued</orgName>
								<address>
									<addrLine>Langgaards Vej 7</addrLine>
									<postCode>2300</postCode>
									<settlement>Copenhagen S</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agi´c</forename><surname>Agi´c</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen Rued</orgName>
								<address>
									<addrLine>Langgaards Vej 7</addrLine>
									<postCode>2300</postCode>
									<settlement>Copenhagen S</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distant Supervision from Disparate Sources for Low-Resource Part-of-Speech Tagging</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="614" to="620"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>614</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce DSDS: a cross-lingual neural part-of-speech tagger that learns from dis-parate sources of distant supervision, and realistically scales to hundreds of low-resource languages. The model exploits annotation projection , instance selection, tag dictionaries, morphological lexicons, and distributed representations , all in a uniform framework. The approach is simple, yet surprisingly effective, resulting in a new state of the art without access to any gold annotated data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Low-resource languages lack manually annotated data to learn even the most basic models such as part-of-speech (POS) taggers. To compensate for the absence of direct supervision, work in cross- lingual learning and distant supervision has dis- covered creative use for a number of alternative data sources to learn feasible models: -aligned parallel corpora to project POS annota- tions to target languages ( <ref type="bibr" target="#b18">Yarowsky et al., 2001;</ref><ref type="bibr">Agi´cAgi´c et al., 2015;</ref><ref type="bibr">Fang and Cohn, 2016)</ref>, -noisy tag dictionaries for type-level approxima- tion of full supervision ( <ref type="bibr" target="#b8">Li et al., 2012</ref>), -combination of projection and type constraints ( <ref type="bibr">Das and Petrov, 2011;</ref><ref type="bibr" target="#b16">Täckström et al., 2013</ref>), -rapid annotation of seed training data ( . However, only one or two compatible sources of distant supervision are typically employed. In re- ality severely under-resourced languages may re- quire a more pragmatic "take what you can get" viewpoint. Our results suggest that combining su- pervision sources is the way to go about creating viable low-resource taggers.</p><p>We propose a method to strike a balance be- tween model simplicity and the capacity to eas- ily integrate heterogeneous learning signals. Our system is a uniform neural model for POS tag- ging that learns from disparate sources of dis- tant supervision (DSDS). We use it to combine: i) multi-source annotation projection, ii) instance selection, iii) noisy tag dictionaries, and iv) dis- tributed word and sub-word representations. We examine how far we can get by exploiting only the wide-coverage resources that are currently readily available for more than 300 languages, which is the breadth of the parallel corpus we employ.</p><p>DSDS yields a new state of the art by jointly leveraging disparate sources of distant supervision in an experiment with 25 languages. We demon- strate: i) substantial gains in carefully selecting high-quality instances in annotation projection, ii) the usefulness of lexicon features for neural tag- ging, and iii) the importance of word embeddings initialization for faster convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>DSDS is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. The base model is a bidirectional long short-term memory net- work (bi-LSTM) ( <ref type="bibr" target="#b2">Graves and Schmidhuber, 2005;</ref><ref type="bibr" target="#b3">Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr" target="#b13">Plank et al., 2016;</ref><ref type="bibr" target="#b5">Kiperwasser and Goldberg, 2016)</ref>. Let x 1:n be a given sequence of input vectors. In our base model, the input sequence consists of word embeddings w and the two output states of a character-level bi-LSTM c. Given x 1:n and a de- sired index i, the function BiRN N θ (x 1:n , i) (here instantiated as LSTM) reads the input sequence in forward and reverse order, respectively, and uses the concatenated (•) output states as input for tag prediction at position i. 1 Our model differs from prior work on the type of input vectors x 1:n and distant data sources, in particular, we extend the input with lexicon embeddings, all described next.</p><p>Annotation projection. Ever since the seminal work of <ref type="bibr" target="#b18">Yarowsky et al. (2001)</ref>, projecting sequen- tial labels from source to target languages has been one of the most prevalent approaches to cross- lingual learning. Its only requirement is that paral- lel texts are available between the languages, and that the source side is annotated for POS.</p><p>We apply the approach by Agi´c <ref type="bibr">Agi´c et al. (2016)</ref>, where labels are projected from multiple sources and then decoded through weighted majority vot- ing with word alignment probabilities and source POS tagger confidences. We exploit their wide- coverage Watchtower corpus (WTC), in contrast to the typically used Europarl data. Europarl cov- ers 21 languages of the EU with 400k-2M sen- tence pairs, while WTC spans 300+ widely diverse languages with only 10-100k pairs, in effect sac- rificing depth for breadth, and introducing a more radical domain shift. However, as our results show little projected data turns out to be the most bene- ficial, reinforcing breadth for depth.</p><p>While Agi´cAgi´c et al. (2016) selected 20k projected sentences at random to train taggers, we propose a novel alternative: selection by coverage. We rank the target sentences by percentage of words cov- ered by word alignment from 21 sources of Agi´c <ref type="bibr">Agi´c et al. (2016)</ref>, and select the top k covered instances for training. In specific, we employ the mean coverage ranking of target sentences, whereby each target sentence is coupled with the arithmetic mean of the 21 individual word alignment cover- ages for each of the 21 source-language sentences. We show that this simple approach to instance se- lection offers substantial improvements: across all languages, we learn better taggers with signifi- cantly fewer training instances.</p><p>Dictionaries. Dictionaries are a useful source for distant supervision ( <ref type="bibr" target="#b8">Li et al., 2012;</ref><ref type="bibr" target="#b16">Täckström et al., 2013)</ref>. There are several ways to exploit such information: i) as type constraints during en- coding <ref type="bibr">(Täckström et al., 2013)</ref>, ii) to guide unsu- pervised learning ( <ref type="bibr" target="#b8">Li et al., 2012</ref>), or iii) as addi- tional signal at training. We focus on the latter and evaluate two ways to integrate lexical knowledge into neural models, while comparing to the former two: a) by representing lexicon properties as n-hot vector (e.g., if a word has two properties accord- ing to lexicon src, it results in a 2-hot vector, if the word is not present in src, a zero vector), with m the number of lexicon properties; b) by embedding the lexical features, i.e., e src is a lexicon src em- bedded into an l-dimensional space. We represent e src as concatenation of all embedded m proper- ties of length l, and a zero vector otherwise. Tun- ing on the dev set, we found the second embedding approach to perform best, and simple concatena- tion outperformed mean vector representations.</p><p>We evaluate two dictionary sources, motivated by ease of accessibility to many languages: WIK- TIONARY, a word type dictionary that maps to- kens to one of the 12 Universal POS tags ( <ref type="bibr" target="#b8">Li et al., 2012;</ref><ref type="bibr" target="#b12">Petrov et al., 2012)</ref>; and UNIMORPH, a morphological dictionary that provides inflec- tional paradigms across 350 languages ( <ref type="bibr" target="#b6">Kirov et al., 2016)</ref>. For Wiktionary, we use the freely available dictionaries from <ref type="bibr" target="#b8">Li et al. (2012)</ref> and Agi´c <ref type="bibr" target="#b9">Agi´c et al. (2017)</ref>. The size of the dictionaries ranges from a few thousands (e.g., Hindi and Bul- garian) to 2M (Finnish UniMorph). Sizes are pro- vided in <ref type="table" target="#tab_4">Table 1</ref>, first columns. UniMorph covers between 8-38 morphological properties (for En- glish and Finnish, respectively).</p><p>Word embeddings. Embeddings are available for many languages. Pre-initialization of w offers consistent and considerable performance improve- ments in our distant supervision setup (Section 4). We use off-the-shelf Polyglot embeddings (Al- Rfou et al., 2013), which performed consistently better than FastText ( <ref type="bibr">Bojanowski et al., 2016</ref>  -GARRETTE: The approach by  that works with projections, dictionaries, and unlabeled target text. -LI: Wiktionary supervision ( <ref type="bibr" target="#b8">Li et al., 2012</ref>).</p><p>Data. Our set of 25 languages is motivated by accessibility to embeddings and dictionaries. In all experiments we work with the 12 Universal POS tags ( <ref type="bibr" target="#b12">Petrov et al., 2012</ref>  <ref type="bibr" target="#b19">Zeman et al., 2014)</ref>, and are more distant from the training and development data.</p><p>Model and parameters. We extend an off-the- shelf state-of-the-art bi-LSTM tagger with lexicon information. The code is available at: https:// github.com/bplank/bilstm-aux. The parameter l=40 was set on dev data across all lan- guages. Besides using 10 epochs, word dropout rate (p=.25) and 40-dimensional lexicon embed- dings, we use the parameters from <ref type="bibr" target="#b13">Plank et al. (2016)</ref>. For all experiments, we average over 3 randomly seeded runs, and provide mean accu- racy. For the learning curve, we average over 5 random samples with 3 runs each. <ref type="table" target="#tab_4">Table 1</ref> shows the tagging accuracy for individual languages, while the means over all languages are given in <ref type="figure" target="#fig_1">Figure 2</ref>. There are several take-aways.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Data selection. The first take-away is that coverage-based instance selection yields substan- tially better training data. Most prior work on an- notation projection resorts to arbitrary selection; informed selection clearly helps in this noisy data setup, as shown in <ref type="figure" target="#fig_1">Figure 2</ref> (a). Training on 5k instances results in a sweet spot; more data (10k) starts to decrease performance, at a cost of run- time. Training on all WTC data (around 120k) is worse for most languages. From now on we con- sider the 5k model trained with Polyglot as our baseline <ref type="table" target="#tab_4">(Table 1</ref>, column "5k"), obtaining a mean accuracy of 83.0 over 21 languages.</p><p>Embeddings initialization. Polyglot initializa- tion offers a large boost; on average +3.8% abso- lute improvement in accuracy for our 5k training scheme, as shown in <ref type="figure" target="#fig_1">Figure 2 (b)</ref>. The big gap in low-resource setups further shows their effective- ness, with up to 10% absolute increase in accuracy when training on only 500 instances.</p><p>Lexical information. The main take-away is that lexical information helps neural tagging, and embedding it proves the most helpful. Embedding Wiktionary tags reaches 83.7 accuracy on average, versus 83.4 for n-hot encoding, and 83.2 for type constraints. Only on 4 out of 21 languages are type constraints better. This is the case for only one language for n-hot encoding (French). The best approach is to embed both Wiktionary and Uni- morph, boosting performance further to 84.0, and resulting in our final model. It helps the most on morphological rich languages such as Uralic.</p><p>On the test sets (  <ref type="bibr">Das and Petrov (2011)</ref>, compared to their 83.4. This shows that our novel "soft" inclusion of noisy dictionar- ies is superior to a hard decoding restriction, and including lexicons in neural taggers helps. We did not assume any gold data to further enrich the lex- icons, nor fix possible tagset divergences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Analysis. The inclusion of lexicons results in higher coverage and is part of the explanation for the improvement of DSDS; see correlation in <ref type="figure" target="#fig_2">Fig- ure 3 (a)</ref>. What is more interesting is that our model benefits from the lexicon beyond its con- tent: OOV accuracy for words not present in the lexicon overall improves, besides the expected im- provement on known OOV, see <ref type="figure" target="#fig_2">Figure 3</ref> (b).  More languages. All data sources employed in our experiment are very high-coverage. However, for true low-resource languages, we cannot safely assume the availability of all disparate information sources. <ref type="table" target="#tab_5">Table 2</ref> presents results for four addi- tional languages where some supervision sources are missing. We observe that adding lexicon in- formation always helps, even in cases where only 1k entries are available, and embedding it is usu- ally the most beneficial way. For closely-related languages such as Serbian and Croatian, using re- sources for one aids tagging the other, and modern resources are a better fit. For example, using the Croatian WTC projections to train a model for Ser- bian is preferable over in-language Serbian Bible data where the OOV rate is much higher.</p><p>How much gold data? We assume not having access to any gold annotated data. It is thus in- teresting to ask how much gold data is needed to reach our performance. This is a tricky question, as training within the same corpus naturally favors the same corpus data. We test both in-corpus (UD) and out-of-corpus data (our test sets) and notice an important gap: while in-corpus only 50 sentences are sufficient, outside the corpus one would need over 200 sentences. This experiment was done for a subset of 18 languages with both in-and out-of- corpus test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LEX (10 3 ) TEST SETS LANGUAGE TEST</head><p>PROJ EMB W U TnT 5k TC W n-hot W e W DSDS Basque (eu) UD Bible eu 1 -57.5 61.8 61.8 61.4 62.7 †62.7 Basque (eu) CoNLL Bible eu 1 -57.0 60.3 60.3 60.3 61.3 †61.3 Estonian (et) UD WTC et -10 79.5 80.6 - - - 81.5 Serbian (sr) UD WTC (hr) hr (hr) 20 -84.0 84.7 85.5 85.1 85.2 †85.2 Serbian (sr) UD Bible (sr) hr (hr) 20 -77.1 78.9 79.4 80.5 80.7 †80.7 <ref type="table">Tamil (ta)</ref> UD WTC ta - -58.2 61.2 - - - - Further comparison. In <ref type="table" target="#tab_4">Table 1</ref> we directly re- port the accuracies from the original contributions by DAS, LI, GARRETTE, and AGIC over the same test data. We additionally attempted to reach the scores of LI by running their tagger over the Ta- ble 1 data setup. The results are depicted in <ref type="figure" target="#fig_3">Fig- ure 4</ref> as mean accuracies over EM iterations until convergence. We show: i) LI peaks at 10 iterations for their test languages, and at 35 iterations for all the rest. This is in slight contrast to 50 iterations that <ref type="bibr" target="#b8">Li et al. (2012)</ref> recommend, although select- ing 50 does not dramatically hurt the scores; ii) Our replication falls ∼5 points short of their 84.9 accuracy. There is a large 33-point accuracy gap between the scores of <ref type="bibr" target="#b8">Li et al. (2012)</ref>, where the dictionaries are large, and the other languages in <ref type="figure" target="#fig_3">Figure 4</ref>, with smaller dictionaries. Compared to DAS, our tagger clearly benefits from pre-trained word embeddings, while theirs relies on label propagation through Europarl, a much cleaner corpus that lacks the coverage of the noisier WTC. Similar applies to <ref type="bibr">Täckström et al. (2013)</ref>, as they use 1-5M near-perfect parallel sen- tences. Even if we use much smaller and noisier data sources, DSDS is almost on par: 86.2 vs. 87.3 for the 8 languages from <ref type="bibr">Das and Petrov (2011)</ref>, and we even outperform theirs on four languages: Czech, French, Italian, and Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Most successful work on low-resource POS tag- ging is based on projection ( <ref type="bibr" target="#b18">Yarowsky et al., 2001</ref>), tag dictionaries ( <ref type="bibr" target="#b8">Li et al., 2012)</ref>, annota- tion of seed training data (  or even more recently some combination of these, e.g., via multi-task learning (Fang and  <ref type="table" target="#tab_4">Table 1</ref>. <ref type="bibr">Cohn, 2016;</ref><ref type="bibr" target="#b4">Kann et al., 2018)</ref>. Our paper con- tributes to this literature by leveraging a range of prior directions in a unified, neural test bed.</p><p>Most prior work on neural sequence predic- tion follows the commonly perceived wisdom that hand-crafted features are unnecessary for deep learning methods. They rely on end-to-end train- ing without resorting to additional linguistic re- sources. Our study shows that this is not the case. Only few prior studies investigate such sources, e.g., for MT ( <ref type="bibr" target="#b15">Sennrich and Haddow, 2016;</ref><ref type="bibr">Chen et al., 2017;</ref><ref type="bibr" target="#b7">Li et al., 2017;</ref><ref type="bibr" target="#b11">Passban et al., 2018)</ref> and <ref type="bibr" target="#b14">Sagot and Martínez Alonso (2017)</ref> for POS tagging use lexicons, but only as n-hot features and without examining the cross-lingual aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We show that our approach of distant supervision from disparate sources (DSDS) is simple yet sur- prisingly effective for low-resource POS tagging. Only 5k instances of projected data paired with off-the-shelf embeddings and lexical information integrated into a neural tagger are sufficient to reach a new state of the art, and both data selec- tion and embeddings are essential components to boost neural tagging performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Referenceš</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Referenceš</head><p>Zeljko Agi´cAgi´c, Dirk Hovy, and Anders Søgaard. 2015. If all you have is a bit of the bible: Learning pos tag- gers for truly low-resource languages. In Proceed- ings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th Interna- Meng <ref type="bibr">Fang and Trevor Cohn. 2016</ref>. Learning when to trust distant supervision: An application to low- resource pos tagging using cross-lingual projec- tion. In Proceedings of the 20th SIGNLL Confer- ence on Computational Natural Language Learning (CoNLL), pages 178-186, Berlin, Germany. Associ- ation for Computational Linguistics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of DSDS (Distant Supervision from Disparate Sources).</figDesc><graphic url="image-1.png" coords="1,307.28,222.54,218.27,133.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Learning curves for: a) random vs. coverage-based sentence selection in annotation projection, both with Polyglot embeddings, and b) pre-trained embeddings on top of coverage-based selection. Means over 21 languages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Analysis of DSDS accuracy improvements over the baseline on all development languages with respect to a) token coverage by the lexicon, including Pearson's ρ; b) OOV accuracy for tokens in/not in the lexicon, with 95% confidence intervals of the mean. Here, a token is covered if we can find it in at least one lexicon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The performance of LI with our dictionary data over EM iterations, separate for the languages from Li et al. (2012) and all the remaining languages in Table 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 ,</head><label>4</label><figDesc></figDesc><table>right) DSDS reaches 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Results on the development sets and comparison of our best model to prior work. LEX: Size 
(word types) of dictionaries (W: Wiktionary, U: UniMorph). TC W : type-constraints using Wiktionary; 
e W (embedded Wiktionary tags), DSDS: our model with e W ∪U . Results indicated by  † use W only. Best 
result in boldface; in case of equal means, the one with lower std is boldfaced. Averages over language 
families (with two or more languages in the sample, number of languages in parenthesis). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results for languages with missing data sources: WTC projections, Wiktionary (W), or Uni-
Morph (U). Test sets (TEST), projection sources (PROJ), and embeddings languages (EMB) are indicated. 
Comparison to TnT (Brants, 2000) trained on PROJ. Results indicated by  † use W only. 

</table></figure>

			<note place="foot" n="1"> CRF decoding did not consistently improve POS accuracy, as recently also independently found (Yang et al., 2018).</note>

			<note place="foot" n="3"> Experiments Baselines. We compare to the following weaklysupervised POS taggers:-AGIC: Multi-source annotation projection with Bible parallel data by Agi´cAgi´c et al. (2015).-DAS: The label propagation approach by Das and Petrov (2011) over Europarl data.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning a part-of-speech tagger from two hours of annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="138" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Real-world semi-supervised learning of postaggers for low-resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mielens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="583" to="592" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Character-level supervision for low-resource pos tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Bjerva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Sgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Deep Learning Approaches for Low-Resource NLP</title>
		<meeting>the Workshop on Deep Learning Approaches for Low-Resource NLP<address><addrLine>Melbourne</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliyahu</forename><surname>Kiperwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04351</idno>
		<title level="m">Simple and accurate dependency parsing using bidirectional lstm feature representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Very-large scale parsing and normalization of wiktionary morphological paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Que</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modeling source syntax for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="688" to="697" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Wiki-ly supervised part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Graça</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1389" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Universal dependencies 2.1. LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics ( ´ UFAL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Zeljko Agi´cagi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ahrenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Faculty of Mathematics and Physics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The CoNLL 2007 shared task on dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</title>
		<meeting>the CoNLL Shared Task Session of EMNLP-CoNLL<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="915" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improving character-based decoding using targetside morphological information for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Passban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="58" to="68" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<meeting>the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Istanbul, Turkey. European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="412" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving neural tagging with lexical information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoˆıtbenoˆıt</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alonso</forename><surname>Héctor Martínez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Parsing Technologies</title>
		<meeting>the 15th International Conference on Parsing Technologies<address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="25" to="31" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Linguistic input features improve neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="83" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Token and type constraints for cross-lingual part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in neural sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuailong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3879" to="3889" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Inducing multilingual text analysis tools via robust projection across aligned corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Wicentowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Human Language Technology Research</title>
		<meeting>the First International Conference on Human Language Technology Research</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Martin Popel, Loganathan Ramasamy, Jaň Stěpánek, ZdeněkZdeněkˇZdeněkŽabokrtsk`ZdeněkŽabokrtsk`y, and</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Dušek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mareček</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="601" to="637" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Hamledt: Harmonized multi-language dependency treebank</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
