<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Word Meanings and Grammar for Describing Everyday Activities in Smart Environments</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Attamimi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Ando</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoaki</forename><surname>Nakamura</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takayuki</forename><surname>Nagai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daichi</forename><surname>Mochihashi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Statistical Mathematics</orgName>
								<address>
									<addrLine>10-3 Midori-cho</addrLine>
									<settlement>Tachikawa</settlement>
									<region>Tokyo</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ichiro</forename><surname>Kobayashi</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Ochanomizu University</orgName>
								<address>
									<addrLine>2-1-1 Otsuka Bunkyo-ku Tokyo</addrLine>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Asoh</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">National Institute of Advanced Industrial Science and Technology</orgName>
								<address>
									<addrLine>1-1-1 Umezono</addrLine>
									<settlement>Tsukuba</settlement>
									<region>Ibaraki</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The University of Electro-Communications</orgName>
								<address>
									<addrLine>1-5-1 Chofugaoka, Chofu-shi</addrLine>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Word Meanings and Grammar for Describing Everyday Activities in Smart Environments</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>If intelligent systems are to interact with humans in a natural manner, the ability to describe daily life activities is important. To achieve this, sensing human activities by capturing multimodal information is necessary. In this study, we consider a smart environment for sensing activities with respect to realistic scenarios. We next propose a sentence generation system from observed multimodal information in a bottom up manner using mul-tilayered multimodal latent Dirichlet allocation and Bayesian hidden Markov models. We evaluate the grammar learning and sentence generation as a complete process within a realistic setting. The experimental result reveals the effectiveness of the proposed method.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Describing daily life activities is an important abil- ity of intelligent systems. In fact, we can use this ability to achieve a monitoring system that is able to report on an observed situation, or cre- ate an automatic diary of a user. Recently, sev- eral studies have been performed to generate sen- tences that describe images using Deep Learning ( <ref type="bibr" target="#b14">Vinyals et al., 2014;</ref><ref type="bibr" target="#b4">Fang et al., 2014;</ref><ref type="bibr" target="#b2">Donahue et al., 2014;</ref><ref type="bibr" target="#b8">Kiros et al., 2015)</ref>. Although these results were good, we are interested in unsuper- vised frameworks. This is necessary to achieve a system that can adapt to the user, that is, one that can learn a user-unique language and gener- ate it automatically. Moreover, the use of crowd- sourcing should be avoided to respect the privacy of the user. Regarding this, studies on sentence generation from RGB videos have been discussed in ( <ref type="bibr" target="#b15">Yu and Siskind, 2013;</ref><ref type="bibr" target="#b13">Regneri et al., 2013)</ref>. A promising result for language learning has been shown in <ref type="bibr" target="#b15">(Yu and Siskind, 2013</ref>) and a quite chal- lenging effort to describe cooking activities was made in ( <ref type="bibr" target="#b13">Regneri et al., 2013)</ref>. However, these studies rely only on visual information, while we aim to build a system that is able to describe every- day activities using multimodal information. To realize such systems, we need to consider two problems. The first problem is the sensing of daily life activities. In this paper, we utilize a smart house ( <ref type="bibr" target="#b11">Motooka et al., 2010</ref>) for sensing human activities. Thanks to the smart house, multimodal information such as visual, motion, and audio data can be captured. The second problem to be tack- led is verbalization of the observed scenes. To solve this problem, a multilayered multimodal la- tent Dirichlet allocation (mMLDA) was proposed in ( <ref type="bibr" target="#b0">Attamimi et al., 2014)</ref>.</p><p>In this paper, we propose a sentence generation system from observed scenes in a bottom up man- ner using mMLDA and a Bayesian hidden Markov model (BHMM) <ref type="bibr" target="#b6">(Goldwater and Griffiths, 2007)</ref>. To generate sentences from scenes, we need to consider the words that represent the scenes and their order. Here, mMLDA is used to infer words for given scenes. To determine the order of words, inspired by <ref type="bibr" target="#b7">(Kawai et al., 2014</ref>), a probabilis- tic grammar that considers syntactic information is learned using BHMM. In this study, the order of concepts is generated by sampling the learned grammar. The word selection for each generated concept is then performed using the observed data. Moreover, a language model that represents the re- lationship between words is also used to calculate   the transition probability between them. Consid- ering the transition probability at word level, a lat- tice of word candidates corresponding to the con- cept sequence can be generated. Therefore, sen- tence generation can be thought of as a problem of finding the word sequence that has the high- est probability from the lattice of word candidates, which can be solved by the Viterbi algorithm. Fi- nally, sampling from grammar is performed mul- tiple times to generate sentence candidates and se- lect the most probable one.</p><p>2 Proposed method 2.1 Overview <ref type="figure">Figure 1</ref> illustrates the overall system of proposed language learning and sentence generation. In this study, we use a smart environment for sens- ing multimodal information. The system shown in <ref type="figure" target="#fig_1">Figure 2</ref> is part of a smart house ( <ref type="bibr" target="#b11">Motooka et al., 2010)</ref> that is used to capture multimodal informa- tion. Here, an RFID tag is attached to an object to enable the object information to be read using a wearable tag reader. To capture motion, five sen- sors that consist of 3-axis acceleration with 3-axis gyroscope sensors are attached to the upper body, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>. Moreover, a particle filter- based human tracker ( <ref type="bibr" target="#b5">Glas et al., 2007</ref>) applied to four laser range finders is used to estimate the location of a person while performing an action. This is a setup designed to demonstrate that lan- guage can be learned and generated from real hu- man actions. Ultimately, our goal is sensing based on image recognition. The acquired multimodal data is then processed, which results in a bag-of-words model (BoW) and bag-of-features model (BoF) ( <ref type="bibr" target="#b1">Csurka et al., 2004</ref>). Using mMLDA (see section 2.2), various concepts can be formed from the multimodal data. Given teaching sentences, the connection between words and concepts can be learned based on mMLDA and BHMM which is learned with mutual infor- mation (MI) as the initial value. On the other hand, the bigram model of words is calculated and used as the score when reordering words inferred from multimodal information using grammar. A mor- phological analyzer for parsing words in a sen- tence is also necessary in the proposed system. We use publicly available parser MeCab ( <ref type="bibr" target="#b9">Kudo et al., 2004</ref>). In the future, we plan to use the unsuper- vised morphological analysis technique proposed in ( <ref type="bibr" target="#b10">Mochihashi et al., 2009</ref>). <ref type="figure" target="#fig_2">Figure 3</ref> shows the graphical model of mMLDA used in this paper. Here, z repre- sents the integrated category (concept), whereas z O , z M , and z P represent the object, mo-tion, and place concepts, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">mMLDA</head><p>In the bottom layer (lower panel of <ref type="figure" target="#fig_2">Figure 3</ref>), w m ∈ {w o , w wO , w a , w wM , w l , w wP } represents the multimodal information obtained from each object, motion, and place. Here, w o , w a , and w l denote multimodal information obtained respec- tively from the object used in an action, motion of a person while using the object, and location of the action. Further, w wC ∈ {w wO , w wM , w wP } denotes word information obtained from teaching sentences. Observation information is acquired by using the system shown in <ref type="figure" target="#fig_1">Figure 2</ref>. A brief explanation of each observation is as follows.</p><p>For object information, an</p><formula xml:id="formula_0">N o -dimensional vec- tor w o = (o 1 , o 2 , · · · , o No )</formula><p>is used, where N o de- notes the number of objects. In this vector, o * takes a value of 0 or 1, where o i is set to 1 if an object with index i is observed. Moreover, all of the teaching sentences are segmented into words and represented by a BoW as word information. Here, motion is segmented according to the ob- ject used. A sequence of 15-dimensional feature vectors for each motion is acquired. Using BoF, the acquired feature vectors are vector quantized, resulting in a 70-dimensional vector. The acquired two dimensional of human positions are processed using BoF to construct a 10-dimensional vector as place information.</p><p>In mMLDA, latent variables that represent up- per and lower concepts z and z C ∈ {z O , z M , z P } are learned simultaneously. Gibbs sampling is ap- plied to the marginalized posterior probability of latent variables to learn the model from observed data w m ( <ref type="bibr" target="#b0">Attamimi et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Language learning and generation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Word inference</head><p>In this study, word information is obtained from teaching sentences and employed for all concepts, as shown in <ref type="figure" target="#fig_2">Figure 3</ref>. Considering that appropriate words to express each concept exist, a criterion to measure the correlation between words and con- cepts is needed. At the start of grammar learn- ing, MI, which can measure the mutual depen- dence of two stochastic variables, is used. There- fore, a word is considered to express a category when the MI between the word and category is large. On the other hand, a word with small MI is identified as a functional word. This determi- nation is used as an initial value in the syntac- tic learning and needs not be strictly determined.</p><note type="other">Once the grammar is learned, we can utilize BHMM's parameters P (w w |c) to infer a word w w from observed data w m obs asˆPasˆ asˆP (w wC |w m obs , c) ∝ max k P (w wC |c)P (w wC |k)P (k|w m obs , c), where P (w wC |k) and P (k|w m obs , c) can be estimated from mMLDA (Attamimi et al., 2014) and k is category of concept c ′ ∈ {object, motion, place} and c ∈ {c ′ , f unctional}. It should be note that P (w wC |k) and P (k|w m</note><p>obs , c) are considered as uniform distribution for "functional" since they cannot be inferred from observed data using mMLDA. In this case, we can rely on syntactic in- formation which is learned by BHMM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Grammar learning using BHMM</head><p>Thanks to mMLDA and BHMM, appropriate words to represent the observed information can be inferred. Given an input consisting of a teach- ing sentence of a sequence of words, a BHMM can infer a sequence of concepts. In the learning phase, the MI results of concept selection for each word are used as the initial values of the BHMM. Here, grammar is defined as the concept transi- tion probability P (C t |C t−1 ), which is estimated using Gibbs sampling, where C t ∈ c represents the corresponding concepts of the t-th word in the sentence. In addition, a language model that rep- resent the bigram model of words in the teaching sentences is also used for generating sentences.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Motion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Eating</head><p>Throwing Hanging Acquired multimodal info. Generated sentences G: {dining room, in, cookies, the, eat} P: {dining room, in, cookies, the, eat}</p><p>Eating the cookies in the dining room.</p><p>B: {dining room, with, cookies, the, eat, eat} G: {sofa, on, ball, the, throw} P: {sofa, on, ball, the, throw}</p><p>Throwing the ball on the sofa. In each image, B, P, and G indicate the sentence structure in Japanese grammar generated by the baseline method, proposed method, and correct sentence, respectively; whereas the bottom line gives the meaning of the generated sentence. Words marked in red have been incorrectly generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Sentence generation of observed scenes</head><p>First, concepts are sampled from the begin of sen- tence "BOS" until the end of sentence "EOS" ac- cording to the learned grammar N times. Let the n-th (n ∈ {1, 2, · · · , N }) sequence of con- cepts that excludes "BOS" and "EOS" be C n = {C n 1 , · · · , C n t , · · · , C n Tn }, where, T n denotes the number of sampled concepts, which corresponds to the length of a sampled sentence.</p><p>Next, the word that corresponds to concept C n t is estimated. Here, for a given observed infor- mation w m obs , the top-K words that correspond to concept C n t and have high probabilities w n t = {w n t1 , w n t2 , · · · , w n tK } are used. Hence, the set of all words for a sequence of concepts C n can be written as W n = {w n 1 , w n 2 , · · · , w n Tn }. There- fore, K Tn number of patterns for a candidate of the sentence can be considered for C n and the cor- responding words W n . Each candidate for sen- tence S n is selected from these patterns and has the following probability:</p><formula xml:id="formula_1">P (S n |C n , W n , w m obs ) ∝ ∏ t P (C n t |C n t−1 )P (w n t |w m obs , C n t )P (w n t |w n t−1 ). (1)</formula><p>For observed information, the most probable sen- tence is selected from N sequences of concepts with sets of words. Here, the sentencê S n that maximizes Eq. (1) is determined for each se- quence of concepts. Because many patterns of S n exist, the Viterbi algorithm is applied to cut the computational cost and determine the most probable sentence. Thus, a set of sentences that consists of sentences with the highest probability for each sequence of concepts can be written asˆS asˆ asˆS</p><formula xml:id="formula_2">= { ˆ S 1 , · · · , ˆ S n , · · · , ˆ S N }.</formula><p>We can select the final sentence fromˆSfromˆ fromˆS by con- sidering the most probable candidate. In fact, long sentences tend to have low probability and are less likely to be selected. To cope with this problem, adjustment coefficient ℓ(</p><formula xml:id="formula_3">ˆ S n ) = (L max −L ˆ S n ) ∑ N n L ˆ S n ∑ N n log P ( ˆ S n |C n , W n , w m obs ) is in- troduced, where, L ˆ</formula><p>S n denotes the length of sen- tencê S n and L max represents the maximum value of the sentence length inˆSinˆ inˆS. Using ℓ( ˆ S n ), the logarithmic probability of the sentence can be calculated as log ¯ P ( ˆ S n |C n , W n , w m obs ) = log P ( ˆ S n |C n , W n , w m obs ) + ωℓ( ˆ S n ), where ω is a weight that controls the length of sen- tences. A large weight leads to longer sen- tences. The final sentence S is determined as S = argmaxˆSargmaxˆ argmaxˆS n ∈ ˆ S log ¯ P ( ˆ S n |C n , W n , w m obs ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>The acquisition system shown in <ref type="figure" target="#fig_1">Figure 2</ref> was used to capture multimodal information from hu- man actions. <ref type="table">Table 1</ref> shows the actions that were performed by three subjects twice, resulting in a total of 195 multimodal data with 1170 sentences. We then divided the data into training data (99 multimodal data with 594 sentences) and test data (96 multimodal data with 576 sentences). Some examples of acquired multimodal data are shown in <ref type="figure" target="#fig_4">Figure 4</ref>(b). Using training data, various con- cepts were formed by mMLDA, and the catego- rization accuracies for object, motion, and place were respectively 100.00%, 52.53%, and 95.96%. Motion similarity was responsible for the false cat-  egorization of motion concepts. Since our goal is to generate sentences from observed scenes, these results are used as reference instead of comparing with the baseline. To evaluate the concept selection of words, 98 words in teaching sentences were used. We com- pared the results of concept selection with hand- labeled ones. <ref type="table" target="#tab_3">Table 2</ref> shows the accuracy rate of concept selection. Here, we excluded the func- tional words (resulting in 78 words) for fair com- parison with the baseline method ( <ref type="bibr" target="#b0">Attamimi et al., 2014</ref>). One can see that, better results can be achieved by the proposed method. It is clear that concept selection is improved by using the BHMM, indicating that a better grammar can be learned using this model. Next, the learned grammar was used and sen- tences were generated. To reduce randomness of the results, sentence generation was conducted 10 times for each data. To verify sentence gener- ation quantitatively, we evaluated the sentences automatically using BLEU score ( <ref type="bibr" target="#b12">Papineni et al., 2002</ref>). <ref type="figure" target="#fig_5">Figure 5</ref> depicts the results of 2-to 4-gram of BLEU scores. Since functional words are not considered in <ref type="bibr" target="#b0">(Attamimi et al., 2014)</ref>, we used our grammar and performed sentence generation pro- posed in <ref type="bibr" target="#b0">(Attamimi et al., 2014</ref>) as the baseline method. One can see from the figure that in all cases the BLEU scores of proposed method out performs the baseline method. It can be said that the sentences generated by the proposed method are of better quality than those generated by the baseline method.</p><p>Moreover, we also manually evaluated gener- ated sentences by asking four subjects (i.e., col- lege students who understand Japanese) whether the sentences were: correct both in grammar and meaning (E1), grammatically correct but incorrect in meaning (E2), grammatically incorrect but cor- rect in meaning (E3), or incorrect both in grammar and meaning (E4). The average rates of E1, E2, E3, and E4 were shown in <ref type="table">Table 3</ref>. We can see that the proposed method out performs the base- line method by providing high rates of E1 and E2; and low rates of E4. Because we want to generate sentences that explain actions, incorrect motion in-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Grammar Meaning</head><p>Baseline Proposed E1 correct correct (23.21 ± 5.28)% (45.39 ± 3.02)% E2 correct incorrect (35.07 ± 9.32)% (49.79 ± 3.77)% E3 incorrect correct (11.34 ± 5.59)% (2.79 ± 2.39)% E4 incorrect incorrect (30.38 ± 10.54)% (2.03 ± 2.10)% <ref type="table">Table 3</ref>: Evaluation results of generated sentences. ference would lead to incorrect sentence genera- tion. Examples of E2 are "Eating the plastic wrap in the dining room" and "Opening the dressing in the kitchen." One can see that these sentences are grammatically correct but do not express the scenes correctly because the words that represent the motion are incorrect. Hence, the misclassi- fication that occurred in the motion concept for- mation was responsible for the incorrect meaning of the generated sentences. <ref type="figure" target="#fig_4">Figure 4</ref>(c) shows the sentences generated from the given scenes <ref type="figure" target="#fig_4">(Fig- ure 4(a)</ref>). We can see that meaningful yet natural sentences that explain the observed scenes can be generated using the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we proposed an unsupervised method to generate natural sentences from ob- served scenes in a smart environment using mMLDA and BHMM. In the smart environment, multimodal information can be acquired for real- istic scenarios. Thanks to mMLDA, various con- cepts can be formed and an initial determination of functional words can be made by assuming a weak connection of concepts and words calculated by MI. The possibility that grammar can be learned from BHMM by considering the syntactic infor- mation has also been shown. We conducted exper- iments to verify the proposed sentence generation, and promising preliminary results were obtained. In future work, we aim to implement a nonpara- metric Bayes model that will be able to estimate the number of concepts automatically.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Multimodal information acquisition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Graphical model of mMLDA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>BFigure 4 :</head><label>4</label><figDesc>Figure 4: Examples of: (a) actual images, (b) captured multimodal information, and (c) generated sentences. In each image, B, P, and G indicate the sentence structure in Japanese grammar generated by the baseline method, proposed method, and correct sentence, respectively; whereas the bottom line gives the meaning of the generated sentence. Words marked in red have been incorrectly generated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: BLEU scores of generated sentences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Concepts selection results.</head><label>2</label><figDesc></figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is partly supported by JSPS KAKENHI 26280096.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Integration of Various Concepts and Grounding of Word Meanings Using Multi-layered Multimodal LDA for Sentence Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Attamimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Fadlil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kasumi</forename><surname>Abe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoaki</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kotaro</forename><surname>Funakoshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takayuki</forename><surname>Nagai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE/RSJ International Conference on Intelligent Robots</title>
		<meeting>of IEEE/RSJ International Conference on Intelligent Robots</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2194" to="2201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visual Categorization with Bags of Keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriella</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">R</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jutta</forename><surname>Willamowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cédric</forename><surname>Bray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ECCV International Workshop on Statistical Learning in Computer Vision</title>
		<meeting>of ECCV International Workshop on Statistical Learning in Computer Vision</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Long-term Recurrent Convolutional Networks for Visual Recognition and Description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhashini</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno>No</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ucb/</forename><surname>Eecs</surname></persName>
		</author>
		<idno>2014-180</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">From Captions to Visual Concepts and Back</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Hao Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Forrest</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh</forename><surname>Iandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>of IEEE International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Laser Tracking of Human Body Motion Using Adaptive Shape Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><forename type="middle">F</forename><surname>Glas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takahiro</forename><surname>Miyashita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE/RSJ International Conference on Intelligent Robots</title>
		<meeting>of IEEE/RSJ International Conference on Intelligent Robots</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="602" to="608" />
		</imprint>
	</monogr>
	<note>Hiroshi Ishiguro, and Norihiro Hagita</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Fully Bayesian Approach to Unsupervised Part-ofSpeech Tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 45th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 45th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="744" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Computational Model for Syntactic Development: Identifying How Children Learn to Generalize Nouns and Verbs for Different Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Kawai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Oshima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><surname>Sasamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukie</forename><surname>Nagai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minoru</forename><surname>Asada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Joint IEEE International Conferences on Development and Learning and Epigenetic Robotics</title>
		<meeting>of Joint IEEE International Conferences on Development and Learning and Epigenetic Robotics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="78" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trans. of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Appliying Conditional Random Fields to Japanese Morphological Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaoru</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>of Conference on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="230" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bayesian Unsupervised Word Segmentation with Nested Pitman-Yor Language Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daichi</forename><surname>Mochihashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naonori</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics</title>
		<meeting>of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="100" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ubiquitous Computing House Project: Design for Everyday Life</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuhisa</forename><surname>Motooka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ichiro</forename><surname>Shiio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koji</forename><surname>Tsukada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Kambara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masato</forename><surname>Iguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Asian Architecture and Building Engineering</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="77" to="82" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BLEU: a Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics</title>
		<meeting>of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dominikus Wetzel, Stefan Thater, Bernt Schiele, and Manfred Pinkal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Regneri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="25" to="36" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Grounding Action Descriptions in Videos</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Show and Tell: A Neural Image Caption Generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.4555</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>cs.CV</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Grounded Language Learning from Video Described with Sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haonan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">M</forename><surname>Siskind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics</title>
		<meeting>of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="53" to="63" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
