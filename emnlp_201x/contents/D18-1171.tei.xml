<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Weeding out Conventionalized Metaphors: A Corpus of Novel Metaphor Annotations</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik-Lân</forename><surname>Do</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab (UKP-TUDA</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Dinh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab (UKP-TUDA</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Wieland</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab (UKP-TUDA</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gurevych</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab (UKP-TUDA</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Weeding out Conventionalized Metaphors: A Corpus of Novel Metaphor Annotations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1412" to="1424"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1412</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We encounter metaphors every day, but only a few jump out on us and make us stumble. However, little effort has been devoted to investigating more novel metaphors in comparison to general metaphor detection efforts. We attribute this gap primarily to the lack of larger datasets that distinguish between con-ventionalized, i.e., very common, and novel metaphors. The goal of this paper is to alleviate this situation by introducing a crowd-sourced novel metaphor annotation layer for an existing metaphor corpus. Further, we analyze our corpus and investigate correlations between novelty and features that are typically used in metaphor detection, such as concrete-ness ratings and more semantic features like the Potential for Metaphoricity. Finally, we present a baseline approach to assess novelty in metaphors based on our annotations.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Metaphors have received considerable interest in NLP in recent years (see <ref type="bibr" target="#b19">Shutova (2015)</ref>). Re- search questions range from direct detection of metaphors in text (linguistic metaphors) to find- ing mappings between conceptual source and tar- get domains (conceptual metaphors).</p><p>However, an important aspect of metaphors- novelty-is often overlooked, or intentionally dis- regarded. Consider the metaphors (bold) in the following examples:</p><p>(1) We all live on tight budgets, but we still need to have some fun.</p><p>(2) They were beginning to attract a penumbra of gallery-goers, as though they were offering a guided tour.</p><p>The metaphor tight budgets in (1) is an often used collocation and therefore highly conventionalized.</p><p>While the basic senses of tight-e.g., being phys- ically close together or firmly attached-conflict with the more abstract budget, the metaphoric use as meaning limited can be readily understood. In contrast, the use of penumbra in <ref type="formula">(2)</ref> is more creative and novel. Its literal meaning is "an area covered by the outer part of a shadow." <ref type="bibr">1</ref> Its metaphoric meaning is seldom encountered: Shadows follow objects that cast them, and espe- cially penumbras can be perceived as having fuzzy outlines; attributes which are picked up by the metaphorical sense of a rather unspecified group of people following someone in differing vicinity. Common linguistic metaphor definitions used in NLP ( <ref type="bibr" target="#b23">Steen et al., 2010;</ref><ref type="bibr" target="#b25">Tsvetkov et al., 2014</ref>) do not differentiate between convention- alized and novel metaphors. Some even allow for auxiliary verbs and prepositions to be anno- tated as metaphors when they are not used in their original sense (e.g., the non-spatially used on in "She wrote a study on metaphors"). While such cases can be filtered out rather easily from any given corpus-e.g., by using POS tag and lemma filters-many conventionalized metaphors persist. Existing work avoids this problem par- tially by only annotating certain grammatical con- structions, such as adjective-noun or verb-object relations ( <ref type="bibr" target="#b18">Rei et al., 2017)</ref>. However, these too usually do not distinguish be- tween conventionalized and novel metaphors.</p><p>Following <ref type="bibr" target="#b19">Shutova (2015)</ref>, we deem the dis- tinction between conventionalized and novel metaphors important, because the meaning of con- ventionalized metaphors can usually be found in dictionaries or other resources like WordNet- novel metaphors on the other hand pose a more difficult challenge. But the lack of resources incor- porating this distinction leads to few researchers investigating novel metaphors, or the related mea- sure of metaphoricity. They use small datasets that have been manually annotated by experts <ref type="bibr" target="#b4">(Del Tredici and Bel, 2016)</ref>, or focus crowdsourcing studies on a small number of instances <ref type="bibr" target="#b5">(Dunn, 2014)</ref>. It is only recently that any work has in- troduced larger-scale novel metaphor annotations <ref type="bibr" target="#b16">(Parde and Nielsen, 2018)</ref>. In contrast to our ap- proach, they collect annotations on a relation level (see also Section 2).</p><p>Annotating metaphors is not an easy task, due to the inherent ambiguity and subjectivity. There- fore, we investigate approaches for annotating novelty in metaphors, before closing the resource gap for token-based annotations by creating a layer of novelty scores.</p><p>Our contributions are the following:</p><p>(1) We augment an existing metaphor corpus by assessing metaphor novelty on a token level using crowdsourcing, enabling larger research on novel metaphors, (2) we analyze our corpus for correlation with features used for general metaphor detection or metaphoricity prediction, and (3) we show that a baseline approach based on features usually used for (binary) metaphor detection can be useful for distinguishing novel and conventionalized metaphors.</p><p>In Section 2, we first discuss annotation guide- lines that have been used for existing datasets, as well as prior work on novel metaphor detection and crowdsourcing in NLP. This discussion is fol- lowed by Section 3, where we detail the base cor- pus and the crowdsourced creation of our annota- tion layer. In Section 4, we describe our baseline for detecting novel metaphors and its results. We conclude in Section 5 with a summary of our con- tributions, and an outlook of what our newly intro- duced layer of annotations can enable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Annotating metaphors is a difficult task, because there is no single definition that can be adhered to. Instead, different researchers formulate their own versions, which can vary quite substantially.</p><p>The Pragglejaz Group (2007) created influen- tial metaphor annotation guidelines, the Metaphor Identification Procedure (MIP). After reading a text, an annotator assesses each token as being used metaphorically or not; i.e., if the token has a more basic meaning that can be understood in comparison with the one it expresses in its current context. More basic is described as being:</p><p>• More concrete; what they evoke is easier to imagine, see, hear, feel, smell, and taste.</p><p>• Related to bodily action.</p><p>• More precise (as opposed to vague).</p><p>• Historically older.</p><p>They note that this basic meaning does not nec- essarily have to be the most frequent one. An extended version, MIPVU, was used to annotate parts of the British National Corpus (BNC Consor- tium, 2007, BNC), resulting in the VU Amsterdam Metaphor Corpus ( <ref type="bibr">Steen et al., 2010, VUAMC)</ref>. <ref type="bibr" target="#b21">Shutova and Teufel (2010)</ref> adapt the MIP as a pre- requisite to annotating source and target domains of metaphor-the metaphoric mapping-in parts of the BNC. Others use rather relaxed guidelines. <ref type="bibr" target="#b25">Tsvetkov et al. (2014)</ref> rely on intuitive definitions by their annotators, not specifying metaphor more closely. They ask their annotators to mark words that "are used non-literally in the following sentences." <ref type="bibr" target="#b8">Jang et al. (2015)</ref> provide a Wikipedia definition of metaphor to users in a crowdsourcing study. Sub- sequently, the users are tasked with annotating fo- rum posts by deciding "whether the highlighted word is used metaphorically or literally."</p><p>A common trait of the listed works is that they do not distinguish between nuances of metaphoricity. Instead, they impose a binary scheme (metaphoric/literal) on the rather diffuse language phenomenon of metaphor. In contrast, Dunn (2014) introduces a scalar measurement of metaphoricity on a sentence level. He created a corpus of 60 genre-diverse sentences with varying levels of metaphoricity, which are rated in three crowdsourcing experiments: a binary selection, a ternary selection, and an ordering approach. The mean value for each sentence is then used as the metaphoricity value. <ref type="bibr" target="#b5">Dunn (2014)</ref> uses this data to derive a computational measure of metaphoricity, which he then employs in an unsupervised system to label metaphoric sentences in the VUAMC. The evaluation, however, is only done on the binary la- bels provided therein.</p><p>In a similar direction, Del <ref type="bibr" target="#b4">Tredici and Bel (2016)</ref>  , and nouns. For the purpose of this table, metaphors with a novelty score higher than T = 0.5 are considered novel (the possible range is <ref type="bibr">[-1,1]</ref>).</p><p>Metaphoricity (POM) of verbs. The POM de- scribes the inherent potential of a verb to take on a metaphoric meaning, derived from its distribu- tional behavior. They infer that low-POM verbs are only able to have low degrees of metaphoricity, thus can only evoke conventionalized metaphors. Therefore, they propose to exclude such low-POM verbs from novel metaphor detection systems. <ref type="bibr" target="#b6">Haagsma and Bjerva (2016)</ref> use violations of selectional preferences <ref type="bibr" target="#b27">(Wilks, 1978)</ref> to find novel metaphors. Selectional preferences describe which semantic classes a verb prefers as its direct object. Since they are often mined from large cor- pora and based on frequency, they argue that this feature is more suited for novel metaphor detec- tion than for general detection of (also convention- alized) metaphors. They evaluate their approach on the VUAMC; however, they acknowledge that their usage of this corpus is not optimal because it contains many conventionalized metaphors.</p><p>Parde and Nielsen (2018) create a corpus of novel metaphor annotations. For their crowd- sourced annotation, they use a scale with four op- tions. Unlike our approach, they annotate rela- tions between words as novel or conventionalized. On the one hand, this is a sensible approach be- cause generally the context of a word determines its metaphoricity (and indeed, its novelty in case of metaphoric use). On the other hand, such anno- tations lack the flexibility and ease of use of token- based annotations for which the context is not de- fined a priori.</p><p>We tackle the lack of data by annotating an ex- isting corpus using crowdsourcing; i.e., by split- ting up the task in many small chunks which different, non-expert annotators are instructed to complete. Crowdsourcing has been used for a va- riety of annotation tasks in NLP, often using dif- ferent study designs. <ref type="bibr" target="#b22">Snow et al. (2008)</ref> obtain good annotation results for five tasks with dif- ferent setups: two tasks ask for numerical val- ues (affect recognition, word similarity), two other tasks require a binary decision (textual entailment recognition, event ordering), and a final task pro- vides three options for the annotators (word sense disambiguation). <ref type="bibr" target="#b24">Sukhareva et al. (2016)</ref> utilize crowdsourcing to annotate semantic frames. They design their task as a decision tree, with annotators moving down the tree when annotating.  use crowdsourcing for metaphor and emotion annotation in order to investigate their correlation. They employ an ordering ap- proach to annotation, and only consider verbs that already contain a metaphoric sense in WordNet. <ref type="bibr" target="#b9">Kiritchenko and Mohammad (2016)</ref> obtain anno- tations for sentiment associations via crowdsourc- ing. They use Best-Worst Scaling <ref type="bibr" target="#b12">(Louviere and Woodworth, 1990)</ref>, an annotation approach which creates scores from ranking annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Corpus</head><p>To obtain a corpus of novel metaphor annotations, we employ an existing metaphor corpus. This can potentially reduce ambiguity for annotators and allows us to focus on the creation of nov- elty scores. We use the VU Amsterdam Metaphor Corpus ( <ref type="bibr" target="#b23">Steen et al., 2010</ref>) as the base corpus for our novelty annotations due to its compara- bly large size and genre diversity. It is comprised of over 200,000 tokens from four genres: aca- demic, fiction, and news texts, and conversation transcripts <ref type="table">(Table 1)</ref>. Further, reusing existing an- notations enables us to only query annotators for novelty of already annotated metaphors, instead of having them analyze every token.</p><p>Using crowdsourcing (Amazon Mechanical Turk), we first conduct a pilot study to choose among four different annotations methods. We then employ the best method to collect annotations and create an additional novelty score between 1 (novel) and −1 (conventionalized) for each token labeled as metaphor in the VUAMC. Note that non-content words like prepositions and auxiliary verbs (have, be, do) are filtered out beforehand. Our annotations/scores can be integrated into the original VUAMC resource. We make the annota- tions and scripts to embed them into the original corpus publicly available. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pilot Study</head><p>Similar to <ref type="bibr" target="#b5">Dunn (2014)</ref>, we consider multiple an- notation approaches. We compare them in a pilot study using 210 metaphor tokens with their sen- tence context, randomly chosen from the fiction subcorpus. For the sake of a meaningful evalua- tion, we ensured that 25% of these metaphorically used tokens were novel metaphors. Before choos- ing one approach for the entire corpus, we com- pare the following four annotation approaches:</p><p>• binary annotation: crowd workers decide if a given metaphoric token is used in a novel or conventionalized way;</p><p>• scale annotation: crowd workers decide on the novelty of a given metaphoric token on a four-point scale, from very novel to very con- ventionalized;</p><p>• scale annotation (no metaphor): crowd workers decide on the "unusualness" of a given token in its context on a four-point scale, from I've never heard it before to I'm using it everyday; without giving information that the tokens represent metaphors;</p><p>• best-worst scaling: crowd workers pick the most novel and the most conventionalized metaphor from four samples.</p><p>Conceptually, the binary annotation should put the least cognitive load on the annotator, resulting in fast annotation times and efficient completion of the task. However, this method does not allow for nuances in annotation. <ref type="bibr" target="#b5">Dunn (2014)</ref> counters this problem by assigning as the score the percentage of "metaphoric" labels for an instance. But this solution is only feasible for smaller datasets, as it requires many annotations per instance to yield nuanced scores.  Comparison of the approaches investi- gated in the pilot study. Shown are inter-annotator agreement (Krippendorff's α, after mapping the scale annotations to binary labels), evaluation against our silver standard (F 1 ), and average com- pletion time for an assignment (in case of binary, scale, and scale without metaphor this amounts to one decision, for BWS to two). Note that there is no IAA for the BWS approach because no two tuples are the same.</p><p>The next two approaches, scale annotation and scale annotation (no metaphor), try to mitigate this problem by introducing four options to choose from. We choose a scale of four instead of three options to force the annotators to indicate a pref- erence, rather than allowing a "neutral" answer. The difference between both scale approaches is in the guideline descriptions; for the second scale approach (no metaphor), we remove any mention of metaphor, and instead use paraphrases (e.g., in- stead of "novel metaphor" we use "I have not seen it before"). Our motivation behind this rephrasing is that we want to avoid confusion especially with regards to very conventionalized metaphors. By strictly asking for novelty of the expression/usage, we potentially simplify the task for the annotator.</p><p>The last approach uses best-worst scaling (BWS, see also Section 2). It has the advantage of not explicitly asking the annotator for a deci- sion on a singular token/metaphor. Instead, they are asked to compare (four) different metaphors and select the most novel and the most conven- tionalized. A disadvantage is the higher workload for the annotator, since they have to read four sen- tences for one assignment.</p><p>In <ref type="table" target="#tab_2">Table 2</ref>, we give a short overview of inter- annotator agreement (Krippendorff's α), the av- erage completion time of an assignment, and a comparison with our semi-automatically created silver standard (F 1 ). The latter is built by using the majority vote of all four methods; ties are re- solved manually by looking into the individual an-notations. To obtain binary labels from the two scale approaches for majority voting, we map the two "more novel" options to novel, and the other two options to conventionalized. For the BWS approach, we first average the number of novel metaphors from the other three methods. From a sorted, decreasing list of BWS scores we then mark this many metaphors as novel. We compare against our own annotations as a sanity check.</p><p>Regarding completion time, we observe that the scale method is the fastest by a wide margin. This discrepancy is somewhat surprising, as the scale method introduces two more options to consider compared to the binary method. Apparently, these additional, intermediate options make it easier for annotators to come to a decision, especially for edge cases. On the other hand, scale without metaphors takes twice as long as the scale method. The latter only differs from the former in its inclu- sion of metaphor in the task description and the la- bels, which we thus interpret as creating a setting for the annotators where they may expect to have some kind of intuition about the task, and thus are more confident (and faster) in completing. Given the long completion time in conjunction with the lower F 1 score and the very low IAA, it seems clear that omitting the metaphor information and using a more colloquial task description make the scale annotation (no metaphor) by far the most dif- ficult for workers to complete, resulting in the least usable annotations. While best-worst scaling is time consuming as well, it yields the best results with regards to the silver standard (F 1 = 0.84) by a large margin. We thus choose BWS for annotating the full corpus. Further details on the pilot study can be found in Wieland (2018).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Corpus Creation</head><p>We design our guidelines (see Appendix A) to be simple, but include redundancy in the description to address frequent misunderstandings and ambi- guities. We also explicitly mention idioms and unrecognizable metaphors as cases of convention- alized metaphors, because these were sources of confusion in our pilot study. Unrecognizable here means that a word is used in an established, com- monly understood-but not the most concrete- sense; e.g., hard in "She fought hard." Addi- tionally, the annotators are provided with example metaphors of differing novelty.</p><p>After filtering out prepositions and auxiliary verbs (have, be, do) using the POS tags supplied by the VUAMC, we collect annotations covering 15,180 metaphors in total <ref type="table">(Table 1)</ref>. We only in- clude workers located in the US. For creation of the best-worst scaling tuples, and for aggregation of the annotations, we use the scripts provided by <ref type="bibr" target="#b9">Kiritchenko and Mohammad (2016)</ref>. <ref type="bibr">3</ref> We use a best-worst scaling factor of 1.5 and four items per tuple. Thus, each metaphor appears in six differ- ent best-worst scaling comparisons. This results in 22,770 best-worst scaling items to be annotated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis</head><p>Overall statistics about our created annotations are shown in <ref type="table">Table 1</ref> (along with the already existing annotations). For the sake of this overview, we in- troduce a threshold T = 0.5, and treat metaphors with a BWS score equal to or above this thresh- old as novel, metaphors with a BWS score below the threshold as conventionalized. However, since we provide the scores, this threshold can be adjusted to suit a given application. Note that, while novel metaphors are arguably much more scarce than conventionalized ones, BWS creates scores which are approximately normally distributed, support- ing our threshold choice. Before we conduct a more in-depth analysis of the annotated metaphors, we show some exam- ples. In <ref type="table" target="#tab_3">Table 3</ref>, we list four novel and four con- ventionalized metaphors (as annotated). A good example for a novel metaphor is the description of "words [...] as a coat-hanger" in <ref type="table" target="#tab_3">Table 3 (3)</ref>. This usage cannot be found in dictionaries, and clearly constitutes creative language use. In con- trast, the meaning to experience something bad of to go through [a situation] (ibid., <ref type="formula">(7)</ref>), or the sense to do/conduct of to get <ref type="bibr">[something]</ref> done (ibid., (5)), are strongly conventionalized, as indicated by their inclusion in dictionaries. <ref type="bibr">4</ref> We also group the tokens by lemma to exam- ine if certain words are more likely to be used in a novel metaphoric way. Inspecting the mean no score metaphor in context</p><p>(1) 0.765 Ron Todd <ref type="bibr">[...]</ref> warned that party leaders could not expect everybody to 'goose-step' in the same direction once the policy had been carried. <ref type="formula">(2)</ref> 0.750 Westerns have a gladiatorial, timeless quality. <ref type="formula">(3)</ref> 0.735 Allan Ahlberg says: 'In the past, a lot of children's books seemed to be the work of talented illustrators whose pictures looked brilliant framed in a gallery, but when you tried to read the book, there was nothing there, because the words started as a coat-hanger to hang pictures on.' (4) 0.727 thus one can and must say ... that each fight is the singularisation of all the circum- stances of the social whole in movement and that by this singularisation, it incarnates the enveloping totalization which the historical process is.</p><p>(5) −0.765 If the complaint is proved, a nuisance order is made requiring the defendant to get the necessary work done. (6) −0.765 Apart from some dark patches on the wall that he hadn't noticed before, there was nothing to see. (7) −0.774 In relation to the sentence stem 'A girl and her mother ...', girls often produce responses like 'often go through a bad patch for a year but once they learn to understand each other, become the best of friends' or 'can help each other with their problems'. (8) −0.871 The analyst is then forced on the defensive, explaining why new features can not be included because they are technically difficult or prohibitively expensive.  Further, we investigate how novelty is dis- tributed over the different subcorpora (also see <ref type="table">Table 1</ref>). Somewhat expectedly, the metaphors used in the academic subcorpus are mostly con- ventionalized (1.9% novel metaphors). A larger percentage of novel metaphors can be found in the news (2.8%) and fiction (3.0%) subcorpora. The conversation subcorpus shows the least amount of novel metaphors (1.3%), which we interpret as natural-more novel metaphors require some amount of creativity to create, which is arguably easier in writing. We also show the distribution of novel metaphors across POS tags (  Correlation with Token Frequency We com- pare how the token frequency is related to nov- elty. Intuitively, words that are seldom used should show a higher (average) novelty. In turn, we ex- pect often used words to exhibit a wider range of (already conventionalized) senses, thus having lower (average) novelty. We obtain token fre- quencies from a Wikipedia dump, and correlate them with the mean novelty scores from our an- notations (disregarding part-of-speech tags). The relation in terms of Spearman's rank correlation is ρ = −0.60, which indicates a moderate anti- correlation. This can also be observed in <ref type="figure" target="#fig_2">Figure 1</ref>: while high frequency seems to hint at convention- alized metaphors, low frequency is not necessarily Since we use the automatically created POS tags from the VUAMC to filter out non-content tokens, this can include erroneously tagged tokens. For an improved overview, we manually filtered out the five most frequent, incorrectly tagged tokens from this plot <ref type="bibr">(to, as, on, that, and this)</ref>.</p><p>an indication of novelty of metaphoric use. Two prominent exceptions are the tokens na- tional and united <ref type="figure" target="#fig_2">(Figure 1, upper right)</ref>. While they show comparatively high novelty (both la- beled as metaphorical only once in the VUAMC), they appear surprisingly often in Wikipedia. An- other artifact of using Wikipedia as the back- ground corpus can be seen on the left: try is only annotated as metaphoric in infinitive-compounds that are decidedly conventionalized (e.g., "trying to look"), yet it appears comparatively seldom in Wikipedia. However, we chose to use Wikipedia instead of the BNC in order to have an out-of- domain comparison with a more contemporary, larger background corpus.</p><p>Correlation with Concreteness The use of con- creteness as a feature in automatic metaphor detec- tion grounds in the Conceptual Metaphor Theory ( <ref type="bibr" target="#b10">Lakoff and Johnson, 1980)</ref>. In short, metaphors are modeled as cognitive mappings between an of- ten concrete source domain, and a usually more abstract target domain. For example, in "He shot down my arguments," the more concrete domain of ARMED CONFLICT (shot) is mapped to the rather abstract domain <ref type="bibr">DISCUSSION (argument)</ref>.</p><p>To analyze the relation between novelty and concreteness, we first extend the concreteness list by <ref type="bibr" target="#b3">Brysbaert et al. (2014)</ref> using a technique sim- ilar to <ref type="bibr" target="#b15">Mohler et al. (2014)</ref>. For a given token t, we extract 20 approximate nearest neighbors nn(t) from Google News Embeddings ( <ref type="bibr" target="#b13">Mikolov et al., 2013</ref>) using Annoy. <ref type="bibr">5</ref> The concreteness value for t is then computed by averaging its neighbors' con- creteness values from the concreteness list.</p><p>Subsequently, we calculate the correlation be- tween the average novelty and the concreteness of the lemmas. Both Pearson correlation (r = 0.04) and Spearman's rank correlation (ρ = 0.03) are close to zero and indicate no correlation <ref type="figure" target="#fig_3">(Fig- ure 2)</ref>. Thus, while concreteness has been shown to work well as a feature to distinguish between lit- eral and non-literal language in general <ref type="bibr" target="#b1">(Beigman Klebanov et al., 2014;</ref><ref type="bibr" target="#b25">Tsvetkov et al., 2014</ref>), it does not seem useful for discerning between novel and conventionalized metaphoric usage in partic- ular. For example, the rather abstract now (1.48) and the very concrete people (4.82) are assigned similarly low novelty scores. On the other hand, justice has a quite high novelty score (0.65), while also being as abstract as now. One reason for this non-correlation between concreteness and novelty might be that the automatic induction of concrete- ness ratings introduces too much noise. However, an experiment where we only use tokens occur- ring in the manually composed list <ref type="bibr" target="#b3">(Brysbaert et al., 2014</ref>) shows similarly low correlation. This could be influenced by artifacts in the concrete- ness list: as laid out by Beigman <ref type="bibr" target="#b0">Klebanov et al. (2015)</ref>, it exhibits some problems. For exam- ple, it shows high variance in the annotated con- creteness scores for various non-concrete adjec- tives. But this does not explain the extent of the non-correlation. We thus believe that our results indeed indicate no relation between concreteness and metaphor novelty. And indeed, if a difference of concreteness between components of an expres- sion hints at a metaphor, as is proposed by the con- ceptual metaphor theory, then it is plausible that it does not hint at novelty of the metaphoric expres- sion at the same time. Consequently, we investi- gate a feature with more semantic capacity in the next subsection.</p><p>Correlation with POM The Potential for Metaphoricity (POM) of verbs was introduced by Del Tredici and Bel (2016) (Section 2). It denotes the a priori chance of a verb to occur in highly metaphoric contexts; in essence, it measures the contextual flexibility of a verb. Generally, very novel metaphors also display a high metaphoricity. Therefore, we expect that low-POM verbs (i.e., verbs that occur similarly often in many different contexts) exhibit a low novelty score on average and low variance, while high-POM verbs should show a higher average novelty score. The POM can be regarded as a variant of selectional pref- erence strength, which measures how strongly a verb constrains its direct object in terms of seman- tic classes. As such, we forgo an analysis of selec- tional preference violations in favor of examining the POM. <ref type="bibr" target="#b7">Hovy et al. (2013)</ref> generalize the notion of selectional preferences to other forms of gram- matical relations. However, instead of generating scores, they use dependency trees in an SVM with tree kernels. The POM could be similarly gener- alized to all POS tags, e.g., by including head and dependent tokens as context.</p><p>We create the POM for all annotated verbs using the same procedure as Del <ref type="bibr" target="#b4">Tredici and Bel (2016)</ref>. First, we extract the context (i.e., subject and ob- ject) for each occurrence of a verb from a large, parsed corpus (Wikipedia). To compute context vectors, the word embeddings ( <ref type="bibr" target="#b11">Levy and Goldberg, 2014</ref>) of subject and object are averaged (if only one of the two is available, the embedding for this token serves as the context). For each verb, the context vectors are then clustered using Birch clustering ( <ref type="bibr" target="#b28">Zhang et al., 1996)</ref>. Finally, the standard deviation between the sizes of the context clusters denotes the POM of the verb.</p><p>As with our previous experiments, we com- pute Spearman's rank correlation between the mean novelty scores of the verb lemmas and the corresponding POMs. We arrive at Spearman's ρ = 0.52, which indicates moderate correlation ( <ref type="figure" target="#fig_4">Figure 3</ref>). Verbs like pique (POM: 0.218) and slit (0.134) are more often used in a novel metaphoric way, while low-POM verbs show and see (both: 0.01) are only used as conventional metaphors. Even though the correlation is only moderate, it supports the WordNet-based evaluation by Del <ref type="bibr" target="#b4">Tredici and Bel (2016)</ref>, who found that high- POM verbs generally induced novel metaphoric sentences. Note that their POM values are higher because they optimize the clustering parameters, which we leave at the default setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Baseline</head><p>While the main focus of this work is the analysis of our new annotation layer, we also create a simple baseline regression system for predicting the nov- elty scores. We run the system using two configu- rations: first with only word embeddings as input, then augmented with frequency and POM scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">System</head><p>We implement a single-layer BiLSTM for predict- ing the novelty score. As input, we use a padded 11-token window (five before, five after the token) of dependency-based word embeddings by <ref type="bibr" target="#b11">Levy and Goldberg (2014)</ref> that we also employed for the POM computation. The BiLSTM layer has 50 dimensions and ReLu activation. Training is done in maximally 20 epochs, but can halt earlier due to early stopping on the development set. The data is split into training (50%), development (25%), and test set (25%). We only conduct experiments on verbs, so that we can compare the performance when including additional features.</p><p>Following our analysis of typically used fea- tures for metaphor detection in relation to novelty, we incorporate the relative frequency of a token into the model, to investigate if the substantial cor- relation observed in Section 3.3 has an impact on our regression experiments. Further, we include the POM, as it also showed a moderate correlation with novelty. Both additional features are concate- nated with the respective word embeddings and the resulting vectors are fed to the BiLSTM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>We evaluate our results using mean absolute error (MAE), and average it over 10 runs with different random seeds. Recall that the possible values lie between −1 and 1, leading to a possible MAE be- tween 0 (best) and 2 (worst). The baseline results over different runs are stable, we show the regres- sion plot for one configuration in <ref type="figure" target="#fig_5">Figure 4</ref>.</p><p>The mean absolute error for the configuration using only the embeddings is MAE = 0.166. In contrast, we obtain MAE = 0.163 for the same configuration when we add the frequency and the POM features. Thus, while small, the latter model shows improvements over the word embedding baseline. As can be seen in the plot, there is still much room for improvement (e.g., we did not conduct extensive hyper-parameter optimization). The network makes errors both in underestimat- ing ("they can be seen as riddled with holes") and overestimating novelty ("veins branching off it to form a network"). These errors are in many cases independent from POM and frequency fea- tures. Thus, while a better optimization (e.g., in the clustering step when creating the POM) might reduce estimation errors, we also need to consider further features for metaphor novelty estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented a new layer of novelty scores for the VU Amsterdam Metaphor Corpus, created us- ing crowdsourcing. To this end, we conducted a pilot study to choose an appropriate method for metaphor novelty annotation and found that best-worst scaling outperformed binary and scale methods. Our corpus analysis of typically used features for metaphor detection showed no cor- relation of novelty with concreteness. However, we found substantial correlation with frequency of tokens in a background corpus and with po- tential for metaphoricity, a context-based a pri- ori metaphoricity measure. Further, we created a baseline to distinguish novel from conventional- ized metaphors. For our approach, the latter two features could improve results only slightly, indi- cating a need for more sophisticated features.</p><p>Previous work in automatic metaphor process- ing has largely focused on general detection of linguistic and conceptual metaphors, mostly dis- regarding the subject of novelty. Our corpus en- ables new evaluation and training possibilities for detecting the latter. In future work, we want to develop more sophisticated methods to detect and distinguish novel metaphors. For example, we want to extend the notion of POM to nouns and adjectives, and investigate other a priori measures for metaphor novelty. Further, we want to jointly detect metaphors and score their novelty. Another interesting direction is to investigate the correla- tion between perceived novelty and the existence of dictionary definitions for metaphoric senses of a token or expression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Guidelines</head><p>This task is about metaphors. A metaphor is a figure of speech that describes one thing by mentioning another thing. You can divide metaphors into two types: conventional and novel ones. In the following texts some words are marked as metaphorical. You will be given four metaphors and your task is to decide which metaphor is the most conventional and which metaphor is the most novel. Conventional metaphors are metaphors which are often used in everyday language. In contrast novel metaphors which are usually not used in everyday language. Please check the instructions and examples below before starting with the HIT! Instructions and hints:</p><p>• Please read the whole context around the metaphors before deciding which metaphor is most novel or most conventional.</p><p>• You have to answer two questions per task:</p><p>The first question is which metaphor is most conventional. That means you have to select the metaphor which is the most common in everyday language.</p><p>The second question is which metaphor is the most novel. That means you have to select the metaphor that is the most uncommon in everyday language.</p><p>• Expressions that are so common that you cannot recognize them as a metaphor are candidates for the most conventional metaphor.</p><p>• Idioms are rather conventional metaphors.</p><p>• Each task is about four metaphors which are marked in red.</p><p>• The sentence which contain the metaphor are highlighted in bold letters.</p><p>• You have to fully complete all three tasks to get paid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Examples:</head><p>1: "She gave him that idea."</p><p>2: "I see the point."</p><p>3: "Some books have to be tasted."</p><p>4: "Time flies."</p><p>• Answer: most conventional metaphor: gave (1); most novel metaphor: tasted (4).</p><p>• Explanation: "gave" is in the expression "to give someone an idea" so common that you can barely see the metaphor, that means it is extremely conventional. "to taste books" in contrast is a very uncommon use of the word "taste" and thus a novel metaphor. The other two metaphors are idioms which are conventional but not as conventional as "to give someone an idea.". B Example of a Best-Worst Scaling HIT <ref type="figure">Figure 6</ref>: Example of a best-worst scaling HIT, where annotators were asked to choose the most novel and the most conventionalized metaphor among 4 instances.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>For example, in this way the metaphor "[...] the artistic tem- perament which kept her tight-coiled as a spring [...]" (0.514) is treated as novel, while "To quench [thirst] is more than to refresh [...]" (0.424) is treated as conventionalized.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>scores</head><label></label><figDesc>, we see the large conventionalization of words such as get (−0.37), see (−0.35), or new (−0.35). Examples for words used in a mostly novel way are envelop (0.53), incarnate (0.50), and thrust (0.46). In the following sections, we ex- amine the correlations with frequency and POM, which give further weight to the examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Frequency. Relation between average novelty score of metaphoric tokens and their frequency in Wikipedia (correlation of ρ = −0.60). Since we use the automatically created POS tags from the VUAMC to filter out non-content tokens, this can include erroneously tagged tokens. For an improved overview, we manually filtered out the five most frequent, incorrectly tagged tokens from this plot (to, as, on, that, and this).</figDesc><graphic url="image-1.png" coords="7,73.09,62.81,216.09,173.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Concreteness. Relation between novelty score of metaphoric tokens and their concreteness, showing no discernible correlation (ρ = 0.03). A similar picture emerges if we only consider the manually annotated tokens included in the original concreteness list by Brysbaert et al. (2014).</figDesc><graphic url="image-2.png" coords="7,308.37,62.81,216.09,164.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: POM. Relation between average novelty score of verb lemmas and POM (correlation of ρ = 0.52).</figDesc><graphic url="image-3.png" coords="8,73.09,62.81,216.09,162.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Predicted and actual novelty score of metaphoric tokens in the VUAMC for a baseline configuration (word embeddings only, without adding frequency and POM information).</figDesc><graphic url="image-4.png" coords="9,307.28,62.81,218.27,163.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Annotation guidelines for best-worst scaling HITs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Example uses of very novel and very conventionalized annotated metaphorical tokens (bold) in sentence context, according to our aggregated annotations. Scores near 1 denote strong novelty, scores near −1 indicate very conventionalized metaphors.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 )</head><label>4</label><figDesc>. It is striking that the verbs are least represented among the novel metaphors, especially compared to their overall metaphoric occurrence. In contrast, adjec- tives/adverbs and nouns are more likely to be used in a novel way.</figDesc><table>POS 
tokens metaphors 
novel 
metaphors 

nouns 
47,171 
5,513 
145 
verbs 
27,831 
6,513 
88 
adj/adv 45,842 
3,154 
120 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Metaphor annotations grouped by POS 
tags. For this overview, we treat metaphors with 
a score above T = 0.5 as novel. 

</table></figure>

			<note place="foot" n="1"> https://www.macmillandictionary.com/dictionary/ american/penumbra</note>

			<note place="foot" n="2"> https://github.com/UKPLab/ emnlp2018-novel-metaphors</note>

			<note place="foot" n="3"> http://saifmohammad.com/WebPages/BestWorst.html 4 e.g., https://www.macmillandictionary.com/dictionary/ american/go-through#go-through 7, https://www.macmillandictionary.com/dictionary/american/ get#get 60</note>

			<note place="foot" n="5"> https://github.com/spotify/annoy</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work has been supported by the German Fed-eral Ministry of Education and Research (BMBF) under the promotional reference 01UG1816B (CEDIFOR).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Supervised Word-Level Metaphor Detection: Experiments with Concreteness and Reweighting of Examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chee Wee</forename><surname>Beata Beigman Klebanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Metaphor in NLP</title>
		<meeting>the Third Workshop on Metaphor in NLP<address><addrLine>Denver, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Different Texts, Same Metaphors: Unigrams and Beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chee Wee</forename><surname>Beata Beigman Klebanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Metaphor in NLP</title>
		<meeting>the Second Workshop on Metaphor in NLP<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="11" to="17" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The British National Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bnc Consortium</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>version 3 (BNC XML Edition</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brysbaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><forename type="middle">Beth</forename><surname>Warriner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Kuperman</surname></persName>
		</author>
		<title level="m">Concreteness Ratings for 40 Thousand Generally Known English Word Lemmas. Behavior Research Methods</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="904" to="915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Assessing the Potential of Metaphoricity of Verbs Using Corpus Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Del Tredici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Núria</forename><surname>Bel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2016</title>
		<meeting>LREC 2016<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4573" to="4577" />
		</imprint>
	</monogr>
	<note>European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Measuring Metaphoricity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Dunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2014</title>
		<meeting>ACL 2014<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="745" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Detecting Novel Metaphor Using Selectional Preference Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hessel</forename><surname>Haagsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Bjerva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Metaphor in NLP</title>
		<meeting>the Fourth Workshop on Metaphor in NLP<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="10" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Identifying Metaphorical Word Use with Tree Kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujay</forename><surname>Kumar Jauhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinmaya</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Whitney</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Metaphor in NLP</title>
		<meeting>the First Workshop on Metaphor in NLP<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="52" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Metaphor Detection in Discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeju</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghwan</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohan</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolyn</forename><forename type="middle">Penstein</forename><surname>Rosé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGDIAL 2015</title>
		<meeting>SIGDIAL 2015<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="384" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Capturing Reliable Fine-Grained Sentiment Associations by Crowdsourcing and Best-Worst Scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of NAACL-HLT 2016</title>
		<meeting>eeding of NAACL-HLT 2016<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="811" to="817" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Metaphors We Live By</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Lakoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Chicago University Press</publisher>
			<pubPlace>Chicago, IL, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">DependencyBased Word Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2014</title>
		<meeting>ACL 2014<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Best-worst Analysis. Working paper. Department of Marketing and Economic Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">G</forename><surname>Louviere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Woodworth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
		<respStmt>
			<orgName>University of Alberta</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS 2013</title>
		<meeting>NIPS 2013<address><addrLine>Stateline, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Metaphor as a Medium for Emotion: An Empirical Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Shutova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of *SEM 2016</title>
		<meeting>*SEM 2016<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="23" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-Supervised Methods for Expanding Psycholinguistics Norms by Integrating Distributional Similarity with the Structure of WordNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bracewell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Rink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2014</title>
		<meeting>LREC 2014<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Corpus of Metaphor Novelty Scores for SyntacticallyRelated Word Pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathalie</forename><surname>Parde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rodney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2018</title>
		<meeting>LREC 2018<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1535" to="1540" />
		</imprint>
	</monogr>
	<note>European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">MIP: A Method for Identifying Metaphorically Used Words in</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pragglejaz</forename><surname>Group</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discourse. Metaphor and Symbol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Grasping the Finer Point: A Supervised Similarity Network for Metaphor Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luana</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2017</title>
		<meeting>EMNLP 2017<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1538" to="1547" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Design and Evaluation of Metaphor Processing Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="579" to="623" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Black Holes and White Rabbits: Metaphor Identification with Visual Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Maillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2016</title>
		<meeting>NAACL-HLT 2016<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="160" to="170" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Metaphor Corpus Annotated for Source-Target Domain Mappings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2010</title>
		<meeting>LREC 2010<address><addrLine>Valetta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3255" to="3261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cheap and Fast-But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2008</title>
		<meeting>EMNLP 2008<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="254" to="263" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A Method for Linguistic Metaphor Identification. From MIP to MIPVU</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><forename type="middle">J</forename><surname>Steen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aletta</forename><forename type="middle">G</forename><surname>Dorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Berenike</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Kaal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tina</forename><surname>Krennmayr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trijntje</forename><surname>Pasma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>John Benjamins Publishing Company</publisher>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Crowdsourcing a Large Dataset of Domain-Specific Context-Sensitive Semantic Verb Relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Sukhareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Eckle-Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2016</title>
		<meeting>LREC 2016<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2131" to="2137" />
		</imprint>
	</monogr>
	<note>European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Metaphor Detection with Cross-Lingual Model Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Boytsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatole</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2014</title>
		<meeting>ACL 2014<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="248" to="258" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Crowd-Sourcing Novel Metaphor Annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Wieland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>TU Darmstadt</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Bachelor Thesis</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Making Preferences More Active</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yorick</forename><surname>Wilks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="197" to="223" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">BIRCH: An Efficient Data Clustering Method for Very Large Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghu</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miron</forename><surname>Livny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGMOD 1996</title>
		<meeting>SIGMOD 1996<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="103" to="114" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
