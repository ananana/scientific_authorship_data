<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Has Machine Translation Achieved Human Parity? A Case for Document-level Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Läubli</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computational Linguistics</orgName>
								<orgName type="institution">University of Zurich</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
							<email>rico.sennrich@ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computational Linguistics</orgName>
								<orgName type="institution">University of Zurich</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Volk</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computational Linguistics</orgName>
								<orgName type="institution">University of Zurich</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Has Machine Translation Achieved Human Parity? A Case for Document-level Evaluation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="4791" to="4796"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>4791</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent research suggests that neural machine translation achieves parity with professional human translation on the WMT Chinese-English news translation task. We empirically test this claim with alternative evaluation protocols, contrasting the evaluation of single sentences and entire documents. In a pairwise ranking experiment, human raters assessing adequacy and fluency show a stronger preference for human over machine translation when evaluating documents as compared to isolated sentences. Our findings emphasise the need to shift towards document-level evaluation as machine translation improves to the degree that errors which are hard or impossible to spot at the sentence-level become decisive in discriminating quality of different translation outputs.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural machine translation <ref type="bibr" target="#b9">(Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b15">Sutskever et al., 2014;</ref><ref type="bibr" target="#b0">Bahdanau et al., 2015</ref>) has become the de-facto standard in machine translation, outperforming earlier phrase- based approaches in many data settings and shared translation tasks ( <ref type="bibr" target="#b12">Luong and Manning, 2015;</ref><ref type="bibr" target="#b14">Sennrich et al., 2016;</ref><ref type="bibr" target="#b4">Cromieres et al., 2016)</ref>. Some recent results suggest that neural machine transla- tion "approaches the accuracy achieved by average bilingual human translators [on some test sets]" ( <ref type="bibr">Wu et al., 2016)</ref>, or even that its "translation qual- ity is at human parity when compared to profes- sional human translators" <ref type="bibr">(Hassan et al., 2018)</ref>. Claims of human parity in machine translation are certainly extraordinary, and require extraordinary evidence. <ref type="bibr">1</ref> Laudably, <ref type="bibr">Hassan et al. (2018)</ref> have released their data publicly to allow external val- idation of their claims. Their claims are further strengthened by the fact that they follow best prac- tices in human machine translation evaluation, us- ing evaluation protocols and tools that are also used at the yearly Conference on Machine Trans- lation (WMT) ( <ref type="bibr">Bojar et al., 2017)</ref>, and take great care in guarding against some confounds such as test set selection and rater inconsistency.</p><p>However, the implications of a statistical tie be- tween two machine translation systems in a shared translation task are less severe than that of a statis- tical tie between a machine translation system and a professional human translator, so we consider the results worthy of further scrutiny. We per- form an independent evaluation of the professional translation and best machine translation system that were found to be of equal quality by <ref type="bibr">Hassan et al. (2018)</ref>. Our main interest lies in the eval- uation protocol, and we empirically investigate if the lack of document-level context could explain the inability of human raters to find a quality dif- ference between human and machine translations. We test the following hypothesis:</p><p>A professional translator who is asked to rank the quality of two candidate trans- lations on the document level will prefer a professional human translation over a machine translation.</p><p>Note that our hypothesis is slightly different from that tested by <ref type="bibr">Hassan et al. (2018)</ref>, which could be phrased as follows:</p><p>A bilingual crowd worker who is asked to directly assess the quality of candi- date translations on the sentence level will prefer a professional human trans- lation over a machine translation.</p><p>As such, our evaluation is not a direct replication of that by <ref type="bibr">Hassan et al. (2018)</ref>, and a failure to re- produce their findings does not imply an error on either our or their part. Rather, we hope to indi- rectly assess the accuracy of different evaluation protocols. Our underlying assumption is that pro- fessional human translation is still superior to neu- ral machine translation, but that the sensitivity of human raters to these quality differences depends on the evaluation protocol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Human Evaluation of Machine Translation</head><p>Machine translation is typically evaluated by com- paring system outputs to source texts, reference translations, other system outputs, or a combi- nation thereof (for examples, see <ref type="bibr" target="#b1">Bojar et al., 2016a</ref>). The scientific community concentrates on two aspects: adequacy, typically assessed by bilinguals; and target language fluency, typically assessed by monolinguals. Evaluation protocols have been subject to controversy for decades (e. g., Van Slype, 1979), and we identify three aspects with particular relevance to assessing human par- ity: granularity of measurement (ordinal vs. inter- val scales), raters (experts vs. crowd workers), and experimental unit (sentence vs. document).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Related Work</head><p>Granularity of Measurement Callison- <ref type="bibr">Burch et al. (2007)</ref> show that ranking (Which of these translations is better?) leads to better inter-rater agreement than absolute judgement on 5-point Likert scales (How good is this translation?) but gives no insight about how much a candidate trans- lation differs from a (presumably perfect) refer- ence. To this end, <ref type="bibr" target="#b6">Graham et al. (2013)</ref> suggest the use of continuous scales for direct assessment of translation quality. Implemented as a slider between 0 (Not at all) and 100 (Perfectly), their method yields scores on a 100-point interval scale in practice ( <ref type="bibr">Bojar et al., 2016b</ref><ref type="bibr">Bojar et al., , 2017</ref>, with each raters' rating being standardised to increase ho- mogeneity. <ref type="bibr">Hassan et al. (2018)</ref> use source-based direct assessment to avoid bias towards reference translations. In the shared task evaluation by <ref type="bibr" target="#b3">Cettolo et al. (2017)</ref>, raters are shown the source and a candidate text, and asked: How accurately does the above candidate text convey the semantics of the source text? In doing so, they have translations produced by humans and machines rated indepen- dently, and parity is assumed if the mean score of the former does not significantly differ from the mean score of the latter.</p><p>Raters To optimise cost, machine translation quality is typically assessed by means of crowd- sourcing. Combined ratings of bilingual crowd workers have been shown to be more reliable than automatic metrics and "very similar" to ratings produced by "experts" 2 (Callison-Burch, 2009). <ref type="bibr" target="#b7">Graham et al. (2017)</ref> compare crowdsourced to "expert" ratings on machine translations from WMT 2012, concluding that, with proper quality control, "machine translation systems can indeed be evaluated by the crowd alone." However, it is unclear whether this finding carries over to trans- lations produced by NMT systems where, due to increased fluency, errors are more difficult to iden- tify ( <ref type="bibr">Castilho et al., 2017a</ref>), and concurrent work by <ref type="bibr" target="#b16">Toral et al. (2018)</ref> highlights the importance of expert translators for MT evaluation.</p><p>Experimental Unit Machine translation evalu- ation is predominantly performed on single sen- tences, presented to raters in random order (e. g., <ref type="bibr">Bojar et al., 2017;</ref><ref type="bibr" target="#b3">Cettolo et al., 2017)</ref>. There are two main reasons for this. The first is cost: if raters assess entire documents, obtaining the same number of data points in an evaluation cam- paign multiplies the cost by the average number of sentences per document. The second is exper- imental validity. When comparing systems that produce sentences without considering document- level context, the perceived suprasentential cohe- sion of a system output is likely due to random- ness and thus a confounding factor. While in- corporating document-level context into machine translation systems is an active field of research ( <ref type="bibr">Webber et al., 2017)</ref>, state-of-the-art systems still operate at the level of single sentences <ref type="bibr" target="#b13">(Sennrich et al., 2017;</ref><ref type="bibr">Vaswani et al., 2017;</ref><ref type="bibr">Hassan et al., 2018)</ref>. In contrast, human translators can and do take document-level context into account <ref type="bibr" target="#b11">(Krings, 1986)</ref>. The same holds for raters in evaluation campaigns. In the discussion of their results, <ref type="bibr">Wu et al. (2016)</ref> note that their raters "[did] not necessarily fully understand each randomly sam- pled sentence sufficiently" because it was pro- vided with no context. In such setups, raters can- not reward textual cohesion and coherence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Our Evaluation Protocol</head><p>We conduct a quality evaluation experiment with a 2 × 2 mixed factorial design, testing the effect of source text availability (adequacy, fluency) and experimental unit (sentence, document) on ratings by professional translators.</p><p>Granularity of Measurement We elicit judge- ments by means of pairwise ranking. Raters choose the better (with ties allowed) of two trans- lations for each item: one produced by a profes- sional translator (HUMAN), the other by machine translation (MT). Since our evaluation includes that of human translation, it is reference-free. We evaluate in two conditions: adequacy, where raters see source texts and translations (Which transla- tion expresses the meaning of the source text more adequately?); and fluency, where raters only see translations (Which text is better English?).</p><p>Raters We recruit professional translators, only considering individuals with at least three years of professional experience and positive client re- views.</p><p>Experimental Unit To test the effect of context on perceived translation quality, raters evaluate en- tire documents as well as single sentences in ran- dom order (i. e., context is a within-subjects fac- tor). They are shown both translations (HUMAN and MT) for each unit; the source text is only shown in the adequacy condition.</p><p>Quality Control To hedge against random rat- ings, we convert 5 documents and 16 sentences per set into spam items ( <ref type="bibr" target="#b10">Kittur et al., 2008)</ref>: we render one of the two options nonsensical by shuffling its words randomly, except for 10 % at the beginning and end.</p><p>Statistical Analysis We test for statistically sig- nificant preference of HUMAN over MT or vice versa by means of two-sided Sign Tests. Let a be the number of ratings in favour of MT, b the num- ber of ratings in favour of HUMAN, and t the num- ber of ties. We report the number of successes x and the number of trials n for each test, such that x = b and n = a + b. <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Data Collection</head><p>We use the experimental protocol described in the previous section for a quality assessment of Chi- nese to English translations of news articles. To this end, we randomly sampled 55 documents and 2×120 sentences from the WMT 2017 test set. We only considered the 123 articles (documents) which are native Chinese, 4 containing 8.13 sen- tences on average. Human and machine transla- tions (REFERENCE-HT as HUMAN, and COMBO- 6 as MT) were obtained from data released by <ref type="bibr">Hassan et al. (2018)</ref>. <ref type="bibr">5</ref> The sampled documents and sentences were rated by professional translators we recruited from ProZ: 6 4 native in Chinese (2), English (1), or both (1) to rate adequacy, and 4 native in English to rate fluency. On average, translators had 13.7 years of experience and 8.8 positive client reviews on ProZ, and received US$ 188.75 for rating 55 documents and 120 sentences.</p><p>The averages reported above include an ad- ditional translator we recruited when one rater showed poor performance on document-level spam items in the fluency condition, whose judge- ments we exclude from analysis. We also ex- clude sentence-level results from 4 raters because there was overlap with the documents they anno- tated, which means that we cannot rule out that the sentence-level decisions were informed by access to the full document. To allow for external val- idation and further experimentation, we make all experimental data publicly available. <ref type="bibr">7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>In the adequacy condition, MT and HUMAN are not statistically significantly different on the sen- tence level (x = 86, n = 189, p = .244). This is consistent with the results <ref type="bibr">Hassan et al. (2018)</ref> obtained with an alternative evaluation protocol (crowdsourcing and direct assessment; see Sec- tion 2.1). However, when evaluating entire doc- 4 While it is common practice in machine translation to use the same test set in both translation directions, we con- sider a direct comparison between human "translation" and machine translation hard to interpret if one is in fact the orig- inal English text, and the other an automatic translation into English of a human translation into Chinese. In concurrent work, <ref type="bibr" target="#b16">Toral et al. (2018)</ref> expand on the confounding effect of evaluating text where the target side is actually the original document. uments, raters show a statistically significant pref- erence for HUMAN (x = 104, n = 178, p &lt; .05).</p><p>While the number of ties is similar in sentence- and document-level evaluation, preference for MT drops from 50 to 37 % in the latter <ref type="figure" target="#fig_0">(Figure 1a</ref>). In the fluency condition, raters prefer HU- MAN on both the sentence (x = 106, n = 172, p &lt; .01) and document level (x = 99, n = 143, p &lt; .001). In contrast to adequacy, fluency ratings in favour of HUMAN are similar in sentence-and document-level evaluation, but raters find more ties with document-level context as preference for MT drops from 32 to 22 % <ref type="figure" target="#fig_0">(Figure 1b)</ref>.</p><p>We note that these large effect sizes lead to statistical significance despite modest sam- ple size. Inter-annotator agreement (Cohen's κ) ranges from 0.13 to 0.32 (see Appendix for full results and discussion).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Our results emphasise the need for suprasentential context in human evaluation of machine transla- tion. Starting with Hassan et al.'s (2018) finding of no statistically significant difference in trans- lation quality between HUMAN and MT for their Chinese-English test set, we set out to test this re- sult with an alternative evaluation protocol which we expected to strengthen the ability of raters to judge translation quality. We employed profes- sional translators instead of crowd workers, and pairwise ranking instead of direct assessment, but in a sentence-level evaluation of adequacy, raters still found it hard to discriminate between HUMAN and MT: they did not show a statistically signifi- cant preference for either of them.</p><p>Conversely, we observe a tendency to rate HU- MAN more favourably on the document level than on the sentence level, even within single raters. Adequacy raters show a statistically significant preference for HUMAN when evaluating entire documents. We hypothesise that document-level evaluation unveils errors such as mistranslation of an ambiguous word, or errors related to textual co- hesion and coherence, which remain hard or im- possible to spot in a sentence-level evaluation. For a subset of articles, we elicited both sentence-level and document-level judgements, and inspected ar- ticles for which sentence-level judgements were mixed, but where HUMAN was strongly preferred in document-level evaluation. In these articles, we do indeed observe the hypothesised phenom- ena. We find an example of lexical coherence in a 6-sentence article about a new app "微信挪 车", which HUMAN consistently translates into "WeChat Move the Car". In MT, we find three different translations in the same article: "Twit- ter Move Car", "WeChat mobile", and "WeChat Move". Other observations include the use of more appropriate discourse connectives in HU- MAN, a more detailed investigation of which we leave to future work.</p><p>To our surprise, fluency raters show a stronger preference for HUMAN than adequacy raters <ref type="figure" target="#fig_0">(Fig- ure 1)</ref>. The main strength of neural machine trans- lation in comparison to previous statistical ap- proaches was found to be increased fluency, while adequacy improvements were less clear ( <ref type="bibr">Bojar et al., 2016b;</ref><ref type="bibr" target="#b2">Castilho et al., 2017b</ref>), and we ex- pected a similar pattern in our evaluation. Does this indicate that adequacy is in fact a strength of MT, not fluency? We are wary to jump to this conclusion. An alternative interpretation is that MT, which tends to be more literal than HUMAN, is judged more favourably by raters in the bilin- gual condition, where the majority of raters are native speakers of the source language, because of L1 interference. We note that the availability of document-level context still has a strong impact in the fluency condition (Section 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In response to recent claims of parity between hu- man and machine translation, we have empirically tested the impact of sentence and document level context on human assessment of machine transla- tion. Raters showed a markedly stronger prefer- ence for human translations when evaluating at the level of documents, as compared to an evaluation of single, isolated sentences.</p><p>We believe that our findings have several impli- cations for machine translation research. Most im- portantly, if we accept our interpretation that hu- man translation is indeed of higher quality in the dataset we tested, this points to a failure of cur- rent best practices in machine translation evalu- ation. As machine translation quality improves, translations will become harder to discriminate in terms of quality, and it may be time to shift towards document-level evaluation, which gives raters more context to understand the original text and its translation, and also exposes translation er- rors related to discourse phenomena which remain invisible in a sentence-level evaluation.</p><p>Our evaluation protocol was designed with the aim of providing maximal validity, which is why we chose to use professional translators and pair- wise ranking. For future work, it would be of high practical relevance to test whether we can also elicit accurate quality judgements on the document-level via crowdsourcing and direct as- sessment, or via alternative evaluation protocols. The data released by <ref type="bibr">Hassan et al. (2018)</ref> could serve as a test bed to this end.</p><p>One reason why document-level evaluation widens the quality gap between machine trans- lation and human translation is that the machine translation system we tested still operates on the sentence level, ignoring wider context. It will be interesting to explore to what extent exist- ing and future techniques for document-level ma- chine translation can narrow this gap. We ex- pect that this will require further efforts in cre- ating document-level training data, designing ap- propriate models, and supporting research with discourse-aware automatic metrics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Raters prefer human translation more strongly in entire documents. When evaluating isolated sentences in terms of adequacy, there is no statistically significant difference between HUMAN and MT; in all other settings, raters show a statistically significant preference for HUMAN.</figDesc></figure>

			<note place="foot" n="1"> The term &quot;parity&quot; may raise the expectation that there is evidence for equivalence, but the term is used in the definition of &quot;there [being] no statistical significance between [two outputs] for a test set of candidate translations&quot; by Hassan et al. (2018). Still, we consider this finding noteworthy given the strong evaluation setup.</note>

			<note place="foot" n="2"> &quot;Experts&quot; here are computational linguists who develop MT systems, who may not be expert translators.</note>

			<note place="foot" n="3"> Emerson and Simon (1979) suggest the inclusion of ties such that x = b + 0.5t and n = a + b + t. This modification has no effect on the significance levels reported in this paper.</note>

			<note place="foot" n="5"> http://aka.ms/Translator-HumanParityData 6 https://www.proz.com 7 https://github.com/laeubli/parity</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Xin Sennrich for her help with the analysis of translation errors. We also thank An-tonio Toral and the anonymous reviewers for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translation Evaluation-From Fragmented Tools and Data Sets to an Integrated Ecosystem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2016 Workshop</title>
		<meeting>the LREC 2016 Workshop<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
	<note>Ten years of WMT evaluation campaigns: Lessons learnt</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Comparative Quality Evaluation of PBSMT and NMT using Professional Translators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheila</forename><surname>Castilho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joss</forename><surname>Moorkens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Gaspari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vilelmini</forename><surname>Sosoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yota</forename><surname>Georgakopoulou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pintu</forename><surname>Lohar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gialama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MT Summit</title>
		<meeting>MT Summit<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Overview of the IWSLT 2017 Evaluation Campaign</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Stüker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuitho</forename><surname>Sudoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koichiro</forename><surname>Yoshino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWSLT</title>
		<meeting>IWSLT<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Kyoto University participation to WAT 2016</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Cromieres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhui</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WAT</title>
		<meeting>WAT<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="166" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Another Look at the Sign Test When Ties Are Present: The Problem of Confidence Intervals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="140" to="142" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Continuous Measurement Scales in Human Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop &amp; Interoperability with Discourse</title>
		<meeting>the 7th Linguistic Annotation Workshop &amp; Interoperability with Discourse<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="33" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Can machine translation systems be evaluated by the crowd alone?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="30" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Aue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Chowdhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuangzhi</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05567</idno>
		<title level="m">Yingce Xia, Dongdong Zhang, Zhirui Zhang, and Ming Zhou. 2018. Achieving Human Parity on Automatic Chinese to English News Translation. Computing Research Repository</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Recurrent Continuous Translation Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1700" to="1709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Crowdsourcing User Studies with Mechanical Turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniket</forename><surname>Kittur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bongwon</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CHI</title>
		<meeting>CHI<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="453" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Was in den Köpfen von¨Ubersetzern von¨ von¨Ubersetzern vorgeht</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krings</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Gunter Narr</publisher>
			<pubPlace>Tübingen, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stanford Neural Machine Translation Systems for Spoken Language Domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWSLT</title>
		<meeting>IWSLT<address><addrLine>Da Nang, Vietnam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The University of Edinburgh&apos;s Neural MT Systems for WMT17</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Currey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WMT</title>
		<meeting>WMT<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="389" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Edinburgh Neural Machine Translation Systems for WMT 16</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WMT</title>
		<meeting>WMT<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="368" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Attaining the Unattainable? Reassessing Claims of Human Parity in Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Toral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheila</forename><surname>Castilho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WMT</title>
		<meeting>WMT<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
