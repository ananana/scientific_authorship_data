<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Strong Lexical Matching Method for the Machine Comprehension Test</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellery</forename><surname>Smith</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Greco</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matko</forename><surname>Bo≈°njak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University College London</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Strong Lexical Matching Method for the Machine Comprehension Test</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Machine comprehension of text is the overarching goal of a great deal of research in natural language processing. The Machine Comprehension Test (Richard-son et al., 2013) was recently proposed to assess methods on an open-domain, exten-sible, and easy-to-evaluate task consisting of two datasets. In this paper we develop a lexical matching method that takes into account multiple context windows, question types and coreference resolution. We show that the proposed method outper-forms the baseline of Richardson et al. (2013), and despite its relative simplicity, is comparable to recent work using machine learning. We hope that our approach will inform future work on this task. Furthermore , we argue that MC500 is harder than MC160 due to the way question answer pairs were created.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine comprehension of text is the central goal in NLP. The academic community has proposed a variety of tasks, such as information extrac- tion <ref type="bibr" target="#b13">(Sarawagi, 2008)</ref>, semantic parsing <ref type="bibr" target="#b9">(Mooney, 2007)</ref> and textual entailment <ref type="bibr">(Androutsopoulos and Malakasiotis, 2010)</ref>. However, these tasks as- sess performance on each task individually, rather than on overall progress towards machine compre- hension of text.</p><p>To this end, <ref type="bibr" target="#b11">Richardson et al. (2013)</ref> proposed the Machine Comprehension Test (MCTest), a new challenge that aims at evaluating machine comprehension. It does so through an open- domain multiple-choice question answering task on fictional stories requiring the common sense reasoning typical of a 7-year-old child. It is easy to evaluate as it consists of multiple choice ques- tions. <ref type="bibr" target="#b11">Richardson et al. (2013)</ref> also showed how the creation of stories and questions can be crowd- sourced efficiently, constructing two datasets for the task, namely MC160 and MC500. In ad- dition, the authors presented a lexical matching baseline which is combined with the textual en- tailment recognition system BIUTEE ( <ref type="bibr" target="#b14">Stern and Dagan, 2011)</ref>.</p><p>In this paper we develop an approach based on lexical matching which we extend by taking into account the type of the question and coreference resolution. These components improve the per- formance on questions that are difficult to han- dle with pure lexical matching. When combined with BIUTEE, we achieved 74.27% accuracy on MC160 and 65.96% on MC500, which are signif- icantly better than those reported by <ref type="bibr" target="#b11">Richardson et al. (2013)</ref>. Despite the simplicity of our ap- proach, these results are comparable with the re- cent machine learning-based approaches proposed by <ref type="bibr" target="#b10">Narasimhan and Barzilay (2015)</ref>, <ref type="bibr" target="#b15">Wang et al. (2015)</ref> and <ref type="bibr" target="#b12">Sachan et al. (2015)</ref>.</p><p>Furthermore, we examine the types of questions and answers in the two datasets. We argue that some types are relatively simple to answer, partly due to the limited vocabulary used, which explains why simple lexical matching methods can per- form well. On the other hand, some questions re- quire understanding of higher level concepts such as those of the story and its characters, and/or re- quire inference. This is still beyond the scope of current NLP systems. However, we believe our analysis will be useful in developing new methods and datasets for the task. To that extent, we will make our code and analysis publicly available. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task description</head><p>MCTest is an open-domain multiple-choice ques- tion answering task on fictional stories consist- ing of two datasets, MC160 and MC500. The It was a terrible day to live in the zoo again for Pauly. It wasn't a terrible day for Zip, the monkey next to him, or Garth, the giraffe down the sidewalk, or Pat, the alligator in the pond, or for Bam the prairie dog, but it was a terrible day in the monkey cage for Pauly. Pauly didn't feel he belonged in the monkey cage because he wasn't a monkey. He was a sailor who had visited the zoo on vacation and fallen asleep on a bench right before closing time. The zoo worker saw how hairy he was and thought he was a monkey that had escaped from his cage, so they put him in a cage. two datasets contain 160 and 500 stories respec- tively, with 4 questions per story, and 4 candi- date answers per question <ref type="figure" target="#fig_0">(Figure 1</ref>). All stories and questions were crowd-sourced using Amazon Mechanical Turk. 2 MC160 was manually curated by Richardson et al., while MC500 was curated by crowdworkers. Both datasets are divided into training, development, and test sets. All develop- ment was conducted on the training and develop- ment sets; the test sets were used only to report the final results. <ref type="bibr" target="#b11">Richardson et al. (2013)</ref> proposed a sliding win- dow algorithm that ranks the answers by form- ing the bag-of-words vector of each answer paired with the question text and then scoring them ac- cording to their overlap with the story text. We propose a modified version of this algorithm, which combines the scores across a range of win- dow sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Scoring function</head><p>More concretely, the algorithm of <ref type="bibr" target="#b11">Richardson et al. (2013)</ref> passes a sliding window over the story, size of which is equal to the number of words in the question-answer pair. The highest over- lap score between a story text window and the question-answer pair is taken as the score for the answer. Therefore, their algorithm makes a single pass over the story text per answer. In compar- ison, our system scores each answer by making multiple passes and summing the obtained scores. Concretely, on the first pass, we set the sliding window size to 2 tokens, and increment this size on each subsequent pass, up to a length of 30 to- kens. We then combine this score with the over- all number of matches of the question-answer pair across the story as a whole. This enables our algo- rithm to catch long-distance relations in the story. Similar to <ref type="bibr" target="#b11">Richardson et al. (2013)</ref>, we use a lin- ear combination of this score with their distance- based scoring function, and we weigh tokens with their inverse document frequencies in each indi- vidual story.</p><p>By itself, this simple enhancement gives sub- stantial improvements over the MSR baseline as shown in <ref type="table">Table 1</ref> (Enhanced SW+D), as it mea- sures the overlap of the question-answer pair with multiple portions of the story text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Incorporating linguistic analyses</head><p>We build upon our enhanced scoring function us- ing stemming, rules taking into account the type of the question, and coreference. The improvements due to each of these components are presented in <ref type="table">Table 1</ref>, and we discuss the application of corefer- ence and the rules used in more detail in the fol- lowing subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MC160 MC500 MSR SW+D</head><p>69.43% 63.01% Enhanced SW+D 72.65% 63.57% +Coreference Rules +2.38% +1.36% +Negation +0.75% +0.36% +Stemming +2.04% +0.50% Final system 75.77% 65.43% <ref type="table">Table 1</ref>: Performance improvements on combined train and dev sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Coreference resolution</head><p>The entities mentioned in MCTest stories are frequently referred to by anaphoric expressions throughout the story and the questions, which is ignored by the described scoring function. Therefore, we substituted each mention in a co- reference chain with its representative mention, applied the scoring function on the processed text and added the score to the original one. The chains and their represenatative mentions were ob- tained using the Stanford CoreNLP toolkit ). We found that coreference im- proved performance on some question types, but decreased performance on others. Thus we devel- oped a set of question rules in order to apply it selectively, which we discuss in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Rules</head><p>ROOT Which food was not eaten ? To account for the variety of questions in MCTest, we developed a set of rules to handle cer- tain question types differently. To this purpose, we created rules which detect numerical, tempo- ral, narrative and negation-based questions, and additionally partition questions by their wh-word.</p><p>By partitioning questions in different types, we found that who questions, which primarily deal with identifying a character in the story, benefit from the use of coreference chains described in the previous section. In addition, performance in questions aimed at selecting an appropriate noun, such as which, where or numerical questions, also improved with coreference. However, other ques- tion types, such as why questions, or questions concerning the story narrative, did not register any consistent improvement, and we opted not to use co-reference for them. This selective application of co-reference resulted in improvements on both datasets <ref type="table">(Table 1)</ref>.</p><p>We also identified negation questions as requir- ing special treatment. Some negation questions are trivially solvable by selecting an answer which does not appear in the text. However, our proposed function that scores answers according to the lexi- cal overlap with the story text is unlikely to score answers not appearing in text highly. Motivated by this observation we invert the score of each word when a question with a negated root verb was de- tected, e.g. "What did James not eat for dinner?", using Stanford Typed Dependencies <ref type="bibr" target="#b2">(De Marneffe and Manning, 2008)</ref>, as depicted in <ref type="figure" target="#fig_1">Figure 2</ref>. Due to this inversion a higher lexical overlap results in a lower score, improving accuracy on both MC160 and MC500 (+negation in <ref type="table">Table 1)</ref> In a similar fashion we detected numerical ques- tions based on the presence of a POS tag for a cardinal number in either the question or any of the answers choices. Questions concerning the story's narrative (e.g. "Which is the first char- acter mentioned in the story") were detected us- ing keywords (e.g. character, book, etc.). Addi- tionally, we detected temporal questions such as "What did Jane do before she went home?" by the presence of a temporal modifier or temporal prepositions (e.g. before, while, etc.). Then we attempted to account for them by searching the text for the sentence indicating that she had gone home and reducing the weight for all subsequent sentences. However, since the improvements due to these rules were negligible, we did not include them in our final system. Nevertheless, these rules were helpful in analyzing problem areas in the datasets, as discussed in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We evaluated our system on MC160 and MC500 test sets and the results are shown in <ref type="table" target="#tab_1">Table 2</ref>. Our proposed baseline outperforms the baseline of <ref type="bibr" target="#b11">Richardson et al. (2013)</ref> by 4 and 3 points in accuracy on MC160 and MC500 respectively. <ref type="bibr">3</ref> Our system is comparable to the MSR baseline with the RTE system BIUTEE ( <ref type="bibr" target="#b14">Stern and Dagan, 2011</ref>). If we linearly combine the RTE scores used in the MSR baseline with our method, we achieve 5 and 2.5 accuracy points higher than the best re- sults achieved by <ref type="bibr" target="#b11">Richardson et al. (2013)</ref>.</p><p>Concurrently with ours, three other approaches to solving MCTest were developed and sub- sequently published a few months before our method. <ref type="bibr" target="#b10">Narasimhan and Barzilay (2015)</ref> pre- sented a discourse-level approach, which chooses an answer by utilising relations between sentences chosen as important. Despite is simplicity, our method is comparable in performance, suggesting that better lexical matching could help improve their model. <ref type="bibr" target="#b12">Sachan et al. (2015)</ref> treated MCTest as a structured prediction problem, searching for a latent structure connecting the question, answer and the text, dubbed the answer-entailing struc- ture. Their model performs better on MC500 (was</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MC160 MC500 MSR SW+D</head><p>68.02% 59.93%   not tested on MC160), however the strength of our model is obtaining comparable results with a much simpler model. The work of <ref type="bibr" target="#b15">Wang et al. (2015)</ref> is the most similar to ours, in the sense that they combine a baseline feature set with more ad- vanced linguistic analyses, namely syntax, frame semantics, coreference, and word embeddings. In- stead of a rule-based approach, they combine them through a latent-variable classifier achieving the current state-of-the-art performance on MCTest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Using the question-filtering rules mentioned in Section 4.2, we obtained individual accuracy scores per question type for the final system com- bined with RTE ( <ref type="table" target="#tab_3">Table 3</ref>). Note that these types are in three groups: i) wh-word questions (dis- joint, questions without an wh-word are in Other), ii) classes of questions requiring non-trivial lin- guistic analysis and reasoning (not disjoint, not all questions considered), and iii) questions originally classified by crowdworkers, classifying whether the question can be answered by a single or multi- ple sentences in the story (disjoint). Compared to the wh-word question type re- sults of <ref type="bibr" target="#b10">Narasimhan and Barzilay (2015)</ref>, our ap- proach performs better primarily on why questions (72.97% and 80.65% vs. 59.45% and 69.35% on MC160 and MC500 respectively) and slightly bet- ter on how, when and what questions on MC500. Additionally, our system is more successful in questions requiring multiple sentences to be an- swered correctly (70.31% and 63.3%vs. 65.23% and 59.9% on MC160 and MC500 respectively).</p><p>If we remove the RTE component from our sys- Category MC160 MC500 What 76.98% (126) 68.77% (317) Who 71.43% <ref type="formula">(28)</ref> 58.44% (77) When 80.00% <ref type="formula">(5)</ref> 100.00% (7) How 72.62% <ref type="formula">(21)</ref> 50.58% (43) Which 66.67% (6) 40.00% (25) Where 91.67% <ref type="formula">(12)</ref> 68.97% (58) Why 72.97% <ref type="formula">(37)</ref> 80.65% (62) Whose - 66.67% (3) Other 0.00% <ref type="formula">(5)</ref> 25.00% (8) Negation 53.33% <ref type="formula">(15)</ref> 34.48% (29) Temporal 58.82% <ref type="formula">(17)</ref> 56.41% (39) Numerical 69.32% <ref type="formula">(22)</ref> 48.26% (43) Narrative 81.82% <ref type="formula">(11)</ref> 58.41% (26) Quantifiers 70.00% <ref type="formula">(20)</ref> 53.38% (37) Single 78.79% <ref type="formula">(112)</ref>   tem, the performance on relatively simple question types such as what, who and where remains practi- cally the same, thus confirming that our approach can handle simple questions well. On the other hand, the performance on why questions drops without RTE, thus stressing the need for deeper text understanding. There are several clear deficiencies in certain question types, particularly in handling negation. These errors provide a broad overview of the cases in which simple lexical techniques are not suffi- cient to determine the correct answer.</p><p>Many numerical questions, particularly in MC500, require the use of simple algebra over story elements, including counting characters and objects, and understanding temporal order. One question even requires calculating the probability of an event occurring, while another one calls for complex volumetric calculation. Answering ques- tions such as these is beyond the capabilities of a lexical algorithm, and accuracies in this cate- gory are worse than on all questions. Addition- ally, lexical algorithms such as ours, which ig- nore predicate-argument structure, perform worse in the presence of quantifiers.</p><p>In MC500, the performance of our system on more abstract questions, concerning the overall narrative of the story, also demonstrates a sig-nificant inadequacy of lexical-based algorithms. Questions such as "What was the first character mentioned in the story?", which relate to the over- all narrative flow of the passage, or questions con- cerning the state of the story environment, such as "Where is the story set?", are difficult to solve without a system which understands the concept of a story. Typical question-answering methods would also struggle here.</p><p>Another type of challenging question are those which require an implicit temporal understanding of the text, i.e. questions concerning time without using a temporal modifier. For example, given a story which states that "John is at the beach", then later "John went home", a question such as "What did John do at home?" would prove itself difficult for traditional methods to answer. These questions are difficult to identify automatically by the form of the question alone, thus we cannot provide ac- curacies for them.</p><p>Our results confirm that it is easier to achieve better performance on MC160 with simple lexi- cal techniques, while the MC500 has proved more resilient to the same improvements. We also ob- served that the MC500 registers smaller improve- ments in accuracy when adding components such as co-reference. This is a consequence of the de- sign and curation process of the MC500 dataset, which stipulated that answers must not be con- tained directly within the story text, or if they are, that two or more misleading choices included. <ref type="bibr" target="#b11">Richardson et al. (2013)</ref> demonstrate that the MC160 and MC500 have similar ratings for clar- ity and grammar, and that humans perform equally well on both. However, in many cases MC500 ap- pears to be designed in such a way to confuse lex- ical algorithms and encourage the use of more so- phisticated techniques necessary to deal with phe- nomena such as elimination questions, negation, and common knowledge not explicitly written in the story.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related work</head><p>The use of shallow methods for machine compre- hension has been explored in previous work, for example <ref type="bibr" target="#b4">Hirschman et al. (1999)</ref> used a bag-of- words to match question-answer pairs to sentences in the text, and choose the best pair with the best matching sentence. As discussed in our analysis, such systems cannot handle well questions involv- ing negation and quantification. Numerical ques- tions, which we found to be particularly challeng- ing, have been the focus of recent work on algebra word problems ( <ref type="bibr" target="#b5">Kushman et al., 2014</ref>) for which dedicated systems have been developed. <ref type="bibr" target="#b7">MacCartney et al. (2006)</ref> demonstrated that a large set of rules can be used to recognize valid textual entailments. These consider phenomena such as polarity and quantification, similar to those we used in our analysis of the MCTest datasets. More complex methods, which attempt deeper modeling of text include Natural Logic ( <ref type="bibr" target="#b1">Angeli and Manning, 2014</ref>) and Combinatorial Catego- rial Grammars ( <ref type="bibr" target="#b6">Lewis and Steedman, 2013</ref>) com- bined with distributional models. While promis- ing, these approaches have been developed pri- marily on sentence-level tasks, thus the stories in MCTest are likely to present additional challenges.</p><p>The recently proposed class of methods called Memory Network ( <ref type="bibr">Weston et al., 2014</ref>), uses neu- ral networks and external memory to answer a simpler comprehension task. Though quite suc- cessful on toy tasks, those methods cannot yet be applied to MCTest as they require much larger training datasets than the ones available for this task.</p><p>A recent approach by <ref type="bibr" target="#b3">Hermann et al. (2015)</ref> uses attention-based recurrent neural networks to attack the problem of machine comprehension. In this work, the authors show how to generate large amounts of data for machine comprehension exploiting news websites, and how to use novel architectures in deep learning to solve the task. However, due to the need for a large dataset for training, and the focus only on questions that take entities as answers, this approach has not been ap- plied to MCTest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this paper we developed an approach to MCTest that combines lexical matching with simple lin- guistic analysis. We evaluated it on the two MCTest datasets, MC160 and MC500, and we showed that it improves upon the original baseline by 4 and 3 percentage points respectively, while being comparable to more complex approaches. In addition, our analysis highlighted the challenges involved and in particular in the MC500 dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 .</head><label>1</label><figDesc>Figure 1: An excerpt from story mc500.train.44</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Dependency tree to detect negation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Final</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance on the MC160 and MC500 
test sets, including the results of all previous work. 
* denotes statistically significant (p &lt; 0.05) im-
provement using McNemar's test, with respect to 
the MSR baseline (SW+D) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Performance of our final system + RTE 
per question type on the test sets. The number of 
relevant questions is in parentheses. 

</table></figure>

			<note place="foot" n="1"> http://github.com/elleryjsmith/ UCLMCTest</note>

			<note place="foot" n="2"> http://www.mturk.com</note>

			<note place="foot" n="3"> We consider the updated MSR algorithms and results, together with partial credit accuracies, provided at http://research.microsoft.com/en-us/um/ redmond/projects/mctest/results.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Tom Brown for his contri-butions in the early stages of this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey of paraphrasing and textual entailment methods</title>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page" from="135" to="187" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Ion Androutsopoulos and Prodromos Malakasiotis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Naturalli: Natural logic inference for common sense reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Stanford typed dependencies manual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://nlp.stanford.edu/software/dependenciesmanual.pdf" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Teaching Machines to Read and Comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom√°≈°</forename><surname>Koƒçisk¬¥koƒçisk¬¥y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep read: A reading comprehension system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynette</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Light</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="325" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to automatically solve algebra word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="271" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Combined distributional and logical semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="179" to="192" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to recognize features of valid textual entailments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HLTNAACL</title>
		<meeting>the HLTNAACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL: System Demonstrations</title>
		<meeting>ACL: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="311" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Machine comprehension with discourse relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Renshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="193" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning answerentailing structures for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinmaya</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinava</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Information extraction. Foundations and trends in databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="261" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Confidence Model for Syntactically-Motivated Entailment Proofs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asher</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Recent Advances in Natural Language Processing</title>
		<meeting>Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="455" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Machine comprehension with syntax, frames, and semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcallester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL: Short papers</title>
		<meeting>ACL: Short papers</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1410.3916</idno>
		<imprint/>
	</monogr>
<note type="report_type">Bordes. 2014. Memory networks. arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
