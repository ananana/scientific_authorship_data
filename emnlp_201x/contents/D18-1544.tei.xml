<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Grammar Induction with Neural Language Models: An Unusual Replication</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phu</forename><forename type="middle">Mon</forename><surname>Htut</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<addrLine>60 Fifth Avenue New York</addrLine>
									<postCode>10011</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
							<email>kyunghyun.cho@nyu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<addrLine>60 Fifth Avenue New York</addrLine>
									<postCode>10011</postCode>
									<region>NY</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<addrLine>60 Fifth Avenue New York</addrLine>
									<postCode>10011</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
							<email>bowman@nyu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<addrLine>60 Fifth Avenue New York</addrLine>
									<postCode>10011</postCode>
									<region>NY</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<addrLine>60 Fifth Avenue New York</addrLine>
									<postCode>10011</postCode>
									<region>NY</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Dept. of Linguistics</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<addrLine>10 Washington Place New York</addrLine>
									<postCode>10003</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">AdeptMind Scholar</orgName>
								<orgName type="department" key="dep2">CIFAR Global Scholar</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Grammar Induction with Neural Language Models: An Unusual Replication</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="4998" to="5003"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>4998</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A substantial thread of recent work on latent tree learning has attempted to develop neural network models with parse-valued latent variables and train them on non-parsing tasks, in the hope of having them discover interpretable tree structure. In a recent paper, Shen et al. (2018) introduce such a model and report near-state-of-the-art results on the target task of language modeling, and the first strong latent tree learning result on constituency parsing. In an attempt to reproduce these results, we discover issues that make the original results hard to trust, including tuning and even training on what is effectively the test set. Here, we attempt to reproduce these results in a fair experiment and to extend them to two new datasets. We find that the results of this work are robust: All variants of the model under study outper-form all latent tree learning baselines, and perform competitively with symbolic grammar induction systems. We find that this model represents the first empirical success for latent tree learning, and that neural network language modeling warrants further study as a setting for grammar induction.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Background</head><p>Work on grammar induction attempts to find methods for syntactic parsing that do not re- quire expensive and difficult-to-design expert- labeled treebanks for training <ref type="bibr" target="#b2">(Charniak and Carroll, 1992;</ref><ref type="bibr" target="#b8">Klein and Manning, 2002;</ref><ref type="bibr" target="#b14">Smith and Eisner, 2005</ref>). Recent work on latent tree learning offers a new family of approaches to the problem ( <ref type="bibr" target="#b11">Maillard et al., 2017;</ref><ref type="bibr" target="#b3">Choi et al., 2018)</ref>. Latent tree learning models attempt to induce syntactic structure using the supervision from a downstream NLP task such as textual en- tailment. Though these models tend to show good task performance, they are often not evaluated us- ing standard parsing metrics, and <ref type="bibr" target="#b16">Williams et al. (2018a)</ref> report that the parses they produce tend to be no better than random trees in a standard evalu- ation on the full Wall Street Journal section of the Penn Treebank (WSJ; <ref type="bibr" target="#b12">Marcus et al., 1993)</ref>.</p><p>This paper addresses the Parsing-Reading- Predict Network (PRPN; <ref type="bibr" target="#b13">Shen et al., 2018)</ref>, which was recently published at ICLR, and which reports near-state-of-the-art results on language modeling and strong results on grammar induction, a first for latent tree models (though they do not use that term). PRPN is built around a substantially novel architecture, and uses convolutional networks with a form of structured attention <ref type="bibr" target="#b7">(Kim et al., 2017)</ref> rather than recursive neural networks <ref type="bibr" target="#b5">(Goller and Kuchler, 1996;</ref><ref type="bibr" target="#b15">Socher et al., 2011</ref>) to evaluate and learn trees while performing straightforward back- propagation training on a language modeling ob- jective. In this work, we aim to understand what the PRPN model learns that allows it to succeed, and to identify the conditions under which this success is possible.</p><p>Their experiments on language modeling and parsing are carried out using different configura- tions of the PRPN model, which were claimed to be optimized for the corresponding tasks. PRPN- LM is tuned for language modeling performance, and PRPN-UP for (unsupervised) parsing perfor- mance. In the parsing experiments, we also ob- serve that the WSJ data is not split, such that the test data is used without parse information for training. This approach follows the previ- ous works on grammar induction using non-neural models where the entire dataset is used for train- ing ( <ref type="bibr" target="#b8">Klein and Manning, 2002</ref>). However, this implies that the parsing results of PRPN-UP may not be generalizable in the way usually expected of machine learning evaluation results. Addition- ally, it is not obvious that the model should be able to learn to parse reliably: (1) Since the parser is trained as part of a language model, it makes pars-There 's nothing worth seeing in the tourist offices .</p><p>There 's nothing worth seeing in the tourist offices .</p><p>The entire Minoan civilization was destroyed by a volcanic eruption . The entire Minoan civilization was destroyed by a volcanic eruption .</p><p>Figure 1: Left Parses from PRPN-LM trained on AllNLI. Right Parses from PRPN-UP trained on AllNLI (stopping criterion: parsing). We can observe that both sets of parses tend to have roughly reasonable high-level structure and tend to identify noun phrases correctly.</p><p>ing decisions greedily and with no access to any words to the right of the point where each parsing decision must be made ( <ref type="bibr" target="#b4">Collins and Roark, 2004</ref>); (2) As RNN language models are known to be in- sufficient for capturing syntax-sensitive dependen- cies ( <ref type="bibr" target="#b10">Linzen et al., 2016)</ref>, language modeling as the downstream task may not be well-suited to la- tent tree learning. In this replication we train PRPN on two cor- pora: The full WSJ, a staple in work on gram- mar induction, and AllNLI, the concatenation of the Stanford Natural Language Inference Corpus (SNLI; <ref type="bibr" target="#b1">Bowman et al., 2015</ref>) and the Multi-Genre NLI Corpus (MultiNLI; <ref type="bibr">Williams et al., 2018b)</ref>, which is used in other latent tree learning work for its non-syntactic classification labels for the task of textual entailment, and which we include for comparison. We then evaluate the constituency trees produced by these models on the WSJ test set, full WSJ10, 1 and the MultiNLI development set.</p><p>Our results indicate that PRPN-LM achieves better parsing performance than PRPN-UP on both WSJ and WSJ10 even though PRPN-UP was tuned-at least to some extent-for parsing. Sur- prisingly, a PRPN-LM model trained on the large out-of-domain AllNLI dataset achieves the best parsing performance on WSJ despite not being tuned for parsing. We also notice that vocabulary size affects the language modeling significantly- the perplexity gets higher as the vocabulary size increases.</p><p>Overall, despite the relatively uninformative ex- perimental design used in <ref type="bibr" target="#b13">Shen et al. (2018)</ref>, we find that PRPN is an effective model. It outper- forms all latent tree learning baselines by large 1 A standard processed subset of WSJ used in grammar induction in which the sentences contain no punctuation and no more than 10 words. margins on both WSJ and MultiNLI, and performs competitively with symbolic grammar induction systems on WSJ10, suggesting that PRPN in par- ticular and language modeling in general are a vi- able setting for latent tree learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>PRPN consists of three components: (i) a parsing network that uses a two-layer convolution kernel to calculate the syntactic distance between suc- cessive pairs of words, which can form an indi- rect representation of the constituency structure of the sentence, (ii) a recurrent reading network that summarizes the current memory state based on all previous memory states and the implicit con- stituent structure, and (iii) a predict network that uses the memory state to predict the next token. We refer readers to the appendix and the original work for details.</p><p>We do not re-implement or re-tune PRPN, but rather attempt to replicate and understand the re- sults of the work using the author's publicly avail- able code. <ref type="bibr">2</ref> The experiments on language model- ing and parsing are carried out using different con- figurations of the model, with substantially differ- ent hyperparameter values including the size of the word embeddings, the maximum sentence length, the vocabulary size, and the sizes of hidden layers. PRPN-LM is larger than PRPN-UP, with embed- ding layer that is 4 times larger and the number of units per layer that is 3 times larger. We use both versions of the model in all our experiments.</p><p>We use the 49k-sentence WSJ corpus in two set- tings. To replicate the original results, we re-run an experiment with no train/test split, and for a clearer picture of the model's performance, we run it again with the train (Section 0-21 of WSJ), val- idation (Section 22 of WSJ), and test (Section 23   For early stopping, we remove 10k random sen- tences from the MultiNLI training set and combine them with the SNLI development set to create a validation set. Our AllNLI training set contains 280.5K unique sentences (1.8M sentences in total including duplicate premise sentences), and cov- ers six distinct genres of spoken and written En- glish. We do not remove the duplicate sentences. We train the model for 100 epochs for WSJ and 15 epochs for AllNLI. We run the model five times with random initializations and average the results from the five runs. The generated parses from the trained models with the best F1 scores and the pre-trained model that provides the highest F1 are available online. <ref type="bibr">3</ref>    <ref type="table" target="#tab_2">Table 1</ref> shows results with all the models under study, plus several baselines, on WSJ test set and full WSJ10. On full WSJ10, we reproduce the main parsing result of <ref type="bibr" target="#b13">Shen et al. (2018)</ref> with their UP model trained on WSJ without a data split. We also find the choice of parse quality as an early stopping criterion does not have a substantial effect and that training on the (unlabeled) test set does not give a significant improvement in performance. In addition and unexpectedly, we observe that PRPN-LM models achieve higher parsing perfor- mance than PRPN-UP. This shows that any tuning done to separate PRPN-UP from PRPN-LM was not necessary, and more importantly, that the re- sults described in the paper can be largely repro- duced by a unified model in a fair setting. More- over, the PRPN models trained on WSJ achieves   comparable results with CCM ( <ref type="bibr" target="#b8">Klein and Manning, 2002</ref>). The PRPN models are outperformed by DMV+CCM( <ref type="bibr" target="#b9">Klein and Manning, 2005</ref>), and UML-DOP <ref type="bibr" target="#b0">(Bod, 2006</ref>). However, these models use additional information such as POS and de- pendency parser so they are not strictly compara- ble with the PRPN models. Turning to the WSJ test set, the results look somewhat different: Although the differences in WSJ10 performance across models are small, the same is not true for the WSJ in terms of average F1. PRPN-LM outperforms all the other mod- els on WSJ test set, even the potentially-overfit PRPN-UP model. Moreover, the PRPN models trained on the larger, out-of-domain AllNLI per- form better than those trained on WSJ. Surpris- ingly, PRPN-LM tained on out-of-domain AllNLI achieves the best F1 score on WSJ test set among all the models we experimented, even though its performance on WSJ10 is the lowest of all. This mean that PRPN-LM trained on AllNLI is strik- ingly good at parsing longer sentences though its performance on shorter sentences is worse than other models. Under all the configurations we tested, the PRPN model yields much better per-formance than the baselines from <ref type="bibr">Yogatama et al. (2017, called RL-SPINN)</ref> and <ref type="bibr">Choi et al. (2018, called ST-Gumbel)</ref>, despite the fact that the model was tuned exclusively for WSJ10 parsing. This suggests that PRPN is consistently effective at la- tent tree learning.</p><formula xml:id="formula_0">CCM WSJ10 Full - - - 71.9 - - - - - - - DMV+CCM WSJ10 Full - - - 77.6 - - - - - - - UML-DOP WSJ10 Full - - - 82.9 - - - - - - - Random</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>We also show detailed results for several spe- cific constituent types, following <ref type="bibr" target="#b16">Williams et al. (2018a)</ref>. We observe that the accuracy for NP (noun phrases) on the WSJ test set is above 46% <ref type="table" target="#tab_2">(Table 1)</ref> for all PRPN models, much higher than any of the baseline models. These runs also per- form substantially better than the random baseline in the two other categories <ref type="bibr" target="#b16">Williams et al. (2018a)</ref> report: ADJP (adjective phrases) and PP (preposi- tional phrases). However, as WSJ test set contains only one INTJ (interjection phrases), the results on INTJ are either 0.0% or 100%.</p><p>In addition, <ref type="table" target="#tab_6">Table 3</ref> shows that the PRPN-UP models achieve the median parsing F1 scores of 46.3 and 48.6 respectively on the MultiNLI dev set while PRPN-LM performs the median F1 of 45.7; setting the state of the art in parsing perfor- mance on this dataset among latent tree models by a large margin. We conclude that PRPN does ac- quire some substantial knowledge of syntax, and that this knowledge agrees with Penn Treebank (PTB) grammar significantly better than chance.</p><p>Qualitatively, the parses produced by most of the best performing PRPN models are relatively balanced (F1 score of 36.5 w.r.t balanced trees) and tend toward right branching (F1 score of 42.0 with respect to balanced trees). They are also shal- lower than average ground truth PTB parsed trees. These models can parse short sentences relatively well, as shown by their high WSJ10 performance.</p><p>For a large proportion of long sentences, most of the best performing models can produce rea- sonable constituents <ref type="table" target="#tab_2">(Table 1)</ref>. The best perform- ing model, PRPN-LM trained on AllNLI, achieves the best accuracy at identifying ADJP (adjective phrases), PP (prepositional phrases), and INTJ (in- terjection phrases) constituents, and a high accu- racy on NP (noun phrases). In a more informal inspection, we also observe that our best PRPN- LM and PRPN-UP runs are fairly good at pairing determiners with NPs as we can observe in <ref type="figure">Fig- ure 1)</ref>. Although lower level tree constituents ap- pear random in many cases for both PRPN-LM and PRPN-UP, the intermediate and higher-level constituents are generally reasonable. For exam- ple, in <ref type="figure">Figure 1</ref>, although the parse for lower level constituents like The entire Minoan seem random, the higher-level constituents, such as The entire Minoan civilization and nothing worth seeing in the tourist offices, are reasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In our attempt to replicate the grammar induction results reported in <ref type="bibr" target="#b13">Shen et al. (2018)</ref>, we find sev- eral experimental design problems that make the results difficult to interpret. However, in exper- iments and analyses going well beyond the scope of the original paper, we find that the PRPN model presented in that work is nonetheless robust. It represents a viable method for grammar induction and the first clear success for latent tree learning with neural networks, and we expect that it her- alds further work on language modeling as a tool for grammar induction research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>F1 wrt. shows F1 with respect to strictly right-and left-branching (LB/RB) trees and with respect to the Stanford Parser (SP) trees supplied with the corpus; The evaluations of SPINN, RL-SPINN, and ST-Gumbel are from Williams et al. (2018a). SPINN is a supervised parsing model, and the oth- ers are latent tree models. Median F1 of each model trained with 5 different random seeds is re- ported.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Unlabeled parsing F1 results evaluated on full WSJ10 and WSJ test set broken down by train-
ing data and by early stopping criterion. The Accuracy columns represent the fraction of ground truth 
constituents of a given type that correspond to constituents in the model parses. Italics mark results that 
are worse than the random baseline. Underlining marks the best results from our runs. Results with 
RL-SPINN and ST-Gumbel are from Williams et al. (2018a), and are evaluated on the full WSJ. We 
run the model with 5 different random seeds to calculate the average F1. We use the model with the 
best F1 score to report ADJP, NP, PP, and INTJ. WSJ10 baselines are from Klein and Manning (2002, 
CCM), Klein and Manning (2005, DMV+CCM), and Bod (2006, UML-DOP). As the WSJ10 baselines 
are trained using additional information such as POS tags and dependency parser, they are not strictly 
comparable with the latent tree learning results. 

of WSJ) splits. To compare PRPN to the models 
studied in Williams et al. (2018a), we also retrain 
it on AllNLI. As the MultiNLI test set is not pub-
licly available, we follow Williams et al. (2018a) 
and use the development set for testing. The pars-
ing evaluation code in the original codebase does 
not support PRPN-LM, and we modify it in our 
experiments only to add this support. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 shows</head><label>2</label><figDesc>our results for language modeling. PRPN-UP, configured as-is with parsing criterion and language modeling criterion, performs dra- matically worse than the standard PRPN-LM (a vs. d and e). However, this is not a fair comparison as the larger vocabulary gives PRPN-UP a harder task to solve. Adjusting the vocabulary of PRPN- UP down to 10k to make a fairer comparison pos- sible, the PPL of PRPN-UP improves significantly (c vs. d), but not enough to match PRPN-LM (a vs. c). We also observe that early stopping on</figDesc><table>Training 
Stopping Vocab 
PPL 
Model 
Data 
Criterion Size Median 

(a) PRPN-LM WSJ Train LM 
10k 
61.4 
(b) PRPN-LM WSJ Train UP 
10k 
81.6 
(c) PRPN-UP WSJ Train LM 
10k 
92.8 
(d) PRPN-UP WSJ Train LM 
15.8k 112.1 
(e) PRPN-UP WSJ Train UP 
15.8k 112.8 

(f) PRPN-UP AllNLI Train LM 
76k 797.5 
(g) PRPN-UP AllNLI Train UP 
76k 848.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Language modeling performance (per-
plexity) on the WSJ test set, broken down by train-
ing data used and by whether early stopping is 
done using the parsing objective (UP) or the lan-
guage modeling objective (LM). 

parsing leads to incomplete training and a substan-
tial decrease in perplexity (a vs. b and d vs. e). 
The models stop training at around the 13th epoch 
when we early-stop on parsing objective, while 
they stop training around the 65th epoch when we 
early-stop on language modeling objective. Both 
PRPN models trained on AllNLI do even worse 
(f and g), though the mismatch in vocabulary and 
domain may explain this effect. In addition, since 
it takes much longer to train PRPN on the larger 
AllNLI dataset, we train PRPN on AllNLI for only 
15 epochs while we train the PRPN on WSJ for 
100 epochs. Although the parsing objective con-
verges within 15 epochs, we notice that language 
modeling perplexity is still improving. We expect 
that the perplexity of the PRPN models trained on 
AllNLI could be lower if we increase the number 
of training epochs. 
Turning toward parsing performance, </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Unlabeled parsing F1 on the MultiNLI 
development set for models trained on AllNLI. </table></figure>

			<note place="foot" n="2"> https://github.com/yikangshen/PRPN</note>

			<note place="foot" n="3"> https://github.com/nyu-mll/ PRPN-Analysis</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This project has benefited from financial support to SB by Google and Tencent Holdings, and was partly supported by Samsung Electronics (Improv-ing Deep Learning using Latent Structure). We thank Adina Williams, Katharina Kann, Ryan Cot-terell, and the anonymous reviewers for their help-ful comments and suggestions, and NVIDIA for their support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An All-Subtrees Approach to Unsupervised Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rens</forename><surname>Bod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="865" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Two experiments on learning probabilistic dependency grammars from corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Workshop on Statistically-Based NLP Techniques</title>
		<meeting>the AAAI Workshop on Statistically-Based NLP Techniques</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page">113</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to compose task-specific tree structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang-Goo</forename><surname>Kang Min Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence (AAAI-18)</title>
		<meeting>the Thirty-Second Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence (AAAI-18)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Incremental parsing with the perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 42nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07-26" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning task-dependent distributed representations by backpropagation through structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Goller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kuchler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Neural Networks (ICNN&apos;96)</title>
		<meeting>International Conference on Neural Networks (ICNN&apos;96)</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Long Short Term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory</title>
		<imprint>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luong</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Structured attention networks</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A generative constituent-context model for improved grammar induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics-ACL &apos;02</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics-ACL &apos;02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">128</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Natural language grammar induction with a generative constituent-context model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1407" to="1419" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Assessing the ability of lstms to learn syntaxsensitive dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Linzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Dupoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="521" to="535" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Jointly learning sentence embeddings and syntax with unsupervised Tree-LSTMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<idno>1705.09189</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural language modeling by jointly learning syntax and lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yikang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin</forename><surname>Wei Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Guiding unsupervised grammar induction using contrastive estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI Workshop on Grammatical Inference Applications</title>
		<meeting>IJCAI Workshop on Grammatical Inference Applications</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parsing Natural Scenes and Natural Language with Recursive Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff Chiung-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Do latent tree learning models identify meaningful structure in sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Drozdov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bowman. 2018b. A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<meeting>the North American Chapter of the Association for Computational Linguistics (NAACL)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning to Compose Words into Setences with Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
