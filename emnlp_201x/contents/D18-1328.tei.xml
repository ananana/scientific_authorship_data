<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fixing Translation Divergences in Parallel Corpora for Neural MT</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minhquang</forename><surname>Pham</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josep</forename><surname>Crego</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Yvon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename><surname>Systran</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">CNRS</orgName>
								<address>
									<addrLine>5 rue Feydeau</addrLine>
									<postCode>75002</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Université Paris-Saclay</orgName>
								<address>
									<postCode>91405</postCode>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fixing Translation Divergences in Parallel Corpora for Neural MT</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2967" to="2973"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Corpus-based approaches to machine translation rely on the availability of clean parallel corpora. Such resources are scarce, and because of the automatic processes involved in their preparation, they are often noisy. This paper describes an unsupervised method for detecting translation divergences in parallel sentences. We rely on a neural network that computes cross-lingual sentence similarity scores, which are then used to effectively filter out divergent translations. Furthermore , similarity scores predicted by the network are used to identify and fix some partial divergences, yielding additional parallel segments. We evaluate these methods for English-French and English-German machine translation tasks, and show that using fil-tered/corrected corpora actually improves MT performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Parallel sentence pairs are the only necessary re- source to build Machine Translation (MT) sys- tems. In the case of neural MT, a large neural network is trained through maximising a proxy of translation performance on a parallel corpus. Therefore, the quality of MT engines is heavily dependent on the amount but also the quality of available parallel sentences. <ref type="bibr">1</ref> Parallel texts are unfortunately, scarce re- sources: There are relatively few language pairs for which parallel corpora of large sizes exist, and even for those pairs, available corpora only con- cern few restricted domains. To alleviate the lack of parallel data, several approaches have been de- veloped over the years. They range from methods using non-parallel, or comparable data (Zhao and 1 Recent work on neural MT ( <ref type="bibr" target="#b4">Lample et al., 2018;</ref><ref type="bibr">Artetxe et al., 2018)</ref> completely dispenses with parallel data, using unsupervised methods to obtain performance improvements over word-by-word statistical MT. These systems however lag far behind supervised systems, as considered in this work. <ref type="bibr" target="#b18">Vogel, 2002;</ref><ref type="bibr">Fung and Cheung, 2004;</ref><ref type="bibr" target="#b9">Munteanu and Marcu, 2005;</ref><ref type="bibr">Grégoire and Langlais, 2018;</ref><ref type="bibr" target="#b1">Grover and Mitra, 2017;</ref><ref type="bibr" target="#b11">Schwenk, 2018)</ref> to tech- niques that produce synthetic parallel data from monolingual corpora ( <ref type="bibr" target="#b12">Sennrich et al., 2016a;</ref><ref type="bibr">Chinea-Rios et al., 2017)</ref>, using automated align- ment/translation engines that are prone to the in- troduction of noise in the resulting parallel sen- tences. Mismatches in parallel sentences extracted from translated texts are also reported <ref type="bibr" target="#b14">(Tiedemann, 2011;</ref><ref type="bibr" target="#b17">Xu and Yvon, 2016)</ref>. This problem is mostly ignored in MT, where parallel sentences are considered to convey the exact same meaning; yet it seems particularly important for neural MT engines <ref type="bibr">(Chen et al., 2016</ref>   <ref type="table" target="#tab_1">Table 1</ref> gives some examples of English-French parallel sentences that are not completely semanti- cally equivalent, extracted from the OpenSubtitles corpus ( <ref type="bibr" target="#b7">Lison and Tiedemann, 2016)</ref>.</p><p>Multiples types of translation divergences are found in parallel corpora: Additional segments are included on either side of the parallel sentences (first and second rows) most likely due to errors in sentence segmentation; Some translations may be completely uncorrelated (third row); Inaccurate translations also exist (fourth row). Note that di- vergent translations can be due various reasons ( <ref type="bibr" target="#b6">Li et al., 2014)</ref>, the study of which is beyond the scope of this paper.</p><p>In this work, we present an unsupervised method for building cross-lingual sentence em- beddings based on modelling word similarity, re- lying on a neural architecture (see § 3) that is able to identify several types of common cross-lingual divergences. The resulting embeddings are then used to measure semantic equivalence between sentences. To evaluate our method, we show in § 4 that translation accuracy can be improved after filtering out divergent sentence pairs in an English- to-French and an English-to-German translation tasks. We also show that in some cases, divergent sentences can be fixed by removing divergent seg- ments, further increasing translation quality. All the code used in this paper is freely available. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Attempts to measure the impact of translation di- vergences in MT have focused on the introduc- tion of noise in sentence alignments ( <ref type="bibr">Goutte et al., 2012)</ref>, showing that statistical MT is highly robust to noise, and that performance only degrades seri- ously at very high noise levels. In contrast, neu- ral MTs seem to be more sensitive to noise <ref type="bibr">(Chen et al., 2016</ref>), as they tend to assign high probabili- ties to rare events ( <ref type="bibr">Hassan et al., 2018)</ref>. Efforts devoted to characterising the degree of semantic equivalence between two snippets of texts in the same or different languages are pre- sented ( <ref type="bibr" target="#b0">Agirre et al., 2016)</ref>. In <ref type="bibr" target="#b8">(Mueller and Thyagarajan, 2016</ref>), a monolingual sentence similar- ity network is proposed, making use of a simple LSTM layer to compute sentence representations. The authors show that a simple SVM classifier exploiting such sentence representations achieves state-of-the-art results in a textual entailment task. With the same objective, the system of He and Lin (2016) uses multiple convolutional layers and models pairwise word interactions.</p><p>Our work is inspired by <ref type="bibr">Carpuat et al. (2017)</ref>, who train a SVM-based cross-lingual divergence detector using word alignments and sentence length features. Their work shows that an NMT system trained only on non-divergent sentences yields slightly better translation scores, while re- quiring less training time. A follow-up study by the same authors ( <ref type="bibr" target="#b16">Vyas et al., 2018</ref>) achieves even better results, using the neural architecture of <ref type="bibr" target="#b3">He and Lin (2016)</ref>. Our work differs from theirs as we 2 https://github.com/jmcrego/similarity make use of a network with a different, arguably simpler, topology. We model sentence similarity by means of optimising a loss function based on word alignments. Furthermore, the network pre- dicts word similarity scores that we further use to correct divergent sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Neural Divergence Classifier</head><p>The architecture of our network is inspired by the work on word alignment of <ref type="bibr" target="#b5">Legrand et al. (2016)</ref>, using however contextual, rather than fixed, word embeddings (see <ref type="figure" target="#fig_0">Figure 1</ref>). It computes the similarity of any source-target sentence pair (s, t), where s = (s 1 , ..., s I ) and t = (t 1 , ..., t J ). The model is composed of 2 bi-directional LSTM subnetworks, net s and net t , which respectively encode source and tar- get sentences. Since both net s and net t take the same form, we only describe the former net- work: it outputs forward and backward hidden states, − → h src i and ← − h src i , which are then concate-nated into a vector encoding the i th source word as h src</p><formula xml:id="formula_0">i = [ − → h src i ; ← − h src i ].</formula><p>In addition, the last for- ward/backward hidden states (in dark grey on Fig- ure 1) are also concatenated to represent whole sentences</p><formula xml:id="formula_1">h src = [ − → h src I ; ← − h src 1 ].</formula><p>The similarity be- tween sentence pairs can then be obtained using eg. the cosine similarity:</p><formula xml:id="formula_2">sim(h src , h tgt ) = h src · h tgt ||h src || * ||h tgt || (1)</formula><p>Our model is trained to maximize word align- ment scores between words in both sentences, using aggregation functions that summarise the alignment scores for each source/target word. Similar to ( <ref type="bibr" target="#b5">Legrand et al., 2016</ref>), alignment scores S(i, j) are given by the dot-product S(i, j) = h src i · h tgt j , further aggregated as follows:</p><formula xml:id="formula_3">aggr s (i, S) = 1 r log   J j=1 e r * S(i,j)   aggr t (j, S) = 1 r log I i=1 e r * S(i,j)<label>(2)</label></formula><p>The training loss function is then defined as:</p><formula xml:id="formula_4">L(src, tgt) = I i=1 log(1 + e aggrs(i,S) * sign i ) + + J j=1 log(1 + e aggrt(j,S) * sign j )<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training with Negative Examples</head><p>Training is performed by minimizing Eq. (3), for which annotated examples of source (sign i ) and target (sign j ) words are needed. As positive ex- amples, we use paired sentences of a parallel cor- pus; all words in such sentences are labelled as parallel (∀i, j, sign i = sign j = −1). We con- sider three types of negative instances: the basic case uses random unpaired sentences; in this case, all words are labelled as divergent (∀i, j, sign i = sign j = +1.). Since negative pairs may be very easy to classify and we want our network to detect less obvious divergences, we further create more difficult negative examples as follows.</p><p>We first replace random sequences of words in source or target by a sequence of words with the same part-of-speeches. <ref type="bibr">3</ref> Words that are not re- placed are deemed parallel (sign i = −1) while those replaced are annotated as sign i = +1. Words aligned to some replaced words are also assigned the divergent label (sign i = +1). For instance, given the original sentence pair: src: What do you feel ? tgt: Que ressentez-vous ? , we may replace 'you feel', with part-of-speech tags 'PRP VB', by another sequence with same tags (i.e. 'we want'), yielding a new negative instance (divergent words are in bold):</p><p>src:</p><p>What do we want ?</p><formula xml:id="formula_5">Y src : -1 -1 +1 +1 -1 tgt:</formula><p>Que ressentez-vous ?</p><formula xml:id="formula_6">Y tgt : -1 +1 -1</formula><p>Note that we need word alignments to identify as divergent the sequence 'ressentez-vous', which was aligned to 'you feel' in the original sentence. Finally, motivated by sentence segmen- tation errors observed in many corpora, we also build negative examples by inserting a sentence at the beginning (or end) of the source (or target) sen- tence. Words in the original sentence pair are an- notated sign i = −1, while the new words inserted are considered divergent (sign i = +1). Given the same sentence pair as above, a negative example is created by inserting the sentence 'Not .' at the end of the original source: src:</p><p>What do you want ? Not .</p><formula xml:id="formula_7">Y src : -1 -1 -1 -1 -1 +1 +1 tgt:</formula><p>Que ressentez-vous ?</p><formula xml:id="formula_8">Y tgt : -1 -1 -1</formula><p>To finally avoid the generation of easy negative sentence pairs having a large difference in sen- tence length, we restrict negative examples to have a length ratio &lt; 2.0 (3.0 for shortest sentences).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Divergence Correction</head><p>Our training corpora contains many divergent sen- tences that follow a common pattern, consisting of adding some extra leading/trailing words. Accord- ingly, we implemented a simple algorithm that dis- cards sequences of leading/trailing words on both sides. To find optimal source (u, v) and target (x, y) indices that enclose parallel segments within the original sentence, we compute:</p><formula xml:id="formula_9">arg max u,v,x,y u≤I≤v max x≤j≤y {S(i, j)}</formula><p>The N -best sequences (s v u , t y x ) are considered as likely corrections, in which we use the one having the highest similarity score to replace the original (s I 1 , t J 1 ). Note that short sentences are not consid- ered and we enforce v − u &gt; τ and y − x &gt; τ . <ref type="figure" target="#fig_2">Figure 2</ref> (left) displays an example of an align- ment matrix S(i, j). An acceptable correction is: Que ressentez-vous ? ⇔ What do you feel ?. cor- responding to u = 1, v = 5, x = 1 and y = 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Corpora</head><p>We filter out divergences from the English-French OpenSubtitles corpus ( <ref type="bibr" target="#b7">Lison and Tiedemann, 2016)</ref>, which consists of a collection of movie and TV subtitles. We also use the very noisy English- German Paracrawl 4 corpus. Both corpora present many potential divergences. To evaluate English- French translation performance, we use the En- Fr Microsoft Spoken Language Translation cor- pus, created from actual Skype conversations <ref type="bibr">(Federmann and Lewis, 2016)</ref>. English-German per- formance is evaluated on the publicly available Newstest-2017 ( <ref type="bibr">Bojar et al., 2017</ref>), corresponding to news stories selected from online sources.</p><p>In order to better assess the quality of our clas- sifier when facing different word divergences, we also collected from the original OpenSubtitles cor- pus 500 sentences containing different types of ex- amples: 200 paired sentences; 100 unpaired sen- tences; 100 sentences with replace examples; and 100 sentences with insert examples (see § 3.1). All data is preprocessed with OpenNMT 5 , per- forming minimal tokenisation. After tokenisation, each out-of-vocabulary word is mapped to a spe- cial UNK token, assuming a vocabulary contain- ing the 50, 000 more frequent words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Neural Divergence</head><p>Word embeddings of E s = E t = 256 cells are initialised using fastText, <ref type="bibr">6</ref> further aligned by means of MUSE 7 following the unsupervised method of <ref type="bibr" target="#b4">Lample et al. (2018)</ref>. Both bi-LSTMs use 256-dimensional hidden representations (E = 512). Network optimization is done using SGD with gradient clipping ( <ref type="bibr" target="#b10">Pascanu et al., 2013)</ref>. For each epoch, we randomly select 1 million sentence pairs that we place in batches of 32 examples. We run 10 epochs and start decaying at each epoch by 0.8 when the loss on validation set increases. Di- vergence is computed as in equation <ref type="formula">(1)</ref> and set- ting r = 1.0 ; For divergence correction, we use N = 20 and τ = 3. The same number of exam- ples are always generated for each type of exam- ple (Paired, Unpaired, Replace and Insert). Align- ments needed for Replace and Insert methods are performed using fast align 8 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Neural Translation</head><p>In addition to the basic tokenisation detailed above, we perform Byte-Pair Encoding ( <ref type="bibr" target="#b13">Sennrich et al., 2016b</ref>) with 30000 merge operations learned by joining both language sides. Neural systems are based on the open-source project OpenNMT; using a Transformer model similar to the model of <ref type="bibr" target="#b15">Vaswani et al. (2017)</ref>: both encoder and de- coder have 6 layers; Multi-head attention is per- formed over 8 head; the hidden layer size is 512; and the inner layer of feed forward network is of size 2048. Word embeddings have 512 cells. We set the dropout probability to 0.1 and the batch size to 3072. The optimiser is Lazy Adam with β 1 = 0.9, β 2 = 0.98, = 10 −9 , warmup steps = 4000. Training stops after 30 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We first evaluate the ability of our divergence clas- sifier to predict different types of divergences at the level of words. We use the test set manually an- notated for that purpose and train our model on the OpenSubtitles corpus. A word is considered di- vergent when associated to a negative aggregation score (see Equation <ref type="formula" target="#formula_3">(2)</ref>). Accuracies obtained for various combinations of negative examples, where we see that non-divergent words in parallel and un- paired sentences (columns P and U) are easy to spot, as long as the model has seen these types of examples in training. However, the accuracy drops dramatically when the model is not trained with unpaired sentences (rows PR, PI and PRI). Regarding columns R and I, accuracies are lower since these sentences contain a mix of divergent and non-divergent words.  Models that were trained with the matching ex- amples (R and I) obtain the highest accuracies (in bold letters). Column PURI gives results for the complete test set, mixing all type of examples. As expected, the best accuracy is also obtained when training on all types of examples. <ref type="figure" target="#fig_2">Figure 2</ref> illustrates the output of our network when trained using PU examples (right) and PURI examples (left). The former (right) fails to predict some divergences, most likely because its train- ing set does not contain sentences mixing diver- gent and non-divergent words. Furthermore, the network trained with PURI examples correctly as- signs a lower similarity score to this pair, as both sentences do not convey the exact same meaning. Finally, BLEU scores obtained with varying training data configurations are in <ref type="table" target="#tab_4">Table 3</ref>: The en- tire 9 data sets (all); The most similar pairs after <ref type="bibr">9</ref> Paracrawl contains more than 100M sentences. We re- duced its size to 22.2M using standard filtering techniques. optimizing Eq. (3) (sim); After applying the cor- rection algorithm of § 3.2 (sim+fix). Columns Ref and Fix indicate the number of original and corrected sentences (in millions) used in training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head><p>Ref <ref type="formula">(</ref>  Results obtained after filtering sentence pairs (sim) clearly outperform the baseline (all) by +0.94 and +2.25 BLEU respectively. Regarding OpenSubtitles, when fixing 2.5M sentences (4 th row) the accuracy is further boosted to +2.01, whereas the same sentence pairs do not show any improvement when added in their original form (3 rd row). Similar results are obtained for the Paracrawl corpus. Results after fixing 2.5M sen- tences (4 th row) outperform those obtained with their original form (3 rd row).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and outlook</head><p>We presented an unsupervised method based on deep neural networks for detecting translation di- vergences in parallel corpora. Our model op- timizes word alignments, and computes a fine grained divergence prediction at the level of words. Misaligned/divergent words can then be filtered out, yielding larger and better training sets. Our experiments on two machine translation tasks show significant improvements in comparison to training with the entire data set.</p><p>We plan to use our model to predict sentence embeddings over monolingual corpora, allowing to collect parallel pairs through vector similarity measures. In addition, we would like to mea- sure the performance of our model after applying subword tokenisation, as well as using multiple LSTM layers, a technique well known to capture hierarchical structure in the context of MT. Cyril Goutte, marine carpuat, and Georges Foster. 2012. The impact of sentence alignment errors on phrase-based machine translation performance. In The Tenth Biennial Conference of the Association for Machine Translation in the Americas, San Diego, California.</p><p>Francis Grégoire and Philippe Langlais. 2018. Ex- tracting parallel sentences with bidirectional recur- rent neural networks to improve machine translation. In Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018, Santa Fe, New Mexico, USA, August <ref type="bibr">20-26, 2018, pages 1442-1453.</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of the model.</figDesc><graphic url="image-1.png" coords="2,329.10,246.61,174.62,361.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sentence pair with similarity scores produced by our model when trained with PU examples (right) and over PURI examples (left). Aggregation scores (Eq. (2)) are shown next to words. Matrices contain alignment scores. Sentence similarities (Eq. (1)) are below matrices.</figDesc><graphic url="image-2.png" coords="5,103.38,458.62,76.40,159.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Marine</head><label></label><figDesc>Carpuat, Yogarshi Vyas, and Xing Niu. 2017. Detecting cross-lingual semantic divergence for neural machine translation. In Proceedings of the First Workshop on Neural Machine Translation, pages 69-79, Vancouver. Association for Computa- tional Linguistics. Boxing Chen, Roland Kuhn, George Foster, Colin Cherry, and Fei Huang. 2016. Bilingual methods for adaptive training data selection for machine trans- lation. In Proceedings of the 12th biennial confer- ence of the Association for the Machine Translation in Americas (AMTA2016), Austin, TX. Mara Chinea-Rios, ´ Alvaro Peris, and Francisco Casacuberta. 2017. Adapting neural machine trans- lation with parallel synthetic data. In Proceedings of the Second Conference on Machine Translation, pages 138-147, Copenhagen, Denmark. Association for Computational Linguistics. Christian Federmann and Will Lewis. 2016. Mi- crosoft speech language translation (MSLT) cor- pus: The IWSLT 2016 release for English, French and German. In Proceedings of the Interna- tional Workshop on Spoken Language Translation (IWSLT2016), Seattle, WA. Pascale Fung and Percy Cheung. 2004. Mining very- non-parallel corpora: Parallel sentence and lexicon extraction via bootstrapping and EM. In Proceed- ings of the 2004 Conference on Empirical Methods in Natural Language Processing, EMNLP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples of semantically divergent parallel sen-

tences. English (en), French (fr) and gloss of French (gl). 
Divergences are in bold letters. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Word divergence accuracies according to different 

type of examples used in train/test. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>M) Fix (M) Test (BLEU)</head><label></label><figDesc></figDesc><table>OpenSubtitles English-French 

all 
27.2 
-
42.18 
sim 
15.5 
-
43.12 (+0.94) 
sim 
18.0 
-
43.19 (+1.01) 
sim+fix 
15.5 
2.5 
44.19 (+2.01) 

Paracrawl English-German 

all 
22.2 
-
19.27 
sim 
15.0 
-
21.52 (+2.25) 
sim 
17.5 
-
21.97 (+2.70) 
sim+fix 
15.0 
2.5 
22.42 (+3.15) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>BLEU scores obtained by neural MT using differ-

ent subsets of the OpenSubtitles and Paracrawl corpora. 

</table></figure>

			<note place="foot" n="3"> The rationale is to try to keep the generated sentences as grammatical as possible; Otherwise, the network could learn to flag non-grammatical sentences as non-parallel.</note>

			<note place="foot" n="4"> http://paracrawl.eu/ 5 http://opennmt.net 6 https://github.com/facebookresearch/fastText 7 https://github.com/facebookresearch/MUSE</note>

			<note place="foot" n="8"> https://github.com/clab/fast align</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are grateful to J. Legrand for his fruitful com-ments regarding the neural divergence classifier.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 1: Semantic textual similarity, monolingual and cross-lingual evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carmen</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><forename type="middle">T</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="497" to="511" />
		</imprint>
	</monogr>
	<note>SemEval@NAACLHLT</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bilingual word embeddings with bucketed CNN for parallel sentence extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeenu</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pabitra</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2017, Student Research Workshop</title>
		<meeting>ACL 2017, Student Research Workshop<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="11" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Aue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Chowdhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuangzhi</forename><surname>Wu</surname></persName>
		</author>
		<idno>abs/1803.05567</idno>
		<title level="m">Yingce Xia, Dongdong Zhang, Zhirui Zhang, and Ming Zhou. 2018. Achieving human parity on</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pairwise word interaction modeling with deep neural networks for semantic similarity measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="937" to="948" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Word translation without parallel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<meeting><address><addrLine>Long Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural network-based word alignment through score aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joël</forename><surname>Legrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cross-lingual discourse relation analysis: A corpus study and a semi-supervised classification system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyi Jessy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="577" to="587" />
		</imprint>
		<respStmt>
			<orgName>Dublin City University and Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Opensubtitles2016: Extracting large parallel corpora from movie and tv subtitles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Lison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting><address><addrLine>Portoroz, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Siamese recurrent architectures for learning sentence similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Thyagarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI&apos;16</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence, AAAI&apos;16<address><addrLine>Phoenix, Arizona</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2786" to="2792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improving machine translation performance by exploiting non-parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dragos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Munteanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="477" to="504" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>III- 1310-III-1318</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on International Conference on Machine Learning</title>
		<meeting>the 30th International Conference on International Conference on Machine Learning<address><addrLine>Atlanta, GA, USA. JMLR.org</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Filtering and mining parallel data in a joint multilingual space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="228" to="234" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="86" to="96" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Bitext Alignment. Synthesis Lectures on Human Language Technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Identifying semantic divergences in parallel text without annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogarshi</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1503" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Novel elicitation and annotation schemes for sentential and subsentential alignments of bitexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Portoroz, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adaptive parallel sentences mining from web bilingual news collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 IEEE International Conference on Data Mining, ICDM &apos;02</title>
		<meeting>the 2002 IEEE International Conference on Data Mining, ICDM &apos;02<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
