<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Compositional Denotational Semantics for Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Gupta</surname></persName>
							<email>nitishg@seas.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research Seattle</orgName>
								<orgName type="institution">University of Pennsylvania Philadelphia</orgName>
								<address>
									<region>PA, WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
							<email>mikelewis@fb.com</email>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research Seattle</orgName>
								<orgName type="institution">University of Pennsylvania Philadelphia</orgName>
								<address>
									<region>PA, WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Compositional Denotational Semantics for Question Answering</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2152" to="2161"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2152</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Answering compositional questions requiring multi-step reasoning is challenging. We introduce an end-to-end differentiable model for interpreting questions about a knowledge graph (KG), which is inspired by formal approaches to semantics. Each span of text is represented by a denotation in a KG and a vector that captures ungrounded aspects of meaning. Learned composition modules recursively combine constituent spans, culminating in a grounding for the complete sentence which answers the question. For example, to interpret &quot;not green&quot;, the model represents &quot;green&quot; as a set of KG entities and &quot;not&quot; as a trainable un-grounded vector-and then uses this vector to parameterize a composition function that performs a complement operation. For each sentence , we build a parse chart subsuming all possible parses, allowing the model to jointly learn both the composition operators and output structure by gradient descent from end-task supervision. The model learns a variety of challenging semantic operators, such as quanti-fiers, disjunctions and composed relations, and infers latent syntactic structure. It also generalizes well to longer questions than seen in its training data, in contrast to RNN, its tree-based variants, and semantic parsing baselines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Compositionality is a mechanism by which the meanings of complex expressions are systemati- cally determined from the meanings of their parts, and has been widely assumed in the study of both artificial and natural languages <ref type="bibr" target="#b13">(Montague, 1973)</ref> as a means for allowing speakers to generalize to understanding an infinite number of sentences. Pop- ular neural network approaches to question answer- ing use a restricted form of compositionality, typi- cally encoding a sentence word-by-word, and then * Work done while interning with <ref type="bibr">Facebook AI Research.</ref> executing the complete sentence encoding against a knowledge source ( <ref type="bibr" target="#b16">Perez et al., 2017)</ref>. Such mod- els can fail to generalize from training data in sur- prising ways. Inspired by linguistic theories of compositional semantics, we instead build a latent tree of interpretable expressions over a sentence, recursively combining constituents using a small set of neural modules. Our model outperforms RNN encoders, particularly when test questions are longer than training questions.</p><p>Our approach resembles Montague semantics, in which a tree of interpretable expressions is built over the sentence, with nodes combined by a small set of composition functions. However, both the structure of the sentence and the composition func- tions are learned by end-to-end gradient descent. To achieve this, we define the parametric form of small set of composition modules, and then build a parse chart over each sentence subsuming all pos- sible trees. Each node in the chart represents a span of text with a distribution over groundings (in terms of booleans and knowledge base nodes and edges), as well as a vector representing aspects of the meaning that have not yet been grounded. The representation for a node is built by taking a weighted sum over different ways of building the node (similar to <ref type="bibr" target="#b12">Maillard et al. (2017)</ref>). The trees induced by our model are linguistically plausible, in contrast to prior work on structure learning from semantic objectives ( <ref type="bibr" target="#b20">Williams et al., 2018)</ref>.</p><p>Typical neural approaches to grounded question answering first encode a question with a recur- rent neural network (RNN), and then evaluate the encoding against an encoding of the knowledge source (for example, a knowledge graph or image) ( <ref type="bibr" target="#b17">Santoro et al., 2017)</ref>. In contrast to classical ap- proaches to compositionality, constituents of com- plex expressions are not given explicit interpreta- tions in isolation. For example, in Which cubes are large or green?, an RNN encoder will not explic- A correct parse for a question given the knowledge graph on the right, using our model. We show the type for each node, and its denotation in terms of the knowledge graph. The words or and not are represented by vectors, which parameterize composition modules. The denotation for the complete question represents the answer to the question. Nodes here have types E for sets of entities, R for relations, V for ungrounded vectors, EV for a combination of entities and a vector, and φ for semantically vacuous nodes. While we show only one parse tree here, our model builds a parse chart subsuming all trees.</p><p>itly build an interpretation for the phrase large or green. We show that such approaches can general- ize poorly when tested on more complex sentences than they were trained on. Our approach instead imposes independence assumptions that give a lin- guistically motivated inductive bias. In particular, it enforces that phrases are interpreted indepen- dently of surrounding words, allowing the model to generalize naturally to interpreting phrases in different contexts. In our model, large or green will be represented as a particular set of entities in a knowledge graph, and be intersected with the set of entities represented by the cubes node.</p><p>Another perspective on our work is as a method for learning layouts of Neural Module Networks (NMNs) ( <ref type="bibr" target="#b1">Andreas et al., 2016b</ref>). Work on NMNs has focused on construction of the structure of the network, variously using rules, parsers and rein- forcement learning ( <ref type="bibr" target="#b0">Andreas et al., 2016a;</ref><ref type="bibr" target="#b6">Hu et al., 2017)</ref>. Our end-to-end differentiable model jointly learns structures and modules by gradient descent.</p><p>Our model is a new combination of classical and neural methods, which maintains the interpretabil- ity and generalization behaviour of semantic pars- ing, while being end-to-end differentiable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model Overview</head><p>Our task is to answer a question q = w 1..|q| , with respect to a Knowledge Graph (KG) consisting of nodes E (representing entities) and labelled di- rected edges R (representing relationship between entities). In our task, answers are either booleans, or specific subsets of nodes from the KG.</p><p>Our model builds a parse for the sentence, in which phrases are grounded in the KG, and a small set of composition modules are used to combine phrases, resulting in a grounding for the complete question sentence that answers it. For example, in <ref type="figure" target="#fig_0">Figure 1</ref>, the phrases not and cylindrical are interpreted as a function word and an entity set, respectively, and then not cylindrical is interpreted by computing the complement of the entity set. The node at the root of the parse tree is the answer to the question. Our model answers questions by:</p><p>(a) Grounding individual tokens in a KG, that can either be grounded as particular sets of entities and relations in the KG, as ungrounded vectors, or marked as being semantically vacuous. For each word, we learn parameters that are used to compute a distribution over semantic types and correspond- ing denotations in a KG ( § 3.1).</p><p>(b) Combining representations for adjacent phrases into representations for larger phrases, us- ing trainable neural composition modules ( § 3.2). This produces a denotation for the phrase.</p><p>(c) Assigning a binary-tree structure to the ques- tion sentence, which determines how words are grounded, and which phrases are combined using which modules. We build a parse chart subsuming all possible structures, and train a parsing model to increase the likelihood of structures leading to the correct answer to questions. Different parses leading to a denotation for a phrase of type t are merged into an expected denotation, allowing dy- namic programming ( § 4).</p><p>(d) Answering the question, with the most likely grounding of the phrase spanning the sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2154</head><p>3 Compositional Semantics</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Semantic Types</head><p>Our model classifies spans of text into different se- mantic types to represent their meaning as explicit denotations, or ungrounded vectors. All phrases are assigned a distribution over semantic types. The se- mantic type determines how a phrase is grounded, and which composition modules can be used to combine it with other phrases. A phrase spanning w i..j has a denotation w i..j t KG for each semantic type t. For example, in <ref type="figure" target="#fig_0">Figure 1</ref>, red corresponds to a set of entities, left corresponds to a set of rela- tions, and not is treated as an ungrounded vector.</p><p>The semantic types we define can be classified into three broad categories.</p><p>Grounded Semantic Types: Spans of text that can be fully grounded in the KG.</p><p>1. Entity (E): Spans of text that can be grounded to a set of entities in the KG, for example, red sphere or large cube. E-type span grounding is represented as an attention value for each en- tity,</p><formula xml:id="formula_0">[p e 1 , . . . , p e |E| ], where p e i ∈ [0, 1]</formula><p>. This can be viewed as a soft version of a logical set-valued denotation, which we refer to as a soft entity set.</p><p>2. Relation (R): Spans of text that can be grounded to set of relations in the KG, for example, left of or not right of or above. R- type span grounding is represented by a soft adjacency matrix A ∈ R |E|×|E| where A ij = 1 denotes a directed edge from e i → e j .</p><p>3. Truth (T): Spans of text that can be grounded with a Boolean denotation, for example, Is anything red?, Is one ball green and are no cubes red?. T-type span grounding is repre- sented using a real-value p true ∈ [0, 1] that denotes the probability of the span being true.</p><p>Ungrounded Semantic Types: Spans of text whose meaning cannot be grounded in the KG.</p><p>1. Vector (V): This type is used for spans repre- senting functions that cannot yet be grounded in the KG (e.g. words such as and or every). These spans are represented using 4 different real-valued vectors v 1 -v 4 ∈ R 2 -R 5 , that are used to parameterize the composition mod- ules described in §3.2.</p><p>2. Vacuous (φ φ φ): Spans that are considered se- mantically vacuous, but are necessary syntac- tically, e.g. of in left of a cube. During com- position, these nodes act as identity functions.</p><p>Partially-Grounded Semantic Types: Spans of text that can only be partially grounded in the knowledge graph, such as and red or are four spheres. Here, we represent the span by a com- bination of a grounding and vectors, representing grounded and ungrounded aspects of meaning re- spectively. The grounded component of the repre- sentation will typically combine with another fully grounded representation, and the ungrounded vec- tors will parameterize the composition module. We define 3 semantic types of this kind: EV, RV and TV, corresponding to the combination of entities, relations and boolean groundings respectively with an ungrounded vector. Here, the word represented by the vectors can be viewed as a binary function, one of whose arguments has been supplied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Composition Modules</head><p>Next, we describe how we compose phrase repre- sentations (from § 3.1) to represent larger phrases. We define a small set of composition modules, that take as input two constituents of text with their cor- responding semantic representations (grounded rep- resentations and ungrounded vectors), and outputs the semantic type and corresponding representation of the larger constituent. The composition modules are parameterized by the trainable word vectors. These can be divided into several categories:</p><p>Composition modules resulting in fully grounded denotations: Described in <ref type="figure" target="#fig_3">Figure 2</ref>.</p><p>Composition with φ φ φ-typed nodes: Phrases with type φ φ φ are treated as being semantically transparent identity functions. Phrases of any other type can combined with these nodes, with no change to their type or representation.</p><p>Composition modules resulting in partially grounded denotations: We define several mod- ules that combine fully grounded phrases with un- grounded phrases, by deterministically taking the union of the representations, giving phrases with partially grounded representations ( § 3.1). These modules are useful when words act as binary func- tions; here they combine with their first argument. For example, in <ref type="figure" target="#fig_0">Fig. 1</ref>, or and not cylindrical com- bine to make a phrase containing both the vectors for or and the entity set for not cylindrical. </p><formula xml:id="formula_1">E E E p ei = 2 4 w 1 w 2 b 3 5 · 2 4 p L ei p R ei 1 3 5 ! E + E → E:</formula><p>This module performs a function on a pair of soft entity sets, parameterized by the model's global param- eter vector [w1, <ref type="bibr">w2, b]</ref> to produce a new soft entity set. The composition function for a single entity's resulting attention value is shown. Such a composition module can be used to interpret compound nouns and entity appositions. For exam- ple, the composition module shown above learns to output the intersection of two entity sets.</p><formula xml:id="formula_2">not cylindrical E V E p ei = ✓ v 1 ·  p R ei 1 ◆ V + E → E:</formula><p>This module performs a function on a soft entity set, parameterized by a word vector, to produce a new soft entity set. For example, the word not learns to take the com- plement of a set of entities. The entity attention representation of the resulting span is computed by using the indicated func- tion that takes the v1 ∈ R 2 vector of the V constituent as a parameter argument and the entity attention vector of the E constituent as a function argument. </p><formula xml:id="formula_3">small or purple E E EV p ei = v 2 · 2 4 p L ei p R ei 1 3 5 ! EV + E → E:</formula><formula xml:id="formula_4">E E R p ei = max ej A ji · p R ej R + E → E:</formula><p>This module composes a set of relations (repre- sented as a single soft adjacency matrix) and a soft entity set to produce an output soft entity set. The composition function uses the adjacency matrix representation of the R-span and the soft entity set representation of the E-span.</p><formula xml:id="formula_5">E V T is anything cylindrical True p true = v 1 3 " X ei  v 3 3 v 4 3 ·  p R ei 1 !# + v 2 3 ! V + E → T:</formula><p>This module maps a soft entity set onto a soft boolean, parameterized by word vector (v3). The module counts whether a sufficient number of elements are in (or out) of the set. For example, the word any should test if a set is non-empty.</p><formula xml:id="formula_6">p true = v 1 4 " X ei 2 4 v 3 4 v 4 4 v 5 4 3 5 · 2 4 p L ei p R ei 1 3 5 !# + v 2 4 ! False E EV T is every cylinder blue</formula><p>EV + E → T: This module combines two soft entity sets into a soft boolean, which is useful for modelling generalized quantifiers. For example, in is every cylinder blue, the module can use the inner sigmoid to test if an element ei is in the set of cylinders (p L e i ≈ 1) but not in the set of blue things (p R e i ≈ 0), and then use the outer sigmoid to return a value close to 1 if the sum of elements matching this property is close to 0. This module maps a pair of soft booleans into a soft boolean using the v2 word vector to parameterize the composition function. Similar to EV + E → E, this module facilitates modeling a range of boolean set operations. Using the same functional form for different composition functions allows our model to use the same ungrounded word vector (v2) for compositions that are semantically analogous.</p><formula xml:id="formula_7">A ij = v 2 · 2 4 A L ij A R ij 1 3 5 ! left of or above R R RV RV + R → R:</formula><p>This module composes a pair of soft set of relations to a produce an output soft set of relations. For example, the relations left and above are composed by the word or to produce a set of relations such that entities ei and ej are related if either of the two relations exists between them. The functional form for this composition is similar to EV + E → E and TV + T → T modules. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Parsing Model</head><p>Here, we describe how our model classifies ques- tion tokens into semantic type spans and computes their representations ( § 4.1), and recursively uses the composition modules defined above to parse the question into a soft latent tree that provides the answer ( § 4.2). The model is trained end-to-end using only question-answer supervision ( § 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Lexical Representation Assignment</head><p>Each token in the question sentence is assigned a distribution over the semantic types, and a grounded representation for each type. Tokens can only be assigned the E, R, V, and φ φ φ types. For example, the token cylindrical in the question in <ref type="figure" target="#fig_0">Fig. 1</ref> is assigned a distribution over the 4 semantic types (one shown) and for the E type, its represen- tation is the set of cylindrical entities.</p><p>Semantic Type Distribution for Tokens: To compute the semantic type distribution, our model represents each word w, and each semantic type t using an embedding vector; v w , v t ∈ R d . The se- mantic type distribution is assigned with a softmax:</p><formula xml:id="formula_8">p(t|w i ) ∝ exp(v t · v w i )</formula><p>Grounding for Tokens: For each of the seman- tic type, we need to compute their representations:</p><p>1. E-Type Representation: Each entity e ∈ E, is represented using an embedding vector v e ∈ R d based on the concatenation of vectors for its properties. For each token w, we use its word vector to find the probability of each entity being part of the E-Type grounding:</p><formula xml:id="formula_9">p w e i = σ(v e i · v w ) ∀ e i ∈ E</formula><p>For example, in <ref type="figure" target="#fig_0">Fig. 1</ref>, the word red will be grounded as all the red entities.</p><p>2. R-Type Representation: Each relation r ∈ R, is represented using an embedding vector v r ∈ R d . For each token w i , we compute a distribution over relations, and then use this to compute the expected adjacency matrix that forms the R-type representation for this token.</p><formula xml:id="formula_10">p(r|w i ) ∝ exp(v r · v w i ) A w i = r∈R p(r|w i ) · A r</formula><p>e.g. the word left in <ref type="figure" target="#fig_0">Fig. 1</ref> is grounded as the subset of edges with label 'left'.</p><p>3. V-Type Representation: For each word w ∈ V, we learn four vectors v 1 ∈ R 2 , v 2 ∈ R 3 , v 3 ∈ R 4 , v 4 ∈ R 5 , and use these as the representation for words with the V-Type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">φ φ φ-Type</head><p>Representation: Semantically vacuous words that do not require a representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parsing Questions</head><p>To learn the correct structure for applying composi- tion modules, we use a simple parsing model. We build a parse-chart over the question encompass- ing all possible trees by applying all composition modules, similar to a standard CRF-based PCFG parser using the CKY algorithm. Each node in the parse-chart, for each span w i..j of the question, is represented as a distribution over different semantic types with their corresponding representations.</p><p>Phrase Semantic Type Potential (ψ t i,j ): The model assigns a score, ψ t i,j , to each w i..j span, for each semantic type t. This score is computed from all possible ways of forming the span w i..j with type t. For a particular composition of span w i..k of type t 1 and w k+1..j of type t 2 , using the t 1 + t 2 → t module, the composition score is:</p><formula xml:id="formula_11">ψ t 1 +t 2 →t i,k,j = ψ t 1 i,k · ψ t 2 k+1,j · e θ·f t 1 +t 2 →t (i,j,k|q)</formula><p>where θ is a trainable vector and f t 1 +t 2 →t (i, j, k|q) is a simple feature function. Features consist of a conjunction of the composition module type and: the words before (w i−1 ) and after (w j+1 ) the span, the first (w i ) and last word (w k ) in the left con- stituent, and the first (w k+1 ) and last (w j ) word in the right constituent. The final t-type potential of w i..j is computed by summing scores over all possible compositions: where w i..j t KG , is the t-type representation of the span w i..j and w i..k..j t 1 +t 2 →t KG is the representa- tion resulting from the composition of w i..k with w k+1..j using the t 1 +t 2 → t composition module.</p><formula xml:id="formula_12">ψ t i,j = j</formula><p>Answer Grounding: By recursively computing the phrase semantic-type potentials and representa- tions, we can infer the semantic type distribution of the complete question and the resulting grounding for different semantic types t, w 1..|q| t KG . p(t|q) ∝ ψ(1, |q|, t)</p><p>The answer-type (boolean or subset of entities) for the question is computed using:</p><formula xml:id="formula_14">t * = argmax t∈T,E p(t|q)<label>(2)</label></formula><p>The corresponding grounding is w 1..|q| t * KG , which answers the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training Objective</head><p>Given a dataset D of (question, answer, knowledge- graph) tuples,</p><formula xml:id="formula_15">{q i , a i , KG i } i=|D| i=1</formula><p>, we train our model to maximize the log-likelihood of the correct answers. We maximize the following objective:</p><formula xml:id="formula_16">L = i log p(a i |q i , KG i )<label>(3)</label></formula><p>Further details regarding the training objective are given in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Dataset</head><p>We experiment with two datasets, 1) Questions gen- erated based on the CLEVR (Johnson et al., 2017) dataset, and 2) Referring Expression Generation (GenX) dataset <ref type="bibr" target="#b4">(FitzGerald et al., 2013)</ref>, both of which feature complex compositional queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLEVRGEN:</head><p>We generate a dataset of ques- tion and answers based on the CLEVR dataset <ref type="bibr" target="#b7">(Johnson et al., 2017)</ref>, which contains knowledge graphs containing attribute information of objects and relations between them. We generate a new set of questions as existing questions contain some biases that can be exploited by models. <ref type="bibr">1</ref> We generate 75K questions for train- ing and 37.5K for validation. Our questions test var- ious challenging semantic operators. These include conjunctions (e.g. Is anything red and large?), negations (e.g. What is not spherical?), counts (e.g. Are five spheres green?), quantifiers (e.g. Is every red thing cylindrical?), and relations (e.g. What is left of and above a cube?). We create two test sets:</p><p>1. Short Questions: Drawn from the same dis- tribution as the training data (37.5K).</p><p>2. Complex Questions: Longer questions than the training data (22.5K). This test set con- tains the same words and constructions, but chained into longer questions. For example, it contains questions such as What is a cube that is right of a metallic thing that is beneath a blue sphere? and Are two red cylinders that are above a sphere metallic? Solving these questions require more multi-step reasoning.</p><p>REFERRING EXPRESSIONS (GENX) ( <ref type="bibr" target="#b4">FitzGerald et al., 2013)</ref>: This dataset con- tains human-generated queries, which identify a subset of objects from a larger set (e.g. all of the red items except for the rectangle). It tests the ability of models to precisely understand human-generated language, which contains a far greater diversity of syntactic and semantic structures. This dataset does not contain relations between entities, and instead only focuses on entity-set operations. The dataset contains 3920 questions for training, 600 for development and 940 for testing. Our modules and parsing model were designed independently of this dataset, and we re-use hyperparameters from CLEVRGEN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>Our experiments investigate the ability of our model to understand complex synthetic and nat- ural language queries, learn interpretable structure, and generalize compositionally. We also isolate the effect of learning the syntactic structure and repre- senting sub-phrases using explicit denotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimentation Setting</head><p>We describe training details, and the baselines.</p><p>Training Details: Training the model is chal- lenging since it needs to learn both good syntac- tic structures and the complex semantics of neural modules-so we use Curriculum Learning ( <ref type="bibr" target="#b2">Bengio et al., 2009</ref>) to pre-train the model on an easier sub- set of questions. Appendix B contains the details of curriculum learning and other training details.  <ref type="table" target="#tab_3">Table 1</ref>: Results for Short Questions (CLEVRGEN): Performance of our model compared to baseline models on the Short Questions test set. The LSTM (NO KG) has accuracy close to chance, showing that the questions lack trivial biases. Our model almost perfectly solves all questions showing its ability to learn challenging semantic operators, and parse questions only using weak end-to-end supervision.</p><p>Baseline Models: We compare to the following baselines. (a) Models that assume linear structure of language, and encode the question using linear RNNs-LSTM (NO KG), LSTM, BI-LSTM, and a RELATION-NETWORK ( <ref type="bibr" target="#b17">Santoro et al., 2017</ref>) aug- mented model. 2 (b) Models that assume tree-like structure of language. We compare two variants of Tree-structured LSTMs ( <ref type="bibr" target="#b22">Zhu et al., 2015;</ref><ref type="bibr" target="#b18">Tai et al., 2015</ref>)-TREE-LSTM, that operates on pre- parsed questions, and TREE-LSTM(UNSUP.), an unsupervised Tree-LSTM model ( <ref type="bibr" target="#b12">Maillard et al., 2017</ref>) that learns to jointly parse and represent the sentence. For GENX, we also use an end-to-end semantic parsing model from <ref type="bibr" target="#b15">Pasupat and Liang (2015)</ref>. Finally, to isolate the contribution of the proposed denotational-semantics model, we train our model on pre-parsed questions. Note that, all LSTM based models only have access to the enti- ties of the KG but not the relationship information between them. See Appendix C for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experiments</head><p>Short Questions Performance:  Results for Complex Questions (CLEVRGEN): All baseline models fail to gener- alize well to questions requiring longer chains of reasoning than those seen during training. Our model substantially outperforms the baselines, showing its ability to perform complex multi-hop reasoning, and generalize from its training data. Analysis suggests that most errors from our model are due to assigning incorrect structures, rather than mistakes by the composition modules.</p><p>Complex Questions Performance: <ref type="table" target="#tab_4">Table 2</ref> shows results on complex questions, which are con- structed by combining components of shorter ques- tions. These require complex multi-hop reasoning, and the ability to generalize robustly to new types of questions. We use the same models as in <ref type="table" target="#tab_3">Table 1</ref>, which were trained on short questions. All base- lines achieve close to random performance, despite high accuracy for shorter questions. This shows the challenges in generalizing RNN encoders be- yond their training data. In contrast, the strong inductive bias from our model structure allows it to generalize well to complex questions. Our model outperforms TREE-LSTM (UNSUP.) and the ver- sion of our model that uses pre-parsed questions, showing the effectiveness of explicit denotations and learning the syntax, respectively.  Performance on Human-generated Language: <ref type="table" target="#tab_6">Table 3</ref> shows the performance of our model on complex human-generated queries in GENX. Our approach outperforms strong LSTM and semantic parsing baselines, despite the semantic parser's use of hard-coded operators. These results suggest that our method represents an attractive middle ground between minimally structured and highly structured approaches to interpretation. Our model learns to interpret operators such as except that were not con- sidered during development. This shows that our model can learn to parse human language, which contains greater lexical and structural diversity than synthetic questions. Trees induced by the model are linguistically plausible (see Appendix D).</p><p>Error Analysis: We find that most model errors are due to incorrect assignments of structure, rather than semantic errors from the modules. For exam- ple, in the question Are four red spheres beneath a metallic thing small?, our model's parse composes metallic thing small into a constituent instead of composing red spheres beneath a metallic thing into a single node. Future work should explore more sophisticated parsing models.</p><p>Discussion: While our model shows promising results, there is significant potential for future work. Performing exact inference over large KGs is likely to be intractable, so approximations such as KNN search, beam search, feature hashing or paralleliza- tion may be necessary. To model the large number of entities in KGs such as Freebase, techniques proposed by recent work <ref type="bibr" target="#b19">(Verga et al., 2017;</ref><ref type="bibr" target="#b5">Gupta et al., 2017</ref>) that explore representing entities as composition of its properties, such as, types, de- scription etc. could be used. The modules in this work were designed in a way to provide good induc- tive bias for the kind of composition we expected them to model. For example, EV + E → E is mod- eled as a linear composition function making it easy to represent words such as and and or. These modules can be exchanged with any other function with the same 'type signature', with different trade- offs-for example, more general feed-forward net- works with greater representation capacity would be needed to represent a linguistic expression equiv- alent to xor. Similarly, more module types would be required to handle certain constructions-for example, a multiword relation such as much larger than needs a V + V → V module. This is an excit- ing direction for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Many approaches have been proposed to perform question-answering against structured knowledge sources. Semantic parsing models have learned structures over pre-defined discrete operators, to produce logical forms that can be executed to an- swer the question. Early work trained using gold- standard logical forms <ref type="bibr" target="#b21">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b9">Kwiatkowski et al., 2010)</ref>, whereas later ef- forts have only used answers to questions <ref type="bibr" target="#b3">(Clarke et al., 2010;</ref><ref type="bibr" target="#b11">Liang et al., 2011;</ref><ref type="bibr" target="#b8">Krishnamurthy and Kollar, 2013)</ref>. A key difference is that our model must learn semantic operators from data, which may be necessary to model the fuzzy meanings of function words like many or few.</p><p>Another similar line of work is neural pro- gram induction models, such as Neural Program- mer (  and Neural Sym- bolic Machine ( <ref type="bibr" target="#b10">Liang et al., 2017</ref>). These models learn to produce programs composed of predefined operators using weak supervision to answer ques- tions against semi-structured tables.</p><p>Neural module networks have been proposed for learning semantic operators ( <ref type="bibr" target="#b1">Andreas et al., 2016b</ref>) for question answering. This model assumes that the structure of the semantic parse is given, and must only learn a set of operators. Dynamic Neural Module Networks (D-NMN) extend this approach by selecting from a small set of candidate module structures ( <ref type="bibr" target="#b0">Andreas et al., 2016a</ref>). We instead learn a model over all possible structures.</p><p>Our work is most similar to N2NMN <ref type="bibr" target="#b6">(Hu et al., 2017</ref>) model, which learns both semantic operators and the layout in which to compose them. How- ever, optimizing the layouts requires reinforcement learning, which is challenging due to the high vari- ance of policy gradients, whereas our chart-based approach is end-to-end differentiable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We have introduced a model for answering ques- tions requiring compositional reasoning that com- bines ideas from compositional semantics with end- to-end learning of composition operators and struc- ture. We demonstrated that the model is able to learn a number of complex composition operators from end task supervision, and showed that the linguistically motivated inductive bias imposed by the structure of the model allows it to generalize well beyond its training data. Future work should explore scaling the model to other question answer- ing tasks, using more general composition modules, and introducing additional module types.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A correct parse for a question given the knowledge graph on the right, using our model. We show the type for each node, and its denotation in terms of the knowledge graph. The words or and not are represented by vectors, which parameterize composition modules. The denotation for the complete question represents the answer to the question. Nodes here have types E for sets of entities, R for relations, V for ungrounded vectors, EV for a combination of entities and a vector, and φ for semantically vacuous nodes. While we show only one parse tree here, our model builds a parse chart subsuming all trees.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Composition Modules that compose two constituent span representations into the representation for the combined larger span, using the indicated equations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 1 shows</head><label>1</label><figDesc></figDesc><table>that our model perfectly answers all test questions, 
demonstrating that it can learn challenging seman-
tic operators and induce parse trees from end task 
supervision. Performance drops when using ex-
ternal parser, showing that our model learns an 
effective syntactic model for this domain. The 
RELATION NETWORK also achieves good perfor-
mance, particularly on questions involving rela-
tions. LSTM baselines work well on questions not 
involving relations. 3 

2 We use this baseline only for CLEVRGEN since GENX 
does not contain relations. 
3 Relation questions are out of scope for these models. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results for Human Queries (GENX) 
Our model outperforms LSTM and semantic pars-
ing models on complex human-generated queries, 
showing it is robust to work on natural language. 
Better performance than TREE-LSTM (UNSUP.) 
shows the efficacy in representing sub-phrases us-
ing explicit denotations. Our model also performs 
better without an external parser, showing the ad-
vantages of latent syntax. 

</table></figure>

			<note place="foot" n="1"> Johnson et al. (2017) found that many spatial relation questions can be answered only using absolute spatial information, and many long questions can be answered correctly without performing all steps of reasoning. We employ some simple tests to remove trivial biases from our dataset.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We would like to thank Shyam Upadhyay and the anonymous reviewers for their helpful suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning to compose neural networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural module networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérôme</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<title level="m">Curriculum learning. In ICML</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Driving semantic parsing from the world&apos;s response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Roth</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning distributions over logical forms for referring expression generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Entity linking via joint encoding of types, descriptions, and context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to reason: End-to-end module networks for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronghang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Jointly learning to parse and perceive: Connecting natural language to the physical world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kollar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="193" to="206" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inducing probabilistic ccg grammars from logical form with higherorder unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural symbolic machines: Learning semantic parsers on freebase with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">D</forename><surname>Forbus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Jointly learning sentence embeddings and syntax with unsupervised tree-lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<idno>abs/1705.09189</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The proper treatment of quantification in ordinary English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Approaches to Natural Language</title>
		<editor>K. J. J. Hintikka, J. Moravcsic, and P. Suppes</editor>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1973" />
			<biblScope unit="page" from="221" to="242" />
		</imprint>
	</monogr>
	<note>Reidel</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning a natural language interface with neural programmer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning visual reasoning without strong priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Harm De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Courville</surname></persName>
		</author>
		<idno>abs/1707.03017</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A simple neural network module for relational reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">W</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai Sheng</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generalizing to unseen entities and entity pairs with row-less universal schema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Do latent tree learning models identify meaningful structure in sentences? TACL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Drozdov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="253" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>UAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Long short-term memory over recursive structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Sobihani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
