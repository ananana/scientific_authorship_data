<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Combining Distant and Partial Supervision for Relation Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Combining Distant and Partial Supervision for Relation Extraction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1556" to="1567"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Broad-coverage relation extraction either requires expensive supervised training data, or suffers from drawbacks inherent to distant supervision. We present an approach for providing partial supervision to a distantly supervised relation extrac-tor using a small number of carefully selected examples. We compare against established active learning criteria and propose a novel criterion to sample examples which are both uncertain and representative. In this way, we combine the benefits of fine-grained supervision for difficult examples with the coverage of a large distantly supervised corpus. Our approach gives a substantial increase of 3.9% end-to-end F 1 on the 2013 KBP Slot Filling evaluation, yielding a net F 1 of 37.7%.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Fully supervised relation extractors are limited to relatively small training sets. While able to make use of much more data, distantly supervised ap- proaches either make dubious assumptions in or- der to simulate fully supervised data, or make use of latent-variable methods which get stuck in local optima easily. We hope to combine the benefits of supervised and distantly supervised methods by annotating a small subset of the available data us- ing selection criteria inspired by active learning.</p><p>To illustrate, our training corpus contains 1 208 524 relation mentions; annotating all of these mentions for a fully supervised classifier, at an average of $0.13 per annotation, would cost ap- proximately $160 000. Distant supervision allows us to make use of this large corpus without requir- ing costly annotation. The traditional approach is based on the assumption that every mention of an entity pair (e.g., Obama and USA) participates in the known relation between the two (i.e., born in). However, this introduces noise, as not every men- tion expresses the relation we are assigning to it.</p><p>We show that by providing annotations for only 10 000 informative examples, combined with a large corpus of distantly labeled data, we can yield notable improvements in performance over the distantly supervised data alone. We report results on three criteria for selecting examples to anno- tate: a baseline of sampling examples uniformly at random, an established active learning criterion, and a new metric incorporating both the uncer- tainty and the representativeness of an example. We show that the choice of metric is important -yielding as much as a 3% F 1 difference -and that our new proposed criterion outperforms the standard method in many cases. Lastly, we train a supervised classifier on these collected exam- ples, and report performance comparable to dis- tantly supervised methods. Furthermore, we no- tice that initializing the distantly supervised model using this supervised classifier is critical for ob- taining performance improvements.</p><p>This work makes a number of concrete contri- butions. We propose a novel application of active learning techniques to distantly supervised rela- tion extraction. To the best of the authors knowl- edge, we are the first to apply active learning to the class of latent-variable distantly supervised mod- els presented in this paper. We show that anno- tating a proportionally small number of examples yields improvements in end-to-end accuracy. We compare various selection criteria, and show that this decision has a notable impact on the gain in performance. In many ways this reconciles our results with the negative results of <ref type="bibr" target="#b30">Zhang et al. (2012)</ref>, who show limited gains from na¨ıvelyna¨ıvely an- notating examples. Lastly, we make our annota- tions available to the research community. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Relation Extraction</head><p>We are interested in extracting a set of relations y 1 . . . y k from a fixed set of possible relations R, given two entities e 1 and e 2 . For example, we would like to extract that Barack Obama was born in Hawaii. The task is decomposed into two steps: First, sentences containing mentions of both e 1 and e 2 are collected. The set of these sentences x, marked with the entity mentions for e 1 and e 2 , becomes the input to the relation extractor, which then produces a set of relations which hold be- tween the mentions. We are predominantly in- terested in the second step -classifying a set of pairs of entity mentions into the relations they ex- press. <ref type="figure">Figure 1</ref> gives the general setting for re- lation extraction, with entity pairs Barack Obama and Hawaii, and Barack Obama and president.</p><p>Traditionally, relation extraction has fallen into one of four broad approaches: supervised classi- fication, as in the ACE task ( <ref type="bibr" target="#b3">Doddington et al., 2004;</ref><ref type="bibr" target="#b9">GuoDong et al., 2005;</ref><ref type="bibr" target="#b25">Surdeanu and Ciaramita, 2007)</ref>, distant supervision <ref type="bibr" target="#b2">(Craven and Kumlien, 1999;</ref><ref type="bibr" target="#b28">Wu and Weld, 2007;</ref><ref type="bibr" target="#b14">Mintz et al., 2009;</ref><ref type="bibr" target="#b24">Sun et al., 2011;</ref><ref type="bibr" target="#b18">Roth and Klakow, 2013</ref>) deterministic rule-based systems <ref type="bibr" target="#b23">(Soderland, 1997;</ref><ref type="bibr" target="#b8">Grishman and Min, 2010;</ref><ref type="bibr" target="#b1">Chen et al., 2010)</ref>, and translation from open domain informa- tion extraction schema ( <ref type="bibr" target="#b17">Riedel et al., 2013</ref>). We focus on the first two of these approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Supervised Relation Extraction</head><p>Relation extraction can be naturally cast as a su- pervised classification problem. A corpus of rela- tion mentions is collected, and each mention x is annotated with the relation y, if any, it expresses. The classifier's output is then aggregated to decide the relations between the two entities.</p><p>However, annotating supervised training data is generally expensive to perform at large scale. Although resources such as Freebase or the TAC KBP knowledge base have on the order of millions of training tuples over entities it is not feasible to manually annotate the corresponding mentions in the text. This has led to the rise of distantly su- pervised methods, which make use of this indirect supervision, but do not necessitate mention-level supervision.</p><p>Barack Obama was born in Hawaii.</p><p>Barack Obama visited Hawaii.</p><p>The president grew up in Hawaii.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>state of birth state of residence</head><p>Barack Obama met former president Clinton.</p><p>Obama became president in 2008. title <ref type="figure">Figure 1</ref>: The relation extraction setup. For a pair of entities, we collect sentences which men- tion both entities. These sentences are then used to predict one or more relations between those entities. For instance, the sentences containing both Barack Obama and Hawaii should support the state of birth and state of residence relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Distant Supervision</head><p>Traditional distant supervision makes the assump- tion that for every triple (e 1 , y, e 2 ) in a knowledge base, every sentence containing mentions for e 1 and e 2 express the relation y. For instance, tak- ing <ref type="figure">Figure 1</ref>, we would create a datum for each of the three sentences containing BARACK OBAMA and HAWAII labeled with state of birth, and like- wise with state of residence, creating 6 training examples overall. Similarly, both sentences in- volving Barack Obama and president would be marked as expressing the title relation.</p><p>While this allows us to leverage a large database effectively, it nonetheless makes a number of na¨ıvena¨ıve assumptions. First -explicit in the formulation of the approach -it assumes that every mention ex- presses some relation, and furthermore expresses the known relation(s). For instance, the sen- tence Obama visited Hawaii would be erroneously treated as a positive example of the born in rela- tion. Second, it implicitly assumes that our knowl- edge base is complete: entity mentions with no known relation are treated as negative examples.</p><p>The first of these assumptions is addressed by multi-instance multi-label (MIML) learning, de- scribed in Section 2.4. <ref type="bibr" target="#b13">Min et al. (2013)</ref> address the second assumption by extending the MIML model with additional latent variables, while <ref type="bibr" target="#b29">Xu et al. (2013)</ref> allow feedback from a coarse relation extractor to augment labels from the knowledge base. These latter two approaches are compatible with but are not implemented in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Multi-Instance Multi-Label Learning</head><p>The multi-instance multi-label (MIML-RE) model of <ref type="bibr" target="#b27">Surdeanu et al. (2012)</ref>, which builds upon work  Each entity pair has a set of mention pairs M i , and a corresponding plate in the diagram for each men- tion pair in M i . The variable x represents the in- put mention pair, whereas y represents the positive and negative relations for the given pair of entities. The latent variable z denotes a mention-level pre- diction for each input. The weight vector for the multinomial z classifier is given by w z , and there is a weight vector w j for each binary y classifier.</p><p>by <ref type="bibr" target="#b10">Hoffmann et al. (2011)</ref> and <ref type="bibr" target="#b16">Riedel et al. (2010)</ref>, addresses the assumptions of distantly supervised relations extractors in a principled way by positing a latent mention-level annotation. The model groups mentions according to their entity pair -for instance, every mention pair with Obama and Hawaii would be grouped together. A latent variable z i is created for every mention i, where z i ∈ R ∪ {None} takes a single relation label, or a no relation marker. We create |R| bi- nary variables y representing the known positive and negative relations for the entity pair. A set of binary classifiers (log-linear factors in the graphi- cal model) links the latent predictions z 1 . . . z |M i | and each y j . These classifiers include two classes of features: first, a binary feature which fires if at least one of the mentions expresses a known rela- tion between the entity pair, and second, a feature for each co-occurrence of relations for a given en- tity pair. <ref type="figure" target="#fig_1">Figure 2</ref> describes the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Background on Active Learning</head><p>We describe preliminaries and prior work on ac- tive learning; we use this framework to propose two sampling schemes in Section 3 which we use to annotate mention-level labels for MIML-RE.</p><p>One way of expressing the generalization error of a hypothesisˆhhypothesisˆ hypothesisˆh is through its mean-squared error with the true hypothesis h:</p><formula xml:id="formula_0">E[(h(x) − ˆ h(x)) 2 ] = E[E[(h(x) − ˆ h(x)) 2 |x]] = x E[(h(x) − ˆ h(x)) 2 |x]p(x)dx.</formula><p>The integrand can be further broken into bias and variance terms:</p><formula xml:id="formula_1">E[(h(x) − ˆ h(x)) 2 ] = (E[ ˆ h(x)] − h(x)) 2 + E[( ˆ h(x) − E[ ˆ h(x)]) 2 ]</formula><p>where for simplicity we've dropped the condition- ing on x.</p><p>Many traditional sampling strategies, such as query-by-committee (QBC) <ref type="bibr" target="#b5">(Freund et al., 1992;</ref><ref type="bibr" target="#b6">Freund et al., 1997</ref>) and uncertainty sampling ( <ref type="bibr" target="#b11">Lewis and Gale, 1994)</ref>, work by decreasing the variance of the learned model. In QBC, we first create a 'committee' of classifiers by ran- domly sampling their parameters from a distribu- tion based on the training data. These classifiers then make predictions on the unlabeled examples, and the examples on which there is the most dis- agreement are selected for labeling. This strat- egy can be seen as an attempt to decrease the ver- sion space -the set of classifiers that are consis- tent with the labeled data. Decreasing the version space should lower variance, since variance is in- versely related to the size of the hypothesis space.</p><p>In most scenarios, active learning does not con- cern itself with the bias term. If a model is fun- damentally misspecified, then no amount of ad- ditional training data can lower its bias. How- ever, our paradigm differs from the traditional set- ting, in that we are annotating latent variables in a model with a non-convex objective. These an- notations may help increase the convexity of our objective, leading us to a more accurate optimum and thereby lowering bias.</p><p>The other component to consider is x · · · p(x)dx. This suggests that it is impor- tant to choose examples that are representative of the underlying distribution p(x), as we want to label points that will improve the classifier's predictions on as many and as high-probability examples as possible. Incorporating a repre- sentativeness metric has been shown to provide a significant improvement over plain QBC or uncertainty sampling <ref type="bibr" target="#b12">(McCallum and Nigam, 1998;</ref><ref type="bibr" target="#b21">Settles, 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Active Learning for Relation Extraction</head><p>Several papers have explored active learning for relation extraction. <ref type="bibr" target="#b7">Fu and Grishman (2013)</ref> em- ploy active learning to create a classifier quickly for new relations, simulated from the ACE corpus. <ref type="bibr" target="#b4">Finn and Kushmerick (2003)</ref> compare a number of selection criteria -including QBC -for a su- pervised classifier. To the best of our knowledge, we are the first to apply active learning to distantly supervised relation extraction. Furthermore, we evaluate our selection criteria live in a real-world setting, collecting new sentences and evaluating on an end-to-end task.</p><p>For latent variable models, <ref type="bibr" target="#b12">McCallum and Nigam (1998)</ref> apply active learning to semi- supervised document classification. We take in- spiration from their use of QBC and the choice of metric for classifier disagreement. However their model assumes a fully Bayesian set-up, whereas ours does not require strong assumptions about the parameter distributions. <ref type="bibr" target="#b20">Settles et al. (2008)</ref> use active learning to im- prove a multiple-instance classifier. Their model is simpler in that it does not allow for unobserved variables or multiple labels, and the authors only evaluate on image retrieval and synthetic text clas- sification datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Example Selection</head><p>We describe three criteria for selection examples to annotate. The first -sampling uniformly -is a baseline for our hypothesis that intelligently se- lecting examples is important. For this criterion, we select mentions uniformly at random from the training set to annotate. This is the approach used in <ref type="bibr" target="#b30">Zhang et al. (2012)</ref>. The other two criteria rely on a metric for disagreement provided by QBC; we describe our adaptation of QBC for MIML-RE as a preliminary to introducing these criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">QBC For MIML-RE</head><p>We use a version of QBC based on bootstrap- ping <ref type="bibr" target="#b19">(Saar-Tsechansky and Provost, 2004</ref>). To create the committee of classifiers, we re-sample the training set with replacement 7 times and train a model over each sampled dataset. We mea- sure disagreement on z-labels among the classi- fiers using a generalized Jensen-Shannon diver- gence <ref type="bibr" target="#b12">(McCallum and Nigam, 1998)</ref>, taking the average KL divergence of all classifier judgments.</p><p>We first calculate the mention-level confi- dences. Note that z (m) i ∈ M i denotes the latent variable in entity pair i with index m; z (−m) i de- notes the set of all latent variables except z</p><formula xml:id="formula_2">(m) i : p(z (m) i |y i , x i ) = p(y i , z (m) i |x i ) p(y i |x i ) = z (−m) i p(y i , z i |x i ) z (m) i p(y i , z (m) i |x i ) .</formula><p>Notice that the denominator just serves to nor- malize the probability within a sentence group. We can rewrite the numerator as follows:</p><formula xml:id="formula_3">z (−m) i p(y i , z i |x i ) = z (−m) i p(y i |z i )p(z i |x i ) = p(z (m) i |x i ) z (−m) i p(y i |z i )p(z (−m) i |x i ).</formula><p>For computational efficiency, we approximate p(z (−m) i |x i ) with a point mass at its maximum. Next, we calculate the Jensen-Shannon (JS) diver- gence from the k bootstrapped classifiers:</p><formula xml:id="formula_4">1 k k c=1 KL(p c (z (m) i |y i , x i )||p mean (z (m) i |y i , x i )) (1)</formula><p>where p c is the probability assigned by each of the k classifiers to the latent z (m) i , and p mean is the av- erage of these probabilities. We use this metric to capture the disagreement of our model with re- spect to a particular latent variable. This is then used to inform our selection criteria.</p><p>We note that QBC may be especially useful in our situation as our objective is highly nonconvex. If two committee members disagree on a latent variable, it is likely because they converged to dif- ferent local optima; annotating that example could help bring the classifiers into agreement.</p><p>The second selection criterion we consider is the most straightforward application of QBC -se- lecting the examples with the highest JS disagree- ment. This allows us to compare our criterion, de- scribed next, against an established criterion from the active learning literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sample by JS Disagreement</head><p>We propose a novel active learning sampling cri- terion that incorporates not only disagreement but also representativeness in selecting examples to annotate. Prior work has taken a weighted combi- nation of an example's disagreement and a score corresponding to whether the example is drawn from a dense portion of the feature space (e.g., <ref type="bibr" target="#b12">McCallum and Nigam (1998)</ref></p><note type="other">). However, this re- quires both selecting a criterion for defining den- sity (e.g., distance metric in feature space), and tuning a parameter for the relative weight of dis- agreement versus representativeness. Instead, we account for choosing representa- tive examples by sampling without replacement proportional to the example's disagreement. For- mally, we define the probability of selecting an example z (m) i</note><p>to be proportional to the Jensen- Shannon divergence in (1). Since the training set is an approximation to the prior distribution over ex- amples, sampling uniformly over the training set is an approximation to sampling from the prior prob- ability of seeing an input x. We can view our crite- rion as an approximation to sampling proportional to the product of two densities: a prior over exam- ples x, and the JS divergence mentioned above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Incorporating Sentence-Level Annotations</head><p>Following <ref type="bibr" target="#b27">Surdeanu et al. (2012)</ref>, MIML-RE is trained through hard discriminative Expectation Maximization, inferring the latent z values in the E-step and updating the weights for both the z and y classifiers in the M-step. During the E-step, we constrain the latent z to match our sentence-level annotations when available. It is worth noting that even in the hard-EM regime, we can in principle incorporate annotator uncertainty elegantly into the model. At each E step, each z i is set according to</p><formula xml:id="formula_5">z i (m) * ≈ arg max z∈R p(z | x (m) i , w z ) × r p(y (r) i | z i , w (r) y )</formula><p>where z i contains the inferred labels from the previous iteration, but with its mth component re- placed by z i , w z ) to re- flect uncertainty among annotators, we can leave open the possibility for the model to choose a re- lation which annotators deemed unlikely, but the model nonetheless prefers. For simplicity, how- ever, we treat our annotations as a hard assign- ment.</p><p>In addition to incorporating annotations during training, we can also use this data to intelligently initialize the model. Since the MIML-RE objec- tive is non-convex, the initialization of the classi- fier weights w y and w z is important. The y clas- sifiers are initialized with the "at-least-once" as- sumption of <ref type="bibr" target="#b10">Hoffmann et al. (2011)</ref>; w z can be ini- tialized either using traditional distant supervision or from a supervised classifier trained on the an- notated sentences. If initialized with a supervised classifier, the model can be viewed as augment- ing this supervised model with a large distantly labeled corpus, providing both additional entity pairs to train from, and additional mentions for an annotated entity pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Crowdsourced Example Annotation</head><p>Most prior work on active learning is done by sim- ulation on a fully labeled dataset; such a dataset doesn't exist for our case. Furthermore, a key aim of this paper is to practically improve state-of-the- art performance in relation extraction in addition to evaluating active learning criteria. Therefore, we develop and execute an annotation task for col- lecting labels for our selected examples.</p><p>We utilize Amazon Mechanical Turk to crowd- source annotations. For each task, the annotator (Turker) is presented with the task description, fol- lowed by 15 questions, 2 of which are randomly placed controls. For each question, we present Turkers with a relation mention and the top 5 re- lation predictions from our classifier. The Turker also has an option to freely specify a relation not presented in the first five options, or mark that there is no relation. We attempt to heuristically match common free-form answers to official rela- tions.</p><p>To maintain the quality of the results, we dis- card all submissions in which both controls were answered incorrectly, and additionally discard all submissions from Turkers who failed the controls on more than <ref type="bibr">1</ref> 3 of their submissions. Rejected tasks were republished for other workers to com- plete. We collect 5 annotations for each example, and use the most commonly agreed answer as the ground truth. Ties are broken arbitrarily, except in the case of deciding between a relation and no re- lation, in which case the relation was always cho- sen.</p><p>A total of 23 725 examples were annotated, cov- ering 10 000 examples for each of the three selec- tion criteria. Note that there is overlap between the examples selected for the three criteria. In ad- dition, 10 023 examples were annotated during de- velopment; these are included in the set of all an- notated examples, but excluded from any of the three criteria. The compensation per task was 23 cents; the total cost of annotating examples was $3156, in addition to $204 spent on developing the task. Informally, Turkers achieved an accuracy of around 75%, as evaluated by a paper author, per- forming disproportionately well on identifying the no relation label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We evaluate the three high-level research contri- butions of this work: we show that we improve the accuracy of MIML-RE, we validate the effec- tiveness of our selection criteria, and we provide a corpus of annotated examples, evaluating a super- vised classifier trained on this corpus. The train- ing and testing methodology for evaluating these contributions is given in Sections 6.1 and 6.2; ex- periments are given in Section 6.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Training Setup</head><p>We adopt the setup of <ref type="bibr" target="#b27">Surdeanu et al. (2012)</ref> for training the MIML-RE model, with minor modifi- cations. We use both the 2010 and 2013 KBP of- ficial document collections, as well as a July 2013 dump of Wikipedia as our text corpus. We sub- sample negatives such that 1 3 of our dataset con- sists of entity pairs with no known relations. In all experiments, MIML-RE is trained for 7 iterations of EM; for efficiency, the z classifier is optimized using stochastic gradient descent; 2 the y classifiers are optimized using L-BFGS.</p><p>Similarly to <ref type="bibr" target="#b26">Surdeanu et al. (2011)</ref>, we as- sign negative relations which are either incompat- ible with the known positive relations (e.g., re- lations whose co-occurrence would violate type constraints); or, are actually functional relations in which another entity already participates. For example, if we know that Obama was born in the United States, we could add born in as a negative relation to the pair Obama and Kenya.</p><p>Our dataset consists of 325 891 entity pairs with at least one positive relation, and 158 091 entity pairs with no positive relations. Pairs with at least one known relation have an average of 4.56 men- tions per group; groups with no known relations have an average of 1.55 mentions per group. In to- tal, 1 208 524 distinct mentions are considered; the annotated examples are selected from this pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Testing Methodology</head><p>We compare against the original MIML-RE model using the same dataset and evaluation methodol- ogy as <ref type="bibr" target="#b27">Surdeanu et al. (2012)</ref>. This allows for an evaluation where the only free variable between this and prior work is the predictions of the rela- tion extractor.</p><p>Additionally, we evaluate the relation extractors in the context of Stanford's end-to-end KBP sys- tem ( <ref type="bibr" target="#b0">Angeli et al., 2014</ref>) using the NIST TAC- KBP 2013 English Slotfilling evaluation. In the end-to-end framework, the input to the system is a query entity and a set of articles, and the output is a set of slot fills -each slot fill is a candidate triple in the knowledge base, the first element of which is the query entity. This amounts to roughly pop- ulating a data structure like Wikipedia infoboxes automatically from a large corpus of text.</p><p>Importantly, an end-to-end evaluation in a top- performing full system gives a more accurate idea of the expected real-world gain from each model. Both the information retrieval component provid- ing candidates to the relation extractor, as well as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Init</head><p>Active Learning Criterion Not Used Uniform High JS Sample JS All Available  <ref type="table">Table 1</ref>: A summary of results on the end-to-end KBP 2013 evaluation for various experiments. The first column denotes the algorithm used: either traditional distant supervision (Mintz++), MIML-RE, or a supervised classifier. In the case of MIML-RE, the model may be initialized either using Mintz++, or the corresponding supervised classifier (the "Not Used" column is initialized with the "All" supervised classifier). One of five active learning scenarios are evaluated: no annotated examples provided, the three active learning criteria, and all available examples used. The entry in blue denotes the basic MIML-RE model; entries in gray perform worse than this model. The bold items denote the best performance among selection criteria.</p><formula xml:id="formula_6">P R F 1 P R F 1 P R F 1 P R F 1 P R F 1 Mintz++ -41</formula><p>the consistency and inference performed on the classifier output introduce bias in this evaluation's sensitivity to particular types of errors. Mistakes which are easy to filter, or are difficult to retrieve using IR are less important in this evaluation; in contrast, factors such as providing good confi- dence scores for consistency become more impor- tant.</p><p>For the end-to-end evaluation, we use the offi- cial evaluation script with two changes: First, all systems are evaluated with provenance ignored, so as not to penalize any system for finding a new provenance not validated in the official evaluation key. Second, each system reports its optimal F 1 along its P/R curve, yielding results which are optimistic when compared against other systems entered into the competition. However, this also yields results which are invariant to threshold tun- ing, and is therefore more appropriate for compar- ing between systems in this paper.</p><p>Development was done on the KBP 2010-2012 queries, and results are reported using the 2013 queries as a simulated test set. Our best system achieves an F 1 of 37.7; the top two teams at KBP 2013 (of 18 entered) achieved F 1 scores of 40.2 and 37.1 respectively, ignoring provenance. <ref type="table">Table 1</ref> summarizes all results for the end-to-end task; relevant features of the table are copied in subsequent sections to illustrate key trends. Mod- els which perform worse than the original MIML- RE model (MIML-RE, initialized with "Dist," un- der "Not Used") are denoted in gray. The best per-  <ref type="table">Table 2</ref>: A summary of improvements to MIML- RE on the end-to-end slotfilling task, copied from <ref type="table">Table 1</ref>. Mintz++ is the traditional distantly su- pervised model. The second row corresponds to the unmodified MIML-RE model. The third row corresponds to MIML-RE initialized with a su- pervised classifier (trained on all examples). The fourth row is MIML-RE with annotated exam- ples incorporated during training (but not initial- ization). The last row shows the best results ob- tained by our model. forming model improves on the base model by 3.9 F 1 points on the end-to-end task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results</head><p>We evaluate each of the individual contribu- tions of the paper: improving the accuracy of the MIML-RE relation extractor, evaluating our example selection criteria, and demonstrating the annotated examples' effectiveness for a fully- supervised relation extractor.</p><p>Improve MIML-RE Accuracy A key goal of this work is to improve the accuracy of the MIML- RE model; we show that we improve the model both on the end-to-end slotfilling task <ref type="table">(Table 2)</ref> as well as on a standard evaluation ( <ref type="figure">Figure 5</ref>). Sim- ilar to our work, recent work by Pershina et al.   <ref type="table">Table 4</ref>: A comparison of the best performing su- pervised classifier with other systems. The top section compares the supervised classifier with prior work. The lower section highlights the im- provements gained from initializing MIML-RE with a supervised classifier.</p><p>(2014) incorporates labeled data to guide MIML- RE during training. They make use of labeled data to extract training guidelines, which are intended to generalize across many examples. We show that we can match or outperform their improvements with our best criterion.</p><p>A few interesting trends emerge from the end- to-end results in <ref type="table">Table 2</ref>. Using annotated sen- tences during training alone did not improve per- formance consistently, even hurting performance when the SampleJS criterion was used. This supports an intuition that the initialization of the model is important, and that it is relatively difficult to coax the model out of a local optimum if it is initialized poorly. This is further supported by the improvement in performance when the model is initialized with a supervised classifier, even when no examples are used during training. Similar trends are reported in prior work, e.g., <ref type="bibr" target="#b22">Smith and Eisner (2007</ref>  Also interesting is the relatively small gain MIML-RE provides over traditional distant super- vision (Mintz++) in this setting. We conjecture that the mistakes made by Mintz++ are often rel- atively easily filtered by the downstream consis- tency component. This is supported by <ref type="figure">Figure 4</ref>; we evaluate our trained MIML-RE model against Mintz++ and the results reported in <ref type="bibr" target="#b27">Surdeanu et al. (2012)</ref>. We show that our model performs as well or better than the original implementation, and consistently outperforms Mintz++.</p><p>Evaluate Selection Criteria A key objective of this work is to evaluate how much of an impact careful selection of annotated examples has on the overall performance of the system. We evaluate the three selection criteria from Section 3.2, show- ing the results for MIML-RE in <ref type="table" target="#tab_3">Table 3</ref>; results for the supervised classifier are given in <ref type="table">Table 1</ref>. In both cases, we show that the sampled JS cri-terion performs comparably to or better than the other criteria.</p><p>At least two interesting trends can be noted from these results: First, the uniformly sampled crite- rion performed worse than MIML-RE initialized with a supervised classifier. This may be due to noise in the annotation: a small number of an- notation errors on entity pairs with only a single corresponding mention could introduce dangerous noise into training. These singleton mentions will rarely have disagreement between the committee of classifiers, and therefore will generally only be selected in the uniform criterion.</p><p>Second, adding in the full set of examples did not improve performance -in fact, performance generally dropped in this scenario. We conjecture that this is due to the inclusion of the uniformly sampled examples, with performance dropping for the same reasons as above.</p><p>Both of these results can be reconciled with the results of <ref type="bibr" target="#b30">Zhang et al. (2012)</ref>; like this work, they annotated examples to analyze the trade-off between adding more data to a distantly super- vised system, and adding more direct supervi- sion. They conclude that annotations provide only a relatively small improvement in performance. However, their examples were uniformly selected from the training corpus, and did not make use of the structure provided by MIML-RE. Our re- sults agree in that neither the uniform selection criterion nor the supervised classifier significantly outperformed the unmodified MIML-RE model; nonetheless, we show that if care is taken in se- lecting these labeled examples we can achieve no- ticeable improvements in accuracy.</p><p>We also evaluate our selection criteria on the evaluation of <ref type="bibr" target="#b27">Surdeanu et al. (2012)</ref>, both initial- ized with Mintz++ ( <ref type="figure">Figure 7</ref>) and with the super- vised classifier ( <ref type="figure">Figure 6</ref>). These results mirror those in the end-to-end evaluation; when initial- ized with the supervised classifier the high dis- agreement (High JS) and sampling proportional to disagreement (Sample JS) criteria clearly outper- form both the base MIML-RE model as well as the uniformly sampling criterion. Using the an- notated examples only during training yielded no perceivable benefit over the base model <ref type="figure">(Figure 7)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supervised Relation Extractor</head><p>The examples collected can be used to directly train a supervised classifier, with results summarized in <ref type="table">Table 4</ref>. The most salient insight is that the performance of the best supervised classifier is similar to that of the MIML-RE model, despite being trained on nearly two orders of magnitude less training data.</p><p>More interestingly, however, the supervised classifier provides a noticeably better initializa- tion for MIML-RE than Mintz++, yielding better results even without enforcing the labels during EM. These results suggest that the power gained from the the more sophisticated MIML-RE model is best used in conjunction with a small amount of training data. That is, using MIML-RE as a princi- pled model for combining a large distantly labeled corpus and a small number of careful annotations yields significant improvement over using either of the two data sources alone.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The MIML-RE model, as shown in Surdeanu et al. (2012). The outer plate corresponds to each of the n entity pairs in our knowledge base. Each entity pair has a set of mention pairs M i , and a corresponding plate in the diagram for each mention pair in M i. The variable x represents the input mention pair, whereas y represents the positive and negative relations for the given pair of entities. The latent variable z denotes a mention-level prediction for each input. The weight vector for the multinomial z classifier is given by w z , and there is a weight vector w j for each binary y classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>By setting the distribution p(z | x (m)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The task shown to Amazon Mechanical Turk workers. A sentence along with the top 5 relation predictions from our classifier are shown to Turkers, as well as an option to specify a custom relation or manually enter "no relation." The correct response for this example should be either no relation or a custom relation.</figDesc><graphic url="image-14.png" coords="6,78.27,62.80,205.74,124.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: MIML-RE and Mintz++ evaluated according to Surdeanu et al. (2012). The original model from the paper is plotted for comparison, as our training methodology is somewhat different.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: A comparison of models trained with various selection criteria on the evaluation of Surdeanu et al. (2012), all initialized with the corresponding supervised classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>A summary of the performance of each 
example selection criterion. In each case, the 
model was initialized with a supervised classifier. 
The first row corresponds to the MIML-RE model 
initialized with a supervised classifier. The middle 
three rows show performance for the three selec-
tion criteria, used both for initialization and during 
training. The last row shows results if all available 
annotations are used, independent of their source. 

System 
P 
R 
F 1 
Mintz++ 
41.3 28.2 33.5 
MIML + Dist 
38.0 30.5 33.8 
Supervised + SampleJS 
33.5 35.0 34.2 
MIML + Sup 
35.1 35.6 35.5 
MIML + Sup + SampleJS 39.4 36.2 37.7 

</table></figure>

			<note place="foot" n="1"> http://nlp.stanford.edu/software/ mimlre.shtml</note>

			<note place="foot" n="2"> For the sake of consistency, the supervised classifiers and those in Mintz++ are trained identically to the z classifiers in MIML-RE.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the anonymous reviewers for their thoughtful comments, and Dan Weld for his feed-back on additional experiments and analysis. We gratefully acknowledge the support of the Defense Advanced Research Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract no. FA8750-13-2-0040. Any opinions, findings, and conclusion or recommen-dations expressed in this material are those of the authors and do not necessarily reflect the view of the DARPA, AFRL, or the US government.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Analysis By Relation</head><p>In this section, we explore which of the KBP rela- tions were shown to Turkers, and whether the im- provements in accuracy correspond to these rela- tions. We compare only the unmodified MIML- RE model, and our best model (MIML-RE initial- ized with the supervised classifier, under the Sam- pleJS criterion). Results are shown in <ref type="table">Table 5</ref>. A few interesting trends emerge from this anal- ysis. We note that annotating even 80+ examples for a relation seems to provide a consistent boost in accuracy, whereas relations with fewer anno- tated examples tended to show little or no change. However, the gains of our model are not univer- sal across relation types, even dropping noticeably on some -for instance, F 1 drops on both state of residence and country of birth. This could suggest systematic noise from Turker judgments; e.g., for foreign geography (state of residence) or ambigu- ous relations (top members).</p><p>An additional insight from the table is the mis- match between examples chosen to be annotated, and the most popular relations in the KBP evalu- ation. For instance, by far the most popular KBP relation (title) had only 121 examples annotated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have shown that providing a relatively small number of mention-level annotations can improve the accuracy of MIML-RE, yielding an end-to-end improvement of 3.9 F 1 on the KBP task. Further- more, we have introduced a new active learning criterion, and shown both that the choice of crite- rion is important, and that our new criterion per- forms well. Lastly, we make available a dataset of mention-level annotations for constructing a tradi- tional supervised relation extractor.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Stanford&apos;s 2013 KBP system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Chaganty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Reschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Osbert</forename><surname>Bastani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Siilats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<editor>TAC-KBP</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Tamang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Pin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marissa</forename><surname>Passantino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CUNYBLENDER</title>
		<editor>TAC-KBP</editor>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Constructing biological knowledge bases by extracting information from text sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Kumlien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The automatic content extraction (ACE) program-tasks, data, and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>George R Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Lance A Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph M</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Active learning selection strategies for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Kushmerick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Adaptive Text Extraction and Mining</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Information, prediction, and query by committee</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Selective sampling using the query by committee algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="133" to="168" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An efficient active learning framework for new relation types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisheng</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">New York University KBP 2010 slot-filling system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. TAC 2010 Workshop</title>
		<meeting>TAC 2010 Workshop</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploring various knowledge in relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Guodong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Min</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-HLT</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A sequential algorithm for training text classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Employing EM and pool-based active learning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Nigam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Distant supervision for relation extraction with an incomplete knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Rion Snow, and Dan Jurafsky</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Infusion of labeled data into distant supervision for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pershina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin M</forename><surname>Marlin</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Featurebased models for improving the quality of noisy training data for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietrich</forename><surname>Klakow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Active sampling for class probability estimation and ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maytal</forename><surname>Saar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Tsechansky</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Foster</forename><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="153" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiple-instance active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1289" to="1296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Active learning literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<idno>1648</idno>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin Madison</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Novel estimation methods for unsupervised discovery of latent structure in natural language text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Johns Hopkins</publisher>
		</imprint>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning text analysis rules for domain-specific natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soderland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">New York University 2011 system for KBP slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analytics Conference</title>
		<meeting>the Text Analytics Conference</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust information extraction with perceptrons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACE07 Proceedings</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Stanfords distantlysupervised slot-filling system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><forename type="middle">I</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analytics Conference</title>
		<meeting>the Text Analytics Conference</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multiinstance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Autonomously semantifying wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel S Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixteenth ACM conference on information</title>
		<meeting>the sixteenth ACM conference on information</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Filling knowledge base gaps for distant supervision of relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Big data versus the crowd: Looking for relationships in all the right places</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jude</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
