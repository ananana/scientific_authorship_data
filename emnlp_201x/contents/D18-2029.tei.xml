<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Universal Sentence Encoder for English</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Yi</forename><surname>Kong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Hua</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicole</forename><surname>Limtiaco</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Google AI</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rhomni</forename><surname>St</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>John</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Constant</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Guajardo-CÃ©spedes</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Yuan</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Google Cambridge</orgName>
								<address>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Tar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Hsuan</forename><surname>Sung</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Strope</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Kurzweil</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google AI Mountain View</orgName>
								<address>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Universal Sentence Encoder for English</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations)</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations) <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="169" to="174"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>169</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present easy-to-use TensorFlow Hub sentence embedding models having good task transfer performance. Model variants allow for trade-offs between accuracy and compute resources. We report the relationship between model complexity, resources , and transfer performance. Comparisons are made with baselines without transfer learning and to baselines that incorporate word-level transfer. Transfer learning using sentence-level embeddings is shown to outperform models without transfer learning and often those that use only word-level transfer. We show good transfer task performance with minimal training data and obtain encouraging results on word embedding association tests (WEAT) of model bias.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We present easy-to-use sentence-level embed- ding models with good transfer task performance even when using remarkably little training data. <ref type="bibr">1</ref> Model engineering characteristics allow for trade- offs between accuracy versus memory and com- pute resource consumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model Toolkit</head><p>Models are implemented in <ref type="bibr">TensorFlow (Abadi et al., 2016)</ref> and are made publicly available on TensorFlow Hub. <ref type="bibr">2</ref> Listing 1 provides an example Listing 1: Python sentence embedding code.</p><p>code snippet to compute a sentence-level embed- ding from a raw untokenized input string. <ref type="bibr">3</ref> The re- sulting embedding can be used directly or incorpo- rated into a downstream model for a specific task. <ref type="bibr">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Encoders</head><p>Two sentence encoding models are provided: (i) transformer <ref type="bibr" target="#b23">(Vaswani et al., 2017)</ref>, which achieves high accuracy at the cost of greater resource con- sumption; (ii) deep averaging network (DAN) <ref type="bibr" target="#b11">(Iyyer et al., 2015)</ref>, which performs efficient in- ference but with reduced accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Transformer</head><p>The transformer sentence encoding model con- structs sentence embeddings using the encod- ing sub-graph of the transformer architecture ( <ref type="bibr" target="#b23">Vaswani et al., 2017)</ref>. The encoder uses atten- tion to compute context aware representations of words in a sentence that take into account both the ordering and identity of other words. The context aware word representations are averaged together to obtain a sentence-level embedding.</p><p>We train for broad coverage using multi-task learning, with the same encoding model support- ing multiple downstream tasks. The task types include: a Skip-Thought like task ( <ref type="bibr" target="#b13">Kiros et al., 2015)</ref>; 5 conversational response prediction <ref type="bibr" target="#b8">(Henderson et al., 2017)</ref>; and a select supervised classi- fication task that improves sentence embeddings. <ref type="bibr">6</ref> The transformer encoder achieves the best transfer performance. However, this comes at the cost of compute time and memory usage scaling dramati- cally with sentence length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Deep Averaging Network (DAN)</head><p>The DAN sentence encoding model begins by averaging together word and bi-gram level em- beddings. Sentence embeddings are then obtain by passing the averaged representation through a feedforward deep neural network (DNN). The DAN encoder is trained similar to the transformer encoder. Multitask learning trains a single DAN encoder to support multiple downstream tasks. An advantage of the DAN encoder is that compute time is linear in the length of the input sequence. Similar to <ref type="bibr" target="#b11">Iyyer et al. (2015)</ref>, our results demon- strate that DANs achieve strong baseline perfor- mance on text classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Encoder Training Data</head><p>Unsupervised training data are drawn from a va- riety of web sources. The sources are Wikipedia, web news, web question-answer pages and discus- sion forums. We augment unsupervised learning with training on supervised data from the Stanford Natural Language Inference (SNLI) corpus <ref type="bibr" target="#b2">(Bowman et al., 2015</ref>) in order to further improve our representations ( <ref type="bibr" target="#b5">Conneau et al., 2017)</ref>. Since the only supervised training data is SNLI, the models can be used for a wide range of downstream super- vised tasks that do not overlap with this dataset. <ref type="bibr">7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Transfer Tasks</head><p>This section presents the data used for the transfer learning experiments and word embedding asso- ciation tests (WEAT): (MR) Movie review senti- ment on a five star scale <ref type="bibr" target="#b20">(Pang and Lee, 2005</ref>); (CR) Sentiment of customer reviews (Hu and Liu, 2004); (SUBJ) Subjectivity of movie re- views and plot summaries ( <ref type="bibr" target="#b19">Pang and Lee, 2004</ref>); <ref type="bibr">5</ref> The Skip-Thought like task replaces the LSTM (Hochre- iter and <ref type="bibr" target="#b9">Schmidhuber, 1997</ref>) in the original formulation with a transformer model. <ref type="bibr">6</ref>   <ref type="table">Table 1</ref> gives the number of samples for each transfer task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Transfer Learning Models</head><p>For sentence classification transfer tasks, the out- put of the sentence encoders are provided to a task specific DNN. For the pairwise semantic similar- ity task, the similarity of sentence embeddings u and v is assessed using â arccos uv ||u|| ||v|| . 9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baselines</head><p>For each transfer task, we include baselines that only make use of word-level transfer and baselines that make use of no transfer learning at all. For word-level transfer, we incorporate word embed- dings from a word2vec skip-gram model trained on a corpus of news data ( <ref type="bibr" target="#b15">Mikolov et al., 2013</ref>). The pretrained word embeddings are included as input to two model types: a convolutional neural network model (CNN) <ref type="bibr" target="#b12">(Kim, 2014)</ref>; a DAN. The baselines that use pretrained word embeddings al- low us to contrast word-vs. sentence-level trans- fer. Additional baseline CNN and DAN models are trained without using any pretrained word or sentence embeddings. For reference, we com- pare with InferSent ( <ref type="bibr" target="#b5">Conneau et al., 2017</ref>) and Skip-Thought with layer normalization ( <ref type="bibr" target="#b0">Ba et al., 2016</ref>) on sentence-classification tasks. On the STS Benchmark, we compare with InferSent and the state-of-the-art neural STS systems CNN (HCTI) <ref type="bibr" target="#b21">(Shao, 2017)</ref> and gConv ( <ref type="bibr" target="#b25">Yang et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Combined Transfer Models</head><p>We explore combining the sentence and word- level transfer models by concatenating their rep- resentations prior to the classification layers. For completeness, we report results providing the clas- sification layers with the concatenating of the sentence-level embeddings and the representations produced by baseline models that do not make use of word-level transfer learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>Experiments use our most recent transformer and DAN encoding models. <ref type="bibr">10</ref> Transfer task model hy- perparamaters are tuned using a combination of Vizier ( <ref type="bibr" target="#b6">Golovin et al., 2017</ref>) and light manual tun- ing. When available, model hyperparameters are tuned using task dev sets. Otherwise, hyperparam- eters are tuned by cross-validation on task train- ing data or the evaluation test data when neither training nor dev data are provided. Training re- peats ten times for each task with randomly ini- tialized weights and we report results by averaging across runs. Transfer learning is important when training data is limited. We explore using vary- ing amounts of training data for SST. Contrasting the transformer and DAN encoders demonstrates trade-offs in model complexity and the training data required to reach a desired level of task ac- curacy. Finally, to assess bias in our encoders, we evaluate the strength of biased model associations on WEAT. We compare to <ref type="bibr" target="#b3">Caliskan et al. (2017)</ref> who discovered that word embeddings reproduce human-like biases on implicit association tasks.     <ref type="table" target="#tab_4">Table 3</ref> compares our models to strong base- lines on the STS Benchmark. Our transformer em- beddings outperform the sentence representations produced by InferSent. Moreover, computing sim- ilarity scores by directly comparing the repre- sentations produced by our encoders approaches the performance of state-of-the-art neural models whose representations are fit to the STS task. <ref type="table" target="#tab_6">Table 4</ref> illustrates transfer task performance for varying amounts of training data. With small quantities of training data, sentence-level trans- fer achieves surprisingly good performance. Us- ing only 1k labeled examples and the transformer embeddings for sentence-level transfer surpasses the performance of transfer learning using In- ferSent on the full training set of 67.3k exam- ples. Training with 1k labeled examples and the transformer sentence embeddings surpasses word- level transfer using the full training set, CNN <ref type="bibr">w2v</ref> , and approaches the performance of the best model without transfer learning trained on the complete dataset, CNN rnd @67.3k. Transfer learning is not always helpful when there is enough task training data. However, we observe that our best perform- ing model still makes use of transformer sentence- level transfer but combined with a CNN with no word-level transfer, U T +CNN rnd . <ref type="table">Table 5</ref> contrasts <ref type="bibr" target="#b3">Caliskan et al. (2017)</ref>'s find- ings on bias within GloVe embeddings with results from the transformer and DAN encoders. Similar to GloVe, our models reproduce human associa- tions between flowers vs. insects and pleasantness vs. unpleasantness. However, our models demon- strate weaker associations than GloVe for probes targeted at revealing ageism, racism and sexism. 11 Differences in word association patterns can be at- tributed to training data composition and the mix- ture of tasks used to train the representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><note type="other">Embedding Transfer Learning + DNN/CNN with word-level transfer UT +CNNw2v 80.1 85.2 95.8 88.4 98.7 85.3 UT +DANw2v 81.4 86.4 93.7 87.5 97.0 86.0 UD+CNNw2v 76.7 82.0 91.2 85.2 97.1 85.1 UD+DANw2v 76.4 81.0 94.0 88.0 92.6 82.2 Sentence Embedding Transfer Learning + DNN/CNN without word-level transfer UT +CNN rnd 82.7 88.6 93.6 87.8 98.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Resource Usage</head><p>This section describes memory and compute re- source usage for the transformer and DAN sen- tence encoding models over different batch sizes and sentence lengths. <ref type="figure">Figure 1</ref> plots model re- source consumption against sentence length. <ref type="bibr">12</ref> Compute Usage The transformer model time complexity is O(n 2 ) in sentence length, while the <ref type="bibr">11</ref> The development of our models did not target reducing bias. Researchers and developers are strongly encouraged to independently verify whether biases in their overall model or model components impacts their use case. For resources on ML fairness visit https://developers.google.com/machine- learning/fairness-overview/. <ref type="bibr">12</ref> All benchmark values are averaged over 25 runs that follow 5 priming runs. CPU and mem. benchmarks are per- formed on a machine with an Intel(R) Xeon(R) Platinum P-8136 CPU @ 2.00GHz CPU. GPU benchmarks use an Intel(R) Xeon(R) CPU E5-2696 v4 @ 2.20GHz CPU and NVIDIA Tesla P100 GPU.   <ref type="table" target="#tab_1">Table  2</ref>. Using 1k examples, U T transfer learning rivals models trained on the full training set, 67.3k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MODEL</head><note type="other">SST 1K SST 4K SST 16K SST 67.3K Sentence Embedding Transfer</note><p>DAN model is O(n). As seen in <ref type="figure">Figure 1</ref> (a- b), for short sentences, the transformer encoding model is only moderately slower than the much simpler DAN model. However, compute time for transformer increases noticeably with sentence length. In contrast, the compute time for the DAN model stays nearly constant across different lengths. When running on GPU, even for large batches and longer sentence lengths, the trans- former model still achieves performance that can be used within an interactive systems.</p><p>Memory Usage The transformer model space complexity also scales quadratically, O(n 2 ), in sentence length, while the DAN is linear, O(n).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>Our encoding models provide sentence-level em- beddings that demonstrate strong transfer perfor- mance on a number of NLP tasks. The encoding models make different trade-offs regarding accu- racy and model complexity that should be consid- ered when choosing the best one for a particular application. Overall, our sentence-level embed- dings tend to surpass the performance of trans- fer using word-level embeddings alone. Models that make use of sentence-and word-level trans- fer often achieve the best performance. Sentence- level transfer using our models can be exception- ally helpful when limited training data is avail- able. The pre-trained encoding models are pub- licly available for research and use in industry applications that can benefit from a better under- standing of natural language.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>5 :</head><label>5</label><figDesc>WEAT for GloVe vs. our DAN and transformer encoding models. Effect size is reported as Cohen's d over the mean cosine similarity scores across grouped attribute words. Statistical significance uses one-tailed p-scores. The Ref column indicates the source of the IAT word lists: (a) Greenwald et al. (1998) (b) Bertrand and Mullainathan (2004) (c) Nosek et al. (2002a) (d) Nosek et al. (2002b) (e) Monteith and Pettit (2011). very short sequences transformer requires almost half as much memory as the DAN model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 presents</head><label>2</label><figDesc>results on classification tasks. Us- ing transformer sentence-level embeddings alone outperforms InferSent on MR, SUBJ, and TREC. The transformer sentence encoder also strictly out- performs the DAN encoder. Models that make use of just the transformer sentence-level embeddings tend to outperform all models that only use word- level transfer, with the exception of TREC and</figDesc><table>10 universal-sentence-encoder/2 
(DAN); 
universal-
sentence-encoder-large/3 (Transformer). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>5 88.9 UT +DAN rnd 80.6 84.8 94.3 86.0 98.6 86.2 UD+CNN rnd 78.0 82.9 90.2 87.8 96.2 83.2 UD+DAN rnd 76.4 84.9 94.0 85.3 98.1 86.2</figDesc><table>Baselines with No Transfer Learning 
CNN rnd 
76.5 81.0 89.6 82.2 97.9 85.0 
DAN rnd 
74.6 81.2 91.8 79.9 93.9 82.0 
Prior Work 
InferSent 
81.1 86.3 92.4 90.2 88.2 84.6 
Skip Thght 79.4 83.1 93.7 89.3 
-
-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Classification tasks. U T uses the trans-
former encoder for transfer learning, while U D 
uses the DAN encoder. DAN/CNN w2v use pre-
trained w2v emb. DAN/CNN rnd train rand. init. 
word emb. on the final classification task. 

SST, on which CNN w2v performs better. Trans-
fer learning with DAN sentence embeddings tends 
to outperform a DAN with word-level transfer, ex-
cept on MR and SST. Models with sentence-and 
word-level transfer often outperform similar mod-
els with sentence-level transfer alone. 

MODEL 

DEV 
TEST 

Transformer Encoder 

0.802 
0.766 

DAN Encoder 
0.760 0.717 

Prior Work 

gConv (Yang et al., 2018) 

0.835 
0.808 

CNN (HCTI) (Shao, 2017) 
0.834 0.784 
InferSent (Conneau et al., 2017) 0.801 0.758 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc>STS Benchmark Pearson's r. Our prior gConv model (Yang et al., 2018) is a variant of our TF Hub transformer model tuned to STS.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc>SST performance varying the amount of training data. Model types are the same as</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="3"> Basic text preprocessing and white-space tokenization is performed internally. Preprocessing lowercases the text and removes punctuation. OOV items are handled using string hashing to index into 400,000 OOV embeddings. 4 Visit https://colab.research.google.com/ to try the code snippet in Listing 1. Example code and documentation is available on the TF Hub website.</note>

			<note place="foot" n="8"> For MR, CR, SUBJ, SST, and TREC we use the preparation of the data provided by Conneau et al. (2017). 9 arccos converts cosine similarity into an angular distance that obeys the triangle inequality. We find that angular distance performs better on STS than cosine similarity.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank our teammates from Descartes, Ai.h and other Google groups for their feedback and sug-gestions. Special thanks goes to Ben Packer and Yoni Halpern for implementing the WEAT assess-ments and discussions on model bias.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno>abs/1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Are emily and greg more employable than lakisha and jamal? a field experiment on labor market discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marianne</forename><surname>Bertrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sendhil</forename><surname>Mullainathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Economic Review</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantics derived automatically from language corpora contain human-like biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aylin</forename><surname>Caliskan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><forename type="middle">J</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="issue">6334</biblScope>
			<biblScope unit="page" from="183" to="186" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semeval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inigo</forename><surname>Lopezgazpio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval-2017</title>
		<meeting>SemEval-2017</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.02364</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Google vizier: A service for black-box optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Golovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Solnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhodeep</forename><surname>Moitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Kochanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Karro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD &apos;17</title>
		<meeting>KDD &apos;17</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Measuring individual differences in implicit cognition: the implicit association test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><forename type="middle">G</forename><surname>Greenwald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debbie</forename><forename type="middle">E</forename><surname>Mcghee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><forename type="middle">L K</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality and social psychology</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Efficient natural language response suggestion for smart reply</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Hsuan</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">LÃ¡szlÃ³</forename><surname>LukÃ¡cs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balint</forename><surname>Miklos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Kurzweil</surname></persName>
		</author>
		<idno>abs/1705.00652</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">JÃ¼rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD &apos;04</title>
		<meeting>KDD &apos;04</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep unordered composition rivals syntactic methods for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Manjunatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>DaumÃ©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL/IJCNLP</title>
		<meeting>ACL/IJCNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning question classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING &apos;02</title>
		<meeting>COLING &apos;02</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS&apos;13</title>
		<meeting>NIPS&apos;13</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Implicit and explicit stigmatizing attitudes and stereotypes about depression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lindsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><forename type="middle">W</forename><surname>Monteith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pettit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Social and Clinical Psychology</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Harvesting implicit group attitudes and beliefs from a demonstration web site</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">A</forename><surname>Nosek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahzarin</forename><forename type="middle">R</forename><surname>Banaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><forename type="middle">G</forename><surname>Greenwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Group Dynamics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Math = male, me = female, therefore math me</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">A</forename><surname>Nosek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahzarin</forename><forename type="middle">R</forename><surname>Banaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony G</forename><surname>Greenwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">83</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04)</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04)</meeting>
		<imprint>
			<publisher>Main Volume</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL&apos;05</title>
		<meeting>ACL&apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hcti at semeval-2017 task 1: Use convolutional neural network to evaluate semantic textual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</title>
		<meeting>the 11th International Workshop on Semantic Evaluation (SemEval-2017)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="130" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning semantic textual similarity from conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Sheng Yi Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heming</forename><surname>Pilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Hsuan</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kurzweil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RepL4NLP workshop at ACL</title>
		<meeting>RepL4NLP workshop at ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
