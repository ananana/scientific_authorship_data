<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ExtRA: Extracting Prominent Review Aspects from Customer Feedback</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyi</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Xu Bill</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanyuan</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenny</forename><forename type="middle">Q</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ExtRA: Extracting Prominent Review Aspects from Customer Feedback</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3477" to="3486"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3477</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Many existing systems for analyzing and summarizing customer reviews about products or service are based on a number of prominent review aspects. Conventionally, the prominent review aspects of a product type are determined manually. This costly approach cannot scale to large and cross-domain services such as Amazon.com, Taobao.com or Yelp.com where there are a large number of product types and new products emerge almost everyday. In this paper, we propose a novel framework, for extracting the most prominent aspects of a given product type from textual reviews. The proposed framework, ExtRA, extracts K most prominent aspect terms or phrases which do not overlap semantically automatically without supervision. Extensive experiments show that ExtRA is effective and achieves the state-of-the-art performance on a dataset consisting of different product types.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Online user review is an essential part of e- commerce. Popular e-commerce websites feature an enormous amount of text reviews, especially for popular products and services. To improve the user experience and expedite the shopping pro- cess, many websites provide qualitative and quan- titative analysis and summary of user reviews, which is typically organized by different promi- nent review aspects. For instance, <ref type="figure" target="#fig_0">Figure 1</ref> shows a short review passage from a customer on Tri- pAdvisor.com, and the customer is also asked to give scores on several specific aspects of the hotel, such as location and cleanness. With aspect-based reviews summary, potential customers can assess a product from various essential aspects very ef- ficiently and directly. Also, aspect-based review summary offers an effective way to group prod- ucts by their prominent aspects and hence enables quick comparison. Existing approaches for producing such promi- nent aspect terms have been largely manual work ( <ref type="bibr" target="#b21">Poria et al., 2014;</ref><ref type="bibr" target="#b22">Qiu et al., 2011</ref>). This is feasible for web services that only sell (or re- view) a small number of product types of the same domain. For example, TripAdvisor.com only fea- tures travel-related products, and Cars.com only reviews automobiles, so that human annotators can provide appropriate aspect terms for cus- tomers based on their domain knowledge. While it is true that the human knowledge is useful in characterizing a product type, such manual ap- proach does not scale well for general-purpose e- commerce platforms, such as Amazon, eBay, or Yelp, which feature too many product types, not to mention that new product and service types are emerging everyday. In these cases, manually se- lecting and pre-defining aspect terms for each type is too costly and even impractical.</p><p>Moreover, the key aspects of a product type may also change over time. For example, in the past, people care more about the screen size and signal intensity when reviewing cell phones. These as- pects are not so much of an issue in present days. People instead focus on battery life and processing speed, etc. Therefore, there is a growing need to automatically extract prominent aspects from user reviews.</p><p>A related but different task is aspect-based opinion mining ( <ref type="bibr" target="#b25">Su et al., 2008;</ref><ref type="bibr" target="#b32">Zeng and Li, 2013)</ref>. Here techniques have been developed to automatically mine product-specific "opinion phrases" such as those shown in <ref type="figure" target="#fig_4">Figure 2</ref>. In this example, the most frequently mentioned opin- ion phrases about a phone model along with the mention frequency are displayed. Their goal is to get the fine-grained opinion summary on pos- sibly overlapping aspects of a particular product. For example, "good looks" and "beautiful screen" both comments on the "appearance" aspect of the phone. However, these aspects are implicit and can't be used in aspect-based review summariza- tion directly. The main disadvantage of these opin- ion phrases is that their aspects differ from prod- uct to product, making it difficult to compare the product side by side.</p><p>fast system (196) long battery-life <ref type="bibr">(193)</ref> good design (236) high call-quality <ref type="formula" target="#formula_4">(163)</ref> nice functions (181) good value <ref type="bibr">(282)</ref> tufs@gmail.com kzhu@cs.sjtu.edu.cn of summarizing users opinions grade it by a number of distinct by the same type of product or cts for a product type are deter- t scale to large number of product latform such as amazon.com or ropose a unsupervised multistage tically discovering the best aspect textual user reviews. This method ny product or service types. Our pproach is efficient and achieves for a diverse set of products and ODUCTION integral part of e-commerce. s feature enormous amount of popular products and services. nce and expedite the shopping ides either qualitative or quanti- eviews, organized by important e target product or service. Two d review summarization <ref type="bibr">[1]</ref> are <ref type="figure" target="#fig_0">Fig. 1</ref> from TripAdvisor, besides en by the user, the user are asked scale of 1-5) on various aspects on and cleanness. The ratings of iews can then be aggregated into product by many users, such as car model in <ref type="figure" target="#fig_4">Fig. 2</ref>, a snapshot e several advantages compared w form that consists of a short . In aspect-based reviews, more ively and more directly, and the s aspects of a product without w passage. Another advantage of ifferent products within the same irectly with respect to multiple rall rating. When researching on f their time comparing different ased review summarization pro- way for doing such comparison, d effort. At present, websites that offers aspect-based review sum- maries typically only features a single or small number of product categories, e.g., TripAdvisor.com only features travel related products while car.com reviews automobiles. The rea- son is that it takes in-depth knowledge about the product to produce a set of words that best characterize the product, both in terms of the coverage and user interests. It is such a difficult task that these aspects are mostly manually chosen by the website operator. Manual selection of aspects certainly cannot scale to large number of product types as featured by gen- eral e-commerce platforms such as amazon.com, taobao.com and Yelp!. These platforms instead turn to automatic review summarization, mined from the user review text.   The goal of this paper is to develop an unsuper- vised framework for automatically extracting K most prominent, non-overlapping review aspects for a given type of product from user review texts. Developing such an unsupervised framework is challenging for the following reasons:</p><p>• The extracted prominent aspects not only need to cover as many customer concerns as possible but also have little semantic overlap.</p><p>• The expression of user opinions is highly versatile: aspect terms can be expressed ei- ther explicitly or implicitly. For example, the mention of "pocket" implies the aspect "size".</p><p>• Product reviews are information rich. A short piece of comments may target multiple as- pects, so topics transit quickly from sentence to sentence.</p><p>Most previous unsupervised approaches for the prominent aspect extraction task are variants of topic modeling techniques ( <ref type="bibr" target="#b11">Lakkaraju et al., 2011;</ref><ref type="bibr" target="#b12">Lin and He, 2009;</ref><ref type="bibr" target="#b29">Wang et al., 2011a</ref>). The main problem of such approaches is that they typically use only word frequency and co-occurrence infor- mation, and thus degrade when extracting aspects from sentences that appear different on the surface but actually discuss similar aspects.</p><p>Given all review text about a certain product type, our framework, ExtRA, extracts most promi- nent aspect terms in four main steps: first it ex- tracts potential aspect terms from text corpus by lexico-syntactic analysis; then it associates the terms to synsets in WordNet and induce a sub- graph that connect these terms together; after that it ranks the aspect terms by a personalized page rank algorithm on the sub-graph; and finally picks the top K non-overlapping terms using the sub- sumption relation in the subgraph.</p><p>The main contributions in this paper are as fol- lows:</p><p>1. We propose a novel framework for extracting prominent aspects from customer review cor- pora (Section 2), and provide an evaluation dataset for future work in this research area.</p><p>2. Extensive experiments show that our unsu- pervised framework is effective and outper- forms the state-of-the-art methods by a sub- stantial margin (Section 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Framework</head><p>In this section, we first state the review aspect ex- traction problem, then present the workflow of our method, shown in <ref type="figure" target="#fig_3">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Statement</head><p>The review aspect extraction problem is given all the text reviews about one type of product or ser- vice, extract K words (or phrases), each of which represents a prominent and distinct review aspect. For instance, if the given product type is ho- tel, we expect a successful extraction framework to extract K = 5 aspect terms as follows: room, location, staff, breakfast, pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Aspect Candidates Extraction</head><p>Following the observation of <ref type="bibr" target="#b9">Liu (2004;</ref>, we assume that aspect terms are nouns and noun phrases. First, we design a set of effective syn- tactic rules, which can be applied across domains, to collect the aspect candidates from review texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>It is a great zoom lens</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>amod</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ID Sentence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(1) It's a great zoom lens, but it's too much of a risk for me for that much money.</head><p>(2) The only issues that I have with the camera is somewhat slower autofocus, a noisy shutter and cheap lens cover.</p><p>(3) The shutter is quick and quiet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 1: Aspect Candidates Extraction</head><p>Review corpus from different domains We mainly use the adjectival modifier dependency relation (amod) and the nominal subject relation (nsubj) to extract the aspect-opinion pairs N, A.</p><p>In addition, we leverage the conjunction relation (conj) between adjectives to complement the ex- tracted pairs. Formally, the extraction rules can be specified as follows:</p><formula xml:id="formula_0">Rule 1. If amod(N, A), then extract N, A.</formula><p>Rule 2. If nsubj(A, N ), then extract N, A.</p><formula xml:id="formula_1">Rule 3. If N, A i and conj(A i , A j ), then extract N, A j .</formula><p>In this case, N indicates a noun, and A (e.g.</p><formula xml:id="formula_2">A i , A j )</formula><p>is an adjective. The dependencies (e.g. amod(N, A)) are expressed as rel(head, depen- dent), where rel is the dependency relation which holds between head and dependent. Note that many aspects are expressed by phrases, thus, we extend the phrases as aspect candidates by intro- ducing the extension rules as follows:</p><formula xml:id="formula_3">Rule E1. If N, A and N −1 N ∈ P , then use N −1 N, A to replace N, A. Rule E2. If N, A and N N +1 ∈ P , then use N N +1 , A to replace N, A.</formula><p>where N −1 and N +1 denotes the noun word, and the subscript represents displacement to N in the sentence. We use AutoPhrase ( <ref type="bibr" target="#b13">Liu et al., 2017)</ref> to extract a set of phrases P with high coherence.</p><p>Then we use P to filter out the incoherent phrases so as to obtain the high-quality phrases as aspect candidates. The example in <ref type="figure" target="#fig_3">Figure 3</ref> (Stage 1) demonstrates the extraction process. For example, we extract the pair great, zoom lens from sen- tence (1) by applying Rule 1 and Rule E1. Simi- larly, the extraction rules match slower, autofo- cus , noisy, shutter , cheap, lens cover in sentence (2) and quick, shutter , quiet, shut- ter in sentence <ref type="formula" target="#formula_7">(3)</ref> as potential aspect-opinion pairs. After extracting such pairs from the text re- views, we sort them by the number of occurrences, and extract the nouns and noun phrases in the top pairs as aspect candidates, assuming that the most prominent aspects are subsumed by those candi- dates terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Aspect Taxonomy Construction</head><p>The aspect candidates extracted in the last stage come with the counts modified by adjectives. We can directly use such raw counts to rank the as- pect candidates. This is one of the baseline models in our experiments. However, such ranking usu- ally suffers from the aspect overlapping problem which obviously violates the principle of pursuing both coverage and distinctiveness of prominent as- pects. For example, given the number of promi- nent aspects K as 5, we can extract both of 'lo- cation' and 'place' aspects from the hotel reviews.</p><p>In order to solve this problem, we construct an as- pect taxonomy to obtain such overlapping infor- mation between aspect candidates by leveraging the WordNet ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">WordNet Synset Matching</head><p>First, we need to match our aspect candidates onto WordNet synsets. The accuracy of synset match- ing is very important for our aspect taxonomy construction. This is actually a classical word sense disambiguation (WSD) problem. Our ini- tial attempt is to use a Python WSD tool <ref type="bibr" target="#b26">(Tan, 2014</ref>). For each aspect candidate, we take it as the target and randomly sample a bunch of sen- tences that contain this target. We use the extended word sense disambiguation algorithm ( <ref type="bibr" target="#b0">Banerjee and Pedersen, 2003</ref>) in this tool. We count the to- tal occurrences for each noun sense (synset) of the candidate and match the candidate to the most fre- quent synset. However, such a method is not good enough for our problem, as shown in the results later. It only considers the local context informa- tion within the review sentence. Whats more, the review sentences are usually very short and collo- quial, which makes it more difficult to match prop- erly by a common WSD algorithm. Therefore, it is critical to construct more reliable contexts for aspect candidate matching. To achieve this goal, we cluster the aspect can- didates with similar semantics together. Then, for each aspect candidate, we take the other candi- dates within the same cluster as its context for later disambiguation. As shown in the first step of stage 2 in <ref type="figure" target="#fig_3">Figure 3</ref>, the semantic similar aspect candidates such as lens, lens cover, zoom lens, ex- posure and shutter are clustered together. For ex- ample, we can disambiguate the sense of shutter by leveraging lens, lens cover, zoom lens, and ex- posure. We observed that our aspect candidates can be fine-grain clustered with a two-stage k- means clustering method, 1 which generates the better context for the aspect candidates. More specifically, for a particular aspect candidate a t from the cluster C = {a 1 , a 2 , ..., a t , ..., a n }, we calculate the context vector of a t as:</p><formula xml:id="formula_4">c(a t ) = n i=1,i =t E(a i ),<label>(1)</label></formula><p>where c(a t ) denotes the context vector of a t , and E(a i ) represents the embedding of a i . The set of candidate synsets S(a t ) = {s t 1 , s t 2 , ..., s t m } con- sists of the noun senses (e.g. s t i ) of a t from Word- Net. Each sense s t i is associated with a gloss g t i (i.e. a brief definition of s t i ) which covers the se- mantics of the sense. Therefore, we encode s t i as the summation of the word vectors in g t i :</p><formula xml:id="formula_5">v(s t i ) = q j=1 E(w t,i j ),<label>(2)</label></formula><formula xml:id="formula_6">W (g t i )</formula><p>is the sequence of words in g t i , i.e., W (g t i ) = [w t,i 1 , w t,i 2 , ..., w t,i q ]. For each candidate <ref type="bibr">1</ref> The implementation details are in Section 3.2.</p><p>sense s t i of the aspect candidate a t , we calculate the cosine semantic similarity between v(s t i ) and c(a t ), and match a t to the most similar s t i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Aspect Taxonomy Extraction from WordNet</head><p>In order to construct the aspect taxonomy from WordNet, we first extract the hypernym paths for every matched synsets in the previous step. By definition, a hypernym path p of synset s is the is-a relation path from s to the root synset (i.e. entity.n.01 for nouns). We extract the hypernym paths for each matched synset s i in the WordNet ontology. Next, we scan over all the collected paths once to construct the aspect taxonomy which is a directed acyclic graph (DAG). In p, s 1 is the synset matched from our potential aspects, and s i+1 is the hypernym of s i . As shown in step 2 of Stage 2 in <ref type="figure" target="#fig_3">Figure 3</ref>, we match the aspect can- didate shutter to shutter.n.01. The only one hy- pernym path of shutter.n.01 is [shutter.n.01, opti- cal device.n.01, device.n.01, ..., entity.n.01].</p><p>However, the matched synset usually has multi- ple hypernym paths in WordNet. We use the fol- lowing strategy to compact and minimize the as- pect taxonomy:</p><p>• Among all the paths from an aspect candidate s 1 , we will keep those paths that contain more than 1 aspect candidates, unless there's only one path from s 1 . If all paths contain only 1 aspect candidate s 1 each, we will keep all of them.</p><p>• To further optimize the taxonomy structure, we induce a minimum subgraph from the original taxonomy using a heuristic algo- rithm ( <ref type="bibr" target="#b10">Kou et al., 1981)</ref>. Such a subgraph satisfies the following conditions: 1) it con- tains all the nodes matched from aspect can- didates; 2) the total number of nodes in the graph is minimal. Consequently, the induced graph is a weakly connected DAG.</p><p>After acquiring the aspect taxonomy for the given product or service, we can now tell if two aspects are semantically overlapped or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Aspect Ranking</head><p>In this section, we propose a novel method based on personalized page rank to compute the overall rank values for the potential aspects by leveraging the aspect taxonomy.</p><p>Let the aspect taxonomy be a graph G = (V, E). Each node v ∈ V is a synset in the as- pect taxonomy and encoded as a vector by instan- tiating E as Glove embeddings in <ref type="bibr">(2)</ref> . Each edge e = u, v carries a weight which is the semantic similarity between the nodes u and v, computed using cosine similarity.</p><p>Next, we perform the random walks on our con- structed aspect taxonomy. The propagation starts from candidate aspect nodes in the aspect taxon- omy, which are called seeds here. The rank values (aspect importance) of all nodes are:</p><formula xml:id="formula_7">x t = (1 − α) * Ax t−1 + α * E,<label>(3)</label></formula><p>where t is the time step in random walk process.</p><p>In the initial state E(i.e. x 0 ), the aspect impor- tance only distributes on the seeds (v ∈ V b ). E i is the i-th dimension of E, indicating the portion of aspect importance on node s i at time step 0. E is calculated as follows:</p><formula xml:id="formula_8">E i = f (le(s i )) n j=1 f (le(s j ))</formula><p>, if s i is a seed</p><formula xml:id="formula_9">0 , otherwise,<label>(4)</label></formula><p>where n is the number of nodes in the graph, s i is the synset node, le(s i ) denotes the lemma form of s i , and f (le(s i )) represents the frequency that le(s i ) is modified by adjectives. The aspect importance is updated using the tran- sition probabilities matrix A which are the normal- ized weights on the edges of the taxonomy. α is the teleport probability, which is the probability of returning to the initial distribution at each time step. α determines the distance of propagation of the taxonomy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Aspect Generation</head><p>Finally, we generate the prominent aspects using the rank values of the aspects as well as the is-a relations in the aspect taxonomy.</p><p>We sort le(s i ) in decreasing order by their rank values. We essentially take the top aspects from the sorted list. However there might be two types of overlapping that we need to avoid: i) duplicate: different synset nodes may map to the same as- pects, i.e., le(s i ) = le(s j ), s i = s j ( aspects); ii) taxonomy overlap: the later aspect in the list is the hypernym or hyponym of the one of previous as- pects. To this end, we just skip overlapped aspect, and move along the list until we generate K non- overlapping prominent aspects from the list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We compare the ExtRA framework with multiple strong baselines on extracting aspect terms from user reviews. We first introduce the dataset and the competing models, then show the quantitative evaluation as well as qualitative analysis for dif- ferent models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>We use the customer review corpora of 6 kinds of product and service 2 collected from popular web- sites, including Amazon, TripAdvisor and Yelp. The number of hotel reviews ( <ref type="bibr" target="#b30">Wang et al., 2011b</ref>) in the original corpus is huge. Therefore, we randomly sample 20% of the reviews to perform our experiments. The statistics of the corpora are shown in <ref type="table" target="#tab_1">Table 1</ref>. Existing published aspect extraction datasets ( <ref type="bibr" target="#b9">Hu and Liu, 2004;</ref><ref type="bibr" target="#b20">Popescu and Etzioni, 2007;</ref><ref type="bibr" target="#b18">Pavlopoulos and Androutsopoulos, 2014;</ref><ref type="bibr" target="#b4">Ding et al., 2008</ref>) include only fine-grained aspects from reviews, which are not suitable for evalu- ating the performance of prominent aspects ex- traction. Therefore, we build a new evaluation dataset particularly for this task. Following the previous work ( <ref type="bibr" target="#b5">Ganu et al., 2009;</ref><ref type="bibr" target="#b2">Brody and Elhadad, 2010;</ref><ref type="bibr" target="#b33">Zhao et al., 2010;</ref><ref type="bibr" target="#b31">Wang et al., 2015)</ref> as well as the popular commercial websites (e.g. TripAdvisor), which most manually labeled 3-6 prominent aspects for rating, we set K as five. Therefore, we ask each annotator who are famil- iar with the domain to give 5 aspect terms which they think are most important for each category. We have five annotators in total. <ref type="bibr">3</ref> One prominent aspect can be expressed by different terms. Thus, it is difficult to achieve a satisfied inner-agreement. We propose two evaluation methods, especially the soft accuracy in Section 3.3.1 to compensate <ref type="bibr">2</ref> The data is available from http://times. this problem. To acquire a relatively higher inner- agreement, we educate the annotators with top 100 frequent aspect candidates as hints. Though, they are not required to pick up labels from the can- didates. The inter-annotator agreement of each product type shown in <ref type="table" target="#tab_4">Table 3</ref> is computed as the average jaccard similarity between every two an- notators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baselines and ExtRA</head><p>We introduce three topic modeling based baselines for the task. These are LDA ( <ref type="bibr" target="#b1">Blei et al., 2003</ref>), BTM ( <ref type="bibr" target="#b3">Cheng et al., 2014</ref>) and MG-LDA ( <ref type="bibr" target="#b27">Titov and McDonald, 2008)</ref>. MG-LDA is a strong base- line which attempts to capture multi-grain topics (i.e. global &amp; local), where the local topics cor- respond to the rateable prominent aspects. We treat each review as a document and perform those models to extract K topics. Then, we select most probable words in each topic as our extracted as- pect terms. To prevent extracting the same as- pects (w) from different topics, we only keep w for the topic t with the highest probability p(w|t) value, then re-select aspects for the other topics until we get K different aspects. For fair compar- ison among different models, the number of target aspects K is set as 5. The hyper-parameter of MG- LDA (global topics) is set to 30 with fine-tuning. Another syntactic rule-based baseline model AmodExt is from the first stage of our framework. After extracting the aspect candidates using amod- rule in Section 2.2, we sort the aspect candidates by their counts of extracted occurrences. Then se- lect the top K candidates as the prominent aspects.</p><p>ABAE ( <ref type="bibr" target="#b7">He et al., 2017</ref>) is a neural based model that can to infer K aspect types. Each aspect type is a ranked list of representative words. To gener- ate K prominent aspects, we first infer K aspect types using ABAE, then select the most represen- tative word from each aspect type.</p><p>For ExtRA, in the taxonomy construction stage, we use a two-stage K-means clustering method for synset matching task, and the cluster number is auto-tuned using silhouette score <ref type="bibr" target="#b24">(Rousseeuw, 1987)</ref>. We use SkipGram ( <ref type="bibr" target="#b16">Mikolov et al., 2013)</ref> model to train the embeddings on review texts for k-means clustering. We set the dimension of the embeddings as 100 and run 64 epochs for each product corpora. In the aspect ranking stage, we empirically set the teleport probability α as 0.5 which indicates that the expected walk-length from the seeds is 1 α = 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation</head><p>In this section, we compare ExtRA with five base- line models both quantitatively and qualitatively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Quantitative Evaluation</head><p>First, we perform two experiments to justify our aspect taxonomy construction stage:</p><p>• To justify the synset matching step, we com- pare our proposed cluster method with classi- cal WSD algorithm (Lesk) on matching accu- racy. We manually label 100 sampled synset nodes for each category. The synset match- ing accuracies are shown in <ref type="table" target="#tab_3">Table 2</ref>. We can see that our clustering method is effective for the synset matching task.</p><p>• We induce the aspect taxonomy using a heuristic algorithm to obtain more compact and aspect-oriented subgraph. We show the size of aspect taxonomy induced before and after taxonomy minimization in <ref type="figure">Figure 4</ref>.</p><p>Next, we evaluate our model as well as above baselines on the evaluation dataset described above. We did not remove the duplicate aspect labels for the qualitative evaluation, since the re- peated aspects are assume to be better. For a given category, we first calculate the percentage of the 25 labels that exactly match one of the 5 aspect terms generated by the model as the hard accuracy of the model. Formally, Aspects(m) = [a 1 , a 2 , a 3 , a 4 , a 5 ] denotes the five prominent as- pects generated from model m for the given cate- gory. L = [l 1 , l 2 , ..., l 25 ] are the 25 golden aspect terms, where L (h) = [l 5h−4 , ..., l 5h ] are from the h-th human annotator. The hard accuracy is de- fined as:</p><formula xml:id="formula_10">hacc(m) = 25 i=1 hit(Aspects(m), l i ) 25<label>(5)</label></formula><p>hit(Aspects(m), l i ) = 1, l i ∈ Aspects(m) 0, otherwise, (6) However, counting the number of exact matches makes the accuracy score discrete and coarse. Be- sides, it penalizes aspect terms that don't match the label but actually have similar meanings. To   Figure 4: Statistics of induced aspect taxonomy before and after taxonomy minimization remedy this, we propose the soft accuracy eval- uation measure. For each set of five golden la- bels from h-th annotator, we first align each gen- erated aspect a k ∈ Aspects(m) with one golden aspect</p><formula xml:id="formula_11">l j ∈ L (h) (i.e. align (h) (a k ) = l j ).</formula><p>We align the exact match terms together, and then choose the optimal alignment for the oth- ers by permuting all possible alignments. The optimal alignment align (h) (a k ) acheives maxi- mum soft accuracy. Then we calculate the soft matching score between Aspects(m) and</p><formula xml:id="formula_12">L (h) as K k=1 sim(a k , align (h) (a k )),</formula><p>where sim is the cosine similarity computed by <ref type="bibr">Glove (2014)</ref>  <ref type="bibr">4</ref> . We then compute the soft accuracy measure as fol- lows:  <ref type="table" target="#tab_5">Table 4</ref>.</p><formula xml:id="formula_13">sacc(m) = 1 5 * 5 h=1 K k=1 sim(a k , align (h) (a k )),<label>(</label></formula><p>Our model (ExtRA) outperforms all the other baselines in all categories except cameras using the hard accuracy measure. Besides, ExtRA is the best model on four out of six products under the soft accuracy measure. As shown in <ref type="table" target="#tab_3">Table 2</ref>, the accuracy for synset matching is relatively low for  cameras and restaurant, resulting in the lower ac- curacy in overall aspect extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Qualitative Analysis</head><p>To qualitatively evaluate different models, we present the extracted 5 aspect terms by each model from each domain in <ref type="table">Table 5</ref>. Our model (ExtRA) has significant advantage over other baselines for that we can do better aspect extraction with rea- sonable results, and extract not only words but also phrases as prominent aspects, e.g. sound qual- ity, image quality. The proposed model avoid the overlapping aspects appeared in our strong base- line (AmodExt) by deduplication using generated aspect taxonomy information. The overlapping as- pects are marked in italics. For example, both lo-cation and place are extracted as top aspects, but they mean nearly the same concept. The results from other baseline methods, inevitably contain some sentiment words and opinions, like good, nice, great, etc. Our model resolves such draw- back by extracting aspect candidates from only nouns and using syntactic rules to find words that are frequently modified by adjectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Existing research on aspect-based review analy- sis has focused on mining opinion based on given aspects ( <ref type="bibr" target="#b25">Su et al., 2008;</ref><ref type="bibr" target="#b32">Zeng and Li, 2013)</ref> or jointly extracting the aspects and sentiment <ref type="bibr" target="#b12">(Lin and He, 2009;</ref><ref type="bibr" target="#b33">Zhao et al., 2010;</ref><ref type="bibr" target="#b22">Qiu et al., 2011;</ref><ref type="bibr" target="#b31">Wang et al., 2015;</ref><ref type="bibr" target="#b15">Liu et al., 2016)</ref>. They are mostly interested in detecting aspect words in a given sentence, whereas our goal is to extract the most prominent aspects of a type of product from a large number of reviews about that product type. We divide the existing work on review aspect ex- traction into three types:</p><p>• rule-based methods, most of which utilize handcrafted rules to extract candidate aspects and then perform clustering algorithm on them.</p><p>• topic modeling based methods, which di- rectly model topics from texts and then ex- tract aspects from the topics.</p><p>• neural network based methods, which takes advantage of the recent deep neural network models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Rule-based Methods</head><p>These methods leverage word statistical and syn- tactic features to manually design rules, recog- nizing aspect candidates from texts. <ref type="bibr" target="#b21">Poria et al. (2014)</ref> use manually crafted mining rules. <ref type="bibr" target="#b22">Qiu et al. (2011)</ref> also used rules, plus the Double Propa- gation method to better relate sentiment to aspects. <ref type="bibr" target="#b6">Gindl et al. (2013)</ref> cooperate the Double Prop- agation with anaphora resolution for identifying co-references to improve the accuracy. <ref type="bibr" target="#b25">Su et al. (2008)</ref> used a clustering method to map the im- plicit aspect candidates (which were assumed to be the noun form of adjectives in the paper) to explicit aspects. <ref type="bibr" target="#b32">Zeng et al. (2013)</ref> mapped im- plicit features to explicit features using a set of sentiment words and by clustering explicit feature- sentiment pairs. <ref type="bibr" target="#b23">Rana et al. (2017)</ref> propose a two- fold rules-based model, using rules defined by se- quential patterns. Their first fold extracts aspects associated with domain independent opinions and the second fold extracts aspects associated with domain dependent opinions. However, such rule-based models are designed for extracting product features which can not eas- ily adapt to our K most prominent aspect extrac- tion problem. Besides, most of them require hu- man efforts to collect lexicons and to carefully de- sign complex rules and thus do not scale very well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Topic Modeling Based Methods</head><p>Most work in this domain are based on two ba- sic models, pLSA <ref type="bibr" target="#b8">(Hofmann, 1999</ref>) and LDA( <ref type="bibr" target="#b1">Blei et al., 2003)</ref>. The variants of these models consider two special features of review texts: 1) topics shift quickly between sentences, 2) sentiment plays an important role and there is a strong correlation be- tween sentiments and aspects. The approach of Lin et al. (2011) models are parallel aspects and sentiments per review. <ref type="bibr" target="#b12">Lin et al. (2009)</ref> models the dependency between the latent aspects and ratings. <ref type="bibr" target="#b29">Wang et al. (2011a)</ref> proposed a generative model which incorporates topic modeling technique into the latent rating regression model ( <ref type="bibr" target="#b28">Wang et al., 2010)</ref>. <ref type="bibr" target="#b17">Moghaddam et al. (2012)</ref> made a nice summarization of some basic variations of LDA for opinion mining. In stead of using topics, our method relies on word embeddings to cap- ture the latent semantics of words and phrases and achieves better results. MG-LDA <ref type="bibr" target="#b27">(Titov and McDonald, 2008</ref>) is a variant of LDA that can also model topics at different granularities, which are based on extensions to standard topic modeling methods such as LDA and PLSA to induce multi- grain topics. D-PLDA <ref type="bibr" target="#b17">(Moghaddam and Ester, 2012)</ref>, is a variant of LDA models, which is de- signed specifically for modeling topics from user reviews. D-PLDA only considers opinion-related terms and phrases, and nouns and phrases are con- trolled by two separate hidden parameters. Thus, the model needs aspects, ratings, and phrases as input, which are all very expensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Neural Network Based Methods</head><p>He et al. <ref type="formula" target="#formula_4">(2017)</ref> propose a neural attention model for identifying aspect terms. Their goal is simi- lar to ours but instead of directly comparing their extracted terms with the gold standard, they ask human judges to map the extracted terms to one of the prominent gold aspects manually before computing the precision/recall. This evaluation methodology mixed machine results with human judgment and is problematic in our opinion. Our experiments showed that their output aspects are too fine-grained and can not be used as prominent aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose an unsupervised frame- work ExtRA for extracting the most prominent aspect terms about a type of product or service from user reviews, which benefits both qualitative and quantitative aspect-based review summariza- tion. Using WordNet as a backbone, and by run- ning personalized page rank on the network, we can produce aspect terms that are both important and non-overlapping. Results show that this ap- proach is more effective than a number of other strong baselines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example user review about a hotel on TripAdvisor. The grades are organized by different prominent review aspects: value, rooms, etc.</figDesc><graphic url="image-1.png" coords="1,340.02,222.54,152.77,115.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 User review from TripAdvisor.</figDesc><graphic url="image-2.png" coords="2,102.45,28.51,177.92,82.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>looks good (462) beautiful screen (398) nice functions (356) high resolution (872) good camera (218) good value (628)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 Automatic review summarization for a mobile phone from an e-commerce website.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Automatic review summarization for two mobile phones on an e-commerce website</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>7) where K = 5 in this case. The comparison results are shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>nsubj Step 1: WordNet Noun Synset Matching</head><label></label><figDesc></figDesc><table>Syntactic Rule 

Phrase Mining 
(AutoPhrase) 

amod 

A 

Raw Corpus 

Stage 2: Aspect Taxonomy Construction 

Cluster 

lens 
lens_cover 
zoom_lens 
exposure 
shutter 
…. 
Aspect Candidates 

Aspect 
Candidates 
Clustering 

Context 
for 
shutter 

shutter.n.01 

shutter.n.02 
✘ 

✔ 

Step 2: Aspect Taxonomy Extraction from WordNet 

lens.n.01 

device.n.01 
optical_device.n.01 

Aspect Taxonomy 

shutter.n.01 

lens 

zoom_lens 
shutter 

Stage 3: Aspect Ranking 

Aspect Graph &amp; Random Walk (Personalized Page Rank) 

lens.n.01 

device.n.01 
optical_device.n.01 

shutter.n.01 

lens 
telephoto_l 
ens.n.01 
zoom_lens 
shutter 

0.75 

0.66 

0.5 

0.32 

Teleport 

Stage 4: Aspect Generation 

Top-K Aspects 

Deduplication 

Remove Taxonomy 
Overlapping 

lens 
telephoto_lens 
shutter 
…. 
Final Aspects 

The shutter is quick and quiet. 

conj 

N-1 N 

Ai 
Aj 
N 
telephoto_lens.n.01 

zoom_lens 
lens_cover 
… 

Figure 3: Overall framework. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Dataset statistics.</head><label>1</label><figDesc></figDesc><table>Product type 
Source 
#Reviews 
hotel 
TripAdvisor 3,155,765 
mobile phone 
Amazon 
185,980 
mp3 player 
Amazon 
30,996 
laptop 
Amazon 
40,744 
cameras 
Amazon 
471,113 
restaurant 
Yelp 
269,000 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>WordNet Synset matching accuracies 

hotel mp3 cameras 
mobile 
phone 
laptop restaurant 

LESK 
0.71 
0.59 
0.62 
0.64 
0.53 
0.65 
Cluster 
0.86 
0.83 
0.74 
0.80 
0.78 
0.69 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 : Inner-annotator agreements</head><label>3</label><figDesc></figDesc><table>hotel 
mp3 
cameras 
mobile 
phone 
laptop restaurant 

Jaccard 0.470 0.554 
0.304 
0.440 
0.271 
0.671 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Comparison of hard (upper row) &amp; soft (lower row) 

accuracies using different models for aspect extraction. 

LDA 
BTM 
MG-
LDA 
ABAE 
AmodExt 
ExtRA 

hotel 
0.16 
0.16 
0.16 
0.16 
0.44 
0.56 
0.50 
0.49 
0.67 
0.35 
0.65 
0.70 

</table></figure>

			<note place="foot" n="4"> We use the GloVe embeddings with 300 dimensions, trained from 840B tokens using common crawl data.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>Kenny Q. Zhu is the contact author and was sup-ported by NSFC grants 91646205 and 61373031.</p><p>Thanks to the anonymous reviewers for their valu-able feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Extended gloss overlaps as a measure of semantic relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satanjeev</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ijcai</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="805" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An unsupervised aspect-sentiment model for online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noemie</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="804" to="812" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Btm: Topic modeling over short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>TKDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A holistic lexicon-based approach to opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WSDM</title>
		<meeting>WSDM</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Beyond the stars: improving rating predictions using review text content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gayatree</forename><surname>Ganu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noemie</forename><surname>Elhadad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amélie</forename><surname>Marian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WebDB</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rule-based opinion target and aspect extraction to acquire affective knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Gindl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Weichselbraun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arno</forename><surname>Scharl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An unsupervised neural attention model for aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruidan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Wee Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahlmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of KDD</title>
		<meeting>of KDD</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A fast algorithm for steiner trees. Acta informatica</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Markowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Berman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Exploiting coherence for the simultaneous discovery of latent facets and associated sentiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himabindu</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiranjib</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Indrajit</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srujana</forename><surname>Merugu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Joint sentiment/topic model for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Phrase mining from massive text and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Synthesis Lectures on Data Mining and Knowledge Discovery</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automated rule selection for aspect extraction in opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1291" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Improving opinion aspect extraction using semantic similarity and aspect associations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doo</forename><forename type="middle">Soon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the design of lda models for aspect-based opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samaneh</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Aspect term extraction for sentiment analysis: New datasets, new evaluation measures and an improved unsupervised method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LASMEACL</title>
		<meeting>LASMEACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Extracting product features and opinions from reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana-Maria</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orena</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural language processing and text mining</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A rule-based approach to aspect extraction from product reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lun-Wei</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop on Natural Language Processing for Social Media</title>
		<meeting>of the Workshop on Natural Language essing for Social Media</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Opinion word expansion and target extraction through double propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>CL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A two-fold rulebased model for aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toqir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-N</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter J Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational and applied mathematics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hidden sentiment association in chinese web opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinying</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhili</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Swen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Pywsd: Python implementations of word sense disambiguation (wsd) technologies [software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liling</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Modeling online reviews with multi-grain topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Latent aspect rating analysis on review text data: a rating regression approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of KDD</title>
		<meeting>of KDD</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Latent aspect rating analysis without aspect keyword supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of KDD</title>
		<meeting>of KDD</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning online discussion structures by conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sentiment-aspect extraction based on restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="616" to="625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A classificationbased approach for implicit feature identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingwei</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Jointly modeling aspects and opinions with a maxent-lda hybrid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
