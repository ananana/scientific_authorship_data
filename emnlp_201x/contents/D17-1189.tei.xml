<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Soft-label Method for Noise-tolerant Distantly Supervised Relation Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kexiang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Soft-label Method for Noise-tolerant Distantly Supervised Relation Extraction</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1790" to="1795"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Distant-supervised relation extraction inevitably suffers from wrong labeling problems because it heuristically labels rela-tional facts with knowledge bases. Previous sentence level denoise models don&apos;t achieve satisfying performances because they use hard labels which are determined by distant supervision and immutable during training. To this end, we introduce an entity-pair level denoise method which exploits semantic information from correctly labeled entity pairs to correct wrong labels dynamically during training. We propose a joint score function which combines the relational scores based on the entity-pair representation and the confidence of the hard label to obtain a new label, namely a soft label, for certain entity pair. During training, soft labels instead of hard labels serve as gold labels. Experiments on the benchmark dataset show that our method dramatically reduces noisy instances and outperforms the state-of-the-art systems.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Relation Extraction (RE) aims to obtain relational facts from plain text. Traditional supervised RE systems suffer from lack of manually labeled data. <ref type="bibr" target="#b4">Mintz et al. (2009)</ref> proposes distant supervision, which exploits relational facts in knowledge bases <ref type="bibr">(KBs)</ref>. Distant supervision automatically gener- ates training examples by aligning entity mentions in plain text with those in KB and labeling entity pairs with their relations in KB. If there's no re- lation link between certain entity pair in KB, it will be labeled as negative instance (NA). How- ever, the automatic labeling inevitably accompa- nies with wrong labels because the relations of entity pairs might be missing from KBs or mis- labeled. Multi-instances learning (MIL) is proposed by <ref type="bibr" target="#b5">Riedel et al. (2010)</ref> to combat the noise. The method divides the training set into multiple bags of entity pairs (shown in <ref type="figure" target="#fig_0">Fig 1)</ref> and labels the bags with the relations of entity pairs in the KB. Each bag consists of sentences mentioning both head and tail entities. Much effort has been made in reducing the influence of noisy sentences within the bag, including methods based on at-least-one assumption ( <ref type="bibr" target="#b1">Hoffmann et al., 2011;</ref><ref type="bibr" target="#b6">Ritter et al., 2013;</ref><ref type="bibr" target="#b9">Zeng et al., 2015)</ref> and attention mechanisms over instances ( <ref type="bibr" target="#b3">Lin et al., 2016;</ref><ref type="bibr" target="#b2">Ji et al., 2017</ref>).</p><p>However, the sentence level denoise methods can't fully address the wrong labeling problem largely because they use a hard-label method in which the labels of entity pairs are immutable dur-ing training, no matter whether they are correct or not. As shown in <ref type="figure" target="#fig_0">Fig 1,</ref> due to the absence of (Jan Eliasson 1 , Sweden) from Nationality relation in the KB, the entity pair is mislabeled as NA. How- ever, we find the sentences in the bag of (Jan Elias- son, Sweden) share similar semantic pattern "X of Y" with correctly labeled instances (blue). In the false positive instance, Sebastian Roch is indeed from France, but the syntactic pattern of the sen- tence in the bag differs greatly from those of cor- rectly labeled instances. Actually, the reliability of a distant-supervised (DS) label can be determined by the syntactic/semantic similarity between cer- tain instance and the potential correctly labeled in- stances. Soft-label method intends to utilize corre- sponding similarities to correct wrong DS labels in the training stage dynamically, which means the same bag may have different soft labels in dif- ferent epochs of training. The basis of soft-label method is the dominance of correctly labeled in- stances. Fortunately, <ref type="bibr" target="#b8">Xu et al. (2013)</ref> proves that correctly labeled instances account for 94.4% (in- cluding true negatives) in the distant-supervised New York Times corpus (benchmark dataset).</p><p>To this end, we introduce a soft-label method to correct wrong labels at entity-pair level dur- ing training by exploiting semantic/syntactic in- formation from correctly labeled instances. In our model, the representation of certain entity pair is a weighted combination of related sentences which are encoded by piecewise convolutional neural network (PCNN) ( <ref type="bibr" target="#b9">Zeng et al., 2015</ref>). Besides, we propose a joint score function to obtain soft labels during training by taking both the confidence of DS labels and the entity-pair representations into consideration. Our contributions are three-fold:</p><p>• To the best of our knowledge, we first propose an entity-pair level noise-tolerant method while previous works only focused on sentence level noise.</p><p>• We propose a simple but effective method called soft-label method to dynamically cor- rect wrong labels during training. Case study shows our corrections are of high accuracy.</p><p>• We evaluate our model on the benchmark dataset and achieve substantial improvement compared with the state-of-the-art systems.</p><p>1 Jan Eliasson is a Swedish diplomat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Multi-instances learning (MIL) framework splits the training set M into multiple entity-pair bags {{h 1 , t 1 , h 2 , t 2 , · · · , h n , t n }. Each bag h i , t i contains sentences {x 1 , x 2 , · · · , x c } which mention both head entity h i and tail entity t i . The representation s i of bag h i , t i is a weighted combination of related sentence vectors {x 1 , x 2 , · · · , x c } which are encoded by CNN. Fi- nally, we use soft-label score function to correct wrong labels of bags of entity pairs while comput- ing probabilities for each relation type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sentence Encoder</head><p>We get the representation of certain sentence</p><formula xml:id="formula_0">x i = {w 1 , w 2 , · · · , w m } by concatenating word em- beddings {w 1 , w 2 , · · · , w m } and position embed- dings (Zeng et al., 2014) {p 1 , p 2 , · · · , p m }, where w i ∈ R d , w i ∈ R dw , p i ∈ R dp (d = d w + d p ).</formula><p>Convolution layer utilizes a sliding window of size l. We define q i ∈ R l×d as the concatenation of words within the i-th window.</p><formula xml:id="formula_1">q i = w i−l+1:i (1 ≤ i ≤ m + l − 1)<label>(1)</label></formula><p>The convolution matrix is denoted by W c ∈ R dc×(l×d) , where d c is the sentence embedding size. The i-th filter of the convolutional layer is computed as:</p><formula xml:id="formula_2">f i = [W c q + b] i (2)</formula><p>Afterwards, Piecewise max-pooling ( <ref type="bibr" target="#b9">Zeng et al., 2015</ref>) is used to divide convolutional filter f i into three parts</p><formula xml:id="formula_3">f 1 i , f 2 i , f 3 i</formula><p>by head and tail enti- ties. For example, the sentence "Barack Obama was born in Honululu in 1961" are divided into 'Barack Obama', 'was born in Honululu' and 'in 1961'. We perform max-pooling on these three parts separately, and the i-th element of sentence vector x ∈ R dc is defined as the concatenation of them:</p><formula xml:id="formula_4">x i = [max(f 1 i ); max(f 2 i ); max(f 3 i )]<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sentence Level Weight distribution</head><p>The representation of entity pair h i , t i is defined as a weighted combination of sentences in the bag.</p><p>At-least-one: At-least-one assumption is a down sampling method which assumes at least one sen- tence in the bag will express the relation between two entities, and select the most likely sentence in the bag for training and prediction. To be more specific, the weight of the selected sentence is 1 while those of other sentences in the bag are all 0. Selective Attention: <ref type="bibr" target="#b3">Lin et al. (2016)</ref> proposes se- lective attention mechanism to reduce weights of noisy instances within the entity-pair bag.</p><formula xml:id="formula_5">s = i α i x i ; α i = exp (x i Ar) k exp (x k Ar)<label>(4)</label></formula><p>where α i is the weight of sentence vector x i , A and r are diagonal and relation query parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Soft-label Adjustment</head><p>The key of our method is to derive a soft label as the gold label for each bag dynamically during training, which is not necessarily the same label as the distant supervised (DS) label. We still use DS labels while testing.</p><p>The soft label is determined dynamically, which means the same bag may have different soft labels in different training epochs. we propose follow- ing joint function to determine the soft label r i for entity pair h i , t i :</p><formula xml:id="formula_6">r i = arg max(o + max(o)A L i )<label>(5)</label></formula><p>where o, A, L i ∈ R dr (d r is the number of pre- defined relations). One-hot vector L i indicates the DS label of h i , t i . Relation Confidence vector A represents the reliability of DS labels. Each element in A is a decimal between 0 and 1, which indicates the confidence of correspond- ing DS labeled relation type. operation rep- resents element-wise production. o is the vector of relational scores based on the entity-pair repre- sentation s i of h i , t i . max(o) is a scaling con- stant which restricts the effect of the DS label. The score of the t-th relation type o t is calculated based on the trained relation matrice M and bias b:</p><formula xml:id="formula_7">o t = exp (Ms t + b) k exp (Ms k + b)<label>(6)</label></formula><p>We use entity-pair level cross-entropy loss func- tion using soft labels as gold labels while training:</p><formula xml:id="formula_8">J(θ) = n i=1</formula><p>log p(r i |s i ; θ)</p><p>In the testing stage, we still use the DS label l i of certain entity pair h i , t i as the gold label: </p><formula xml:id="formula_10">G(θ) = n i=1 log p(l i |s i ; θ)<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section, we first introduce the dataset and evaluation metrics in our experiments. Then, we demonstrate the parameter settings in our experi- ments. Besides, we compare the performance of our method with state-of-the-art feature-based and neural network baselines. Case study shows our soft-label corrections are of high accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Evaluation Metrics</head><p>We evaluate our model on the benchmark dataset proposed by <ref type="bibr" target="#b4">Mintz et al. (2009)</ref>, which has also been used by <ref type="bibr" target="#b5">Riedel et al. (2010)</ref> Window size Word dimension Position dimension Filter dimension Batch size Learning rate Dropout l = 3 dw = 50 dp = 5 dc = 230 B = 160 λ = 0.001 p = 0.5  <ref type="table">Table 2</ref>: Top-N precision (P@N) for relation extraction in the entity pairs with different number of sen- tences. Following ( <ref type="bibr" target="#b3">Lin et al., 2016)</ref>, One, Two and All test settings random select one/two/all sentences on the bags of entity pairs from the testing set which have more than one sentence to predict relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison with previous work</head><p>Mintz ( <ref type="bibr" target="#b4">Mintz et al., 2009</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Settings</head><p>We use cross-validation to determine the parame- ters in our model. Soft-label method uses PCNN- ONE/PCNN-ATT to represent the bags of entity pairs, and we don't tune on the parameters of PCNN-ONE/PCNN-ATT for fair comparsion. So we use the same pre-trained word embeddings and parameters of CNN encoder as those of <ref type="bibr" target="#b3">Lin et al. (2016)</ref>. Detailed parameter settings are shown in <ref type="table" target="#tab_1">Table 1</ref>. Moreover, we use Adam optimizer. Be- sides, to avoid negative effects of dominant NA instances in the begining of training, soft-label method is adopted after 3000 steps of parameter updates. The confidence vector A is heuristically set as [0.9, 0.7, · · · , 0.7] (the confidence of NA is 0.9 while confidence of other relations are all 0.7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Precision Recall Curve</head><p>We have following observations from <ref type="figure" target="#fig_1">Figure 2:</ref> (1) For both ATT and ONE configuration, soft-label method achieves higher precision than baselines when recall is greater than 0.05. After manual evaluation, we find that most wrong instances with less than 0.05 recall are wrong labeling entity pairs in test set.  <ref type="table">Table 3</ref>: Some examples of soft-label corrections while training using soft labels gets a slightly better performance than PCNN-ATT. (3) When recall is between 0.05 and 0.15, the curve of our model ATT+soft-label is relatively stable, which demonstrates soft-label can obtain relatively stable performance in extract- ing relational facts. <ref type="table">Table 2</ref> shows top-N precision (P@N) of the state- of-the-art systems and our model. We can see that (1) For both PCNN-ONE and PCNN-ATT model, soft-label method improves the precisions by over 10% in all test settings, which demonstrates the effects of our model. (2) Even a weaker baseline (PCNN-ONE) with soft-label method achieves higher precision than a strong model (PCNN- ATT). It shows that entity-pair level denoise model performs much better than the models which only focus on sentence level noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Top N precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case 1: Place of Birth → Nationality</head><p>Marcus Samuelsson began · · · when he was visiting his native Ethiopia. Marcus Samuelsson chef born in Ethiopia and raised in Sweden · · ·. Case 2: Location Contains → NA · · ·, he is from neighboring towns in Georgia (such as Blairsville and Young Harris) <ref type="table">Table 4</ref>: Two typical wrong corrections of soft- label adjustment during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Case Study</head><p>Some examples of soft-label corrections during training are shown in <ref type="table">Table 3</ref>. We can see that soft-label method can recognize both false posi- tives and false negatives during training and cor- rect wrong labels successfully. The two sentences above are mislabeled as place lived because triple facts (Fernand nault, place lived, Montreal) and (Alexandra pelosi, place lived, San francisco) ex- ist in Freebase. However, the two sentences fail to express place lived relation. Our model can au- tomatically correct them by soft-label adjustment. The two sentences below show that our model can also change false negative (NA) examples caused by missing facts in Freebase to correct ones. Besides, our model has strong ability to distin- guish different relational patterns, even for similar relations like Place lived, Place of born, Place of Death.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Error Analysis</head><p>We randomly select 200 instances of soft-label corrections during training for PCNN-ONE and PCNN-ATT respectively and check them manu- ally. The accuracy of soft-label corrections for PCNN-ONE is 88.5% (177/200) while that for PCNN-ATT is 92% (184/200). We notice that the accuarcy of PCNN-ATT+soft-label is slightly higher than that of PCNN-ONE+soft-label. The condition is the same as our expectation. As ex- plained in Sec 2.2, PCNN-ATT has better bag rep- resentations than PCNN-ONE because it can re- duce the effect of noisy instances within the bag. The soft-label of certain bag is determined by its bag representation and the confidence of corre- sponding DS label. So the accuracy of soft-label corrections for PCNN-ATT can benefit from better bag representations.</p><p>Although most of soft-label corrections are of high accuracy (90.25%), there are still several wrong corrections. <ref type="table">Table 4</ref> lists two typical wrong corrections during training. Wrong corrections like Case 1 fail to distinguish similar relations (both Nationality and place of birth are relations between people and locations) between entities because of their similar sentence patterns. How- ever, wrong corrections like Case 1 are rare (5/39) in our experiments. Soft-label method can still dis- tinguish most similiar relations as shown in Sec 3.6. In Case 2, factual relation location contains is mistaken as NA partially because the relational pattern of this sentence is somewhat different from the regular location contains pattern. Addition- ally, soft-label method has a tendency to label am- biguous facts as NA because negative instances (NA) are dominated in the corpus. However, most bags which are soft-labeled as NA are still well- labeled in our experiments.</p><p>We argue that the minor wrong corrections of relational facts during training don't affect the overall performance much because distant super- vision doesn't lack instances of relational facts due to its strong ability to automatically label large web text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>This paper proposes a noise-tolerant method to combat wrong labels in distant-supervised relation extraction with soft labels. Our model focuses on entity-pair level noise while previous models only dealt with sentence level noise. Our model achieves significant improvement over baselines on the benchmark dataset. Case study shows that soft-label corrections are of high accuracy.</p><p>In the future, we plan to develop a new measure- ment for the reliability of certain distantly super- vised label by evaluating the corresponding sim- ilarity between certain instance and the potential correctly labeled instances instead of using heuris- tically set confidence vector. In addition, we tend to find a more suitable sentence encoder rather than piece-wise CNN for our soft-label method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>&gt;Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of soft-label correction on Nationality relation. We intend to use syntactic/ semantic information of correctly labeled entity pairs (blue) to correct the false positive and false negative instances (orange) during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Precision/Recall curves of our model and previous state-of-the-art systems. Mintz (Mintz et al., 2009), MultiR (Hoffmann et al., 2011) and MIMLRE (Surdeanu et al., 2012) are feature-based models. ONE (Zeng et al., 2015) and ATT (Lin et al., 2016) are neural network models based on at-least-one assumption and selective attention, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>), MultiR (Hoffmann et al., 2011) and MIMLRE (Surdeanu et al., 2012) are feature-based models. PCNN-ONE (Zeng et al., 2015) and PCNN-ATT (Lin et al., 2016) are piecewise convolutional neural network (PCNN) models based on at-least-one assumption and se- lective attention, which are introduced in Section 2.2, respectively. All the results of compared mod- els come from the data reported in their papers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 2 )</head><label>2</label><figDesc>Even weaker baseline PCNN-ONE False positive: Place lived → Place of death Fernand nault , one of canada 's foremost dance figures , died in montreal on tuesday . False positive: Place lived → NA Alexandra pelosi, a daughter of representat- ive nancy pelosi · · · , and paul pelosi of san francisco, was married yesterday to · · ·. False Negative: NA → Nationality By spring the renowned chef Gordon Ram- say of England should be in hotels here. False Negative: NA → Work in · · ·, said Billy Ccox , a spokesman for the United States Department of Agriculture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Parameter settings of our experiments.</head><label>1</label><figDesc></figDesc><table>Settings 
One 
Two 
All 
P@N(%) 100 200 300 Avg 100 200 300 Avg 100 200 300 Avg 
ONE 73.3 64.8 56.8 65.0 70.3 67.2 63.1 66.9 72.3 69.7 64.1 68.7 
+soft-label 77.0 72.5 67.7 72.4 80.0 74.5 69.7 74.7 84.0 81.0 74.0 79.7 
ATT 73.3 69.2 60.8 67.8 77.2 71.6 66.1 71.6 76.2 73.1 67.4 72.2 
+soft-label 84.0 75.5 68.3 75.9 86.0 77.0 73.3 78.8 87.0 84.5 77.0 82.8 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their valu-able comments. This work is supported by the Na-</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<publisher>AcM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction with sentence-level attention and entity descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-02-04" />
			<biblScope unit="page" from="3060" to="3066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural relation extraction with selective attention over instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2124" to="2133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Modeling missing data in distant supervision for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="367" to="378" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Filling knowledge base gaps for distant supervision of relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (2)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="665" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction via piecewise convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
