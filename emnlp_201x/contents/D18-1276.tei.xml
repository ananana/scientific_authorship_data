<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Free as in Free Word Order: An Energy Based Model for Word Segmentation and Morphological Tagging in Sanskrit</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018. 2550</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrith</forename><surname>Krishna</surname></persName>
							<email>amrith@iitkgp.ac.in, bsantraigi@gmail.com, pawang@cse.iitkgp.ernet.in</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<orgName type="institution">IIT Kharagpur</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishal</forename><surname>Santra</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<orgName type="institution">IIT Kharagpur</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasi</forename><surname>Prasanth Bandaru</surname></persName>
							<affiliation key="aff1">
								<address>
									<settlement>Flipkart</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Sahu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishnu</forename><surname>Dutt Sharma</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">American Express India Pvt Ltd</orgName>
								<address>
									<addrLine>5 Chinmaya Vishwavidyapeeth</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavankumar</forename><surname>Satuluri</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawan</forename><surname>Goyal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<orgName type="institution">IIT Kharagpur</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Free as in Free Word Order: An Energy Based Model for Word Segmentation and Morphological Tagging in Sanskrit</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2550" to="2561"/>
							<date type="published">October 31-November 4, 2018. 2018. 2550</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The configurational information in sentences of a free word order language such as Sanskrit is of limited use. Thus, the context of the entire sentence will be desirable even for basic processing tasks such as word segmentation. We propose a structured prediction framework that jointly solves the word segmentation and morphological tagging tasks in Sanskrit. We build an energy based model where we adopt approaches generally employed in graph based parsing techniques (McDonald et al., 2005a; Carreras, 2007). Our model outperforms the state of the art with an F-Score of 96.92 (per-centage improvement of 7.06%) while using less than one tenth of the task-specific training data. We find that the use of a graph based approach instead of a traditional lattice-based sequential labelling approach leads to a percentage gain of 12.6% in F-Score for the segmen-tation task. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sanskrit, a morphologically-rich and a free word order language ( <ref type="bibr" target="#b31">Kulkarni et al., 2015)</ref>, poses a se- ries of challenges even for automation of basic processing tasks such as word segmentation. The recent surge in the digitisation efforts for archiv- ing the works ranging from the pre-classical to modern times <ref type="bibr">(Hellwig, 2010</ref><ref type="bibr" target="#b23">(Hellwig, -2016</ref>) has led to a growing demand for such tools ( <ref type="bibr" target="#b17">Goyal et al., 2012;</ref><ref type="bibr" target="#b25">Huet, 2006</ref>). We propose a structured prediction approach that jointly solves the word segmenta- tion and morphological tagging tasks for Sanskrit.</p><p>The computational problems arising from the mechanical treatment of Sanskrit fall somewhere * Work done while the authors were at IIT Kharagpur † Part of the work was done while the authors were at IIT Kharagpur <ref type="bibr">1</ref> The code and the pretrained edge vectors ( §3) used in this work are available at https://zenodo.org/record/ 1035413#. <ref type="bibr">W35s8hjhUUs</ref> between speech recognition and the analysis of written text <ref type="bibr" target="#b24">(Huet, 2005</ref>). For instance, consider <ref type="figure" target="#fig_0">Figure 1a</ref> which shows all the phonetically valid word splits for a Sanskrit poetic verse 2 . The writ- ten representation in Sanskrit is actually a phone- mic stream <ref type="bibr" target="#b24">(Huet, 2005</ref>). The constructions often undergo phonetic transformations at the juncture of successive words, similar to what one observes in connected speech <ref type="bibr" target="#b43">(Morris et al., 2004;</ref><ref type="bibr" target="#b53">Shieber and Tao, 2003)</ref>. These transformations obscure the word boundaries and often modify the phones at these word boundaries. In Sanskrit, these transfor- mations get reflected in writing as well. This is primarily due to the presence of an advanced dis- cipline of phonetics in Sanskrit which explicitly described euphonic assimilation as sandhi ( <ref type="bibr" target="#b16">Goyal and Huet, 2016)</ref>. For instance, words prefixed with numbers 14 and 15 in <ref type="figure" target="#fig_0">Figure 1a</ref> are valid candidates in spite of the phonetic differences they posses from that of the original sentence.</p><p>Sanskrit is rich with syncretisms (Crystal, 2011) and homonyms. For example, the surface form 'sat¯ ı', prefixed with numbers 6 and 10, are homonyms, while the root 'satya' generates iden- tical surface form for three different morphologi- cal classes leading to syncretism (1 to 3 in <ref type="figure" target="#fig_0">Figure  1a</ref>). Hence, in addition to segmentation, the mor- phological analysis of the segmented word forms will be critical for reducing the ambiguity in fur- ther downstream tasks such as syntactic analy- sis. The sentence construction in the language fol- lows weak non-projectivity <ref type="bibr" target="#b20">(Havelka, 2007)</ref> per- mitting the words to have a relatively free word order structure ( <ref type="bibr" target="#b31">Kulkarni et al., 2015</ref>). The lan- guage is all the more lenient for poetic construc- tions ( <ref type="bibr" target="#b50">Scharf et al., 2015;</ref><ref type="bibr" target="#b31">Kulkarni et al., 2015)</ref>, where arranging the words to adhere to metri- cal constraints is a bigger concern ( <ref type="bibr" target="#b41">Melnad et al., 2013)</ref>. Hence, the whole input context is desirable when making each prediction at the output ( <ref type="bibr" target="#b2">Bahdanau et al., 2015)</ref>, even for preliminary tasks such as segmentation in Sanskrit ( <ref type="bibr" target="#b48">Reddy et al., 2018)</ref>.</p><p>The word splits in <ref type="figure" target="#fig_0">Figure 1</ref> are based on the analysis by a lexicon driven analyser, Sanskrit Heritage Reader (SHR) 3 . A total of 1,056 combi- nations can be formed from the word splits, such that each of those combinations is a solution which covers the entire input. We call such a solution as an 'exhaustive segmentation'. Out task is to find an 'exhaustive segmentation', which is also semantically valid. <ref type="figure" target="#fig_0">Figure 1b</ref> shows the semanti- cally valid solution for the sentence.</p><p>We propose our structured prediction frame- work as an energy based model ( <ref type="bibr" target="#b35">LeCun et al., 2006</ref>). Considering the free word-orderness, mor- phological richness and the phenomena of Sandhi in Sanskrit, we adopt a graph based treatment for a given input sentence as shown in <ref type="figure">Figure 2</ref>. All the word splits, as predicted by SHR, are treated as the nodes in the graph. Every pair of nodes that can co-occur in at least one 'exhaustive segmenta- tion' 4 forms directed edges in both the directions. By construction, any subset of nodes that forms a maximal clique will be an 'exhaustive segmen- tation'. We formalise our task as the search for a maximal clique. The graph structure eliminates the sequential nature of the input, while the greedy maximal clique selection inference policy of ours can take the entire input context into considera- tion. We hypothesise that both of these will be beneficial for processing constructions in Sanskrit.</p><p>The major contributions of our work are:</p><p>1. We propose the first model that performs both word segmentation and morphological tagging for Sanskrit as suggested by <ref type="bibr" target="#b29">Krishna et al. (2017)</ref>; the combined task reports an F-Score of 90.45.</p><p>2. We obtain an F-Score of 96.92 for the word seg- mentation task, an improvement of 7.06% over the state of the art, a seq2seq model with atten- tion ( <ref type="bibr" target="#b48">Reddy et al., 2018</ref>).</p><p>3. We achieve the results with less than one-tenth of the training data that <ref type="bibr" target="#b48">Reddy et al. (2018)</ref> uses, a desirable outcome for a low resource language such as Sanskrit. The pre-training in the form of morphological constraints to form edge vectors enables this.</p><p>4. We propose a scheme that uses the Path Rank- ing Algorithm ( <ref type="bibr" target="#b33">Lao and Cohen, 2010)</ref> to auto- mate the feature selection and the feature vec- tor generation for the edges. This eliminates the need for manual feature engineering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Architecture</head><p>Given an input construction, we obtain our search space of possible word splits using SHR as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The search space represents all the possible exhaustive segmentations with possi- ble gaps and overlaps between the word splits in each of the exhaustive segmentation ( <ref type="bibr" target="#b30">Kudo, 2006;</ref><ref type="bibr" target="#b45">Oerder and Ney, 1993;</ref><ref type="bibr" target="#b62">Wolf and Woods, 1977)</ref>. <ref type="bibr">5</ref> In such a setting, representing the search space as a lattice <ref type="bibr" target="#b30">(Kudo, 2006;</ref><ref type="bibr" target="#b54">Smith et al., 2005</ref>) has been <ref type="figure">Figure 2</ref>: Architecture for the proposed model. Word- splits for 'satyamapriyam', a sub-sequence of the sen- tence in <ref type="figure" target="#fig_0">Figure 1a</ref> are considered here. The nodes are numbered from 1 to 10 and are marked with the same in <ref type="figure" target="#fig_0">Figure 1a</ref>. For simplicity, we assume that words in nodes 4 to 10 have only one morphological analysis each.</p><p>a popular approach for fusional languages <ref type="bibr" target="#b15">(Goldberg and Tsarfaty, 2008;</ref><ref type="bibr" target="#b9">Cohen and Smith, 2007;</ref><ref type="bibr" target="#b19">Hatori et al., 2012</ref>). In a lattice, there will be edges only between the adjacent word splits of an ex- haustive segmentation. We deviate from this norm in a minor yet fundamental way. In the search space, we choose to add edges between every pair of word splits that are part of a single exhaustive segmentation. Henceforth, we will refer this struc- ture as the sentence graph G. We then employ our minimum cost maximal clique finding energy based model on the sentence graph G. <ref type="figure">Figure 2</ref> shows the proposed architecture of the model. It shows the sentence graph G for 'satyamapriyam', a sub-sequence of the sentence in <ref type="figure" target="#fig_0">Figure 1a</ref>.</p><p>Our current design choice results in a denser graph structure as input and a computationally ex- pensive inference. Such a choice requires justifi- cation. Currently, there exist digitised versions of texts which spans over a period of 3000 years cat- egorised into pre-classical literature (1500 BCE - 100 BCE), classical literature (300 CE -800 CE) and modern literature (900 CE to now). <ref type="bibr" target="#b21">Hellwig (2009)</ref> assert that the assumption that Sanskrit syntax has remained unchanged over an interval of over 3000 years is not valid. <ref type="bibr" target="#b31">Kulkarni et al. (2015)</ref> notes that the constructions in prose gener- ally follow weak non-projectivity <ref type="bibr" target="#b20">(Havelka, 2007;</ref><ref type="bibr" target="#b38">Maier and Lichte, 2011</ref>). <ref type="bibr" target="#b31">Kulkarni et al. (2015)</ref> also observes that constructions in verses violate weak non-projectivity especially with the adjecti- val and genitive relations. A large number of texts are written in verses or to complicate things fur- ther, they are written as a combination of prose and verse. A lack of consensus among the ex- perts on a common set of rules for works across the different time spans, and the enormous effort in categorising constructions based on their writ- ing styles, motivated us to use this graph construc- tion scheme which is agnostic to word order.</p><p>Graph Formation: 6 In <ref type="figure" target="#fig_0">Figure 1a</ref>, identical surface-forms with the same root are grouped to- gether and displayed as a single entity. But we consider, every unique combination of root, mor- phological class and the word position in SHR as a separate node in G(V, E). Hence the surface- from satyam, appears as 6 separate nodes num- bered from 1-3 and 11-13 in <ref type="figure" target="#fig_0">Figure 1a</ref>. Here the nodes 1-3 differ from each other in terms of their morphological classes. The nodes 1 and 11 dif- fer only in terms of their position owing to its re- peated occurrence in the input. The position in- formation is opaque to our proposed system and is used only in forming the nodes for the sentence graph. During the inference, we consider all the pairwise potentials as contexts for each of the pre- diction made in the search space. The edges in our model should capture the likeliness of two nodes to co-occur in the final solution. Hence, every pair of nodes that can co-occur in an 'exhaustive seg- mentation' forms two directed edges, one each at either of the directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Energy Based Model (EBM) Architecture:</head><p>Our approach is inspired from the graph based parsing approaches employed generally for depen- dency parsing <ref type="bibr" target="#b40">(McDonald et al., 2005b;</ref><ref type="bibr" target="#b8">Carreras, 2007)</ref> and follows a likewise structured prediction paradigm ( <ref type="bibr" target="#b59">Taskar et al., 2005</ref>). Specifically, we use an EBM where we model our joint task as search for a maximal clique with minimum en- ergy. Learning consists of finding an energy func- tion that associates lower energies to cliques with increasing similarity to the correct clique. The cor- rect clique configuration will have the lowest en- ergy ( <ref type="bibr" target="#b35">LeCun et al., 2006</ref>). The inference policy, a maximal clique selection algorithm, is used to make the predictions.</p><p>We follow an approach similar to the arc- factored approaches in graphs ( <ref type="bibr" target="#b40">McDonald et al., 2005b;</ref><ref type="bibr" target="#b8">Carreras, 2007)</ref>, where the total energy of a maximal clique,</p><formula xml:id="formula_0">T i = (V T i , E T i )</formula><p>, is de- composed as the summation of energies of its edges <ref type="bibr" target="#b26">(Ishikawa, 2011)</ref>.</p><formula xml:id="formula_1">S(T i ) = epq∈E T i S( e pq )</formula><p>where, V T i ⊆ V, E T i ⊆ E. The edges are fea- turised. For an edge e pq ∈ E, the features are rep- resented as a vector, denoted by e pq . For a given edge, the energy function, S(·) : [0, ∞) | e| → (−∞, ∞), takes the edge feature vector and pro- duces a scalar value as the energy assignment.</p><p>Loss Function and Training: We use Hinge Loss ( <ref type="bibr" target="#b0">Altun et al., 2003;</ref><ref type="bibr" target="#b60">Taskar et al., 2003</ref>) as our loss function. The hinge loss is formulated such that it increasingly penalises those cliques, sam- pled by our inference algorithm, with increasingly more number of wrong segmentation candidates. We minimise the hinge loss L which is defined as</p><formula xml:id="formula_2">L = max(0, S(T GT ) − argmin T i ∈A Q (S(T i ) − ∆(T i ))</formula><p>Here, A Q denotes the set of all the unique maxi- mal cliques and T GT denotes the maximal clique corresponding to the ground truth.</p><formula xml:id="formula_3">The margin ∆(T i ) is defined as ∆(T i ) = |V T i − V GT | 2 .</formula><p>We minimise the given loss function using gradient descent method. The network parameters are updated per sentence using back-propagation. The hinge loss function is not differentiable at the origin. Hence, we use the subgradient method to update the network parameters ( <ref type="bibr" target="#b55">Socher et al., 2010;</ref><ref type="bibr" target="#b47">Ratliff et al., 2007</ref>). We use a multi-layer perceptron network with a single hidden layer and a leaky ReLU activation function at the hidden layer for the training.</p><p>Inference Policy: For the maximal clique selec- tion, we use a greedy heuristic approach inspired from Prim's algorithm <ref type="bibr" target="#b46">(Prim, 1957)</ref>. The policy is described in Algorithm 1.</p><p>In Algorithm 1, we start the clique selection with a single node. At any given instance, we loop through the nodes in the graph which are not yet part of the clique. We add a vertex v to the clique if the cumulative score of all the edges from v to every vertex that is already in the clique is the min- imum. We discard all the nodes which are conflict- ing with vertex v. "Conflicting" nodes are any pair of nodes which are not connected by an edge be- tween them. This follows from the construction of the graph G, as the non-connectivity between the nodes implies that they are proposed as alternative Algorithm 1: Greedy maximal clique se- lection heuristic</p><formula xml:id="formula_4">1 for each node v i in V do 2 Initialize a graph K i (V K i , E K i ) with K i = G such that V K i = V and E K i = E.</formula><p>Initialise a vertex set V T i with v i as the only element in it. Remove all the vertices which are conflicting with v i from K i .</p><formula xml:id="formula_5">3 Add the vertex v j ∈ (V K i − V T i ) to V T i ,</formula><p>such that in K i , the sum of edge weights for the edges starting from v j to all other vertices in V T i is minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>Remove all the vertexes which are conflicting with v j from V K i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5</head><p>Repeat steps 3 -4 till</p><formula xml:id="formula_6">V K i − V T i = ∅ 6 end</formula><p>word suggestions in G. As guaranteed by our sen- tence graph construction, we obtain the maximal clique (exhaustive segmentation) when there exist no more vertices to loop through. We perform this for every node in the graph G. From all the cliques so obtained we select the maximal clique with the least score. The approach does not guarantee enu- meration of all the cliques, but it is guaranteed that every node will be covered by at least one maxi- mal clique. The heuristic can be seen as a means of sampling some potential minimum energy max- imal cliques for the learning task. Energy based models do not require proper normalisation of the solution space ( <ref type="bibr" target="#b35">LeCun et al., 2006</ref>), a choice that enables the use of the heuristic. During inference, the greedy clique selection heuristic is performed for every node in G. Though the run-time for this inference is poly- nomial, it can still be computationally expensive. But, in practice we find that our inference proce- dure results in faster output for graphs with &gt; 19 nodes in comparison to the exponential time Bron- Kerbosch algorithm ( <ref type="bibr" target="#b61">Tomita et al., 2006;</ref><ref type="bibr" target="#b7">Bron and Kerbosch, 1973</ref>) for clique enumeration <ref type="bibr" target="#b39">(McDonald et al., 2005a</ref>). We further improve the run time of our inference procedure by paralleling the clique selection procedure for each node on a sep- arate thread.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Feature Generation for the Edges</head><p>Given two non-conflicting nodes in G, there exists a pair of directed edges, one each in either direc-tion. For every edge in the sentence graph G, we need to generate features that capture the distri- butional information between the candidate nodes that the edge connects. Similar in spirit to <ref type="bibr" target="#b5">Bilmes and Kirchhoff (2003)</ref> and <ref type="bibr" target="#b28">Krishna et al. (2016)</ref>, we condition the distributional information based on different morphological constraints to enrich the context. The distributional information is obtained from a morphologically tagged corpus C. Let V w , V m and V r be the vocabulary of the inflected word forms, morphological classes and the roots respec- tively in the corpus. Let V = V w ∪ V m ∪ V r . For each n i , n j ∈ V, the conditional probability is calculated as P co (n j |n i ) = count(n j ,n i ) count(n i ) . Here count(·) represents the count of co-occurrence be- tween the entries in the corpus. Also, let M C be the set of morphological constraints used for con- ditioning the distributional information. Now, for each n i , n j ∈ V and each g k ∈ M C, we can ob- tain the feature value as follows:</p><formula xml:id="formula_7">P g k (n j |n i ) = −log(P co (n j |g k ) × P co (g k |n i ))</formula><p>We use the following scheme for feature gener- ation. A node in G essentially contains three at- tributes, namely, the root, the morphological class and the inflected word form. A feature uses corpus evidence of exactly one of the three attributes. For instance, consider two candidate nodes o 1 , o 2 in G with (o 1w , o 1m , o 1r ) and (o 2w , o 2m , o 2r ) as the respective 3-tuple attributes. Now, one such possi- ble feature value for the edge from o 1 to o 2 can be calculated as P g 1 (o 1r |o 2w ) where g 1 ∈ M C and o 1r , o 2w ∈ V. Hence, features for a directed edge connecting two different nodes in G can be gener- ated in 3 × |M C|×3 ways.</p><p>We automate the process of feature generation and feature selection using the framework of Path Ranking Algorithm ( <ref type="bibr" target="#b33">Lao and Cohen, 2010)</ref>. For- malising our approach using PRA leads to an effi- cient and scalable implementation of our scheme. In PRA, enumerating and generating all the possi- ble features needs to be performed only for a sam- pled set of data pairs from the corpus. By using a supervised feature selection approach, a relevant sub-set of features is filtered. This is a one-time process <ref type="bibr" target="#b14">(Gardner and Mitchell, 2015)</ref>. During in- ference, the feature values are computed only for the filtered features. <ref type="bibr">7</ref> Morphological Constraints: M C is defined as the set of grammatical category combinations, each combination falling into one of the follow- ing two descriptions. a) Complete combination, i.e., a morphological class -In Sanskrit, similar to Czech ( <ref type="bibr" target="#b54">Smith et al., 2005</ref>), a morphological class represents a certain combination of grammatical categories. For instance, a noun is represented by case, gender and number. Hence, the combination 'genitive-masculine-singular' forms a morpholog- ical class. b) Partial combination -A combina- tion of grammatical categories, which can form a morphological class by adding one or more cate- gories to it. For instance, 'genitive-masculine' is a partial combination that denotes all the possible (three) morphological classes which differ from each other only in terms of the category 'number'. However, 'genitive-present tense' is not a 'valid' combination as it can never form a valid morpho- logical class. The evidence for a partial combi- nation in the corpus C can be obtained by sum- ming the evidence of all the morphological classes which it denotes. We obtain a total of 528 morpho- logical constraints. A filtered set of 1500 features (out of 4752) is used in our model. Mutual Infor- mation Regression ( <ref type="bibr" target="#b27">Kraskov et al., 2004</ref>) with the word to word co-occurrence probability as label is used for feature selection. <ref type="bibr">8</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Dataset: We use the Digital Corpus of Sanskrit (DCS) <ref type="bibr">(Hellwig, 2010</ref><ref type="bibr" target="#b23">(Hellwig, -2016</ref>, a morphologically tagged corpus of Sanskrit, for all our experiments. DCS contains digitised works from periods that span over 3000 years and contain constructions written in prose or poetry. Identifying sentence boundaries in Sanskrit constructions is a chal- lenge of its own <ref type="bibr" target="#b23">(Hellwig, 2016)</ref>. DCS currently has split the corpus into more than 560,000 text lines, all of which need not be following explicit sentence boundaries. <ref type="bibr" target="#b28">Krishna et al. (2016)</ref> iden- tify 350,000 constructions from the DCS fit for the segmentation task. They use a separate set of 9,577 constructions from the DCS, called as 'DCS10k', and use it as the test set. They ig- nore the remaining text lines from DCS due to am- biguities either in the provided tagging or align- ment with SHR ( <ref type="bibr" target="#b29">Krishna et al., 2017)</ref>. We use the 350,000 constructions used in <ref type="bibr" target="#b28">Krishna et al. (2016)</ref> as the corpus C ( §3) for the generation of our edge vectors. 'DCS10k' was neither used in the training of our model, nor in the generation of edge vectors. <ref type="bibr" target="#b48">Reddy et al. (2018)</ref> report their results on a subset of DCS10k containing 4,200 sentences, which we will refer to as 'DCS4k'.</p><p>We experiment with the following systems: SupervisedPCRW: Proposed in <ref type="bibr" target="#b28">Krishna et al. (2016)</ref>, this model also uses the graph output from SHR. Using PCRW ( <ref type="bibr" target="#b33">Lao and Cohen, 2010;</ref><ref type="bibr" target="#b42">Meng et al., 2015)</ref>, feature vectors for edges are generated using hand-crafted morphological con- straints. Starting with the longest word in the graph, the prediction is performed by greedily se- lecting the candidates as per the edge weights. EdgeGraphCRF: This is a second order CRF <ref type="bibr">Model (Müller and Behnke, 2014;</ref><ref type="bibr" target="#b26">Ishikawa, 2011)</ref> which uses the sentence graph structure G as the input to the system. Every node is represented with fastText ( <ref type="bibr" target="#b6">Bojanowski et al., 2017</ref>) word em- beddings trained under default settings. The edges are featurised with the PRA vectors ( §3). We used 1-slack structured SVM for training. For the bi- nary class problem, QPBO <ref type="bibr" target="#b49">(Rother et al., 2007)</ref> inference approach provided the best results. <ref type="bibr">Seq2Seq -Reddy et al. (2018)</ref> uses an Encoder- Decoder framework with LSTM cells for the seg- mentation task. We consider two models from the work, namely, 'segSeq2Seq' and 'attnSegSeq2seq' as our baselines. The later which uses attention ( <ref type="bibr" target="#b2">Bahdanau et al., 2015</ref>) is the current state of the art in Sanskrit word segmentation. Lattice-EBM: An energy based sequence la- belling model, where the input is a lattice <ref type="bibr" target="#b62">(Wolf and Woods, 1977)</ref> similar to that of <ref type="bibr" target="#b30">Kudo (2006)</ref>. The model can be seen as a special case of Graph Transformer Networks ( <ref type="bibr" target="#b34">LeCun et al., 1998</ref><ref type="bibr" target="#b36">LeCun et al., , 2007</ref>). In the lattice structure, the candidate links only to its adjacent nodes in an exhaustive segmenta- tion. We also generate edge vectors for the dummy nodes that act as the start and end markers in the lattice. During prediction, we have to find the best path from the lattice which minimises the sentence score. Here, we consider two variants of Lattice- EBM. L-EBM-Vanilla uses the discriminative for- ward training approach <ref type="bibr" target="#b10">(Collobert et al., 2011</ref>) with the standard hinge loss. The second vari- ant L-EBM-Beam, uses multi-margin loss <ref type="bibr" target="#b13">(Edunov et al., 2018)</ref>, instead of the hinge loss. Here, we employ beam search to generate multiple candi- dates as required by the loss.</p><p>Tree-EBM: The baseline model works exactly the same as the proposed model where the only differ- ence between both is in the inference algorithm used. Tree-EBM has an inference that searches for a Steiner Tree <ref type="bibr" target="#b58">(Takahashi, 1980)</ref> from the input graph G(V, E), the structure of which is described in §2. <ref type="bibr">9</ref> The inference procedure outputs a span- ning tree that covers a subset of the nodes from G. This raises a challenge while estimating the loss as, unlike in the case of a clique, there can be mul- tiple rooted tress that spans the subset of nodes in the ground truth. In this model, we augment the loss L tree such that the Steiner tree with the least energy that spans the nodes in ground truth is cho- sen.</p><formula xml:id="formula_8">L tree = max(0, argmin Tm∈A G S(T m ) − argmin T i ∈A Q (S(T i ) − ∆(T i ))</formula><p>Here A G represents set of all the trees that spans the nodes in the ground truth. Clique-EBM: The proposed model. The EBM model uses the maximal clique selection heuristic for the inference. Tasks and Evaluation Measures: We use the macro-averaged Precision (P), Recall (R), F1- score (F) and also the percentage of sentences with perfect matching (PM) as our evaluation metrics. We evaluate the competing systems on the follow- ing two different tasks.</p><p>Word Prediction Task (WPT) -The word seg- mentation task is evaluated based on the correct- ness of the inflected word forms predicted. This was used in <ref type="bibr" target="#b28">Krishna et al. (2016)</ref>.</p><p>Word++ Prediction Task (WP3T) -This is a stricter metric for the evaluation of the joint task of segmentation and morphological tag prediction. It evaluates the correctness of each of the inflected word form, lemma and its morphological tag.  <ref type="table" target="#tab_0">Table 1</ref>.B: WP3T on DCS10k <ref type="table" target="#tab_0">Table 1</ref>: Performance evaluation of the competing sys- tems in ascending order of their F-Score. improvement of 7.06% and 40.79% in terms of F- score and perfect matching from the current state of the art (System 6) in WPT. Currently there ex- ists no system that predicts the morphological tags for a given word in Sanskrit. For WP3T, Clique- EBM has shown a percentage increase of 11.64% and 69.65% in F-Score and the perfect matching score from Tree-EBM, the next best system. All the systems except 1 and 6 in <ref type="table" target="#tab_0">Table 1</ref>.A use the linguistically refined output from SHR as their search space to predict the final solution. Out of which 3, 4, 5, 7 and 8 use the edge vectors, which encodes the morphological constraints refined us- ing PRA ( <ref type="bibr" target="#b33">Lao and Cohen, 2010)</ref>, generated by the method discussed in §3. As a result these systems require &lt;10% training data than required by sys- tem 6. System 3 was trained on 10,000 sentences, while systems 4 and 5 were trained on 9,000 sen- tences after which the models got saturated. Sys- tems 7 and 8 were trained on 8,200 sentences which is 7.66% of the training data (107,000) used in System 6. In terms of training time, <ref type="bibr" target="#b48">Reddy et al. (2018)</ref> reports a training time of 12 hours on a GPU machine, while systems 7 and 8 take a train- ing time of 8 hours on an Intel Xeon CPU based machine with 24 cores and 256 GB RAM. <ref type="bibr">10</ref> For systems 4 and 5 it takes roughly 4 hours to train on the same machine. There was no training involved for the prediction of segmentations in system 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results</head><p>In systems 4 and 5, the inference is performed <ref type="bibr">10</ref> Please refer §4 of the supplementary for wall time anal- ysis. System 6, when trained on this CPU based system, did not converge even after 15 hours of training. sequentially from left to right 11 . The use of beam search with multi margin in System 5 resulted in marginal improvements (&lt;2) in terms of F-Score to that of system 4. Further, the improvement in the results saturated after a beam size of 128. Sys- tem 3 being a second order CRF model <ref type="bibr" target="#b26">(Ishikawa, 2011)</ref>, does not take the entire sentence context into account. In fact, about 85.16% of the sen- tences predicted by the model from DCS10K do not correspond to an 'exhaustive segmentation'. Prediction of an 'exhaustive segmentation' is guar- anteed in all our EBM models 4, 5, 7 and 8 (also in system 2) by virtue of the inference procedure we use. Both systems 7 and 8, along with System 6 which uses attention, consider the entire input context when making each prediction. System 8 considers all the pairwise potentials between the nodes while making a prediction, but System 7 does not (Steiner tree vs. maximal clique). <ref type="figure" target="#fig_1">Figure 3</ref> reports the performance of the systems 2, 5, 6 and 8 where the sentences in DCS4k <ref type="bibr">12</ref> are categorised based on the number of words presented in the segmented ground-truth solution. Our proposed system Clique-EBM performs the best across all the lengths with an exception to- wards shorter constructions of 2 words or less. In- terestingly, both the sequential models (systems 5 and 6) show a decreasing trend as the number of words increases, while the Clique-EBM model shows an increasing trend with a larger length, which might indicate that more context helps the model. In fact, the greedy yet non-sequential ap- proach used in <ref type="bibr" target="#b28">Krishna et al. (2016)</ref> outperforms both the sequential models at longer lengths. The average length of a sentence in DCS is 6.7 <ref type="bibr" target="#b28">(Krishna et al., 2016)</ref>, the share of sentences with seven or more words is 62.78%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fine Grained Analysis on Clique-EBM 13</head><p>Pruning the edges in sentence graph G: Constructions in Sanskrit follow weak non- projectivity (with exception to verses), imply- ing that they adhere to the principle of proxim- ity ( <ref type="bibr" target="#b31">Kulkarni et al., 2015)</ref>. By proximity we expect that the words in a phrase go together, without be- ing interrupted by a syntactically unrelated word. But the relative ordering between the phrases in a construction and the order of words within a phrase can be free. For any two words appearing in an exhaustive segmentation, we keep an edge only if both the words overlap within a distance of k characters. We experiment with k = 5, 10, 15 and 20. Hence, for K = 20, a word will form edges with all the words that fall within 20 characters to left and 20 characters to right. The average length of an in- put sequence in DCS10K is 40.79 characters. We do not modify our inference procedure in system 8 other than to take care of the possibility that a clique need not always be returned. <ref type="table" target="#tab_2">Table 2</ref> shows the results for different values of k. Interestingly, the results show a monotonic increase with the increase in context window, and the results with the entire context are still better than those with k = 20, even though only marginally. It is inter- esting to note that, keeping the entire context does not adversely affect the predictions as none of the pruned models outperforms System 8.</p><p>The lattice structure can be seen as an extreme case of pruning. We modify System 4 to use a non-sequential inference procedure, adapted from System 7. Here, the start and end markers were re- moved. Additionally, a given connected node pair has 2 edges, each in either of the directions. We find that the model gives an F-Score of 87.4 which outperforms System 4 by more than three points.</p><p>Out of Vocabulary words: As described in §3, the distributional information from DCS is used as the corpus C for the feature generation. For the case of OOV in roots (V r ), we use add-1 smooth- ing. But, for the case of OOV in inflections (V w ) we find that using the evidence from correspond- ing root of the candidate is beneficial. DCS10k has 8,007 roots of which 514 are OOV and 833 occur   <ref type="table">Table 3</ref>: System performance on the coarse level POS for the competing systems Clique-EBM (C-EBM) and Tree-EBM (T-EBM) only 1 to 5 times. The micro-averaged F-Score for these are 57.98 and 72.87, respectively.</p><p>Morphological class specific assessment : Ta- ble 3 presents the micro-averaged recall for the words grouped based on their parts of speech (POS) for Clique-EBM and Tree-EBM. Both the systems follow similar trends and the morphologi- cal class misprediction is highest among the nouns and compounds (WP3T Recall). It also needs to be noted that the improvement made by Clique-EBM in comparison to Tree-EBM for WP3T was also on prediction of noun and compound morphological classes. Also in Tree-EBM, the mispredictions in compounds were mostly cases of the system get- ting the compound components confused to one of the morphological classes in nouns. We find that considering the pairwise potential between all the words in a sentence in Clique- EBM led to improved morphological agreement between the words in comparison to Tree-EBM. In Tree-EBM, the top 5 cases of mispredictions from one morphological class to a particular wrong class were between those classes of nouns that dif- fered in exactly one of the three possible grammat- ical categories, namely gender, number or declen- sion, that makes up a noun. In Clique-EBM such patterns were not anymore present and more im- portantly the skewedness in such mispredictions were considerably reduced. <ref type="bibr">14</ref> Summarily, our non-sequential method of infer- ence results in better performance in comparison to the sequential models. We also find that the se- quential models see a drop in their performances when the number of words in a sentence increases. Leveraging the pairwise potentials between every connected nodes while making a prediction im- proves the performance. The performance gain of Clique-EBM over Tree-EBM illustrates the effec- tiveness of this approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In Sanskrit, syncretism (Crystal, 2011) leads to ambiguity during morphological analysis. It can further be observed that such common root iden- tical surface forms often have one or more com- mon grammatical categories in their morpholog- ical classes <ref type="bibr" target="#b16">(Goyal and Huet, 2016)</ref>. We find that the first three models in <ref type="table" target="#tab_0">Table 1</ref>.B often end up predicting an identical surface-form with an incorrect morphological tag, thus affecting the WP3T scores. <ref type="bibr">15</ref> . The grammatical categories in a morphological class are indicative of the syn- tactic roles and the morphological agreement be- tween the words in a construction. We empirically observe that the inference procedure for clique- EBM, which considers the entire input context and pairwise potentials between the candidates, helps in improving the performance of the model. A similar observation regarding incompatible mor- phological agreements between predicted words was made by <ref type="bibr" target="#b18">Hassan et al. (2018)</ref> for their NMT model. The authors introduced an elaborate 2 phase decoder and a KL-Divergence based regu- larisation to combat the issue.</p><p>The energy based model (EBM) we propose is a general framework for structured prediction in Sanskrit. EBMs are widely used for various struc- tured prediction tasks ( <ref type="bibr" target="#b36">LeCun et al., 2007;</ref><ref type="bibr" target="#b4">Belanger and McCallum, 2016)</ref>. <ref type="bibr" target="#b3">Belanger (2017)</ref> states that, "CRFs are typically attributed to <ref type="bibr" target="#b32">Lafferty et al. (2001)</ref>, but many of the core techni- cal contributions of the paper appeared earlier in <ref type="bibr" target="#b34">LeCun et al. (1998)</ref>." GTNs ( <ref type="bibr" target="#b34">LeCun et al., 1998)</ref>, in fact, work on a graph based input very simi- lar to that of a lattice, a variant of which we use in L-EBM-Vanilla. For dependency parsing, use of a word-level lattice structure similar to Seeker and C ¸ etino˘ glu <ref type="bibr">(2015)</ref>, where all the homonyms and syncertisms of a given surface-form form a lattice, will potentially result in a reduced candi- date space than ours. Additionally, our model cur- 15 Details in §4 of the Supplementary material rently does not take into account the phrasal na- ture of compounds in Sanskrit <ref type="bibr" target="#b37">(Lowe, 2015)</ref>. This can further reduce the edge density in our current graph construction. But, this needs further explo- ration, as current edge vectors may not be suitable for the task. To generate the possible candidates, we rely completely on the SHR. In case of words not recognised by the lexicon driven SHR, analy- sis of sentences with a partially recognised portion is still possible. Once a root is added, all its inflec- tions can be generated by the SHR automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We proposed a novel approach to tackle word seg- mentation and morphological tagging problem in Sanskrit. Our model outperforms <ref type="bibr" target="#b48">Reddy et al. (2018)</ref>, the current state of the art, with an F- Score of 96.92. <ref type="bibr" target="#b48">Reddy et al. (2018)</ref> report that the extension of their model to perform morphologi- cal tagging is not straightforward, as they learn a new sub-word vocabulary using the sentencepiece model ( <ref type="bibr" target="#b51">Schuster and Nakajima, 2012</ref>).</p><p>The free word order nature of the language mo- tivated us to consider the input to be a graph so as to avoid the sequential processing of input. For the EBM we use, there is no requirement of proper normalisation ( <ref type="bibr" target="#b35">LeCun et al., 2006</ref>). We benefit from this as we perform a search in the space of complete outputs and there is a combinatorial ex- plosion in the output space for a linear increase in the input space ( <ref type="bibr" target="#b12">Doppa et al., 2014</ref>). The pre- training of the edge vectors with external knowl- edge in the form of morphological constraints is effective in reducing the task specific training size ( <ref type="bibr" target="#b63">Yang et al., 2017;</ref><ref type="bibr" target="#b1">Andor et al., 2016</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: a) All the phonetically valid segmentations (link) for 'satyam. br¯ uy¯ atpriyam. br¯ uy¯ annabr¯ uy¯ atsatyamapriyam. priyam. can¯ anr. tambr¯ uy¯ ades. adharmah. san¯ atanah. ' from (subh¯ as. itam) as output by Sanskrit Heritage Reader (SHR) and b) correct segmentation selected from the candidate space.</figDesc><graphic url="image-1.png" coords="2,72.00,62.81,453.54,125.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance of the competing systems for DCS4k grouped on the word counts in the ground-truth</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 provides</head><label>1</label><figDesc>the results for the best performing configurations for each of the systems. The results for WPT on DCS4k and WP3T on DCS10k for each of the systems are shown in Tables 1.A and 1.B. The proposed model, Clique-EBM (System 8), outperforms all the other models across all the 4 metrics on both the tasks. Clique-EBM shows an 9 The inference procedure is given in §2 of the supplemen- tary material</figDesc><table>No: 
System 
P 
R 
F 
PM 
1 
segSeq2Seq 
73.44 73.04 73.24 
29.2 
2 
SupervisedPCRW 76.30 79.47 77.85 38.64 
3 
EdgeGraphCRF 
79.27 
81.6 
80.42 35.91 
4 
L-EBM-Vanilla 
86.38 85.49 84.29 53.62 
5 
L-EBM-Beam 
86.38 85.77 86.07 60.32 
6 
AttnsegSeq2Seq 
90.77 
90.3 
90.53 55.99 
7 
Tree-EBM 
89.44 92.35 90.87 61.72 
8 
Clique-EBM 
96.18 97.67 96.92 78.83 

Table 1.A: WPT on DCS4k 

System 
P 
R 
F 
PM 
EdgeGraphCRF 
76.69 78.74 
77.7 
31.82 
LatticeEBM-Vanilla 76.88 74.76 
75.8 
27.49 
LatticeEBM-Beam 
79.41 77.98 78.69 31.57 
Tree-EBM 
82.35 79.74 81.02 32.88 
Clique-EBM 
91.35 89.57 90.45 55.78 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Performance of Clique-EBM with pruned edges in G.</head><label>2</label><figDesc></figDesc><table>Type 
WPT Recall 
WP3T Recall 
T-EBM C-EBM T-EBM C-EBM 
Noun 
93.06 
96.87 
86.14 
89.0 
Verb 
89.14 
95.91 
87.38 
94.42 
Compound 
89.35 
93.52 
86.01 
91.07 
Indeclinable 95.07 
97.09 
94.93 
96.47 

</table></figure>

			<note place="foot" n="2"> A saying from subh¯ as. itam text: One should tell the truth, one should say kind words; one should neither tell harsh truths, nor flattering lies; this is a rule for all times.</note>

			<note place="foot" n="3"> Available at http://sanskrit.inria.fr/, SHR is a lexicondriven segmenter which produces all the valid word splits. An interface is provided for manual selection of a solution (Goyal and Huet, 2016) 4 For instance, segments 6 and 7 in Figure 1a are connected, while 6 and 9 are not.</note>

			<note place="foot" n="5"> The word splits in an exhaustive segmentation often overlap and sometimes leave gaps by virtue of Sandhi. For examples, please refer the §1 supplementary material.</note>

			<note place="foot" n="6"> Our graph construction approach is explained using finite state methods in §1 of the supplementary material</note>

			<note place="foot" n="7"> The edge vector formation is explained in terms of Metapaths (Sun, 2010) in §3 of the Supplementary.</note>

			<note place="foot" n="8"> For different settings we experimented with, for the vector generation, refer to §4 of the supplementary material.</note>

			<note place="foot" n="11"> We also tried reversing the input effectively enabling the right to left direction but the results were worse than the reported system by an F-Score of 3. 12 sentences with length more than 12 words are not shown as such sentences appear less than 10 times in DCS4k. 13 For hyper-parameter settings, and other fine-grained analysis refer to §4 of the supplementary material.</note>

			<note place="foot" n="14"> Please refer to Tables 6 and 7 in the supplementary material for details</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are grateful to Oliver Hellwig for providing the DCS Corpus and Gérard Huet for providing the Sanskrit Heritage Engine, to be installed at local systems. We extend our gratitude to Amba Kulka-rni and Rogers Mathew, along with Gérard for helpful comments and discussions regarding the work. We thank the anonymous reviewers for their constructive and helpful comments, which greatly improved the paper. We are indebted to Unni Kr-ishnan T A for his contributions towards imple-mentation of the framework.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Investigating loss functions and optimization methods for discriminative learning of label sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasemin</forename><surname>Altun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2003 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Globally normalized transition-based neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Andor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Presta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2442" to="2452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Conference on Learning Representation (ICLR)</title>
		<meeting>the Third International Conference on Learning Representation (ICLR)<address><addrLine>San Diego, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deep Energy-Based Models for Structured Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts Amherst</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Structured prediction energy networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning<address><addrLine>New York, New York, USA. PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="983" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Factored language models and generalized parallel backoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><forename type="middle">A</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Volume of the Proceedings of HLTNAACL 2003-Short Papers</title>
		<meeting><address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Algorithm 457: finding all cliques of an undirected graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Coen</forename><surname>Bron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joep</forename><surname>Kerbosch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="575" to="577" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Experiments with a higherorder projective dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="957" to="961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint morphological and syntactic disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="208" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A dictionary of linguistics and phonetics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crystal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Hc-search: a learning framework for search-based structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janardhan</forename><surname>Rao Doppa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasad</forename><surname>Tadepalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="369" to="407" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Classical structured prediction losses for sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
	<note>Long Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient and expressive knowledge base completion using subgraph feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1488" to="1498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A single generative model for joint morphological segmentation and syntactic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="371" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Design and analysis of a lean interface for sanskrit corpus annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawan</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Huet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language Modelling</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="182" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A distributed platform for sanskrit processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawan</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gérard</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amba</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Scharf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Bunker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1011" to="1028" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Achieving human parity on automatic chinese to english news translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Aue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Chowdhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05567</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Incremental joint approach to word segmentation, pos tagging, and dependency parsing in chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Hatori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju Island</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1045" to="1053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Beyond projectivity: Multilingual evaluation of constraints and measures on nonprojective structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Havelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="608" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Extracting dependency trees from sanskrit texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Hellwig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sanskrit Computational Linguistics</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="106" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">DCS-The Digital Corpus of Sanskrit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Hellwig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Detecting sentence boundaries in sanskrit texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Hellwig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="288" to="297" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A functional toolkit for morphological and phonological processing, application to a Sanskrit tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gérard</forename><surname>Huet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Functional Programming</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="573" to="614" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Themes and Tasks in Old and Middle Indo-Aryan Linguistics, chapter Lexicondirected Segmentation and Tagging of Sanskrit. Motilal Banarsidass</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gérard</forename><surname>Huet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>Delhi</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Transformation of general binary mrf minimization to the first-order case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Ishikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1234" to="1249" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Estimating mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kraskov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><surname>Stögbauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Grassberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">66138</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Word segmentation in sanskrit using path constrained random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrith</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishal</forename><surname>Santra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavankumar</forename><surname>Satuluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanth</forename><surname>Sasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhumi</forename><surname>Bandaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuvendra</forename><surname>Faldu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawan</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="494" to="504" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A dataset for sanskrit word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrith</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><surname>Kumar Satuluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawan</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</title>
		<meeting>the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Mecab: Yet another part-of-speech and morphological analyzer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<ptr target="http://mecab.source-forge.jp" />
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">How Free is free Word Order in Sanskrit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amba</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavankumar</forename><surname>Satuluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devanand</forename><surname>Shukl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Sanskrit Library</title>
		<meeting><address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="269" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML &apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML &apos;01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Relational retrieval using a combination of path-constrained random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="67" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A tutorial on energy-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Jie</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Predicting Structured Data</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Energy-based models in document recognition and computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Jie</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Document Analysis and Recognition (ICDAR)</title>
		<meeting>International Conference on Document Analysis and Recognition (ICDAR)<address><addrLine>Curitiba, Paraná, Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="337" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The syntax of sanskrit compounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">J</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Historical Syntax</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="71" to="115" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Characterizing discontinuity in constituent treebanks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timm</forename><surname>Lichte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Formal Grammar</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="167" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Simple algorithms for complex relation extraction with applications to biomedical ie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Kulick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Winters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pete</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="491" to="498" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Non-projective dependency parsing using spanning tree algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Ribarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing<address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="523" to="530" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Meter identification of sanskrit verse. The Sanskrit Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawan</forename><surname>Keshav S Melnad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scharf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Discovering meta-paths in large heterogeneous information networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changping</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reynold</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silviu</forename><surname>Maniu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangda</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web, WWW &apos;15</title>
		<meeting>the 24th International Conference on World Wide Web, WWW &apos;15<address><addrLine>Republic and Canton of Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="754" to="764" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">From wer and ril to mer and wil: improved evaluation measures for connected speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktoria</forename><surname>Andrew Cameron Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Pystruct: learning structured prediction in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2055" to="2060" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Word graphs: an efficient interface between continuous-speech recognition and language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oerder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1993 IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="119" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Shortest connection networks and some generalizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Clay Prim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Labs Technical Journal</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1389" to="1401" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">(online) subgradient methods for structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Nathan D Ratliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zinkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics (AIStats)</title>
		<meeting>the Eleventh International Conference on Artificial Intelligence and Statistics (AIStats)<address><addrLine>San Juan, Puerto Rico. JMLR.org</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="380" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Building a Word Segmenter for Sanskrit Overnight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrith</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishnu</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M R</forename><surname>Vineeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawan</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Optimizing binary mrfs via extended roof duality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Szummer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2007)</title>
		<meeting><address><addrLine>Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>Minneapolis</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Distinctive features of poetic syntax preliminary results. Sanskrit syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Scharf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuja</forename><surname>Ajotikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampada</forename><surname>Savardekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawan</forename><surname>Goyal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="305" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Japanese and korean voice search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakajima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="5149" to="5152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A graph-based lattice dependency parser for joint morphological segmentation and syntactic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Seeker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Comma restoration using constituency information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="142" to="148" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Context-based morphological disambiguation with random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><forename type="middle">W</forename><surname>Tromble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing<address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="475" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning continuous phrase representations and syntactic parsing with recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS-2010</title>
		<meeting>the NIPS-2010</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<title level="m">Deep Learning and Unsupervised Feature Learning Workshop</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Word-based and character-based word segmentation models: Comparison and combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coling 2010: Posters</title>
		<meeting><address><addrLine>Beijing, China. Coling</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1211" to="1219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">An approximate solution for steiner problem in graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiromitsu</forename><surname>Takahashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Japonica</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="573" to="577" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning structured prediction models: A large margin approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassil</forename><surname>Chatalbashev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Machine Learning</title>
		<meeting>the 22nd International Conference on Machine Learning<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="896" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Max-margin markov networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Neural Information Processing Systems, NIPS&apos;03</title>
		<meeting>the 16th International Conference on Neural Information Processing Systems, NIPS&apos;03<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The worst-case time complexity for generating all maximal cliques and computational experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etsuji</forename><surname>Tomita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akira</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haruhisa</forename><surname>Takahashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">363</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="42" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The hwim speech understanding system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Woods</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP &apos;77. IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="784" to="787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Neural word segmentation with rich pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="839" to="849" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
