<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interpreting Neural Networks to Improve Politeness Comprehension</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malika</forename><surname>Aubakirova</surname></persName>
							<email>aubakirova@uchicago.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Chicago</orgName>
								<orgName type="institution" key="instit2">UNC Chapel Hill</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
							<email>mbansal@cs.unc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Chicago</orgName>
								<orgName type="institution" key="instit2">UNC Chapel Hill</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Interpreting Neural Networks to Improve Politeness Comprehension</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2035" to="2041"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an interpretable neural network approach to predicting and understanding politeness in natural language requests. Our models are based on simple convolutional neural networks directly on raw text, avoiding any manual identification of complex sentiment or syntactic features, while performing better than such feature-based models from previous work. More importantly, we use the challenging task of politeness prediction as a testbed to next present a much-needed understanding of what these successful networks are actually learning. For this, we present several network visualizations based on activation clusters, first derivative saliency, and embedding space transformations, helping us automatically identify several subtle linguistics markers of politeness theories. Further, this analysis reveals multiple novel, high-scoring politeness strategies which, when added back as new features, reduce the accuracy gap between the original featurized system and the neural model, thus providing a clear quantitative interpretation of the success of these neu-ral networks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Politeness theories <ref type="bibr" target="#b1">(Brown and Levinson, 1987;</ref><ref type="bibr" target="#b11">Gu, 1990;</ref><ref type="bibr" target="#b0">Bargiela-Chiappini, 2003)</ref> include key com- ponents such as modality, indirection, deference, and impersonalization. Positive politeness strate- gies focus on making the hearer feel good through offers, promises, and jokes. Negative politeness examples include favor seeking, orders, and re- quests. Differentiating among politeness types is a highly nontrivial task, because it depends on fac- tors such as a context, relative power, and culture.</p><p>Danescu-Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2013)</ref> proposed a useful computational framework for predicting po- liteness in natural language requests by designing various lexical and syntactic features about key po- liteness theories, e.g., first or second person start vs. plural. However, manually identifying such polite- ness features is very challenging, because there ex- ist several complex theories and politeness in natu- ral language is often realized via subtle markers and non-literal cues.</p><p>Neural networks have been achieving high perfor- mance in sentiment analysis tasks, via their ability to automatically learn short and long range spatial relations. However, it is hard to interpret and ex- plain what they have learned. In this paper, we first propose to address politeness prediction via sim- ple CNNs working directly on the raw text. This helps us avoid the need for any complex, manually- defined linguistic features, while still performing better than such featurized systems. More impor- tantly, we next present an intuitive interpretation of what these successful neural networks are learning, using the challenging politeness task as a testbed.</p><p>To this end, we present several visualization strategies: activation clustering, first derivative saliency, and embedding space transformations, some of which are inspired by similar strategies in computer vision ( <ref type="bibr" target="#b7">Erhan et al., 2009;</ref><ref type="bibr" target="#b27">Simonyan et al., 2014;</ref><ref type="bibr" target="#b8">Girshick et al., 2014)</ref>, and have also been recently adopted in NLP for recurrent neural net- works ( <ref type="bibr" target="#b13">Kádár et al., 2016</ref>). The neu- ron activation clustering method not only rediscov- ers and extends several manually defined features from politeness theories, but also uncovers multi- ple novel strategies, whose importance we measure quantitatively. The first derivative saliency tech- nique allows us to identify the impact of each phrase on the final politeness prediction score via heatmaps, revealing useful politeness markers and cues. Fi- nally, we also plot lexical embeddings before and af- ter training, showing how specific politeness mark- ers move and cluster based on their polarity. Such visualization strategies should also be useful for un- derstanding similar state-of-the-art neural network models on various other NLP tasks.</p><p>Importantly, our activation clusters reveal two novel politeness strategies, namely indefinite pro- nouns and punctuation. Both strategies display high politeness and top-quartile scores (as defined by Danescu-Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2013)</ref>). Also, when added back as new features to the original fea- turized system, they improve its performance and re- duce the accuracy gap between the featurized system and the neural model, thus providing a clear, quan- titative interpretation of the success of these neural networks in automatically learning useful features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Danescu-Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2013)</ref> presented one of the first useful datasets and computational ap- proaches to politeness theories <ref type="bibr" target="#b1">(Brown and Levinson, 1987;</ref><ref type="bibr" target="#b10">Goldsmith, 2007;</ref><ref type="bibr" target="#b12">Kádár and Haugh, 2013;</ref><ref type="bibr" target="#b20">Locher and Watts, 2005</ref>), using manually de- fined lexical and syntactic features. Substantial pre- vious work has employed machine learning models for other sentiment analysis style tasks ( <ref type="bibr" target="#b25">Pang et al., 2002;</ref><ref type="bibr" target="#b24">Pang and Lee, 2004;</ref><ref type="bibr" target="#b16">Kennedy and Inkpen, 2006;</ref><ref type="bibr" target="#b9">Go et al., 2009;</ref><ref type="bibr" target="#b7">Ghiassi et al., 2013)</ref>. Recent work has also applied neural network based mod- els to sentiment analysis tasks <ref type="bibr" target="#b2">(Chen et al., 2011;</ref><ref type="bibr" target="#b28">Socher et al., 2013;</ref><ref type="bibr" target="#b22">Moraes et al., 2013;</ref><ref type="bibr" target="#b5">Dong et al., 2014;</ref><ref type="bibr" target="#b6">dos Santos and Gatti, 2014;</ref><ref type="bibr" target="#b14">Kalchbrenner et al., 2014</ref>). However, none of the above methods focused on visualizing and understanding the inner workings of these successful neural networks.</p><p>There have been a number of visualization tech- niques explored for neural networks in computer vi- sion ( <ref type="bibr" target="#b18">Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b27">Simonyan et al., 2014;</ref><ref type="bibr" target="#b29">Zeiler and Fergus, 2014;</ref><ref type="bibr" target="#b26">Samek et al., 2016;</ref><ref type="bibr" target="#b21">Mahendran and Vedaldi, 2015)</ref>. Recently in NLP,  successfully adopt computer vision tech- niques, namely first-order saliency, and present rep- resentation plotting for sentiment compositionality across RNN variants. Similarly, <ref type="bibr">Kádár et al. (2016)</ref> analyze the omission scores and top-k contexts of hidden units of a multimodal RNN. <ref type="bibr" target="#b15">Karpathy et al. (2016)</ref> visualize character-level language models. We instead adopt visualization techniques for CNN style models for NLP <ref type="bibr">1</ref> and apply these to the chal- lenging task of politeness prediction, which often involves identifying subtle and non-literal sociolin- guistic cues. We also present a quantitative interpre- tation of the success of these CNNs on the politeness prediction task, based on closing the performance gap between the featurized and neural models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Convolutional Neural Networks</head><p>We use one convolutional layer followed by a pool- ing layer. For a sentence v 1:n (where each word v i is a d-dim vector), a filter m applied on a window of t words, produces a convolution feature</p><formula xml:id="formula_0">c i = f (m * v i:i+t−1 + b),</formula><p>where f is a non-linear function, and b is a bias term. A feature map c ∈ R n−t+1 is ap- plied on each possible window of words so that c = [c 1 , ..., c n−t+1 ]. This convolutional layer is then fol- lowed by a max-over-pooling operation <ref type="bibr" target="#b3">(Collobert et al., 2011</ref>) that gives C = max{c} of the partic- ular filter. To obtain multiple features, we use mul- tiple filters of varying window sizes. The result is then passed to a fully-connected softmax layer that outputs probabilities over labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We used the two datasets released by Danescu- Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2013)</ref>: Wikipedia (Wiki) and Stack Exchange (SE), containing community re- quests with politeness labels. Their 'feature devel- opment' was done on the Wiki dataset, and SE was used as the 'feature transfer' domain. We use a sim- pler train-validation-test split based setup for these datasets instead of the original leave-one-out cross- validation setup, which makes training extremely slow for any neural network or sizable classifier. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Details</head><p>Our tuned hyperparameters values (on the dev set of Wiki) are a mini-batch size of 32, a learning rate of 0.001 for the Adam ( <ref type="bibr" target="#b17">Kingma and Ba, 2015)</ref> opti- mizer, a dropout rate of 0.5, CNN filter windows of 3, 4, and 5 with 75 feature maps each, and ReLU as the non-linear function <ref type="bibr" target="#b23">(Nair and Hinton, 2010)</ref>. For convolution layers, we use valid padding and strides of all ones. We followed Danescu-Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2013)</ref> in using SE only as a transfer domain, i.e., we do not re-tune any hyperparameters or fea- tures on this domain and simply use the chosen val- ues from the Wiki setting. The split and other train- ing details are provided in the supplement. <ref type="table">Table 1</ref> first presents our reproduced classification accuracy test results (two labels: positive or nega- tive politeness) for the bag-of-words and linguistic features based models of Danescu-Niculescu-Mizil et al. (2013) (for our dataset splits) as well as the performance of our CNN model. As seen, without using any manually defined, theory-inspired linguis- tic features, the simple CNN model performs better than the feature-based methods. <ref type="bibr">3</ref> Next, we also show how the linguistic features baseline improves on adding our novelly discovered features (plus correcting some exising features), re- vealed via the analysis in Sec. 6. Thus, this reduces the gap in performance between the linguistic fea- tures baseline and the CNN, and in turn provides a quantitative reasoning for the success of the CNN model. More details in Sec. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Analysis and Visualization</head><p>We present the primary interest and contribution of this work: performing an important qualitative and quantitative analysis of what is being learned by our neural networks w.r.t. politeness strategies. <ref type="bibr">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Activation Clusters</head><p>Activation clustering is a non-parametric approach (adopted from Girshick et al. <ref type="formula">(2014)</ref> each CNN unit's activations on a dataset and then analyzing the top-scoring samples in each cluster. We keep track of which neurons get maximally acti- vated for which Wikipedia requests and analyze the most frequent requests in each neuron's cluster, to understand what each neuron reacts to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Rediscovering Existing Strategies</head><p>We find that the different activation clusters of our neural network automatically rediscover a num- ber of strategies from politeness theories considered in Danescu-Niculescu-Mizil et al. (2013) (see <ref type="table">Table  3</ref> in their paper). We present a few such strate- gies here with their supporting examples, and the rest (e.g., Gratitude, Greeting, Positive Lexicon, and Counterfactual Modal) are presented in the supple- ment. The majority politeness label of each category is indicated by (+) and (-). Deference (+) A way of sharing the burden of a request placed on the addressee. Activation cluster examples: {"nice work so far on your rewrite..."; "hey, good work on the new pages..."} Direct Question (-)</p><p>Questions imposed on the converser in a direct manner with a demand of a fac- tual answer. Activation cluster examples: {"what's with the radio , and fist in the air?"; "what level warning is appropriate?"}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Extending Existing Strategies</head><p>We also found that certain activation clusters de- picted interesting extensions of the politeness strate- gies given in previous work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gratitude (+)</head><p>Our CNN learns a special shade of gratitude, namely it distinguishes a cluster con- sisting of the bigram thanks for. Activation cluster examples: {"thanks for the good advice."; "thanks for letting me know."} Counterfactual Modal (+) Sentences with Would you/Could you get grouped together as expected; but in addition, the cluster contains requests with Do you mind as well as gapped 3-grams like Can you ... please?, which presumably implies that the combi-  True label 0; <ref type="table" target="#tab_3">Predicted 0   0  50 100 150 200 250 300  hey  thanks  for  reassessing  the  &lt;  url  &gt;  article  to  b  class  .  so  what  's  need  to  be  done  to  make</ref> it ga ?</p><p>True label 1; Predicted 1 nation of a later please with future-oriented variants can/will in the request gives a similar effect as the conditional-oriented variants would/could. Activa- tion cluster examples: {can this be reported ... grid, please?"; do you mind having another look?"}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Discovering Novel Strategies</head><p>In addition to rediscovering and extending polite- ness strategies mentioned in previous work, our net- work also automatically discovers some novel acti- vation clusters, potentially corresponding to new po- liteness strategies. Indefinite Pronouns (-)</p><p>Danescu-Niculescu- Mizil et al. <ref type="formula">(2013)</ref> distinguishes requests with first and second person (plural, starting position, etc.). However, we find activations that also react to in- definite pronouns such as something/somebody. Ac- tivation cluster examples: {"am i missing something here?"; "wait for anyone to discuss it."} Punctuation (-)</p><p>Though non-characteristic in direct speech, punctuation appears to be an impor- tant special marker in online communities, which in some sense captures verbal emotion in text. E.g., one of our neuron clusters gets activated on ques- tion marks "???" and one on ellipsis "...". Activa- tion cluster examples: {"now???"; "original arti- cle????"; "helllo?????"} <ref type="bibr">5</ref> In the next section, via saliency heatmaps, we will further study the impact of indefinite pronouns in the final-decision making of the classifier. Finally, in Sec. 6.4, we will quantitatively show how our newly discovered strategies help directly improve the accu- racy performance of the linguistic features baseline and achieve high politeness and top-quartile scores as per Danescu-Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2013)</ref>. <ref type="bibr">5</ref> More examples are given in the supplement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">First Derivative Saliency</head><p>Inspired from neural network visualization in com- puter vision <ref type="bibr" target="#b27">(Simonyan et al., 2014</ref>), the first deriva- tive saliency method indicates how much each input unit contributes to the final decision of the classifier. If E is the input embedding, y is the true label, and S y (E) is the neural network output, then we con- sider gradients</p><formula xml:id="formula_1">∂Sy(E)</formula><p>∂e . Each image in <ref type="figure" target="#fig_1">Fig. 1</ref> is a heatmap of the magnitudes of the derivative in abso- lute value with respect to each dimension.</p><p>The first heatmap gets signals from please (Please strategy) and could you (Counterfactual Modal strat- egy), but effectively puts much more mass on help. This is presumably due to the nature of Wikipedia requests such that the meaning boils down to ask- ing for some help that reduces the social distance. In the second figure, the highest emphasis is put on why would you, conceivably used by Wikipedia ad- ministrators as an indicator of questioning. Also, the indefinite pronoun somebody makes a relatively high impact on the decision. This relates back to the activation clustering mentioned in the previous sec- tion, where indefinite pronouns had their own clus- ter. In the third heatmap, the neural network does not put much weight on the greeting-based start hey, be- cause it instead focuses on the higher polarity 6 grati- tude part after the greeting, i.e., on the words thanks for. This will be further connected in Sec. 6.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Embedding Space Transformations</head><p>We selected key words from Danescu-Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2013)</ref> and from our new activation clus- ters ( Sec. 6.1) and plotted (via PCA) their embed-   ding space positions before and after training, to help us gain insights into specific sentiment trans- formations. <ref type="figure" target="#fig_2">Fig. 2</ref> shows that the most positive keys such as hi, appreciate, and great get clustered even more tightly after training. The key thanks gets a no- tably separated position on a positive spectrum, sig- nifying its importance in the NN's decision-making (also depicted via the saliency heatmaps in Sec. 6.2).</p><p>The indefinite pronoun something is located near direct question politeness strategy keys why and what. Please, as was shown by Danescu-Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2013)</ref>, is not always a positive word be- cause its sentiment depends on its sentence position, and it moves further away from a positive key group. Counterfactual Modal keys could and would as well as can of indicative modal get far more separated from positive keys. Moreover, after the training, the distance between could and would increases but it gets preserved between can and would, which might suggest that could has a far stronger sentiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Quantitative Analysis</head><p>In this section, we present quantitative measures of the importance and polarity of the novelly discov- ered politeness strategies in the above sections, as well how they explain some of the improved perfor- mance of the neural model.</p><p>In <ref type="table">Table 3</ref> of Danescu-Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2013)</ref>, the pronoun politeness strategy with the highest percentage in top quartile is 2nd Person (30%). Our extension <ref type="table" target="#tab_3">Table 2</ref> shows that our nov- elly discovered Indefinite Pronouns strategy repre- sents a higher percentage (39%), with a politeness score of -0.13. Moreover, our Punctuation strategy also turns out to be a top scoring negative politeness strategy and in the top three among all strategies (af- ter Gratitude and Deference). It has a score of -0.71, whereas the second top negative politeness strategy (Direct Start) has a much lower score of -0.43.</p><p>Finally, in terms of accuracies, our newly dis- covered features of Indefinite Pronouns and Punc- tuation improved the featurized system of Danescu- Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2013)</ref> (see <ref type="table">Table 1</ref>). <ref type="bibr">7</ref> This reduction of performance gap w.r.t. the CNN par- tially explains the success of these neural models in automatically learning useful linguistic features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented an interpretable neural network ap- proach to politeness prediction. Our simple CNN model improves over previous work with manually- defined features. More importantly, we then under- stand the reasons for these improvements via three visualization techniques and discover some novel high-scoring politeness strategies which, in turn, quantitatively explain part of the performance gap between the featurized and neural models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>0</head><label>0</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Saliency heatmaps for correctly classified sentences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Projection before (red) and after (blue) training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Extending Table 3 of Danescu-Niculescu-Mizil et al. (2013) with our novelly discovered politeness strategies.</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> The same techniques can also be applied to RNN models. 2 The result trends and visualizations using cross-validation were similar to our current results, in preliminary experiments. We will release our exact dataset split details.</note>

			<note place="foot" n="6"> See Table 3 of Danescu-Niculescu-Mizil et al. (2013) for polarity scores of the various strategies.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous reviewers for their helpful comments. This work was supported by an IBM Faculty Award, a Bloomberg Research Grant, and an NVIDIA GPU donation to MB. <ref type="bibr">7</ref> Our NN visualizations also led to an interesting feature cor-rection. In the 'With Discovered Features' result in <ref type="table">Table 1</ref>, we also removed the existing pronoun features (#14-18) based on the observation that those had weaker activation and saliency contributions (and lower top-quartile %) than the new indefi-nite pronoun feature. This correction and adding the two new features contributed ∼50-50 to the total accuracy improvement.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Face and politeness: new (insights) for old (concepts)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Bargiela-Chiappini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of pragmatics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1453" to="1469" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Politeness: Some universals in language usage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Penelope</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stephen C Levinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Cambridge university press</publisher>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A neural network based approach for sentiment classification in the blogosphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long-Sheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Hsiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui-Ju</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Informetrics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="322" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A computational approach to politeness with application to social factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Sudhof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive recursive neural network for target-dependent twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="49" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for sentiment analysis of short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cícero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maira</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Twitter brand sentiment analysis: A hybrid system using ngram analysis and dynamic artificial neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Dumitru Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vincent ; M Ghiassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Skinner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zimbra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with applications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="6266" to="6282" />
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Montreal</orgName>
		</respStmt>
	</monogr>
	<note>Visualizing higher-layer features of a deep network</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Twitter sentiment classification using distant supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richa</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">12</biblScope>
			<pubPlace>Stanford, 1</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">CS224N Project Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Explaining communication: Contemporary theories and exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goldsmith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="219" to="236" />
		</imprint>
	</monogr>
	<note>Brown and levinsons politeness theory</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Politeness phenomena in modern chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueguo</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of pragmatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="237" to="257" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Understanding politeness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dániel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kádár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Haugh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akos</forename><surname>Kádár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Chrupała</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afra</forename><surname>Alishahi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.08952</idno>
		<title level="m">Representation of linguistic form and function in recurrent neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visualizing and understanding recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR Workshop</title>
		<meeting>ICLR Workshop</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sentiment classification of movie reviews using contextual valence shifters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="110" to="125" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Visualizing and understanding neural models in NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Politeness theory and relational work</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miriam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard J</forename><surname>Locher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Watts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Politeness Research. Language, Behaviour, Culture</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="33" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Understanding deep image representations by inverting them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravindh</forename><surname>Mahendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5188" to="5196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Document-level sentiment classification: An empirical comparison between svm and ann</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Moraes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><forename type="middle">Francisco</forename><surname>Valiati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilson P Gavião</forename><surname>Neto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="621" to="633" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">271</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Thumbs up?: sentiment classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivakumar</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evaluating the visualization of what a deep neural network has learned</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep inside convolutional networks: Visualising image classification models and saliency maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR Workshop</title>
		<meeting>ICLR Workshop</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
