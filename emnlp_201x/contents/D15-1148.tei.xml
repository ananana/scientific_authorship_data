<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:09+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Detecting Content-Heavy Sentences: A Cross-Language Case Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyi</forename><forename type="middle">Jessy</forename><surname>Li</surname></persName>
							<email>ljunyi@seas.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Pennsylvania</orgName>
								<orgName type="institution" key="instit2">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
							<email>nenkova@seas.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Pennsylvania</orgName>
								<orgName type="institution" key="instit2">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Detecting Content-Heavy Sentences: A Cross-Language Case Study</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The information conveyed by some sentences would be more easily understood by a reader if it were expressed in multiple sentences. We call such sentences content heavy: these are possibly grammatical but difficult to comprehend, cumbersome sentences. In this paper we introduce the task of detecting content-heavy sentences in cross-lingual context. Specifically we develop methods to identify sentences in Chinese for which English speakers would prefer translations consisting of more than one sentence. We base our analysis and definitions on evidence from multiple human translations and reader preferences on flow and understandability. We show that machine translation quality when translating content heavy sentences is markedly worse than overall quality and that this type of sentence are fairly common in Chinese news. We demonstrate that sentence length and punctuation usage in Chi-nese are not sufficient clues for accurately detecting heavy sentences and present a richer classification model that accurately identifies these sentences.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>To generate text, people and machines need to de- cide how to package the content they wish to ex- press into clauses and sentences. There are multi- ple possible renderings of the same information, with varying degrees of ease of comprehension, compactness and naturalness. Some sentences, even though they are grammatical, would be more accessible to a reader if expressed in multiple sen- tences. We call such sentences content heavy sen- tences, or heavy sentences for brevity.</p><p>In the established areas of language research, text simplification and sentence planning in dia- log and generation systems are clearly tasks in which identification of content-heavy sentences is of great importance. In this paper we introduce a novel flavor of the task in the cross-lingual setting, which in the long term may guide improvements in machine translation. We seek to identify sentences in Chinese that would result in heavy sentences in English if translated to a single sentence.</p><p>Example I in <ref type="table" target="#tab_0">Table 1</ref> shows a Chinese sentence and its two English translations A and B. Transla- tor A used three English sentences to express all the information. Translator B, on the other hand, used a single sentence, which most readers would find more difficult to read. Example II illustrates a case where a translator would be hard pressed to convey all the content in a sentence in Chinese into a single grammatical English sentence.</p><p>Here we provide an operational characteriza- tion of content-heavy sentences in the context of Chinese-English translation. Instead of establish- ing guidelines for standalone annotation, we re- purpose datasets developed for evaluation of ma- chine translation consisting of multiple reference translations for each Chinese sentence. In this cross-lingual analysis, sentences in Chinese are considered content-heavy if their content would be more felicitously expressed in multiple sentences in English.</p><p>We first show that, with respect to English, content-heavy Chinese sentences are common. A fifth to a quarter of the sentences in the Chi- nese news data that we analyze are translated to multiple sentences in English. Moreover our experiments with reader preference indicate that for these sentences, readers strongly prefer multi- sentence translation to a single-sentence transla- tion ( § 4.1). We also compare the difference in ma- chine translation quality for heavy sentences and find that it is considerably lower than overall sys- tem performance <ref type="bibr">( § 4.2)</ref>. Then we study the con- nection between heavy sentences and the factors <ref type="bibr">[Example I</ref></p><formula xml:id="formula_0">] 虽 然 菲 军 方 在 南 部 的 巴 西 兰 岛 上 部 署 了5000多兵力，并在美军的帮助下围剿阿布沙耶夫分</formula><p>子，但迄今收效不大。Although the Philippine army on the southern Basilan island deployed over 5,000 troops, and with the US army's help are hunting down ASG members, but so far achieved little.</p><p>[A] The Philippine army has already deployed over 5 thou- sand soldiers on the southern island of Basilan. With the help of U.S. army, these soldiers are searching and suppress- ing members of Abu Sayyaf. However, there is not much achievement this far.</p><p>[B] The Philippine military has stationed over 5,000 troops on Basilan Island in the southern Philippines and also tried to hunt down ASG members with the help of the United States, yet so far it has little success.</p><p>[Example II] 端粒是染色体末端的结构，随着细胞老化 和失去分裂能力，端粒会逐渐缩短长度，换言之，端粒 愈长显示细胞老化愈慢。Telomeres are chromosome ends structures, with cell aging and losing division ability, telom- eres will gradually decrease length, in other words, telomeres the longer shows cell aging the slower.</p><p>[A] Telomeres are structures at the ends of chromosomes, which gradually reduce in length with the aging of the cells and their loss of the ability to divide. In other words, longer telomeres indicate the slower aging of the cells.</p><p>[B] Telomeres are the physical ends of chromosomes. As cells age and lose the ability to divide, the telomeres shrink gradually. That is to say, longer telomeres indicate that cells are aging more slowly. used in prior work to split a Chinese sentence into multiple sentences, showing that they do not fully determine the empirically defined content-heavy status ( § 5). Finally, we present an effective system to automatically identify content-heavy sentences in Chinese ( § 6, 7, 8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The need for identifying content-heavy sentences arises in many specialized domains, including di- alog systems, machine translation, text simplifica- tion and Chinese language processing but it is usu- ally addressed in an implicit or application specific way. In contrast, we focus on identifying heavy sentences as a standalone task, providing a uni- fying view of the seemingly disparate strands of prior work. We now overview the literature which motivated our work.</p><p>Sentence planning. In text generation, a sen- tence planner produces linguistic realizations of a list of propositions <ref type="bibr" target="#b27">(Rambow and Korelsky, 1992)</ref>. One subtask is to decide whether to package the same content into one or more sentences. In the example below <ref type="bibr" target="#b25">(Pan and Shaw, 2005</ref>), the multi- sentence expression B is much easier to process:</p><p>[A] This is a 1 million dollar 3 bedroom, 2 bathroom, 2000 square foot colonial with 2 acre of land, 2 car garage, annual taxes 8000 dollars in Armonk and in the Byram Hills school district.</p><p>[B] This is a 3 bedroom, 2 bathroom, 2000 square foot colo- nial located in Armonk with 2 acres of land. The asking price is 1 million dollar and the annual taxes are 8000 dollars. The house is located in the Byram Hills School District.</p><p>Identifying sentence <ref type="bibr">[A]</ref> as heavy would be useful in selecting the best realization.</p><p>A crucial difference between our task and its counterpart in sentence planning is that traditional text generation systems have access to rich se- mantic information about the type of propositions the system needs to convey, while in our task we have access only to Chinese text. In some dia- log systems, content selection is treated as an op- timization problem, balancing the placement of full-stops and the insertion or deletion of proposi- tions with the similarity of the resulting output and an existing corpus of acceptable productions <ref type="bibr" target="#b25">(Pan and Shaw, 2005)</ref>. Others formulate the problem as a supervised ranking task, in which different pos- sible content realizations are generated, including variation in the number of sentences ( <ref type="bibr" target="#b34">Walker et al., 2001;</ref><ref type="bibr" target="#b31">Stent et al., 2004</ref>). With the introduction of the concept of content-heavy sentences, we can envision dialog systems addressing the sentence realization task in two steps, first predicting if the semantic content will require multiple sentences, then having different rankers for expressing the content in one or multiple sentences. In that case the ranker will need to capture only sentence-level information and the discourse-level decision to use multiple sentences will be treated separately.</p><p>Text simplification. "Text simplification, de- fined narrowly, is the process of reducing the lin- guistic complexity of a text, while still retain- ing the original information content and mean- ing" <ref type="bibr" target="#b29">(Siddharthan, 2014</ref>). An important aspect of simplification is syntactic transformation in which sentences deemed difficult are re-written as multi- ple sentences <ref type="bibr">(Chandrasekar et al., 1996;</ref><ref type="bibr" target="#b0">Aluísio et al., 2008)</ref>. Our task may be viewed as identi- fying sentences in one language that will require simplification when translated, for the benefit of the speakers of the target language. In rule-based simplification systems, splitting is performed al-ways when a given syntactic construction such as relative clause, apposition or discourse connec- tive are detected ( <ref type="bibr">Chandrasekar et al., 1996;</ref><ref type="bibr" target="#b28">Siddharthan, 2006;</ref><ref type="bibr" target="#b8">De Belder and Moens, 2010)</ref>. Most recently, text simplification has been ad- dressed as a monolingual machine translation task from complex to simple language <ref type="bibr" target="#b30">(Specia, 2010;</ref><ref type="bibr" target="#b7">Coster and Kauchak, 2011;</ref><ref type="bibr" target="#b36">Wubben et al., 2012)</ref>. However simplification by repackaging the con- tent into multiple sentences is not naturally com- patible with the standard view of statistical MT in which a system is expected to produce a single output sentence for a single input sentence. Some of the recent systems using MT techniques sep- arately model the need for sentence splitting ( <ref type="bibr" target="#b43">Zhu et al., 2010;</ref><ref type="bibr" target="#b35">Woodsend and Lapata, 2011;</ref><ref type="bibr" target="#b24">Narayan and Gardent, 2014)</ref>. Identifying heavy sentences in simplification is equivalent to identifying sen- tences that require syntactic simplification.</p><p>Sentence structure and MT. Prior work in ma- chine translation has discussed the existence of sentences in Chinese which would result in a poor translation if translated in one sentence in English. The main factors proposed to characterize such problematic sentences are sentence length ( <ref type="bibr" target="#b37">Xu and Tan, 1996)</ref> and the presence of given syntactic constructions ( <ref type="bibr" target="#b38">Xu et al., 2005;</ref><ref type="bibr" target="#b42">Yin et al., 2007;</ref><ref type="bibr" target="#b13">Jin and Liu, 2010)</ref>. <ref type="bibr" target="#b23">Mishra et al. (2014)</ref> used rules in- volving similar factors to distinguish sentences in Hindi that need simplification prior to translation.</p><p>In each of these approaches, the identified sen- tences are segmented into smaller units. Similar to work in text simplification, the simplification rules are applied to all sentences meeting certain crite- ria, normally to all sentences longer than a pre- defined threshold or where certain conjunctions or coordinations are present. In contrast, the model we propose here can be used to predict when seg- mentation is at all necessary.</p><p>Our approach to the problem is more compat- ible with the empirical evidence we presented in our prior work ( <ref type="bibr" target="#b19">Li et al., 2014</ref>) where we ana- lyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality. Rather we showed that the quality of translation was markedly inferior, compared to overall transla- tion quality, for sentences that were translated into multiple English sentences. This prior work was carried over a dataset containing a single reference translation for each Chinese sentence. In the work presented in this paper, we strengthen our find- ings by examining multiple reference translations for each Chinese sentence. We define heavy sen- tences based on agreement of translator choices and reader preferences.</p><p>Commas in Chinese. Often a comma in a sen- tence can be felicitously replaced by a full stop. Such commas offer a straightforward way to split a long sentence into multiple shorter ones by replac- ing the comma with a full stop. Monolingual text simplification systems often try to identify such commas. They are particularly common in Chi- nese and replacing them with full stops leads to improvements in the accuracy of syntactic parsing <ref type="bibr" target="#b14">(Jin et al., 2004;</ref><ref type="bibr" target="#b18">Li et al., 2005</ref>). Moreover, exist- ing syntactically parsed corpora conveniently pro- vide numerous examples of these full-stop com- mas, and thus training data for systems to identify them ( <ref type="bibr" target="#b39">Xue and Yang, 2011;</ref><ref type="bibr" target="#b41">Yang and Xue, 2012)</ref>. In this paper, we systematically study the relation- ship between the presence of full-stop commas in the sentence and whether it is content-heavy for Chinese to English translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>In this work we use three news datasets: the newswire portion of the NIST 2012 Open Ma- chine Translation Evaluation (OpenMT) <ref type="bibr">(Group, 2013)</ref>, Multiple-Translation Chinese (MTC) parts 1-4 ( <ref type="bibr" target="#b11">Huang et al., 2002;</ref><ref type="bibr" target="#b12">Huang et al., 2003;</ref><ref type="bibr" target="#b20">Ma, 2004;</ref><ref type="bibr" target="#b21">Ma, 2006</ref>), and the Chinese Treebank ( <ref type="bibr" target="#b40">Xue et al., 2005</ref>). In OpenMT and MTC, multiple reference translations in English are available for each Chinese segment (sentence).</p><p>To study the relationship between content- heavy sentences and reader preference for multi- sentence translations ( § 4.1), we use OpenMT (688 segments) and MTC parts 2-4 (2,439 segments), both of which provide four English translations for each Chinese segment. This analysis forms the basis for labeling heavy sentences for supervised training and evaluation ( § 5, 6, 7).</p><p>The Chinese Treebank (CTB) has been used in prior work as data for identifying full-stop com- mas. Moreover, 52 documents in MTC part 1 were drawn from the CTB. The intersection of the two datasets allows us to directly analyze the relation- ship between heavy sentences and full-stop com- mas in Chinese ( § 5). Furthermore we use this in- tersection as test set to identify heavy sentences so we can directly compare with models developed for comma disambiguation. To be consistent with the rest of the MTC data, we use 4 out of the 11 translators in part 1 in these experiments. <ref type="bibr">1</ref> Our model for Chinese full-stop comma recog- nition is trained following the features and training sets specified in <ref type="bibr" target="#b39">Xue and Yang (2011)</ref>  <ref type="bibr">2</ref> , excluding the overlapping MTC/CTB documents mentioned above. There are 12,291 sentences in training that contain at least one comma. A classifier for detecting heavy sentences is trained on OpenMT and MTC (excluding the test set). A quick in- spection of both datasets reveals that Chinese sen- tences without a comma were never translated into multiple sentences by more than one translator. Therefore in our experiments we consider only sentences that contain at least one comma. There are 301 test sentences, 511 training sentences in OpenMT and 2418 in MTC. Sentences are pro- cessed by the Stanford NLP packages <ref type="bibr">3</ref> . CTB gold- standard parses are used to obtain full-stop com- mas and to train comma disambiguation models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Content-heavy sentences: definition</head><p>In this section we provide an operational definition for which sentences should be considered content- heavy, based on the choices made by translators and the fluency preferences of readers when a sen- tence is translated into a single or multiple sen- tences. We further demonstrate the difference in machine translation quality when translating content-heavy sentences compared to other sen- tences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Content-heaviness and multi-sentence translations</head><p>First we quantify how often translators choose to translate a Chinese sentence into multiple English sentences. Content-heavy Chinese sentences are those for which there is a strong preference to pro- duce multiple sentences when translating to En- glish (at the end of the section we present specific criteria). Obviously, splitting a sentence into multiple ones is often possible but is not necessarily pre- ferred. In <ref type="table" target="#tab_2">Table 2</ref>, we show in the "%data"  in MTC, at least three of the translators produce a multi-sentence translation, a rate high enough to warrant closer inspection of the problem.</p><p>Next, we conduct a study to find out what level of translator agreement leads to strong reader pref- erence for the same information to be presented in multiple sentences.</p><p>For each Chinese segment with one, two or three multi-sentence reference translations, we ask five annotators on Mechanical Turk to rank the reference translations according to their general flow and understandability. The annotators saw only the four randomly ordered English transla- tions and were not shown the Chinese original, with the following instruction:</p><p>Below are 1-2 sentence snippets that describe the same con- tent. Some are more readable and easier to understand than others. Your task is to rank them from the best to worst in terms of wording or flow (organization). There can be ties, but you have to pick one that is the best.</p><p>We obtain reader preference for each segment in the following manner: for each annotator, we take the highest ranked translation and check whether it consists of multiple sentences. In this way we have five binary indicators. We say readers prefer a sentence to have a multi-sentence translation in terms of flow and comprehensibility if the major- ity of these five indicators are positive.</p><p>In the "%best multi" columns of <ref type="table" target="#tab_2">Table 2</ref>, we tabulate the percentage of segments with major- ity preference for multi-sentence translation, strat- ified by the number of translators who split the content. Obviously the more multi-sentence trans- lations there are, the higher the probability that the readers will select one as the best translation. We are interested in knowing for which conditions the <ref type="table">Table 3</ref>: Percentage of data for heavy sentences along with BLEU scores for heavy and non-heavy sentences and their difference.</p><note type="other">Criteria %data(Y) Y N ∆bleu heavy 27.2 15.34 19.24 3.9</note><p>preference for multi-sentence translation exceeds the probability of randomly picking one. When only one (out of four) translations is multi-sentence, the best translations chosen by the majority of readers contain multiple sentences less often than in random selection from the avail- able translations. When two out of the four ref- erence translations are multi-sentence, the reader preference towards them beats chance by a good margin. The difference between chance selec- tion and reader preference for multiple sentences grows steadily with the number of reference trans- lations that split the content. These data suggest that when at least two translators perform a multi- sentence translation, breaking down information in the source sentence impacts the quality of the translation.</p><p>Hence we define content-heavy sentences in Chinese to be those for which at least two out of four reference translations consist of multiple sen- tences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">A challenge for MT</head><p>We now quantitatively show that heavy sentences are particularly problematic for machine transla- tion. We collect translations for each segment in OpenMT and MTC from the Bing Translator. We split the sentences into two groups, heavy and other, according to the gold standard label ex- plained in the previous section. We then com- pare the BLEU score for sentences in a respective group, where each group is in turn used as a test set. The difference in BLEU scores (∆bleu) is a strong indicator whether these sentences are chal- lenging for MT systems.</p><p>In <ref type="table">Table 3</ref> we show the BLEU scores and ∆bleu for sentences that are heavy (Y) and non-heavy (N). Also included in the table is the percentage of heavy sentences in all the data.</p><p>Translations for heavy sentences received a BLEU score that is 3.9 points lower than those that are not. This clearly illustrates the challenge and potential for improvement for MT systems posed by content-heavy sentences. Therefore the ability to reliably recognize them provides a first step to- Root IP IP clause PU (,) IP clause  <ref type="table">Table 4</ref>: Count of heavy and non-heavy sentences with and without full-stop commas.</p><p>wards developing a better translation approach for such sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Comma usage and heavy sentences</head><p>In Chinese, commas can sometimes act as sen- tence boundaries, similar to the function of an En- glish period. In Xue and Yang (2011), the au- thors showed that these full-stop commas can be identified in the constituent parse tree as coordi- nating IPs at the root level, shown in <ref type="figure" target="#fig_0">Figure 1</ref>. <ref type="bibr" target="#b9">Fancellu and Webber (2014)</ref> demonstrated that it is beneficial to split sentences containing negation on these types of commas, translate the resulting shorter sentences separately, then stitch the result- ing translations together. They report that this ap- proach prevented movement of negation particles beyond their scope. Here we study the degree to which the content-heavy status of a sentence is ex- plained by the presence of a full-stop comma in the sentence. We show that they are interrelated but not equivalent.</p><p>Corpus analysis. First we study how often a heavy sentence contains a full-stop comma and vice versa, using the overlapping MTC/CTB doc- uments. We show in <ref type="table">Table 4</ref> the number of heavy and non-heavy sentences with and without full- stop commas <ref type="bibr">4</ref> . When there is a full-stop comma in the sentence, there is a higher chance that the sentence is content-heavy. Yet of the 102 heavy sentences in this data, fewer than 40% contain full-stop commas; of the 242 sentences without full-stop commas, more than a quarter are heavy. Therefore, although comma usage in the Chinese sentence may provide clues for detecting content heaviness, the two phenomena are not equivalent and heavy sentences are not fully explained by the presence of full-stop commas.</p><p>Learning with full-stop commas. Here we evaluate the usefulness of using full-stop commas as training data to predict whether a sentence is content-heavy. From the analysis presented above we know that the two tasks are not equivalent. Nevertheless we would like to test directly if the Chinese Treebank-the large (but noisy for the task at hand) data available for comma function disambiguation-would lead to better results than learning on the cleaner but much smaller datasets for which multiple translations are available. We use logistic regression as our classification model <ref type="bibr">5</ref> . The performance of identifying heavy sentences on the MTC/CTB overlapping test set is compared using the following methods: <ref type="bibr">[Parallel]</ref> A classifier is trained using four English translations for each Chinese sentence (OpenMT and MTC training set). Following the definition in Section 4.1, content-heavy sentences are those translated into multiple English sen- tences by two or more translators.</p><p>[Oracle comma] A test sentence is assigned to class "heavy" if there is a full-stop comma in its corresponding gold standard parse tree.</p><p>[Predicted comma] We train a comma disam- biguation system on CTB to predict if a comma is a full-stop comma. In testing, a sentence is marked "heavy" if it contains a predicted full-stop comma.</p><p>Features. We reimplemented the per-comma features used in <ref type="bibr" target="#b39">Xue and Yang (2011)</ref>  <ref type="bibr">6</ref> . As in their best performing system, features are extracted from gold-standard parse trees during training and from automatic parsing during testing. These in- clude: words and part-of-speech tags immediately before and after the comma; left-and right-sibling node labels of the parent of the comma; ordered ancestor node labels above the comma; punctua- tion tokens ordered from left to right of the sen- tence; whether the comma has a coordinating IP structure; whether the comma's parent is a child of the root of the tree; whether there is a subordi- nation before the comma; whether the difference in number of words before and after the comma is greater than or equal to seven. <ref type="bibr">5</ref> We use the Liblinear package <ref type="bibr">(Fan et al., 2008)</ref>. <ref type="bibr">6</ref> For predicted comma, our reimplementation of Xue and Yang (2011) gave practically identical results to those re- ported in the original paper on the test set that they used.  <ref type="table">Table 5</ref>: Performance for identify heavy sentences using multiple reference data (parallel) vs. full- stop comma oracle labels (oracle comma) and pre- dicted full-stop commas (predicted comma).</p><p>For parallel, feature values are accumulated from all the commas in the sentence. For binary features, we use an or operation on the feature val- ues for each individual comma.</p><p>Results and comparison. In <ref type="table">Table 5</ref>, we show the accuracy, precision and recall for identifying content-heavy sentences using the three methods described above. We do not include the majority baseline here because it assumes no sentences are content heavy. Interestingly, the system using oracle informa- tion in each test sentence for full-stop commas per- forms the worst. The system trained to identify full-stop commas outperform the oracle system with about 10% better in recall and less than 1% lower in precision. This finding strongly suggests that the features used for learning capture certain characteristics of heavy sentences even with non- ideal training labels. The best performance is ob- tained learning directly on parallel corpora with multiple reference translations. Note that we try to provide the best possible setting for full-stop comma prediction, using much more training data, gold-standard parses, same-domain training and testing, as well as the reimplementation of state- of-the-art system. These settings allow us to con- servatively interpret the results listed here, which confirm that content-heaviness is different from using a full-stop comma in the Chinese sentence. It is more advantageous-leading to higher pre- cision and overall accuracy-to learn from data where translators encode their interpretation in the form of multi-sentence translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Features to characterize content-heavy sentences</head><p>In this section, we experiment with a wide range of features from the sentence string, part-of-speech tags and dependency parse trees.</p><p>Baseline. Intuitively, sentence length can be an indication of too much content that needs to be repackaged into multiple sentences. Therefore as our baseline we train a decision tree using the number of words 7 in a Chinese sentence.</p><p>Sentence structure cues. We collect potential signals for structural complexity: punctuation, conjunctions, prepositional phrases and relative clauses. As features we count the number of commas, conjunction, preposition and postposi- tion part-of-speech tags. In Chinese "DE" of- ten marks prepositional phrases or relative clauses among other functions ( <ref type="bibr" target="#b4">Chang et al., 2009a</ref>). Here we include a simple count the number of "DEG" tags in the sentence.</p><p>Dependencies. Dependency grammar captures both syntactic and semantic relationship between words and are shown to improve reordering in MT ( <ref type="bibr" target="#b6">Chang et al., 2009b</ref>). To account for such rela- tional information we include two feature classes: the percentage of each dependency type and the typed dependency pairs themselves. For the latter we use the universal part-of-speech tags (Petrov et al., 2012) for each word rather than the word itself to avoid too detailed and sparse representations. For example, the relation dobj(处理/handle, 事 情/matter) becomes feature dobj(verb, noun). Furthermore, we use dependency trees to ex- tract four features for potentially complex con- structions. First, we indicate the presence of noun phrases with heavy modifiers on the left. These are frequently used in Chinese and would require a relative clause or an additional sentence in En- glish. Specifically we record the maximum num- ber of dependents for the nouns in the sentence. The second type of construction is the use of se- rial verb phrases, illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>. We record the number of dependents of the head verb of the sentence. The third feature class is the typed de- pendencies (over universal POS tags) whose edge crosses a comma. Finally, we also record the max- imum number of dependents in the sentence to capture the general phrasal complexity in the sen- tence. <ref type="bibr">7</ref> obtained using the Stanford Chinese Word Segmenter ( <ref type="bibr" target="#b33">Tseng et al., 2005</ref>  <ref type="table">Table 6</ref>: Accuracy, precision and recall (for the content heavy class) of binary classification using proposed features to identify content-heavy sen- tences.</p><p>Parts-of-speech. POS information captures nu- merous aspects of the sentence such as the fre- quency of different classes of words used and the transition between them. Historically they are also shown to be helpful for phrase boundary detection <ref type="bibr" target="#b32">(Taylor and Black, 1998</ref>). Here, we first convert all Chinese POS tags into their corresponding uni- versal tags. We then use the percentage of each tag and tag bigram as two feature classes. To capture the transition of each phrase and clause in the sen- tence, we construct functional POS trigrams for each sentence by removing all nouns, verbs, adjec- tives, adverbs, numbers and pronouns in the sen- tence. Percentages of these sequences are used as feature values.</p><p>Comma disambiguation features. We also in- corporate most of the features proposed by <ref type="bibr" target="#b39">Xue and Yang (2011)</ref>, aggregated in the same way as the parallel method (cf. Section 5). These include: POS tags immediately before and af- ter the comma; left-and right-sibling node labels of the parent of the comma; the punctuation to- kens ordered from left to right in the sentence, whether the comma has a coordinating IP struc- ture; whether the comma's parent is a child of the root of the tree; whether there is a subordination before the comma; whether the difference in num- ber of words before and after the comma is greater than or equal to seven.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Recognizing content-heavy sentences</head><p>We train a logistic regression model as in the par- allel method in Section 5 using features illustrated above. In <ref type="table">Table 6</ref>, we show the performance of detecting heavy sentences using four systems: the baseline system using the number of words in the sentence and three systems using our full feature set, trained on MTC, OpenMT and both. The baseline performance is characterized by a remarkably poor recall. It becomes appar-  <ref type="table">Table 7</ref>: Number of segments, precision, recall and posterior probability (for the content-heavy class) for examples where at least 0-4 translators split the sentence.</p><formula xml:id="formula_1">#ref multi ≥ 0 ≥ 1 ≥ 2 ≥ 3</formula><p>ent that length alone cannot characterize content- heaviness. On the other hand, using the full fea- ture set achieves an accuracy of above 80%, a pre- cision close to 80% and a recall about 58%. The improvement in precision and recall over using or- acle full-stop commas <ref type="table">(Table 5)</ref> are about 12% and 19%. When compared with using features tuned for comma disambiguation from Xue and Yang (2011) ( <ref type="table">Table 5</ref>), our full feature set achieved a 5% increase in accuracy, about 10% increase in precision and 8% increase in recall.</p><p>We also demonstrate the usefulness of having more multi-reference translation data by compar- ing training using MTC and OpenMT individually and both. Remarkably, using only the very small dataset of OpenMT is sufficient to produce a pre- dictor that is more accurate than all of the meth- ods listed in Section 5. Adding these examples to MTC drastically improves precision by more than 13% with a less than 3% drop on recall.</p><p>Finally, we consider the portions of our test set for which at least n translators provided a multi-sentence translation (n ranges from 0 to 4). In <ref type="table">Table 7</ref> we show the respective precision, re- call and the average posterior probability from the classifier for marking a sentence as content- heavy. There is a clear trend that the classifier is more confident and has higher precision for sentences where more translators produce multi- sentence translations. Although the model is not highly confident in all groups, the precision of the predictions are remarkably high. Miss rate also decreases when more translators translate the source into multiple sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Post-hoc feature analysis</head><p>Here we identify which of the feature classes from our full set are most helpful by performing for- ward feature selection: in each iteration, the fea- ture class that improves accuracy the most is se- lected. The process is repeated until none of the re- maining feature classes lead to improvement when added to the model evaluated at the previous itera- tion. We use our test data as the evaluation set for forward selection, but we do so only to evaluate features, not to modify our system.</p><p>Five feature classes are selected using this greedy procedure. The first selected class is the typed dependencies over universal POS tags. Re- markably, this single feature class achieves 76.6% accuracy, a number already reasonably high and better than features used in <ref type="bibr" target="#b39">Xue and Yang (2011)</ref>. The second feature added is whether there is a comma of coordinating IP structure in the auto- matic parse tree of the sentence. It gives a fur- ther 1.7% increase in accuracy, showing that the comma structure provide useful information as features for detecting heavy sentences. Note that this feature does not represent full stop commas, i.e., it does not record whether the comma is un- der the root level of the parse tree. The next se- lected class is typed dependencies over universal POS tags that have an edge across commas in the sentence, with an 1% increase in accuracy. The fourth feature selected is the number of preposi- tions and postposition POS tags in the sentence, improving the accuracy about 1%. Finally, part- of-speech tags before each comma are added, with a 0.3% improvement of accuracy.</p><p>The results from forward selection analysis re- veal that the dependency structure of a sentence captures the most helpful information for heavy sentence identification. The interplay between punctuation and phrase structure gives further im- portant enhancements to the model. The final ac- curacy, precision and recall after forward selec- tion are 0.804, 0.8209, 0.5392, respectively. This overall performance shows that forward selection yields a sub-optimal feature set, suggesting that the other features are also informative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">A challenge for MT: revisited</head><p>It is important to know whether a predictor for content-heavy sentences is good at identifying challenging sentences for applications such as ma- chine translation. Here, we would like to revisit Section 4.2 and see if predicted heavy sentences are harder to translate.</p><p>For all the source sentences in OpenMT and MTC, we compare five criteria for dividing the test data in two subsets: whether the sentence contains a full-stop comma or not; whether the sentence is longer than the baseline decision tree threshold  <ref type="table">Table 8</ref>: Data portion, BLEU scores and dif- ferences for sentences with/without a full-stop comma, are/are not longer than the length thresh- old, are/are not content heavy.</p><p>(47 words) or not; whether the sentence is pre- dicted to be content-heavy with posterior proba- bility threshold of 0.5, 0.55 and 0.6. Predictions for the training portion is obtained using 10-fold cross-validation. In the same manner as <ref type="table">Table 3</ref>, <ref type="table">Table 8</ref> shows the percentage of data that satis- fies each criterion, BLEU scores of Bing transla- tions for sentences that satisfy a criterion and those that do not, as well as the difference of BLEU be- tween the two subsets (∆bleu). As reference we also include numbers listed in <ref type="table">Table 3</ref> using ora- cle content-heavy labels. First, notice that regardless of the posterior probability threshold, the numbers of sentences predicted to be content-heavy are much larger than that using the length cutoff. These sentences are also collectively translated much worse than the sentences in the other subset. Sentences that con- tain a predicted full-stop comma are also harder to translate, but show smaller difference in BLEU than when sentence heaviness or length are used as separation criterion. As the posterior probability threshold goes up and the classifier becomes more confident when it identifies heavy sentences, there is a clear trend that system translations for these sentences become worse. These BLEU score com- parisons indicate that our proposed model identi- fies sentences that pose a challenge for MT sys- tems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion and future work</head><p>In this work, we propose a cross-lingual task of detecting content-heavy sentences in Chinese, which are best translated into multiple sentences in English. We show that for such sentences, a multi-sentence translation is preferred by readers in terms of flow and understandability. Content- heavy sentences defined in this manner present practical challenges for MT systems. We further demonstrate that these sentences are not fully ex- plained by sentence length or syntactically defined full-stop commas in Chinese. We propose a clas- sification model using a rich set of features that effectively identify these sentences.</p><p>The findings in this paper point out a defi- nite issue in different languages currently under- investigated in text-to-text generation systems. One possible way to improve MT systems is to incorporate sentence simplification before trans- lation ( <ref type="bibr" target="#b23">Mishra et al., 2014</ref>). Future work could use our proposed model to detect heavy sentences that needs such pre-processing. Our findings can also inspire informative features for sentence qual- ity estimation, in which the task is to predict the sentence-level fluency <ref type="bibr" target="#b1">(Beck et al., 2014</ref>). We have shown that heavy Chinese sentences are likely to lead to hard to read, disfluent sentences in English. Another important future direction lies in text simplification. In our inspection of par- allel Wikipedia/Simple Wikipedia data <ref type="bibr" target="#b15">(Kauchak, 2013)</ref>, around 23.6% of the aligned sentences in- volve a single sentence on one side and multiple sentences on another. A similar analysis using ideas from this work can be useful in identify- ing sentences that needs simplification in the first place.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Coordinating IP structure at the root. heavy fs-comma No fs-comma N 19 180 Y 40 62</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Multiple VP structures</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Examples of Chinese sentences expressed in multiple English sentences.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Percentage of sentences for which a given 
number of translators prefer to use multiple sen-
tences in English, along with percentage of times 
a multi-sentence translation was selected as most 
fluent and comprehensible by readers. 

columns the percentage of source sentences split 
in translation by 0, 1, 2, 3 and all 4 translators. 
For about 20% of segments in OpenMT and 15% 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>)</head><label></label><figDesc></figDesc><table>Features 
Training 
A 
P 
R 

baseline MTC+OpenMT 71.43 
73.5 
24.5 
full set 
OpenMT 
76.41 66.67 60.78 
full set 
MTC 
78.41 74.03 
55.9 
full set 
MTC+OpenMT 80.73 79.73 57.84 

</table></figure>

			<note place="foot" n="1"> We did not use translator IDs as parameters in any of our systems. 2 Document IDs 41-325, 400-454, 500-554, 590-596, 600885, 900, 1001-1078, 1100-1151. 3 The Stanford segmenter (Tseng et al., 2005), parser (Levy and Manning, 2003) and the CoreNLP package (Manning et al., 2014)</note>

			<note place="foot" n="4"> For the study we exclude sentences without a comma. A χ 2 test for the strength of association between the presence of full stop commas and heavy sentence status shows high significance.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to express our gratitude to Bonnie Webber for her detailed comments on earlier ver-sions of this paper. Her encouragement and sup-port were essential in seeing the work through to publication. We would also like the reviewers for their thoughtful suggestions which we have tried to incorporate in the final version. The work was partially supported by NSF CAREER grant IIS-0953445.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards Brazilian Portuguese automatic text simplification systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">M</forename><surname>Aluísio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Thiago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erick</forename><forename type="middle">G</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renata</forename><forename type="middle">P M</forename><surname>Maziero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fortes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACM Symposium on Document Engineering (DocEng)</title>
		<meeting>the Eighth ACM Symposium on Document Engineering (DocEng)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SHEF-Lite 2.0: Sparse multi-task gaussian processes for translation quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth Workshop on Statistical Machine Translation (WMT)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chandrasekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Doran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Srinivas</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Motivations and methods for text simplification</title>
	</analytic>
	<monogr>
		<title level="m">The 16th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Chinese-English machine translation</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Statistical Machine Translation (WSMT)</title>
		<meeting>the Fourth Workshop on Statistical Machine Translation (WSMT)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Discriminative reordering with Chinese grammatical relations features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihsin</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation (SSST)</title>
		<meeting>the Third Workshop on Syntax and Structure in Statistical Translation (SSST)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to simplify sentences using Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Coster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kauchak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Monolingual Text-To-Text Generation</title>
		<meeting>the Workshop on Monolingual Text-To-Text Generation</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Text simplification for children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">De</forename><surname>Belder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Prroceedings of the SIGIR workshop on accessible search systems</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Applying the semantics of negation to SMT through n-best list re-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Fancellu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">NIST 2008-2012 Open Machine Translation (OpenMT) Progress Test Sets LDC2013T07. Web Download</title>
	</analytic>
	<monogr>
		<title level="m">Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>NIST Multimodal Information Group</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multiple-Translation Chinese Corpus LDC2002T01. Web Download</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shudong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multiple-Translation Chinese (MTC) Part 2 LDC2003T17. Web Download</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shudong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improving Chinese-English patent machine translation using sentence segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaohong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiying</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering</title>
		<meeting>the 6th International Conference on Natural Language Processing and Knowledge Engineering</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>NLP-KE</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Segmentation of Chinese long sentences using commas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meixun</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mi-Young</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongil</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghyeok</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third SIGHAN Workshop on Chinese Language Processing (SIGHAN)</title>
		<meeting>the Third SIGHAN Workshop on Chinese Language Processing (SIGHAN)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving text simplification language modeling using unsimplified text data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kauchak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Is it harder to parse Chinese, or the Chinese Treebank?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast and accurate prediction of sentence specificity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessy</forename><surname>Junyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the Twenty-Ninth Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2015-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A hierarchical parsing approach with punctuation processing for long Chinese sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rile</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Joint Conference on Natural Language Processing (IJNLP): Companion Volume including Posters/Demos and Tutorial Abstracts</title>
		<meeting>the Second International Joint Conference on Natural Language Processing (IJNLP): Companion Volume including Posters/Demos and Tutorial Abstracts</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Assessing the discourse factors that influence the quality of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyi Jessy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL): Short Papers</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL): Short Papers</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiple-Translation Chinese (MTC) Part 3 LDC2004T07. Web Download</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multiple-Translation Chinese (MTC) Part 4 LDC2006T04. Web Download</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics (ACL): System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics (ACL): System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Exploring the effects of sentence simplification on Hindi to English machine translation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitij</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankush</forename><surname>Soni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipti</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Automatic Text Simplification-Methods and Applications in the Multilingual Society</title>
		<meeting>the Workshop on Automatic Text Simplification-Methods and Applications in the Multilingual Society</meeting>
		<imprint>
			<publisher>ATS-MA</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hybrid simplification using deep semantics and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Instance-based sentence boundary determination by optimization for natural language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the Eight International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Applied text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanya</forename><surname>Korelsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Applied Natural Language Processing</title>
		<meeting>the Third Conference on Applied Natural Language Processing</meeting>
		<imprint>
			<publisher>ANLP</publisher>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Syntactic simplification and text cohesion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research on Language and Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="109" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A survey of research on text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Applied Linguistics</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page" from="259" to="298" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Translating from complex to simplified sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Computational Processing of the Portuguese Language</title>
		<meeting>the 9th International Conference on Computational Processing of the Portuguese Language</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Trainable sentence planning for complex information presentations in spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Stent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prassad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Assigning phrase breaks from part-of-speech sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech and Language</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="99" to="117" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A conditional random field word segmenter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihsin</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pichuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galen</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Prroceedings of the Fourth SIGHAN Workshop on Chinese Language Processing</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Spot: A trainable sentence planner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Rogati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<meeting>the Second Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to simplify sentences with quasi-synchronous grammar and integer programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Woodsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sentence simplification by monolingual machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sander Wubben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krahmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Automatic alignment of English-Chinese bilingual texts of CNS news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghua</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chew Lim Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Chinese Computing</title>
		<meeting>International Conference on Chinese Computing</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Sentence segmentation using IBM word alignment model 1</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Annual Conference of the European Association for Machine Translation (EAMT)</title>
		<meeting>the 10th Annual Conference of the European Association for Machine Translation (EAMT)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Chinese sentence segmentation as comma classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqin</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT): Short Papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT): Short Papers</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The Penn Chinese TreeBank: Phrase structure annotation of a large corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Dong</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="238" />
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Chinese comma disambiguation for discourse analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Chinese complex long sentences processing method for Chinese-Japanese machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuji</forename><surname>Dapeng Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peilin</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shingo</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuroiwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Natural Language Processing and Knowledge Engineering</title>
		<meeting>the International Conference on Natural Language Processing and Knowledge Engineering</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>NLP-KE</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A monolingual tree-based translation model for sentence simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhemin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delphine</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 23rd International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
