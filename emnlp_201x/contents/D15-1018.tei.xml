<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Prediction for Entity/Event-Level Sentiment Analysis using Probabilistic Soft Logic Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Deng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Intelligent Systems Program</orgName>
								<orgName type="department" key="dep2">Intelligent Systems Program Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">University of Pittsburgh</orgName>
								<orgName type="institution" key="instit2">University of Pittsburgh</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
							<email>wiebe@cs.pitt.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Intelligent Systems Program</orgName>
								<orgName type="department" key="dep2">Intelligent Systems Program Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">University of Pittsburgh</orgName>
								<orgName type="institution" key="instit2">University of Pittsburgh</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Joint Prediction for Entity/Event-Level Sentiment Analysis using Probabilistic Soft Logic Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this work, we build an entity/event-level sentiment analysis system, which is able to recognize and infer both explicit and implicit sentiments toward entities and events in the text. We design Probabilistic Soft Logic models that integrate explicit sentiments , inference rules, and +/-effect event information (events that positively or negatively affect entities). The experiments show that the method is able to greatly improve over baseline accuracies in recognizing entity/event-level sentiments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There are increasing numbers of opinions ex- pressed in various genres, including reviews, newswire, editorials, and forums. While much early work was at the document or sentence level, to fully understand and utilize opinions, re- searchers are increasingly carrying out more fine- grained sentiment analysis to extract components of opinion frames: the source (whose sentiment is it), the polarity, and the target (what is the senti- ment toward). Much fine-grained analysis is span or aspect based <ref type="bibr" target="#b29">(Yang and Cardie, 2014;</ref><ref type="bibr" target="#b17">Pontiki et al., 2014</ref>). In contrast, this work contributes to entity/event-level sentiment analysis. A sys- tem that could recognize sentiments toward enti- ties and events would be valuable in an application such as Automatic Question Answering, to sup- port answering questions such as "Who is nega- tive/positive toward X?" ( <ref type="bibr" target="#b22">Stoyanov et al., 2005</ref>), where X could be any entity or event.</p><p>Let us consider an example from the MPQA opinion annotated corpus ( <ref type="bibr" target="#b25">Wiebe et al., 2005a;</ref><ref type="bibr" target="#b27">Wilson, 2007;</ref><ref type="bibr" target="#b6">Deng and Wiebe, 2015)</ref>. <ref type="bibr">Ex(1)</ref> When the Imam ( may God be satisfied with him 1 ) issued the fatwa against 2 Salman Rushdie for insulting 3 the Prophet ( peace be upon him 4 ), the countries that are so-called 5 supporters of human rights protested against 6 the fatwa.</p><p>There are several sentiment expressions anno- tated in MPQA. In the first clause, the writer is positive toward Imam and Prophet as expressed by may God be satisfied with him (1) and peace be upon him (4), respectively. Imam is negative toward Salman Rushdie and the insulting event, as revealed by the expression issued the fatwa against (2). And Salman Rushdie is negative to- ward Prophet, as revealed by the expression insult- ing (3). In the second clause, the writer is negative toward the countries, as expressed by so-called (5). And the countries are negative toward fatwa, as revealed by the expression protested against (6). Using the source and the target, we summa- rize the positive opinions above in a set P , and the negative opinions above in another set N . Thus, P contains {(writer, Imam), (writer, Prophet)}, and N contains {(Imam, Rushdie), (Imam, insulting), (Rushdie, Prophet), (writer, countries), (countries, fatwa)}. <ref type="bibr">1</ref> An (ideal) explicit sentiment analysis system is expected to extract the above sentiments expressed by (1)-(6). However, there are many more sen- timents communicated by the writer but not ex- pressed via explicit expressions. First, Imam is positive toward the Prophet, because Rushdie in- sults the Prophet and Imam is angry that he does so. Second, the writer is negative toward Rushdie, because the writer is positive toward the Prophet but Rushdie insults him! Also, the writer is prob- ably positive toward the fatwa since it is against Rushdie. Third, the countries are probably nega- tive toward Imam, because the countries are neg- ative toward fatwa and it is Imam who issued the fatwa. Thus, the set P should also contain {(Imam, Prophet), (writer, fatwa)}, and the set N should also contain {(writer, Rushdie), (coun- tries, Imam)}. These opinions are not directly ex- pressed, but are inferred by a human reader. <ref type="bibr">2</ref> The explicit and implicit sentiments are summarized in <ref type="figure" target="#fig_0">Figure 1</ref>, where each green line represents a posi- tive sentiment and each red line represents a neg- ative sentiment. The solid lines are explicit senti- ments and the dashed lines are implicit sentiments.</p><p>In this work, we detect sentiments such as those in P and N , where the sources are entities (or the writer) and the targets are entities and events.</p><p>Previous work in sentiment analysis mainly fo- cuses on detecting explicit opinions. Recently there is emerging focus on sentiment inference, which recognizes implicit sentiments by inferring them from explicit sentiments via inference rules. Current works in sentiment inference differ on how the sentiment inference rules are defined and how they are expressed. For example, Zhang and Liu (2011) define linguistic templates to rec- ognize phrases that express implicit sentiments, while previously we ) represent a few simple rules as (in)equality constraints in In- teger Linear Programming. In contrast to previous work, we propose a more general set of inference rules and encode them in a probabilistic soft logic (PSL) framework ( <ref type="bibr" target="#b1">Bach et al., 2015)</ref>. We chose PSL because it is designed to have efficient infer- ence and, as similar methods in Statistical Rela- tional Learning do, it allows probabilistic models to be specified in first-order logic, an expressive and natural way to represent if-then rules, and it supports joint prediction. Joint prediction is criti- cal for our task because it involves multiple, mutu- ally constraining ambiguities (the source, polarity, and target).</p><p>Thus, this work aims at detecting both implicit and explicit sentiments expressed by an entity to- ward another entity/event (i.e., an eTarget) within the sentence. The contributions of this work are: (1) defining a method for entity/event-level senti- ment analysis to provide a deeper understanding of the text; (2) exploiting first-order logic rules to infer such sentiments, where the source is not lim- ited to the writer, and the target may be any entity, event, or even another sentiment; and (3) devel- oping a PSL model to jointly resolve explicit and implicit sentiment ambiguities by integrating in- ference rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Fined-grained sentiment analysis. Most fine- grained sentiment analysis is span or aspect based. Previous work differs from the entity/event-level sentiment analysis task we address in terms of tar- gets and sources. In terms of targets, in a span- based sentiment analysis system, the target is a span instead of the exact head of the phrase re- ferring to the target. The target in a span-based system is evaluated by measuring the overlapping proportion of an extracted span against the gold standard phrase <ref type="bibr" target="#b28">(Yang and Cardie, 2013)</ref>, while the eTarget in an entity/event-level system is eval- uated against the exact word (i.e., head of NP/VP) in the gold standard. It is a stricter evaluation. While the targets in aspect-based sentiment analy- sis are often entity targets, they are mainly product aspects, which are a predefined set. <ref type="bibr">3</ref> In contrast, the target in the entity/event-level task may be any noun or verb. In terms of sources, previous work in sentiment analysis trained on review data assumes that the source is the writer of the review ( <ref type="bibr" target="#b11">Hu and Liu, 2004;</ref><ref type="bibr" target="#b23">Titov and McDonald, 2008)</ref>.</p><p>Our work is rare in that it allows sources other than the writer and finds sentiments toward eTar- gets which may be any entity or event.</p><p>Sentiment Inference. There is some recent work investigating features that directly indicate implicit sentiments ( <ref type="bibr" target="#b30">Zhang and Liu, 2011;</ref><ref type="bibr" target="#b9">Feng et al., 2013)</ref>. That work assumes the source is only the writer. Further, as it uses features to di- rectly extract implicit sentiments, it does not per- form general sentiment inference.</p><p>Previously, we <ref type="bibr" target="#b7">(Deng et al., 2013;</ref>) develop rules and models to infer sentiments related to +/-effect events, events that positively or negatively affect entities. That work assumes that the source is only the writer, and the targets are limited to entities that participate in +/-effect events. Further, our previous models all require certain manual (ora- cle) annotations to be input. In this work we use an expanded set of more general rules. We al- low sources other than the writer, and targets that may be any entity or event. In fact, under our new rules, the targets of sentiments may be other sen- timents; we model such novel "sentiment toward sentiment" structures in Section 4.3. Finally, our method requiring no manual annotations as input when the inference is conducted.</p><p>Previously, we also propose a set of sentiment inference rules and develop a rule-based system to infer sentiments ). How- ever, the rule-based system requires all informa- tion regarding explicit sentiments and +/-effect events to be provided as oracle information by manual annotations.</p><p>Probabilistic Soft Logic. Probabilistic Soft Logic (PSL) is a variation of Markov Logic Net- works, which is a framework for probabilistic logic that employs weighted formulas in first- order logic to compactly encode complex undi- rected probabilistic graphical models (i.e., Markov networks) ( <ref type="bibr" target="#b1">Bach et al., 2015;</ref><ref type="bibr" target="#b2">Beltagy et al., 2014</ref>). PSL is a new statistical relational learning method that has been applied to many NLP and other ma- chine learning tasks in recent years ( <ref type="bibr" target="#b2">Beltagy et al., 2014;</ref><ref type="bibr" target="#b14">London et al., 2013;</ref><ref type="bibr" target="#b18">Pujara et al., 2013;</ref><ref type="bibr" target="#b16">Memory et al., 2012</ref>). Previously, PSL has not been applied to entity/event-level sentiment analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Definition</head><p>In this section, we introduce the definition of the entity/event-level sentiment analysis task, fol- lowed by a description of the gold standard corpus.</p><p>For each sentence s, we define a set E consist- ing of entities, events, and the writer of s, and sets P and N consisting of positive and negative senti- ments, respectively. Each element in P is a tuple, representing a positive pair of two entities, (e 1 , e 2 ) where e 1 , e 2 ∈ E, and e 1 is positive toward e 2 . A positive pair (e 1 ,e 2 ) aggregates all the posi- tive sentiments from e 1 to e 2 in the sentence. N is the corresponding set for negative pairs.</p><p>The goal of this work is to automatically rec- ognize a set of positive pairs (P auto ) and a set of negative pairs (N auto ). We compare the system output (P auto ∪ N auto ) against the gold standard (P gold ∪ N gold ) for each sentence.  <ref type="bibr" target="#b27">Wilson, 2007)</ref>, which includes editorials, reviews, news reports, and scripts of interviews from different news agen- cies, and covers a wide range of topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Gold Standard</head><p>In both MPQA 2.0 and 3.0, the top-level an- notations include direct subjectives (DS). Each DS has a nested-source annotation. Each DS has one or more attitude links, meaning that all of the attitudes share the same nested source. The at- titudes differ from one another in their attitude types, polarities, and/or targets. Moreover, both corpora contain expressive subjective element (ESE) annotations, which pinpoint specific ex- pressions used to express subjectivity. We ignore neutral ESEs and only consider ESEs whose po- larity is positive or negative.</p><p>MPQA 2.0 and 3.0 differ in their target annota- tions. In 2.0, each target is a span. A target annota- tion of an opinion captures the most important tar- get this opinion is expressed toward. Since the ex- act boundaries of the spans are hard to define even for human annotators ( <ref type="bibr" target="#b25">Wiebe et al., 2005a;</ref><ref type="bibr" target="#b28">Yang and Cardie, 2013)</ref>, the target span in MPQA 2.0 could be a single word, an NP or VP, or a text span covering more than one constituent. In contrast, in MPQA 3.0, each target is anchored to the head of an NP or VP, which is a single word. It is called an eTarget since it is an entity or an event. In MPQA 2.0, only attitudes have target-span annotations. In MPQA 3.0, both attitudes and ESEs have eTarget annotations. Importantly, the eTargets include the targets of both explicit and implicit sentiments.</p><p>Recall Ex(1) in Section 1. P gold = {(writer, Imam), (writer, Prophet), (Imam, Prophet), (writer, fatwa)}, and N gold = {(Imam, Rushdie), (Imam, insulting), (Rushdie, Prophet), (writer, countries), (countries, fatwa), (writer, Rushdie), (countries, Imam)}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PSL for Sentiment Analysis</head><p>We need to resolve three components for an opin- ion frame: the source, the polarity, and the eTarget. Each of these ambiguities has several candidates. For example in Ex(1), the eTarget of the opinion expression insulting is an ambiguity. The candi- dates include Prophet, countries, and so on.</p><p>In this work, we use Probabilistic Soft Logic (PSL). A PSL model is defined using a set of atoms to be grounded, and a set of weighted if- then rules expressed in first-order logic. For ex- ample, we define the atom ETARGET(y,t) to rep- resent an opinion y having eTarget t. If y and t are constants, then ETARGET(y,t) is a ground atom (e.g., ETARGET(insulting, Prophet)). Each ground atom is assigned a score by a local system. PSL takes as input all the local scores as well as the constraints defined by the rules among atoms, so that it is able to jointly resolve all the ambigu- ities. In the final output, for example, the score ETARGET(insulting, Prophet) &gt; 0 means that PSL considers Prophet to be an eTarget of insulting, while ETARGET(insulting, countries) = 0 means that PSL does not consider countries to be an eTar- get of insulting.</p><p>In this section, we first introduce PSL in Section 4.1. We then present three PSL models in turn. PSL1 (Section 4.2) aggregates span-based opin- ions into P auto and N auto . PSL2 (Section 4.3) adds sentiment inference rules to PSL1. For PSL3 (Sec- tion 4.4), rules involving +/-effect events are added to PSL2, resulting in the richest overall model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Probabilistic Soft Logic</head><p>PSL ( <ref type="bibr" target="#b1">Bach et al., 2015</ref>) uses logical representa- tions to compactly define large graphical models with continuous variables, and includes methods for performing efficient probabilistic inference for the resulting models ( <ref type="bibr" target="#b2">Beltagy et al., 2014</ref>). As mentioned above, a PSL model is defined using a set of atoms to be grounded, and a set of weighted if-then rules in first-order logic. For example, friend(x,y) ∧ votesFor(y,z) ⇒ votesFor(x,z) means that a person may vote for the same per- son as his/her friend. Each predicate in the rule is an atom (e.g., friend(x,y)). A ground atom is pro- duced by replacing variables with constants (e.g., friend(Tom, Mary)). Each rule is associated with a weight, indicating the importance of this rule in the whole rule set.</p><p>A key distinguishing feature of PSL is that each ground atom a has a soft, continuous truth value in the interval <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>, denoted as I(a), rather than a binary truth value as in Markov Logic Net- works and most other probabilistic logic frame- works ( <ref type="bibr" target="#b2">Beltagy et al., 2014</ref>). To compute soft truth values for logical formulas, Lukasiewicz re- laxations are used:</p><formula xml:id="formula_0">l 1 ∧ l 2 = max{0, I(l 1 ) + I(l 2 ) − 1} l 1 ∨ l 2 = min{I(l 1 ) + I(l 2 ), 1} ¬l 1 = 1 − I(l 1 )</formula><p>A rule r ≡ r body → r head , is satisfied (i.e. I(r) = 1) iff I(r body ) ≤ I(r head ). Other- wise, a distance to satisfaction d(r) is calculated, which defines how far a rule r is from being satis- fied: d(r) = max {0, I(r body ) − I(r head )}. Us- ing d(r), PSL defines a probability distribution over all possible interpretations I of all ground atoms:</p><formula xml:id="formula_1">p(I) = 1 Z exp {−1 * r∈R λ r (d(r)) p }</formula><p>where Z is the normalization constant, λ r is the weight of rule r, R is the set of all rules, and p de- fines loss functions. PSL seeks the interpretation with the minimum distance d(r) and which satis- fies all rules to the extent possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">PSL for Sentiment Aggregation (PSL1)</head><p>The first PSL model, PSL1, aggregates span-based opinions into P auto and N auto . We call this senti- ment aggregation because, instead of building an entity/event-level sentiment system from scratch, we choose to fully utilize previous work on span- based sentiment analysis. PSL1 aggregates span- based opinions into entity/event-level opinions. Consistent with the task definition in Section 3, we define two atoms in PSL: (1) POSPAIR(s,t): a positive pair from s toward t (2) NEGPAIR(s,t): a negative pair from s toward t Both s and t are chosen from the set E. The val- ues of ground atoms <ref type="formula">(1)</ref> and <ref type="formula">(2)</ref> are not observed and are inferred by PSL.</p><p>Then, we define atoms to model an entity/event- level opinion: (3) POS(y): y is a positive sentiment <ref type="figure">(ETARGET(y,t)</ref>), but also represents the aggregated sentiments among enti- ties and events (POSPAIR(s,t) and NEGPAIR(s,t)) in the sentence.</p><note type="other">(4) NEG(y): y is a negative sentiment (5) SOURCE(y,s): the source of y is s (6) ETARGET(y,t): the eTarget of y is t Two rules are defined to aggregate various opin- ions extracted by span-based systems into positive pairs and negative pairs, shown in Part 1 of Table 1 as Rules 1.1 and 1.2. Thus, under our repre- sentation, the PSL model not only finds a set of eTargets of an opinion</note><p>Next, we turn to assigning local scores to ground atoms (3)-(6).</p><p>POS(y) and NEG(y): We build upon three span- based sentiment analysis systems. The first, S1 <ref type="bibr" target="#b28">(Yang and Cardie, 2013)</ref>, and the second, S2 <ref type="bibr" target="#b29">(Yang and Cardie, 2014</ref>), are both trained on MPQA 2.0, which does not contain any eTarget annotations. S1 extracts triples of source span, opinion span, target span, but does not extract opinion polarities. S2 extracts opinion spans and opinion polarities, but it does not extract sources or targets. The third system, S3 <ref type="bibr">(Socher et al., 2013)</ref>, is trained on movie review data. It extracts opinion spans and polarities. The source is always assumed to be the writer.</p><p>We take the union set of opinions extracted by S1, S2 and S3. For each opinion y, a ground atom is created, depending on the polarity (POS(y) if y is positive and NEG(y) is y is negative). The po- larity is determined as follows. If S2 assigns a po- larity to y, then that polarity is used. If S3 but not S2 assigns a polarity to y, then S3's polarity is used. In both cases, the score assigned to the ground atom is 1.0. If neither S2 nor S3 assigns a polarity to y, we use the MPQA subjectivity lex- icon to determine its polarity. The score assigned to the ground atom is the proportion of the words in the opinion span that are included in the subjec- tivity lexicon. SOURCE(y,s): S1 extracts the source of each opinion, S2 does not extract the source, and S3 as- sumes the source is always the writer. Thus, for an opinion y, if the source s is assigned by S1, a ground atom SOURCE(y,s) is created with score 1.0. Otherwise, if S3 extracts opinion y, a ground atom SOURCE(y,writer) is created with score 1.0 (since S3 assumes the source is always the writer). Otherwise, we run the Stanford named entity rec- ognizer ( <ref type="bibr" target="#b15">Manning et al., 2014;</ref><ref type="bibr" target="#b10">Finkel et al., 2005</ref>) to extract named entities in the sentence. The near- est named entity to the opinion span on the depen- dency parse graph will be treated as the source. The score is the reciprocal of the length of the path between the opinion span and the source span in the dependency parse.</p><p>ETARGET(y,t): Though each eTarget is an en- tity or event, it is difficult to determine which nouns and verbs should be considered. Taking into consideration the trade-off between precision and recall, we experimented with three methods to select eTarget candidates. For each opinion y, a ground atom ETARGET(y,t) is created for each eTarget candidate t.</p><p>ET1 considers all the nouns and verbs in the sentence, to provide a full recall of eTargets.</p><p>ET2 considers all the nouns and verbs in the tar- get spans and opinion spans that are automatically extracted by systems S1, S2 and S3. We hypoth- esized that ET2 would be useful because most of the eTargets in MPQA 3.0 appear within the opin- ion or the target spans of MPQA 2.0.</p><p>ET3 considers the heads of the target and opin- ion spans that are automatically extracted by sys- tems S1, S2 and S3. 5 ET3 also considers the heads of siblings of target spans and opinion spans. Among the three methods, ET3 has the lowest re- call but the highest precision.</p><p>In addition, for the eTarget candidate set ex- tracted by ET2, or ET3, we run the Stanford co- reference system <ref type="bibr" target="#b15">(Manning et al., 2014;</ref><ref type="bibr" target="#b19">Recasens et al., 2013;</ref><ref type="bibr" target="#b13">Lee et al., 2013</ref>) to expand the set in two ways. First, for each eTarget candidate t, the co-reference system extracts the entities that co-refer with t. We add the referring entities into the candidate set. Second, the co-reference system extracts words which the Stanford system judges to be entities, regardless of whether they have any referent or not. We add this set of entities to the candidate set as well.</p><p>We train an SVM classifier <ref type="bibr" target="#b4">(Cortes and Vapnik, 1995)</ref> to assign a score to the ground atom ETARGET(y,t). Syntactic features describing the Part 1. Aggregation Rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">SOURCE(y,s) ∧ ETARGET(y,t) ∧ POS(y) ⇒ POSPAIR(s,t) 1.2 SOURCE(y,s) ∧ ETARGET(y,t) ∧ NEG(y) ⇒ NEGPAIR(s,t) Part 2. Inference Rules. 2.1 POSPAIR(s 1 ,y 2 ) ∧ SOURCE(y 2 ,s 2 ) ⇒ POSPAIR(s 1 ,s 2 ) 2.2 POSPAIR(s 1 ,y 2 ) ∧ ETARGET(y 2 ,t 2 ) ∧ POS(y 2 ) ⇒ POSPAIR(s 1 ,t 2 ) 2.3 POSPAIR(s 1 ,y 2 ) ∧ ETARGET(y 2 ,t 2 ) ∧ NEG(y 2 ) ⇒ NEGPAIR(s 1 ,t 2 ) 2.4</head><p>NEGPAIR(s 1 ,y 2 ) ∧ SOURCE(y 2 ,s 2 ) ⇒ NEGPAIR(s 1 ,s 2 ) 2.5 NEGPAIR(s 1 ,y 2 ) ∧ ETARGET(y 2 ,t 2 ) ∧ POS(y 2 ) ⇒ NEGPAIR(s 1 ,t 2 ) 2.6 NEGPAIR(s 1 ,y 2 ) ∧ ETARGET(y 2 ,t 2 ) ∧ NEG(y 2 ) ⇒ POSPAIR(s 1 ,t 2 ) Part 3. Inference Rules w.r.t +/-Effect Event Information.</p><p>3 relations between an eTarget and the extracted opinion span and target span are considered, in- cluding: (1) whether the eTarget is in the opin- ion/target span; (2) the unigrams and bigrams on the path from the eTarget to the opinion/target span in the constituency parse tree; and (3) the unigrams and bigrams on the path from the eTar- get to the opinion/target word in the dependency parse graph. We normalize the SVM scores into the range of a ground atom score, [0,1].</p><formula xml:id="formula_2">.1 POSPAIR(s,x) ∧ AGENT(x,a) ⇒ POSPAIR(s,a) 3.2 POSPAIR(s,x) ∧ THEME(x,h) ∧ +EFFECT(x) ⇒ POSPAIR(s,h) 3.3 POSPAIR(s,x) ∧ THEME(x,h) ∧ -EFFECT(x) ⇒ NEGPAIR(s,h) 3.4 NEGPAIR(s,x) ∧ AGENT(x,a) ⇒ NEGPAIR(s,a) 3.5 NEGPAIR(s,x) ∧ THEME(x,h) ∧ +EFFECT(x) ⇒ NEGPAIR(s,h) 3.6 NEGPAIR(s,x) ∧ THEME(x,h) ∧ -EFFECT(x) ⇒ POSPAIR(s,h) 3.7 POSPAIR(s,a) ∧ AGENT(x,a) ⇒ POSPAIR(s,x) 3.8 POSPAIR(s,h) ∧ THEME(x,h) ∧ +EFFECT(x) ⇒ POSPAIR(s,x) 3.9 POSPAIR(s,h) ∧ THEME(x,h) ∧ -EFFECT(x) ⇒ NEGPAIR(s,x) 3.10 NEGPAIR(s,a) ∧ AGENT(x,a) ⇒ NEGPAIR(s,x) 3.11 NEGPAIR(s,h) ∧ THEME(x,h) ∧ +EFFECT(x) ⇒ NEGPAIR(s,x) 3.12 NEGPAIR(s,h) ∧ THEME(x,h) ∧ -EFFECT(x) ⇒ POSPAIR(s,x)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">PSL for Sentiment Inference (PSL2)</head><p>The two rules defined in Section 4.2 aggregate various opinions into positive pairs and negative pairs, but inferences have not yet been introduced. PSL2 is defined using the atoms and rules in PSL1. But it also includes some rules defined in , represented here in first-order logic in Part 2 of The inference rules in Part 2 of <ref type="table" target="#tab_0">Table 1</ref> are novel in that eTargets may be sentiments (e.g., NEG- PAIR(Imam,insulting) means that Imam is nega- tive toward the negative sentiment revealed by in- sulting). The inference rules link sentiments to sentiments and, transitively, link entities to entities (e.g., from Imam to Rushdie to the Prophet).</p><p>To support such rules, more groundings of ETARGET(y,t) are created in PSL2 than in PSL1. For two opinions y 1 and y 2 , if the target span of y 1 overlaps with the opinion span of y 2 , we cre- ate ETARGET(y 1 ,y 2 ) as a ground atom represent- ing that y 2 is an eTarget of y 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">PSL Augmented with +/-Effect Events (PSL3)</head><p>Finally, for PSL3, +/-effect event atoms and rules are added to PSL2 for the inference of additional sentiments. According to <ref type="bibr" target="#b7">(Deng et al., 2013</ref>), a +effect event has positive effect on the theme (examples are help, increase, and save), and a -effect event has negative effect on the theme (examples are ob- struct, decrease, and kill). <ref type="bibr">6</ref> We define the follow- ing atoms to represent such events: (7) +EFFECT(x): x is a +effect event (8) -EFFECT(x): x is a -effect event (9) AGENT(x,a): the agent of x is a (10) THEME(x,h): the theme of x is h Next we assign scores to these ground atoms.</p><p>+EFFECT(x) and -EFFECT(x): We use the +/-effect sense-level lexicon   <ref type="bibr">7</ref> to extract the +/-effect events in each sen- tence. The score of +EFFECT(x) is the fraction of that word's senses that are +effect senses accord- ing to the lexicon, and the score of -EFFECT(x) is the fraction of that word's senses that are -effect senses according to the lexicon. If a word does not appear in the lexicon, we do not treat it as a +/- effect event, and thus assign 0 to both +EFFECT(x) and -EFFECT(x).</p><p>AGENT(x,a) and THEME(x,h): We consider all nouns in the same or in sibling constituents of a +/-effect event as potential agents or themes. An SVM classifier is run to assign scores to AGENT(x,a), and another SVM classifier is run to assign scores to THEME(x,h). Both SVM clas- sifiers are trained on a separate corpus, the +/- effect corpus <ref type="bibr" target="#b7">(Deng et al., 2013</ref>) used in , which is annotated with +/-effect event, agent, and theme spans. The features we use to train the agent and theme classifier include uni- gram, bigram and syntax information.</p><p>Generalizations of the inference rules used in ( ) are expressed in first-order logic, shown in Part 3 of <ref type="table" target="#tab_0">Table 1</ref>. Let us go through an example inference for Ex(1), in partic- ular, the inference that the countries are negative toward Imam. Recall that we infer this because the countries are negative toward the fatwa and it is Imam who issued the fatwa. The rules support- ing this inference are Rules 3.11 and 3.4 in <ref type="table">Table   6</ref> In <ref type="bibr" target="#b7">(Deng et al., 2013)</ref>, such events are called good- For/badFor events; they are later renamed as +/-effect events. <ref type="bibr">7</ref> Available at: http://mpqa.cs.pitt.edu/lexicons/effect lexicon/ 1, where s is the countries, h is the fatwa, x is the issue event, and a is Imam. The application of Rule 3.11 can be explained as follows. The countries are negative toward the fatwa, and the issue event is a +effect event with theme fatwa (the issue event is +effect for the fatwa because it creates the fatwa; creation is one type of +effect event identified in <ref type="figure" target="#fig_0">(Deng et al.,  2013)</ref>); thus, the countries are negative toward the issue event.</p><p>NEGPAIR(countries, fatwa) ∧ THEME(issue, fatwa) ∧ +EFFECT(issue) ⇒ NEGPAIR(countries, issue) .</p><p>The application of Rule 3.4 can be explained as follows. The countries are negative toward the is- sue event, and it is Imam who conducted the event; thus, the countries are negative toward Imam.</p><formula xml:id="formula_3">NEGPAIR(countries, issue) ∧ AGENT(issue, Imam) ⇒ NEGPAIR(countries, Imam) .</formula><p>Finally, to support the new inferences, more groundings of ETARGET(y,t) are defined in PSL3. For a +/-effect event x whose agent is a, if one of x and a is an eTarget candidate of y, the other will be added to the eTarget candidate set for y (senti- ments toward both +effect and -effect events and their agents have the same polarity according to the rules ( ). For +effect event x whose theme is h, if one of x and h is an eTar- get candidate of y, the other is added to the eTar- get candidate set for y (sentiments toward +effect events and their themes have the same polarity).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We carry out experiments on the MPQA 3.0 cor- pus. Currently, there are 70 documents, 1,634 sen- tences, and 1,921 DS and ESEs in total. The to- tal number of POSPAIR(s,t) and NEGPAIR(s,t) are 867 and 1,975, respectively. Though the PSL in- ference does not need supervision and the SVM classifier for agents and themes in Section 4.4 is trained on a separate corpus, we still have to train the eTarget SVM classifier to assign local scores as described in Section 4.2. Thus, the experiments are carried out using 5-fold cross validation. For each fold test set, the eTarget classifier is trained on the other folds. The trained classifier is then run on the test set, and PSL inference is carried out on the test set.</p><p>In total, we have three methods for eTarget can- didate selection (ET1, ET2, ET3) and three mod- els for sentiment analysis (PSL1, PSL2, PSL3).</p><p>Baselines. Since each noun and verb may be an eTarget, the first baseline (All NP/VP) regards all the nouns and verbs as eTargets. The first baseline estimates the difficulty of this task.</p><p>The second baseline (SVM) uses the SVM lo- cal classification results from Section 4.2. The score of ETARGET(y,t) is assigned by the SVM classifier. Then it is normalized as input into PSL. Before normalization, if the score assigned by the SVM classifier is above 0, the SVM baseline con- siders it as a correct eTarget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluations</head><p>First, we examine the performance of the PSL models on correctly recognizing eTargets of a par- ticular opinion. This evaluation is carried out on a subset of the corpus: we only examine the opinions which are automatically extracted by the span-based systems (S1, S2 and S3). If an opinion expression in the gold standard is not extracted by any span-based system, it is not input into PSL, so PSL cannot possibly find its eTargets.</p><p>The second and third evaluations assess perfor- mance of the PSL models on correctly extracting positive and negative pairs. Note that our senti- ment analysis system has the capability, through inference, to recognize positive and negative pairs even if corresponding opinion expressions are not extracted. Thus, the second and third evaluations are carried out on the entire corpus. The second evaluation uses ET3, and compares PSL1, PSL2 and PSL3. The third evaluation uses PSL3 and compares performance using ET1, ET2 and ET3. The results for the other combinations follow the same trends.</p><p>ETargets of An Opinion. According to the gold standard in Section 3.1, each opinion has a set of eTargets. But not all eTargets are equally impor- tant. Thus, our first evaluation assesses the perfor- mance of extracting the most important eTarget. As introduced in Section 3.1, a span-based target annotation of an opinion in MPQA 2.0 captures the most important target this opinion is expressed toward. Thus, the head of the target span can be considered to be the most important eTarget of an opinion. We model this as a ranking problem to compare models. For an opinion y automatically extracted by a span-based system, both the SVM baseline and PSL assign scores to ETARGET(y,t). We rank the eTargets according to the scores. Be- cause the ALL NP/VP baseline does not assign scores to the nouns and verbs, we do not compare with that baseline in this ranking experiment. We use the Precision@N evaluation metric. If the top N eTargets of an opinion contain the head of tar- get span, we consider it as a correct hit. The results are in <ref type="table" target="#tab_3">Table 2</ref>   <ref type="table" target="#tab_3">Table 2</ref> shows that SVM is poor at ranking the most important eTarget. The PSL models are much better, even PSL1, which does not include any inference rules. This shows that SVM, which only uses local features, cannot distinguish the most important eTarget from the others. But the PSL models consider all the opinions, and can rec- ognize a true negative even if it ranks high in the local results. The ability of PSL to rule out true negative candidates will be repeatedly shown in the later evaluations.</p><p>We not only evaluate the ability to recognize the most important eTarget of a particular opinion, we also evaluate the ability to extract all the eTargets of that opinion. The F-measure of SVM is 0.2043, while the F-measures of PSL1, PSL2 and PSL3 are 0.3135, 0.3239, and 0.3275, respectively. Cor- rectly recognizing all the eTargets is difficult, but all the PSL models are better than the baseline.</p><p>Positive Pairs and Negative Pairs. Now we evaluate the performance in a stricter way. We compare automatically extracted sets of sentiment pairs: P auto = {POSPAIR(s, t) &gt; 0} and N auto = {NEGPAIR(s, t) &gt; 0}, against the gold standard sets P gold and N gold . <ref type="table" target="#tab_5">Table 3</ref> shows the accura- cies using ET3. Note that higher accuracies can be achieved, as shown later. Here we use ET3 just to show the trend of results.</p><p>As shown in <ref type="table" target="#tab_5">Table 3</ref>, the low accuracy of base- line All NP/VP shows that entity/event-level sen- timent analysis is a difficult task. Even the SVM baseline does not have good accuracy. Note that the SVM baseline in <ref type="table" target="#tab_5">Table 3</ref>   ion spans, which are extracted by state-of-the- art span-based sentiment analysis systems. This shows the results from span-based sentiment anal- ysis systems do not provide enough accurate in- formation for the more fine-grained entity/event- level sentiment analysis task. In contrast, PSL1 achieves much higher accuracy than the baselines. PSL2 and PSL3, which add sentiment toward sen- timent and +/-effect event inferences, give fur- ther improvements. A reason is that SVM uses a hard constraint to cut off many eTarget candidates, while the PSL models take the scores as soft con- straints. A more critical reason is due to the definition of accuracy: (TruePositive+TrueNegative)/All. A significant benefit of using PSL is correctly recog- nizing true negative eTarget candidates and elim- inating them from the set. Interestingly, even though both PSL2 and PSL3 introduce more eTar- get candidates, both are able to recognize more true negatives and improve the accuracy.</p><p>Note that F-measure does not count true nega- tives. Precision is T P T P +F P , and recall is T P T P +F N ; neither considers true negatives (TN). As shown in <ref type="table" target="#tab_7">Table 4</ref>, the increment of PSL model over base- lines on F-measure is not as large as the increase in accuracy. Comparing PSL2 and PSL3 to PSL1, the inference rules largely increase recall but lower precision. However, the accuracy in <ref type="table" target="#tab_5">Table 3</ref> keeps growing. Thus, the biggest advantage of PSL models is to correctly rule out true negative eTar- gets. For the baselines, though the SVM baseline has higher precision, it eliminates so many eTarget candidates that the F-measure is not high.</p><p>ETarget Selection. To assess the methods for eTarget selection, we run PSL3 (the fullest PSL model) using each method in turn. The F- measures and accuracies are listed in   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This work builds upon state-of-the-art span- based sentiment analysis systems to perform entity/event-level sentiment analysis covering both explicit and implicit sentiments expressed among entities and events in text. Probabilis- tic Soft Logic models incorporating explicit senti- ments, inference rules and +/-effect event informa- tion are able to jointly disambiguate the ambigui- ties in the opinion frames and improve over base- line accuracies in recognizing entity/event-level sentiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Explicit and implicit sentiments in Ex(1).</figDesc><graphic url="image-1.png" coords="2,72.81,62.81,216.65,154.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Corpus: MPQA 3.0 MPQA 3.0 is a recently developed corpus with entity/event-level sentiment annotations (Deng and Wiebe, 2015). 4 It is built on the basis of MPQA 2.0 (Wiebe et al., 2005b;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Rules in First-Order Logic. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Let us go 
through an example inference for Ex(1), in partic-
ular, the inference that Imam is positive toward the 
Prophet. Rule 2.6 supports this inference. Recall 
the two explicit sentiments: Imam is negative to-
ward the insulting sentiment (revealed by issued 
the fatwa against), and Rushdie is negative to-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>.</head><label></label><figDesc></figDesc><table>Prec@1 Prec@3 Prec@5 
SVM 0.0370 
0.0556 
0.0820 
PSL1 0.5105 
0.6905 
0.7831 
PSL2 0.5317 
0.7486 
0.7883 
PSL3 0.5503 
0.7434 
0.8148 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Precision@N of Most Important ETarget.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>uses ET3. The base- line classifies the heads of target spans and opin-</figDesc><table>POSPAIR NEGPAIR 
All NP/VP 
0.1280 
0.1654 
SVM 
0.0765 
0.0670 
PSL1 
0.3356 
0.3754 
PSL2 
0.3705 
0.3705 
PSL3 
0.4315 
0.3892 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Accuracy comparing PSL models (ET3 
used for all) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table>The 
F-measure of ET1 is slightly lower than the F-
measures of ET2 and ET3, while the accuracy of 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>F-measure comparing PSL models (ET3 
used for all) 

ET1 is much better than the accuracies of ET2 
and ET3. Again, this is because PSL recognizes 
true negatives in the eTarget candidates. Since 
ET1 considers more eTarget candidates, ET1 gives 
PSL a greater opportunity to remove true nega-
tives, leading to an overall increase in accuracy. 

POSPAIR 
NEGPAIR 
F 
Acc. 
F 
Acc. 
ET1 0.2192 0.4963 0.3157 0.4461 
ET2 0.2374 0.4433 0.3261 0.3969 
ET3 0.2256 0.4315 0.3295 0.3892 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Comparison of eTarget selection methods 
(PSL3 used for all) 

</table></figure>

			<note place="foot" n="1"> Sources in MPQA are nested, having the form writer or writer, S1,. .. , Sn. This work only deals with the rightmost source, writer or Sn. Also, actions like issuing a fatwa are treated the same as private states. Please see (Wiebe et al., 2005a).</note>

			<note place="foot" n="2"> Note that the inferences are conversational implicatures; they are defeasible and may not go through in context (Deng et al., 2014; Wiebe and Deng, 2014).</note>

			<note place="foot" n="3"> As stated in SemEval-2014: &quot;we annotate only aspect terms naming particular aspects&quot;.</note>

			<note place="foot" n="4"> Available at http://mpqa.cs.pitt.edu/corpora/</note>

			<note place="foot" n="5"> The head of a phrase is extracted by the Collins head finder in the Stanford parser (Manning et al., 2014).</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning latent groups with hinge-loss markov random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Inferning: ICML Workshop on Interactions between Inference and Learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><surname>Broecheler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Getoor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.04406</idno>
		<title level="m">Hinge-loss markov random fields and probabilistic soft logic</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>cs.LG</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Probabilistic soft logic for semantic textual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Islam Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1210" to="1219" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">+/effectwordnet: Sense-level lexicon acquisition for opinion inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonjung</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="1181" to="1191" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Supportvector networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sentiment propagation via implicature constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-04" />
			<biblScope unit="page" from="377" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mpqa 3.0: An entity/event-level sentiment corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="1323" to="1328" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Benefactive/malefactive event and writer attitude annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonjung</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>ACL 2013</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Joint inference and disambiguation of implicit sentiments via implicature constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonjung</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="79" to="88" />
		</imprint>
		<respStmt>
			<orgName>August. Dublin City University and Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Connotation lexicon: A dash of sentiment beneath the surface meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><forename type="middle">Sak</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Polina</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A flexible framework for probabilistic models of social trust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelika</forename><surname>Kimmig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Golbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Computing, Behavioral-Cultural Modeling and Prediction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="265" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deterministic coreference resolution based on entity-centric, precision-ranked rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Peirsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="885" to="916" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Collective activity detection using hinge-loss Markov random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameh</forename><surname>Khamis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop on Structured Prediction: Tractability, Learning and Inference</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Graph summarization in annotated data using probabilistic soft logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Memory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelika</forename><surname>Kimmig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louiqa</forename><surname>Raschid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Uncertainty Reasoning for the Semantic Web</title>
		<meeting>the 8th International Workshop on Uncertainty Reasoning for the Semantic Web</meeting>
		<imprint>
			<publisher>URSW</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">900</biblScope>
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 4: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dimitrios Galanis, Ion Androutsopoulos, John Pavlopoulos, and Suresh Manandhar</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="27" to="35" />
		</imprint>
	</monogr>
	<note>Proceedings of the 8th International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Knowledge graph identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web-ISWC 2013</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="542" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The life and death of discourse entities: Identifying singleton mentions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="627" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">188</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-Perspective Question Answering using the OpQA corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technologies Conference/Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP-2005)</title>
		<meeting>the Human Language Technologies Conference/Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP-2005)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="923" to="930" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A joint model of text and aspect ratings for sentiment summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="308" to="316" />
		</imprint>
	</monogr>
<note type="report_type">Citeseer</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>An account of opinion implicatures. arXiv, 1404.6491[cs.CL</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Annotating expressions of opinions and emotions in language ann</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="164" to="210" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Fine-grained Subjectivity and Sentiment Analysis: Recognizing the Intensity, Polarity, and Attitudes of private states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>Intelligent Systems Program, University of Pittsburgh</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Joint inference for fine-grained opinion extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1640" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Context-aware learning for sentence-level sentiment analysis with posterior regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Identifying noun product features that imply opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="575" to="580" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
