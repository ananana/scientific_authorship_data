<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Context and Copying in Neural Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Knowles</surname></persName>
							<email>rknowles@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept. of Computer Science</orgName>
								<orgName type="institution" key="instit1">Johns Hopkins University</orgName>
								<orgName type="institution" key="instit2">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept. of Computer Science</orgName>
								<orgName type="institution" key="instit1">Johns Hopkins University</orgName>
								<orgName type="institution" key="instit2">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Context and Copying in Neural Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3034" to="3041"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3034</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Neural machine translation systems with sub-word vocabularies are capable of translating or copying unknown words. In this work, we show that they learn to copy words based on both the context in which the words appear as well as features of the words themselves. In contexts that are particularly copy-prone, they even copy words that they have already learned they should translate. We examine the influence of context and subword features on this and other types of copying behavior.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In translation, certain tokens -often names and numbers -should be copied from the source sen- tence to the target sentence. Word copying is fairly straightforward in phrase-based statistical machine translation, where unknown words can be left untranslated (copied to the target). It poses more of a challenge in neural machine transla- tion systems, which often use limited or subword vocabularies and soft attention rather than strict alignment. This has resulted in a variety of ap- proaches to copying, which make use of pre-/post- processing and/or network modifications (e.g. ex- plicit switching between generation and copying).</p><p>Neural machine translation models that use sub- word vocabularies to perform open-vocabulary translation have been observed to correctly trans- late unknown words or copy words (one subword at a time, if need be) even when the full word to be translated or copied was not observed in training. <ref type="bibr">Koehn and Knowles (2017)</ref> found that neural ma- chine translation systems using subword vocab- ularies outperformed phrase-based statistical ma- chine translation systems on the translation of un- known words. This raises the questions that we seek to answer: to what extent does byte-pair en- coding 1 solve the copying problem (without re- quiring modifications to the network structure)? <ref type="bibr">1</ref> A type of subword vocabulary <ref type="bibr">(Sennrich et al., 2016b</ref>).</p><p>More generally, what are subword neural machine translation models learning about copying?</p><p>We find that neural machine translation systems (with attention, trained on subword vocabularies) learn to copy words (both novel and observed) based on their sentential contexts. Additionally, though the models have no knowledge about the components of each subword unit, they learn that certain categories of tokens (e.g. capitalized to- kens) tend to be copied. We use quantitative and qualitative evaluations to shed light on what these models learn about copying tokens and about the contexts in which copying occurs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Prior work on copying in neural machine trans- lation has typically focused on rare or unknown words. <ref type="bibr">Luong et al. (2015)</ref> augment data with word alignments to train a neural machine trans- lation system (without attention) that emits both a translation and source word positions for any out- of-vocabulary (OOV) tokens emitted. They post- process OOVs with a dictionary or by copying. <ref type="bibr">Currey et al. (2017)</ref> augment training data with monolingual target language text as bitext and find that it improves copying in low-resource settings. <ref type="bibr">Ott et al. (2018)</ref> and <ref type="bibr">Khayrallah and Koehn (2018)</ref> examine negative effects of source copying.</p><p>Both <ref type="bibr">Gu et al. (2016)</ref> and <ref type="bibr">Gulcehre et al. (2016)</ref> modify neural sequence to sequence models to ex- plicitly perform copying. <ref type="bibr">Gu et al. (2016)</ref> focus on monolingual tasks (dialogue systems and summa- rization), proposing a model that can both gener- ate and copy text. <ref type="bibr">Gulcehre et al. (2016)</ref> perform experiments on neural machine translation (with attention), using whole-word vocabularies (and an UNK token to represent unknown words). Their model incorporates a switching variable that deter- mines whether to copy or generate a translation.</p><p>In this work, we focus on subword vocabularies for neural machine translation, using byte-pair en-  <ref type="table">Table 1</ref>: Percentage of tokens which should be copied, across training data sources.</p><p>coding <ref type="bibr">(BPE, Sennrich et al. (2016b)</ref>). The other approaches described are somewhat orthogonal to the use of subword vocabularies, but may require modifications to handle subwords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data and Models</head><p>We train German-English (DE-EN) and English- German (EN-DE) neural machine translation models with attention, similar to the University of Edinburgh's WMT 2016 submissions <ref type="bibr">(Sennrich et al., 2016a</ref>). Models are trained using the Mar- ian toolkit <ref type="bibr">(Junczys-Dowmunt et al., 2018</ref>). <ref type="bibr">2</ref> We use the WMT parallel text 3 (Europarl, News Com- mentary, and CommonCrawl) along with synthetic backtranslated data. <ref type="bibr">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Initial Analysis</head><p>We analyze the training data to learn about the prevalence and characteristics of words that should be copied in translation and the contexts in which they occur. We consider both the full train- ing data (including backtranslations and Common- Crawl) and cleaner subsets. We restrict our search for copied words to tokens of length 3 or more characters. <ref type="bibr">5</ref> Our heuristic for detecting copied to- kens is this: a word is a "copied token" if it appears the same number of times in both the source and target sentence. <ref type="bibr">6</ref> As we will show, copied words tend to belong to specific categories (proper nouns, numbers, etc.) which coincide with their repeated appearance in certain contexts (e.g. names follow- ing titles like "Ms" or "Prime Minister").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Where do copied words appear?</head><p>In <ref type="table">Table 1</ref>, we see that between 1.8% and 9.2% of tokens are copied. <ref type="bibr">7</ref> Though the majority (or near- majority) of sentences do not contain any copied words (of length 3 or more), copied words are still quite prevalent: approximately 18% of sentences in each full training dataset contain one, 4% to 5% contain four, and there is a long tail (one sentence contains 70). Sentences with many copied words often contain direct quotations, third language text (not source/target), or a sequence of copied words (e.g. comma-separated numbers or names).</p><p>The cleaner Europarl and News Commentary corpora have lower percentages of copied tokens than the overall training data. Of particular note, the backtranslated data contains some examples of copying that we'd prefer for the system not to learn, such as target language words appearing un- translated in the (backtranslated) source side data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">What words are copied?</head><p>We first examine the part-of-speech (POS) tags 8 of copied words. In the EN-DE training data, most copied words are tagged on the English side as NNP (proper noun, singular), including names of individuals, places, or organizations (eg. González, Wales, Union). The next most frequent categories are CD (cardinal number) -including numbers like 42 that should be copied and ones like seven which should be translated -and NN (noun, singular or mass). The results are similar for DE-EN training data (tagged on German with a different tag set): PROPN (proper noun) is the most frequent tag for copied words, followed by NUM (numbers) and NOUN. Punctuation would rank highly if we included short tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Analysis</head><p>We address two main questions: (1) Do certain contexts encourage copying? (2) Do certain words exhibit features that make them more likely to be copied (regardless of context)?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Contexts</head><p>Working from the intuition that certain contexts indicate that copying should occur -for exam- ple, a name following a title like "Ms" or "Frau" S: Therefore, Mrs Ashton, your role in this is invaluable. R: Darum, Frau Ashton, ist Ihre Aufgabe in diesem Zusammenhang von unschätzbarem Wert. T: Therefore, Mrs <ref type="bibr">[NNP]</ref>, your role in this is invaluable. E1: Therefore, Mrs BBC, your role in this is invaluable. D1: Deshalb, Frau BBC, ist Ihre Rolle hierbei von <ref type="bibr">[...]</ref> E2: Therefore, Mrs June, your role in this is invaluable. D2: Deshalb, Frau June, ist Ihre Rolle dabei von <ref type="bibr">[...]</ref> E3: Therefore, Mrs Lutreo, your role in this is invaluable. D3: Daher, Frau Lutreo, ist Ihre Rolle hierbei von <ref type="bibr">[...]</ref>  <ref type="table">Table 2</ref>: Source, reference, template, and examples of template-token combinations. E1 has a word usually (76.0% of the time) copied in training, E2 has one rarely (0.8% of the time) copied, and E3 has a novel one. In training, 84.8% of NNPs with this left bigram context (", Mrs") were copied.</p><p>should often be copied -we examine the relation- ship between context and copying, focusing on left bigram contexts. We show that the machine trans- lation system learns that certain contexts are so indicative of copying that it will even copy (not translate) words that it has learned to translate if they are seen in a sufficiently copy-prone context.</p><p>For each POS, we collect a set of left bigram contexts that precede a word with that tag. We filter by frequency and diversity of tokens follow- ing the bigram. <ref type="bibr">9</ref> For each context-POS pair, we select 50 random templates from the training data containing the bigram context followed by a word with that POS. 10 Each context-POS pair is associ- ated with a percentage that represents how often it exhibited copying in the training data. For exam- ple, in the copy-prone context "thank Mrs <ref type="bibr">[NNP]</ref>" the NNP was copied 91.1% of the time, compared to 15.3% of the time in "Republic of <ref type="bibr">[NNP]</ref>". <ref type="bibr">11</ref> We take all word types with a given POS tag from the WMT 2016 test set, dividing them into four categories based on two binary distinctions: observed (in training data) or novel (not observed in training), and copy (typically copied) or non- copy (not typically copied) and filter the observed ones based on training frequency. We count words as non-copy if they were copied ≤ 30% of the time, and as copy if they were copied ≥ 70% of <ref type="figure">Figure 1</ref>: Percent of NNP (EN-DE) tokens copied by how copy-prone the context is, by cate- gory. Each point is the percentage of copying for all within-category words, across all exam- ple templates for one particular context (averaged over between 1,100 (novel-non-copy) and 13,150 (observed-non-copy) binary copy values). the time. <ref type="bibr">12</ref> We then combine each word with each POS-appropriate example template and perform preprocessing (including BPE) and translation. 13 <ref type="table">Table 2</ref> shows examples.</p><p>For each context, we calculate the percent- age (across all example templates for that con- text and all words, separated by observed/novel and copy/non-copy categories) of the time that the words in that context were copied. We then com- pare it to the percentage of the time that copying occurred for that context-POS tag pair in training. <ref type="figure">Figure 1</ref> shows NNP (EN-DE) results. Both observed-copy and novel-copy words behave al- most identically, with copying percentages gen- erally above 80%, and a slight trend upward as contexts become more copy-prone (moving to the right along the horizontal axis). Novel-non-copy words shadow these, but with a drop in copying percentage (see Section 5.3). Most interesting is the observed-non-copy category. In contexts that are not copy-prone, minimal copying occurs. <ref type="bibr">14</ref> However, as they are placed in increasingly copy- prone contexts, even these words that the system has learned it should translate are being copied. We observe the same trend for words tagged NN and CD, and for PROPN, NOUN, and NUM words in the DE-EN direction. This demonstrates that the machine translation system has learned that certain contexts are copy-prone.</p><p>We manually analyze outliers that appear much <ref type="table" target="#tab_3">Novel-Copy  24  102  60  Novel-Non-Copy  14  128  50  Observed-Copy  51  6  126  Observed-Non-Copy  12  1  186   Table 3</ref>: Counts of automatically detected output categories (drop, change, and other) for a sample of NNP tokens (EN-DE) that were not copied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drop Change Other</head><p>more or less copy-prone than expected. In both cases, the cause appears the same: the context oc- curred repeatedly in many very similar sentences in the training data. Highly copy-prone contexts that produced copying percentages greater than 70% even in observed-non-copy tokens often ap- peared in common boilerplate text (e.g. "stay at [NNP]" or "rates for <ref type="bibr">[NNP]</ref>" followed by "Ho- tel"). <ref type="bibr">15</ref> Where we observe lower than expected rates (e.g. ") of [NNP]"), we find that the system may have memorized training sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Analysis of Words That Are Not Copied</head><p>When words are not copied, what sort of output is the system producing? We find that it typically falls into one of four categories: drop (no target token aligns with the source token), change (the word is changed: partially translated, transliter- ated, or inflected even if it is not a target language word), substitution (the word is replaced with a fluent but not adequate substitute), or translation (translated into a target language word).</p><p>We begin with an automatic analysis. We randomly sample 200 examples each of sen- tences containing words that were not copied for novel-copy, novel-non-copy, observed-copy, and observed-non-copy NNPs (EN-DE). We retrans- late each sentence and produce a soft alignment matrix from the attention mechanism, then con- vert the soft alignments between BPE segments into hard alignments between the source word and one or more target words. <ref type="bibr">16</ref> A word has been dropped if it is unaligned. We count a word as be- ing changed if any words it is aligned to have any subword (BPE segment) overlap with the original word's subwords. Both substitution and transla- tion fall under other; we analyze those manually.</p><p>Results are shown in <ref type="table">Table 3</ref>. <ref type="bibr">17</ref> For all novel <ref type="bibr">15</ref> Since hidden representations contain whole sentence in- formation, right side context may influence copying too. <ref type="bibr">16</ref> We use AmuNMT (Junczys-Dowmunt et al., 2016), pro- ducing slightly different output. See Appendix C for details. <ref type="bibr">17</ref> Rows do not sum to 200 because some words in our ran- words, the most frequent output type is change. For example, the novel NNP Bishnu is changed into Bischnu in German. <ref type="bibr">18</ref> Other changes include translations of parts of the word, and concatena- tion with other tokens. The output token often starts with the same character or sequence of char- acters as the source token. <ref type="bibr">19</ref> We</p><note type="other">manually inspect examples in the other cat- egory. For observed-non-copy words, almost all are translations (e.g. Sea translated correctly as Meer), as expected. For observed-copy words, we see a mix of translations and other changes to the words, which are almost evenly split between sub- stitutions and small changes. These include inflec- tions (e.g. Bremen magazine reasonably translated as Bremer Magazin 20 ).</note><p>Within the other category, perhaps the most in- teresting cases are those where words appear to be substituted with a fluent but not adequate al- ternative. Many substitutions occur when the rare word is inserted next to a word that often forms a collocation (like "United States" -in sentences that include "in the <ref type="bibr">[NNP]</ref> States" the transla- tion sometimes defaults to a translation of "United States" regardless of the actual NNP inserted in place of "United"). Others have a less common NNP swapped for one that belongs to a similar se- mantic category (e.g. the place name Dublin be- ing generated instead of the less common Halle -as <ref type="bibr">Arthur et al. (2016)</ref> and others observed). For novel-copy words labeled as other, three quar- ters are substitutions and one quarter exhibit small changes. The reverse is true for novel-non-copy words: the majority exhibit small changes while almost thirty percent are substitutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Properties of Copied Words</head><p>Certain words exhibit properties that make them more likely to be copied, regardless of context. At first glance, it seems unintuitive that the rate of copying of novel-copy words and novel-non- copy words differs <ref type="figure">(Fig. 1)</ref> -the model has never observed any of these words, and they are being presented in identical contexts -why does it dif- ferentiate between them? Doing so indicates that the model has learned what makes a sequence of dom sample were copied by the the AmuNMT decoder.</p><p>18 A near-transliteration -the "sh"/"sch" transformation is seen in EN-DE cognates, e.g. "ship" and "Schiff". <ref type="bibr">19</ref> Appendix D contains examples of this and more. <ref type="bibr">20</ref> Bremen and Bremer are unique BPE segments, so the change heuristic could not be applied. subwords likely to be copied. <ref type="bibr">Belinkov et al. (2017)</ref> observe that neural ma- chine translation models may encode informa- tion about part-of-speech, which could be used when determining whether or not to copy (but does not explain within-POS differences). For numbers, it mainly learns to copy numerical por- tions while changing commas to periods and vice versa (as required by the target language's conven- tions). Nouns and proper nouns are more interest- ing: some should be translated (e.g. novel noun compounds like hallmate), or, in the case of mis- spellings (e.g. manfacturer), corrected, while oth- ers should be copied. For novel NN words, there is another striking difference between copy and non- copy: most of the former contain capital letters and most of the latter do not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Capitalization and Copying</head><p>To experiment with the influence of capitalization on copying, we take each novel NNP word (96 copy and 22 non-copy) and convert it to lower- case, leave it in its natural case (all have at least one uppercase letter), or convert it to uppercase. We then translate all of them in all NNP contexts (from previous EN-DE experiments). Using only novel words sidesteps the issue of truecasing.</p><p>Lowercase words are the least frequently copied (average copy rate of 40.2%), uppercase words are the most copied (94.4%), and the natural case falls in the middle (81.7%). However, changing cas- ing changes the BPE segmentation, and uppercase words tend to be split into more pieces: a mean of 4.4 segments, as compared to means of 3.1 (low- ercase) and 2.9 (natural case). The number of subword segments correlates positively with copy- ing rate <ref type="figure" target="#fig_0">(Fig. 2)</ref>, but, controlling for that, we still find that NNP words that are completely capital- ized tend to be copied more than those with the same number of subword segments but only low- ercased letters, suggesting that the system is en- coding information about the connection between capitalization and copying. We also perform this experiment with PROPN words in the DE-EN di- rection, and find that increased capitalization in- creases copying, though we do not find there that an increase in the number of BPE segments in- creases copying. The true casing of the word con- sistently falls between these two extremes. The high copying rate of fully-capitalized words is in- tuitive: acronyms are often both uppercased and copied from source to target. That is not to say that the model always learns to copy acronyms; it also learns to translate them when appropriate (such as GDP to BIP). There is always an inter- play between learned translations and features that may encourage copying.</p><p>The connection between copying rate and capi- talization provides one explanation for the gap in behavior of the two novel word types, and demon- strates that features of words influence copying. Note that it learns this behavior based on training data, without access to information at a finer gran- ularity (character-level) than the subword units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We show that subword vocabulary neural machine translation systems learn about copying from con- text and the subwords themselves. The effect of context is strong enough to cause words that would otherwise be translated to be copied. Characteris- tics of subword tokens play a role in copying be- havior, with capitalized tokens more likely to be copied. We leave as future work a deeper analy- sis of the level of character-awareness encoded in representations of the BPE segments as a byprod- uct of training. We provide an analysis of what happens when words are not copied, showing ex- pected differences between novel words and words that were observed during training. Additionally, we provide more examples and evidence of the problem of substituting fluent but non-adequate translations for rare or unknown words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>Philip Arthur, Graham Neubig, and Satoshi Nakamura.</p><p>2016. Incorporating discrete translation lexicons into neural machine translation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Collection of Left Bigram Contexts</head><p>We use left bigram contexts as a proxy to evaluate the contexts in which words are copied. Here, we provide details of the context selection process de- scribed in Section 5.1. In overview: for each POS, we collect the full set of left bigram contexts that ever precede a word with that tag, then filter by frequency and subsequent token diversity. For each POS, first, we find all left bigram con- texts (tok0, tok1, copiedword) that occur in the training data (where the copied word was tagged with the given POS). We then filter this set so that it only contains contexts (tok0, tok1) that ap- peared at least 1000 times (left of NNP/PROPN) or 500 times (left of CD/NN/NUM/NOUN) in the training data. To ensure that we're not simply cap- turing collocations ("European Union"), we filter out left bigram contexts that have been followed by fewer than 150 unique types with that particular POS. This results in between 53 and 276 contexts, as shown in <ref type="table" target="#tab_3">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>POS</head><p>Num  Each context is then associated with a copying rate, calculated as the number of times the token (with the given POS tag) following (tok0, tok1) is copied, divided by the total number of times (tok0, tok1) was observed to be followed by a to- ken with that POS tag. In <ref type="table" target="#tab_4">Table 5</ref>, we show the most-and least-copy-prone contexts for EN-DE (those with the highest and lowest copying rates).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Collection and Labeling of Copy/Non-Copy Words</head><p>In Section 5.1, we give a high-level description of how we collect and label words. All words that we examine are labeled as either copy or non-copy. For words that were observed in training, we filter</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>POS Context</head><p>Copy Rate NNP Finance Minister 94.5% rates for 94.0% congratulate Mr 91.7% between the 10.5% President , 7.7% CD updated on 94.0% the B 0.1% NN notified when 97.3% the first 0.6%  out those that appeared fewer than 1000 times. We label them as copy if they were copied ≥ 70% of the time in training data (according to the heuris- tic described in Section 4), and as non-copy if they were copied ≤ 30% of the time in training data, discarding the remainder. For words that were un- observed in training, we used the same threshold but calculate it over all instances in the test data (with no requirement that they appear a certain number of times). <ref type="table" target="#tab_5">Table 6</ref> shows the number of words selected after filtering and thresholding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Attention and Alignments</head><p>We produce soft alignments (the attention ma- trix) using the AmuNMT decoder with the "return- nematus-alignment" flag set. It performs normal- ization differently than Marian's decoder (produc- ing slightly different outputs for many sentences, including sometimes copying words that were not copied in our original translations).</p><p>For each target (subword) token, we align it to the source (subword) token with the highest soft alignment weight. Given our source word of interest s (composed of subword segments s 1 . . . s n ), we define its translation to be the list of all target words t (composed of subword segments t 1 . . . t m ) for which any subword t i was aligned to a subword s j of s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional Examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Changes</head><p>Here we show additional examples of changes, like the transliteration-like change of Bishnu to Bischnu described in Section 5.2.</p><p>There are also partial translations when BPE segments are full source language words - like Thneed (segmented "Th@@ need") be- coming ThNotwendigkeit (segmented "Th@@ Notwendigkeit" -Notwendigkeit is a valid trans- lation of need). Sometimes, a token is copied but then concatenated with another token.</p><p>Even without overlap of BPE segments between the source and the translation, changed words sometimes share a number of characters (espe- cially at the beginning or end of a word). Half of the other category output of Thneed ("Th@@ need") begin with the letter "T" (but not the BPE token "Th@@"). This may suggest some level of character-awareness in the representations of BPE segments, produced as a byproduct of training. We leave a deeper analysis of this to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 NNP Substitutions</head><p>Here we provide additional examples of substitu- tions, as seen in Section 5.2. These findings pro- vide additional support and nuance to the study of this phenomenon of neural machine translation system errors.</p><p>Many substitutions occur when the rare word is inserted next to a word that often forms a colloca- tion (like "United States" or "European Union" or "Madam President"). For example, in a template where "in the [NNP]" is followed by "States", in- serting the NNP Accies results in "in the Accies States" -which was then translated by the sys- tem as "in den Vereinigten Staaten" (gloss: "in the United States").</p><p>We also observe examples that may have to do with a combination of (in)frequency of tokens and the context. For example, we have the novel NNP Sloveina (perhaps a misspelling of Slove- nia), which is often replaced with Slowaken (Slo- vakia) when translated to German. In another sen- tence, we find that "this year, Angela expects" is translated to "in diesem Jahr erwartet Merkel" despite Merkel appearing nowhere in the source text. The first and last names of German chan- cellor Angela Merkel appear frequently together in training data, and thus likely have sufficiently similar representations. We see other similar sub- stitutions: Mitt for Romney, US for Obama, and Thomas for Sarah. Sometimes a specific name is replaced with a title, such as "your prime minis- ter, York" being translated as "ihr Premierminister, Herr Präsident" (glossed as "your prime minister, Mr. President").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Additional Plots</head><p>Here we include plots for DE-EN PROPN. <ref type="figure" target="#fig_1">Fig. 3</ref> shows context experiments. It shows similar trends to <ref type="figure">Fig. 1</ref>, but with a greater gap between novel-copy/non-copy words. As noted, the DE- EN capitalization experiments <ref type="figure" target="#fig_2">(Fig. 4)</ref> show the same trends as EN-DE in terms of capitalization (despite the capitalization of all nouns in German), but not in terms of numbers of BPE segments.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Copying rate based on casing and number of BPE segments for novel NNP words (EN-DE), averaged across all NNP contexts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Percent of PROPN (DE-EN) tokens copied by how copy-prone the context is, by category. Each point is the percentage of copying for all within-category words, averaged across all example templates for one particular context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Copying rate based on casing and number of BPE segments for novel PROPN words (DEEN), averaged across all PROPN contexts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>In Proceedings of the 2016 Conference on Empirical Methods in Natu- ral Language Processing, pages 1557-1567, Austin, Texas. Association for Computational Linguistics.</head><label></label><figDesc></figDesc><table>Yonatan Belinkov, Lluís M` arquez, Hassan Sajjad, 
Nadir Durrani, Fahim Dalvi, and James Glass. 2017. 
Evaluating layers of representation in neural ma-
chine translation on part-of-speech and semantic 
tagging tasks. In Proceedings of the Eighth In-
ternational Joint Conference on Natural Language 
Processing (Volume 1: Long Papers), pages 1-10, 
Taipei, Taiwan. Asian Federation of Natural Lan-
guage Processing. 

Anna Currey, Antonio Valerio Miceli Barone, and Ken-
neth Heafield. 2017. Copied monolingual data im-
proves low-resource neural machine translation. In 
Proceedings of the Second Conference on Machine 
Translation, pages 148-156, Copenhagen, Den-
mark. Association for Computational Linguistics. 

Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K. 
Li. 2016. Incorporating copying mechanism in 
sequence-to-sequence learning. In Proceedings of 
the 54th Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers), 
pages 1631-1640, Berlin, Germany. Association for 
Computational Linguistics. 

Caglar Gulcehre, Sungjin Ahn, Ramesh Nallapati, 
Bowen Zhou, and Yoshua Bengio. 2016. Pointing 
the unknown words. In Proceedings of the 54th 
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers), pages 
140-149, Berlin, Germany. Association for Compu-
tational Linguistics. 

Marcin Junczys-Dowmunt, Tomasz Dwojak, and Hieu 
Hoang. 2016. Is neural machine translation ready 
for deployment? a case study on 30 translation 
directions. In Proceedings of the 9th Interna-
tional Workshop on Spoken Language Translation 
(IWSLT), Seattle, WA. 

Marcin Junczys-Dowmunt, Roman Grundkiewicz, 
Tomasz Dwojak, Hieu Hoang, Kenneth Heafield, 
Tom Neckermann, Frank Seide, Ulrich Germann, 
Alham Fikri Aji, Nikolay Bogoychev, Andr F. T. 
Martins, and Alexandra Birch. 2018. Marian: Fast 
neural machine translation in c++. In Proceedings 
of ACL 2018, System Demonstrations, pages 116-
121, Melbourne, Australia. Association for Compu-
tational Linguistics. 

Huda Khayrallah and Philipp Koehn. 2018. On the 
impact of various types of noise on neural machine 
translation. In Proceedings of the 2nd Workshop on 
Neural Machine Translation and Generation, pages 
74-83, Melbourne, Australia. Association for Com-
putational Linguistics. 

Philipp Koehn and Rebecca Knowles. 2017. Six chal-
lenges for neural machine translation. In Pro-
ceedings of the First Workshop on Neural Machine 
Translation, pages 28-39, Vancouver. Association 
for Computational Linguistics. 

Thang Luong, Ilya Sutskever, Quoc Le, Oriol Vinyals, 
and Wojciech Zaremba. 2015. Addressing the rare 
word problem in neural machine translation. In Pro-
ceedings of the 53rd Annual Meeting of the Associ-
ation for Computational Linguistics and the 7th In-
ternational Joint Conference on Natural Language 
Processing (Volume 1: Long Papers), pages 11-19, 
Beijing, China. Association for Computational Lin-
guistics. 

Myle Ott, Michael Auli, David Grangier, and 
Marc'Aurelio Ranzato. 2018. Analyzing uncer-
tainty in neural machine translation. In Interna-
tional Conference on Machine Learning. 

Rico Sennrich, Barry Haddow, and Alexandra Birch. 
2016a. Edinburgh neural machine translation sys-
tems for WMT 16. In Proceedings of the First Con-
ference on Machine Translation (WMT). 

Rico Sennrich, Barry Haddow, and Alexandra Birch. 
2016b. Neural machine translation of rare words 
with subword units. In Proceedings of the 54th An-
nual Meeting of the Association for Computational 
Linguistics (Volume 1: Long Papers), pages 1715-
1725, Berlin, Germany. Association for Computa-
tional Linguistics. 

Kristina Toutanova, Dan Klein, Christopher D Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network. 
In Proceedings of the 2003 Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology-
Volume 1, pages 173-180. Association for Compu-
tational Linguistics. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Context counts by POS tag (NNP, NN, CD 
for EN-DE; PROPN, NOUN, NUM for DE-EN), 
selected as described in Appendix A. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Left bigram contexts with the high-
est/lowest copying rates (EN-DE), by POS tag. 

Novel 
Observed 
POS 
Copy Non-C. Copy Non-C. 
NNP 
96 
22 
251 
263 
NN 
14 
16 
13 
1664 
CD 
3 
29 
60 
44 
PROPN 
92 
76 
463 
418 
NOUN 
12 
222 
29 
2176 
NUM 
2 
29 
55 
68 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Counts of each word type by 
novel/observed, 
copy/non-copy 
distinction 
and POS tag (NNP, NN, CD are EN-DE; PROPN, 
NOUN, NUM are DE-EN). 

</table></figure>

			<note place="foot" n="2"> We use recommended settings and early stopping, with results comparable to WMT 2016 systems, with BLEU scores of 39.9 (DE-EN) and 33.2 (EN-DE) on the 2016 test set. 3 http://www.statmt.org/wmt16/translation-task.html 4 http://data.statmt.org/rsennrich/wmt16 backtranslations/ 5 This has the benefit of removing words like in which are the same in German and English, but may nonetheless be considered translations rather than copies. 6 In DE-EN, we find one notable exception to this heuristic-was-which is a homograph, not a copy. It makes up &lt; 1% of copied tokens in Europarl/News Commentary.</note>

			<note place="foot" n="7"> The two full training sets differ due to the synthetic backtranslated data; the rest of the corpora are identical. 8 POS tags are generated by the Stanford POS tagger (Toutanova et al., 2003). For English: english-left3wordsdistsim.tagger. For German: german-ud.tagger.</note>

			<note place="foot" n="9"> See Appendix A for details and examples of contexts. 10 We select contexts and templates from the full training data, rather than only Europarl/News Commentary, because we are interested in what patterns the model is learning from all data to which it has been exposed. 11 For DE-EN translation, we see similar patterns: two of the three most copy-prone PROPN left bigram contexts are &quot;sagte Frau&quot; and &quot;sagte Herr&quot; (&quot;said Ms/Mr&quot;), while many less copy-prone ones end with articles.</note>

			<note place="foot" n="12"> See Appendix B for details. 13 We use the Marian batch decoder, with recommended settings: beam size 6 and length normalization penalty of 0.6. 14 Note that some of the non-copy words were sometimes copied in training data, even if only in backtranslations.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
