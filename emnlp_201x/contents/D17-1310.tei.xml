<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Multi-Task Learning for Aspect Term Extraction with Memory Interaction *</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">Department of Systems Engineering and Engineering Management</orgName>
								<orgName type="laboratory">Key Laboratory on High Confidence Software Technologies (Sub-Lab, CUHK)</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">Department of Systems Engineering and Engineering Management</orgName>
								<orgName type="laboratory">Key Laboratory on High Confidence Software Technologies (Sub-Lab, CUHK)</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Multi-Task Learning for Aspect Term Extraction with Memory Interaction *</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2886" to="2892"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a novel LSTM-based deep multi-task learning framework for aspect term extraction from user review sentences. Two LSTMs equipped with extended memories and neural memory operations are designed for jointly handling the extraction tasks of aspects and opinions via memory interactions. Sentimental sentence constraint is also added for more accurate prediction via another LSTM. Experiment results over two benchmark datasets demonstrate the effectiveness of our framework.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The aspect-based sentiment analysis (ABSA) task is to identify opinions expressed towards specific entities such as laptop or attributes of entities such as price ( <ref type="bibr" target="#b2">Liu, 2012a)</ref>. This task involves three sub- tasks: Aspect Term Extraction (ATE), Aspect Po- larity Detection and Aspect Category Detection. As a fundamental subtask in ABSA, the goal of the ATE task is to identify opinionated aspect ex- pressions. One of most important characteristics is that opinion words can provide indicative clues for aspect detection since opinion words should co-occur with aspect words. Most publicly avail- able datasets contain the gold standard annotations for opinionated aspects, but the ground truth of the corresponding opinion words is not commonly provided. Some works tackling the ATE task ig- nore the consideration of opinion words and just focus on aspect term modeling and learning (Jin * The work described in this paper is substantially sup- ported by a grant from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Code: 14203414). We thank Lidong Bing and Piji Li for their helpful comments on this draft and the anonymous reviewers for their valuable feedback.</p><p>et al., <ref type="bibr">2009;</ref><ref type="bibr">Jakob and Gurevych, 2010;</ref><ref type="bibr" target="#b18">Toh and Wang, 2014;</ref><ref type="bibr">Chernyshevich, 2014;</ref><ref type="bibr" target="#b8">Manek et al., 2017;</ref><ref type="bibr" target="#b15">San Vicente et al., 2015;</ref><ref type="bibr" target="#b7">Liu et al., 2015;</ref><ref type="bibr" target="#b13">Poria et al., 2016;</ref><ref type="bibr" target="#b17">Toh and Su, 2016;</ref><ref type="bibr" target="#b23">Yin et al., 2016)</ref>. They fail to leverage opinion information which is supposed to be useful clues.</p><p>Some works tackling the ATE task con- sider opinion information ( <ref type="bibr">Hu and Liu, 2004a,b;</ref><ref type="bibr" target="#b12">Popescu and Etzioni, 2005;</ref><ref type="bibr" target="#b24">Zhuang et al., 2006;</ref><ref type="bibr" target="#b14">Qiu et al., 2011;</ref><ref type="bibr" target="#b4">Liu et al., 2012b</ref><ref type="bibr" target="#b3">Liu et al., , 2013a</ref><ref type="bibr">Liu et al., ,b, 2014</ref>) in an unsupervised or partially supervised manner. <ref type="bibr" target="#b14">Qiu et al. (2011)</ref> proposed Double Propagation (DP) to collectively extract aspect terms and opin- ion words based on information propagation over a dependency graph. One drawback is that it heav- ily relies on the dependency parser, which is prone to generate mistakes when applying on informal online reviews. <ref type="bibr" target="#b6">Liu et al. (2014)</ref> modeled relation between aspects and opinions by constructing a bi- partite heterogenous graph. It cannot perform well without a high-quality phrase chunker and POS tagger reducing its flexibility. As unsupervised or partially supervised frameworks cannot take the full advantages of aspect annotations commonly found in the training data, the above methods lead to deficiency in leveraging the data. Recently, <ref type="bibr" target="#b20">Wang et al. (2016)</ref> considered relation between opinion words and aspect words in a supervised model named RNCRF. However, RNCRF tends to suffer from parsing errors since the structure of the recursive network hinges on the dependency parse tree. CMLA ( <ref type="bibr" target="#b21">Wang et al., 2017a</ref>) used a multi- layer neural model where each layer consists of aspect attention and opinion attention. However CMLA merely employs standard GRU without ex- tended memories.</p><p>We propose MIN (Memory Interaction Net- work), a novel LSTM-based deep multi-task learn- ing framework for the ATE task. Two LSTMs with extended memory are designed for handling the extraction tasks of aspects and opinions. The aspect-opinion relationship is established based on neural memory interactions between aspect ex- traction and opinion extraction where the global indicator score of opinion terms and local posi- tional relevance between aspects and opinions are considered. To ensure that aspects are from sen- timental sentences, MIN employs a third LSTM for sentimental sentence classification facilitating more accurate aspect term extraction. Experiment results over two benchmark datasets show that our framework achieves superior performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head><p>Let an input review sentence with T word tokens and the corresponding distributed representations be w = {w 1 , ..., w T } and x = {x 1 , ..., x T } re- spectively. The ATE task is treated as a sequence labeling task with BIO tagging scheme and the set of aspect tags for the word w t is y A t ∈ {B, I, O}, where B, I, O represent beginning of, inside and outside of the aspect span respectively. Commonly found training data contains gold annotations for aspect terms and opinionated sentences, but the gold standard of opinion words are usually not available.</p><p>In our multi-task learning framework, three tasks are involved: (1) aspect term extraction (ATE), (2) opinion word extraction and (3) sen- timental sentence classification. We design a task- specific LSTM, namely, A-LSTM, O-LSTM and S-LSTM, for tackling each of the above tasks re- spectively. The first component of our proposed framework consists of A-LSTM and O-LSTM where we equip LSTMs with extended operational memories and some operations are defined over the memories for task-level memory interactions. The second component is to determine if a review sentence is sentimental. This is achieved by em- ploying a vanilla LSTM, namely, S-LSTM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Model Description</head><p>The first component of our framework MIN is composed of A-LSTM and O-LSTM. Both LSTMs have extended memories for task-level memory interactions. A-LSTM involves a large aspect memory H A t ∈ R nm×dim A h and an opin- ion summary vector m O t ∈ R dim O h where H A t con- tains n m pieces of aspect hidden states of dimen- sion dim A h and m O t is distilled from H O t . As for O-LSTM, similarly, an opinion memory H O t ∈ R nm×dim O h and an aspect-specific summary vector m A t ∈ R dim A h are included. We use the aspect term annotations in the training data for training A-LSTM. As there is no ground truth available for opinion words in the training data, sentiment lexicon and high- precision dependency rules are introduced to find potential opinion words. Commonly used opin- ion words can be found in some general sentiment lexicons. To find opinion words, not in sentiment lexicons, in a sentence, we build a small rule set R composed of dependency relations with high con- fidence, e.g., amod, nsubj, and determine if w t directly depends on the gold aspect word through the dependencies in R. If so, w t will be treated as a potential opinion word. Then such opinion words are used as training data for O-LSTM.</p><p>In the memory-enhanced A-LSTM and O- LSTM, we manually design three kinds of op- erations: (1) READ to select n m pieces of as- pect (opinion) hidden states from the past mem- ories and build</p><formula xml:id="formula_0">H A t (H O t ); (2) DIGEST to distill an aspect (opinion)-specific summary m A t (m O t ) from H A t (H O t )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>where influences of opinion terms and relative positions of inputs are considered; (3)</head><p>INTERACT to perform interaction between A- LSTM and O-LSTM using the task specific sum- maries (i.e., m A t and m O t ). Consider the work flow of A-LSTM for as- pect term extraction. Since opinion words and as- pect terms should co-occur, the goal of A-LSTM participating in memory interactions is to acquire opinion summaries from O-LSTM (i.e., m O t ) for better aspect prediction. First of all, MIN will READ n m pieces of opinion memories which are most related to w t from O-LSTM. Syntax structure could be used but syntactic parsers are not effective for processing short informal review sentences. Therefore, MIN selects memory seg- ments temporally related to w t . Precisely, the opinion memory at the time step t is</p><formula xml:id="formula_1">H O t = [h O t−1 ; ...; h O t−nm ]</formula><p>where h O t−i is the (t − i)-th hid- den state from O-LSTM. Since the linear context contains most of the parent nodes and the child nodes of w t on the dependency parse tree, treat- ing the corresponding memory segments as rele- vant segments to w t is reasonable.</p><p>Then MIN will DIGEST the collected opinion memories H O t in the A-LSTM. As different mem- ory segments are not of equal importance for the current decision and the same segment in differ- ent memories (i.e., different H O t ) also makes a difference, MIN leverages two kind of weights to summarize the collected content. The first weight is the indicator score of being opinion terms de- noted as v I ∈ R nm , which is used to measure how much opinion information the word w t−i (i = 1, .., n m ) holds. We adopt Euclidean dis- tance between distributed representations of w t−i and opinion words. It is obvious that computing the distance between x t−i and each opinion word is expensive. Thus, we run an off-the-shelf clus- tering algorithm over opinion words in the train- ing set and then use the produced n c centroids to estimate the indicator score v I i of w t−i being an opinion word:</p><formula xml:id="formula_2">v I i = nc j=1 1 ||x t−i − c j || 2<label>(1)</label></formula><p>where x t−i is the distributed representation of w t−i and c j is the centroid vector representation of j-th cluster. This weighting scheme ensures that w t−i is assigned a high score as long as x t−i is close to a particular centroid. The aspect de- cision of w t is also affected by relative position between w t−i and w t . Thus, MIN employs the second weight v P to explicitly model their posi- tional relevance and the initial weight for the i-th segment v P i is calculated as below:</p><formula xml:id="formula_3">v P i = n m − i + 1 nm k=1 k<label>(2)</label></formula><p>where n m is the number of hidden state in H O t . This position-aware weight enables that the closer the word w t−i is to the current input, the more the corresponding memory segment will contribute to the current decision. To better capture the local po- sitional relevance, we make the initialized v P as learnable parameters. Combining the above two weights helps to utilize each active memory seg- ment according to the importance for prediction and m O t , the summary of H O t is generated:</p><formula xml:id="formula_4">m O t = (H O t ) ( v I v P ||v I || 2 )<label>(3)</label></formula><p>where denotes element-wise multiplication and || * || 2 is Euclidean norm of vectors. From Equa- tion 3, m O t is dominated by the associated memory segment of w t−i that obtains the high combined weights.</p><p>In the last operation INTERACT, A-LSTM communicates with O-LSTM by acquiring m O t from O-LSTM and incorporating the summary into the memory update. The update process is as follows:</p><formula xml:id="formula_5">i A t = σ(W A i x t + U A i [H A t [1] : m O t ]) + b A i ) f A t = σ(W A f x t + U A f [H A t [1] : m O t ]) + b A f ) ˆ c A t = tanh(W A c x t + U A c [H A t [1] : m O t ]) + b A c ) o A t = σ(W A o x t + U A o [H A t [1] : m O t ]) + b A o ) c A t = i A t ˆ c A t + c A t−1 f A t h A t = tanh(c A t ) o A t<label>(4)</label></formula><p>where W A * , U A * and b A * are weight parameters of the A-LSTM and σ is the sigmoid activation function.</p><p>[:] denotes vector concatenation oper- ation. m O t can be seen as the summary of the opinion indicator in the left context of w t and H A t <ref type="bibr">[1]</ref> is the most immediate hidden memory of A-LSTM. MIN blends the opinion summary from O-LSTM with the memory from A-LSTM. The co-occurrence relation between aspects and opin- ion words is modeled by such "memory fusion" strategy. Since opinion words can appear on both sides of w t , memory segments corresponding to the right context (i.e., "future" memory) should be included. Hence, we conduct bi-directional train- ing for A-LSTM.</p><p>The work flow of memory interaction and the update process of the internal memories in O- LSTM are kept same with those in A-LSTM ex- cept the DIGEST operation. Specifically, we set m A t , the task-specific summary of A-LSTM, as h A t . The second component of MIN is a generic LSTM called S-LSTM for discriminating senti- mental sentences and non-sentimental sentences. The design and the process of the memory update in this component are similar to that in Jozefow- icz et al. (2015). In sentences not conveying any sentimental meanings, some words like food, ser- vice tend to be misclassified as aspect terms since they are commonly used in user reviews. To avoid this kind of error, we add a constraint that an as- pect term should come from sentimental sentence. Specifically, S-LSTM learns the sentimental rep- resentation h S T of the sentence and then feeds it in aspect prediction as a soft constraint:</p><formula xml:id="formula_6">P (y A t |x t ) = softmax(W A f c ([h A t : h S T ]))<label>(5)</label></formula><p>where W A f c denotes the weight matrix of the fully- connected softmax layer.</p><p>On the whole, our proposed MIN framework has three LSTMs and each of them is differen- tiable. Thus, our MIN framework can be ef- ficiently trained with gradient descent. For A- LSTM and O-LSTM, we use the token-level cross-entropy error between the predicted distribu- tion P (y T t |x t ) and the gold standard distribution P (y T ,g t |x t ) as the loss function (T ∈ {A, O}):</p><formula xml:id="formula_7">Loss(T ) = − 1 N * T N i=1 T t=1 P (Y T ,g i,t |X i,t ) log[P (Y T i,t |X i,t )]<label>(6)</label></formula><p>For S-LSTM, sentence-level cross entropy error are employed to calculate the corresponding loss:</p><formula xml:id="formula_8">Loss(S) = − 1 N N i=1 P (Y S,g i |X i ) log[P (Y S i |X i )]</formula><p>(7) Then, losses from different LSTMs are combined to form the training objective of the MIN frame- work: </p><formula xml:id="formula_9">J(θ) = Loss(A) + Loss(O) + Loss(S) (8</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>We conduct experiments on two benchmark datasets from SemEval ABSA challenge ( <ref type="bibr" target="#b11">Pontiki et al., 2014</ref><ref type="bibr" target="#b10">Pontiki et al., , 2016</ref> as shown in <ref type="table">Table 1</ref>. D 1 (Se- mEval 2014) contains reviews from the laptop do- main and D 2 (SemEval 2016) contains reviews from the restaurant domain. In these datasets, as- pect terms have been labeled and sentences con- taining at least one golden truth aspect are re- garded as sentimental sentences. As gold stan- dard annotations for opinion words are not pro- vided, we select words with strong subjectivity from MPQA 1 as potential opinion words. Apart from the common opinion words in the sentiment lexicon, we also treat words, which directly de- pend on gold standard aspect terms through high- precision dependency rules, as opinion words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiment Design</head><p>To evaluate the proposed MIN framework, we per- form comparison with the following two groups of methods:</p><p>(1) CRF based methods:</p><p>• CRF: Conditional Random Fields with basic feature templates 2 and word embeddings.</p><p>• Semi-CRF: First-order semi-Markov condi- tional random fields ( <ref type="bibr" target="#b16">Sarawagi et al., 2004</ref>) and the feature template in <ref type="bibr">Cuong et al. (2014)</ref> is adopted.</p><p>• IHS RD <ref type="bibr">(Chernyshevich, 2014</ref>), NLANGP (Toh and Su, 2016): Best systems in ATE subtask in SemEval ABSA challenges ( <ref type="bibr" target="#b11">Pontiki et al., 2014</ref><ref type="bibr" target="#b10">Pontiki et al., , 2016</ref>).</p><p>• DLIREC (Toh and <ref type="bibr" target="#b18">Wang, 2014</ref>), AUEB (Xenos et al., 2016): Top-ranked CRF-based systems in ATE subtask in SemEval ABSA challenges ( <ref type="bibr" target="#b11">Pontiki et al., 2014</ref><ref type="bibr" target="#b10">Pontiki et al., , 2016</ref>).</p><p>• WDEmb (Yin et al., 2016): Enhanced CRF with word embeddings, linear context em- beddings and dependency path embeddings.</p><p>(2) Neural Network based methods</p><p>• LSTM: Vanilla bi-directional LSTM with pre-trained word embeddings 3 .</p><p>• RNCRF ( <ref type="bibr" target="#b20">Wang et al., 2016)</ref>: Dependency Tree based Recursive Neural Network with CRF extractor 4 .</p><p>For datasets in the restaurant domain, we train word embeddings of dimension 200 with word2vec ( <ref type="bibr" target="#b9">Mikolov et al., 2013</ref>) on Yelp reviews <ref type="bibr">5</ref> . For those in laptop domain, we use pre-trained glove.840B.300d 6 .</p><p>2 http://sklearn-crfsuite.readthedocs.io/en/latest/ 3 As we use our own implementation of LSTM, the re- ported results are different from those in ( <ref type="bibr" target="#b7">Liu et al., 2015)</ref> 4 Specifically, we list the result of RNCRF over D1 with- out opinion annotations for fair comparison. As no result is provided for RNCRF-no-opinion over D2, we report the cor- responding performance of the full model. See their follow- ing works ( <ref type="bibr">Wang et al., 2017a,b)</ref>. Also, CMLA ( <ref type="bibr" target="#b21">Wang et al., 2017a</ref>) reports better results than RNCRF but we do not com- pare with it. The reason is that CMLA introduces the gold standard opinion labels in the training data while such labels are not available for our experiments <ref type="bibr">5</ref>   The hyper-parameters are selected via ten-fold cross validation. The dimension of hidden repre- sentations are 100, 20, 40 for A-LSTM, O-LSTM and S-LSTM respectively. The dropout rate for O-LSTM and S-LSTM is 0.4. The size of the as- pect (opinion) memory n m is 4. The batch size is set to 32. As for initialization of network parame- ters, we adopt the strategy that the initial weights are sampled from the uniform distribution <ref type="bibr">(Glorot and Bengio, 2010)</ref>. We employ ADAM ( <ref type="bibr" target="#b1">Kingma and Ba, 2014</ref>) as optimizer and the default settings of ADAM are used.</p><p>To better reveal the capability of the proposed MIN, we train 5 models with the same group of hyper-parameters and report the average F 1 score over the testing set. With memory interactions and consideration of sentimental sentence, our MIN boosts the performance of vanilla bi-directional LSTM (+2.0% and +1.7% respectively). It vali- dates the effectiveness of the manually designed memory operations and the proposed memory in- teraction mechanism. MIN also outperforms the state-of-the-art RNCRF on each dataset suggest- ing that memory interactions can be an alterna- tive strategy instead of syntactic parsing. To fur- ther study the impact of each element in MIN, we conduct ablation experiments. As shown in Ta- ble 3, removing bi-directionality decreases the ex- traction performances (-2.0% and -1.0%). The soft sentimental constraint proves to be useful since MIN is 1.5% and 1.0% superior than the frame- work without S-LSTM on D 1 and D 2 respec- tively. O-LSTM brings in the largest performance gains on D 2 compared with ablated framework (i.e., MIN without O-LSTM), verifying our pos- tulation that aspect-opinion "interaction" is more effective than only considering aspect terms. We also observe that the contribution of O-LSTM is less significant than that of bi-directionality on D 1 (+1.6% vs +2.0%). This is reasonable since using opinion words as adjective modifiers placed after the aspects is common in English.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results and Analysis</head><formula xml:id="formula_10">D 1 D 2 MIN without bi-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>We propose Memory Interaction Network (MIN), a multi-task learning framework, to detect aspect terms from the online user reviews. Compared with previous studies, our MIN has following fea- tures:</p><p>• Co-occurrence pattern between aspects and opinions is captured via memory interactions, where the neural memory operations are de- signed to summarize task-level information and perform interactions.</p><p>• A novel LSTM unit with extended memories is developed for memory interactions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Experiment results</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 depicts experiment results.</head><label>2</label><figDesc></figDesc><table>Compared 
to the best systems in SemEval challenge, MIN 
achieves 3.0% and 1.1% absolute gains on D 1 and 
D 2 respectively. Besides, our MIN outperforms 
WDEmb, a strong CRF-based system benefiting 
from several kinds of useful word embeddings, 
by 2.1% on D 1 . </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 : Ablation experiment results.</head><label>3</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://mpqa.cs.pitt.edu/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An empirical exploration of recurrent network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2342" to="2350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis lectures on human language technologies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="167" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Opinion target extraction using partially-supervised word alignment model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2134" to="2140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Opinion target extraction using word-based translation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP/CoNLL</title>
		<meeting>EMNLP/CoNLL</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1346" to="1356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Syntactic patterns versus word alignment: Extracting opinion targets from online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1754" to="1763" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Extracting opinion targets and opinion words from online reviews with graph co-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="314" to="324" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Finegrained opinion mining with recurrent neural networks and word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1433" to="1443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Aspect term extraction for sentiment analysis in large movie reviews using gini index feature selection method and svm classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepa</forename><surname>Asha S Manek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Wide Web Journal</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="154" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 5: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al-</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmoud</forename><surname>Smadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Al-Ayyoub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronique</forename><surname>Orphee De Clercq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marianna</forename><surname>Hoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Apidianaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Loukachevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kotelnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>Núria Bel, Salud María Jiménez-Zafra</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="19" to="30" />
		</imprint>
	</monogr>
	<note>and GülsGüls¸en Eryi˘ git</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 4: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harris</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
		<meeting>the 8th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="27" to="35" />
		</imprint>
	</monogr>
	<note>Ion Androutsopoulos, and Suresh Manandhar</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Extracting product features and opinions from reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana-Maria</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="339" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Aspect extraction for opinion mining with a deep convolutional neural network. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Opinion word expansion and target extraction through double propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="27" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Elixa: A modular and flexible absa platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xabier</forename><surname>Iñaki San Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Saralegi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Agerri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="748" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semimarkov conditional random fields for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William W Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1185" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Nlangp at semeval2016 task 5: Improving aspect based sentiment analysis using neural network features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Toh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="282" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dlirec: Aspect term extraction and term polarity classification system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Toh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenting</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
		<meeting>the 8th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="235" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Multi-task coupled attentions for categoryspecific aspect and opinion terms co-extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahlmeier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01776</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Recursive neural conditional random fields for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="616" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Coupled multi-layer attentions for co-extraction of aspect and opinion terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3316" to="3322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Aueb-absa at semeval-2016 task 5: Ensembles of classifiers and embeddings for aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dionysios</forename><surname>Xenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panagiotis</forename><surname>Theodorakakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="312" to="317" />
		</imprint>
	</monogr>
	<note>Prodromos Malakasiotis, and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unsupervised word and dependency path embeddings for aspect term extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaimeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2979" to="2985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Movie review mining and summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao-Yan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
