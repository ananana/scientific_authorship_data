<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Incorporating Trustiness and Collective Synonym/Contrastive Evidence into Taxonomy Construction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luu</forename><surname>Anh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Engineering</orgName>
								<orgName type="department" key="dep2">Institute for Infocomm Research</orgName>
								<orgName type="department" key="dep3">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan</forename><surname>#1</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Engineering</orgName>
								<orgName type="department" key="dep2">Institute for Infocomm Research</orgName>
								<orgName type="department" key="dep3">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Jae</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Engineering</orgName>
								<orgName type="department" key="dep2">Institute for Infocomm Research</orgName>
								<orgName type="department" key="dep3">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">See</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Engineering</orgName>
								<orgName type="department" key="dep2">Institute for Infocomm Research</orgName>
								<orgName type="department" key="dep3">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kiong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Engineering</orgName>
								<orgName type="department" key="dep2">Institute for Infocomm Research</orgName>
								<orgName type="department" key="dep3">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Incorporating Trustiness and Collective Synonym/Contrastive Evidence into Taxonomy Construction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Taxonomy plays an important role in many applications by organizing domain knowledge into a hierarchy of is-a relations between terms. Previous works on the taxo-nomic relation identification from text corpora lack in two aspects: 1) They do not consider the trustiness of individual source texts, which is important to filter out incorrect relations from unreliable sources. 2) They also do not consider collective evidence from synonyms and contrastive terms, where synonyms may provide additional supports to taxonomic relations, while contrastive terms may contradict them. In this paper, we present a method of taxonomic relation identification that incorporates the trustiness of source texts measured with such techniques as PageR-ank and knowledge-based trust, and the collective evidence of synonyms and con-trastive terms identified by linguistic pattern matching and machine learning. The experimental results show that the proposed features can consistently improve performance up to 4%-10% of F-measure.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Taxonomies which serve as backbone of struc- tured knowledge are useful for many applica- tions such as question answering ( <ref type="bibr" target="#b10">Harabagiu et al., 2003</ref>) and document clustering <ref type="bibr" target="#b5">(Fodeh et al., 2011</ref>). Even though there are many hand-crafted, well-structured taxonomies publicly available, in- cluding WordNet <ref type="bibr" target="#b19">(Miller, 1995)</ref>, OpenCyc <ref type="bibr" target="#b18">(Matuszek et al., 2006</ref>), and Freebase ( <ref type="bibr" target="#b2">Bollacker et al., 2008)</ref>, they are incomplete in specific domains, and it is time-consuming to manually extend them or create new ones. There is thus a need for auto- matically extracting taxonomic relations from text corpora to construct/extend taxonomies. Previous works on the task of taxonomy con- struction capture information about potential tax- onomic relations between concepts, rank the can- didate relations based on the captured information, and integrate the highly ranked relations into a tax- onomic structure. They utilize such information as hypernym patterns (e.g. A is a B, A such as B) ( <ref type="bibr" target="#b16">Kozareva et al., 2008)</ref>, syntactic dependency <ref type="bibr" target="#b4">(Drumond and Girardi, 2010)</ref>, definition sentences ( <ref type="bibr" target="#b21">Navigli et al., 2011</ref>), co-occurrence ( <ref type="bibr" target="#b26">Zhu et al., 2013)</ref>, syntactic contextual similarity ( <ref type="bibr" target="#b22">Tuan et al., 2014)</ref>, and sibling relations ( <ref type="bibr" target="#b1">Bansal et al., 2014</ref>).</p><p>They, however, lack in the three following as- pects: 1) Trustiness: Not all sources are trust- worthy (e.g. gossip, forum posts written by non-experts) ( <ref type="bibr" target="#b3">Dong et al., 2015)</ref>. The trustiness of source texts is important in taxonomic rela- tion identification because evidence from unre- liable sources can be incorrect. For example, the invalid taxonomic relation between "American chameleon" and "chameleon" is mistakenly more popular in the Web than the valid taxonomic rela- tion between "American chameleon" and "lizard", and statistical methods without considering the trustiness may incorrectly extract the invalid rela- tion instead of the latter. However, to the best of our knowledge, no previous work considered this aspect.</p><p>2) Synonyms: A concept may be expressed in multiple ways, for example with synonyms. The previous works mostly assumed that a term repre- sents an independent concept, and did not combine information about a concept, which is expressed with multiple synonyms. The lack of evidence from synonyms may hamper the ranking of can- didate taxonomic relations. <ref type="bibr" target="#b20">Navigli and Velardi (2004)</ref> combined synonyms into a concept, but only for those from WordNet, called synsets.</p><p>3) Contrastive terms: We observe that if two terms are often contrasted (e.g. A but not B, A is different from B) ( <ref type="bibr" target="#b13">Kim et al., 2006</ref>), they may not have a taxonomic relation.</p><p>In this paper, we present a method based on the state-of-the-art method <ref type="bibr" target="#b22">(Tuan et al., 2014</ref>), which incorporates the trustiness of source texts and the collective evidence from synonyms/contrastive terms. <ref type="bibr" target="#b22">Tuan et al. (2014)</ref> rank candidate tax- onomic relations based on such evidence as hy- pernym patterns, WordNet, and syntactic contex- tual similarity, where the pattern matches and the syntactic contexts are found from the Web by us- ing a Web search engine. First, we calculate the trustiness score of each data source with the four following weights: importance (if it is linked by many pages), popularity (if it is visited by many users), authority (if it is from a creditable Web site) and accuracy (if it has many facts). We integrate this score to the work of ( <ref type="bibr" target="#b22">Tuan et al., 2014</ref>) so that evidence for taxonomic relations from unreliable sources is discarded.</p><p>Second, we identify synonyms of two terms (t 1 , t 2 ), whose taxonomic relation is being scrutinized, by matching such queries as "t 1 also known as" against the Web to find t 1 's synonyms next to the query matches (e.g. t in "t 1 also known as t"). We then collect the evidence for all taxonomic rela- tions between t 1 and t 2 , where t i is either t i or its synonym (i ∈ {1, 2}), and combine them to calcu- late the evidence score of the candidate taxonomic relation between t 1 and t 2 . Similarly, for each pair of two terms (t 1 , t 2 ), we collect their contrastive evidence by matching such queries as "t 1 is not a type of t 2 " against the Web, and use them to pro- portionally decrease the evidence score for taxo- nomic relation between contrasting terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The previous methods for identifying taxonomic relations from text can be generally classified into two categories: linguistic and statistical ap- proaches. The former approach mostly exploits lexical-syntactic patterns (e.g. A is a B, A such as B) <ref type="bibr" target="#b12">(Hearst, 1992)</ref>. Those patterns can be man- ually created ( <ref type="bibr" target="#b16">Kozareva et al., 2008;</ref><ref type="bibr" target="#b23">Wentao et al., 2012</ref>) or automatically identified <ref type="bibr" target="#b21">(Navigli et al., 2011;</ref><ref type="bibr" target="#b1">Bansal et al., 2014</ref>). The pattern matching methods show high precision when the patterns are carefully defined, but low coverage due to the lack of contextual analysis across sentences.</p><p>The latter approach, on the other hand, includes asymmetrical term co-occurrence <ref type="bibr" target="#b6">(Fotzo and Gallinari, 2004</ref>), clustering ( <ref type="bibr" target="#b24">Wong et al., 2007)</ref>, syn- tactic contextual similarity ( <ref type="bibr" target="#b22">Tuan et al., 2014)</ref>, and word embedding ( <ref type="bibr" target="#b8">Fu et al., 2014</ref>). The main idea behind these techniques is that the terms that are asymmetrically similar to each other with regard to, for example, co-occurrences, syntactic con- texts, and latent vector representation may have taxonomic relationships. Such methods, however, usually suffer from low accuracy, though show- ing relatively high coverage. To get the balance between the two approaches, <ref type="bibr" target="#b25">Yang and Callan (2009)</ref>, <ref type="bibr" target="#b26">Zhu et al. (2013)</ref> and <ref type="bibr" target="#b22">Tuan et al. (2014)</ref> combine both statistical and linguistic features in the process of finding taxonomic relations.</p><p>Most of these previous methods do not consider if the source text of evidence (e.g. co-occurrences, pattern matches) is trustworthy or not and do not combine evidence from synonyms and contrastive terms as discussed earlier. Related to synonyms, a few previous works utilize siblings for taxonomy construction. <ref type="bibr" target="#b25">Yang and Callan (2009)</ref> use siblings as one of the features in the metric-based frame- work which incrementally clusters terms to form taxonomies. <ref type="bibr" target="#b23">Wentao et al. (2012)</ref> also utilize such sibling feature that, for example of the linguistic pattern "A such as B 1 , B 2 , · · · and B n ", if the concept at the k-th position (e.g. B k ) from pat- tern keywords (e.g. such as) is a valid sub-concept (e.g. of A), then most likely its siblings from po- sition 1 to position k-1 (e.g. B 1 , · · · , B k−1 ) are also valid sub-concepts. <ref type="bibr" target="#b1">Bansal et al. (2014)</ref> in- clude the sibling factors to a structured probabilis- tic model over the full space of taxonomy trees, thus helping to add more evidence to taxonomic relations. <ref type="bibr" target="#b20">Navigli and Velardi (2004)</ref> utilize the synonym feature (i.e. WordNet synsets) for the process of semantic disambiguation and concept clustering as mentioned above, but not for the pro- cess of inducing novel taxonomic relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>We briefly introduce ( <ref type="bibr" target="#b22">Tuan et al., 2014</ref>) in Section 3.1. We then explain how to incorporate trustiness (Section 3.2) and collective evidence from syn- onyms (Section 3.3) and from contrastive terms (Section 3.4) into the work of ( <ref type="bibr" target="#b22">Tuan et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of baseline (Tuan et al., 2014)</head><p>Tuan et al. (2014) follow three steps to construct a taxonomy: term extraction/filtering, taxonomic re- lation identification and taxonomy induction. Be- cause the focus of this paper is on the second step, taxonomic relation identification, we use the same methods for the first and third steps as in <ref type="bibr" target="#b22">(Tuan et al., 2014</ref>) and will not discuss them here.</p><p>Given each ordered pair of two terms t 1 and t 2 from the term extraction/filtering, the taxonomic relation identification of ( <ref type="bibr" target="#b22">Tuan et al., 2014</ref>) calcu- lates the evidence score that t 1 is a hypernym of t 2 (denoted as t 1 t 2 ) based on the following three measures:</p><p>String inclusion with WordNet (SIWN): This measure is to check if t 1 is a substring of t 2 , con- sidering synonymy between words using WordNet synsets. Score SIW N (t 1 , t 2 ) is set to 1 if there is such evidence; otherwise, it is set to 0.</p><p>Lexical-syntactic pattern (LSP): This measure is to find how much more evidence for t 1 t 2 is found in the Web than for t 2 t 1 . Specif- ically, a list of manually constructed hypernym patterns (e.g. "t 2 is a t 1 ") is queried with a Web search engine to estimate the number of evidence for t 1 t 2 from the Web. The LSP measure is calculated as follows, where C W eb (t 1 , t 2 ) denotes the collection of search results:</p><formula xml:id="formula_0">Score LSP (t 1 , t 2 ) = log(|C W eb (t 1 ,t 2 )|) 1+log(|C W eb (t 2 ,t 1 )|)</formula><p>Syntactic contextual subsumption (SCS): The idea of this measure is to derive the hypernymy evidence for two terms t 1 and t 2 from their syntac- tic contexts, particularly from the triples of (sub- ject,verb,object). They observe that if the context set of t 1 mostly contains that of t 2 but not vice versa, then t 1 is likely to be a hypernym of t 2 . To implement this idea, they first find the most com- mon relation (or verb) r between t 1 and t 2 , and use the queries "t 1 r" and "t 2 r" to construct two corpora Corpus Γ t 1 and Corpus Γ t 2 for t 1 and t 2 , re- spectively. Then the syntactic context sets are cre- ated from these contextual corpora using a non- taxonomic relation identification method. The de- tails of calculating Score SCS (t 1 , t 2 ) can be found in ( <ref type="bibr" target="#b22">Tuan et al., 2014</ref>).</p><p>They linearly combine the three scores as follows:</p><formula xml:id="formula_1">Score(t1, t2) = α × ScoreSIW N (t1, t2) + β × ScoreLSP (t1, t2) + γ × ScoreSCS(t1, t2)<label>(1)</label></formula><p>If Score(t 1 , t 2 ) is greater than a threshold value, then t 1 is regarded as a hypernym of t 2 . We use the same values of α, β and γ as in ( <ref type="bibr" target="#b22">Tuan et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Trustiness of the evidence data</head><p>We introduce our method of estimating the trusti- ness of a given source text in Section 3.2.1 and ex- plain how to incorporate it into the work of ( <ref type="bibr" target="#b22">Tuan et al., 2014</ref>) in Section 3.2.2.</p><p>3.2.1 Collecting trustiness score of the evidence data Given a data source (e.g. Web page), we consider four aspects of trustiness as follows:</p><p>• Importance: A data source may be important if it is referenced by many other sources.</p><p>• Popularity: If a data source is accessed by many people, it is considered popular.</p><p>• Authority: If the data is created by a trusted agency, such as government and education institute, it may be more trustful than others from less trusted sources such as forums and social media.</p><p>• Accuracy: If the data contains many pieces of accurate information, it seems trustful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Importance</head><p>To measure the importance of a Web page (d) as data source, we use the Google PageRank score 1 (Score P ageRank (d)) that is calculated based on the number and quality of links to the page. The PageRank scores have the scale from 0 to 9, where the bigger score means more importance than the lower one. Using this score, the importance of a page is calculated as follows:</p><formula xml:id="formula_2">T rustImp(d) = 1 10 − Score P ageRank (d)<label>(2)</label></formula><p>Note that we use the non-linearity for PageR- ank score rather than just normalizing PageRank to 0-1. The reason is to vary the gaps between the important sites (which usually have the PageRank score value from 7-10) and majority unimportant site (which usually have the PageRank score value less than 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Popularity</head><p>We use Alexa's Traffic Rank 2 as the measure of popularity, (Score Alexa (d)) which is based on the traffic data provided by users in Alexa's global data panel over a rolling 3 month period. The Traffic Ranks are updated daily. A site's rank is based on a combined measure of unique visitors and page views. Using this rank, the popularity of a data source is calculated as follows:</p><formula xml:id="formula_3">T rustP op(d) = 1 log(Score Alexa (d) + 1)<label>(3)</label></formula><p>We use log transform in the popularity score in- stead of, for example, linear scoring because we want to avoid the bias of the much large gap be- tween the Alexa scores of different sites (e.g. one site has Alexa score 1000, but the other may have score 100,000)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Authority</head><p>We rank the authority of a data source based on the internet top-level domain (TLD). We observe that the pages with limited and registered TLD (e.g. .gov, .mil, .edu) are often more credible than those with open domain (e.g. .com, .net). Therefore, the authority score of a data source is calculated as follows:</p><formula xml:id="formula_4">T rust Auth (d) = 1 if TLD of d is .gov, .mil or .edu 0 otherwise (4)</formula><p>Note that there are some reasons we choose such implementation of Authority in an elemen- tary way. First, we tried finer categorization of various domains, e.g. .int has score 1/3, .com has score 1/4, etc. However, the experimental results did not show much change of performance. In ad- dition, there is controversy on which open TLD domains are more trustful than the others, e.g. it is difficult to judge whether a .net site is more trust- ful than .org or not. Thus, we let all open TLD domains have the same score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy</head><p>If the data source contains many pieces of accu- rate information, it is trustful. Inspired by the idea of <ref type="bibr" target="#b3">Dong et al. (2015)</ref>, we estimate the accuracy of a data source by identifying correct and incorrect information in form of the triples (Subject, Predi- cate, Object) in the source, where Subject, Predi- cate and Object are normalized with regard to the knowledge base Freebase. The extraction of the triples includes six tasks: named entity recogni- tion, part of speech tagging, dependency parsing, triple extraction, entity linkage (which maps men- tions of proper nouns and their co-references to the corresponding entities in Freebase) and rela- tion linkage. We use three information extraction (IE) tools ( <ref type="bibr" target="#b0">Angeli et al. (2014)</ref>, , MITIE 3 ) for the first four tasks, and de- velop a method similar to <ref type="bibr" target="#b9">Hachey et al. (2013)</ref> for the last two tasks of entity linkage and relation linkage.</p><p>Since the IE tools may produce noisy or unre- liable triples, we use a voting scheme for triple extraction as follows: A triple is only considered to be true if it is extracted by at least two extrac- tors. After obtaining all triples in the data source, we use the closed world assumption as follows: Given subject s and predicate p, O(s, p) denotes the set of such objects that a triple (s,p,o) is found in Freebase. Now given a triple (s,</p><note type="other">p, o) found in the data source, if o ∈ O(s, p), we conclude that the triple is correct; but if o ∈ O(s, p) and |O(s, p)| &gt; 0, we conclude that the triple is incor- rect. If |O(s, p)| = 0, we do not conclude any- thing about the triple, and the triple is removed from the set of facts found in the data source. Given a data source d, we define cf (d) as the number of correct facts, and icf (d) as the number of incorrect facts found in d. The accuracy of d is calculated as follows:</note><formula xml:id="formula_5">T rustAccu(d) = 1 1 + icf (d) 2 − 1 1 + cf (d) 2<label>(5)</label></formula><p>Combining trustiness scores The final trustiness score of a data source is the linear combination of the four scores as follows:</p><formula xml:id="formula_6">T rust(d) = α × T rustImp(d) + β × T rustP op(d) + γ × T rust Auth (d) + δ × T rustAccu(d)<label>(6)</label></formula><p>To estimate the optimal combination for parame- ters α, β, γ and δ, we apply linear regression algo- rithm ( <ref type="bibr">Hastie et al., 2009</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Integrating trustiness into taxonomic relation identification methods</head><p>Given a data collection C, we define:</p><formula xml:id="formula_7">AvgT rust(C) = d∈C T rust(d) |C|</formula><p>as the average trustiness score of all data in C.</p><p>We integrate the trustiness score to the three tax- onomic relation identification methods described in Section 3.1 as follows:</p><formula xml:id="formula_8">LSP method:</formula><p>The LSP evidence score of the taxonomic relation between t 1 and t 2 is recalculated as follows:</p><formula xml:id="formula_9">Score T rust LSP (t1, t2) = ScoreLSP (t1, t2)× (AvgT rust(C W eb (t1, t2)) + AvgT rust(C W eb (t2, t1)))<label>(7)</label></formula><p>The intuition of Formula 7 is that the original LSP evidence score is multiplied with the average trustiness score of all evidence documents for the taxonomic relation from the Web. If the number of Web search results is too large, we use only the first 1,000 results to estimate the average trustiness score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SCS method:</head><p>Similarly, the SCS evidence score is recalculated as follows:</p><formula xml:id="formula_10">Score T rust SCS (t1, t2) = ScoreSCS(t1, t2)× (AvgT rust(Corpus Γ t 1 ) + AvgT rust(Corpus Γ t 2 ))<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SIWN method:</head><p>This method does not use any evidence from the Web, and so its measure does not change as fol- lows:</p><formula xml:id="formula_11">Score T rust SIW N (t1, t2) = ScoreSIW N (t1, t2)<label>(9)</label></formula><p>The three measures of trustiness are also linearly combined as follows:</p><formula xml:id="formula_12">Score T rust (t1, t2) = α × Score T rust SIW N (t1, t2)+ β × Score T rust LSP (t1, t2) + γ × Score T rust SCS (t1, t2)<label>(10)</label></formula><p>The values of α, β, and γ in Formula 10 are identical to those for Formula 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Collective synonym evidence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Synonymy identification</head><p>We use the three following methods to collect syn- onyms: dictionaries, pattern matching, and super- vised learning.</p><p>Dictionaries: Synonyms can be found in dic- tionaries like a general-purpose dictionary Word- Net and also domain-specific ones. Since our do- mains of interest include virus, animals, and plants (see the next section for details), we also utilize MeSH 5 , a well-known vocabulary in biomedicine.</p><p>Pattern matching: Given two terms t 1 and t 2 , we use the following patterns to find their synonymy evidence from the Web:</p><p>• t1 also [known|called|named|abbreviated] as t2</p><formula xml:id="formula_13">• Other common name[s] of t1 [is|are|include] t2</formula><p>• t1, or t2, is a</p><p>• t1 (short for t2)</p><p>, where <ref type="bibr">[a|b]</ref> denotes a choice between a and b. If the number of Web search results is greater than a threshold Ψ, t 1 is considered as a synonym of t 2 .</p><p>Supervised learning: We randomly pick 100 pairs of synonyms in WordNet, and for each pair, we use the Web search engine to collect sample sentences in which both terms of the pair are men- tioned. If the number of collected sentences is greater than 2000, we use only the first 2000 sen- tences for training. After that, we extract the fol- lowing features from the sentences to train a logis- tic regression model ( <ref type="bibr">Hastie et al., 2009</ref>) for the synonymy identification:</p><p>• Headwords of the two terms</p><p>• Average distance between the terms</p><p>• Sequence of words between the terms</p><p>• Bag of words between the terms</p><p>• Dependency path between the terms (using Stanford parser ( <ref type="bibr" target="#b14">Klein and Manning, 2003)</ref>)</p><p>• Bag of words on the dependency path</p><p>The average F-measure of the obtained model with 10-fold cross-validation is 81%. We use the learned model to identify more synonym pairs in the next step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Embedding synonym information</head><p>Given a term t, we denote Syn(t) as the set of synonyms of t (including t itself). The evidence scores of the SCS and LSP methods are recalcu- lated with synonyms as follows:</p><formula xml:id="formula_14">Score Synonym X (t1, t2) = t 1 ∈Syn(t 1 ) t 2 ∈Syn(t 2 ) ScoreX (t 1 , t 2 ) (11)</formula><p>, where the variable X can be replaced with SCS and LSP.</p><p>The intuition of Formula <ref type="formula" target="#formula_1">(11)</ref> is that the evi- dence score of the taxonomic relation between two terms t 1 and t 2 can be boosted by adding all the evidence scores of taxonomic relations between them and their synonyms.</p><p>Again, as for the SIWN method, we do not change the evidence score as follows:</p><formula xml:id="formula_15">Score Synonym SIW N (t1, t2) = ScoreSIW N (t1, t2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Contrastive evidence</head><p>Given two terms t 1 and t 2 , we use the following patterns to find their contrastive (thus negative) ev- idence from the Web:</p><p>• t1 is not a t2</p><p>• t1 is not a [type|kind] of t2</p><p>• t1, unlike the t2</p><formula xml:id="formula_16">• t1 is different [from|with] t2</formula><p>• t1 but not t2</p><p>• t1, not t2 W H(t 1 , t 2 ) denotes the total number of Web search results, and the contrastive evidence score between t 1 and t 2 is computed as follows:</p><formula xml:id="formula_17">Contrast(t1, t2) = log(W H(t1, t2) + 1)<label>(12)</label></formula><p>Similar to the collective synonym evidence, the contrastive evidence score of taxonomic relation between t 1 and t 2 is boosted with the contrastive evidence scores of taxonomic relations between the two terms and their synonyms as follows:</p><formula xml:id="formula_18">Score Contrast (t1, t2) = t 1 ∈Syn(t 1 ) t 2 ∈Syn(t 2 ) Contrast(t 1 , t 2 ) |Syn(t1)| * |Syn(t2)|<label>(13)</label></formula><p>3.5 Combining trustiness, synonym and contrastive evidence</p><p>We combine all the three features into the system of ( <ref type="bibr" target="#b22">Tuan et al., 2014</ref>) as follows:</p><formula xml:id="formula_19">Score F inal X (t1, t2) =Score T rust X (t1, t2) + Score Synonym X (t1, t2)<label>(14)</label></formula><p>, where the variable X can be replaced with each of the three taxonomic relation evidence measures (i.e. SCS, LSP, SIWN). The final combined score is calculated as follows:</p><formula xml:id="formula_20">Score F inal Combined (t1, t2) = α × Score F inal SIW N (t1, t2) + β × Score F inal LSP (t1, t2) + γ × Score F inal SCS (t1, t2) − δ × Score Contrast (t1, t2)<label>(15)</label></formula><p>For each ordered pair of terms t 1 and t 2 , if Score F inal Combined (t 1 , t 2 ) is greater than a threshold value, then t 1 is considered as a hypernym of t 2 .</p><p>We estimate the optimal values of parameters α, β, γ and δ in Formula 15 with ridge regres- sion technique <ref type="bibr">(Hastie et al., 2009)</ref> as follows: First, we randomly select 100 taxonomic relations in Animal domain as the training set. For each taxonomic relation t 1 t 2 , its evidence score is estimated as τ + 1 Dist(t 1 ,t 2 ) , where τ is the thresh- old value for Score F inal Combined , and Dist(t 1 , t 2 ) is the length of the shortest path between t 1 and t 2 found in WordNet. Then we use our system to find evidence scores with taxonomic relation iden- tification methods in Formulas 13 and 14. Finally, we build the training set using Formula 15, and use the ridge regression algorithm to learn that the best value for α is 1.31, β 1.57, γ 1.24 and δ 0.79, where τ =2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We evaluate our method for taxonomy construc- tion against the following collections of six do- mains:</p><p>• Artificial Intelligence (AI) domain: The cor- pus consists of 4,976 papers extracted from the IJCAI proceedings from 1969 to 2014 and the ACL archives from year 1979 to 2014.</p><p>• Finance domain: The corpus consists of 1,253 papers extracted from the freely avail- able collection of "Journal of Financial Eco- nomics" from 1995 to 2012 and from "Re- view Of Finance" from 1997 to 2012.</p><p>• Virus domain: We submit the query "virus" to PUBMED search engine <ref type="bibr">6</ref> and retrieve the first 20,000 abstracts as the corpus of the virus domain.</p><p>• Animals, Plants and Vehicles domains: Col- lections of Web pages crawled by using the bootstrapping algorithm described by <ref type="bibr" target="#b16">Kozareva et al. (2008)</ref>.</p><p>We report the results of two experiments in this section: (1) Evaluating the construction of new taxonomies for Finance and AI domains (Sec- tion 4.2), and (2) comparing with the curated databases' sub-hierarchies. We compare our ap- proach with other three state-of-the-art methods in the literature, i.e. ( <ref type="bibr" target="#b15">Kozareva and Hovy, 2010)</ref>, <ref type="bibr" target="#b21">(Navigli et al., 2011</ref>) and ( <ref type="bibr" target="#b22">Tuan et al., 2014</ref>) (Sec- tion 4.3). In addition, for Animal domain, we also compare with the reported performance of <ref type="bibr" target="#b1">Bansal et al. (2014)</ref>, a recent work to construct taxonomy using belief propagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Constructing new taxonomies for Finance and AI domains</head><p>Referential taxonomy structures such as WordNet and OpenCyc are widely used in semantic analyt- ics applications. However, their coverage is lim- ited to common, well-known areas, and many spe- cific domains like Finance and AI are not well cov- ered in those structures. Therefore, an automatic method which can induce taxonomies for those specific domains can greatly contribute to the pro- cess of knowledge discovery.</p><p>To estimate the precision of a given method, we randomly choose 100 relations among the results of the method and manually check their correct- ness. The results summarized in <ref type="table">Table 1</ref> show that our method extracts much more relations, though with slightly lower precision, than <ref type="bibr" target="#b16">Kozareva et al. (2008)</ref> and <ref type="bibr" target="#b20">Navigli and Velardi (2004)</ref>. Note that due to the lack of gold standards in these two do- mains, we do not compare the methods in terms of F-score, which we will measure with curated databases in the next section. Compared to <ref type="bibr" target="#b22">Tuan et al. (2014)</ref>, which can be considered as the base- line of our approach, our method has significant improvement in both precision and the number of extracted relations. It indicates that the three incorporated features of trustiness, and synonym and contrastive evidence are effective in improv- ing the performance of existing taxonomy con- struction methods.   <ref type="table">Table 1</ref>: Experiment result for finance and AI do- mains. P stands for Precision, and N indicates the number of extracted relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation against curated databases</head><p>We evaluate automatically constructed tax- onomies for four domains (i.e. Animal, Plant, Vehicle, Virus) against the corresponding sub- hierarchies of curated databases. For Animal, Plant and Vehicle domains, we use WordNet as the gold standards, whereas for Virus domain, we use MeSH sub-hierarchy of virus as the reference. Note that in this comparison, to be fair, we change our algorithm to avoid using WordNet in identifying taxonomic relations (i.e. SIWN algo- rithm), and we only use the exact string-matching comparison without WordNet. The evaluation uses the following measures: To understand the individual contribution of the three introduced features (i.e. trustiness, synonym, contrast), we also evaluate our method only with one of the three features each time, as well as with all the three features (denoted as "Combined"). <ref type="table" target="#tab_3">Tables 2 and 3</ref> summarize the experiment re- sults. Our combined method achieves significantly better performance than the previous state-of-the- art methods in terms of F-measure and Recall (t- test, p-value &lt; 0.05) for all the four domains. For Animal domain, it also shows higher perfor- mance than the reported performance of <ref type="bibr" target="#b1">Bansal et al. (2014)</ref>. In addition, the proposed method im- proves the baseline (i.e. <ref type="bibr" target="#b22">Tuan et al. (2014)</ref>) up to 4%-10% of F-measure.</p><p>Furthermore, we find that the three features have different contribution to the performance im- provement. The trustiness feature contributes to the improvement on both precision and recall. The synonym feature has the tendency of improving the recall further than the trustiness, whereas the contrastive evidence improves the precision. Note that we discussed these different contributions of the features in the Introduction.   <ref type="table" target="#tab_3">P  R  F  P  R  F  Kozareva  99 60 75  97 31 47  Navigli  91 49 64  99 37 54  Tuan  93 69 79  93 43 59  Trustiness  96 72 82  97 48 64  Synonym  91 72 80  91 53 67  Contrastive 97 68 80</ref> 98 42 59 Combined 95 73 83 96 54 69 <ref type="table">Table 3</ref>: Experiment results for vehicle and virus domains. P stands for Precision, R Recall, and F F-score. The unit is %.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Animal</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Evaluation of individual methods for trustiness and synonymy identification</head><p>We evaluate the individual methods for trusti- ness measurement and synonymy identification described in Sections 3.2.1 and 3.3.1. For this pur- pose, we evaluate our system only with one of the individual methods at a time (i.e. importance, pop- ularity, authority and accuracy for trustiness mea- sure, and dictionary, pattern matching, and ma- chine learning methods for synonymy identifica- tion).</p><p>As summarized in <ref type="table" target="#tab_5">Table 4</ref>, the "Importance" and "Accuracy" methods for trustiness measure- ment based on PageRank and IE systems, respec- tively, have more contribution than the others. Similarly, the experiment results indicate that the "Machine learning" method has the most contribu- tion among the three methods of synonymy iden- tification.</p><p>In addition, we also examine the interdepen- dence of the four introduced aspects of trustiness by running the system with the combination of only two aspects, Importance and Accuracy. The results in all domains show that when combining only the Importance and Accuracy, the system al- most achieves the same performance to that of the combined system with all four criteria, except for the Plant domain. It can be explained as the Impor- tance aspect (which is expressed as the PageRank score) may subsume the Popularity and Authority aspects. Another interesting point is that the per- formance of Accuracy, which is solely based on the local information from the website, when ap- plied individually, is almost the same with that of Importance which is based on the distributed in- formation. It shows that the method of ranking of the sites based on the knowledge-based facts can achieve the effectiveness as good as the traditional ranking method using PageRank score.  On the other hand, the true taxonomic rela- tion between 'bat' and 'flying fox' is not identi- fied by the baseline, mainly due to the rare men- tion of this relation in the Web. However, our proposed method can recognize this relation be- cause of two reasons: (1) 'flying fox' has many synonyms such as 'fruit bat', 'pteropus', 'kalong', and 'megabat', and there are much evidence that these synonyms are kinds of 'bat' (i.e. using the collective synonym evidence). (2) The ev- idence for the taxonomic relation between 'fly-ing fox' and 'bat', though rare, is from trusted sites 9 which are maintained by scientists. Thus, the trustiness feature helps to boost the evidence score for this relation over the threshold value. Specifically, the average trustiness score of LSP method (i.e. (AvgT rust(C W eb (bat, f lying f ox)) + AvgT rust(C W eb (f lying f ox, bat)))), 2.84, is higher than the average in total, 0.90.</p><p>We further investigate on 256 taxonomic rela- tions that were missed by the baseline but correctly identified by the proposed method. The average Score LSP and the average Score SCS of the re- lations by the baseline are 0.35 and 0.60, respec- tively, while those by the proposed method are 1.17 and 0.82, respectively. We thus find that the proposed method is more effective in correctly im- proving the LSP method than the SCS method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Empirical comparison with WordNet</head><p>By error analysis, we find that our results may complement WordNet. For example, in Animal domain, our method identifies 'wild sheep' as a hyponym of 'sheep', but in WordNet, they are sib- lings. However, many references 10 11 consider 'wild sheep' as a species of 'sheep'. Another such example is that our system recognizes 'aquatic vertebrate' as a hypernym of 'aquatic mammal', but WordNet places them in different subtrees in- correctly <ref type="bibr">12</ref> . Therefore, our results may help re- structure and extend WordNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Threshold tuning</head><p>Our scoring methods utilize several thresholds to select relations of high ranks. Here we discuss them in details below.</p><p>The threshold value Ψ for the pattern match- ing method in Section 3.3.1 controls the number of synonymy relations extracted from text. The threshold value for Score F inal Combined of Formula 15 in Section 3.5 controls the number of extracted taxonomic relations. In general, the larger these threshold values are, the higher number of syn- onyms and taxonomic relations we can get. In our experiments, we found that the threshold val- ues for Ψ between 100 and 120, and those for Score F inal Combined between 2.3 and 2.5 generally help the system achieve the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose the features of trusti- ness, and synonym and contrastive collective ev- idence for the task of taxonomy construction, and show that these features help the system improve the performance significantly. As future work, we will investigate into the task of automatically con- structing patterns for the pattern matching meth- ods in Sections 3.3 and 3.4, to improve cover- age. We will also enhance the accuracy measure of trustiness, based on the observation that some untrusted sites copy information from other sites to make them look more trustful.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Finance</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>P</head><label></label><figDesc>recision = #relations f ound in database and by the method #relations f ound by the method Recall = #relations f ound in database and by the method #relations f ound in database</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Experiment results for animal and plant 
domains. P stands for Precision, R Recall, and F 
F-score. The unit is %. 

1019 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Contribution of individual trustiness mea-
sures and collective synonym evidence in terms of 
F-measure. Imp stands for Important and Accu 
stands for Accuracy 

4.4 Discussion 

4.4.1 Case studies 

We give two examples to illustrate how the pro-
posed features help to infer correct taxonomic re-
lations and filter out incorrect relations. Our base-
line (Tuan et al. (2014)) extracts an incorrect taxo-
nomic relation between 'fox' and 'flying fox' due 
to the following reasons: (1) 'flying fox' includes 
'fox' (SIWN) and (2) untrusted sources such as 
a public forum 7 support the relation. Using our 
proposed method, this relation is filtered out be-
cause those untrusted sources are discouraged by 
the trustiness feature, and also because there are 
contrastive evidence 8 saying that 'flying fox' is 
NOT a 'fox'. Specifically, the average trustiness 
score of LSP method of the sources for the invalid 
relation (i.e. AvgT rust(C W eb (f ox, f lying f ox)) + 
AvgT rust(C W eb (f lying f ox, f ox))) is 0.63, which 
is lower than the average of those scores, 0.90. 
Also, the collective contrastive evidence score 
(i.e. Score Contrast (f ox, f lying f ox)) is 1.10, which 
is higher than the average collective contrastive 
score, 0.32. 
</table></figure>

			<note place="foot" n="1"> http://searchengineland.com/what-is-google-pageranka-guide-for-searchers-webmasters-11068 2 http://www.alexa.com/</note>

			<note place="foot" n="3"> https://github.com/mit-nlp/MITIE 4 http://www.ebizmba.com/articles/gossip-websites</note>

			<note place="foot" n="5"> http://www.ncbi.nlm.nih.gov/mesh</note>

			<note place="foot" n="6"> http://www.ncbi.nlm.nih.gov/pubmed</note>

			<note place="foot" n="7"> http://redwall.wikia.com/wiki/User:Ferretmaiden/Archive3 8 http://en.cc-english.com/index.php?shownews-1397</note>

			<note place="foot" n="9"> http://krjsoutheastasianrainforests.weebly.com/animalsin-biome-and-habitat-structures.html 10 http://en.wikipedia.org/wiki/Ovis 11 http://www.bjornefabrikken.no/side/norwegian-sheep/ 12 http://en.wikipedia.org/wiki/Aquatic mammal</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Combining Distant and Partial Supervision for Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods on Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1556" to="1567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Structured learning for taxonomy induction with belief propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Burkett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><forename type="middle">De</forename><surname>Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the ACL</title>
		<meeting>the 52nd Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1041" to="1051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Knowledge-Based Trust: Estimating the Trustworthiness of Web Sources. Proceedings of the VLDB Endowment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Van</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilko</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camillo</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Lugaresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Extracting ontology concept hierarchies from text using markov logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Drumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosario</forename><surname>Girardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Applied Computing</title>
		<meeting>the ACM Symposium on Applied Computing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1354" to="1358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">On ontology-driven document clustering using core semantic features. Knowledge and information systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samah</forename><surname>Fodeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Punch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><forename type="middle">N</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="395" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermine</forename><forename type="middle">N</forename><surname>Fotzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning &quot;generalization/specialization&quot; relations between concepts-application for automatically building thematic document hierarchies</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Computer-Assisted Information Retrieval</title>
		<meeting>the 7th International Conference on Computer-Assisted Information Retrieval</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning semantic hierarchies via word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiji</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the ACL</title>
		<meeting>the 52nd Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1199" to="1209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Hachey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
		<title level="m">Evaluating entity linking with Wikipedia. Artificial intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="130" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Open-domain textual question answering techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><forename type="middle">M</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Maiorano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><forename type="middle">A</forename><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="231" to="267" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Friedman. 2009. The elements of statistical learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><forename type="middle">H</forename></persName>
		</author>
		<imprint>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic acquisition of hyponyms from large text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marti</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference on Computational Linguistics</title>
		<meeting>the 14th Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="539" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Biocontrasts: extracting and exploiting protein-protein contrastive relations from biomedical literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">See</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="597" to="605" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Accurate Unlexicalized Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the ACL</title>
		<meeting>the 41st Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Semisupervised Method to Learn and Construct Taxonomies Using the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1110" to="1118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual Meeting of the ACL</title>
		<meeting>the 46th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1048" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the ACL</title>
		<meeting>the 52nd Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An introduction to the syntax and content of cyc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Witbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Deoliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Spring Symposium</title>
		<meeting>the AAAI Spring Symposium</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="44" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">WordNet: a Lexical Database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning Domain Ontologies from Document Warehouses and Dedicated Web Sites. Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Velardi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="151" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Graph-based Algorithm for Inducing Lexical Taxonomies from Scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Velardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Faralli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 20th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1872" to="1877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Taxonomy Construction using Syntactic Contextual Evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">J</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">See</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP conference</title>
		<meeting>the EMNLP conference</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="810" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Probase: A probabilistic taxonomy for text understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Wentao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Hongsong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Haixun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenny</forename><forename type="middle">Q</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD conference</title>
		<meeting>the ACM SIGMOD conference</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="481" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Tree-traversing ant algorithm for term clustering based on featureless similarities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilson</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Bennamoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="381" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Metricbased Framework for Automatic Taxonomy Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual Meeting of the ACL</title>
		<meeting>the 47th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Topic hierarchy construction for the organization of multi-source user generated contents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingwei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat</forename><forename type="middle">S</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th ACM SIGIR conference</title>
		<meeting>the 36th ACM SIGIR conference</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
