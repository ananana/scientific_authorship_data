<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Combining Supervised and Unsupervised Ensembles for Knowledge Base Population</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazneen</forename><forename type="middle">Fatema</forename><surname>Rajani</surname></persName>
							<email>nrajani@cs.utexas.edu,</email>
							<affiliation key="aff0">
								<orgName type="department">Department Of Computer Science</orgName>
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
							<email>mooney@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department Of Computer Science</orgName>
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Combining Supervised and Unsupervised Ensembles for Knowledge Base Population</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1943" to="1948"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose an algorithm that combines supervised and unsupervised methods to ensemble multiple systems for two popular Knowledge Base Population (KBP) tasks, Cold Start Slot Filling (CSSF) and Tri-lingual Entity Discovery and Linking (TEDL). We demonstrate that it outperforms the best system for both tasks in the 2015 competition, several ensem-bling baselines, as well as a state-of-the-art stacking approach. The success of our technique on two different and challenging problems demonstrates the power and generality of our combined approach to ensembling.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Ensembling multiple systems is a well known stan- dard approach to improving accuracy in several ma- chine learning applications <ref type="bibr" target="#b1">(Dietterich, 2000)</ref>. En- sembles have been applied to parsing <ref type="bibr" target="#b5">(Henderson and Brill, 1999</ref>), word sense disambiguation <ref type="bibr" target="#b8">(Pedersen, 2000</ref>), sentiment analysis <ref type="bibr" target="#b14">(Whitehead and Yaeger, 2010)</ref> and information extraction (IE) <ref type="bibr" target="#b3">(Florian et al., 2003;</ref><ref type="bibr" target="#b7">McClosky et al., 2012)</ref>. Recently, using stacking <ref type="bibr" target="#b15">(Wolpert, 1992)</ref> to ensemble sys- tems was shown to give state-of-the-art results on slot-filling and entity linking for Knowledge Base Population (KBP) ( <ref type="bibr" target="#b12">Viswanathan et al., 2015;</ref><ref type="bibr" target="#b9">Rajani and Mooney, 2016)</ref>. Stacking uses supervised learning to train a meta-classifier to combine multi- ple system outputs; therefore, it requires historical data on the performance of each system. <ref type="bibr" target="#b9">Rajani and Mooney (2016)</ref> use data from the 2014 iteration of the KBP competition for training and then test on the data from the 2015 competition, therefore they can only ensemble the shared systems that participated in both years.</p><p>However, we would sometimes like to ensem- ble systems for which we have no historical perfor- mance data. For example, due to privacy, some com- panies may be unwilling to share their performance on arbitrary training sets. Simple methods such as voting permit "unsupervised" ensembling, and sev- eral more sophisticated methods have also been de- veloped for this scenario ( <ref type="bibr" target="#b13">Wang et al., 2013)</ref>. How- ever, such methods fail to exploit supervision for those systems for which we do have training data. Therefore, we present an approach that utilizes su- pervised and unsupervised ensembling to exploit the advantages of both. We first use unsupervised en- sembling to combine systems without training data, and then use stacking to combine this ensembled system with other systems with available training data.</p><p>Using this new approach, we demonstrate new state-of-the-art results on two NIST KBP challenge tasks: Cold Start Slot-Filling (CSSF) 1 and the Tri- lingual Entity Discovery and Linking (TEDL) ( <ref type="bibr" target="#b6">Ji et al., 2015)</ref>. Our approach outperforms the best system as well as other state-of-the-art ensembling methods on both tasks in the most recent 2015 com- petition. There is one previous work on ensembling supervised and unsupervised models using graph- based consensus maximization ( <ref type="bibr" target="#b4">Gao et al., 2009</ref>), however we show that it does not do as well as our stacking method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview of KBP Tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cold Start Slot Filling (CSSF)</head><p>The goal of CSSF is to collect information (fills) about specific attributes (slots) for a set of entities (queries) from a given corpus. The query entities can be a person, organization, or geo-political entity (PER/ORG/GPE). The input is a set of queries along with a text corpus in which to look for information. The output is a set of slot fills for each query. Sys- tems must also provide provenance in the form of docid:startoffset-endoffset, where docid specifies a source document and the offsets demarcate the text in this document supporting the filler. Systems may also provide a confidence score to indicate their cer- tainty in the extracted information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tri-lingual Entity Discovery and Linking</head><p>(TEDL)</p><p>The first step in the TEDL task is to discover all en- tity mentions in a corpus with English, Spanish and Chinese documents. The entities can be a person, or- ganization or geo-political entity (PER/ORG/GPE) and in 2015 two more entity types were introduced -facility and location (FAC/LOC). The extracted mentions are then linked to an existing English KB (a version of FreeBase) entity via its ID. If there is no KB entry for an entity, systems are expected to cluster all the mentions for that entity using a NIL ID. The output for the task is a set of extracted men- tions, each with a string, its provenance in the cor- pus, and a corresponding KB ID if the system could successfully link the mention, or else a mention clus- ter with a NIL ID. Systems can also provide a confi- dence score for each mention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Ensembling Algorithm</head><p>Figure 1 illustrates our system which trains a final meta-classifier for combining multiple systems us- ing confidence scores and other auxiliary features depending on the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Supervised Ensembling Approach</head><p>For the KBP systems that are common between years, we use the stacking method of <ref type="bibr" target="#b12">Viswanathan et al. (2015)</ref> for these shared systems. The meta-classifier makes a binary decision for each distinct output represented as a key-value pair. The function of the key is to provide a handle for ag- gregating outputs that are common across systems. For the CSSF task, the key for ensembling multiple systems is a query along with a slot type, for exam- ple, per:age of "Barack Obama" and the value is a computed slot fill. For TEDL, the key is the KB (or NIL) ID and the value is a mention, that is a spe- cific reference to an entity in the text. The top half of <ref type="figure" target="#fig_0">Figure 1</ref> illustrates ensembling multiple systems with historical training data using a supervised ap- proach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Unsupervised Ensembling Approach</head><p>Only 38 of the 70 systems that participated in CSSF 2015 also participated in 2014, and only 24 of the 34 systems that participated in TEDL 2015 also partic- ipated in 2014 EDL. Therefore, many KBP systems in 2015 were new and did not have past training data. In fact, some of the new systems performed better than the shared systems, for example the hltcoe sys- tem did not participate in 2014 but was ranked 4 th in the 2015 TEDL task ( <ref type="bibr" target="#b6">Ji et al., 2015</ref>). Thus, for im- proving recall and performance in general, it is cru- cial to use systems without historical training data, which we call unsupervised systems. To achieve this end, we first ensemble such systems using an unsupervised technique. Frequently, the confidence scores provided by systems are not well-calibrated probabilities. So in order to calibrate the confidence scores across unsupervised systems, we use the con- strained optimization approach proposed by <ref type="bibr" target="#b13">Wang et al. (2013)</ref>. The idea is to aggregate the raw confi- dence values produced by individual KBP systems, to arrive at a single aggregated confidence value for each key-value pair. The constraints ensure that the aggregated confidence score is close to the raw score as well as proportional to the agreement among sys- tems on a value for a given key. Thus for a given key, if a system's value is also produced by multi- ple other systems, it would have a higher score than if it were not produced by any other system. The authors use the inverse ranking of the average pre- cision previously achieved by individual systems as the weights in their algorithm. However since we use this approach for systems with no historical per- formance data, we use uniform weights across all unsupervised systems for both the tasks. We use the slot type for the CSSF task and en- tity type for the TEDL task to define the constraints on the values. The output from the constrained op- timization approach for both tasks is a set of key- values with aggregated confidence scores across all unsupervised systems which go directly into the stacker as shown in the lower half of <ref type="figure" target="#fig_0">Figure 1</ref>. Us- ing the aggregation approach as opposed to directly using the raw confidence scores allows the classifier to meaningfully compare confidence scores across multiple systems although they are produced by very diverse systems.</p><p>Another unsupervised ensembling method we tried in place of the constrained optimization ap- proach is the Bipartite Graph based Consensus Max- imization (BGCM) approach of <ref type="bibr" target="#b4">Gao et al. (2009)</ref>. BGCM is presented as a way of combining super- vised and unsupervised models, so we compare it to our stacking approach to combining supervised and unsupervised systems, as well as an alternative ap- proach to ensembling just the unsupervised systems before passing their output to the stacker. BGCM performs an optimization over a bipartite graph of systems and outputs, where the objective function favors the smoothness of the label assignments over the graph, as well as penalizing deviations from the initial labeling provided by supervised models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Combining Supervised and Unsupervised</head><p>We propose a novel approach to combine the afore- mentioned supervised and unsupervised methods us- ing a stacked meta-classifier as the final arbiter for accepting a given key-value. The outputs from the supervised and unsupervised systems are fed into the stacker in a consistent format such that there is a unique input key-value pair. Most KBP teams sub- mit multiple variations of their system. Before en- sembling, we first combine multiple runs of the same team into one. Of the 38 CSSF systems from 10 teams for which we have 2014 data for training and the 32 systems from 13 teams that do not have train- ing data, we combine the runs of each team into one to ensure diversity of the final ensemble. For the slot fills that were common between the runs of a given team, we compute an average confidence value, and then add any additional fills that are not common between runs. Thus, we obtained 10 systems (one for each team) for which we have supervised data for training stacking. Similarly, we combine the 24 TEDL systems from 6 teams that have 2014 training data and 10 systems from 4 teams that did not have training data into one per team. Thus using the no- tation in <ref type="figure" target="#fig_0">Figure 1</ref>, for TEDL, N = 6 and M = 4 while for CSSF, N = 10 and M = 13.</p><p>The unsupervised method produces aggregated, calibrated confidence scores which go directly into our final meta-classifier. We treat this combination as a single system called the unsupervised ensemble. We add the unsupervised ensemble as an additional system to the stacker, thus giving us a total of N + 1, that is 11 CSSF and 7 TEDL systems. Once we have extracted the auxiliary features for each of the N su- pervised systems and the unsupervised ensemble for both years, we train the stacker on 2014 systems, and test on the 2015 systems. The unsupervised en- semble for each year is composed of different sys- tems, but hopefully the stacker learns to combine a generic unsupervised ensemble with the supervised systems that are shared across years. This allows the stacker to arbitrate the final correctness of a key- value pair, combining systems for which we have no historical data with systems for which training data is available. To learn the meta-classifier, we use an L1-regularized SVM with a linear kernel <ref type="bibr" target="#b2">(Fan et al., 2008</ref>) (other classifiers gave similar results).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Post-processing</head><p>Once we obtain the decisions on each key-value pair from the stacker, we perform some final post- processing. For CSSF, each list-valued slot fill that is classified as correct is included in the final output. For single-valued slot fills, if they are multiple fills Methodology Precision Recall F1 Combined stacking and constrained optimization with auxiliary features 0.4679 0.4314 0.4489 Top ranked SFV system in 2015 ( <ref type="bibr" target="#b10">Rodriguez et al., 2015)</ref> 0.4930 0.3910 0.4361 Stacking using BGCM instead of constrained optimization 0.5901 0.3021 0.3996 BGCM for combining supervised and unsupervised systems 0.4902 0.3363 0.3989 Stacking with auxiliary features described in <ref type="bibr" target="#b9">(Rajani and Mooney, 2016)</ref> 0.4656 0.3312 0.3871 Ensembling approach described in <ref type="figure" target="#fig_0">(Viswanathan et al., 2015)</ref> 0.5084 0.2855 0.3657 Top ranked CSSF system in 2015 ( <ref type="bibr" target="#b0">Angeli et al., 2015)</ref> 0.3989 0.3058 0.3462 Oracle Voting baseline (3 or more systems must agree) 0.4384 0.2720 0.3357 Constrained optimization approach described in ( <ref type="bibr" target="#b13">Wang et al., 2013)</ref> 0.1712 0.3998 0.2397   that were classified as correct for the same query and slot type, we include the fill with the highest meta- classifier confidence. For TEDL, for each entity mention link that is classified as correct, if the link is a KB cluster ID then we include it in the final output, but if the link is a NIL cluster ID then we keep it aside until all mention links are processed. Thereafter, we resolve the NIL IDs across systems since NIL ID's for each system are unique. We merge NIL clusters across systems into one if there is at least one common en- tity mention among them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>All results were obtained using the official NIST scorers after the competitions ended. <ref type="bibr">2</ref> We compare to the purely supervised approach of <ref type="bibr" target="#b12">Viswanathan et al. (2015)</ref> using shared systems between 2014 and 2015, and the constrained optimization approach of <ref type="bibr" target="#b13">Wang et al. (2013)</ref> using all 2015 systems. We also compare to BGCM ( <ref type="bibr" target="#b4">Gao et al., 2009</ref>) in two ways.</p><p>First, we use BGCM in place of the constrained op- timization approach to ensemble unsupervised sys- tems while keeping the rest of our pipeline the same. Secondly, we also compare to combining both su- pervised and unsupervised systems using BGCM in- stead of stacking. We also include an "oracle" vot- ing ensembling baseline, which varies the threshold on the number of systems that must agree to identify an "oracle" threshold that results in the highest F1 score for 2015. We find that for CSSF a threshold of 3, and for TEDL a threshold of 4, gives us the best F1 score. <ref type="table" target="#tab_0">Tables 1 and 2</ref> show CSSF and TEDL results. Our full system, which combines supervised and un- supervised ensembling performed the best on both tasks. TAC-KBP also includes the Slot Filler Val- idation (SFV) task 3 where the goal is to ensem- ble/filter outputs from multiple slot filling systems. The top ranked system in 2015 ( <ref type="bibr" target="#b10">Rodriguez et al., 2015</ref>) does substantially better than many of the other ensembling approaches, but it does not do as well as our best performing system. The purely  <ref type="formula">(2013)</ref> performs very poorly by itself; but when combined with stacking gives a boost to recall and thus the overall F 1. Note that all our combined methods have a substantially higher recall. The oracle voting baseline also performs very poorly indicating that naive ensembling is not ad- vantageous.</p><p>TEDL provides three different approaches to measuring accuracy: entity discovery, entity linking, and mention CEAF ( <ref type="bibr" target="#b6">Ji et al., 2015)</ref>. CEAF finds the optimal alignment between system and gold stan- dard clusters, then evaluates precision and recall micro-averaged. We obtained similar results on all three metrics and only include CEAF. The purely supervised stacking approach over shared systems does not do as well as any of our combined ap- proaches even though it beats the best performing system (i.e. IBM) in the 2015 competition <ref type="bibr" target="#b11">(Sil et al., 2015</ref>). The relative ranking of the approaches is similar to those obtained for CSSF, proving that our approach is very general and improves performance on two quite different and challenging problems.</p><p>Even though it is obvious that the boost in our recall was because of adding the unsupervised sys- tems, it isn't clear how many new key-value pairs were generated by these systems. We thus evalu- ated the contribution of the systems ensembled using the supervised approach and those ensembled using the unsupervised approach, to the final combination for both the tasks. <ref type="figure" target="#fig_2">Figure 2</ref> shows the number of unique as well as common key-value pairs that were contributed by each of the approaches. The unique pairs are those that were produced by one approach but not the other and the common pairs are those that were produced by both approaches. The num- ber of unique pairs in the combination is the union of unique pairs in the supervised and unsupervised approaches. We found that approximately one third of the input pairs in the combination came from the unique pairs produced just by the unsupervised sys- tems for both the TEDL and CSSF tasks. Only about 15% and 22% of the total input pairs were common between the two approaches for the TEDL and CSSF tasks respectively. Our findings highlight the impor- tance of utilizing systems that do not have historical training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented results on two diverse KBP tasks, showing that a novel stacking-based approach to en- sembling both supervised and unsupervised systems is very promising. The approach outperforms the top ranked systems from both 2015 competitions as well as several other ensembling methods, achiev- ing a new state-of-the-art for both of these impor- tant, challenging tasks. We found that adding the unsupervised ensemble along with the shared sys- tems specifically increased recall substantially.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of our approach to combine supervised and unsupervised ensembles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Total number of unique and common input pairs contributed by the supervised and unsupervised systems to the combination for the TEDL and CSSF tasks respectively.</figDesc><graphic url="image-1.png" coords="5,119.40,103.53,141.00,61.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Results on 2015 Cold Start Slot Filling (CSSF) task using the official NIST scorer</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results on 2015 Tri-lingual Entity Discovery and Linking (TEDL) using official NIST scorer and CEAF metric 

</table></figure>

			<note place="foot" n="1"> http://www.nist.gov/tac/2015/KBP/ ColdStart/guidelines.html</note>

			<note place="foot" n="2"> http://www.nist.gov/tac/2015/KBP/ ColdStart/tools.html,https://github.com/ wikilinks/neleval</note>

			<note place="foot" n="3"> http://www.nist.gov/tac/2015/KBP/ SFValidation/index.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This research was supported by the DARPA DEFT program under AFRL grant FA8750-13-2-0026.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bootstrapped Self Training for Knowledge Base Population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Chaganty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><forename type="middle">Johnson</forename><surname>Premkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Text Analysis Conference (TAC2015)</title>
		<meeting>the Eighth Text Analysis Conference (TAC2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ensemble Methods in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First International Workshop on Multiple Classifier Systems</title>
		<editor>J. Kittler and F. Roli</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LIBLINEAR: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang-Rui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Named entity recognition through classifier combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abe</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003</title>
		<meeting>the seventh conference on Natural language learning at HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="168" to="171" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Graph-based consensus maximization among multiple supervised and unsupervised models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS2009)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="585" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploiting Diversity in Natural Language Processing: Combining Parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP99)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP99)<address><addrLine>College Park, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="187" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Overview of TAC-KBP2015 Tri-lingual Entity Discovery and Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Hachey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Text Analysis Conference (TAC2015)</title>
		<meeting>the Eighth Text Analysis Conference (TAC2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Combining Joint Models for Biomedical Event Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Simple Approach to Building Ensembles of Naive Bayesian Classifiers for Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association for Computational Linguistics (NAACL2000)</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="63" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Stacking With Auxiliary Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatema</forename><surname>Nazneen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">University of Florida DSR lab system for KBP slot filler validation 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisy</forename><forename type="middle">Zhe</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Text Analysis Conference (TAC2015)</title>
		<meeting>the Eighth Text Analysis Conference (TAC2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The IBM systems for trilingual entity discovery and linking at TAC 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avirup</forename><surname>Sil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Text Analysis Conference (TAC2015)</title>
		<meeting>the Eighth Text Analysis Conference (TAC2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stacked Ensembles of Information Extractors for KnowledgeBase Population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidhoon</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinon</forename><surname>Nazneen Fatema Rajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Bentor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL2015)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics (ACL2015)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="177" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">JHUAPL TAC-KBP2013 Slot Filler Validation System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I-Jeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwina</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cash</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Piatko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Text Analysis Conference (TAC2013)</title>
		<meeting>the Sixth Text Analysis Conference (TAC2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sentiment mining using ensemble classification models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Whitehead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Yaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovations and Advances in Computer Sciences and Engineering</title>
		<editor>Tarek Sobh</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>SPRINGER</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="241" to="259" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
