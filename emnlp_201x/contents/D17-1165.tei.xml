<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Detecting Perspectives in Political Debates</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilares</surname></persName>
							<email>david.vilares@udc.es</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Departamento de Computación Campus de Elviña s/n</orgName>
								<orgName type="department" key="dep2">School of Engineering and Applied Science</orgName>
								<orgName type="institution">Universidade da Coruña</orgName>
								<address>
									<postCode>15071 A</postCode>
									<settlement>Coruña</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
							<email>y.he@cantab.net</email>
							<affiliation key="aff1">
								<orgName type="institution">Aston University</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Detecting Perspectives in Political Debates</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1573" to="1582"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We explore how to detect people&apos;s perspectives that occupy a certain proposition. We propose a Bayesian modelling approach where topics (or propositions) and their associated perspectives (or viewpoints) are modeled as latent variables. Words associated with topics or perspectives follow different generative routes. Based on the extracted perspectives, we can extract the top associated sentences from text to generate a succinct summary which allows a quick glimpse of the main viewpoints in a document. The model is evaluated on debates from the House of Commons of the UK Parliament, revealing perspectives from the debates without the use of labelled data and obtaining better results than previous related solutions under a variety of evaluations.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Stance classification is binary classification to de- tect whether people is supporting or against a topic. Existing approaches largely rely on labelled data collected under specific topics for learning su- pervised classifiers for stance classification <ref type="bibr" target="#b13">(Mohammad et al., 2016a</ref>). At most time, apart from detecting one's stance, we are interested in find- ing out the arguments behind the person's posi- tion. Perspectives, that state people's ideas or the facts known to one, can be contrastive, i.e. to be in favour of or against something (e.g. Brexit vs Bre- main), or non-contrastive, i.e. independent discus- sions that share a common topic (e.g. unemploy- ment and migration in the context of economy).</p><p>Recent years have seen increasing interests in argumentation mining which involves the auto- matic identification of argumentative structures, e.g., the claims and premises, and detection of argumentative relations between claims and premises or evidences. However, learning mod- els for argumentation mining often require text labelled with components within argumentative structures and detailed indication of argumentative relations among them. Such labelled data is ex- pensive to obtain in practice and it is also difficult to port models trained on one domain to another.</p><p>We are particularly interested in detecting dif- ferent perspectives in political debates. Essen- tially, we would like to achieve somewhere in between stance classification and argumentation mining. Given a text document, we want to iden- tify a speaker's key arguments, without the use of any labelled data. For example, in debates about 'Education', we want to automatically extract sen- tences summarising the key perspectives and their arguments, e.g. 'our education system needs to promote excellence in stem subjects', 'teenagers need to be taught with sexual and health educa- tion' or 'grammar schools promote inequality'. Similarly, if 'Brexit' is being discussed in terms of leaving or remaining, we want to cluster argu- ments into those two viewpoints.</p><p>To do this, we introduce a Latent Argument Model (LAM) which assumes that words can be separated as topic words and argument words and follow different generative routes. While topic words only involve a sampling of topics, argument words involve a joint sampling of both topics and arguments. The model does not rely on labelled data as opposed to most existing approaches to stance classification or argument recognition. It is also different from cross-perspective topic models which assume the perspectives are observed <ref type="bibr" target="#b7">(Fang et al., 2012</ref>). Quantitative and qualitative evalua- tions on debates from the House of Commons of United Kingdom show the utility of the approach and provide a comparison against related models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Our research is related to stance classification, ar- gument recognition and topic modelling for senti- ment/perspective detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Stance Classification</head><p>Stance detection aims to automatically detect from text whether the author is in favour of, against, or neutral towards a target. As previously reported in ( <ref type="bibr" target="#b14">Mohammad et al., 2016b</ref>), a person may express the same stance towards a target by using nega- tive or positive language. Hence, stance detection is different from sentiment classification and senti- ment features alone are not sufficient for stance de- tection. With the introduction of the shared task of stance detection in tweets in <ref type="bibr">SemEval 2016</ref><ref type="bibr" target="#b13">(Mohammad et al., 2016a</ref>), there have been increas- ing interests of developing various approaches for stance detection. But most of them focused on building supervised classifiers from labelled data. The best performing system ( <ref type="bibr" target="#b23">Zarrella and Marsh, 2016</ref>) made use of large unlabelled data by first learning sentence representations via a hashtag prediction auxiliary task and then fine tuning these sentence representations for stance detection on several hundred labelled examples. Nevertheless, labelled data are expensive to obtain and there is a lack of portability of classifiers trained on one domain to move to another domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Argument Recognition</head><p>Closely related to stance detection is argument recognition which can be considered as a more fine-grained task that it aims to identify text segments that contain premises that are against or in support of a claim. <ref type="bibr" target="#b3">Cabrio and Villata (2012)</ref> combined textual entailment with argu- mentation theory to automatically extract the argu- ments from online debates. Boltuzic andŠnajderandˇandŠnajder (2014) trained supervised classifiers for argument extraction from their manually annotated corpus by collecting comments from online discussions about two specific topics. <ref type="bibr" target="#b19">Sardianos et al. (2015)</ref> proposed a supervised approach based on Con- ditional Random Fields for argument extraction from Greek news. <ref type="bibr" target="#b15">Nguyen and Litman (2015)</ref> run an LDA model and post-processed the output, computing argument and domain weights for each of the topics, which were then used to extract ar- gument and domain words. Their model outper- formed traditional n-grams and lexical/syntactic rules on a collection of persuasive essays. <ref type="bibr" target="#b10">Lippi and Torroni (2016a)</ref> hypothesized that vocal fea- tures of speech can improve argument mining and proposed to train supervised classifiers by combin- ing features from both text and speech for claim detection from annotated political debates. Apart from claim/evidence detection, there has also been work focusing on identification of argument dis- course structures such as the prediction of rela- tions among arguments or argument components <ref type="bibr" target="#b20">(Stab and Gurevych, 2014;</ref><ref type="bibr" target="#b16">Peldszus and Stede, 2015)</ref>. A more recent survey of various machine learning approaches used for argumentation min- ing can be found in ( <ref type="bibr" target="#b11">Lippi and Torroni, 2016b)</ref>. All these approaches have been largely domain- specific and rely on a small set of labelled data for supervised model learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Topic Modeling for Sentiment/Perspective Detection</head><p>Topic models can be modified to detect sentiments or perspectives. <ref type="bibr" target="#b8">Lin and He (2009)</ref> introduced a joint sentiment topic (JST) model, which simulta- neously extracts topics and topic-associated sen- timents from text. <ref type="bibr" target="#b21">Trabelsi and Zaıane (2014)</ref> proposed a joint topic viewpoint (JTV) model for the detection of latent viewpoints under a cer- tain topic. This is essentially equivalent to the reparameterized version of the JST model called REVERSE-JST ( <ref type="bibr" target="#b9">Lin et al., 2012</ref>) in which senti- ment label (or viewpoint) generation is dependent on topics, as opposed to JST where topic genera- tion is conditioned on sentiment labels. <ref type="bibr" target="#b7">Fang et al. (2012)</ref> proposed a Cross-Perspective Topic Model (CPT) in which the generative pro- cesses for topic words (nouns) and opinion words (adjectives, adverbs and verbs) are different, as the opinion words are sampled independently from the topic. Also, CPT assumed perspectives are ob- served, which implies texts need to be annotated with the viewpoint they belong to. <ref type="bibr" target="#b0">Awadallah et al. (2012)</ref> detected politically controversial top- ics by creating an opinion-base of opinion hold- ers and their views. <ref type="bibr" target="#b6">Das and Lavoie (2014)</ref> ob- served the editions and interactions of a user in Wikipedia pages to infer topics and points of view at the same time. <ref type="bibr" target="#b17">Qiu et al. (2015)</ref> proposed a regression-based latent factor model which jointly models user arguments, interactions, and attributes for user stance prediction in online debates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Latent Argument Model (LAM)</head><p>We assume that in a political debate, the speaker first decides on which topic she wants to comment on (e.g. Education). She then takes a stance (e.g. remark the importance about stem subjects) and elaborates her stance with arguments. It is worth noting that we do not consider the temporal di- mension of documents here, i.e., our model is fed with a collection of unlabeled documents without temporal order.</p><p>We use a switch variable x to denote whether a word is a background word (shared across mul- tiple topics), a topic word (relating to a certain topic) or an argument word (expressing arguments under a specific topic). Depending on the type of word, we follow a different generative process. For each word in a document, if it is a background word, we simply sample it from the background word distribution φ b ; if it is a topic word, we first sample a topic z from the document-specific topic distribution θ d and then sample the word from the topic-word multinomial distribution ψ z shared across all documents; if it is an argument word, we need to first jointly sample the topic-argument pair, (z, a), where z comes from the existing top- ics already sampled for the topic words in the doc- ument and a is sampled from the topic-specific argument distribution ω z , and finally the word is sampled from the multinomial word distribution for the topic-specific argument ψ z,a . The argu- ment indicator here is a latent categorical variable. It can take a binary value to denote pro/con or pos- itive/negative towards a certain topic. More gener- ally, it could also take a value from multiple stance or perspective categories. We thus propose a La- tent Argument Model (LAM) shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Formally, the generative process is as follows:</p><p>• Draw a distribution over the word switch variable, φ ∼ Dirichlet(γ), and background word distribution,</p><formula xml:id="formula_0">ψ b ∼ Dirichlet(β b ). • For each topic z ∈ {1...T }, draw a multinomial topic-word distribution ψ z ∼ Dirichlet(β z ).</formula><p>-For each argument a ∈ {1...A} draw a multinomial topic-argument distribution ω z ∼ Dirichlet(δ) as well as a multino- mial topic-argument-word distribution</p><formula xml:id="formula_1">ψ v z,a ∼ Dirichlet(β a ). • For each document d ∈ {1...D} : -Draw a multinomial topic distribution, θ d ∼ Dirichlet(α).</formula><p>-For each word n ∈ {1, .., N d } in d:</p><formula xml:id="formula_2">* Choose x d,n ∼ Multinomial(φ). * If x d,n = 0, draw a background word w d,n ∼ ψ b ; * If x d,n = 1, draw a topic z ∼ Multinomial(θ d ) and a word w d,n ∼ Multinomial(ψ z ); * If x d,n = 2, draw a topic z ∼ Multinomial(θ d )</formula><p>, an argument a ∼ Multinomial(ω z ) and a word w d,n ∼ Multinomial(ψ a z,a ). <ref type="figure" target="#fig_0">Figure 1</ref> shows its plate representation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Inference and Parameter Estimation</head><p>We use Collapsed Gibbs Sampling <ref type="bibr" target="#b4">(Casella and George, 1992</ref>) to infer the model parameters and the latent assignments of topics and arguments, given the observed data. Gibbs sampling is a Markov chain Monte Carlo method to iterative es- timate latent parameters. In each iteration, a new sample of the hidden parameters is made based on the distribution of the previous epoch. Letting the index t = (d, n) denote the nth word in document d and the subscript −t denote a quantity that ex- cludes data from the nth word position in docu- ment d, Λ = {α, β b , β z , β a , γ, δ}, the conditional posterior for x t is:</p><formula xml:id="formula_3">P (x t = r|x −t , z, a, w, Λ) ∝ {N r d } −t + γ {N d } −t + 3γ · {N r wt } −t + β r w {N r w } −t + W β r , (1)</formula><p>where r denotes different word types, either back- ground word, topic word or argument word. N r d denotes the number of words in document d as- signed to the word type r, N d is the total number of words in the document d, N r wt is the number of times word w t is sampled from the distribution for the word type r, W is the vocabulary size. For topic words, the conditional posterior for z t is:</p><formula xml:id="formula_4">P (z t = k|z −t , w, Λ) ∝ N −t d,k + α k N −t d + k α k · N −t k,wt + β z N −t k + W β z , (2) where N d,k</formula><p>is the number of times topic k was as- signed to some word tokens in document d, N d is the total number of words in document d, N k,wt is the number of times word w t appeared in topic k.</p><p>For argument words, the conditional posterior for z t and a t is:</p><formula xml:id="formula_5">P (z t = k, a t = j|z −t , a −t , w, Λ) ∝ N −t d,k + α k N −t d + k α k · N −t d,k,j + δ k,j N −t d,k + j δ k,j · N −t k,j,wt + β v N −t k,j + W β v ,<label>(3)</label></formula><p>where N d,k,j is the number of times a word from document d has been associated with topic k and argument j, N k,j,wt is the number of times word w t appeared in topic k and with argument j, and N k,j is the number of words assigned to topic k and argument j.</p><p>Once the assignments for all the latent variables are known, we can easily estimate the model pa- rameters {θ, φ, ρ, ψ b , ψ z , ψ a , ω}. We set the symmetric prior γ = 0.3, = 0.01, β b = β z = 0.01, δ = (0.05 × L)/A, where L is the average document length, A the is total num- ber of arguments, and the value of 0.05 on av- erage allocates 5% of probability mass for mix- ing. The asymmetric prior α is learned di- rectly from data using maximum-likelihood esti- mation <ref type="bibr" target="#b12">(Minka, 2003)</ref> and updated every 40 iter- ations during the Gibbs sampling procedure. In this paper we only consider two possible stances, hence, A = 2. But the model can be easily ex- tended to accommodate more than two stances or perspectives. We set the asymmetric prior β a for the topic-argument-word distribution based on a subjectivity lexicon in hoping that contrastive per- spectives can be identified based on the use of pos- itive and negative words. We run Gibbs sampler for 1 000 iterations and stop the iteration once the log-likelihood of the training data converges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Separating Topic and Perspective Words</head><p>Using the word type switch variable x, we could separate topic and argument words in LAM based solely on the statistics gathered from data. We also explore another two methods to separate topic and argument words based on Part-of-Speech (POS) tags and with the incorporation of a subjectiv- ity lexicon. For the first variant, we adopt the similary strategy as in <ref type="bibr" target="#b7">(Fang et al., 2012</ref>) that nouns (NOUN) are topic words; adjectives (ADJ), adverbs (ADV) and verbs (VERB) are argument words; words with other POS tags are background words. Essentially, x is observed. We call this model LAM POS.</p><p>For the second variant, instead of assuming x is observed, we incorporate the POS tags as prior information to modify the Dirichlet prior γ for the word type switch variable at the initialization step. In addition, we also consider a subjective lexicon 1 , L, that if a word can be found in the lexicon, then it is very likely the word is used to convey an opinion or argument, although there is still a small probability that word could be either background or topic word. Assuming an asymmetric Dirichlet prior for x is parametrized by γ = [γ b , γ z , γ a ] for background, topic and argument words, it is modi- fied by a transformation matrix λ, γ new = λ×γ , where λ is defined by: The conditional probability for the switch variable x is modified by simultaneously considering the POS tag g for the word at position t:</p><formula xml:id="formula_6">• If word w ∈ L ∧ POSTAG(w) = NOUN then λ = [</formula><formula xml:id="formula_7">P (x t = r, y t = g|x −t , z, a, w, Λ) ∝ {N r d } −t + γ {N d } −t + 3γ · {N r wt } −t + β r w {N r w } −t + W β r · {N r g } + r g {N g } + g r g ,<label>(4)</label></formula><p>where an additional term is added to the RHS of Equation 1. Here, N r g denotes the number of words with POS tag g assigned to the word type r, N g is the total number of words assigned to the POS tag g, r g is the Dirichlet prior for the POS tag-word type distribution.</p><p>We call the second variant LAM LEX. As both the POS tag information and the subjectivity lexi- con are only incorporated in the initialisation step, LAM LEX sits in-between LAM and LAM POS that it performs soft clustering of topic words and ar- gument words. That is, during the initialisation, nouns are more likely to be topic words, but there is still a small probability that they could be either argument or background words; and similarly for words tagged as adjectives, adverts and verbs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">House of Common Debates (HCD)</head><p>Debates from the UK parliament are archived and available for consulting. <ref type="bibr">2</ref> A custom web-crawler was developed to obtain the records of every day that The House of Commons was in session be- tween 2009 and 2016. Due to inconsistencies in the data format and volume of data, much of the analysis focuses on the recordings for the parlia- mentary year 2014-2015. The general structure of a single day of recording is as follows: a ques- tion will be put to the house (generally a Bill) and Members of Parliament (MPs) will discuss various aspects regarding the Bill or show stances about it. Each speech made by an MP is considered to be a single document. Multiple Bills will be discussed each day. The current item being discussed is clearly marked in the source data format, so link- ing documents to the current bill and MP is trivial. Each speech is labelled with a major (e.g. edu- cation) and a minor topic (e.g. grammar schools) and help us create a dataset with the desired needs.</p><p>The length that The House will be in session varies and the number of bills discussed also varies. In this paper, we considered debates oc- curred during March of 2015 3 and contains 1 992 speeches belonging to diverse domains: justice, education, energy and climate change, treasury, transport, armed forces, foreign and common- wealth office, environment, transport, royal assent, work and pensions, northern Ireland. This House of Commons Debates (HCD) dataset is made avail- able for the research community. <ref type="bibr">4</ref> We followed a standard methodology to clean the texts: stopwords were removed, lemmatization was applied, and a naive negation treatment was considered for the particle 'not', by creating bi- grams for words occurs in the subjectivity lexicon (e.g., 'not good' becomes 'not good'). As topic models suffer from lack of robustness if large out- liers are present, we also removed very frequent (above 99%) and rare words (below percentile 65%), assuming that word occurrences of the col- lection follow a Zip's law distribution. <ref type="bibr">5</ref> Similar strategy was carried out for texts, in order to just consider texts of similar length. The preprocessed HCD contains a total of 1 598 speeches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>This section evaluates LAM and its variants quali- tatively and quantitatively (averaged over 5 runs).</p><p>The models for comparison are listed below:</p><p>• Both POS tags and a subjec- tive lexicon are used to initialise the Dirichlet prior γ for the word type switch variable as described in §3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Results</head><p>Results are evaluated in terms of both topic coher- ence and the quality of the extracted perspectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Topic Coherence</head><p>The CV metric 7 is used to measure the coherence of the topics generated by the models as it has been shown to give the results closest to human evalu- ation compared to other topic coherence metrics <ref type="bibr">(Röder et al., 2015</ref>). In brief, given a set of words, <ref type="bibr">5</ref> Percentiles were selected on an empirical basis. <ref type="bibr">6</ref> We were not able to find a publicly available code of the JTV implementation.</p><p>7 https://github.com/AKSW/Palmetto/ it gives an intuition of how likely those words co- occur compared to expected by chance. <ref type="figure" target="#fig_2">Figure 2</ref> plots the CV results 8 versus the num- ber of topics on HCD for various models. For each topic z, we extract the top ten most representa- tive words ranked by their respective normalised discriminative score defined by DS(w, z) = P (w|z)/[max z =z P (w|z )]. We chose this ap- proach instead of simple P (w|z) as it was ob- served to turn into higher quality topics. It is clear that LAM LEX models outperform baselines and that all variants are learning well the topics from the data, showing that the three different mecha- nisms for the switch variable are effective to gen- erate coherent topics. Also, our models work ro- bustly under different number of topics. More- over, LAM LEX achieve better coherence scores than the original LAM and LAM POS. This shows that it is more effective to use POS tags and a sub- jectivity lexicon to initialise the Dirichlet prior for the word type switch variable rather than simply relying on POS tags or subjectivity lexica to give hard discrimination between topic and argument words. We also used the gold-standard major topic label assigned by Hansard to each speech to carry out an additional quantitative evaluation. For each topic z, we extract the top ten most representative sentences ranked by their respec- tive normalised discriminative score defined by DS(s, z) = w∈s DS(w, z)/Length(s). If a particular model is clustering robustly, the top sentences it extracts should belong to speeches that discuss the same topic and share the same major and/or minor topic labels in the HCD cor- pus. <ref type="table">Table 2</ref> shows for the studied models the percentage of sentences where x out of top 10 topic sentences belong to the same major topic. The results reinforce the superior performance of the LAM LEX approach in comparison with other models.</p><p>It is worth remarking that in cases where LAM LEX cluster together sentences labelled with different major topics, some clustering results are actually quite sensible. <ref type="table">Table 1</ref> illustrates it with a representative case. These sentences were ex- tracted from a cluster about farmers in which 9 out of 10 top topic sentences have "environment, food and rural affairs" as the gold major topic. The only discording sentence, belonging to trea- sury (major topic) and infrastructure investment (minor topic), is however closely related to farm- ers too and it makes sense to put it into the same cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Perspectiven Summarisation</head><p>In this section we evaluate the quality of the rela- tion of the arguments with respect to their topics.</p><p>In terms of a quantitative evaluation, we are in- terested in knowing how strongly the perspectives are related to their topic: it might be the case that the separate CV coherence for the topic and view- points is high, but there is no actual relation be- tween them, which would be an undesirable be- haviour. To determine whether this is happening or not in the studied models, for each perspective we compute a mixed topic-perspective CV value, by extracting the top 5 perspective words, con- catenating them with the top 5 words of the cor- responding topic and running Palmetto as in the previous section. <ref type="bibr">9</ref> We then average the computed mixed topic-perspective CV values by T × A. Fol- lowing this methodology, a high average CV value means that the perspective words are likely to oc- cur when discussing about that particular topic, and therefore a test of whether the model is learn- ing perspectives that have to do with it. <ref type="figure" target="#fig_4">Figure 3</ref> compares topic-perspective models evaluated fol- lowing this methodology, showing that LAM LEX gives the best overall coherence.</p><p>For a better understanding of what perspec- tives LAM LEX is learning, we extract the top perspective sentences for a given topic based on normalised discriminative score of each sen-Sentence (extracted from a longer speech)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Major topic</head><p>Minor topic I would add that HMRC can provide extra flexibility where there are particular impacts on particular farmers <ref type="table">Treasury  Infrastructure  or other businesses  Investment  I think milk prices will improve, but the banks need to support farmers in the meantime  Environment  Topical questions  food and rural affairs   Table 1</ref>: Example sentences, belonging to speeches that were assigned in Hansard different major topics labels, were clustered together by LAM (and it is sensible to do so as they are both about "farmers").  <ref type="table">Table 2</ref>: Ratio of topics where x or more than x out of top 10 topic sentences (≥ x) belong to the same major topic. tence <ref type="bibr">10</ref> , similar to what have been done in se- lecting the top topic sentences. In specific, we first define the discriminative score of word w un- der topic z and argument a by: DS(w, a, z) = P (w|z,a) max z =z,a =a P (w|z ,a ) . Then the sentence-level discriminative score is calculated based on the ag- gregated discriminative scores over all the words normalised by the sentence length: DS(s, z, a) = w∈s DS(w, a, z)/Length(s). In order to have better correspondence between topics and their respective arguments, we perform two-stage se- lection: first ranking sentences based on topic- level discriminative scores DS(s,z), and then fur- ther ranking sentences based on topic-argument- level discriminative scores DS(s, z, a).</p><p>We can use these extracted top representative sentences together with the gold major topics from HCD to measure if perspectives are connected to their topic. We define the label-based accuracy <ref type="bibr">10</ref> We can also rank sentences for an argument a under a topic z based on the generative probability of sentences. But this consistently produce worse results. (LA) as follows: let p i be the gold major topics associated to the top 10 perspective sentences of a perspective i and let t be the gold major topics cor- responding to the top 10 topic sentences; LA(t,p i ) = |t∩p i | |t∪p i | measures how many gold major topic la- bels are shared between topic and perspective sen- tences. LA also penalises the major topics that are not in common. <ref type="table" target="#tab_1">Table 3</ref> shows for different num- ber of topics the averaged LA measure across all perspectives for three models. It can be observed that LAM LEX obtains the best performance, fol- lowed by CPT.  To compare the quality of perspectives inferred by LAM LEX and CPT (over 30 topics) we also conducted human evaluation. To do this, top- ics and perspectives were represented as bag-of- words. Each perspective was also represented with its three most representative sentences. The outputs from the two models was first merged and shuffled. Two external annotators were then asked to answer ('yes' or 'no') for each topic if they could differentiate two perspectives. Co-hen's Kappa coefficient <ref type="bibr" target="#b5">(Cohen, 1968)</ref> for inter- annotator agreement was 0.421. <ref type="table">Table 4</ref> shows the results of the evaluation and it is clear that LAM LEX outperforms CPT.</p><formula xml:id="formula_8">Annotator LAM LEX CPT 1 0.63 0.10 2 0.67 0.34 1&amp;2</formula><p>0.53 0.10 <ref type="table">Table 4</ref>: Accuracy on detecting perspectives ac- cording to the human outputs. In 1&amp;2 a 'yes' an- swer is only valid if marked by both annotators. <ref type="table">Table 5</ref> shows the three most representative perspective sentences for some of the extracted topics by LAM LEX and CPT, to illustrate how LAM LEX obtains more coherent sentences. <ref type="bibr">11</ref> The example involving the first topic shows a case where LAM LEX learned non-contrastive perspec- tives: both deal with Palestina, but focusing in different aspects (illegal settlements vs. Israel ac- tions). In contrast, CPT mixed perspectives about Israel/Palestina and other viewpoints about GCSE and mortgages. In the second topic, LAM LEX ranks at the top sentences relating to Sinn Fein &amp; Northern Ireland, that show two different stances (positive vs negative) meanwhile in CPT it is not possible to infer any clear perspective despite sen- tences contain semantically related terms. <ref type="table" target="#tab_3">Table 6</ref> shows cases where LAM LEX obtained a less-coherent output according to the annotators. The first topic deals with Shaker Aamer and the legality of its imprisonment in Guantanamo. Per- spective 2 reflects this issue, but Perspective 1 in- cludes other types of crimes. The second exam- ple discusses issues relating to transports. While Perspective 1 is all about the negotiation with the train company, First Great Western, on its fran- chise extension proposal, Perspective 2 contains sentences relating to a number of different issues under transports. To alleviate this problem, we hy- pothesise that additional levels of information (in addition to the topic and perspective levels), such as a Bill or a speaker, might be needed to better distinguish different topics and perspectives that share a significant proportion of vocabulary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Discussion</head><p>LAM LEX gave a glimpse of the perspectives that occupy a topic. However, in many cases those differ from the initial expectation given the priors <ref type="bibr">11</ref> The examples were identified as two perspectives by at least one annotator. Its selection was made based on an exis- tence of a similar topic both on LAM LEX and CPT outputs. used in our model. Despite of the use of the sub- jectivity lexicon to initialise the Dirichlet prior β a for the topic-argument-word distribution, after a few iterations the initial distribution changes rad- ically and turns instead into contrastive and non- contrastive perspectives, with the latter group be- ing the most common one. We think this is due to factors that involve: (1) lack of contrastive speeches about very specific topics; and (2) jargon from the House of Commons that makes the task more challenging as stances are showed in subtle and polite way. This is also in line with what has been previously observed in <ref type="bibr" target="#b14">(Mohammad et al., 2016b</ref>) that a person may express the same stance towards a target by using negative or positive lan- guage. This shows that LAM LEX can infer per- spectives from raw data, but we have little control on guiding the model on what perspectives to ex- tract.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>We have presented LAM, a model able to provide a glimpse of what is going on in political debates, without relying on any labelled data and assum- ing the perspectives of a topic to be latent. It is implemented through a hierarchical Bayesian model considering that words can be separated as topic, argument or background words and fol- low different generative routes. Experiments show that our model obtains more coherent topics than related approaches and also extracts more inter- pretable perspectives. The code is made available at https://github.com/aghie/lam.</p><p>Although LAM can extract perspectives under a certain topic, there is little control in what kind of information to extract (e.g. we might want only contrastive or non-contrastive arguments). In fu- ture work, we plan to improve the model through complex priors or semantic similarity strategies. Also, adding a 'Bill' level could be beneficial as speeches about the same Bill should share the same high-level topic. But we need labels indi- cating to which Bill the text belongs to. Including a 'speaker' level to know which parliamentarians discuss which topics is another interesting path to follow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LAM LEX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CPT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topic 1</head><p>israel, iran, syria, settlement, relocation, counter-terrorism gaza, tpims, airline, metropolitan israel, iran, middle, settlement, palestinian, israeli, gaza, negotiation, vil- lage, hamas Perspective 1</p><p>a) It is contrary to international law in that sense, and any nation has obligations when dealing with occupied territories and their occupants. a) Does he agree that unless that happens it is difficult to envisage a unified and prosperous Palestinian state existing alongside Israel? b) Again, I reiterate the difference between the two issues: one concerns the illegal settlements, and the other is a planning matter that we have raised concerns about. b) Will the Minister discuss that issue with the Israeli Government, urge them to reconsider the upcoming evictions and demolitions due for next month, and instead consider villages co-existing side by side in the spirit of peace? c) That is a slightly separate debate or concern if I can put it that way to the illegal settlements that have been put forward, but nevertheless we are concerned and are having a dialogue with Israel about that. c) That is caused partly by the security situation in Sinai and the Egyp- tian response to that, and partly by the situation between Israel and the Palestinians in Gaza. Perspective 2 a) More to the point, the continual encroachment by the Israeli Govern- ment makes it impossible for East Jerusalem to become the capital of a Palestinian state. a) I share the hon. Ladys desire that every school should offer three sepa- rate sciences at GCSE; that is very important.</p><p>b) We know that 163 Palestinian children are being held in Israeli mili- tary detention, and that many are being held inside Israel in direct viola- tion of the fourth Geneva b) Everybody here will know, however, that a 1,000 monthly payment sustains a mortgage of 200,000.</p><p>c) We want to see the establishment of a sovereign and independent Palestinian state, living in peace and security alongside Israel. c) As I clarified, that is a different matter to the debate about the occupied Palestinian territories, but nevertheless we want a robust planning process that adequately. a) Following our two major reform programmes, spend has fallen to 1.7 billion in 2013-14 and is expected to fall to about 1.5 billion once the reforms have fully worked through the system. b) It is very important for the Stormont House agreement to be imple- mented fully and fairly, including all the sections on welfare and budgets. b) Universal credit is a major reform that will transform the welfare state in Britain for the better. c) The Stormont House agreement was a big step forward, and it is vital for all parties to work to ensure that it is implemented fully and fairly. c) We have put in place a five-year reform programme that will bring our courts into the 21st century. b) This will ensure that the people of Northern Ireland are afforded the same protections from serious and organised crime as those in the rest of the United Kingdom. c) There is no doubt that the announcement by Sinn Fein on Monday was a significant setback for the Stormont House agreement, but it is inevitable that there will be bumps in the road with agreements of this nature.</p><p>c) The Treasury has had meetings with the European Commission to dis- cuss the reinstatement of the aggregate credit levy scheme for Northern Ireland, which could serve as a further tool of investment in infrastruc- ture. <ref type="table">Table 5</ref>: Output sample for representative perspective sentences in non-contrastive and contrastive topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LAM LEX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topic 1</head><p>aamer, shaker, bay, guantanamo, america, obama, american, timetable, embassy, harlington Perspective 1 a) NSPCC research has shown that six in 10 teenagers have been asked for sexual images or videos online. b) Does my right hon. Friend agree that the report released last week that suggested that the punishments for online and offline crime should be equalised demonstrates that education is needed to show that the two sentences should be equal? c) I can confirm that the Government have announced that we are entering into a negotiation on a contract for difference for the Swansea bay lagoon to decide whether the project is affordable and represents value for money. Perspective 2 a) This has been a helpful and constructive debate, and I join others in congratulating the hon. Member for Hayes and Harlington (John McDonnell) on securing it through the Backbench Business Committee. b) I thank the Backbench Business Committee for allocating time for this critical debate at an important time in the campaign to secure the release of Shaker Aamer. c) He has been one of the leading parliamentary campaigners for Mr Aamers release, and I acknowledge the presence of the hon. Member for Battersea (Jane Ellison) , who is the constituency MP for Mr Aamer and his familyindeed, this debate provides an important opportunity to follow up a Backbench Business Committee debate on the same subject that she initiated in April 2013. Topic 2 passenger, franchise, fare, coast, connectivity, journey, gloucester, user, anglia, stagecoach Perspective 1 a) Will my hon. Friend confirm when she expects the Departments negotiations with First Great Western on its franchise extension proposals, which include the improvements at Gloucester, to be completed? b) The hon. Gentleman will be pleased to learn that we expect to conclude negotiations with First Great Western and to finalise the second directly awarded franchise contract during this month, and expect the provision of services to start in September. c) My plans for the regeneration of the city of Gloucester include a new car park and entrance to Gloucester station, but they depend on a land sale agreement between the Ministry of Justice and the city council and the lands onward leasing to First Great Western. Perspective 2 a) I do not want any young people to feel frightened of attending school or of their journey to and from school, and, sadly, that applies particularly to members of the Jewish community at present. b) Why, instead of real localism, have this Government presided over a failed record, with bus fares up 25% and 2,000 routes cut, and a broken bus market, which lets users down, but which Labour will fix in government? c) Last week we introduced the new invitation to tender for the Northern Rail and TransPennine Express services, and transferred East Coast back to the private sector. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The plate notation for the LAM model. Shadowed elements represent the observed variables (words and prior distributions).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>0 .</head><label>0</label><figDesc>05, 0.05, 0.9] • else if POSTAG(w) = NOUN then λ = [0.05, 0.9, 0.05] • else if POSTAG(w) ∈ {ADJ,ADV,VERB} then λ = [0.05, 0.05, 0.9] • else λ = [0.9, 0.05, 0.05]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: CV coherence vs the number of topics for different modeling approaches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Average mixed topic-perspective CV coherence, across different number of topics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Perspective 2 a) There is a clear disparity in political party funding in Northern Ire- land, yet Sinn Fein Members continue to draw hundreds of thousands of pounds in allowances from this House, despite not taking their seats. a) Will the National Crime Agency specifically target the organised crim- inal gangs that are engaging in subterfuge and in the organised criminal activity of fuel laundering along the border areas of Northern Ireland? b) In light of the reneging of Sinn Fein on the introduction of welfare reform, what implications does the Minister see in the devolution of cor- poration tax in Northern Ireland?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Averaged LA measure across all topic-
perspectives for different models. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Output sample for non-representative perspective sentences in the LAM LEX model. 

funded by the Natural Science Foundation of 
China (61528302). </table></figure>

			<note place="foot" n="1"> In this work, we use the subjectivity lexicon presented at (Wiebe et al., 2005).</note>

			<note place="foot" n="2"> https://hansard.parliament.uk 3 Period of time what selected on a basis of existence of a large number of major topics. 4 https://github.com/aghie/lam/blob/ master/hcd.tsv</note>

			<note place="foot" n="8"> The CV results were calculated based on the top 10 words from each topic.</note>

			<note place="foot" n="9"> Palmetto does not accept more than 10 words.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Charles Marshall for crawling the HCD data. DV was funded by MECD (FPU 13/01180), MINECO (FFI2014-51978-C2-2-R) and Inditex-UDC grants for research stays. YH is partly</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Opinions network for politically controversial topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rawia</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first edition workshop on Politics, elections and data</title>
		<meeting>the first edition workshop on Politics, elections and data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Back up your stance: Recognizing arguments in online discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Boltuzic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Snajder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="49" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining textual entailment and argumentation theory for supporting online debates interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL): Short Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics (ACL): Short Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="208" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Explaining the gibbs sampler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Casella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Edward I George</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="167" to="174" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">213</biblScope>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automated inference of point of view from user interactions in collective intelligence venues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanmay</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><surname>Lavoie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mining contrastive opinions on political texts using cross-perspective topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Somasundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengtao</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM international conference on Web search and data mining</title>
		<meeting>the fifth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Joint sentiment/topic model for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="375" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Weakly supervised joint sentimenttopic detection from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Everson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ruger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1134" to="1145" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Argument mining from speech: Detecting claims in political debates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Argumentation mining: State of the art and emerging trends</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Internet Technology (TOIT)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A comparison of numerical optimizers for logistic regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thomas P Minka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Unpublished draft</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 6: Detecting stance in tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Semantic Evaluation</title>
		<meeting>the International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Stance and sentiment in tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Saif M Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kiritchenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.01655</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Extracting argument and domain words for identifying argument components in texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><forename type="middle">J</forename><surname>Litman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ArgMining@ HLT-NAACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="22" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Joint prediction in mst-style discourse parsing for argumentation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>of the Conference on Empirical Methods in Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="938" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modeling user arguments, interactions, and attributes for stance prediction in online debate forums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghui</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchuan</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 SIAM International Conference on Data Mining</title>
		<meeting>the 2015 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="855" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploring the space of topic coherence measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Röder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Both</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hinneburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth ACM international conference on Web search and data mining</title>
		<meeting>the eighth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="399" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ioannis Manousos Katakis, Georgios Petasis, and Vangelis Karkaletsis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sardianos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Argumentation Mining</title>
		<meeting>the 2nd Workshop on Argumentation Mining</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="56" to="66" />
		</imprint>
	</monogr>
	<note>Argument extraction from news</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Identifying argumentative discourse structures in persuasive essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>of the Conference on Empirical Methods in Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Finding arguing expressions of divergent viewpoints in online debates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amine</forename><surname>Trabelsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Osmar R Zaıane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM)@ EACL</title>
		<meeting>the 5th Workshop on Language Analysis for Social Media (LASM)@ EACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="35" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Mitre at semeval-2016 task 6: Transfer learning for stance detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Zarrella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Marsh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03784</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
