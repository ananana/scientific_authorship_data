<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Framework for Comparing Groups of Documents</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><forename type="middle">S</forename><surname>Maiya</surname></persName>
							<email>amaiya@ida.org</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Defense Analyses -Alexandria</orgName>
								<address>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Framework for Comparing Groups of Documents</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a general framework for comparing multiple groups of documents. A bipartite graph model is proposed where document groups are represented as one node set and the comparison criteria are represented as the other node set. Using this model, we present basic algorithms to extract insights into similarities and differences among the document groups. Finally , we demonstrate the versatility of our framework through an analysis of NSF funding programs for basic research.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Motivation</head><p>Given multiple sets (or groups) of documents, it is often necessary to compare the groups to identify similarities and differences along different dimen- sions. In this work, we present a general frame- work to perform such comparisons for extraction of important insights. Indeed, many real-world tasks can be framed as a problem of comparing two or more groups of documents. Here, we pro- vide two motivating examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Program Reviews.</head><p>To better direct research efforts, funding organizations such as the National Science Foundation (NSF), the National Institutes of Health (NIH), and the Department of Defense (DoD), are often in the position of reviewing re- search programs via their artifacts (e.g., grant ab- stracts, published papers, and other research de- scriptions). Such reviews might involve identify- ing overlaps across different programs, which may indicate a duplication of effort. It may also involve the identification of unique, emerging, or dimin- ishing topics. A "document group" here could be defined either as a particular research program that funds many organizations, the totality of funded research conducted by a specific organization, or all research associated with a particular time pe- riod (e.g., fiscal year). In all cases, the objective is to draw comparisons between groups by compar- ing the document sets associated with them.</p><p>2. Intelligence. In the areas of defense and in- telligence, document sets are sometimes obtained from different sources or entities. For instance, the U.S. Armed Forces sometimes seize documents during raids of terrorist strongholds. <ref type="bibr">1</ref> Similarities between two document sets (each captured from a different source) can potentially be used to infer a non-obvious association between the sources.</p><p>Of course, there are numerous additional examples across many domains (e.g., comparing different news sources, comparing the reviews for several products, etc.). Given the abundance of real-world applications as illustrated above, it is surprising, then, that there are no existing general-purpose ap- proaches for drawing such comparisons. While there is some previous work on the comparison of document sets (referred to as comparative text mining), these existing approaches lack the gener- ality to be widely applicable across different use case scenarios with different comparison criteria. Moreover, much of the work in the area focuses largely on the summarization of shared or un- shared topics among document groups (e.g., , <ref type="bibr" target="#b4">Campr and Ježek (2013)</ref>, <ref type="bibr" target="#b16">Wang et al. (2012)</ref>, <ref type="bibr" target="#b17">Zhai et al. (2004)</ref>). That is, the problem of drawing multi- faceted comparisons among the groups themselves is not typically addressed. This, then, motivates our development of a general-purpose model for comparisons of document sets along arbitrary di- mensions. We use this model for the identification of similarities, differences, trends, and anomalies among large groups of documents. We begin by formally describing our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Formal Model for Comparing Document Groups</head><p>As input, we are given several groups of doc- uments, and our task is to compare them. We now formally define these document groups and the criteria used to compare them. Let D = {d 1 , d 2 , . . . , d N } be a document collection com- prising the totality of documents under considera- tion, where N is the size. Let D P be a partition of D representing the document groups.</p><formula xml:id="formula_0">Definition 1 A document group is a subset D P i ∈ D P (where index i ∈ {1 . . . |D P |}).</formula><p>Each document group in D P , for instance, might represent articles associated with either a particular organization (e.g., university), a re- search funding source (e.g., NSF or DARPA pro- gram), or a time period (e.g., a fiscal year). Docu- ment groups are compared using comparison cri- teria, D C , a family of subsets of D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2 A comparison criterion is a subset</head><formula xml:id="formula_1">D C i ∈ D C (where index i ∈ {1 . . . |D C |}).</formula><p>Intuitively, each subset of D C represents a set of documents sharing some attribute. Our model allows great flexibility in how D C is defined. For instance, D C might be defined by the named en- tities mentioned within documents (e.g., each sub- set contains documents that mention a particular person or organization of interest). For the present work, we define D C by topics discovered using la- tent Dirichlet allocation or LDA ( <ref type="bibr" target="#b2">Blei et al., 2003)</ref>.</p><p>LDA Topics as Comparison Criteria. Proba- bilistic topic modeling algorithms like LDA dis- cover latent themes (i.e., topics) in document col- lections. By using these discovered topics as the comparison criteria, we can compare arbitrary groups of documents by the themes and subject areas comprising them. Let K be the number of topics or themes in D. Each document in D is composed of a sequence of words:</p><formula xml:id="formula_2">d i = s i1 , s i2 , . . . , s iN i , where N i is the number of words in d i and i ∈ {1 . . . N }. V = N i=1 f (d i )</formula><p>is the vocabulary of D, where f (·) takes a sequence of elements and returns a set. LDA takes K and D (including its components such as V ) as input and produces two matrices as output, one of which is θ. The matrix θ ∈ R N ×K is the document- topic distribution matrix and shows the distribu- tion of topics within each document. Each row of the matrix represents a probability distribution. D C is constructed using K subsets of documents, each of which represent a set of documents per- taining largely to the same topic. That is, for t ∈ {1 . . . K} and i ∈ {1 . . . N }, each subset D C t ∈ D C is comprised of all documents d i where t = argmax x θ ix . <ref type="bibr">2</ref> Having defined the document groups D P and the comparison criteria D C , we now construct a bipartite graph model used to per- form comparisons.</p><p>A Bipartite Graph Model. Our objective is to compare the document groups in D P based on D C . We do so by representing D P and D C as a weighted bipartite graph, G = (P, C, E, w), where P and C are disjoint sets of nodes, E is the edge set, and w : E → Z + are the edge weights. Each subset of D P is represented as a node in P , and each subset of D C is represented as a node in C. Let α : P → D P and β : C → D C be functions that map nodes to the document sub- sets that they represent. Then, the edge set E is (i.e., a document cluster pertaining primarily to the same topic). Each edge represents the intersection of the two subsets it connects. In the next section, we will describe basic algorithms on such bipartite graphs capable of yielding important insights into the similarities and differences among document groups.</p><formula xml:id="formula_3">{(u, v) | u ∈ P, v ∈ C, α(u) ∩ β(v) = ∅},</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Basic Algorithms Using the Model</head><p>We focus on three basic operations in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Node Entropy. Let</head><p>w be a vector of weights for all edges incident to some node v ∈ E. The en- tropy H of v is:</p><formula xml:id="formula_4">H(v) = − i p i log | w| (p i )</formula><p>, where p i = w i j w j and i, j ∈ {1 . . . | w|}. A similar for- mulation was employed in <ref type="bibr" target="#b7">Eagle et al. (2010)</ref>. In- tuitively, if v ∈ P , H(v) measures the extent to which the document group is concentrated around a small number of topics (lower values of H(v) mean more concentrated). Similarly, if v ∈ C, it is the extent to which a topic is concentrated around a small number of document groups.</p><p>Node Similarity. Given a graph G, there are many ways to measure the similarity of two nodes based on their connections. Such measures can be used to infer similarity (and dissimilarity) among doc- ument groups. However, existing methods are not well-suited for the task of document group com- parison. The well-known SimRank algorithm <ref type="bibr" target="#b10">(Jeh and Widom, 2002</ref>) ignores edge weights, and nei- ther SimRank nor its extension, SimRank++ (An- tonellis et al., 2008), scale to larger graphs. Sim- Rank++ and ASCOS (Chen and Giles, 2013) do incorporate edge weights but in ways that are not appropriate for document group comparisons. For instance, both SimRank++ and ASCOS in- corporate magnitude in the similarity computa- tion. Consider the case where document groups are defined as research labs. ASCOS and Sim- Rank++ will measure large research labs and small research labs as less similar when in fact they may publish nearly identical lines of research. Finally, under these existing methods, document groups sharing zero topics in common could still be con- sidered similar, which is undesirable here. For these reasons, we formulate similarity as follows.</p><p>Let N G (·) be a function that returns the neighbors of a given node in G. Given two nodes u, v ∈ P , let L u,v = N G (u) ∪ N G (v) and let x : I → L u,v be the indexing function for L u,v . <ref type="bibr">3</ref> We construct two vectors, a and b, where a k = w(u, x(k)), b k = w(v, x(k)), and k ∈ I. Each vector is es-</p><formula xml:id="formula_5">3 I is the index set of L u,v .</formula><p>sentially a sequence of weights for edges between u, v ∈ P and each node in L u,v . Similarity of two nodes is measured using the cosine similarity of their corresponding sequences, a· b a b</p><p>, which we compute using a function sim(·, ·). Thus, doc- ument groups are considered more similar when they have similar sets of topics in similar propor- tions. As we will show later, this simple solution, based on item-based collaborative filtering <ref type="bibr" target="#b13">(Sarwar et al., 2001</ref>), is surprisingly effective at infer- ring similarity among document groups in G.</p><p>Node Clusters. Identifying clusters of related nodes in the bipartite graph G can show how doc- ument groups form larger classes. However, we find that G is typically fairly dense. For these reasons, partitioning of the one-mode projection of G and other standard bipartite graph cluster- ing techniques (e.g., Dhillion (2001) and Sun et al. <ref type="formula">(2009)</ref>) are rendered less effective. We instead employ a different tack and exploit the node sim- ilarities computed earlier. We transform G into a new weighted graph G P = (P, E P , w sim ) where</p><formula xml:id="formula_6">E P = {(u, v) | u, v ∈ P, sim(u, v) &gt; ξ}, ξ</formula><p>is a pre-defined threshold, and w sim is the edge weight function (i.e., w sim = sim). Thus, G P is the similarity graph of document groups. ξ = 0.5 was used as the threshold for our analyses. To find clusters in G P , we employ the Louvain al- gorithm, a heuristic method based on modularity optimization ( <ref type="bibr" target="#b3">Blondel et al., 2008)</ref>. Modularity measures the fraction of edges falling within clus- ters as compared to the expected fraction if edges were distributed evenly in the graph <ref type="bibr" target="#b12">(Newman, 2006</ref>). The algorithm initially assigns each node to its own cluster. At each iteration, in a local and greedy fashion, nodes are re-assigned to clusters with which they achieve the highest modularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Example Analysis: NSF Grants</head><p>As a realistic and informative case study, we uti- lize our model to characterize funding programs of the National Science Foundation (NSF). This corpus consists of 132,372 grant abstracts describ- ing awards for basic research and other support funded by the NSF between the years 1990 and 2002 (Bache and Lichman, 2013). <ref type="bibr">4</ref> Each award is associated with both a program element (i.e., fund- ing source) and a date. We define document groups in two ways: by program element and by calendar year. For comparison criteria, we used topics discovered with the MALLET implementa- tion of LDA <ref type="bibr" target="#b11">(McCallum, 2002</ref>) using K = 400 as the number of topics and 200 as the number of iter- ations. All other parameters were left as defaults.</p><p>The NSF corpus possesses unique properties that lend themselves to experimental evaluation. For instance, program elements are not only associ- ated with specific sets of research topics but are named based on the content of the program. This provides a measure of ground truth against which we can validate our model. We structure our anal- yses around specific questions, which now follow.</p><p>Which NSF programs are focused on specific areas and which are not? When defining doc- ument groups as program elements (i.e., each NSF program is a node in P ), node entropy can be used to answer this question. <ref type="table" target="#tab_1">Table 1</ref> shows ex- amples of program elements most and least as- sociated with specific topics, as measured by en- tropy. For example, the program 1311 Linguistics (low entropy) is largely focused on a single lin- guistics topic (labeled by LDA with words such as "language," "languages," and "linguistic"). By contrast, the Australia program (high entropy) was designed to support US-Australia cooperative re- search across many fields, as correctly inferred by our model.  Which research areas are growing/emerging? When defining document groups as calendar years (instead of program elements), low entropy nodes in C are topics concentrated around certain years. Concentrations in later years indicate growth. The LDA-discovered topic nanotechnology is among the lowest entropy topics (i.e., an outlier topic with respect to entropy). As shown in <ref type="figure" target="#fig_2">Figure 2</ref>, the number of nanotechnology grants drastically in- creased in proportion through 2002. This result is consistent with history, as the National Nanotech- nology Initiative was proposed in the late 1990s to promote nanotechnology R&amp;D. <ref type="bibr">5</ref> One could also measure such trends using budget allocations by incorporating the award amounts into the edge weights of G. <ref type="bibr">1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002</ref> Topic: Nanotechnology Given an NSF program, to which other pro- grams is it most similar? As described in Section 3, when each node in P represents an NSF pro- gram, our model can easily identify the programs most similar to a given program. For instance, Ta- ble 2 shows the top three most similar programs to both the Theoretical Physics and Ecology pro- grams. Results agree with intuition. For each NSF program, we identified the top n most sim- ilar programs ranked by our sim(·, ·) function, where n ∈ {3, 6, 9}. These programs were man- ually judged for relatedness, and the Mean Av- erage Precision (MAP), a standard performance metric for ranking tasks in information retrieval, was computed. We were unsuccessful in evaluat- ing alternative weighted similarity measures men- tioned in Section 3 due to their aforementioned issues with scalability and the size of the NSF dataset. (For instance, the implementations of AS- COS ( <ref type="bibr" target="#b0">Antonellis et al., 2008)</ref> and <ref type="bibr">SimRank (Jeh and Widom, 2002</ref>) that we considered are avail- able here. 6 ) Recall that our sim(·, ·) function is based on measuring the cosine similarity between two weight vectors, a and b, generated from our bipartite graph model. As a baseline for compar- ison, we evaluated two additional similarity im- plementations using these weight vectors. The first measures the similarity between weight vec- tors using weighted Jaccard similarity, which is k min(a k ,b k ) k max(a k ,b k ) (denoted as Wtd. Jaccard). The sec- ond measure is implemented by taking the Spear- man's rank correlation coefficient of a and b (de- National_Nanotechnology_Initiative 6 https://github.com/hhchen1105/ networkx_addon noted as Rank). <ref type="figure" target="#fig_3">Figure 3</ref> shows the Mean Average Precision (MAP) for each method and each value of n. With the exception of the difference between Cosine and Wtd. Jaccard for MAP@3, all other performance differentials were statistically signif- icant, based on a one-way ANOVA and post-hoc Tukey HSD at a 5% significance level. This, then, provides some validation for our choice.   How do NSF programs join together to form larger program categories? As mentioned, by using the similarity graph G P constructed from G, clusters of related NSF programs can be discov- ered. <ref type="figure" target="#fig_4">Figure 4</ref>, for instance, shows a discovered cluster of NSF programs all related to the field of neuroscience. Each NSF program (i.e., node) is composed of many documents. Which pairs of grants are the most similar in the research they describe? Although the focus of this paper is on drawing comparisons among groups of documents, it is often necessary to draw comparisons among individual documents, as well. For instance, one may wish to identify pairs of grants from different programs describing highly similar lines of research. One common ap- proach to this is to measure the similarity among low-dimensional representations of documents re- turned by LDA ( <ref type="bibr" target="#b2">Blei et al., 2003)</ref>. We employ the Hellinger distance metric for this. Unfortu- nately, identifying the set of most similar docu- ment pairs in this way can be computationally ex- pensive, as the number of pairwise comparisons scales quadratically with the size of the corpus. To address this, our bipartite graph model can be ex- ploited as a blocking heuristic using either the doc- ument groups or the comparison criteria. In the latter case, one can limit the pairwise comparisons to only those documents that reside in the same subset of D C . For the former case, node similar- ity can be used. Instead of comparing each docu- ment with every other document, we can limit the comparisons to only those document groups of in- terest that are deemed similar by our model. As an illustrative example, the program 1271 Compu- tational Mathematics and the program 2865 Nu- meric, Symbolic, and Geometric Computation are inferred as being highly similar. Between these groups, the following two grants are easily iden- tified as being the most similar with a Hellinger similarity score of 0.73 (only titles are shown due to space constraints):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Low Entropy Program Elements</head><formula xml:id="formula_7">Percentage</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1245">Theoretical Physics 1182 Ecology</head><p>• Grant #1: Analyses of Structured Computational</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problems and Parallel Iterative Algorithms</head><p>(Discusses parallel iterative methods for solutions to large sparse/dense systems of linear equations.)</p><p>• Grant #2: Sparse Matrix Algorithms on Distributed</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Memory Multiprocessors</head><p>As can be seen, despite some differences in ter- minology, the two lines of research are related, as matrices (studied in Grant #2) are used to com- pactly represent and work with systems of linear equations (studied in Grant #1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have presented a bipartite graph model for drawing comparisons among large groups of docu- ments. We showed how basic algorithms using the model can identify trends and anomalies among the document groups. As an example analysis, we demonstrated how our model can be used to better characterize and evaluate NSF research programs. For future work, we plan on employing alterna- tive comparison criteria in our model such as those derived from named entity recognition and para- phrase detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>and the edge weight for any two nodes u ∈ P and v ∈ C is w((u, v)) = |α(u) ∩ β(v)|. Concisely, each weighted edge in G between a document group (in P ) and a topic (in C) represents the number of documents shared among the two sets. Fig- ure 1 shows a toy illustration of the model. Each node in P is shown in black and represents a sub- set of D P (i.e., a document group). Each node in C is shown in gray and represents a subset of D C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: [Toy Illustration of Bipartite Graph Model.] Each black node (i.e., node ∈ P ) represents a document group. Each gray node (i.e., node ∈ C) represents a cluster of documents pertaining primarily to the same topic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: [Uptrend in Nanotechnology.] Our model correctly identifies the surge in nanotechnology R&amp;D beginning in the late 1990s.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 : [Mean Average Precision (MAP).]</head><label>3</label><figDesc>Figure 3: [Mean Average Precision (MAP).] Cosine similarity outperforms alternative approaches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: [Neuroscience Programs.] A discovered cluster of program elements all related to neuroscience.</figDesc><graphic url="image-76.png" coords="5,86.66,534.17,189.10,92.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>[Examples of High/Low Entropy Programs.] 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : [Similarity Queries.] Three most similar pro- grams to the Theoretical Physics and Ecology programs.</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://en.wikipedia.org/wiki/ Document_Exploitation_(DOCEX)</note>

			<note place="foot" n="2"> D C is also a partition of D, when defined in this way.</note>

			<note place="foot" n="4"> Data for years 1989 and 2003 in this publicly available corpus were partially missing and omitted in some analyses.</note>

			<note place="foot" n="5"> http://en.wikipedia.org/wiki/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simrank++: Query Rewriting Through Link Analysis of the Click Graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Antonellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><forename type="middle">G</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="408" to="421" />
			<date type="published" when="2008-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Latent Dirichlet Allocation. J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast unfolding of communities in large networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Loup</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renaud</forename><surname>Guillaume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Lambiotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lefebvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Mechanics: Theory and Experiment</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">10008</biblScope>
			<date type="published" when="2008-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Topic Models for Comparative Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Campr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Ježek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text, Speech, and Dialogue</title>
		<editor>Ivan Habernal and Václav Matoušek</editor>
		<imprint>
			<publisher>Springer Berlin Heidelberg</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">8082</biblScope>
			<biblScope unit="page" from="568" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ASCOS: An Asymmetric Network Structure COntext Similarity Measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM &apos;13</title>
		<meeting>the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="442" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Co-clustering Documents and Words Using Bipartite Spectral GraphPartitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Inderjit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhillion</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<pubPlace>Austin, TX, USA</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Eagle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Claxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network diversity and economic development. Science</title>
		<imprint>
			<biblScope unit="volume">328</biblScope>
			<biblScope unit="issue">5981</biblScope>
			<biblScope unit="page" from="1029" to="1031" />
			<date type="published" when="2010-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Comparative News Summarization Using Linear Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th</title>
		<meeting>the 49th</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="648" to="653" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SimRank: a measure of structural-context similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD &apos;02</title>
		<meeting>the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD &apos;02<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="538" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">MALLET: A Machine Learning for Language Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">K</forename><surname>Mccallum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modularity and community structure in networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2006-06" />
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="8577" to="8582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Item-based Collaborative Filtering Recommendation Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Badrul</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on World Wide Web, WWW &apos;01</title>
		<meeting>the 10th International Conference on World Wide Web, WWW &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ranking-based Clustering of Heterogeneous Information Networks with Star Network Schema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yintao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;09</title>
		<meeting>the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="797" to="806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Summarizing the Differences in Multilingual News</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houping</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;11</title>
		<meeting>the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="735" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparative Document Summarization via Discriminative Sentence Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingding</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghuo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2012-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Cross-collection Mixture Model for Comparative Text Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atulya</forename><surname>Velivelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;04</title>
		<meeting>the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="743" to="748" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
