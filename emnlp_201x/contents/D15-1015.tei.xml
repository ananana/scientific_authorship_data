<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Bilingual Lexicon Induction with Transferred ConvNet Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
							<email>douwe.kiela@cl.cam.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science KU Leuven</orgName>
								<orgName type="department" key="dep2">Computer Laboratory</orgName>
								<orgName type="institution" key="instit1">Computer Laboratory University of Cambridge</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science KU Leuven</orgName>
								<orgName type="department" key="dep2">Computer Laboratory</orgName>
								<orgName type="institution" key="instit1">Computer Laboratory University of Cambridge</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
							<email>stephen.clark@cl.cam.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science KU Leuven</orgName>
								<orgName type="department" key="dep2">Computer Laboratory</orgName>
								<orgName type="institution" key="instit1">Computer Laboratory University of Cambridge</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Visual Bilingual Lexicon Induction with Transferred ConvNet Features</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper is concerned with the task of bilingual lexicon induction using image-based features. By applying features from a convolutional neural network (CNN), we obtain state-of-the-art performance on a standard dataset, obtaining a 79% relative improvement over previous work which uses bags of visual words based on SIFT features. The CNN image-based approach is also compared with state-of-the-art linguistic approaches to bilingual lexicon induction , even outperforming these for one of three language pairs on another standard dataset. Furthermore, we shed new light on the type of visual similarity metric to use for genuine similarity versus re-latedness tasks, and experiment with using multiple layers from the same network in an attempt to improve performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Bilingual lexicon induction is the task of finding words that share a common meaning across differ- ent languages. It plays an important role in a va- riety of tasks in information retrieval and natural language processing, including cross-lingual in- formation retrieval <ref type="bibr" target="#b29">(Lavrenko et al., 2002;</ref><ref type="bibr" target="#b32">Levow et al., 2005</ref>) and statistical machine translation <ref type="bibr" target="#b40">(Och and Ney, 2003)</ref>. Although parallel corpora have been used successfully for inducing bilin- gual lexicons for some languages <ref type="bibr" target="#b40">(Och and Ney, 2003)</ref>, these corpora are either too small or un- available for many language pairs. Consequently, mono-lingual approaches that rely on compara- ble instead of parallel corpora have been devel- oped <ref type="bibr" target="#b16">(Fung and Yee, 1998;</ref><ref type="bibr" target="#b26">Koehn and Knight, 2002</ref>). These approaches work by mapping lan- guage pairs to a shared bilingual space and ex- tracting lexical items from that space. Bergsma and Van Durme (2011) showed that this bilingual space need not be linguistic in nature: they used labeled images from the Web to obtain bilingual lexical translation pairs based on the visual fea- tures of corresponding images. Local features are computed using SIFT <ref type="bibr" target="#b36">(Lowe, 2004</ref>) and color his- tograms ( <ref type="bibr" target="#b10">Deselaers et al., 2008</ref>) and aggregated as bags of visual words (BOVW) <ref type="bibr" target="#b51">(Sivic and Zisserman, 2003</ref>) to get bilingual representations in a shared visual space. Their highest performance is obtained by combining these visual features with normalized edit distance, an orthographic similar- ity metric <ref type="bibr" target="#b39">(Navarro, 2001</ref>).</p><p>There are several advantages to having a vi- sual rather than a linguistic intermediate bilin- gual space: First, while labeled images are readily available for many languages through resources such as Google Images, language pairs that have sizeable comparable, let alone parallel, corpora are relatively scarce. Second, it has been found that meaning is often grounded in the perceptual system, and that the quality of semantic repre- sentations improves significantly when they are grounded in the visual modality <ref type="bibr" target="#b48">(Silberer and Lapata, 2012;</ref>. Having an inter- mediate visual space means that words in differ- ent languages can be grounded in the same space. Third, it is natural to use vision as an intermediate: when we communicate with someone who does not speak our language, we often communicate by directly referring to our surroundings. Lan- guages that are linguistically far apart will, by cog- nitive necessity, still refer to objects in the same visual space. While some approaches to bilingual lexicon induction rely on orthographic properties ( <ref type="bibr" target="#b19">Haghighi et al., 2008;</ref><ref type="bibr" target="#b26">Koehn and Knight, 2002</ref>) or properties of frequency distributions <ref type="bibr" target="#b45">(Schafer and Yarowsky, 2002</ref>) that will work only for closely related languages, a visual space can work for any language, whether it's English or Chinese, Arabic or Icelandic, or all Greek to you.</p><p>It has recently been shown, however, that much better performance can be achieved on seman- tic similarity and relatedness tasks by using vi- sual representations from deep convolutional neu- ral networks (CNNs) instead of BOVW features <ref type="bibr" target="#b23">(Kiela and Bottou, 2014)</ref>. In this paper we ap- ply such CNN-derived visual features to the task of bilingual lexicon induction. To obtain a trans- lation of a word in a source language, we find the nearest neighbours from words in the target language, where words in both languages reside in a shared visual space made up of CNN-based features. Nearest neighbours are found by apply- ing similarity metrics from both <ref type="bibr" target="#b23">Kiela and Bottou (2014)</ref> and Bergsma and Van Durme (2011). In summary, the contributions of this paper are:</p><p>• We obtain a relative improvement of 79% over Bergsma and Van Durme (2011) on a standard dataset based on fifteen language pairs.</p><p>• We shed new light on the question of whether genuine similarity versus semantic related- ness tasks require different similarity metrics for optimal performance <ref type="bibr" target="#b23">(Kiela and Bottou, 2014</ref>). • We experiment with using different layers of the CNN and find that performance is not af- fected significantly in either case, obtaining a slight improvement for the relatedness task but no improvement for genuine similarity.</p><p>• Finally, we show that the visual approach out- performs the linguistic approaches on one of the three language pairs on a standard dataset. To our knowledge this is the first work to pro- vide a comparison of visual and state-of-the- art linguistic approaches to bilingual lexicon induction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Bilingual Lexicon Learning</head><p>Bilingual lexicon learning is the task of auto- matically inducing word translations from raw data, and is an attractive alternative to the time- consuming and expensive process of manually building high-quality resources for a wide vari- ety of language pairs and domains. Early ap- proaches relied on limited and domain-restricted parallel data, and the induced lexicons were typi- cally a by-product of word alignment models <ref type="bibr" target="#b40">(Och and Ney, 2003)</ref>. To alleviate the issue of low cov- erage, a large body of work has been dedicated to lexicon learning from more abundant and less restricted comparable data, e.g., <ref type="bibr" target="#b16">(Fung and Yee, 1998;</ref><ref type="bibr" target="#b42">Rapp, 1999;</ref><ref type="bibr" target="#b17">Gaussier et al., 2004;</ref><ref type="bibr" target="#b47">Shezaf and Rappoport, 2010;</ref><ref type="bibr" target="#b54">Tamura et al., 2012)</ref>. How- ever, these models typically rely on the availabil- ity of bilingual seed lexicons to produce shared bilingual spaces, as well as large repositories of comparable data. Therefore, several approaches attempt to learn lexicons from large monolingual data sets in two languages ( <ref type="bibr" target="#b26">Koehn and Knight, 2002;</ref><ref type="bibr" target="#b19">Haghighi et al., 2008</ref>), but their perfor- mance again relies on language pair-dependent clues such as orthographic similarity. A further approach removed the requirement of seed lexi- cons, and induced lexicons using bilingual spaces spanned by multilingual probabilistic topic mod- els <ref type="bibr" target="#b58">(Vuli´cVuli´c et al., 2011;</ref><ref type="bibr" target="#b34">Liu et al., 2013;</ref><ref type="bibr" target="#b57">Vuli´cVuli´c and Moens, 2013b</ref>). However, these models require document alignments as initial bilingual signals. In this work, following recent research in multi-modal semantics and image representation learning-in particular deep learning and con- volutional neural networks-we test the ability of purely visual data to induce shared bilingual spaces and to consequently learn bilingual word correspondences in these spaces. By compiling images related to linguistic concepts given in dif- ferent languages, the potentially prohibitive data requirements and language pair-dependence from prior work is removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deep Convolutional Neural Networks</head><p>Deep convolutional neural networks (CNNs) have become extremely popular in the computer vi- sion community. These networks currently pro- vide state-of-the-art performance for a variety of key computer vision tasks such as object recogni- tion ( <ref type="bibr" target="#b43">Razavian et al., 2014</ref>). They tend to be rel- atively deep, consisting of a number of rectified linear unit layers <ref type="bibr" target="#b38">(Nair and Hinton, 2010</ref>) and a series of convolutional layers ( <ref type="bibr" target="#b27">Krizhevsky et al., 2012)</ref>. Recently, such layers have been used in transfer learning techniques, where they are used as mid-level features in other computer vision tasks ( <ref type="bibr" target="#b41">Oquab et al., 2014)</ref>. Although the idea of transferring CNN features is not new <ref type="bibr" target="#b11">(Driancourt and Bottou, 1990)</ref>, the simultaneous availability of massive amounts of data and cheap GPUs has led to considerable advances in computer vision, simi- lar in scale to those witnessed with SIFT and HOG descriptors a decade ago ( <ref type="bibr" target="#b43">Razavian et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Multi-Modal Semantics</head><p>Multi-modal semantics is motivated by parallels with human concept acquisition. It has been found that semantic knowledge, from a very early age, relies heavily on perceptual information <ref type="bibr" target="#b35">(Louwerse, 2008)</ref>, and there exists substantial evidence that many concepts are grounded in the percep- tual system ( <ref type="bibr" target="#b2">Barsalou, 2008)</ref>. One way to accom- plish such grounding is by combining linguistic representations with information from a percep- tual modality, obtained from, e.g., property norm- ing experiments <ref type="bibr" target="#b48">(Silberer and Lapata, 2012;</ref><ref type="bibr" target="#b50">Silberer et al., 2013;</ref><ref type="bibr" target="#b44">Roller and Schulte im Walde, 2013;</ref>) or extracting features from raw image data <ref type="bibr" target="#b12">(Feng and Lapata, 2010;</ref><ref type="bibr" target="#b31">Leong and Mihalcea, 2011;</ref>). Such multi-modal vi- sual approaches often rely on local descriptors, such as SIFT <ref type="bibr" target="#b36">(Lowe, 2004</ref>), SURF ( <ref type="bibr" target="#b3">Bay et al., 2008)</ref>, or HOG ( <ref type="bibr" target="#b8">Dalal and Triggs, 2005</ref>), as well as pyramidal variants of these descriptors such as PHOW ( <ref type="bibr" target="#b6">Bosch et al., 2007)</ref>. However, deep CNN features have recently been successfully trans- ferred to multi-modal semantics <ref type="bibr" target="#b23">(Kiela and Bottou, 2014;</ref><ref type="bibr" target="#b46">Shen et al., 2014</ref>). Deep learning tech- niques have also been successfully employed in cross-modal tasks ( <ref type="bibr" target="#b15">Frome et al., 2013;</ref><ref type="bibr" target="#b52">Socher et al., 2014;</ref><ref type="bibr" target="#b30">Lazaridou et al., 2014;</ref><ref type="bibr" target="#b25">Kiros et al., 2014</ref>). Other examples of multi-modal deep learn- ing use restricted Boltzmann machines <ref type="bibr" target="#b53">(Srivastava and Salakhutdinov, 2014</ref>) or auto-encoders ( <ref type="bibr" target="#b59">Wu et al., 2013;</ref><ref type="bibr" target="#b49">Silberer and Lapata, 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Purely Visual Approach to Bilingual Lexicon Learning</head><p>We assume that the best translation, or match- ing lexical item, of a word w s (in the source lan- guage) is the word w t (in the target language) that is the nearest cross-lingual neighbour to w s in the bilingual visual space. Hence a similarity (or distance) score between lexical items from dif- ferent languages is required. In this section, we describe: one, how to build image representations from sets of images associated with each lexical item, i.e. how to induce a shared bilingual visual space in which all lexical items are represented; and two, how to compute the similarity between lexical items using their visual representations in the shared bilingual space. We also describe the evaluation datasets and metrics we use.</p><p>To facilitate further research, we will make our code and data publicly available. Please see the following webpage: http://www.cl.cam. ac.uk/ ˜ dk427/bli.html.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Image Representations</head><p>We use Google Images to extract the top n ranked images for each lexical item in the evaluation datasets. It has been shown that images from Google yield higher quality representations than comparable sources such as Flickr ( <ref type="bibr" target="#b4">Bergsma and Goebel, 2011)</ref> and that Google-derived datasets are competitive with "hand prepared datasets" <ref type="bibr" target="#b13">(Fergus et al., 2005</ref>). Google Images also has the advantage that it has full coverage and is multi-lingual, as opposed to other potential im- age sources such as ImageNet ( <ref type="bibr" target="#b9">Deng et al., 2009)</ref> or the ESP Game Dataset (von <ref type="bibr" target="#b55">Ahn and Dabbish, 2004</ref>). For each Google search we specify the tar- get language corresponding to the lexical item's language. <ref type="figure" target="#fig_1">Figure 2</ref> gives some example images retrieved using the same query terms in different languages. For each image, we extract the pre- softmax layer of an AlexNet ( <ref type="bibr" target="#b27">Krizhevsky et al., 2012</ref>). The network contains a number of lay- ers, starting with five convolutional layers, two fully connected layers and finally a softmax, and has been pre-trained on the ImageNet classifica- tion task using Caffe ( <ref type="bibr" target="#b22">Jia et al., 2014)</ref>. See <ref type="figure" target="#fig_0">Figure  1</ref> for a simple diagram illustrating the approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Visual Similarity</head><p>Suppose that, as part of the evaluation, the similar- ity between bicycle and fiets is required. Each of the two words has n images associated with it -the top n as returned by Google image search, using bicycle and fiets as separate query terms. Hence to calculate the similarity, a measure is required which takes two sets of images as input. The stan- dard approach in multi-modal semantics is to de- rive a single image representation for each word, e.g., by averaging the n images. An alternative is to take the pointwise maximum across the n im- age vector representations, also producing a sin- gle vector <ref type="bibr" target="#b23">(Kiela and Bottou, 2014</ref>). Kiela and Bottou call these combined representations CNN- MEAN and CNN-MAX, respectively. Cosine is then used to calculate the similarity between the resulting pair of image vectors.</p><p>An alternative strategy, however, is to consider the similarities between individual images instead of their aggregated representations. Bergsma and Van Durme (2011) propose two similarity met- rics based on this principle: taking the average of the maximum similarity scores (AVGMAX), or the maximum of the maximum similarity scores (MAXMAX) between associated images. Contin- uing with our example, for each of the n images for bicycle, the maximum similarity is found by searching over the n images for fiets. AVGMAX then takes the average of those n maximum simi- larites; MAXMAX takes the maximum. To avoid confusion, we will refer to the CNN-based mod- els that use these metrics as CNN-AVGMAX and CNN-MAXMAX. Formally, these metrics are de- fined as in <ref type="table">Table 1</ref>. We experiment with both kinds of MAX and find that they optimize for different kinds of similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluations</head><p>Test Sets. Bergsma and Van Durme's primary evaluation dataset consists of a set of five hundred matching lexical items for fifteen language pairs, based on six languages. (The fifteen pairs results from all ways of pairing six languages). The data is publicly available online. <ref type="bibr">1</ref> In order to get the five hundred lexical items, they first rank nouns by the conditional probability of them occurring in the pattern "{image,photo,photograph,picture} of {a,an} " in the web-scale Google N-gram corpus ( <ref type="bibr">Lin et al., 2010)</ref>, and take the top five hun- dred words as their English lexicon. For each item <ref type="bibr">1</ref>  </p><formula xml:id="formula_0">i s , 1 n it∈I(wt) i t )</formula><p>CNN-MAX sim(max I(w s ), max I(w t )) <ref type="table">Table 1</ref>: Visual similarity metrics between two sets of n images. I(w s ) represents the set of im- ages for a given source word w s , I(w t ) the set of images for a given target word w t ; max takes a set of vectors and returns the single element-wise maximum vector.</p><p>in the English lexicon, they obtain correspond- ing items in the other languages-Spanish, Ital- ian, French, German and Dutch-through Google Translate. We call this dataset BERGSMA500. In addition to that dataset, we evaluate on a dataset constructed to measure the general perfor- mance of bilingual lexicon learning models from comparable Wikipedia data <ref type="bibr" target="#b56">(Vuli´cVuli´c and Moens, 2013a</ref>). The dataset comprises 1, 000 nouns in three languages: Spanish (ES), Italian (IT), and Dutch (NL), along with their one-to-one gold- standard word translations in English (EN) com- piled semi-automatically using Google Translate and manual annotators for each language. We call this dataset VULIC1000 2 . The test set is accom- panied with comparable data for training, for the three language pairs ES/IT/NL-EN on which text- based models for bilingual lexicon induction were trained <ref type="bibr" target="#b56">(Vuli´cVuli´c and Moens, 2013a)</ref>.</p><p>Given the way that the BERGSMA500 dataset was created, in particular the use of the pattern described above, it contains largely concrete lin- guistic concepts (since, eg, image of a democracy is unlikely to have a high corpus frequency). In contrast, VULIC1000 was designed to capture general bilingual word correspondences, and con- tains several highly abstract test examples, such as entendimiento (understanding) and desigualdad (inequality) in Spanish, or scoperta (discovery) and cambiamento (change) in Italian. Using the two evaluation datasets can potentially provide   <ref type="table" target="#tab_2">Table 2</ref>: Performance on BERGSMA500 com- pared to Bergsma and Van Durme (B&amp;VD).</p><p>some insight into how purely visual models for bilingual lexicon induction behave with respect to both abstract and concrete concepts.</p><p>Evaluation Metrics. We measure performance in a standard way using mean-reciprocal rank:</p><formula xml:id="formula_1">MRR = 1 M M i=1 1 rank(w s , w t )<label>(1)</label></formula><p>where rank(w s , w t ) denotes the rank of the cor- rect translation w t (as provided in the gold stan- dard) in the ranked list of translation candidates for w s , and M is the number of test cases. We also use precision at N (P@N) ( <ref type="bibr" target="#b17">Gaussier et al., 2004;</ref><ref type="bibr" target="#b54">Tamura et al., 2012;</ref><ref type="bibr" target="#b56">Vuli´cVuli´c and Moens, 2013a)</ref>, which measures the proportion of test instances where the correct translation is within the top N highest ranked translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We evaluate the four similarity metrics on the BERGSMA500 dataset and compare the results to the systems of Bergsma and Van Durme, who report results for the AVGMAX function, hav- ing concluded that it performs better than MAX- MAX on English-Spanish translations. We report their best-performing visual-only system, which combines SIFT-based descriptors with color his- tograms, as well as their best-performing overall system, which combines the visual approach with normalized edit distance (NED). Results are aver- aged over fifteen language pairs. The results can be seen in <ref type="table" target="#tab_2">Table 2</ref>. Each of the CNN-based methods outperforms the B&amp;VD sys- tems. The best performing method overall, CNN- AVGMAX, provides a 79% relative improvement over the B&amp;VD visual-only system on the MRR measure, and a 23% relative improvement over their best-performing approach, which includes non-visual information in the form of orthographic similarity. Moreover, their methods include a tun- ing parameter λ that governs the contributions of SIFT-based, color histogram and normalized edit distance similarity scores, whilst our approach does not require any parameter tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Similarity and Relatedness</head><p>The results in    <ref type="bibr" target="#b23">Kiela and Bottou (2014)</ref> achieved optimal per- formance using the latter metrics on a well-known conceptual relatedness dataset. It has been noted before that there is a clear distinction between sim- ilarity and relatedness. This is one of the reasons that, for example, <ref type="bibr">WordSim353 (Finkelstein et al., 2002</ref>) has been criticized: it gives high similarity scores to cases of genuine similarity as well as re- latedness ( <ref type="bibr" target="#b0">Agirre et al., 2009;</ref>). The MEN dataset ( ) that Kiela and Bottou (2014) evaluate on explicitly measures word relatedness. In contrast, the current lexicon learning task seems to require something else than relatedness: whilst a chair and table are semanti- cally related, a translation for chair is not a good translation for table. For example, we want to make sure we translate chair to stuhl in German, and not to tisch. In other words, what we are inter- ested in for this particular task is genuine similar- ity, rather than relatedness.</p><p>Thus, we can evaluate the quality of our simi- larity metrics by comparing their performance on similarity and relatedness tasks: if a metric per- forms well at measuring genuine similarity, this is indicative of its performance in the bilingual lexi- con induction task. In order to examine this ques- tion further, we evaluate performance on the MEN dataset, which measures relatedness ( , and the nouns-subset of the SimLex-999 dataset, which measures genuine similarity ( ). For each pair in the dataset, we cal- culate the similarity score and report the Spearman ρ s correlation, which measures how well the rank- ing of pairs given by the automatic system matches that according to the gold-standard human similar- ity scores. The results are reported in <ref type="table" target="#tab_4">Table 3</ref>.</p><p>It is clear that the per-image similarity met- rics perform better on genuine similarity, as mea- sured by SimLex-999, than on relatedness, as mea- sured by MEN. In fact, the "aggressive" CNN- MAXMAX method, which picks out a single pair of images to represent a linguistic pair, works best for SimLex-999, indicating how stringently it fo- cuses on genuine similarity. For the aggregated vi- sual representation-based metrics, we see the op- posite effect: they perform better on the related- ness task. This sheds light on a question raised by <ref type="bibr" target="#b23">Kiela and Bottou (2014)</ref>, where they speculate that certain errors are a result of whether their vi- sual similarity metric measures genuine similar- ity on the one hand or relatedness on the other: we are better off using per-image visual metrics for genuine similarity, while aggregated visual representation-based metrics yield better perfor- mance on relatedness tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results on VULIC1000</head><p>This section compares our visual-only approach to linguistic approaches for bilingual lexicon in- duction. Since BERGSMA500 has not been eval- uated with such methods, we evaluate on the VULIC1000 dataset <ref type="bibr" target="#b56">(Vuli´cVuli´c and Moens, 2013a)</ref>. This dataset has been used to test the ability of bilingual lexicon induction models to learn trans- lations from comparable data (see sect. 3.3). We do not necessarily expect visual methods to out- perform linguistic ones, but it is instructive to see the comparison.</p><p>We compare our visual models against the cur- rent state-of-the-art lexicon induction model us- ing comparable data <ref type="bibr" target="#b57">(Vuli´cVuli´c and Moens, 2013b)</ref>. This model induces translations from compara- ble Wikipedia data in two steps: (1) It learns a set of highly reliable one-to-one translation pairs using a shared bilingual space obtained by ap- plying the multilingual probabilistic topic model- ing (MuPTM) framework ( <ref type="bibr" target="#b37">Mimno et al., 2009)</ref>. (2) These highly reliable one-to-one translation pairs serve as dimensions of a word-based bilin- gual semantic space ( <ref type="bibr" target="#b17">Gaussier et al., 2004;</ref><ref type="bibr" target="#b54">Tamura et al., 2012</ref>). The model then bootstraps from the high-precision seed lexicon of translations and learns new dimensions of the bilingual space until convergence. This model, which we call BOOT- STRAP, obtains the current best results on the eval- uation dataset. For more details about the boot- strapping model and its comparison against other approaches, we refer to Vuli´c <ref type="bibr" target="#b57">Vuli´c and Moens (2013b)</ref>. <ref type="table" target="#tab_3">Table 4</ref> shows the results for the language pairs in the VULIC1000 dataset. Of the four similar- ity metrics, CNN-AVGMAX again performs best, as it did for BERGSMA500. The linguistic BOOT- STRAP method outperforms our visual approach for two of the three language pairs, but, for the NL-EN language pair, the visual methods in fact perform better. This can be explained by the ob- servation that Vuli´cVuli´c and Moens's NL-EN training data for the BOOTSTRAP model is less abundant (2-3 times fewer Wikipedia articles) and of lower  quality than the data for their ES-EN and IT-EN models. We view these results as highly encourag- ing: while purely visual methods cannot yet reach the peak performance of linguistic approaches that are trained on sufficient amounts of high-quality text data, they outperform linguistic state-of-the- art methods when there is less or lower quality text data available -which one might reasonably ex- pect to be the default scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Adding CNN Layers</head><p>The AlexNet ( <ref type="bibr" target="#b27">Krizhevsky et al., 2012</ref>) from which our image representations are extracted contains a number of layers. <ref type="bibr" target="#b23">Kiela and Bottou (2014)</ref> only use the fully connected pre-softmax layer (which we call FC7) for their image representa- tions. It has been found, however, that other layers in the network, especially the preceding fully con- nected (FC6) and fifth convolutional max pooling (POOL5) layers, also have good properties for usage in transfer learning ( <ref type="bibr">Yosinski et al., 2014</ref>). Hence we performed a (very) preliminary investigation of whether perfor- mance increases with the use of additional layers.</p><p>In light of our findings concerning the differ- ence between genuine similarity and relatedness, this also gives rise to the question of whether the additional layers might be useful for similarity or relatedness, or both. We hypothesize that the nature of the task matters here: if we are only concerned with genuine similarity, layer FC7 is likely to contain all the necessary information to judge whether two images are similar or not, since    the network has been trained for object recogni- tion. If, however, we are interested in related- ness, related properties may just as well be en- coded deeper in the network, so in the layers pre- ceding FC7 rather than in FC7 itself.</p><p>We combined CNN layers with each other by concatenating the normalized layers. For the bilin- gual lexicon induction tasks, we found that perfor- mance did not signficantly increase, which is con- sistent with our hypothesis (since bilingual lexicon induction requires genuine similarity rather than relatedness, and so only requires FC7). We then tested on the MEN dataset ( ) for relatedness and the nouns subset of the SimLex- 999 dataset ( ) for genuine similar- ity. The results can be found in <ref type="table" target="#tab_6">Table 5</ref>.</p><p>The results appear to indicate that adding such additional information does not have a clear effect for genuine similarity, but may lead to a small per- formance increase for relatedness. This could ex- plain why we did not see increased performance on the bilingual lexicon induction task with ad- ditional layers. However, the increase in perfor- mance on the relatedness task is relatively minor, and further investigation is required into the utility of the additional layers for relatedness tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>A possible explanation for the difference in per- formance between languages and datasets is that some words are more concrete than others: a vi- sual representation for elephant is likely to be of higher quality than one for happiness. Visual representations in multi-modal models have been found to perform much better for concrete than ab- stract concepts ( ).</p><p>Although concreteness ratings are available for (some) English words, this is not the case for other languages, so in order to examine the concreteness of the datasets we use a substitute method that has been shown to closely mirror how abstract a con- cept is: image dispersion ( ). The image dispersion d of a concept word w is defined as the average pairwise cosine distance between all the image representations {i 1 . . . i n } in the set of images for a given word:</p><formula xml:id="formula_2">d(w) = 2 n(n − 1) i&lt;j≤n 1 − i j · i k |i j ||i k |<label>(2)</label></formula><p>The average image dispersions for the two datasets, broken down by language, are shown in <ref type="table" target="#tab_8">Table 6</ref>. BERGSMA500 has a lower average im- age dispersion score in general, and thus is more concrete than VULIC1000. It also has less vari- ance. This may explain why we score higher, in absolute terms, on that dataset than on the more abstract one.</p><p>When examining individual languages in the datasets, we note that the worst performing lan- guage on VULIC1000 is Italian, which is also the most abstract dataset, with the highest average im- age dispersion score and the lowest variance.</p><p>There is some evidence that abstract concepts are also perceptually grounded <ref type="bibr" target="#b28">(Lakoff and Johnson, 1999</ref>), but in a more complex way, since abstract concepts express more varied situations ( <ref type="bibr" target="#b1">Barsalou and Wiemer-Hastings, 2005</ref>). Using an image resource like Google Images that has full coverage for almost any word, means that we can retrieve what we might call "associated" images (such as images of voters for words like democ- racy) as opposed to "extensional" images (such as images of cats for cat). This explains why we still obtain good performance on the more abstract VULIC1000 dataset, in some cases outperform- ing linguistic methods: even abstract concepts can have a clear visual representation, albeit of the as- sociated rather than extensional kind.</p><p>However, abstract concepts are overall more likely to yield noisier image sets. Thus, one way to improve results would be to take a multi-modal ap- proach, where we also include linguistic informa- tion, if available, especially for abstract concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>We have presented a novel approach to bilingual lexicon induction that uses convolutional neural network-derived visual features. Using only such visual features, we outperform existing visual and orthographic systems, and even a state-of-the-art linguistic approach for one language, on standard bilingual lexicon induction tasks. In doing so, we have shed new light on which visual similar- ity metric to use for similarity or relatedness tasks, and have experimented with using multiple layers from a CNN. The beauty of the current approach is that it is completely language agnostic and closely mirrors how humans would perform bilingual lex- icon induction: by referring to the external world.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of calculating similarity between images from different languages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example images for the languages in the Bergsma and Van Durme dataset.</figDesc><graphic url="image-3.png" coords="5,72.00,62.81,453.54,233.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 indicate that the per- image CNN-AVGMAX metric outperforms the</head><label>2</label><figDesc></figDesc><table>Language Pair Method 

P@1 P@5 P@10 P@20 MRR 

ES ⇒ EN 

BOOTSTRAP 
57.7 
74.7 
80.9 
84.8 
0.652 

CNN-AVGMAX 
41.9 
54.6 
59.1 
65.6 
0.485 

CNN-MAXMAX 
34.9 
47.4 
53.7 
58.5 
0.414 

CNN-MEAN 
35.4 
48.5 
51.7 
55.8 
0.416 

CNN-MAX 
33.3 
46.3 
50.3 
54.5 
0.395 

IT ⇒ EN 

BOOTSTRAP 
64.7 
80.6 
85.6 
89.7 
0.716 

CNN-AVGMAX 
28.3 
40.6 
44.8 
50.9 
0.343 

CNN-MAXMAX 
22.6 
33.5 
38.6 
44.4 
0.282 

CNN-MEAN 
22.7 
33.2 
37.9 
42.6 
0.281 

CNN-MAX 
21.3 
32.7 
36.8 
41.5 
0.269 

NL ⇒ EN 

BOOTSTRAP 
20.6 
35.7 
43.4 
51.3 
0.277 

CNN-AVGMAX 
38.4 
48.5 
53.7 
58.6 
0.435 

CNN-MAXMAX 
30.8 
42.6 
47.8 
52.9 
0.367 

CNN-MEAN 
32.3 
42.3 
46.5 
50.1 
0.373 

CNN-MAX 
30.4 
41.0 
44.3 
49.3 
0.356 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Performance on VULIC1000 compared to the linguistic bootstrapping method of Vuli´cVuli´c and 
Moens (2013b). 

Method 
MEN SimLex-999 

CNN-AVGMAX 
0.56 
0.34 

CNN-MAXMAX 
0.55 
0.36 

CNN-MEAN 
0.61 
0.32 

CNN-MAX 
0.60 
0.27 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Spearman ρ s correlation for the visual 
similarity metrics on a relatedness (MEN) and a 
genuine similarity (SimLex-999) dataset. 

aggregated visual representation-based metrics of 
CNN-MEAN and CNN-MAX, despite the fact 
that </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Spearman ρ s correlation for the visual 
similarity metrics on a relatedness (MEN) and 
a genuine similarity (SimLex-999) dataset using 
more than one layer from the CNN. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Average image dispersion for the 
datasets, by language. 

</table></figure>

			<note place="foot" n="2"> http://people.cs.kuleuven.be/˜ivan.vulic/software/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>DK is supported by EPSRC grant EP/I037512/1. IV is supported by the PARIS project (IWT-SBO 110067) and the PDM Kort postdoctoral fellow-ship from KU Leuven. SC is supported by ERC Starting Grant DisCoTex (306920) and EPSRC grant EP/I037512/1. We thank Marco Baroni for useful feedback and the anonymous reviewers for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A study on similarity and relatedness using distributional and WordNet-based approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><forename type="middle">B</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Kravalova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Soroa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Situating abstract concepts. In Grounding cognition: The role of perception and action in memory, language, and thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Barsalou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wiemer-Hastings</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="129" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Grounded cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">W</forename><surname>Barsalou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="617" to="645" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Computer Vision and Image Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><forename type="middle">J</forename><surname>Van Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="346" to="359" />
		</imprint>
	</monogr>
	<note>Speeded-up robust features (SURF)</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using visual information to predict lexical preference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randy</forename><surname>Goebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RANLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="399" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning bilingual lexicons using the visual similarity of labeled web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1764" to="1769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image classification using random forests and ferns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Muñoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multimodal distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam-Khanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artifical Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navneet</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Features for image retrieval: An experimental comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="107" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">TDNNextracted features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Driancourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neuro Nimes 90</title>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Visual information in semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning object categories from Google&apos;s image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1816" to="1823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Placing Search in Context: The Concept Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zach</forename><surname>Solan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gadi</forename><surname>Wolfman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="131" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Devise: A deep visualsemantic embedding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2121" to="2129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An IR approach for translating new words from nonparallel, comparable texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><surname>Lo Yuen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="414" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A geometric view on bilingual lexicon extraction from comparable corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Michel</forename><surname>Renders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Matveeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Déjean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="526" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning bilingual lexicons from monolingual corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="771" to="779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning abstract concept embeddings from multi-modal data: Since you probably can&apos;t see what I mean</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="255" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">SimLex-999: Evaluating semantic models with (genuine) similarity estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<idno>abs/1408.3456</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning image embeddings using convolutional neural networks for improved multi-modal semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improving multi-modal representations using image dispersion: Why less is sometimes more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="835" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multimodal neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="595" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning a translation lexicon from monolingual corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ULA&apos;02 Workshop</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
	<note>Hinton</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Philosophy in the flesh: The embodied mind and its challenge to Western thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Lakoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cross-lingual relevance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Choquette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="175" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Is this a wampimuk? Cross-modal mapping between distributional semantics and the visual world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1403" to="1414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Going beyond text: A hybrid image-text approach for measuring word relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Chee Wee Leong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1403" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Dictionary-based techniques for crosslanguage information retrieval. Information Processing &amp; Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gina-Anne</forename><surname>Levow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="523" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">Ward</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailash</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Pitler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Lathbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikram</forename><surname>Rao</surname></persName>
		</author>
		<title level="m">Kapil Dalwani, and Sushant Narsale. 2010. New tools for Web-scale N-grams. In LREC</title>
		<imprint>
			<biblScope unit="page" from="2221" to="2227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Topic models + word alignment = A flexible framework for extracting bilingual dictionary from comparable corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="212" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Symbol interdependency in symbolic and embodied cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><forename type="middle">M</forename><surname>Louwerse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Topics in Cognitive Science</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="617" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Polylingual topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanna</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="880" to="889" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A guided tour to approximate string matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gonzalo</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="88" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning and transferring mid-level image representations using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1717" to="1724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Automatic identification of word translations from unrelated English and German corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Rapp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">CNN features offthe-shelf: an astounding baseline for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sharif Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Azizpour</surname></persName>
		</author>
		<idno>abs/1403.6382</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Josephine Sullivan, and Stefan Carlsson</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A multimodal LDA model integrating textual, cognitive and visual modalities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1146" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Inducing translation lexicons via diverse similarity measures and bridge languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning semantic representations using convolutional neural networks for Web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="373" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Bilingual lexicon generation using non-aligned signatures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphna</forename><surname>Shezaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="98" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Grounded models of semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1423" to="1433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning grounded meaning representations with autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="721" to="732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Models of semantic representation with visual attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="572" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Video google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Grounded compositional semantics for finding and describing images with sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of ACL</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="207" to="218" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multimodal learning with deep Boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2949" to="2980" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Bilingual lexicon extraction from comparable corpora using label propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiro</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taro</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="24" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Labeling images with a computer game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Luis Von Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dabbish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="319" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Crosslingual semantic similarity of words as the similarity of their semantic word responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="106" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A study on bootstrapping bilingual vector spaces from nonparallel data (and nothing else)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1613" to="1624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Identifying word translations from comparable corpora using latent topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wim</forename><forename type="middle">De</forename><surname>Smet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="479" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Online multimodal deep similarity learning with application to image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peilin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<title level="m">Yoshua Bengio, and Hod Lipson. 2014. How transferable are features in deep neural networks? In NIPS</title>
		<imprint>
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
