<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:09+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Question Generation for Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Microsoft Research</orgName>
								<orgName type="institution" key="instit2">AI Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Microsoft Research</orgName>
								<orgName type="institution" key="instit2">AI Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Microsoft Research</orgName>
								<orgName type="institution" key="instit2">AI Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Microsoft Research</orgName>
								<orgName type="institution" key="instit2">AI Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Microsoft</forename><surname>Research</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Microsoft Research</orgName>
								<orgName type="institution" key="instit2">AI Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asia</forename></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Microsoft Research</orgName>
								<orgName type="institution" key="instit2">AI Group</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Question Generation for Question Answering</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="866" to="874"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents how to generate questions from given passages using neural networks, where large scale QA pairs are automatically crawled and processed from Community-QA website, and used as training data. The contribution of the paper is 2-fold: First, two types of question generation approaches are proposed, one is a retrieval-based method using convo-lution neural network (CNN), the other is a generation-based method using recurrent neural network (RNN); Second, we show how to leverage the generated questions to improve existing question answering systems. We evaluate our question generation method for the answer sentence selection task on three benchmark datasets, including SQuAD, MS MARCO, and WikiQA. Experimental results show that, by using generated questions as an extra signal, significant QA improvement can be achieved.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question Answering (or QA) is one of the core problems for AI, and consists of several typical tasks, i.e. community-based QA ( <ref type="bibr" target="#b12">Qiu and Huang, 2015)</ref>, knowledge-based QA ( <ref type="bibr" target="#b1">Berant et al., 2013</ref>), text-based QA ( <ref type="bibr" target="#b24">Yu et al., 2014)</ref>, and reading com- prehension ( <ref type="bibr" target="#b13">Rajpurkar et al., 2016</ref>). Most of cur- rent QA systems, e.g. <ref type="bibr" target="#b2">(Berant and Liang, 2014)</ref>, ( <ref type="bibr" target="#b12">Qiu and Huang, 2015)</ref>, <ref type="bibr" target="#b18">(Xiong et al., 2017)</ref>, <ref type="bibr" target="#b22">(Yin and Schtze, 2017)</ref>, need labeled QA pairs as train- ing data. Although labeling efforts have been made, such as WebQuestions dataset <ref type="bibr" target="#b1">(Berant et al., 2013)</ref> and SimpleQuestions dataset ( <ref type="bibr" target="#b3">Bordes et al., 2015</ref>) for knowledge-based QA, WikiQA dataset ( <ref type="bibr" target="#b20">Yang et al., 2015</ref>) for text-based QA, SQuAD dataset ( <ref type="bibr" target="#b13">Rajpurkar et al., 2016)</ref> and MS MARCO dataset ( <ref type="bibr" target="#b10">Nguyen et al., 2016</ref>) for reading compre- hension, these datasets are still with limited sizes, as labeling is very expensive.</p><p>Motivated by this, we explore how to generate questions from given passages using neural net- works, with three expected goals: (1) the training data should need few or no human efforts and re- flect commonly-asked question intentions; (2) the questions are generated based on natural language passages, and should have good quality; (3) the generated questions should be helpful to QA tasks.</p><p>To achieve the 1 st goal, we propose to ac- quire large scale high-quality training data from Community-QA (CQA) website. The motivation of using CQA website for training data collection is that, such websites (e.g., YahooAnswers, Quo- ra, etc.) contain large scale QA pairs generated by real users, and these questions reflect the most common user intentions, and therefore are useful to search, QA, and chatbot scenarios.</p><p>To achieve the 2 nd goal, we explore two ways to generate questions for a given passage, one is a retrieval-based method using convolution neural network (CNN), the other is a generation-based method using recurrent neural network (RNN). We evaluate the generation quality by BLEU score ( <ref type="bibr" target="#b11">Papineni et al., 2002</ref>) and human annotations, and discuss their pros and cons in Section 9.</p><p>To achieve the 3 rd goal, we integrate our ques- tion generation approach into an end-to-end QA task, i.e., answer sentence selection, and evaluate its impact on three popular benchmark datasets, SQuAD, MS MARCO, and WikiQA. Experimen- tal results show that, the generated questions can improve the QA quality on all these three datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Question Generation</head><p>Formally, given a passage S, question generation (QG) engine generates a set of questions {Q i }, where each generated Q i can be answered by S. There are four components in our QG engine:</p><p>1. Question Pattern Mining, which extracts the frequently-asked question patterns from large scale CQA questions, without any human an- notation effort;</p><p>2. Question Pattern Prediction, which predicts top-N question patterns Q 1 p , ..., Q N p given S, by a retrieval-based method or a generation- based method. Therefore, "Prediction" has two different meanings here: in retrieval- based method, it means to rank existing ques- tion patterns and select the highest ranked ones, while in generation-based method, it means to generate question patterns based on S in a sequence-to-sequence manner, each of which could be a totally new question pattern beyond the existing question pattern set;</p><p>3. Question Topic Selection, which selects a phrase Q t from S as the question topic, based on a predicted question pattern Q p . Q t will be filled into Q p to form a complete question;</p><p>4. Question Ranking, which ranks all generated questions by a set of features. Here, multiple questions with different intentions could be generated, as S could contain multiple facts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Question Pattern Mining</head><p>A question pattern (or QP) is defined as a word se- quence Q p = {w 1 , w 2 , ..., w L }. Each QP should contain one and only one special word "#" as the placeholder, and all the other L − 1 words are ter- minal words. For example, "who founded # ?" is a question pattern, and "#" denotes the placeholder, which could be an organization name. We gener- ate questions only using frequently-asked question patterns, where "frequently-asked" denotes that each question pattern should be extracted from a large scale question set more than T times, where T denotes a pre-defined threshold.</p><p>In this paper, a question cluster (or QC) based approach is proposed to mine frequently-asked question patterns from large scale CQA questions.</p><p>First, a set of question clusters is collected from CQA webpages, and each question cluster consists of questions that are grouped as related question- s 1 by the CQA website. For example, when the query "what is the population of nyc" is issued to YahooAnswers 2 , the returned page contains a list of related questions including "population of nyc", "nyc population", "nyc census", and etc.</p><p>Second, for each question cluster QC = {Q 1 , ..., Q K }, we enumerate all valid continuous n-grams, each of which should contain at least one content word and its order should be equal or less then 7, as question topic candidates {Q 1 t , ..., Q M t }. We then assign an importance score Impts(·) to each question topic candidate Q m t :</p><formula xml:id="formula_0">Impts(Q m t ) = Q k ∈QC δ(Q m t , Q k ) · |Q m t |</formula><p>Q m t denotes the m th question topic candidate, δ(Q m t , Q k ) equals to 1 when Q m t occurs in Q k , and 0 otherwise, |Q m t | denotes Q m t 's word count, which boosts longer question topic candidates.</p><p>For each QC, we select Q t with the highest im- portance score as the question topic, and remove it from each question to form a question pattern. We call each removed question topic as a histor- ical question topic of its corresponding question pattern. If Q t doesn't exist in a question, ignore it.</p><p>Mining question patterns based on question clusters is motivated by the observation that, all questions within a QC tend to ask questions about an identical "question topic" (e.g., nyc in the above example) from different aspects, or the same as- pect but using different expressions. Thus, we can leverage the consensus information among ques- tions to detect the boundary of the question topic: the more times an n-gram occurs in different ques- tions within a question cluster, the more likely it is the question topic of the current question cluster.</p><p>Although the question pattern mining approach described above is simple, it works surprisingly well. <ref type="table" target="#tab_0">Table 1</ref> shows statistics of question patterns mined from YahooAnswers, and <ref type="figure" target="#fig_0">Figure 1</ref> gives ex- amples of frequently-asked question patterns with their corresponding historical question topics. We have two interesting observations:</p><p>1. Most frequently-asked question patterns (fre- quency &gt;=10,000) are with high quality, and reflect the most common user intentions;</p><p>2. Most historical question topics extracted are entities. This is achieved without using any prior semantic knowledge base or dictionary.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Question Pattern Prediction</head><p>Given a passage S, question pattern prediction predicts S's most related question patterns, and then use them to generate questions. For exam- ple, given S as "Tesla Motors is an American au- tomaker and energy storage company co-founded by Elon Musk, Martin Eberhard, Marc Tarpen- ning, JB Straubel and Ian Wright, and is based in Palo Alto.", two question patterns can be derived from S, including: (1) who founded # ?, which can be inferred by the context around "co-founded by", and <ref type="formula">(2)</ref> where is # located ?, which can be in- ferred by the context around "is based in". Based on these two question patterns, we can generate t- wo questions, "who founded Tesla Motors ?" and "where is Tesla Motors located ?" respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training Data Construction</head><p>We collect QA pairs from YahooAnswers. For each QA pair &lt; Q, A &gt;, if (1) Q can be matched by a frequently-asked question pattern Q p , and (2) the matched question topic Q t of Q based on Q p exists in A, then we create a training instance as &lt; A, Q p , Q t &gt;. Q t ∈ A makes sure that the ques- tion topic occurs in both Q and A. If the matched question topic only exists in Q, we just discard it. By doing so, we collect a total of 1,984,401 train- ing instances as training data for QP prediction. Two neural network-based question pattern pre- diction approaches are explored in this paper:</p><p>• Retrieval-based QP Prediction, which con- siders QP prediction as a ranking task;</p><p>• Generation-based QP Prediction, which con- siders QP prediction as a generation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Retrieval-based QP Prediction</head><p>The retrieval-based QP prediction is done based on an attention-based convolution neural network. It takes a passage and a question pattern as input, and outputs their corresponding vector representa- tions. We denote each input pair as S, Q p , where S is a passage, and Q p is a question pattern.</p><p>In the input layer, given an input pair S, Q p , an attention matrix Att ∈ |S|×|Qp| is generat- ed by pre-trained word embeddings of S and Q p , where each element Att i,j ∈ Att is computed as:</p><formula xml:id="formula_1">Att i,j = cosine(v S i , v Qp j )</formula><p>where v S i (or v Qp j ) denotes the embedding vector of the i th (or j th ) word in S (or Q p ).</p><p>Then, column-wise and row-wise max-pooling are applied to Att to generate two attention vec- tors V S ∈ |S| and V Qp ∈ |Qp| , where the k th elements of V S and V Qp are computed as:</p><formula xml:id="formula_2">V S k = max 1&lt;l&lt;|Qp| {Att k,l } and V Qp k = max 1&lt;l&lt;|S| {Att l,k } V S k (or V Qp k )</formula><p>can be interpreted as the attention score of the k th word in S (or Q p ) with regard to all words in Q p (or S).</p><p>Next, two attention distributions D S ∈ |S| and D Qp ∈ |Qp| are generated for S and Q p based on V S and V Qp respectively, where the k th elements of D S and D Qp are computed as:</p><formula xml:id="formula_3">D S k = e V S k |S| l=1 e V S l and D S Y k = e V Qp k |Qp| l=1 e V Qp l D S X k (or D S Y</formula><p>k ) can be interpreted as the normal- ized attention score of the k th word in S (or Q p ) with regard to all words in Q p (or S).</p><p>Last, we update each pre-trained word embed- <ref type="bibr">k</ref> ). The underlying intuition of updating pre-trained word embeddings is to re-weight the importance of each word in S (or Q p ) based on Q p (or S), instead of treating them in an equal manner.</p><formula xml:id="formula_4">ding v S k (or v Qp k ) tô v S k (orˆvorˆ orˆv Qp k ), by multiplying every value in v S k (or v Qp k ) with D S k (or D Qp</formula><p>In the convolution layer, we first derive an in- put matrix Z S = {l 1 , ..., l |S| }, where l t is the con- catenation of a sequence of</p><formula xml:id="formula_5">m = 2d − 1 3 updat- ed word embeddings [ˆ v S t−d , ..., ˆ v S t , ..., ˆ v S t+d ]</formula><p>, cen- tralized in the t th word in S. Then, the convo- lution layer performs sliding window-based fea- ture extraction to project each vector representa- tion l t ∈ Z S to a contextual feature vector h S t :</p><formula xml:id="formula_6">h S t = tanh(W c · l t )</formula><p>where W c is the convolution matrix, tanh(</p><formula xml:id="formula_7">x) = 1−e −2x 1+e −2x</formula><p>is the activation function. The same oper- ation is performed to Q p as well.</p><p>In the pooling layer, we aggregate local fea- tures extracted by the convolution layer from S, and form a sentence-level global feature vector with a fixed size independent of the length of the input sentence. Here, max-pooling is used to force the network to retain the most useful local features by</p><formula xml:id="formula_8">l S p = [v S 1 , ..., v S K ]</formula><p>, where:</p><formula xml:id="formula_9">v S i = max t=1,...,|S| {h S t (i)}</formula><p>h S t (i) denotes the i th value in the vector h S t . The same operation are performed to Q p as well.</p><p>In the output layer, one more non-linear trans- formation is applied to l S p :</p><formula xml:id="formula_10">y(S) = tanh(W s · l S p )</formula><p>W s is the semantic projection matrix, y(S) is the final sentence embedding of S. The same opera- tion is performed to Q p to obtain y(Q p ).</p><p>We train model parameters W c and W s by min- imizing the following ranking loss function:</p><formula xml:id="formula_11">L = max{0, M − cosine(y(S), y(Q p )) +cosine(y(S), y(Q − p ))}</formula><p>where M is a constant, Q − p is a negative instance. <ref type="bibr">3</ref> In this paper, m is set to 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Generation-based QP Prediction</head><p>The generation-based QP prediction is done based on an sequence-to-sequence BiGRU ( <ref type="bibr" target="#b0">Bahdanau et al., 2015</ref>) that is commonly used in the neural machine translation field. The encoder reads a word sequence of an input passage S = (x 1 , ..., x |S| ), and the decoder pre- dicts a word sequence of an output question pat- tern Q p = (y 1 , ..., y |Qt| ). The probability of gen- erating a question pattern Q p is computed as:</p><formula xml:id="formula_12">p(Q p ) = |Qp| i=1 p(y i |y 1 , ..., y i−1 , c i )</formula><p>where each conditional probability is defined as:</p><formula xml:id="formula_13">p(y i |y 1 , ..., y i−1 , c i ) = g(y i−1 , s i , c i )</formula><p>g(·) denotes a nonlinear function that outputs the probability of generating y i . s i denotes the hidden state of time t in decoder, which is computed as:</p><formula xml:id="formula_14">s i = (1 − z i ) • s i−1 + z i • ˜ s i where˜s where˜ where˜s i = tanh(W E y i−1 + U [r i • s i−1 ] + Cc i ) z i = δ(W z E y i−1 + U z s i−1 + C z c i ) r i = δ(W r E y i−1 + U r s i−1 + C r c i ) δ(·)</formula><p>is the sigmoid function, • represents element- wise multiplication, E w ∈ m×1 denotes the word embedding of a word w, W , W z , W r ∈ n×m , U , U z , U r ∈ n×n , and C, C z , C r ∈ n×2n are weights. c i denotes the context vector, which is computed as:</p><formula xml:id="formula_15">c i = |S| j=1 α ij h j where α ij = exp(e ij ) |S| k=1 exp(e ik ) e ij = v T a tanh(W a s i−1 + U a h j )</formula><p>v a ∈ n , W a ∈ n ×n , and U a ∈ n ×2n are weights. h j denotes the j th hidden state from en- coder, which is the concatenation of the forward hidden state − → h j and the back forward state ← − h j .</p><p>For training, stochastic gradient descent (SGD) algorithm is used, and Adadelta <ref type="bibr" target="#b25">(Zeiler, 2012</ref>) is used to adapt the learning rate of each parameter. Given a batch of D = {&lt; S, Q p &gt;} M i=1 pairs with size M instances, the objective function is to min- imize the negative log-likelihood:</p><formula xml:id="formula_16">L = − 1 M &lt;S,Qp&gt; T t=1</formula><p>log(p(y t |y &lt;t , S))</p><p>For prediction, beam search is used to output the top-N question pattern predictions.</p><p>Retrieval-based approach can only find existing question patterns for each passage, but it makes sure that each question pattern comes from re- al questions and is in a good grammatical form; Generation-based approach, on the other hand, can generate totally new question patterns beyond ex- isting question pattern set. We will compare both of them in the experimental part (Section 8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Question Topic Selection</head><p>Given a passage S and a predicted question pattern Q p , question topic selection selects an n-gram (or a phrase) Q t from S, which can be then filled into Q p to form a complete question. Since we have two question pattern prediction methods, we have two ways to select the question topic Q t as well.</p><p>For Q p from retrieval-based method, two types of prior knowledge are used to extract ques- tion topic candidates from S, including:</p><p>• Entities as question topic candidates, which are detected based on Freebase 4 entities;</p><p>• Noun phrases as question topic candidates, which are detected based on the Stanford parser ( <ref type="bibr" target="#b7">Klein and Manning, 2003)</ref>.</p><p>Once a question topic candidate Q t is extracted from S, we then measure how Q t can fit Q p by:</p><formula xml:id="formula_17">s(Q t , Q p ) = 1 N · k #(Q t k p ) · dist(v Qt , v Q t k p )</formula><p>s(Q t , Q p ) denotes the confidence that Q t can be filled into Q p to generate a reasonable question. Q t k p denotes the k th historical question topic of Q p . #(Q t k p ) denotes the number of times that Q t k p is extracted from different question clusters to generate Q p . v p denotes the question topic em- bedding of p, which is computed as the average of word embeddings in p. dist(·) denotes the cosine distance between two question topic embeddings. N = k #(Q t k p ) denotes the total number of his- torical question topics of Q p . The basic principle of the above equation is that, the historical ques- tion topics of a given question pattern can help on measuring how possible a question topic can- didate can be filled into this question pattern to form a reasonable question. For example, as most historical question topics of "who founded # ?" are organization names, then it is very unlikely a date or a film name is suitable for this question pattern to generate a reasonable question.</p><p>For Q p from generation-based method, sup- pose the placeholder # is the i th word in Q p , then we select the j th word w j ∈ S as the question topic, which satisfies the following constraint:</p><formula xml:id="formula_18">w j = arg max w j ∈S α ij = arg max w j ∈S exp(e ij ) |S| k=1 exp(e ik )</formula><p>This question topic selection strategy leverages the attention scores between S and Q p , and can be considered as a COPY mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Question Ranking</head><p>Given a predicted question pattern Q p and a se- lected question topic Q t of an input passage S, a complete question Q can be simply generated by replacing # in Q p with Q t . We use a set of fea- tures to rank generated question candidates:</p><p>• question pattern prediction score, which is the prediction score by either retrieval-based approach or generation-based approach;</p><p>• question topic selection score, for retrieval- based approach, this score is computed as s(Q t , Q p ), while for generation-based ap- proach, this score is the attention score;</p><p>• QA matching score, which measures rele- vance between generated question Q and S.</p><p>• word overlap between Q and S, which counts number of words that co-occur in Q and S;</p><p>• question pattern frequency, which equals to the extraction frequency of Q p , if Q is gener- ated from or matched by Q p , and 0 otherwise.</p><p>All features are combined by a linear model as:</p><formula xml:id="formula_19">p(Q|S) = i λ i · h i (Q, S, Q p , Q t )</formula><p>where h i (Q, S, Q p , Q t ) is one of the features de- scribed above, and λ i is the corresponding weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Question Generation for QA</head><p>This section describes how question generation can improve existing QA systems. There are sev- eral types of QA systems, i.e. knowledge-based QA, community-based QA, text-based QA, etc, and in this paper, we focus on text-based QA task (a.k.a. answer sentence selection), which aims to select one or multiple answer sentences from a tex- t given an input question. We select this task as it can be considered as a dual task of QG. A typical answer sentence selection method, such as ( <ref type="bibr" target="#b23">Yin et al., 2016;</ref><ref type="bibr" target="#b14">Santos et al., 2016;</ref><ref type="bibr" target="#b9">Miller et al., 2016;</ref><ref type="bibr" target="#b17">Tymoshenko et al., 2016)</ref>, computes the relevance score between input question Q and each answer candidate A, and selects the one with the highest relevance score as the final answer:</p><formula xml:id="formula_20">A = arg max A P (A|Q)</formula><p>Motivated by Dual Learning <ref type="figure" target="#fig_0">(He et al., 2016)</ref>, we integrate question generation into answer rank- ing procedure, by changing the above formula to:</p><formula xml:id="formula_21">A = arg max A {P (A|Q) + λ · QQ(Q, Q gen max )}</formula><p>λ is hyper-parameter, and in order to com- pute QQ(Q, Q gen max ), we generate top-10 questions {Q gen 1 , ..., Q gen 10 } for current answer candidate A, and then compute the question-to-generated ques- tion matching score QQ(Q, Q gen max ), by computing the similarity between input question Q and gen- erated questions {Q gen 1 , ..., Q gen 10 } as:</p><formula xml:id="formula_22">QQ(Q, Q gen max ) = arg max i=1,...,10 sim(Q, Q gen i ) · p(Q gen i ) sim(Q, Q gen i )</formula><p>is the similarity between the input question Q and the i th generated question Q gen i , and computed as the cosine distance between av- eraged word embedding of Q and averaged word embedding of Q gen i , p(Q gen i ) denotes the posterior probability that is computed based on the genera- tion score of each generated question:</p><formula xml:id="formula_23">p(Q gen i ) = p(Q gen i |A) 10 i =1 p(Q gen i |A) p(Q gen i |A)</formula><p>is output by the question generation model described in Section 6. The underlying motivation is that, the questions generated from correct answers are more likely to be similar to labeled questions than questions generated from wrong answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related Work</head><p>Yao et al. <ref type="formula">(2012)</ref> proposed a semantic-based ques- tion generation approach, which first parses the in- put sentence into its corresponding Minimal Re- cursion Semantics (MRS) representation, and then generates a question guided by the English Re- source Grammar that includes a large scale hand- crafted lexicon and grammar rules. <ref type="bibr" target="#b8">Labutov et al. (2015)</ref> proposed an 'ontology- crowd-relevance' method for question genera- tion. First, Freebase types and Wikipedia session names are used as semantic tags to understand texts. Question are then generated based on ques- tion templates that are aligned with types/session names and labeled by crowdsourcing. All gener- ated questions are ranked by a relevance model. <ref type="bibr" target="#b4">Chali and Hasan (2015)</ref> proposed a topic-to- question method, which uses about 350 general- purpose rules to transform the semantic-role la- beled sentences into corresponding questions. <ref type="bibr" target="#b15">Serban et al. (2016)</ref> used the encoder-decoder framework to generate 30M QA pairs, but their in- puts are knowledge triples, instead of passages.</p><p>Song and Zhao <ref type="formula">(2016)</ref> proposed a question gen- eration method using question template seeds and used search engine to do question expansion. <ref type="bibr" target="#b5">Du et al. (2017)</ref> proposed a neural question generation method using a vanilla sequence-to- sequence RNN model, which is most-related to our work. But this method is still based on labeled dataset, and tried RNN only.</p><p>Comparing to all these related work mentioned above, our question generation approach has two uniqueness: (1) all question patterns, that are used as training data for question generation, are auto- matically extracted from a large scale CQA ques- tion set without any crowdsourcing effort. Such question patterns reflect the most common user in- tentions, and therefore are useful to search, QA, and chatbot engines; (2) it is also the first time question generation is integrated and evaluated in an end-to-end QA task directly, and shows signifi- cant improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Dataset</head><p>As described in Section 4.1, we collect 1, 984, 401 &lt; A, Q p , Q t &gt; pairs from YahooAnswers, and use them as the training set of the question pat- tern prediction model. We re-use the dev sets and test sets of SQuAD, MS MARCO, and WikiQA, to evaluate the quality of generated questions. The dataset statistics are in <ref type="table" target="#tab_2">Table 2</ref>  Besides, an answer sentence selection model ( <ref type="bibr" target="#b23">Yin et al., 2016</ref>) is trained based on the 1,984,401 QA pairs from the training set as well, and used to compute the QA matching score for question rank- ing, as we described in Section 6. Feature weights for question ranking are optimized on dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Evaluation on Question Generation</head><p>We first perform a vanilla sequence-to-sequence method ( <ref type="bibr" target="#b5">Du et al., 2017</ref>) using the original training sets of these three datasets, and show QG results in  <ref type="table" target="#tab_3">Table 3</ref>: QG results using original training sets.</p><p>We then evaluate the quality of the generated questions based on auto-extracted training set. For each passage in the test set, we generate two top- 1 questions based on retrieval-based method and generation-based method respectively, and then compare them with labeled questions using BLEU 4 as the metric. Results are listed in  <ref type="table" target="#tab_4">Table 4</ref>: QG results using auto-extracted training set, where R-QG denotes results from Retrieval- based QG method, G-QG denotes results from Generation-based QG method.</p><p>From <ref type="table" target="#tab_3">Table 3</ref> and 4 we can see two findings: (1) Comparing to QG results based on original la- beled training sets, G-QG achieves comparable or better results. We think this is due to two fact- s: first, the size of the automatically constructed training set is much larger than the labeled train- ing sets, and second, as the QA pairs from CQA websites are generated by real users, the quality is good. (2) Generation-based QG performs bet- ter than Retrieval-based QG. By analyzing outputs we find that, for question pattern prediction, both retrieval-based and generation-based methods per- form similarly. However, Generation-based QG performs better than Retrieval-based QG on ques- tion topic selection. This could be caused by the fact that, in Generation-based QG, question top- ic selection is based on the attention mechanis- m, which is optimized together with question pat- tern prediction in an end-to-end way; while in Retrieval-based QG, question topic selection is a separate task, and based on the similarity between each question topic candidate and historical ques- tion topics of a given question pattern. The embed- ding of each question topic is pre-trained, which is not directly related to the question generation task. So such method cannot handle unseen ques- tion topics very well. Another disadvantage of Retrieval-based QG is that, each time, we have to compute the similarity between the input passage and each question pattern. When question pattern size is large, the computation is very expensive.</p><p>In order to better understand the question gener- ation quality, we manually check a set of sampled outputs, and list the main errors in <ref type="figure" target="#fig_1">Figure 2</ref>:</p><p>• Multi-Fact Error (40%). Most input pas- sages include more than one fact. For such a question, it is reasonable to generate different questions from different aspects, all of which can be answered by the input passage. For each passage in QAGen, we only label one question as ground truth. In the future, we will extend QAGen to be a more comprehen- sive dataset, by labeling multiple questions to each passage for more reasonable evaluation;</p><p>• Paraphrase Error (30%). The same question can be expressed by different ways. Labeling more paraphrased questions for a passage can alleviate this issue as well;</p><p>• Question Topic Selection Error (15%). This error is caused by selecting either a total- ly wrong question topic, or a partially right question topic. In the future, we plan to de- velop an independent question topic selection model for the question generation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Evaluation on QA</head><p>As described in Section 7, we combine question generation into QA system for answer sentence s- election task, and do evaluation on SQuAD, M- S MARCO, and WikiQA. Evaluation results are shown in <ref type="table" target="#tab_5">Table 5</ref>   <ref type="table">Table 6</ref>: Impact of QG on MS MARCO.</p><p>The improvement on MS MARCO dataset is most significant. We think it due to the fact that, the questions from MS MARCO dataset are from Bing search log, which are generated naturally by real users. This is similar to the questions coming WikiQA MAP MRR ACC@1 QA 0.7703 0.7851 0.6540 QA+QG 0.7742 0.7893 0.6624 <ref type="table">Table 7</ref>: Impact of QG on WikiQA.</p><p>for CQA websites; while questions from the other datasets are labeled by crowd-sourcing.</p><p>In order to explain these improvements, two datasets, WikiQG+ and WikiQG-, are built from WikiQA test set: given each document and its la- beled question, we pair the question with its COR- RECT answer sentence as a QA pair and add it to WikiQG+; we also pair the same question with a randomly selected WRONG answer sentence as a QA pair and add it to WikiQG-. Then, we generate questions for passages in WikiQG+ and WikiQG- respectively, and compare them with labeled ques- tions. The BLEU 4 score is 0.2031 on Wik- iQG+, and 0.1301 on WikiQG-, which indicates that the questions generated from correct answers are more likely to be similar to labeled questions than questions generated from wrong answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conslusion</head><p>This paper presents a neural question generation method that is based on training data collected from CQA questions. We integrate the QA pair generation task into an end-to-end QA task, and show significant improvements, which indicates that, QA task and QG are dual tasks that can boost each other. In the future, we will explore more ways to leverage QG for QA task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of frequently-asked question patterns with corresponding historical question topics.</figDesc><graphic url="image-1.png" coords="3,72.00,63.80,453.59,130.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: List of error analysis examples. [P] denotes a passage, [Ref] denotes the labeled question of the passage, and [Gen] denotes the generated question of the passage.</figDesc><graphic url="image-2.png" coords="8,72.00,63.80,453.59,172.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>, 6 ,</head><label>6</label><figDesc>and 7, where QA denotes the result of our in-house implementation of a retrieval-based answer selection approach (Doc- Chat) proposed by (Yan et al., 2016), QA+QG de- notes result by combining question-to-generated question matching score with DocChat score. SQuAD MAP MRR ACC@1 QA 0.8843 0.8915 0.8160 QA+QG 0.8887 0.8963 0.8232</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Statistics of question patterns mined from 
YahooAnswers, where QC denotes Question Clus-
ter and QP denotes Question Pattern. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>.</head><label></label><figDesc></figDesc><table># of QA Pairs 
training set 
1,984,401 
dev set (SQuAD) 
26,442 
test set (SQuAD) 
26,604 
dev set (MS MARCO) 
39,510 
test set (MS MARCO) 
42,850 
dev set (WikiQA) 
2,733 
test set (WikiQA) 
6,165 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Dataset Statistics.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 , where BLEU 4 score is used as the metric.</head><label>3</label><figDesc></figDesc><table>BLEU 4 
Seq2Seq-QG 
SQuAD 
12.28 
MS MARCO 
10.46 
WikiQA 
2.04 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table>BLEU 4 
R-QG G-QG 
SQuAD (crawled) 
9.87 
12.39 
MS MARCO (crawled) 9.86 
11.46 
WikiQA (crawled) 
11.38 13.57 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 5 : Impact of QG on SQuAD.</head><label>5</label><figDesc></figDesc><table>MS MARCO MAP 
MRR ACC@1 
QA 
0.5131 0.5195 0.3029 
QA+QG 
0.5230 0.5291 0.3153 

</table></figure>

			<note place="foot" n="1"> Usually, each question page of a CQA website contains a field that shows a list of related questions.</note>

			<note place="foot" n="2"> https://answers.yahoo.com/</note>

			<note place="foot" n="4"> https://developers.google.com/freebase/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>In arXiv</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Towards topic-toquestion generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yllias</forename><surname>Chali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadid</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to ask: Neural question generation for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junru</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dual learning for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep questions without deep understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirhossein</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ms marco: A human generated machine reading comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convolutional neural tensor network architecture for community based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Attentive pooling networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In arXiv</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generating factoid questionswith recurrent neural networks: The 30m factoid question-answer corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Garca-Durn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Domain-specific question generation from a knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">arXiv</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Convolutional neural networks vs. convolution kernels: Feature engineering for answer sentence reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Bonadiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dynamic coattention networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Docchat: An information retrieval approach for chatbot engines using unstructured documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshe</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Wikiqa: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantics-based question generation and implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gosse</forename><surname>Bouma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dialogue and Discourse</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Task-specific attentive pooling of phrase alignments contributes to sentence matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schtze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Abcnn: Attention-based convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Wenpeng Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Schtze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep learning for answer sentence selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Morizt</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Pulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adadelta: an adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Zeiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoRR abs</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
