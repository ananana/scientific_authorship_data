<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:30+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">XL-NBT: A Cross-lingual Neural Belief Tracking Framework</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<settlement>Bellevue</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
							<email>jianshuchen@tencent.com, dongyu@ieee.org</email>
							<affiliation key="aff2">
								<orgName type="institution">The Ohio State University</orgName>
								<address>
									<settlement>Columbus</settlement>
									<region>Ohio</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Su</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<settlement>Bellevue</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">The Ohio State University</orgName>
								<address>
									<settlement>Columbus</settlement>
									<region>Ohio</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<settlement>Bellevue</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<settlement>Bellevue</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Barbara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">XL-NBT: A Cross-lingual Neural Belief Tracking Framework</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="414" to="424"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>414</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Task-oriented dialog systems are becoming pervasive, and many companies heavily rely on them to complement human agents for customer service in call centers. With globalization , the need for providing cross-lingual customer support becomes more urgent than ever. However, cross-lingual support poses great challenges-it requires a large amount of additional annotated data from native speakers. In order to bypass the expensive human annotation and achieve the first step towards the ultimate goal of building a universal dialog system, we set out to build a cross-lingual state tracking framework. Specifically, we assume that there exists a source language with dialog belief tracking annotations while the target languages have no annotated dialog data of any form. Then, we pre-train a state tracker for the source language as a teacher, which is able to exploit easy-to-access parallel data. We then distill and transfer its own knowledge to the student state tracker in target languages. We specifically discuss two types of common parallel resources: bilingual corpus and bilingual dictionary, and design different transfer learning strategies accordingly. Experimentally , we successfully use English state tracker as the teacher to transfer its knowledge to both Italian and German trackers and achieve promising results.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the past few years, we have witnessed the burgeoning of real-world applications of dialog systems, with many academic, industrial, and startup efforts racing to lead the widely-believed next-generation human-machine interfaces. As a result, numerous task-oriented dialog systems such as virtual assistants and customer conversa- tion services were developed <ref type="bibr" target="#b20">Rojas-Barahona et al., 2017;</ref><ref type="bibr" target="#b0">Bordes and Weston, 2017;</ref><ref type="bibr" target="#b23">Williams et al., 2017;</ref><ref type="bibr" target="#b7">Li et al., 2017)</ref>, with Google Duplexbeing the most recent example.</p><p>With the rapid process of globalization, more countries have observed growing populations of immigrants, and more companies have moved for- ward to develop their overseas business sectors. To provide better customer service and bring down the cost of labor at call centers, the development of universal dialog systems has become a practi- cal issue. A straightforward strategy is to sepa- rately collect training data and train dialog sys- tems for each language. However, it is not only tedious but also expensive. Two settings naturally arise for more efficient usage of the training data: (1) Multi-lingual setting: we annotate data for multiple languages and train a single model, with possible innovations on joint training. (2) Cross- lingual setting: we annotate data and train a model for only one (popular) language, and transfer the learned knowledge to other languages. Here we are interested in the second case, and the impor- tant research question we ask is: How can we build cross-lingual dialog systems that can support less popular, low-or even zero-resource languages?</p><p>As an initial step towards cross-lingual dialog systems, we focus on the cornerstone of dialog systems -dialog state tracking (DST), or belief tracking, a key component for understanding user inputs and updating belief state, i.e., a system's in- ternal representation of the state of conversation ( <ref type="bibr" target="#b25">Young et al., 2010</ref>). Based on the perceived belief state, the dialog manager can decide which action to take, and what verbal response to generate <ref type="bibr">(Precup and Teh, 2017;</ref><ref type="bibr" target="#b0">Bordes and Weston, 2017)</ref>.</p><p>DST models require a considerable amount of annotated data for training <ref type="bibr" target="#b3">(Henderson et al., 2014b;</ref>). For a common dialog shown in <ref type="figure">Figure 1</ref>, a typical data acquisition process (Rojas- <ref type="bibr" target="#b20">Barahona et al., 2017</ref>) not only re- quires two human users to converse for multiple turns but also requires annotators to identify user's intention in each turn. Such two-step annotation is very expensive, especially for rare languages.</p><p>We study the novel problem of cross-lingual DST, where one leverages the annotated data of a source language to train DST for a target lan- guage with zero annotated data ( <ref type="figure">Figure 1)</ref>; no con- versation dialog or dialog state annotation is avail- able for the target language. In order to deal with this zero-resource challenging scenario, we first decouple the state-of-the-art neural belief tracker framework ( ) into sub-modules, namely utterance encoder, context gate, and slot- value decoder. By introducing a teacher-student framework, we are able to transfer knowledge across languages module by module, following the divide-and-conquer philosophy. Requiring no target-side dialog data, our method relies on other easy-to-access parallel resources to understand the connection between languages. Depending on the popularity and availability of target language re- sources, we study two kinds of parallel data: bilin- gual corpus and bilingual dictionary, and we re- spectively design two transfer learning strategies.</p><p>We use the popular Wizard-of-Oz (Rojas- <ref type="bibr" target="#b20">Barahona et al., 2017</ref>) dataset as our DST bench- mark to evaluate the effectiveness of our cross- lingual transfer learning. We specify English as the source (primary) language and two different European languages (German and Italian) as our zero-annotation target languages. Compared with an array of alternative transfer learning strate- gies, our cross-lingual DST models consistently achieve promising results in both scenarios for both zero-annotation languages. To ensure repro- ducibility, we release our code, training data and parallel resources in the github 1 . Our main contri- butions are three-fold:</p><p>• Towards building cross-lingual dialog sys- tems, we are the first to study the cross- lingual dialog state tracking problem.</p><p>• We systematically study different scenarios for this problem based on the availability of parallel data and propose novel transfer learn- ing methods to tackle the problem.</p><p>• We empirically demonstrate the efficacy of the proposed methods, showing that our methods can accurately track dialog states for 1 https://github.com/wenhuchen/ Cross-Lingual-NBT languages with zero annotated data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dialog State Tracking</head><p>Broadly speaking, the dialog belief tracking al- gorithms can be divided into three families: 1) hand-crafted rules 2) generative models, and 3) maximum-entropy model ( <ref type="bibr" target="#b9">Metallinou et al., 2013)</ref>. Later on, many deep learning based dis- criminative models have surged to replace the traditional strategies ( <ref type="bibr" target="#b2">Henderson et al., 2014a;</ref><ref type="bibr" target="#b22">Williams et al., 2016)</ref> and achieved state-of-the-art results on various datasets. Though the discriminative models are re- ported to achieve fairly high accuracy, their appli- cations are heavily restricted by the domain, on- tology, and language. Recently, a pointer network based algorithm ( <ref type="bibr" target="#b24">Xu and Hu, 2018)</ref> and another multi-domain algorithm ( <ref type="bibr" target="#b19">Rastogi et al., 2017)</ref> have been proposed to break the ontology and domain boundary. Besides, <ref type="bibr" target="#b13">(Mrkši´Mrkši´c et al., 2017)</ref> has proposed an algorithm to train a unified frame- work to deal with multiple languages with anno- tated datasets. In contrast, our paper focuses on breaking the language boundary and transfer DST knowledge from one language into other zero- annotation languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cross-Lingual Transfer Learning</head><p>Cross-lingual transfer learning has been a very popular topic during the years, which can be seen as a transductive process. In such process, the in- put domains of the source and target are differ- ent <ref type="bibr" target="#b15">(Pan and Yang, 2010)</ref> since each language has its own distinct lexicon. By discovering the un- derlying connections between the source and tar- get domain, we could design transfer algorithms for different tasks. Recently, algorithms have been successfully designed for POS tagging ( <ref type="bibr" target="#b26">Zhang et al., 2016;</ref>), NER ( <ref type="bibr" target="#b16">Pan et al., 2017;</ref><ref type="bibr" target="#b14">Ni et al., 2017</ref>) as well as image cap- tioning ( <ref type="bibr" target="#b10">Miyazaki and Shimizu, 2016)</ref>. These methods first aim at discovering the relatedness between two languages and separate language- common modules from language-specific mod- ules, then resort to external resources to trans- fer the knowledge across the language boundary. Our method addresses the transfer learning using a teacher-student framework and proposes to use the teacher to gradually guide the student to make more proper decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Restaurant</head><p>Price <ref type="formula">(</ref>  <ref type="figure">Figure 2</ref>: Cross-lingual DST structure, the ontology and database between multiple languages are shared.</p><p>The dialog states are defined as a set of search constraints (i.e. informable slots or goals) that the user specified through the dialog and a set of at- tribute questions regarding the search results (i.e. requestable slots or requests). The objective of di- alog state tracking (DST) is to predict and track the user intention (i.e., the values of the aforemen- tioned slots) at each time step based on the cur- rent user utterance and the entire dialog history. As shown in <ref type="figure">Figure 2</ref>, for each slot, the DST com- putes an output distribution of the candidate values using three inputs: (i) system response a t , which is the sentence generated by the system, (ii) ut- terance u t , which is the sentence from the user, and (iii) previous state, which denotes the selected slot-value pairs. We define the ontology of the di- alog system to be the set of all the possible words the dialog slot and value can take. In this pa- per, we are interested in learning a cross-lingual DST. Specifically, we assume that the DST for the source language has access to a human-annotated training dataset D while the DSTs for the target languages do not have access to annotated data in other languages except for testing data. We here mainly consider two different types of parallel re- sources to assist the transfer learning:</p><p>(1) Bilingual Corpus, where abundant bilingual corpora exist between the source and the target languages. This is often the case for common lan- guage pairs like German, Italian, and French, etc.</p><p>(2) Bilingual Dictionary, where public bilingual dictionaries exist between the source and the tar- get languages, but large-scaled parallel corpus are harder to obtain. This can be the case for rarer lan- guages like Finnish, Bulgarian, etc. Furthermore, we assume that all the languages share a common multi-lingual database, whose column/row names and entry values are stored via multiple languages (see the database in <ref type="figure">Fig- ure 1</ref>). That is, the ontology of dialog among dif- ferent languages is known with a one-to-one map- ping between them (e.g., greek=griechisch=greco, food=essen=cibo). Based on that, we could con- struct a mapping function M to associate the on- tology terms from different languages with pre- designed language-agnostic concepts: for exam- ple, M (f oods) = M (Essen) = M (Cibo) = FOOD. We illustrate our problem definition in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Decoupled Neural Belief Tracker</head><p>We design our cross-lingual DST on top of the state-of-the-art Neural Belief Tracker (NBT) ( , which demonstrates many advantages (no hand-crafted lexicons, no linguistic knowledge required, etc). These nice properties are essential for our cross-lingual DST design because we are pursuing a general and simple framework regardless of the language properties. In short, NBT consists of a neural network that computes the matching score for every candidate slot-value pair (c s , c v ) based on the following three inputs: (i) the system dialog acts a t = (t q , t s , t v ), <ref type="bibr">2</ref> (ii) the user utterance u t , and (iii) the candidate slot-value pair. And it identifies the user intents by evaluating the scores for all the slot-value pairs (see <ref type="figure" target="#fig_1">Figure 3)</ref>. With a slight abuse of notation, we still use c s , c v , t s , t v , t q ∈ R H to denote the vector representations of themselves, where H is the embedding dimension. We will use pre-trained embedding vectors in our cross-lingual NBT, just like the original NBT and they will be fixed during training. To enable cross-lingual transfer learning, we first re-interpret the architecture of the original NBT by decomposing it into three components:</p><p>Utterance Encoding The first component is an utterance encoder, which maps the utterance u t = {w 1 , w 2 , · · · , w N } of a particular language into a semantic representation vector r(u t ) ∈ R H , where w i ∈ R H is the word vector for the i-th to- ken and N is the length of the utterance. Note that the dimension of the semantic vector r(u t ) is the same as that of the word vector. We implement  the encoder using the same convolutional neural network (CNN) as the original NBT, with a slight modification of adding a top batch normalization layer. We will explain this change in section 5.</p><p>Context Gate The second part is the context gate, which takes the system acts a t = (t q , t s , t v ) and the candidate slot-value pair (c s , c v ) as its in- puts and filter out the desired information from the encoded utterance. The context gate g is a sum of three separate gates:</p><formula xml:id="formula_0">g(c s , c v , a t ) = g 1 + g 2 + g 3 (1)</formula><p>where the individual gates are defined as:</p><formula xml:id="formula_1">g 1 = σ(W s c (c s + c v ) + b s c ) g 2 = (c s · W q</formula><p>Slot-Value Decoding The final component is a slot-value decoder, which predicts the score y of a given slot-value pair using the filtered information from the utterance representation r as:</p><formula xml:id="formula_2">y(c s , c v , u t , a t ) = W T y [r(u t ) g(c s , c v , a t )] (3)</formula><p>where W y ∈ R H×1 is the weight vector. The above expression computes the score for the slot- value pair based on the information from the cur- rent turn. We combine it with the information from previous turns to get the final score:</p><formula xml:id="formula_3">ˆ y(cv|ut, at, cs) =λy(cs, cv, ut, at)+ (1 − λ)ˆ y(cs, cv, ut−1, at−1)<label>(4)</label></formula><p>here λ is a combination weight. For each given slot c s , NBT selects the single highest value for informable slots and selects all values above a cer- tain threshold for request slots. Here we replace the multi-layer perceptron in the orginal NBT by a linear output layer (to be explained in section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Cross-lingual Neural Belief Tracker</head><p>In this section, we develop a cross-lingual Neu- ral Belief Tracker (XL-NBT) that distills knowl- edge from one NBT to another using a teacher- student framework. We assume the ontology map- ping M is known a priori (see <ref type="figure" target="#fig_1">Figure 3</ref>). XL- NBT uses language-specific utterance encoder and context gate for each input language while shar- ing a common (language-agnostic) slot-value de- coder across different languages (see <ref type="figure" target="#fig_1">Figure 3</ref>).</p><p>The key idea is to optimize the language-specific components of the student network (NBT of the target language) so that their outputs are language- agnostic. This is achieved by making these outputs close to that of the teacher network (NBT of the source language), as we detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Teacher-Student Framework</head><p>We are given a well-trained NBT for a source language e, and we want to learn an NBT for a target language f without any annotated training data. Therefore, we cannot learn the target-side NBT from standard supervised learning. Instead, we use a teacher-student framework to distill the knowledge from the source-side NBT (teacher net- work) into the target-side NBT (student network) (see <ref type="figure">Figure 4)</ref>. Let x e (c e s , c e v , u e t , a e t ) be the input to the teacher network and let x f (c f s , c f v , u f t , a f t ) be the associated input to the stu- dent network. The standard teacher-student frame- work trains the student network by minimizingˆJ1</p><formula xml:id="formula_4">minimizingˆ minimizingˆJ1 = xe,x f ||y(c e s , c e v , u e t , a e t ) − y(c f s , c f v , u f t , a f t )|| 2<label>(5)</label></formula><p>where y(c e s , c e v , u e t , a e t ) and y(c f s , c f v , u f t , a f t ) de- note the scores by the teacher and the student net- works, respectively, and the slot-value pairs satisfy</p><formula xml:id="formula_5">M (c f v ) = M (c e v ) and M (c f s ) = M (c e s )</formula><p>. How- ever, the target-side inputs (c f s , c f v , u f t , a f t ) parallel to (c e s , c e v , u e t , a e t ) are usually not available in cross- lingual DST, and, even worse, the target-side ut- terance u e t is not available. We may have to gener- ate synthetic input data for the student network or leverage external data sources. It is relatively easy to use the mapping M (·) to generate (c f s , c f v , a f t )) (i.e., the inputs of the target-side context gate) from the (c e s , c e v , a e t ). But it is more challenging to obtain the parallel utterance data u f t from u e t ). Therefore, we have to leverage external bilingual data sources to alleviate the problem. However, the external bilingual data are usually not in the same domain as the utterance, and hence they are not aligned with the slot-value pair and system acts (i.e., (c e s , c e v , a e t ) or (c f s , c f v , a f t )). For this reason, we cannot perform the knowledge transfer by min- imizing the cost (5). Instead, we need to develop a new cost function where the utterance is not re- quired to be aligned with the slot-value pair and the system acts. To this end, let g e = g e (c e s , c e v , a e t ) and</p><formula xml:id="formula_6">g f = g f (c f s , c f v , a f t )</formula><p>. And we substitute <ref type="formula">(3)</ref> into (5) and get:</p><formula xml:id="formula_7">ˆ J1 ≤ ||Wy|| 2 c f v ,c e v ||re g e − r f g f || 2 = ||Wy|| 2 c f v ,c e v ||g e (re − r f ) + r f (g e − g f )|| 2 ≤ ||Wy|| 2 c f v ,c e v ||g e || 2 ||re − r f || 2 + ||r f || 2 ||g e − g f || 2</formula><p>where r e = r e (u e t ) and r f = r f (u f t ). As we mentioned earlier, the weight W y in the slot- value decoder is shared between the student and the teacher networks and will not be updated. The teacher-student optimization only adjusts the weights related to the language-specific parts in <ref type="figure" target="#fig_1">Figure 3</ref> (i.e., utterance encoding and context gat- ing). Therefore, the shared weight ||W y || is seen as a constant. Furthermore, c f v ,c e v ||g e || 2 can be seen as a constant since the teacher gate is fixed. Since we use batch normalization layer to nor- malize the encoder output (described in <ref type="figure" target="#fig_1">Figure 3</ref>), ||r f (u f t )|| 2 can also be treated as a constant C 2 . Therefore, we formally write the upper bound ofˆJ ofˆ ofˆJ 1 as our surrogate cost function J:</p><formula xml:id="formula_8">J =C1||re(u e t ) − r f (u f t )|| 2 + C2 c f v ,c e v ||g e − g f || 2<label>(6)</label></formula><p>The surrogate cost has successfully decoupled ut- terance encoder with context gate, and we use J r and J g to measure the encoder matching cost and the gate matching cost, respectively.</p><formula xml:id="formula_9">Jr = ||re(u e t ) − r f (u f t )|| 2 Jg = c f v ,c e v ||g e − g f || 2 (7)</formula><p>The encoder cost J r is optimized to distill the knowledge from the teacher encoder to student encoder while gate cost J g is optimized to dis- till the knowledge from teacher gate to student gate. This objective function successfully decou- ples the optimization of encoder and gate, thus we are able to optimize J r and J g separately from dif- ferent data sources. Recall that we can easily sim- ulate the target-side system acts, slot-value pairs (c f s , c f v , a f ) by using the ontology mapping M . Therefore, optimizing J g is relatively easy. For- mally, we write the gate matching cost as follows:  However, exact optimization of J r is difficult and we have to approximate it using external parallel data. We consider two kinds of external resources (bilingual corpus and bilingual dictionary) in the sections 5.2-5.3 (see <ref type="figure">Figure 5</ref> for the main idea).</p><formula xml:id="formula_10">Jg = a e t ,c e s ,c e v a f t ,c f s ,c f v ||ge(c e s , c e v , a e t ) − g f (c f s , c f v , a f t )|| 2<label>(8</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Bilingual Corpus (XL-NBT-C)</head><p>In our first scenario, we assume there exists a par- allel corpus D p consisting of sentence pairs from the source language and the target language. In this case, the cost function (6) is approximated by</p><formula xml:id="formula_11">J = E (me,m f )∈Dp ||re(me) − r f (m f )|| 2 + αJg (9)</formula><p>where α is the balancing factor and J g is defined in (6). The cost function <ref type="formula">(9)</ref> is minimized by stochas- tic gradient descent. At test time, we switch the encoder to receive target language inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Bilingual Dictionary (XL-NBT-D)</head><p>In the second scenario, we assume there exists no parallel corpus but a bilingual dictionary D B that defines the correspondence between source words and target words (a one-to-many mapping {w : M D (w)}). Likewise, it is infeasible to op- timize the exact encoder cost J r due to the lack of target-side utterances. We propose a word re- placement strategy (to be described later) to gener- ate synthetic parallel sentencê u f t of "mixed" lan- guage. Then, we use the generated target parallel sentences to approximate the cost (6) by</p><formula xml:id="formula_12">Jr = E u t ∈D ||re(u e t ) − r f (ˆ u f t )|| 2 + αJg (10)</formula><p>where α is the balancing factor. For word replace- ment, we first decide the number of words N w to be replaced, then we draw N w positions randomly from the source utterance and substitute the corre- sponding word w i with their target word synonym from M D (w) based on the context as follows:</p><formula xml:id="formula_13">jp(Nw = i) = exp(−i/τ ) i &lt;N exp(−i /τ ) p( ˆ w) = ˆ w · h ˆ w w ∈M (w i ) w · h ˆ w (11)</formula><p>where h ˆ w = 2 k=−2:k =0 w i+k represents the con- text vector and N denotes the utterance length. The context similarity of context and the target- side synonym can better help us in choosing the most appropriate candidate from the list. In our following experiments, we adjust the temperature of τ to control the aggressiveness of replacement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Dataset</head><p>The Wizard of Oz (WOZ) (Rojas- <ref type="bibr" target="#b20">Barahona et al., 2017)</ref> dataset is used for training and evaluation, which consists of user conversations with task- oriented dialog systems designed to help users find suitable restaurants around Cambridge, UK. The corpus contains three informable (i.e. goal- tracking) slots: FOOD, AREA, and PRICE. The users can specify values for these slots in order to find which best meet their criteria. Once the sys- tem suggests a restaurant, the users can ask about the values of up to eight requestable slots (PHONE NUMBER, ADDRESS, etc.). Multilingual WOZ 2.0 (  has expanded this dataset to include more dialogs and more languages. The train, valid and test datasets for three different lan- guages (English, German, Italian) are available online <ref type="bibr">3</ref> . We use the English as source language where 600 dialogs are used for training, 200 for validation and 400 for testing. We use the German and Italian as the target language to transfer our knowledge from English DST system. In the ex- periments, we do not have access to any training or validation dataset for German and Italian, and we only have access to their testing dataset which is composed of 400 dialogs.</p><p>For external resource, we use the IWSLT2014 Ted Talk parallel corpus ( <ref type="bibr" target="#b8">Mauro et al., 2012</ref>) from the official website 4 for bilingual corpus scenario. In the IWSLT2014 parallel corpus, we only keep the sentences between 4 and 40 words and de- crease the sentence pairs to around 150K. We use Panlex ( <ref type="bibr" target="#b4">Kamholz et al., 2014</ref>) as our data source and crawl translations for all the words appearing in the dialog datasets to build our bilingual dictio- nary. We specifically investigate two kinds of pre- trained embedding, and we use Glove ( <ref type="bibr" target="#b17">Pennington et al., 2014</ref>) as the monolingual embedding and MUSE ( <ref type="bibr" target="#b1">Conneau et al., 2017)</ref> as the bilingual em- bedding to see their impacts on the DST perfor- mance.</p><p>We split the raw DST corpus into turn-level ex- amples. During training, we use the ground truth previous state V t−1 as inputs. At test time, we use the model searched states as the previous state to continue tracking intention until the end of the dialog. When the dialog terminates, we use two evaluation metrics introduced in <ref type="bibr" target="#b2">Henderson et al. (2014a)</ref> to evaluate the DST performance: (1) Goals: the proportion of dialog turns where all the users search goal constraints were correctly iden- tified. (2) Requests: similarly, the proportion of dialog turns where users requests for information were identified correctly. Our implementation is based on the NBT <ref type="bibr">5</ref> , the details of our system set- ting are described in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>Here we highlight the baselines we use to compare with our cross-lingual algorithm as follows:</p><p>(1) Supervised: this baseline algorithm assumes the existence of annotated dialog belief tracking datasets, and it determines the upper bound of the DST model. (2) w/o Transfer: this algorithm trains an English NBT, and then directly feeds target language into the embedding level as inputs during test time to evaluate the performance. (3) Ontology-match: this algorithm directly uses exact string matching against the utterance to dis- cover the perceived slot-value pairs, it directly as- signs a high score to the appearing candidates. (4) Translation-based: this system pre-trains a translator on the external bilingual corpus and then translates the English dialog and ontology into tar- get language as "annotated" data, which is used to train the NBT in the target language domain (more details about the implementation, perfor- mance and examples are listed in the appendix). (5) Word-By-Word (WBW): this system trans- forms the English dialog corpus into target lan- guage word by word using the bilingual dictionary, which is used to train the NBT in target side. We demonstrate the results for our proposed al- gorithms and other competing algorithms in Ta- ble 2, from which we can easily conclude that that (i) our Decoupled NBT does not affect the perfor- mance, and (ii) our cross-lingual NBT framework is able to achieve significantly better accuracy for both languages in both parallel-resource scenarios.</p><p>Compare with Translator/WBW. With bilin- gual corpus, XL-NBT-C with pre-trained bilin- gual embedding can significantly outperform our Translator baseline ( <ref type="bibr" target="#b6">Klein et al., 2017)</ref>. This is intuitive because the translation model requires</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Error Type Examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modify Failure</head><p>Machine: I have two options that fit that description, golden wok Chinese restaurant and the Nirala which serves Indian food, do you have a preference? User: How about Nirala, whats the address and phone of that? Previous State: food=Chinese; Prediction: food=none; Groundtruth: food=Indian</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Maintain Failure</head><p>Machine: there are $num places with a moderate price range. can you please tell me what kind of food you would like? User: well I want to eat in the north, whats up that way? Previous State: food=expensive; Prediction: food=none; Groundtruth: food=expensive</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>History Failure</head><p>Machine: Anatolia is located at $num bridge street city center. User: thank you goodbye! Previous State: food=Chinese; Prediction: food=Chinese;,Groundtruth: food=Turkish <ref type="table">Table 1</ref>: Here we show the frequent error types, the examples are translated to English for better understanding.  <ref type="table">Table 2</ref>: Experimental results for cross-lingual NBT and other baseline algorithms. All results are averaged over 5 runs. Here we use "mono" to refer to the experiments with pre-trained monolingual embedding, "bilingual" to refer to the experiments with pre-trained bilingual embedding.</p><p>both source-side encoding and target-side word- by-word decoding, while our XL-NBT only needs a bilingual source-encoding to align two vector space, which averts the compounded decoding er- rors. With the bilingual dictionary, the word-by- word translator is very weak and leading to many broken target sentences, which poses challenges for DST training. In comparison, our XL-NBT- D can control the replacement by adjusting its temperature to maintain the stability of utterance representation. Furthermore, for both cases, our teacher-student framework can make use of the knowledge learned in source-side NBT to assist its decision making, while translator-based methods learn from scratch.</p><p>Bilingual Corpus vs. Bilingual Dictionary.</p><p>From the table, we can easily observe that bilin- gual corpus is obviously a more informative par- allel resource to perform cross-lingual transfer learning. The accuracy of XL-NBT-D is lower than XL-NBT-C. We conjecture that our replace- ment strategy to generate "mixed" language ut- terance can sometimes break the semantic coher- ence and cause additional noises during the trans- fer process, which remarkably degrades the DST performance.</p><p>Monolingual vs. Bilingual embedding. From the table, we can observe that the bilingual embed- ding and monolingual embedding does not make much difference in supervised training. How- ever, the gap in the bilingual corpus case is quite obvious. Monolingual embedding even causes the transfer to fail in a bilingual dictionary case. We conjecture that the bilingual word embed- ding already contain many alignment information between two languages, which largely eases the training of encoder matching objective.</p><p>German vs. Italian As can be seen, the transfer learning results for Italian are remarkably higher than German, especially for the "Goal" accuracy. We conjecture that it is due to German declen- sion, which can produce many word forms. The very diverse word forms present great challenges for DST to understand its intention behind. Espe- cially for the bilingual dictionary, German tends to have much longer replacement candidate lists than Italian, which introduces more noises to the replacement procedure.</p><p>Error Analysis Here we showcase the most fre- quent error types in subsection 6.1. From our observation, these three types of errors distribute evenly in the test dialogs. The error mainly comes from the unaligned utterance space, which leads to failure in understanding the intention of human utterance in the target language. This can lead the system to fail in modifying the dialog state or maintaining the previous dialog states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Discussion</head><p>Here we want to further highlight the comparison between our transfer learning algorithm with the MT-based approach. Though our approach outper- forms the standard Translator trained on IWSLT- 2014, it does not necessarily claim that our transfer algorithm outperforms any translation methods on any parallel corpus. In our further ablation stud- ies, we found that using Google Translator 6 can actually achieve a better score than our transfer al- gorithm, which is understandable considering the complexity of Google Translator and the much larger parallel corpus it leverages. By leverag- ing more close-to-domain corpus and comprehen- sive entity recognition/replacement strategy, the translator model is able to achieve a higher score. Apparently, we need to trade off the efficiency for the accuracy. For DST problem, it is an overkill to introduce a more complex translation algorithm, what we pursue is a simple yet effi- cient algorithm to achieve promising scores. It is also worth mentioning that our XL-NBT al- gorithm only takes several hours to achieve the reported score, while the translator model takes much more time and memory to train depend- ing on the complexity. Thus, the simplicity and efficiency makes our model a better fit for rare- language and limited-budget scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Ablation Test</head><p>Here we investigate the effect' of hyper-parameter α, τ on the evaluation results. The α is used to balance the optimization of encoder constraint and gate constraint, where larger α means more opti- mization on gate constraint. The temperature τ is used to control the aggressiveness of the replace- ment XL-NBT-D, where smaller τ means more source words are replaced by target synonyms. <ref type="table" target="#tab_4">From the table Table 3</ref>, we can observe that the α ablation (τ fixed to 0.1) τ ablation (α fixed to 1)  experimental results are not very sensitive to α, a dramatic change of α will not harm the final results too much, we simply choose α = 1 as the hyper-parameter. In contrast, the system is more sensitive to temperature. Too conservative replacement will lead to weak transfer, while too aggressive replacement will destroy the utterance representation. Therefore, we choose the a moder- ate temperature of τ = 0.1 throughout our experi- ments. We also draw the learning curve (Precision vs. Iteration) in the Appendix for both XL-NBT- C and XL-NBT-D. The learning curves show that our algorithm is stable and converges quickly, and the reported results are highly reproducible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In our paper, we propose a novel teacher-student framework to perform cross-lingual transfer learn- ing for DST. The key idea of our model is to de- couple the current DST neural network into two separate modules and transfer them separately. We believe our method can be further extended into a general purpose multi-lingual transfer framework to resolve other NLP matching or classification problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Our implementation of baseline NBT, slightly modified from (Mrksic et al., 2017).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :birds, life gains new mobility. Bei Vögeln erhält das Leben neue Mobilität. I can take a look at your records. Ich kann mir deine Unterlagen ansehen.Figure 5 :</head><label>45</label><figDesc>Figure 4: Teacher-Student Framework for cross-lingual transfer learning. The dotted line denotes the imaginary utterances, which expresses the same intention as the source side.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>)µí±³(í µí² í µí² (í µí² í µí² |í µí°® í µí°­ , í µí° í µí°­ ,í µí² í µí² )||í µí² í µí² (í µí² í µí² |í µí°® í µí°­ , í µí° í µí°­ , í µí² í µí² ))</head><label></label><figDesc></figDesc><table>I want to order Greek food 

What kind of food do 
you want? 

greek 
chinese 
thai 
japanese 

í µí±²í í µí² í µí² : í µí±­í µí± ¶í µí± ¶í µí±« 
í µí² í µí² , í µí² í µí² : None, None 

í µí² í µí² 
í µí² , í µí² í µí² 
í µí² : (FOOD, greek) 

||í µí² í µí² í µí² 
í µí² − í µí²(í µí² í µí² 
í µí² )|| 

Ich möchte griechisches Essen 

Welche Art von Essen 
willst du? 

í µí² í µí² : í µí±¬í µí±ºí µí±ºí µí±¬í µí±µ 
í µí² í µí² , í µí² í µí² : None, None 

í µí² í µí² 
í µí² , í µí² í µí² 
í µí² : (ESSEN, grieschisch) 

í µí² í µí² 

í µí² 

í µí² í µí² 

í µí² 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Ablation test for hyper-parameter α and τ on 
English-to-German XL-NBT-D. 

</table></figure>

			<note place="foot" n="2"> tq represents the system request, ts, tv represents the system confirmation. If the system wants to request some information from the user by asking &quot;what&apos;s your favorite area?&quot;, then NBT sets tq=&quot;AREA&quot;. If the system wants to confirm some information from a user by asking &quot;should I try Persian restaurants in the north?&quot; then NBT sets ts, tv=&quot;area, north&quot;.</note>

			<note place="foot">t t q ) [1, · · · , 1] H g 3 = (c s · W s t t s )(c v · W v t t v ) [1, · · · , 1] H (2) where W s c , W q t , W s t , W v t ∈ R H×H are the weight matrices, and and · denote the Hadamard product and the inner product, respectively. The three gates g 1 ∈ R H , g 2 ∈ R H , g 3 ∈ R H model the relevance between the candidate slot and value, the system request and the system confirms, respectively. The transformation matrices W q t , W s t , W v t are added to the original NBT to increase the model flexibility of the gates.</note>

			<note place="foot" n="3"> https://github.com/nmrksic/ neural-belief-tracker/tree/master/data 4 https://wit3.fbk.eu/mt.php?release= 2014-01</note>

			<note place="foot" n="5"> https://github.com/nmrksic/ neural-belief-tracker</note>

			<note place="foot" n="6"> https://translate.google.com/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgement</head><p>We are gratefully supported by a Tencent AI Lab Rhino-Bird Gift Fund. We are also very thank-ful for the public belief tracking code and multi-lingual state-tracking datasets released by Nikola Mrksic from the University of Cambridge.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning end-to-end goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Word translation without parallel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust dialog state tracking using delexicalised recurrent neural networks and unsupervised adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="360" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Word-based dialog state tracking with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">J</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting><address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06-20" />
			<biblScope unit="page" from="292" to="299" />
		</imprint>
	</monogr>
	<note>Proceedings of the SIGDIAL 2014 Conference</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Panlex: Building a resource for panlingual lexical translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kamholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">M</forename><surname>Colowick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3145" to="3150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cross-lingual transfer learning for pos tagging without cross-lingual resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joo-Kyung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Fosler-Lussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2832" to="2838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">OpenNMT: Open-Source Toolkit for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">End-to-end taskcompletion neural dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli C ¸</forename><surname>Elikyilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-11-27" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="733" to="743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Wit3: Web inventory of transcribed and translated talks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cettolo</forename><surname>Mauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girardi</forename><surname>Christian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of European Association for Machine Translation</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discriminative state tracking for spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Metallinou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Bohus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="466" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cross-lingual image caption generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuyuki</forename><surname>Shimizu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1780" to="1790" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multidomain dialog state tracking using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´odiarmuid´</forename><forename type="middle">Diarmuid´o</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">J</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="794" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural belief tracker: Data-driven dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´odiarmuid´</forename><forename type="middle">Diarmuid´o</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">J</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1777" to="1788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Semantic specialisation of distributional word vector spaces using monolingual and cross-lingual constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´odiarmuid´</forename><forename type="middle">Diarmuid´o</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Leviant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.00374</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Weakly supervised cross-lingual named entity recognition via effective annotation and representation projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="0304" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1470" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Crosslingual name tagging and linking for 282 languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1946" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>Doina Precup and Yee Whye Teh</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-11" />
			<biblScope unit="volume">70</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Scalable multi-domain dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">P</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Automatic Speech Recognition and Understanding Workshop</title>
		<meeting><address><addrLine>Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-16" />
			<biblScope unit="volume">2017</biblScope>
			<biblScope unit="page" from="561" to="568" />
		</imprint>
	</monogr>
	<note>ASRU</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A network-based end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Maria Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">J</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vandyke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter<address><addrLine>Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-04-03" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantically conditioned lstm-based natural language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihao</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">J</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09-17" />
			<biblScope unit="page" from="1711" to="1721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The dialog state tracking challenge series: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Raux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue &amp; Discourse</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="4" to="33" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hybrid code networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavosh</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="665" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An end-to-end approach for handling unknown slot values in dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018-07-15" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1448" to="1457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The hidden information state model: A practical framework for pomdp-based spoken dialogue management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Mairesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Schatzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="150" to="174" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ten pairs to tag-multilingual POS tagging via coarse mapping between embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gaddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting><address><addrLine>San Diego California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-12" />
			<biblScope unit="page" from="1307" to="1317" />
		</imprint>
	</monogr>
	<note>NAACL HLT 2016</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
