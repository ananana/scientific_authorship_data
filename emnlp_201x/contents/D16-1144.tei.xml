<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AFET: Automatic Fine-Grained Entity Typing by Hierarchical Partial-Label Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename><surname>Lifu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huang</forename><surname>Heng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><forename type="middle">Jiawei</forename><surname>Han</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
								<address>
									<country>USA †</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AFET: Automatic Fine-Grained Entity Typing by Hierarchical Partial-Label Embedding</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1369" to="1378"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Distant supervision has been widely used in current systems of fine-grained entity typing to automatically assign categories (en-tity types) to entity mentions. However, the types so obtained from knowledge bases are often incorrect for the entity mention&apos;s local context. This paper proposes a novel embedding method to separately model &quot;clean&quot; and &quot;noisy&quot; mentions, and incorporates the given type hierarchy to induce loss functions. We formulate a joint optimization problem to learn embeddings for mentions and type-paths, and develop an iterative algorithm to solve the problem. Experiments on three public datasets demonstrate the effectiveness and robustness of the proposed method, with an average 15% improvement in accuracy over the next best compared method 1 .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Assigning types (e.g., person, organization) to mentions of entities in context is an important task in natural language processing (NLP). The ex- tracted entity type information can serve as primi- tives for relation extraction <ref type="bibr" target="#b13">(Mintz et al., 2009</ref>) and event extraction <ref type="bibr" target="#b8">(Ji and Grishman, 2008)</ref>, and as- sists a wide range of downstream applications in- cluding knowledge base (KB) completion <ref type="bibr" target="#b2">(Dong et al., 2014</ref>), question answering ( <ref type="bibr" target="#b10">Lin et al., 2012</ref>) and entity recommendation ( <ref type="bibr" target="#b32">Yu et al., 2014</ref>). While Current systems may detect Arnold Schwarzenegger in sentences S1-S3 and assign the same types to all (listed within braces), when only some types are correct for context (blue labels within braces).</p><p>traditional named entity recognition systems <ref type="bibr" target="#b17">(Ratinov and Roth, 2009;</ref><ref type="bibr" target="#b14">Nadeau and Sekine, 2007)</ref> fo- cus on a small set of coarse types (typically fewer than 10), recent studies ( <ref type="bibr" target="#b11">Ling and Weld, 2012;</ref><ref type="bibr" target="#b31">Yosef et al., 2012</ref>) work on a much larger set of fine-grained types (usually over 100) which form a tree-structured hierarchy (see the blue region of <ref type="figure" target="#fig_0">Fig. 1</ref>). Fine-grained typing allows one mention to have multiple types, which together constitute a type-path (not necessarily ending in a leaf node) in the given type hierarchy, depending on the lo- cal context (e.g., sentence). Consider the example in <ref type="figure" target="#fig_0">Fig. 1</ref>, "Arnold Schwarzenegger" could be labeled as {person, businessman} in S3 (investment). But he could also be labeled as {person, politician} in S1 or {person, artist, actor} in S2. Such fine-grained type representation provides more in- formative features for other NLP tasks. For exam-ple, since relation and event extraction pipelines rely on entity recognizer to identify possible arguments in a sentence, fine-grained argument types help dis- tinguish hundreds or thousands of different relations and events <ref type="bibr" target="#b11">(Ling and Weld, 2012)</ref>.</p><p>Traditional named entity recognition systems adopt manually annotated corpora as training data ( <ref type="bibr" target="#b14">Nadeau and Sekine, 2007)</ref>. But the process of manually labeling a training set with large num- bers of fine-grained types is too expensive and error- prone (hard for annotators to distinguish over 100 types consistently). Current fine-grained typing sys- tems annotate training corpora automatically using knowledge bases (i.e., distant supervision) ( <ref type="bibr" target="#b11">Ling and Weld, 2012;</ref><ref type="bibr" target="#b19">Ren et al., 2016a)</ref>. A typical work- flow of distant supervision is as follows (see <ref type="figure" target="#fig_0">Fig. 1</ref>):</p><p>(1) identify entity mentions in the documents; (2) link mentions to entities in KB; and (3) assign, to the candidate type set of each mention, all KB types of its KB-linked entity. However, existing distant supervision methods encounter the following limi- tations when doing automatic fine-grained typing.</p><p>• Noisy Training Labels. Current practice of dis- tant supervision may introduce label noise to train- ing data since it fails to take a mention's local con- texts into account when assigning type labels (e.g., see <ref type="figure" target="#fig_0">Fig. 1</ref>). Many previous studies ignore the la- bel noises which appear in a majority of train- ing mentions (see <ref type="table">Table.</ref> 1, row (1)), and assume all types obtained by distant supervision are "cor- rect" <ref type="bibr" target="#b30">(Yogatama et al., 2015;</ref><ref type="bibr" target="#b11">Ling and Weld, 2012</ref>). The noisy labels may mislead the trained models and cause negative effect. A few systems try to denoise the training corpora using simple pruning heuristics such as deleting mentions with conflicting types ( ). However, such strate- gies significantly reduce the size of training set (Ta- ble 1, rows (2a-c)) and lead to performance degrada- tion (later shown in our experiments). The larger the target type set, the more severe the loss.</p><p>• Type Correlation. Most existing methods <ref type="bibr" target="#b30">(Yogatama et al., 2015;</ref><ref type="bibr" target="#b11">Ling and Weld, 2012</ref>) treat ev- ery type label in a training mention's candidate type set equally and independently when learning the classifiers but ignore the fact that types in the given hierarchy are semantically correlated (e.g., actor is more relevant to singer than to politician). As a consequence, the learned classifiers may bias  toward popular types but perform poorly on infre- quent types since training data on infrequent types is scarce. Intuitively, one should pose smaller penalty on types which are semantically more relevant to the true types. For example, in <ref type="figure" target="#fig_0">Fig. 1</ref> singer should receive a smaller penalty than politician does, by knowing that actor is a true type for "Arnold Schwarzenegger" in S2. This provides classifiers with additional information to distinguish between two types, especially those infrequent ones.</p><p>In this paper, we approach the problem of auto- matic fine-grained entity typing as follows: (1) Use different objectives to model training mentions with correct type labels and mentions with noisy labels, respectively. (2) Design a novel partial-label loss to model true types within the noisy candidate type set which requires only the "best" candidate type to be relevant to the training mention, and progressively estimate the best type by leveraging various text fea- tures extracted for the mention. (3) Derive type cor- relation based on two signals: (i) the given type hier- archy, and (ii) the shared entities between two types in KB, and incorporate the correlation so induced by enforcing adaptive margins between different types for mentions in the training set. To integrate these ideas, we develop a novel embedding-based frame- work called AFET. First, it uses distant supervision to obtain candidate types for each mention, and ex- tract a variety of text features from the mentions themselves and their local contexts. Mentions are partitioned into a "clean" set and a "noisy" set based on the given type hierarchy. Second, we embed mentions and types jointly into a low-dimensional space, where, in that space, objects (i.e., features and types) that are semantically close to each other also have similar representations. In the proposed objective, an adaptive margin-based rank loss is pro-posed to model the set of clean mentions to capture type correlation, and a partial-label rank loss is for- mulated to model the "best" candidate type for each noisy mention. Finally, with the learned embeddings (i.e., mapping matrices), one can predict the type- path for each mention in the test set in a top-down manner, using its text features. The major contribu- tions of this paper are as follows:</p><p>1. We propose an automatic fine-grained entity typ- ing framework, which reduces label noise in- troduced by distant supervision and incorporates type correlation in a principle way.</p><p>2. A novel optimization problem is formulated to jointly embed entity mentions and types to the same space. It models noisy type set with a partial-label rank loss and type correlation with adaptive-margin rank loss.</p><p>3. We develop an iterative algorithm for solving the joint optimization problem efficiently.</p><p>4. Experiments with three public datasets demon- strate that AFET achieves significant improve- ment over the state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Automatic Fine-Grained Entity Typing</head><p>Our task is to automatically uncover the type infor- mation for entity mentions (i.e., token spans repre- senting entities) in natural language sentences.  Automatically Labeled Training Corpora. There exist publicly available labeled corpora such as Wik- ilinks ( <ref type="bibr" target="#b21">Singh et al., 2012</ref>) and ClueWeb ( <ref type="bibr" target="#b6">Gabrilovich et al., 2013)</ref>. In these corpora, entity mentions are identified and mapped to KB entities using anchor links. In specific domains (e.g., product reviews) where such public corpora are unavailable, one can utilize distant supervision to automatically label the corpus ( <ref type="bibr" target="#b11">Ling and Weld, 2012)</ref>. Specifically, an en- tity linker will detect mentions m i and map them to one or more entity e i in E Ψ . Types of e i in KB are then associated with m i to form its type set</p><formula xml:id="formula_0">Y i , i.e., Y i = y | (e i , y) ∈ F Ψ , y ∈ Y</formula><p>. Formally, a training corpus D consists of a set of extracted entity</p><formula xml:id="formula_1">mentions M = {m i } N i=1 , the context (e.g., sentence, paragraph) of each mention {c i } N i=1</formula><p>, and the candi- date type sets</p><formula xml:id="formula_2">{Y i } N i=1 for each mention. We repre- sent D using a set of triples D = (m i , c i , Y i ) N i=1</formula><p>.</p><p>Problem Description. For each test mention, we aim to predict the correct type-path in Y based on the mention's context. More specifically, the test set T is defined as a set of mention-context pairs (m, c), where mentions in T (denoted as M t ) are extracted from their sentences using existing extractors such as named entity recognizer ( <ref type="bibr" target="#b5">Finkel et al., 2005</ref> Framework Overview. At a high level, the AFET framework (see also <ref type="figure" target="#fig_1">Fig. 2</ref>) learns low-dimensional representations for entity types and text features, and infers type-paths for test mentions using the learned embeddings. It consists of the following steps:</p><p>1. Extract text features for entity mentions in train- ing set M and test set M t using their surface names as well as the contexts. (Sec. 3.1).</p><p>2. Partition training mentions M into a clean set (denoted as M c ) and a noisy set (denoted as M n ) based on their candidate type sets (Sec. 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Perform joint embedding of entity mentions</head><p>M and type hierarchy Y into the same low- dimensional space where, in that space, close ob- jects also share similar types (Secs. 3.3-3.6).</p><p>4. For each test mention m, estimate its type-path Y * (on the hierarchy Y) in a top-down manner using the learned embeddings (Sec. 3.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The AFET Framework</head><p>This section introduces the proposed framework and formulates an optimization problem for learning em- beddings of text features and entity types jointly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Text Feature Generation</head><p>We start with a representation of entity mentions.</p><p>To capture the shallow syntax and distributional se- mantics of a mention m i ∈ M, we extract various features from both m i itself and its context c i . <ref type="table" target="#tab_4">Ta- ble 2</ref> lists the set of text features used in this work, which is similar to those used in ( <ref type="bibr" target="#b30">Yogatama et al., 2015;</ref><ref type="bibr" target="#b11">Ling and Weld, 2012)</ref>. We denote the set of M unique features extracted from D as F = {f j } M j=1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training Set Partition</head><p>A training mention m i (in set M) is considered as a "clean" mention if its candidate type set obtained by distant supervision (i.e., Y i ) is not ambiguous, i.e., candidate types in Y i can form a single path in tree Y. Otherwise, a mention is considered as "noisy" mention if its candidate types form multiple type- paths in Y. Following the above hypothesis, we judge each mention m i (in set M) and place it in either the "clean" set M c , or the "noisy" set M n . Finally, we have M = M c ∪ M n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Joint Mention-Type Model</head><p>We propose to learn mappings into low-dimensional vector space, where, both entity mentions and type ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example Type-Type Correlation Scores</head><p>Knowledge Base <ref type="bibr">(Ben Affleck, act or)</ref> (Ben Affleck, director) (Woody Al len, act or) (Woody Al len, director) (J. K. Rowling, aut hor) (Kobe B ryant, at hlete) ... </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity-type facts</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ben</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adaptive Margin</head><p>Sn _Ted Cruz Context in Sn: "The effective end of Ted Cruz 's presidential campaign came on a call …" labels (in the training set) are represented, and in that space, two objects are embedded close to each other if and only if they share similar types. In doing so, we later can derive the representation of a test men- tion based on its text features and the learned map- pings. Mapping functions for entity mentions and entity type labels are different as they have differ- ent representations in the raw feature space, but are jointly learned by optimizing a global objective of interests to handle the aforementioned challenges. Each entity mention m i ∈ M can be represented by a M -dimensional feature vector m i ∈ R M , where m i,j is the number of occurrences of feature f j (in set F) for m i . Each type label y k ∈ Y is represented by a K-dimensional binary indicator vector y k ∈ {0, 1} K , where y k,k = 1, and 0 otherwise.</p><p>Specifically, we aim to learn a mapping func- tion from the mention's feature space to a low- dimensional vector space, i.e., Φ M (m i ) : R M → R d and a mapping function from type label space to the same low-dimensional space, i.e., Φ Y (y k ) : R K → R d . In this work, we adopt linear maps, as similar to the mapping functions used in <ref type="bibr" target="#b29">(Weston et al., 2011</ref>).</p><formula xml:id="formula_3">Φ M (m i ) = Um i ; Φ Y (y k ) = Vy k ,<label>(1)</label></formula><p>where U ∈ R d×M and V ∈ R d×K are the projection matrices for mentions and type labels, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Modeling Type Correlation</head><p>In type hierarchy (tree) Y, types closer to each other (i.e., shorter path) tend to be more related (e.g., actor is more related to artist than to person in the right column of <ref type="figure" target="#fig_1">Fig. 2)</ref>. In KB Ψ, types as- signed to similar sets of entities should be more re- lated to each other than those assigned to quite dif- ferent entities (Jiang et al., 2015) (e.g., actor is Syntactic head token of the mention "HEAD Turing" Token Tokens in the mention "Turing", "Machine" POS Part-of-Speech tag of tokens in the mention "NN" Character All character trigrams in the head of the mention ":tu", "tur", ..., "ng:" Word Shape Word shape of the tokens in the mention "Aa" for "Turing" Length Number of tokens in the mention "2" Context Unigrams/bigrams before and after the mention "CXT B:Maserati ,", "CXT A:and the" Brown Cluster</p><p>Brown cluster ID for the head token (learned using D) "4 1100", "8 1101111", "12 111011111111" Dependency Stanford syntactic dependency ( <ref type="bibr" target="#b12">Manning et al., 2014</ref>) associated with the head token "GOV:nn", "GOV:turing" more related to director than to author in the left column of <ref type="figure" target="#fig_3">Fig. 3</ref>). Thus, type correlation be- tween y k and y k (denoted as w kk ) can be measured either using the one over the length of shortest path in Y, or using the normalized number of shared en- tities in KB, which is defined as follows.</p><formula xml:id="formula_4">w kk = E k ∩ E k / E k + E k ∩ E k / E k /2. (2)</formula><p>Although a shortest path is efficient to compute, its accuracy is limited-It is not always true that a type (e.g., athlete) is more related to its parent type (i.e., person) than to its sibling types (e.g., coach), or that all sibling types are equally re- lated to each other (e.g., actor is more related to director than to author). We later compare these two methods in our experiments.</p><p>With the type correlation computed, we propose to apply adaptive penalties on different negative type labels (for a training mention), instead of treat- ing all of the labels equally as in most existing work <ref type="bibr" target="#b29">(Weston et al., 2011</ref>). The hypothesis is intu- itive: given the positive type labels for a mention, we force the negative type labels which are related to the positive type labels to receive smaller penalty. For example, in the right column of <ref type="figure" target="#fig_3">Fig. 3</ref>, negative la- bel businessman receives a smaller penalty (i.e., margin) than athele does, since businessman is more related to politician.</p><p>Hypothesis 1 (Adaptive Margin) For a mention, if a negative type is correlated to a positive type, the margin between them should be smaller.</p><p>We propose an adaptive-margin rank loss to model the set of "clean" mentions (i.e., M c ), based on the above hypothesis. The intuition is simple: for each mention, rank all the positive types ahead of negative types, where the ranking score is measured by similarity between mention and type. We denote f k (m i ) as the similarity between (m i , y k ) and is de- fined as the inner product of Φ M (m i ) and Φ Y (y k ).</p><formula xml:id="formula_5">c (m i , Y i , Y i ) = y k ∈Yi y¯ k ∈Y i L rank y k f (m i ) Θ i,k, ¯ k ; Θ i,k, ¯ k = max 0, γ k, ¯ k − f k (m i ) + f¯ k (m i ) ; rank y k f (m i ) = y¯ k ∈Y i 1 γ k, ¯ k + f¯ k (m i ) &gt; f k (m i ) .</formula><p>Here, γ k, ¯ k is the adaptive margin between positive type k and negative type ¯ k, which is defined as γ k, ¯</p><formula xml:id="formula_6">k = 1 + 1/(w k, ¯ k + α) with a smooth parameter α. L(x) = x i=1 1</formula><p>i transforms rank to a weight, which is then multiplied to the max-margin loss Θ i,k, ¯ k to optimize precision at x (Weston et al., 2011).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Modeling Noisy Type Labels</head><p>True type labels for noisy entity mentions M n (i.e., mentions with ambiguous candidate types in the given type hierarchy) in each sentence are not avail- able in knowledge bases. To effectively model the set of noisy mentions, we propose not to treat all candidate types (i.e., {Y i } as true labels. Instead, we model the "true" label among the candidate set as latent value, and try to infer that using text features.</p><p>Hypothesis 2 (Partial-Label Loss) For a noisy mention, the maximum score associated with its candidate types should be greater than the scores associated with any other non-candidate types</p><p>We extend the partial-label loss in <ref type="bibr" target="#b15">(Nguyen and Caruana, 2008</ref>) (used to learn linear classifiers) to enforce Hypothesis 2, and integrate with the adap- tive margin to define the loss for m i (in set M n ).</p><formula xml:id="formula_7">n (m i , Y i , Y i ) = ¯ k∈Y i L rank y k * f (m i ) Ω i, ¯ k ; Ω i,k = max 0, γ k * , ¯ k − f k * (m i ) + f¯ k (m i ) ; rank y k * f (m i ) = y¯ k ∈Y i 1 γ k * , ¯ k + f¯ k (m i ) &gt; f k * (m i )</formula><p>where we define . y k * = argmax y k ∈Yi f k (m i ) and</p><formula xml:id="formula_8">y¯ k * = argmax y k ∈Y i f k (m i ).</formula><p>Minimizing n encourages a large margin be- tween the maximum scores max y k ∈Yi f y k (m i ) and max y¯ k ∈Y i f y k (m i ). This forces m i to be embed- ded closer to the most "relevant" type in the noisy candidate type set, i.e., y * = argmax y k ∈Yi f y k (m i ), than to any other non-candidate types (i.e., Hypoth- esis 2). This constrasts sharply with multi-label learning ( <ref type="bibr" target="#b31">Yosef et al., 2012)</ref>, where a large margin is enforced between all candidate types and non- candidate types without considering noisy types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Hierarchical Partial-Label Embedding</head><p>Our goal is to embed the heterogeneous graph G into a d-dimensional vector space, following the three proposed hypotheses in the section. Intuitively, one can collectively minimize the objectives of the two kinds of loss functions c and n , across all the train- ing mentions. To achieve the goal, we formulate a joint optimization problem as follows.</p><formula xml:id="formula_9">min U, V O = mi∈Mc c (m i , Y i , Y i ) + mi∈Mn n (m i , Y i , Y i ).</formula><p>We use an alternative minimization algorithm based on block-wise coordinate descent <ref type="bibr" target="#b25">(Tseng, 2001)</ref>   top-down search in the given type hierarchy Y to estimate the correct type-path Y * i . Starting from the tree's root, we recursively find the best type among the children types by measuring the dot product of the corresponding mention and type embeddings, i.e., sim(u i , v k ). The search process stops when we reach a leaf type, or the similarity score is below a pre-defined threshold η &gt; 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Preparation</head><p>Datasets. Our experiments use three public datasets.  <ref type="table" target="#tab_6">Table 3</ref>.</p><p>Training Data. We followed the process in ( <ref type="bibr" target="#b11">Ling and Weld, 2012</ref>) to generate training data for the Wiki dataset. For the BBN and OntoNotes datasets, we used DBpedia Spotlight 3 for entity linking. We discarded types which cannot be mapped to Free- base types in the BBN dataset (47 of 93). <ref type="table" target="#tab_4">Table 2</ref> lists the set of features used in our experi- ments, which are similar to those used in ( <ref type="bibr" target="#b30">Yogatama et al., 2015;</ref><ref type="bibr" target="#b11">Ling and Weld, 2012</ref>) except for top- ics and ReVerb patterns. We discarded the features which occur only once in the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Settings</head><p>For the Wiki and OntoNotes datasets, we used the provided test set. Since BBN corpus is fully anno- tated, we followed a 80/20 ratio to partition it into training/test sets. We report Accuracy (Strict-F1), Micro-averaged F1 (Mi-F1) and Macro-averaged F1 (Ma-F1) scores commonly used in the fine-grained type problem ( <ref type="bibr" target="#b11">Ling and Weld, 2012;</ref><ref type="bibr" target="#b30">Yogatama et al., 2015</ref>). Since we use the gold mention set for testing, the Accuracy (Acc) we reported is the same as the Strict F1. Baselines. We compared the proposed method (AFET) and its variant with state-of-the-art typ- ing methods, embedding methods and partial-label learning methods 4 : (1) FIGER (Ling and Weld, 2012); (2) HYENA <ref type="figure" target="#fig_0">(Yosef et al., 2012)</ref>; (3) FIGER/HYENA-Min ( ): re- moves types appearing only once in the docu- ment; (4) ClusType (Ren et al., 2015): predicts types based on co-occurring relation phrases; (5) HNM ( <ref type="bibr" target="#b3">Dong et al., 2015)</ref>: proposes a hybrid neu- ral model without hand-crafted features; (6) Deep- Walk ( <ref type="bibr" target="#b16">Perozzi et al., 2014</ref>): applies Deep Walk to a feature-mention-type graph by treating all nodes as the same type; (7) LINE (Tang et al., 2015b): uses a second-order LINE model on feature-type bi- partite graph; (8) PTE (Tang et al., 2015a): ap- plies the PTE joint training algorithm on feature- mention and type-mention bipartite graphs. (9) WS- ABIE ( <ref type="bibr" target="#b30">Yogatama et al., 2015)</ref>: adopts WARP loss to learn embeddings of features and types; (10) PL- SVM <ref type="bibr" target="#b15">(Nguyen and Caruana, 2008)</ref>: uses a margin- based loss to handle label noise. (11) CLPL (Cour et al., 2011): uses a linear model to encourage large average scores for candidate types.</p><p>We compare AFET and its variant: (1) AFET: complete model with KB-induced type correlation; (2) AFET-CoH: with hierarchy-induced correlation (i.e., shortest path distance); (3) AFET-NoCo: with- out type correlation (i.e., all margin are "1") in the objective O; and (4) AFET-NoPa: without label partial loss in the objective O. <ref type="table" target="#tab_8">Table 4</ref> shows the results of AFET and its variants. Comparison with the other typing methods. AFET outperforms both FIGER and HYENA sys- tems, demonstrating the predictive power of the learned embeddings, and the effectiveness of mod- eling type correlation information and noisy candi- date types. We also observe that pruning methods do not always improve the performance, since they ag- gressively filter out rare types in the corpus, which may lead to low Recall. ClusType is not as good as FIGER and HYENA because it is intended for coarse types and only utilizes relation phrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance Comparison and Analyses</head><p>Comparison with the other embedding methods. AFET performs better than all other embedding methods. HNM does not use any linguistic features. None of the other embedding methods consider the label noise issue and treat the candidate type sets as clean. Although AFET adopts the WARP loss in WSABIE, it uses an adaptive margin in the objec- tive to capture the type correlation information.</p><p>Comparison with partial-label learning methods. Compared with PL-SVM and CLPL, AFET obtains superior performance. PL-SVM assumes that only one candidate type is correct and does not consider type correlation. CLPL simply averages the model output for all candidate types, and thus may gener- ate results biased to frequent false types. Superior performance of AFET mainly comes from modeling type correlation derived from KB.</p><p>Comparison with its variants. AFET always out- performs its variant on all three datasets. It gains performance from capturing type correlation, as well as handling type noise in the embedding process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Case Analyses</head><p>Example output on news articles. <ref type="table" target="#tab_9">Table 5</ref> shows the types predicted by AFET, FIGER, PTE and WSABIE on two news sentences from OntoNotes dataset: AFET predicts fine-grained types with bet- ter accuracy (e.g., person title) and avoids overly-specific predictions (e.g., news company). <ref type="figure" target="#fig_7">Figure 5</ref> shows the types estimated by AFET, PTE and WSABIE on a training sentence from OntoNotes dataset. We found AFET could discover the best type from noisy candidate types.    Testing the effect of training set size and dimen- sion. Experimenting with the same settings for model learning, <ref type="figure">Fig. 6(a)</ref> shows the performance trend on the Wiki dataset when varying the sampling ratio (subset of mentions randomly sampled from the training set D). <ref type="figure">Fig. 6(b)</ref> analyzes the perfor- mance sensitivity of AFET with respect to d-the embedding dimension on the BBN dataset. Accu- racy of AFET improves as d becomes large but the gain decreases when d is large enough. Testing sensitivity of the tuning parameter. <ref type="figure">Fig. 7(b)</ref> analyzes the sensitivity of AFET with re- spect to α on the BBN dataset. Performance in- creases as α becomes large. When α is large than 0.5, the performance becomes stable.</p><p>Testing at different type levels. <ref type="figure">Fig. 7(a)</ref> reports the Ma-F1 of AFET, FIGER, PTE and WSABIE at different levels of the target type hierarchy (e.g., per- son and location on level-1, politician and artist on level-2, author and actor on level-3). The results show that it is more difficult to distinguish among more fine-grained types. AFET always outperforms the other two method, and achieves a 22.36% im- provement in Ma-F1, compared to FIGER on level-3 types. The gain mainly comes from explicitly mod- eling the noisy candidate types.</p><p>Testing for frequent/infrequent types. We also  evaluate the performance on frequent and rare types ( <ref type="table" target="#tab_11">Table 6</ref>). Note that we use a different evaluation metric, which is introduced in ( <ref type="bibr" target="#b31">Yosef et al., 2012)</ref> to calculate the F1 score for a type. We find AFET can always perform better than other baselines and it works for both frequent and rare types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>There has been considerable work on named entity recognition (NER) ( <ref type="bibr" target="#b12">Manning et al., 2014</ref>), which fo- cuses on three types (e.g., person, location) and cast the problem as multi-class classification fol- lowing the type mutual exclusion assumption (i.e., one type per mention) ( <ref type="bibr" target="#b14">Nadeau and Sekine, 2007)</ref>. Recent work has focused on a much larger set of fine-grained types ( <ref type="bibr" target="#b31">Yosef et al., 2012;</ref><ref type="bibr" target="#b11">Ling and Weld, 2012)</ref>. As the type mutual exclusion assump- tion no longer holds, they cast the problem as multi- label multi-class (hierarchical) classification prob- lems ( <ref type="bibr" target="#b31">Yosef et al., 2012;</ref><ref type="bibr" target="#b11">Ling and Weld, 2012)</ref>. Embedding techniques are also recently applied to jointly learn feature and type rep- resentations ( <ref type="bibr" target="#b30">Yogatama et al., 2015;</ref><ref type="bibr" target="#b3">Dong et al., 2015)</ref>. Del <ref type="bibr" target="#b1">Corro et al. (2015)</ref> proposed an unsuper- vised method to generate context-aware candidates types, and subsequently select the most appropriate type.  discuss the label noise is- sue in fine-grained typing and propose three pruning heuristics. However, these heuristics aggressively delete training examples and may suffer from low recall (see <ref type="table">Table.</ref> 4).</p><p>In the context of distant supervision, label noise issue has been studied for other information extrac- tion tasks such as relation extraction ( <ref type="bibr" target="#b22">Takamatsu et al., 2012</ref>). In relation extraction, label noise is intro- duced by the false positive textual matches of en- tity pairs. In entity typing, however, label noise comes from the assignment of types to entity men- tions without considering their contexts. The forms of distant supervision are different in these two prob- lems. Recently, <ref type="bibr" target="#b20">(Ren et al., 2016b</ref>) has tackled the problem of label noise in fine-grained entity typing, but focused on how to generate a clean training set instead of doing entity typing.</p><p>Partial label learning (PLL) <ref type="bibr" target="#b33">(Zhang, 2014;</ref><ref type="bibr" target="#b15">Nguyen and Caruana, 2008;</ref><ref type="bibr" target="#b0">Cour et al., 2011</ref>) deals with the problem where each training example is as- sociated with a set of candidate labels, where only one is correct. Unlike existing PLL methods, our method considers type hierarchy and correlation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we study automatic fine-grained en- tity typing and propose a hierarchical partial-label embedding method, AFET, that models "clean" and "noisy" mentions separately and incorporates a given type hierarchy to induce loss functions. AFET builds on a joint optimization framework, learns em- beddings for mentions and type-paths, and itera- tively refines the model. Experiments on three pub- lic datasets show that AFET is effective, robust, and outperforms other comparing methods.</p><p>As future work, it would be interesting to study topical features as the context cues of the entity men- tions, to leverage multi-sensing embedding to repre- sent linguistic features with multiple senses, and to exploits other effective modeling methods to inject type hierarchy information. The proposed objective function is general and can be considered to incorpo- rate various language features, to conduct integrated modeling of multiple sources, and to be extended to distantly-supervised relation extraction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Current systems may detect Arnold Schwarzenegger in sentences S1-S3 and assign the same types to all (listed within braces), when only some types are correct for context (blue labels within braces).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Framework Overview of AFET.</figDesc><graphic url="image-10.png" coords="3,313.20,56.06,133.03,114.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An illustration of KB-based type correlation computation, and the proposed adaptive margin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Types ranked w.r.t. mi Partial-Label Rank Loss for Noisy Mentions Mention:"Full" Rank Loss for Clean Mentions Distance between mi and types Distance between mi andFigure 4 :</head><label>4</label><figDesc>Figure 4: An illustration of the partial-label rank loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>( 1 )</head><label>1</label><figDesc>Wiki (Ling and Weld, 2012): consists of 1.5M sentences sampled from Wikipedia articles; (2) OntoNotes (Weischedel et al., 2011): consists of 13,109 news documents where 77 test documents are manually annotated (Gillick et al., 2014); (3) BBN (Weischedel and Brunstein, 2005): consists of 2,311 Wall Street Journal articles which are man- ually annotated using 93 types. Statistics of the datasets are shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>.Figure 5 :</head><label>5</label><figDesc>Figure 5: Example output of AFET and the compared methods on a training sentence from OntoNotes dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>FIGER WSABIE AFET</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>A study of label noise. (1): %mentions with 
multiple sibling types (e.g., actor, singer); (2a)-(2c): 
%mentions deleted by the three pruning heuristics (2014) 
(see Sec. 4), for three experiment datasets and New York 
Times annotation corpus (2014). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Text features used in this paper. "Turing Machine" is used as an example mention from "The band's former drummer Jerry Fuchs-who 

was also a member of Maserati, Turing Machine and The Juan MacLean-died after falling down an elevator shaft.". 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head></head><label></label><figDesc>to jointly optimize the objective O. One can also apply stochastic gradient descent to do online update. Type Inference. With the learned mention embed- dings {u i } and type embeddings {v k }, we perform</figDesc><table>Data sets 
Wiki 
OntoNotes BBN 
#Types 
113 
89 
47 
#Documents 
780,549 13,109 
2,311 
#Sentences 
1.51M 
143,709 
48,899 
#Training mentions 
2.69M 
223,342 
109,090 
#Ground-truth mentions 
563 
9,604 
121,001 
#Features 
644,860 215,642 
125,637 
#Edges in graph 
87M 
5.9M 
2.9M 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Statistics of the datasets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Study of typing performance on the three datasets. 

Text 

"... going to be an im-
minent easing of mon-
etary policy, " said 
Robert Dederick , chief 
economist at Northern 
Trust Co. in Chicago. 

...It's terrific for adver-
tisers to know the reader 
will be paying more , " 
said Michael Drexler , 
national media director 
at Bozell Inc. ad agency. 
Ground 
Truth 
organization, 
company 

person, 
person title 
FIGER 
organization 
organization 

WSABIE 
organization, 
company, 
broadcast 

organization, 
company, 
news company 
PTE 
organization 
person 

AFET 
organization, 
company 

person, 
person title 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Example output of AFET and the compared 
methods on two news sentences from OntoNotes dataset. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Example output of AFET and other methods on 
frequent/infrequent type from OntoNotes dataset. 

</table></figure>

			<note place="foot" n="3"> http://spotlight.dbpedia.org/</note>

			<note place="foot" n="4"> We used the published code for FIGER, ClusType, HNM, LINE, PTE, and DeepWalk, and implemented other baselines which have no public code. Our implementations yield comparable performance as those reported in the original papers.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgments</head><p>Research was sponsored in part by the U.S. Army Research Lab.</p><p>under Cooperative Agreement No. W911NF-09-2-0053 (NSCTA), DARPA DEFT No. FA8750-13-2-0041, National Science Foun-dation IIS-1017362, IIS-1320617, IIS-1354329, and IIS-1523198, HDTRA1-10-1-0120, and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov). The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning from partial labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothee</forename><surname>Cour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1501" to="1536" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Finet: Context-aware fine-grained named entity typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdalghani</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luna</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A hybrid neural model for type classification of entity mentions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A new entity salience task with millions of training examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dunietz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Facc1: Freebase annotation of clueweb corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Contextdependent fine-grained entity type tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nevena</forename><surname>Lazic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Huynh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.1820</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Refining event extraction through cross-document inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Entity-driven type hierarchy construction for freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jyun-Yu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pu-Jen</forename><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">No noun phrase left behind: detecting and typing unlinkable entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fine-grained entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel S Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclosky</surname></persName>
		</author>
		<title level="m">The stanford corenlp natural language processing toolkit. ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A survey of named entity recognition and classification. Lingvisticae Investigationes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Nadeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Classification with partial labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Clustype: Effective entity recognition and typing by relation phrase-based clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>El-Kishky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangbo</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic entity recognition and typing in massive text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>El-Kishky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Label noise reduction in entity typing by heterogeneous partial-label embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Xiang Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Wikilinks: A largescale cross-document coreference corpus labeled via links to wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno>UM-CS-2012-015</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reducing wrong labels in distant supervision for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shingo</forename><surname>Takamatsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pte: Predictive text embedding through large-scale heterogeneous text networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Convergence of a block coordinate descent method for nondifferentiable minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOTA</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="475" to="494" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Bbn pronoun coreference and entity type corpus. Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ada</forename><surname>Brunstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">112</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<pubPlace>Robert Belvin, Sameer Pradhan, Lance Ramshaw, and Nianwen Xue</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Ontonotes: A large training corpus for enhanced processing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Wsabie: Scaling up to large vocabulary image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Embedding methods for fine grained entity type classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nevena</forename><surname>Lazic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hyena: Hierarchical type classification for entity names</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Amir Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Personalized entity recommendation: A heterogeneous information network approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Sturt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Norick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Disambiguation-free partial label learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Ling</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
