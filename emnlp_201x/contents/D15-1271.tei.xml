<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adapting Coreference Resolution for Narrative Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quynh</forename><surname>Ngoc</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thi</forename><surname>Do</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Katholieke Universiteit Leuven</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Alabama at Birmingham</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Katholieke Universiteit Leuven</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adapting Coreference Resolution for Narrative Processing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Domain adaptation is a challenge for supervised NLP systems because of expensive and time-consuming manual annotated resources. We present a novel method to adapt a supervised coreference resolution system trained on newswire to short narrative stories without retraining the system. The idea is to perform inference via an Integer Linear Programming (ILP) formulation with the features of narratives adopted as soft constraints. When testing on the UMIREC 1 and N2 2 corpora with the-state-of-the-art Berkeley coreference resolution system trained on OntoNotes 3 , our inference substantially outperforms the original inference on the CoNLL 2011 metric.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Coreference resolution is the task of partitioning the set of mentions of discourse referents in a text into classes (or 'chains') corresponding to those referents <ref type="bibr" target="#b15">(Stede, 2011)</ref>. To solve the problem, con- textual and grammatical clues, as well as semantic information and world knowledge are necessary for either learning-based ( <ref type="bibr" target="#b2">Bengtson and Roth, 2008;</ref><ref type="bibr" target="#b16">Stoyanov et al., 2010;</ref><ref type="bibr" target="#b9">Haghighi and Klein, 2010)</ref> or rule-based ( <ref type="bibr" target="#b8">Haghighi and Klein, 2009;</ref><ref type="bibr" target="#b11">Lee et al., 2011</ref>) coreference systems. These systems draw on diverse information sources and complex heuristics to resolve pronouns, model discourse, determine anaphoricity, and identify semantically compati- ble mentions. However, this leads to systems with many hetorogenous parts that can be difficult to interpret or modify. <ref type="bibr">Durrett and Klein (2013)</ref> propose a learning- based, mention-synchronous coreference system to <ref type="bibr">1</ref>  tackle the various aspects of coreference by using the simplest possible set of features. Its advantage is that the system can both implicitly model impor- tant linguistic effects and capture other patterns in the data that are not easily teased out by hand. With a simple set of features including head/first/last words, preceding/following words, length, exact string match, head match, sentence/mention dis- tance, gender, number etc. and an efficient training using conditional log-likelihood augmented with a parameterized loss function optimization they report state-of-the-art results on CoNLL 2011 data.</p><p>But while CoNLL 2011 training data (OntoNotes) includes a few different source domains (newswire, weblogs, etc.), we witness significant drops in performance when systems trained on CoNLL 2011 are applied to new target domains such as narratives. Some linguistic effects and patterns that are very important for the target domain were never seen in the source domain on which the model was trained. In such cases, when adapting a coreference system to a new domain, it is necessary to incorporate these more complex linguistic features and patterns into the model. We propose a novel method to adopt the tar- get domain's features to a supervised coreference system without retraining the model. We present a case of transferring the system of <ref type="bibr">(Durrett and Klein, 2013)</ref>, which is trained on OntoNotes, to short narrative stories. The idea is to perform infer- ence via a linear programming formulation with the features of narratives adopted as soft constraints. Since the new features are incorporated only into the linear program, there is no need to retrain the original model. Our formulation models three phe- nomena that are important for short narrative sto- ries: local discourse coherence, which we model via centering theory constraints, speaker-listener relations, which we model via direct speech act con- straints, and character-naming, which we model via definite noun phrase and exact match constraints.</p><p>We also suggest a method to compute back pointers (as defined in <ref type="bibr">Durrett and Klein (2013)</ref>) globally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Berkeley coreference system</head><p>Given N mentions m 1 , ..., m N from a document x, each m i has an associated random variable a i taking values in the set of {1, ..., i − 1, N EW }. This variable specifies m i 's selected antecedent or indicates that it begins a new coreference chain. We call a i the back pointer of m i . A setting of all the back pointers, denoted by a = (a 1 , ..., a n ), implies an unique set of coreference chains that serve as the system output.</p><p>A log-linear model of the conditional distribu-</p><formula xml:id="formula_0">tion P (a|x) ∝ exp n i=1 f(i, a i , x) is used, where f(i, a i , x)</formula><p>is a feature function that examines the coreference decision a i for m i with document con- text x. If a i = N EW , the features indicate the suitability of the given mention to be anaphoric or not; when a i = j for some j, the features express aspects of the pairwise linkage, and examine rele- vant attributes of the anaphor i or the antecedent j. During training, the model is optimized with a parameterized loss function. The inference is sim- ple and efficient: because log P (a|x) decomposes linearly over mentions, a i = arg max a i P (a i |x) <ref type="bibr">(Durrett and Klein, 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Computing back pointers globally</head><p>A drawback of computing each a i locally is that the system does not take into account constraints from mentions outside of the (mention, antecedent) pairs. For example, given three mentions m 1 , m 2 , m 3 , if the system predicts that a 2 = 1 and a 3 = 2 (i.e., that m 2 's antecedent is m 1 and m 3 's antecedent is m 2 ), then m 3 will be automatically inferred as coreferent with m 1 . But if there is a clear clue that m 1 and m 3 are not coreferent, leveraging this clue could help avoid the error of linking m 3 to m 2 .</p><p>In this work, we perform inference via an ILP formulation which allows new linguistic features and patterns over mentions -not only (mention, antecedent) pairs -that were not part of training the original model to be adopted as constraints of the ILP problem.</p><p>Let U be the set of binary indicator variables corresponding to the values assigned to the back pointers. Specifically, u ij = 1 iff a i = j and</p><formula xml:id="formula_1">u ii = 1 iff a i = N EW .</formula><p>C is the set of K binary constraint indicator vari- ables indicating if linguistic constraints are violated. Specifically, c k,i,j = 1 iff the linguistic constraint C k is violated for the back pointer u ij . Each C k is associated with a penalty score ρ k .</p><p>We aim to maximize the objective function:</p><formula xml:id="formula_2">N i=1 i j=1 u ij P (a i = j|x) − K k=1 ρ k c k,i,j (1) Subject to:</formula><p>∀i :</p><formula xml:id="formula_3">i j=1 u ij = 1</formula><p>To incorporate coreference constraints, we intro- duce V, a set of binary variables indicating if two mentions are in the same coreference chain. For each pair of j &lt; i, a variable v ij is added to the ILP model, where v ij = 1 iff m i and m j are in the same chain. The definition of v ij in terms of u ij is encoded as the following ILP constraints:</p><formula xml:id="formula_4">∀j &lt; i : u ii + v ij ≤ 1 ∀j &lt; i : u ij − v ij ≤ 0 ∀k &lt; j &lt; i : u ij + v jk − v ik ≤ 1 ∀k &lt; j &lt; i : u ij − v jk + v ik ≤ 1 ∀j &lt; k &lt; i : u ij + v kj − v ik ≤ 1 ∀j &lt; k &lt; i : u ij − v kj + v ik ≤ 1</formula><p>For long texts, to reduce the complexity of the ILP problem, we set a threshold, windows v , so that v ij is only available if i − windows v ≤ j.</p><p>The framework of V variables allows corefer- ence constraints to be adopted easily by any coref- erence resolution system that provides scores for each possible back pointer value. For example, con- sider the Stanford exact string match sieve, which "requires an exact string match between a mention and its antecedent" ( <ref type="bibr" target="#b11">Lee et al., 2011</ref>). If we want to encourage such matches, for each pair j &lt; i where the two nominal mentions m i and m j have an ex- act string match, we would introduce a constraint indicator variable c exact,i,j and add the constraint v ij + c exact,i,j = 1 to the ILP model. The result would be that when the exact match constraint is violated and some v ij = 0, ILP would force the cor- responding c exact,i,j = 1 and the objective function would be reduced by ρ exact .</p><p>ILP has been used previously to enforce global consistency in coreference resolution ( <ref type="bibr">Finkel and Manning, 2008;</ref><ref type="bibr">Denis and Baldridge, 2007;</ref><ref type="bibr" target="#b0">Barzilay and Lapata, 2006</ref>). These models were de- signed for an all-pairs classification approach to coreference resolution, and are not directly appli- cable to the back pointer approach of <ref type="bibr">(Durrett and Klein, 2013)</ref>. But the back pointer approach allows features to be expressed more naturally using local context, rather than requiring, for example, judg- ments of whether two pronouns separated by many paragraphs are coreferent. Moreover, our ILP for- mulation is the only one to consider the problem of adapting to another domain and incorporating new features without retraining the original model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Centering theory constraints</head><p>Pronouns, in particular, have a huge effect on in- formation flow across sentences. Since they are almost void of meaning (only signal gender and number of the antecedent), the discourse referent to be picked up must be particularly salient, so that it can be readily identified by the reader <ref type="bibr" target="#b15">(Stede, 2011)</ref>. The discourse center hypothesis <ref type="bibr">(HudsonD'Zmura, 1988</ref>) states that at any point in discourse understanding, there is one single entity that is the most salient discourse referent at that point. This referent is called the center. Centering theory is a key element of the discourse center hypothesis used in anaphora resolution ( <ref type="bibr" target="#b7">Grosz et al., 1995)</ref>. Beaver (2004) reformulates the centering theory in terms of Optimality Theory ( <ref type="bibr" target="#b14">Prince and Smolensky, 2004</ref>). Six ranked constraints -Agree, Disjoint, ProTop, FamDef, Cohere and Align -are used to make anaphora decisions. We adopt four of these constraints in our ILP model as follows:</p><p>Disjoint "Co-arguments of a predicate 4 are dis- joint." For each j &lt; i such that m i and m j are subject and object arguments of a non-reflexive predicate, we introduce a constraint indicator vari- able c disjoint,i,j , and add the ILP constraint v ij − c disjoint,i,j = 0.</p><p>ProTop "The topic of a sentence which is the en- tity referred to in both the current and the previous sentence, is pronominalized." If a sentence con- tains pronouns then at least one of its pronouns is coreferent with a mention in the previous sentence. For each sentence t containing pronouns, we in- troduce a constraint indicator variable c protop,t,t−1 , and add the ILP constraints:</p><formula xml:id="formula_5">∀i ∈ P t , ∀j ∈ M t−1 : v ij + c protop,t,t−1 ≤ 1 c protop,t,t−1 + i∈Pt j∈M t−1 v ij ≥ 1</formula><p>4 A word that evokes a semantic frame (event) in a sentence. P t is the set of all pronouns in sentence t. M t−1 is the set of all mentions in sentence t − 1 5 .</p><p>FamDef "No new information about the refer- ent is provided by the definite." We consider only pronouns here, though the original FamDef also includes definite descriptions and proper names <ref type="bibr" target="#b1">(Beaver, 2004</ref>). For each pronoun m i , we intro- duce a constraint indicator variable c f amdef,i,i and add the ILP constraint u ii − c f amdef,i,i = 0.</p><p>Align "The topic is in subject position." More specifically, the topic of a sentence is pronominal- ized and prefers the subject position over other positions. For each sentence containing only one pronoun m i , if the previous sentence has only one verbal semantic frame and m j is its subject, we introduce a constraint indicator variable c align,i,j , and add the ILP constraint v ij + c align,i,j = 1.</p><p>Note: The ProTop, FamDef and Align constraints are not applied to sentences containing quotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Direct speech constraints</head><p>Direct speech acts (with quotation marks) are de- tected and attached to the closest verbal commu- nication semantic frames. For each direct speech act q t , we call the mentions m st , m ot the speaker and listener of q t if they play the subject and ob- ject roles respectively in the semantic frame of q t . We detect the set of subject pronouns 6 inside the quote marks of q t and name it S t . The set of all mentions that refer to the speaker of q t is SPEAKER t = {m st } ∪ S t . For each (m i , m j ) ∈ SPEAKER t × SPEAKER t with i &gt; j, we introduce a constraint indicator variable c subject,i,j , and add the ILP constraint v ij + c subject,i,j = 1.</p><p>Similarly, O t is the set of object pronouns 7 in- side the quote marks of q t . The set of all men- tions that refer to the listener of q t is LISTENER t = {m ot }∪O t . For each pair of mentions (m i , m j ) ∈ LISTENER t × LISTENER t with i &gt; j, we introduce a constraint indicator variable c object,i,j , and add the constraint v ij + c object,i,j = 1.</p><p>If a conversation is detected (a sequence of "question" and "answer" semantic frames), the sub- ject of the "question" is coreferent with the object of the "answer" and vice versa. For each pair of di- rect speech acts (q t , q t+1 ) that is a ("question", "an- swer") pair, for each pair of mentions (m i , m j ) ∈ {LISTENER t+1 × SPEAKER t } ∪ {SPEAKER t+1 × LISTENER t }, we introduce a constraint indicator variable c conversation,i,j and add the ILP constraint v ij + c conversation,i,j = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UMIREC (Tales) N2 (Hadith) MUC BCUB CEAFE AVG MUC BCUB CEAFE AVG</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Definite noun phrase and exact match constraints</head><p>In short narrative stories, characters are frequently named via proper names, pronouns or definite noun phrases <ref type="bibr" target="#b17">(Toolan, 2009)</ref>. Character names are re- peated regularly over the whole stories. A character is often first presented as an indefinite noun phrase (such as "a woman"), then later as a definite noun phrase (such as "the woman"). In this work we introduce the definite noun phrase constraint: For each pair j &lt; i, if m j is the indefinite form and m i is the definite form of the same noun phrase, to en- force that m i and m j are coreferent, we introduce a constraint indicator variable c name,i,j , and add the ILP constraint v ij + c name,i,j = 1. To boost the identification of characters in the stories, the def- inite noun phrase constraint is used together with the exact match constraint (See Section 3) applied to noun phrases and proper nouns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiment</head><p>We test our model on 30 English folktales from the UCM/MIT Indications, Referring Expressions, and Coreference (UMIREC) Corpus v1.1 <ref type="bibr" target="#b5">(Finlayson and Hervs, 2010)</ref>, and 64 text stories from the Ha- dith section of the Narrative Networks (N2) Cor- pus ( <ref type="bibr" target="#b6">Finlayson et al., 2014</ref>). The texts are prepro- cessed using the Stanford sentence splitter (Man- ning et al., 2014) 8 and the Berkeley coreference system's preprocessor. The Berkeley coreference system is trained on OntoNotes (newswire, broad-cast news/conversation, and web texts). We use Gurobi 9 to solve our ILP problem, and the Lund semantic role labeler <ref type="bibr" target="#b3">(Björkelund et al., 2009</ref>) to detect semantic frames. Note that in our imple- mentation, "subject" and "object" used in Sec- tion 4 and Section 5 refer to "subject role" and "object role" of the semantic frames respectively. We use a separate section of the N2 corpus, the Inspire story texts, as the held-out validation set used for parameter tuning, resulting in</p><formula xml:id="formula_6">window v = 40, ρ subject = ρ object = ρ conversation = ρ def inite = ρ exact =ρ disjoint =1, ρ protop =0.2, ρ f amdef =0.2, ρ align =0.1.</formula><p>We compare our ILP inference (ILPI) to the standard Berkeley coreference system (BER) with both gold and predicted mentions. <ref type="table">Table 1</ref> shows that our inference improves the MUC, BCUB and CEAFE scores on both datasets, especially when using gold mentions <ref type="bibr">10</ref> . The average ILP running times are 42.37s per UMIREC document and 22.7s per N2 document on a Core I7 2.3 GHz quad-core computer. <ref type="table" target="#tab_3">Table 2</ref> shows the effects of each con- straint type when used alone. Surprisingly, the sim- plest constraint type (definite &amp; exact match con- straints) gives us the best improvement especially in terms of CEAFE score. This may be because definite &amp; exact match constraint links mentions in the whole document, while the centering theory and direct speech act constraints are more local. And since short narrative stories often have a small set of characters (usually represented by definite noun phrases or proper nouns), when these charac- ters are linked correctly, the coreference resolution result is improved considerably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion</head><p>Our method provides a promising solution when retraining a system is impossible or difficult. How- ever, it may raise a question of the computing cost  for tuning penalty scores especially with the large number of constraints. In such these cases, dividing the constraints into different groups where all con- straints in the same group have the same penalty score may help to limit the number of scores that need to be tuned. In our case study, the system is not very sensitive to the values of the penalty parameters. If we set all the penalty scores to 1, the final AVG results on UMIREC and N2 corpus are 66.05 and 66.68 respectively <ref type="bibr">11</ref> . Those scores are a bit less than the scores obtained after tuning parameters but still higher than the results obtained without ILP. Regardless, it's true that the proposed ILP approach is not necessarily less costly in some settings, but it can be applied to any coreference system that provides back pointers, not just the Berkeley one.</p><p>Instead of adopting features of the target domain as soft constraints as in our method, one may con- sider to use them as linguistic features and retrain the model. A simple domain adaptation approach by augmenting the feature space <ref type="bibr" target="#b4">(Daumé et al., 2010</ref>) based on a limited set of annotated data in the target domain might be an alternative solution. But note that our approach does not use any anno- tated data of the target domain. Also, an unsuper- vised system as ( <ref type="bibr" target="#b11">Lee et al., 2011</ref>) might encode the target domain features (exact match noun phrases, direct speech act) as sieves (hard), but with the soft constraints, our system is more flexible when making global decisions.</p><p>Our approach can be applied to another target do- main, such as bio-medical domain where we have entities and a list of acronyms in texts. Constrain- ing the entities with their acronyms might help to improve the coreference resolution for bio-medical texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>We have proposed a novel approach to adapt a su- pervised coreference resolution system trained on newswire domain to short narrative stories without <ref type="bibr">11</ref> with gold mentions retraining the system by modeling the inference as an ILP problem with the features of narratives adopted as soft constraints. Three phenomena that are important for short narrative stories: local dis- course coherence, speaker-listener relations, and character-naming are modeled via centering theory, direct speech act and definite noun phrase &amp; ex- act match constraints. We obtain promising results when transferring the Berkeley coreference resolu- tion trained on OntoNotes to UMIREC (Tales) and N2 (Hadith). We find that the simplest constraints, definite noun phrase &amp; exact match constraints, are the most effective in our case study assuming the gold mentions. We also suggest an approach to compute back pointers in coreference resolution globally.</p><p>adaptation. In Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Process- ing, DANLP 2010, pages 53-59, Stroudsburg, PA, USA. Association for Computational Linguistics.</p><p>Pascal Denis and Jason <ref type="bibr">Baldridge. 2007</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>ILPI with gold mentions 84.16 65.65 50.47 66.76 80.47 65.53 54.06 66.69 BER with gold mentions 80.58 60.96 42.48 61.34 76.28 62.66 45.48 61.47 ILPI with predicted mentions 73.32 59.18 37.54 56.68 66.13 62.55 40.51 56.40 BER with predicted mentions 72.71 58.12 35.76 55.53 64.87 59.60 37.96 54.14</figDesc><table>Table 1: ILPI and BER inference results on UMIREC (Tales) and N2 (Hadith) data. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>Constraint MUC BCUB CEAFE AVG Centering theory 81.15 61.80 43.01 61.99 Direct speech 81.26 62.74 42.93 62.31 Definite &amp; Exact 83.09 62.85 49.60 65.18</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Effects of different constraints on ILP inference on UMIREC (Tales) with gold mentions.</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="5"> We can relax the constraint by replacing Mt−1 with Mt−1 ∪ Mt−2 ∪ Mt−3 6 (&quot;I&quot;, &quot;me&quot;, &quot;my&quot;, &quot;mine&quot;, &quot;myself&quot;) if mst is singular or (&quot;we&quot;, &quot;us&quot;, &quot;our&quot;, &quot;ourself&quot;) if mst is plural 7 (&quot;you&quot;, &quot;your&quot;, &quot;yours&quot;, &quot;yourself&quot;)</note>

			<note place="foot" n="8"> If two direct speech acts enclosed in quotation marks are adjacent and one is placed at the end of a sentence, we separate them into two different sentences.</note>

			<note place="foot" n="9"> http://www.gurobi.com/ 10 Using gold mentions, our method also improves the score on the CoNLL 2011 test set by +1.11% (AVG: 72.46).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work acknowledges the financial support of the Future and Emerging Technologies (FET) programme within the Seventh Framework Pro-gramme for Research of the European Com-mission, under FET-Open grant number 295703 (FET project "Machine Understanding for in-teractive StorytElling" (MUSE) http://www. muse-project.eu/).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Aggregation via set partitioning for natural language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL &apos;06</title>
		<meeting>the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL &apos;06<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="359" to="366" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The optimization of discourse anaphora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beaver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistics and Philosophy</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="56" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Understanding the value of features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bengtson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;08</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;08<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="294" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multilingual semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Love</forename><surname>Hafdell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, CoNLL &apos;09</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning: Shared Task, CoNLL &apos;09<address><addrLine>Stroudsburg, PA, USA. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Frustratingly easy semi-supervised domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Iii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Ucm/mit indications, referring expressions, and co-reference corpus v1.1 (umirec corpus). MIT CSAIL Work Product</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hervs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The n2 corpus: A semantically annotated collection of islamist extremist stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffry</forename><forename type="middle">R</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">R</forename><surname>Halverson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 9th Language Resources and Evaluation Conference (LREC)</title>
		<meeting><address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Centering: A framework for modelling the local coherence of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Weinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="226" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simple coreference resolution with rich syntactic and semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1152" to="1161" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Coreference resolution in a modular, entity-centered model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT &apos;10</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="385" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The structure of discourse and anaphore resolution: The discourse center and the roles of nouns and pronouns. Unpublished doctoral dissertation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hudson-D&amp;apos;zmura</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stanford&apos;s multi-pass sieve coreference resolution system at the conll-2011 shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Peirsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task, CONLL Shared Task &apos;11</title>
		<meeting>the Fifteenth Conference on Computational Natural Language Learning: Shared Task, CONLL Shared Task &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="28" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd</title>
		<meeting>52nd</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<imprint>
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Optimality theory: Constraint interaction in generative grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Smolensky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Wiley-Blackwell</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Discourse processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Coreference resolution with reconcile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Buttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hysom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010 Conference Short Papers</title>
		<meeting>the ACL 2010 Conference Short Papers<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="156" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Narrative Progression in the Short Story: A Corpus Stylistic Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Toolan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>John Benjamins Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
