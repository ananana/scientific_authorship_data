<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:34+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cheap Translation for Cross-Lingual Named Entity Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Mayhew</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana-Champaign</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana-Champaign</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana-Champaign</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cheap Translation for Cross-Lingual Named Entity Recognition</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2536" to="2545"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
					<note>201 N. Goodwin Urbana, Illinois, 61801</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent work in NLP has attempted to deal with low-resource languages but still assumed a resource level that is not present for most languages, e.g., the availability of Wikipedia in the target language. We propose a simple method for cross-lingual named entity recognition (NER) that works well in settings with very minimal resources. Our approach makes use of a lexicon to &quot;translate&quot; annotated data available in one or several high resource language(s) into the target language, and learns a standard monolingual NER model there. Further, when Wikipedia is available in the target language, our method can enhance Wikipedia based methods to yield state-of-the-art NER results; we evaluate on 7 diverse languages, improving the state-of-the-art by an average of 5.5% F1 points. With the minimal resources required , this is an extremely portable cross-lingual NER approach, as illustrated using a truly low-resource language, Uyghur.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, interest in the natural language processing (NLP) community has expanded to in- clude multilingual applications. Although this uptick of interest has produced diverse annotated corpora, most languages are still classified as low- resource. In order to build NLP tools for low- resource languages, we either need to annotate data (a costly exercise, especially for languages with few native speakers), or find a way to use an- notated data in other languages in service to the cause. We refer to the latter techniques as cross- lingual techniques.</p><p>In this paper, we address cross-lingual named  <ref type="table">Table 1</ref>: We show dramatic improvement on 3 Eu- ropean languages in a low-resource setting. More detailed results in <ref type="table" target="#tab_3">Table 2</ref> show that this improve- ment continues to a wide variety of languages. The baseline is a simple direct transfer model. The pre- vious state-of-the-art (SOA) is  entity recognition (NER). Prior methods (de- scribed in detail in Section 2) depend heavily on limited and expensive resources such as Wikipedia or large parallel text. Concretely, there are about 3800 written languages in the world. <ref type="bibr">1</ref> Wikipedia exists in about 280 languages, but most versions are too sparse to be useful. Parallel text may be found on an ad-hoc basis for some languages, but it is hardly a general solution. Religious texts, such as the Bible and the Koran, exist in many lan- guages, but the unique domain makes them hard to use. This leaves the vast majority of the world's languages with no general method for NER.</p><p>We propose a simple solution that requires only minimal resources. We translate annotated data in a high-resource language into a low-resource lan- guage, using just a lexicon. <ref type="bibr">2</ref> We refer to this as cheap translation, because in general, lexicons are much cheaper and easier to find than parallel text ( <ref type="bibr" target="#b15">Mausam et al., 2010)</ref>.</p><p>One of the biggest efforts at gathering lexicons is Panlex ( <ref type="bibr" target="#b10">Kamholz et al., 2014</ref>), which has lex- icons for 10,000 language varieties available to download today. The quality and size of these dic-tionaries may vary, but in Section 5.3 we showed that even small dictionaries can give improve- ments. If there is no dictionary, or if the quality is poor, then the Uyghur case study outlined in Sec- tion 6 suggests that effort is best spent in develop- ing a high-quality dictionary, rather than gathering questionable-quality parallel text.</p><p>We show that our approach gives non-trivial scores across several languages, and when com- bined with orthogonal features from Wikipedia, improves on state-of-the-art scores. <ref type="table">Table 1</ref> com- pares a simple direct transfer baseline, the previ- ous state-of-the-art in cross-lingual NER, and our proposed algorithm. For these languages, we beat the baseline by 25.4 points, and the state-of-the-art by 5.9 points. In addition, we found that translat- ing from a language related to the target language gives a further boost. We conclude with a case study of a truly low-resource language, Uyghur, and show a good score, despite having almost no target language resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There are two main branches of work in cross- lingual NLP: projection across parallel data, and language independent methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Projection</head><p>Projection methods take a parallel corpus between source and target languages, annotate the source side, and push annotations across learned align- ment edges. Assuming that source side annota- tions are of high quality, success depends largely on the quality of the alignments, which depends, in turn, on the size of the parallel data.</p><p>There is work on projection for POS tagging ( <ref type="bibr" target="#b30">Yarowsky et al., 2001;</ref><ref type="bibr" target="#b2">Das and Petrov, 2011;</ref><ref type="bibr" target="#b4">Duong et al., 2014</ref>), NER ( <ref type="bibr" target="#b29">Wang and Manning, 2014;</ref><ref type="bibr" target="#b11">Kim et al., 2012;</ref><ref type="bibr" target="#b6">Ehrmann et al., 2011;</ref><ref type="bibr" target="#b17">Ni and Florian, 2016)</ref>, mention detection ( <ref type="bibr" target="#b31">Zitouni and Florian, 2008)</ref>, and parsing ( <ref type="bibr" target="#b8">Hwa et al., 2005;</ref><ref type="bibr" target="#b16">McDonald et al., 2011</ref>).</p><p>For NER, the received wisdom is that paral- lel projection methods work very well, although there is no consensus on the necessary size of the parallel corpus. Most approaches require mil- lions of sentences, with a few exceptions which require thousands. Accordingly, the drawback to this approach is the difficulty of finding any paral- lel data, let alone millions of sentences. Religious texts (such as the Bible and the Koran) exist in a large number of languages, but the domain is too far removed from typical target domains (such as newswire) to be useful. As a simple example, the Bible contains almost no entities tagged as 'orga- nization'. We approach the problem with the as- sumption that little to no parallel data is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Language Independent</head><p>The second common tool for cross-lingual NLP is to use language independent features. This is of- ten called direct transfer, in the sense that a model is trained on one language and then applied with- out modification on a dataset in a different lan- guage. Lexical or lexical-derived features are typ- ically not used unless there is significant vocabu- lary overlap between languages.</p><p>Täckström et al. <ref type="formula">(2012)</ref> experiments with di- rect transfer of dependency parsing and NER, and showed that using word cluster features can help, especially if the clusters are forced to conform across languages. The cross-lingual word clusters were induced using large parallel corpora.</p><p>Building on this work, Täckström (2012) fo- cuses solely on NER, and includes experiments on self-training and multi-source transfer for NER.</p><p>Tsai and Roth (2016) link words and phrases to entries in Wikipedia and use page categories as features. They showed that these wikifier fea- tures are strong language independent features. We build on this work, and use these features in our experiments. <ref type="bibr" target="#b0">Bharadwaj et al. (2016)</ref> build a transfer model using phonetic features instead of lexical fea- tures. These features are not strictly language- independent, but can work well when languages share vocabulary but with spelling variations, as in the case of Turkish, Uzbek, and Uyghur.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Others</head><p>In a technique similar to ours, <ref type="bibr" target="#b1">Carreras et al. (2003)</ref> use Spanish resources for Catalan NER. They translate the features in the weight vector, which has the flavor of a language independent model with the lexical features of a projection model. Our work is a natural extension of this pa- per, but explores these techniques on many more languages, showing that with some modifications, it has a broad applicability. Further, we experi- ment with orthogonal features, and with combin- ing multiple source languages to get state of the art results on standard datasets. <ref type="bibr" target="#b9">Irvine and Callison-Burch (2016)</ref> build a ma- chine translation system for low-resource lan- guages by inducing bilingual dictionaries from monolingual texts. <ref type="bibr" target="#b14">Koehn and Knight (2001)</ref> experiment with vary- ing knowledge levels on the task of translating German nouns in a small parallel German-English corpus. A lexicon along with monolingual text can correctly translate 79% of the nouns in the evalua- tion set. They reach a score of 89% when a parallel corpus is available along with a lexicon, but also comment on the scarcity of parallel corpora.</p><p>The main takeaways from the viewpoint of our work are a) word level translation can be effec- tive, at least for nouns, and b) obtaining the correct word pair is more difficult than choosing between a set of options.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our method: Cheap Translation</head><p>We create target language training data by trans- lating source data into the target language. It is ef- fectively the same as standard phrase-based statis- tical machine translation systems (such as MOSES ( <ref type="bibr">Koehn et al., 2007)</ref>), except that the translation table is not induced from expensive parallel text, but is built from a lexicon, hence the name cheap translation.</p><p>The entries in our lexicon contain word-to-word translations, as well as word-to-phrase, phrase- to-word, and phrase-to-phrase translations. En- tries typically do not have any further information, such as part of speech or sense disambiguation. The standard problems related to ambiguity in lan- guage apply: a source language word may have several translations, and several source language words may have the same translation.</p><p>We are mostly concerned with the problem of multiple translations of a source language word. For example, in the English-Spanish lexicon, the English word woman translates into about 50 dif- ferent words, with meanings ranging from woman, to female golfer, to youth. Although all candidates might be technically correct, we are interested in the most prominent translation. To estimate this, we gathered cooccurrence counts of each source- target word pair in the lexicon. For Spanish, in the case of woman, the most probable translation is mujer, because it shows up in other contexts in the dictionary, such as farm woman or young woman, whereas translations such as joven cooccur infre- quently with woman. We normalize these cooc-</p><formula xml:id="formula_0">Algorithm 1 Our translation algorithm Input D E : Annotated data in E L: Lexicon between E-F Returns D F : Annotated data in F 1: for ∀w i ∈ D E do 2: p = w i w i+1 ...w i+j Window of size j 3:</formula><p>while p not in L and j ≥ 0 do Increment i by length of p 16: end for currence counts in each candidate set, and call this the prominence score.</p><p>With these probabilities in hand, we have effec- tively constructed a phrase translation table. We use a simple greedy decoding method (as shown in Algorithm 1) where options from the lexicon are resolved by a language model multiplied by the prominence score of each option. We use SRILM ( <ref type="bibr" target="#b21">Stolcke et al., 2002</ref>) trained on Wikipedia (al- though any large monolingual corpus will do).</p><p>During decoding, once we have chosen a candi- date, we copy all labels from the source phrase to the target phrase. Since the translation is phrase- to-phrase, we can copy gold labels directly, 3 with- out worrying about getting good alignments. The result is annotated data in the target language.</p><p>Notice that the algorithm allows for no reorder- ing beyond what exists in the phrase-to-phrase entries of the lexicon. Compared to phrase- tables learned from massive parallel corpora, our lexicon-based phrase tables are not large enough or expressive enough for robust reordering. We leave explorations of reordering to future work.</p><p>See <ref type="figure">Figure 1</ref> for a representative example of translation from English to Turkish, with a hu- man translation as reference. There are sin- Correct: Nikaragua Cumhurbaşkanı Violeta Chamorro ABD'ye uçacaktı <ref type="figure">Figure 1</ref>: Demonstration of word translation. The top is English, the bottom is Turkish. Lines represent dictionary translations (e.g. the translates to bir). Correct is the correct translation. This illustrates congruence in named entity patterns between languages, as well as some errors we are prone to make.</p><p>gle words translated into phrases, named entities copied over verbatim, and phrases translated into single words. Some words are translated correctly (President into Cumhurbas¸kanıCumhurbas¸kanı) and some incor- rectly (fly into iki tas¸ıntas¸ın arasında, which loosely translates to 'between two stones'). We see ig- norance of morphology (seen in translation of United States), and confused word order. But in spite of all these mistakes, the context around the entities, which is what matters for NER, is reasonably well-preserved. Notably, the word President/Cumhurbas¸kanıCumhurbas¸kanı is a strong context fea- ture for both LOC (Nicaragua) and PER (Violeta Chamorro) in both languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>Before we describe our experiments, we describe some of the tools we used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Lexicons</head><p>We use lexicons provided by <ref type="bibr" target="#b19">(Rolston and Kirchhoff, 2016)</ref>, which are harvested from PanLex, Wiktionary, and various other sources. There are 103 lexicons, each mapping between English and a target language. These vary in size from 56K en- tries to 1.36M entries, as shown in the second row of <ref type="table" target="#tab_3">Table 2</ref>. There are also noisy translations. Some entries consist of a single English letter, some are morphological endings, others are misspellings, others are obscure translations of metaphors, and still others are just wrong.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Datasets</head><p>We use data from CoNLL2002/2003 shared tasks <ref type="bibr" target="#b24">(Tjong Kim Sang, 2002;</ref><ref type="bibr" target="#b26">Tjong Kim Sang and De Meulder, 2003</ref>). The 4 languages represented are English, German, Spanish, and Dutch. All training is on the train set, and testing is on the test set (TestB). The evaluation metric for all ex- periments is phrase level F1, as explained in Tjong Kim Sang <ref type="bibr">(2002)</ref>.</p><p>In order to experiment on a broader range of languages, we also use data from the RE- FLEX ( <ref type="bibr" target="#b20">Simpson et al., 2008)</ref>, and LORELEI projects. From LORELEI, we use Turkish and Hausa <ref type="bibr">4</ref> From REFLEX, we use Bengali, Tamil, and Yoruba. <ref type="bibr">5</ref> We use the same set of test docu- ments as used in .</p><p>We also use Hindi and Malayalam data from FIRE 2013, <ref type="bibr">6</ref> pre-processed to contain only PER, ORG, and LOC tags.</p><p>While several of these languages are decidedly high-resource, we limit the resources used in or- der to show that our techniques will work in truly low-resource settings. In practice, this means gen- erating training data where high-quality manually annotated data is already available, and using dic- tionaries where translation is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">NER Model</head><p>In all of our work we use the Illinois NER system (Ratinov and Roth, 2009) with standard features (forms, capitalization, affixes, word prior, word af- ter, etc.) as our base model. We train Brown clus- ters on the entire Wikipedia dump for any given language (again, any monolingual corpus will do), and include the multilingual gazetteers and wiki- fier features proposed in .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We performed two different sets of experiments: first translating only from English, then translating from additional languages selected to be similar to the target language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Translation from English</head><p>We start by translating from the highest resourced language in the world, English. We first show that our technique gives large improvement over a sim- ple baseline, then combine with orthogonal fea- tures, then compare against a ceiling obtained with Google Translate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline Improvement</head><p>To get the baseline, we trained a model on English CoNLL data (train set), and applied the model directly to the target language, mismatching lex- ical features notwithstanding. We did not use gazetteers in this approach. For the non-Latin script languages, Tamil and Bengali, we transliter- ated the entire English corpus into the target script. These results are in <ref type="table" target="#tab_3">Table 2</ref>, row "Baseline".</p><p>In our approach ("Cheap Translation"), for each test language, we translated the English CoNLL data (train set) into that language. The first row of <ref type="table" target="#tab_3">Table 2</ref> shows the coverage of each dictionary. For example, in the case of Spanish, 90.94% of the words were translated into Spanish. This gives an average of 14.6 points F1 improvement over the baseline. This shows that simple translation is sur- prisingly effective across the board. The improve- ment is most noticeable for Bengali and Tamil, which are languages with non-Latin script. This mostly shows that the trivial baseline doesn't work across scripts, even with transliteration. Spanish shows the least improvement over the baseline, which may be because English and Spanish are so similar that the baseline is already high.</p><p>We found that we needed to normalize the Yoruba text (that is, remove all pronunciation sym- bols on vowels) in order to make the data less sparse. Since the training data for Bengali and Tamil never shares a script with the test data, we omit using the word surface form as a feature. This is indicated by the † in <ref type="table" target="#tab_3">Table 2</ref>. Brown clusters, which implicitly use the word form, are still used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wikifier Features</head><p>Now we show that our approach is also orthogo- nal to other approaches, and can be combined with great effect. Wikifier features (  are obtained by grounding words and phrases to English Wikipedia pages, and using the categories of the linked page as NER features for the surface text. Our approach can be naturally combined with wikifier features. We show results in <ref type="table" target="#tab_3">Table 2</ref>, in the row marked 'Cheap Translation+Wiki'.</p><p>Using wikifier features improves scores for all 7 languages. Further, for all languages we beat , with an average of 3.92 points F1 improvement. For the three European languages (Dutch, German, and Spanish), we have an aver- age improvement of 4.8 points F1 over . This may reflect the fact that English is more closely related to European languages than Indian or African languages, in terms of lexical similarities, word order, and spellings and distri- bution of named entities. This suggests that it is advantageous to select a source language similar to the target language (by some definition of simi- lar). We explore this hypothesis in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Google Translate</head><p>Since we are performing translation, we compared against a high-quality translation system to get a ceiling. We used Google Translate to translate the English CoNLL training data into the target language, sentence by sentence. We aligned the source-target data using fast align ( <ref type="bibr" target="#b5">Dyer et al., 2013)</ref>, and projected labels across alignments. <ref type="bibr">7</ref> Since this is high-quality translation, we treat it as an upper bound on our technique, but with the caveat that the alignments can be noisy given the relatively small amount of text. This introduces a source of noise that is not present in our technique, but the loss from this noise is small compared to the gain from the high-quality translation. As with the other approaches, we found that Brown cluster features were an important signal.</p><p>Surprisingly, Google Translate beats our basic approach with a margin of only 4.3 points. De- spite the na¨ıvetena¨ıvete of our approach, we are relatively close to the ceiling. Further, Google Translate is limited to 103 languages, whereas our approach is limited only by available dictionaries. In low- resource settings, such as the one presented in Sec- tion 6, Google Translate is not available, but dic- tionaries are available, although perhaps only by pivoting through a high-resource language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Translation from Similar Languages</head><p>Observing that English as a source works well for European languages, but not as well for non- European languages, we form a key hypothe- sis: cheap translation between similar languages should be better than between different languages. There are several reasons for this. First, sim- ilar languages should have similar word order- ings. Since we do no reordering in translation, this means the target text has a better chance of a   coherent ordering. Second, in case of dictionary misses, vocabulary common between languages will be correct in the target language. This requires two new resources: annotated data in a similar language S, and a lexicon that maps from S to T , the target language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data in other languages</head><p>For most target languages, English is not the clos- est language, and it is likely that there exists an annotated dataset in a closer language. There are annotated datasets available in many languages with a diversity of script and family. We have datasets annotated in about 10 different languages, although more exist.</p><p>One caveat is that the source dataset must have a matching tagset with the target dataset. At present, we accept this as a limitation, with the understand- ing that there is a common set of coarse-grained tags that is widely used (PER, ORG, LOC). We leave further exploration to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pivoting Lexicons</head><p>Although we cannot expect to find lexicons be- tween all pairs of languages, we can usually expect that a language will have at least one lexicon with a high-resource language. Often that language is English. We can use this high-resource language as a pivot to transitively create an S-T dictionary, although perhaps with some loss of precision.</p><p>Assume we want a Turkish-Bengali lexicon and we have only English-Bengali and English- Turkish lexicons. We collect all English words that appear in both dictionaries. Each such En- glish word has two sets of candidate translations, one set in Turkish, the other in Bengali. To cre- ate transitive pairs, we take the Cartesian product of these two sets of candidate translations. This will create too many entries, some of which will be incorrect, but usually the correct entry is there.</p><p>Notice also that the resulting dictionary con- tains only those English words that appear in both original dictionaries. If either of the original dic- tionaries is small, the result will be smaller still.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source Selection and Combination</head><p>To choose a related source language, we used syntactic features of languages retrieved from the World Atlas of Language Structures (WALS) <ref type="bibr" target="#b3">(Dryer and Haspelmath, 2013)</ref>. Each language is represented as a binary vector with each index in- dicating presence or absence of a syntactic feature in that language. We used the feature set called syntax knn, which includes 103 syntactic features, such as subject before verb, and possessive suffix, and uses k-Nearest Neighbors to predict missing values. We measure similarity as cosine distance between language vectors.</p><p>In the absence of criteria for a similarity cut- off, we chose to include only the top most similar language as source for that target language. The results of this similarity calculation are shown in <ref type="table" target="#tab_4">Table 3</ref>. For example, when the target language is Dutch, German is the closest. We also included English in the training, as the highest resource lan- guage, and with the highest quality dictionaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Our results are in <ref type="table" target="#tab_3">Table 2</ref>, in the row named 'Best Combination'. The average over all languages sur- passes the English-source average by 5.4 points, and also beats ( ). We also add wik- ifier features, and report results in row 'Best Com- bination+Wiki.' This shows improvement on all but Spanish, with an average improvement of 5.58 points F1 over . To the best of our knowledge, these are the best cross-language settings scores for all these datasets.</p><p>While these scores are lower than those seen on typical NER tasks (70-90% F1), we emphasize first that cross-lingual scores will necessarily be much lower than monolingual scores, and second that these are the best available given the setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Dictionary Ablation</head><p>The most expensive resource we require is a lex- icon. In this section, we briefly explore what ef- fect the size of the lexicon has on the end result. Using Turkish, we vary the size of the dictionary by randomly removing entries. The sizes vary from no entries to full dictionary (rows 'Baseline' and 'Cheap Translation' in <ref type="table" target="#tab_3">Table 2</ref>, respectively), with several gradations in the middle. With each reduced dictionary, we translate from English to generate Turkish training data as in Section 5.1. As before, we train an NER model on the gener- ated data, and test on the Turkish test data. Results are shown in <ref type="figure">Figure 2</ref>.</p><p>Interestingly, we see improvement over the baseline even with only 500 entries. This improve- ment continues until 125K entries. It is important to note that only a small number of dictionary en- tries -words that typically show up in the contexts of named entities, such as president, university or town -are likely to be useful. The larger the dic- tionary, the more likely these valuable entries are present. Further, our random removal process may unfairly prioritize less common words, compared to a manually compiled dictionary which would prioritize common words. It is likely that a small   <ref type="figure">Figure 2</ref>: Effect of dictionary size on F1 score for Turkish. Each column is an experiment with a ran- domly reduced dictionary. The orange bars repre- sent how much of the corpus is translated.</p><p>but carefully constructed manual dictionary could have a large impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Case study: Uyghur</head><p>We have shown in the previous sections that our method is effective across a variety of languages.</p><p>However, all of the tested languages have some re- sources, most notably, Google Translate and rea- sonably sized Wikipedias. In this section, we show that our methods hold up on a truly low-resource language, Uyhgur. Uyghur is a language native to northwest China, with about 25 million speakers. 8 It is a Turkic lan- guage, and is related most closely to Uzbek, al- though it uses an Arabic writing system. Uyghur is not supported by Google Translate, and the Uyghur Wikipedia has less than 3,000 articles. In contrast, the smallest Wikipedia size language in our test set is Yoruba, with 30K articles. Because of the small Wikipedia size, we do not use any wikifier features.</p><p>We did this work as part of the NIST LoReHLT evaluation in the summer of 2016. The official evaluation scores were calculated over a set of 4500 Uyghur documents. Each team was given the unannotated version of those documents, with the task being to submit annotations on that set. Our official scores are reported in <ref type="table">Table 4</ref>, and com- pared with <ref type="bibr" target="#b0">Bharadwaj et al. (2016)</ref>.</p><p>After the evaluation, NIST released 199 of the annotated evaluation documents, called the unse-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>All</head><p>Unseq.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bharadwaj et al. (2016) 51.2 - Ours</head><p>55.6 51.32 <ref type="table">Table 4</ref>: F1 scores of official submissions in LoReHLT16. The numbers in the "All" column are the scores on the entire evaluation data re- ported from NIST. We evaluate our submissions on the unsequestered data in order to compare with the results in  questered set. In this section, we will drill into the various methods we used to build the transfer model, and report finer-grained results using the unsequestered set.</p><p>The following are some of the language-specific techniques we employed.</p><p>• Dictionary The dictionary provided for Uyghur from <ref type="bibr" target="#b19">Rolston and Kirchhoff (2016)</ref> had only 5K entries, so we augmented this with the dictionary provided in the LORELEI evaluation, which resulted in 116K entries.</p><p>• Name Substitution As with Bengali and Tamil, very few names were translated. We found transliteration models were too noisy, so instead, we gathered a list of gazetteers from Uyghur Wikipedia, categorized by tag type (PER, LOC, GPE, ORG). Upon en- countering an untranslatable NE, we replaced it with a randomly selected NE from the gazetteer list corresponding to the tag. This led to improbable sentences like John Kerry has joined the Baskin Robbins, but it meant that NEs were fluent in the target text.</p><p>• Stemming We created a very simple stemmer for Uyghur. This consists of 45 common suf- fixes sorted longest first. For each Uyghur word in a corpus, we removed all possible suffixes (Uyghur words can take multiple suf- fixes). We stemmed all train and test data.</p><p>We report results in <ref type="table" target="#tab_6">Table 5</ref>. The first row is from a monolingual model trained on 158 docu- ments in the unsequestered set, and tested on the remaining 41. All other rows test on the com- plete unsequestered set. The next section, 'Stan- dard Translation', refers to the method described above. Notably, we do not use stemming for train or test data here. As with Bengali and Tamil, we omit form features.</p><p>We translate from English, Turkish, and Uzbek, which are the closest languages predicted by WALS. Next, we incorporated language specific methods. The scores we get from training on En- glish, Turkish and Uzbek all go up because the stemming makes the features more dense. Next we generated dictionaries using observations over Uyghur and Uzbek, and we used non-native speak- ers to annotate Uyghur data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Language Specific Dictionary Induction</head><p>We began by romanizing Uyghur text into the Uyghur Latin alphabet (ULY) so we could read it. We noticed that Uzbek and Uyghur are very similar, sharing a sizable amount of vocabulary, and several morphological rules. However, while there is a shared vocabulary, the words are usually spelled slightly differently. For example, the word for "southern" is "janubiy" in Uzbek and "jenu- biy" in Uyghur.</p><p>We tried several ideas for gathering a mapping for this shared vocabulary: manual mapping, edit- distance mapping, and cross-lingual CCA with word vectors.</p><p>Manual mapping: We manually translated about 100 words often found around entities, such as president, and university Edit-distance mapping: We gathered (Uyghur, Uzbek) word pairs with low-edit distance, using a modified edit-distance algorithm that allowed cer-tain substitutions at zero cost. For example, this discovered such pairs as pokistan-pakistan and telegraph-télégraf.</p><p>Cross-lingual CCA with word vectors: We pro- jected Uyghur and Uzbek monolingual vectors into a shared semantic space, using CCA <ref type="bibr" target="#b7">(Faruqui and Dyer, 2014)</ref>. We used the list of low edit- distance word pairs as the dictionary for the pro- jection. Once all the vectors were in the same space, we found the closest Uyghur word to each Uzbek word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>Scores are in <ref type="table" target="#tab_6">Table 5</ref>. Interestingly, the language specific methods evaluated individually did not improve much over the generic word translation methods. But with all language specific methods combined, 'All Lang. Spec.', the score increased by nearly 10 points, suggesting that the different training data covers many angles.</p><p>To the best of our knowledge, there are no pub- lished scores on the unsequestered data set. Our best score is comparable to the score of our evalu- ation submission on the unsequestered dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have shown a novel cross-lingual method for generating NER data that gives significant improvement over state-of-the-art on standard datasets. The method benefits from annotated data in many languages, combines well with orthogo- nal features, and works even when resources are virtually nil. The simplicity and minimal use of resources makes this approach more portable than all previous approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>p</head><label></label><figDesc>= w i w i+1 ...w i+j 6: end while 7: if p in L then 8: if |L[p]| &gt; 1 then 9: resolve with LM and prominence 10: end if 11: D F add (L[p], labels of p) 12: else 13: D F add (w i , label of w i ) 14: end if 15:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>0</head><label>0</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Baseline is naive direct transfer, with no gazetteers. 'Cheap Translation' translates from English 
into the target. Google Translate translates whole sentences, and does not use gazetteers. 'Cheap Trans-
lation+Wiki' incorporates wikifier features. 'Best Combination' uses language combinations from Table 
3 for source training data.  † denotes that this run does not use word features. 

Target 
Train lang 

Dutch 
English, German 
German English, Dutch 
Spanish English, Dutch 
Turkish English, Uzbek 
Bengali English, Hindi 
Tamil 
English, Malayalam 
Yoruba 
English, Hausa 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>This shows the language selection results. 
In each row, we see the target language, and the 
languages used for training. For example, when 
testing on Dutch, we train on German and English. 
These scores came from WALS. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table>Method 
F1 

Monolingual 
69.92 

Standard Translation 
Train: English 
27.20 
Train: Turkish 
33.02 
Train: Uzbek 
27.88 

Language Specific (stemmed) 
Train: English 
30.84 
Train: Turkish 
40.04 
Train: Uzbek 
40.15 
Induced dictionaries 
43.46 
Manual annotations 
42.51 

All Lang. Spec. 
51.32 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>F1 scores for Uyghur. Monolingual 
scores are on the 41 document test set. All other 
scores are on the full unsequestered data. We omit 
forms or gazetteers but use Brown clusters. 'Stan-
dard Translation' uses the same resources as the 
scores in Table 2 (e.g. without stemming) 

</table></figure>

			<note place="foot" n="1"> https://www.ethnologue.com/enterprise-faq/how-manylanguages-world-are-unwritten-0 2 We use the terms &apos;lexicon&apos; and &apos;dictionary&apos; interchangeably.</note>

			<note place="foot" n="3"> We use a standard BIO labeling scheme.</note>

			<note place="foot" n="4"> LDC2014E115,LDC2015E70 5 LDC2015E13,LDC2015E90,LDC2015E83, LDC2015E91 6 http://au-kbc.org/nlp/NER-FIRE2013/</note>

			<note place="foot" n="7"> Google Translate does not output alignments. If we had an in-house translation system, we could avoid this step.</note>

			<note place="foot" n="8"> https://en.wikipedia.org/wiki/Uyghur_ language, accessed July 21, 2017</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This material is based on research sponsored by the US Defense Advanced Research Projects Agency (DARPA) under agreement numbers FA8750-13-2-0008 and HR0011-15-2-0025. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of DARPA or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Phonologically aware neural model for named entity recognition in low resource transfer settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akash</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">R</forename><surname>Mortensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Named entity recognition for catalan using spanish resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Padró</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics</title>
		<meeting>the tenth conference on European chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised part-of-speech tagging with bilingual graph-based projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">WALS Online. Max Planck Institute for Evolutionary Anthropology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">S</forename><surname>Dryer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Haspelmath</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>Leipzig</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">What can we get from 1000 tokens? A case study of multilingual POS tagging for resource-poor languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="886" to="897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A simple, fast, and effective reparameterization of ibm model 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Chahuneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Building a multilingual named entityannotated corpus using annotation projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maud</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Steinberger</surname></persName>
		</author>
		<editor>RANLP</editor>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Improving vector space word representations using multilingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bootstrapping parsers via syntactic projection across parallel texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Weinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><forename type="middle">I</forename><surname>Cabezas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okan</forename><surname>Kolak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="311" to="325" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Endto-end statistical machine translation with zero or small parallel texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="517" to="548" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Panlex: Building a resource for panlingual lexical translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kamholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">M</forename><surname>Colowick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3145" to="3150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multilingual named entity recognition using parallel data and metadata from Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungchul</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<imprint>
			<pubPlace>Christine Moran</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th annual meeting of the ACL on interactive poster and demonstration sessions</title>
		<meeting>the 45th annual meeting of the ACL on interactive poster and demonstration sessions</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Knowledge sources for word-level translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Panlingual lexical translation via probabilistic inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kobi</forename><surname>Daniel S Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Skinner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Sammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="619" to="637" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-source transfer of delexicalized dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods for Natural Language Processing (EMNLP)<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="62" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Improving multilingual named entity recognition with wikipedia entity type mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>of the Annual Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Collection of bilingual data for lexicon transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leanne</forename><surname>Rolston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
		<respStmt>
			<orgName>University of Washington</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Human language technology resources for less commonly taught languages: Lessons learned toward creation of basic language resources. Collaboration: interoperability between people in the creation of language resources for less-resourced languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heather</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathryn</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Onyshkevych</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Srilm-an extensible language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">2002</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nudging the envelope of direct transfer methods for multilingual named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL-HLT Workshop on the Induction of Linguistic Structure</title>
		<meeting>the NAACL-HLT Workshop on the Induction of Linguistic Structure</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cross-lingual word clusters for direct transfer of linguistic structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Conll-2002</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="155" to="158" />
			<pubPlace>Taipei, Taiwan</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien De</forename><surname>Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2003</title>
		<meeting>CoNLL-2003<address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cross-lingual named entity recognition via wikification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoNLL</title>
		<imprint>
			<biblScope unit="page">219</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cross-lingual wikification using multilingual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cross-lingual projected expectation regularization for weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Inducing multilingual text analysis tools via robust projection across aligned corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Wicentowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first international conference on Human language technology research</title>
		<meeting>the first international conference on Human language technology research</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mention detection crossing the language barrier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imed</forename><surname>Zitouni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="600" to="609" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
