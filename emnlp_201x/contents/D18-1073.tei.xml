<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Extending Neural Generative Conversational Model using External Knowledge Sources</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanna</forename><surname>Parthasarathi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">McGill University</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
							<email>jpineau@cs.mcgill.ca</email>
							<affiliation key="aff1">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution">McGill University</orgName>
								<address>
									<country>Canada, Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Extending Neural Generative Conversational Model using External Knowledge Sources</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="690" to="695"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>690</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack coherence and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chitchat type of generative dialogue models. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved perplexity when leveraging external knowledge .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Much of the research in dialogue systems from the last few years has focused on replacing all (or some) of its components with Deep Neural Net- work (DNN) architectures <ref type="bibr" target="#b10">(Levin and Pieraccini, 1997;</ref><ref type="bibr" target="#b3">Dahl et al., 2012;</ref><ref type="bibr" target="#b11">Li et al., 2017;</ref><ref type="bibr">Serban et al., 2016a,b;</ref><ref type="bibr">Vinyals and Le, 2015)</ref>. These DNN models are trained end-to-end with large corpora of human-to-human dialogues, and essen- tially learn to mimic human conversations.</p><p>Although these models can represent the input context, the need for a dedicated external memory to remember information in context was pointed out and mechanisms were introduced in models like Memory Networks ( <ref type="bibr" target="#b20">Sukhbaatar et al., 2015;</ref><ref type="bibr" target="#b0">Bordes et al., 2016;</ref><ref type="bibr" target="#b6">Gulcehre et al., 2018)</ref>, and the Neural Turing Machine ( <ref type="bibr" target="#b5">Graves et al., 2014</ref>). Al- though these models, in theory, are better at main- taining the state using their memory component, they require longer training time and excessive search for hyperparameters.</p><p>In this paper we explore the possibility of in- corporating external information in dialogue sys- tems as a mechanism to supplement the standard context encoding and facilitate the generation to be more specific with faster learning time. Fur- thermore, especially in the case of chit-chat sys- tems, knowledge can be leveraged from differ- ent topics ( education, sports, news, travel, etc.). Current memory-based architectures cannot effi- ciently handle access to large unstructured exter- nal knowledge sources.</p><p>In this work, we build on the popular Encoder- Decoder model, and incorporate external knowl- edge as an additional continuous vector. The pro- posed Extended Encoder-Decoder (Ext-ED) archi- tecture learns to predict the embedding of the rel- evant external context during training and, during testing, uses an augmented state of external con- text and encoder final state to generate the next ut- terance. We evaluate our model with experiments on Reddit News dataset, and consider using either the Wikipedia summary <ref type="bibr">(Scheepers, 2017)</ref> or the NELL KB <ref type="bibr" target="#b1">(Carlson et al., 2010)</ref> as a source of ex- ternal context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Incorporating supplemental knowledge in neural conversational agents has been addressed in a few recent works on dialogue systems. Previous re- search however was mostly in the context of goal- driven dialogue systems, where the knowledge- base is highly structured, and queried to obtain very specific information (e.g. bus schedules, restaurant information, more broad tourist infor- mation).</p><p>Few goal-oriented dialogues research use ex- ternal information directly from the web or rele- vant data sources. An exception is ( <ref type="bibr" target="#b12">Long et al., 2017)</ref>, which searches the web for relevant infor-mation that pertains to the input context and pro- vides them as suggestions (like advising on places to visit while the user intends to visit a city). Sim- ilarly, instead of dynamically querying the web, ( <ref type="bibr">Ghazvininejad et al., 2017)</ref> pre-trains the model from facts in Foursquare ( <ref type="bibr">Yang et al., 2013</ref>) to se- lect relevant facts as suggestions.</p><p>Moving closer to unstructured domains, but still within task-driven conversations, (  proposes a way of retrieving relevant re- sponses based on external knowledge sources. The model selects relevant knowledge from Ubuntu man pages and uses it to retrieve a relevant context-response pair that is inline with the knowl- edge extracted. Similarly, ( <ref type="bibr">Young et al., 2017</ref>) ex- tracts relations within the context and parses over it to score the message response pairs. The rela- tional knowledge provides a way of incorporating useful knowledge or common sense as termed by the authors.</p><p>Though (Guu et al., 2017) did not directly make use of an external knowledge source, they used an edit vector that aids in editing a sampled prototype sentence. This is relevant to our proposed model as the generated response is conditioned on a sup- plementary vector similar to the external context vector discussed later in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Technical Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Recurrent Neural Networks</head><p>The Recurrent Neural Network (RNN) is a vari- ant of neural network used for learning represen- tations of inputs, x 1:T , that have an inherent se- quential structure (speech, video, dialogue etc.). In natural language processing, RNNs are used to learn language models that generalize over n-gram models <ref type="bibr" target="#b9">(Katz, 1987)</ref>. The RNN maintains a hid- den state, h t , that is an abstraction of inputs ob- served until time-step t of the input sequence, and uses x t to operate on them. RNN uses two pro- jection functions, U and W , for computing oper- ations on input and hidden states respectively. A third function, V , to map h t to the output, y t , the output of the RNN at every time step t. y t , is a distribution over the next token given the previous tokens, and is computed as a function of h t . The functions of the RNN can be explained as shown in Equations 1 and 2,</p><formula xml:id="formula_0">h t = g (U · x t + W · h t−1 + b) ,<label>(1)</label></formula><formula xml:id="formula_1">y t = V · h t + d,<label>(2)</label></formula><p>where y t is the output, x t is the vector represen- tation of input token, h t is the internal state of the RNN at time t and g is a non-linear function (like tanh or sigmoid). RNNs are trained with Back Propagation Through Time (BPTT) <ref type="bibr" target="#b14">(Rumelhart et al., 1988</ref>) to compute weight updates using the derivative of a loss function with respect to the parameters over all previous time-steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Seq2Seq Dialogue Architecture</head><p>Generative dialogue models ( <ref type="bibr">Sutskever et al., 2014;</ref>) extends the language model learned by RNNs to generate natural lan- guage that are conditioned not only on the previ- ous words generated in the response but also on a representation of the input context. The ability of such a learning module to understand an input se- quence of words (that we call context (c i 1:T )) and generate a response r i 1:T tantamount to solving the dialogue task.</p><p>(Vinyals and Le, 2015) first proposed a vanilla LSTM <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997</ref>) dia- logue model that encodes a given context with an LSTM (Encoder) and feeds it to another LSTM (Decoder) that generates a response token-by- token. Here the choice of encoder and decoder modules can be any recurrent architectures like GRU ( <ref type="bibr" target="#b2">Cho et al., 2014</ref>), RNN, Bi-directional LSTM <ref type="bibr" target="#b16">(Schuster and Paliwal, 1997)</ref>, etc. The model is then trained to learn a conditional distri- bution over the vocabulary for generating the next token in response to the i th context as shown in Equation 3:</p><formula xml:id="formula_2">P r i 1:T | c i 1:T = Π T k=1 P r i k | r i 1:k−1 , c i 1:T . (3)</formula><p>With neural language models, this form can aid in maintaining long term dependencies and the next word distribution can be made to condition- ally depend on an arbitrarily long context. Sophis- ticated models have made significant architectural improvements to aid better modelling of the con- texts ( <ref type="bibr" target="#b19">Serban et al., 2016b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Extended Encoder Decoder Architecture</head><p>The primary objective of the proposed architecture is to supplement response generation with exter- nal knowledge relevant to the context. Most of the knowledge sources that are available are free- form and lack suitable structure for easy querying of relevant information. In this work, we attempt to incorporate such unstructured knowledge cor- pora for dialogue generation in Seq2Seq models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Model</head><p>The Extended Encoder Decoder (Ext-ED) model, shown in <ref type="figure" target="#fig_0">Figure 1</ref>, uses an encoder LSTM (param- eterized as Θ Enc ) to encode the i th context, c i 1:T , and a fully connected layer (f ) to predict an ex- ternal context vector (ec i ) conditioned on the en- coded context. The predicted external context vec- tor, ec i , is provided to the decoder LSTM (Θ Dec ) at every step, augmented with the encoder final state and previous predicted token, to generate the next token in the response:</p><formula xml:id="formula_3">P ec i | c i 1:T = f Θ Enc c i 1:T<label>(4)</label></formula><formula xml:id="formula_4">P r i 1:T | c i 1:T = Π T k=1 P r i k | r i 1:k−1 , c i 1:T , ec i . (5)</formula><p>The decoder is provided with an encoding of the context along with the external knowledge en- coding, as ec i acts as information supplement to the knowledge available in the context as shown in Equations 4 and 5.</p><p>During training, the gradients for Ext-ED pa- rameters (f, Θ Enc , Θ Dec ) are computed by back- propagating the gradients for parameters with re- spect to losses in Equations 6, 7 and 8:</p><formula xml:id="formula_5">L 1 = T k=1 Q r i | ˆ ec i , c i log P r i | c i ,<label>(6)</label></formula><formula xml:id="formula_6">L 2 = ˆ ec i − ec i 2 ,<label>(7)</label></formula><formula xml:id="formula_7">L 3 = − T k=1 Q r i | c i , 0 log P r i | c i .<label>(8)</label></formula><p>Here L 1 is the log-likelihood that is used to make the model distribution mimic the data dis- tribution. L 2 trains f to correctly predict ec i , and L 3 trains Θ Dec to make use of the external con- text by forcing it the model distribution to diverge when not provided with the external context (ec i is set to 0 vector). In the loss equations, P and Q rep- resent the data and the model learned distributions respectively, and ec i andêcandˆandêc i represent true and model(f ) predicted external knowledge encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">External Context Vector</head><p>We use Wikipedia summary <ref type="bibr">(Scheepers, 2017)</ref> and NELL knowledge base (KB) <ref type="bibr" target="#b1">(Carlson et al., 2010)</ref> to compute the external knowledge encod- ing for every context in the context-response pairs. Algorithm 1 oultines the pseudocode for comput- ing the external context vector (ec i ). For i th input context, the methods Return All Values for Entity or Wiki Summary Query is used to extract the ex- ternal knowledge vector, ec i , from NELL KB or Wikipedia summary sources. The external context encoding, ec i , is a fixed length continuous embedding of the knowledge from external sources, as having all the words sampled (represented as a Bag of Words ) proved to be a severe computational overhead because of sparsity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Get External Context Vector</head><p>The continuous embedding of external context provides an additional conditioning with relevant external knowledge that is used to generate the next utterance. Although this is the intended hy- pothesis, there are certain expected characteristics that are desirable of external knowledge sources for them to be useful:</p><p>• The knowledge vectors being away from the mean of their distribution.</p><p>• The knowledge vectors having high variance.</p><p>We analyzed the knowledge vectors constructed using the two knowledge sources and the distri- bution of distances of ec i from their mean. The variance of this distribution in NELL KB was 1.44 and from that of Wikipedia summary was 0.73. Mean distance was very low (0.77) in the case of Wikipedia compared to that of NELL (2.16). We observed that the vectors not being spread out made them less useful than the encoded context itself in the initial experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Discussion</head><p>We evaluated Ext-ED by training with Reddit News dataset, and incorporated Wikipedia Sum- mary and NELL KB as sources of external knowl- edge. The objective of the experiments are three- fold: (1) to evaluate the ability of the model to make use of the external context to condition the response; (2) to analyze the training time with the additional knowledge provided; and (3) to observe any tangible differences in training with the two knowledge sources.</p><p>For the first analysis, we trained Ext-ED with external context (R 100 ) and validated it without providing it (see Ext-ED -L 3 Ablation in <ref type="table">Table 1</ref>). Without the inclusion of L 3 , Ext-ED did not find the external context useful and the performance was not very different from a Vanilla Seq2Seq di- alogue model <ref type="figure" target="#fig_1">(Figure 2</ref>). The encoder context had enough variance to be a viable information source and hence the external context was ignored. This can be observed from similar learning curves of Vanilla Seq2Seq, Ext-ED -L3 (Wiki) models in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>With propagating back gradients with respect to L 3 , we observed that the model learns to use the external context, but, as discussed in Section 4.2, the variance in the external context vectors constructed using the two knowledge sources was too low. To fix this, we scaled the external con- text vectors <ref type="figure" target="#fig_0">with N (4, 1)</ref>. This improved the vari- ance in the knowledge that subsequently improved the usefulness of these vectors which was also ob- served in <ref type="figure" target="#fig_1">Figure 2</ref>. The provision of external knowledge improved the Perplexity and BLEU-4 scores as shown in Ta- ble 1. Though the improvements are reasonable, the metrics used are not strong indicators for eval- uating the influence of external contexts in dia- logue. But, they do indicate that the prediction ac- curacy is improved with the inclusion of external knowledge sources. The poor perplexity for Ext- ED Ablation is because the model is conditioned to predict the next utterance using ec i and when not provided the context alone is not sufficiently informative. Another way to interpret this would be to see that the external context and and the dia- logue context provide complementary information for better predicting the next utterance. Further, the experiments illustrated that the model, when provided with an informative source of knowl- edge (the one that has higher variance), will let the model converge faster. One possible hypothe- sis is that ec i , which has high variance and is pro- vided as input in every step of decoding, is learned before the RNN parameters converge. The infor- mation in ec i is relevant to the context and subse- quently helps in training the decoder faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The proposed model, Extended Encoder Decoder, offers a framework to incorporate unstructured external knowledge to generate dialogue utter- ances. The experiments helped in understanding the need for external knowledge sources for im- proving learning time, and helped characterize the value of external knowledge sources. The exper- iments showed that external knowledge improved the learning time of the models. In future work, we aim to add more experiments with dialogue tasks that require understanding a supplementary source of knowledge to solve the task. Also, we plan to look at specialized tasks that naturally evaluate the influence of external knowledge, to help the model to generate diverse responses. <ref type="bibr">Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.</ref> Sequence to sequence learning with neural net- works.</p><p>Oriol </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture Diagram of Extended Encoder Decoder Model.</figDesc><graphic url="image-1.png" coords="3,72.00,117.18,249.45,99.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Convergence of Sequence loss (cross-entropy loss in sequential outputs) over different models during training.(-L3 in legend denote exclusion of L 3 loss from gradient computation.)</figDesc><graphic url="image-2.png" coords="4,72.00,62.81,226.77,170.08" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors gratefully acknowledge financial sup-port for portions of this work by the Samsung Advanced Institute of Technology (SAIT) and the Natural Sciences and Engineering Research Coun-cil of Canada (NSERC).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning end-to-end goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-Lan</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Toward an architecture for never-ending language learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Betteridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation: Encoder-decoder approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>George E Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Acero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on audio, speech, and language processing</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<title level="m">Wen-tau Yih, and Michel Galley. 2017. A knowledge-grounded neural conversation model</title>
		<imprint/>
	</monogr>
	<note>In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<title level="m">Neural turing machines</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dynamic neural turing machine with continuous and discrete addressing schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural computation</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Generating sentences by editing prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tatsunori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Oren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural computation</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Estimation of probabilities from sparse data for the language model component of a speech recognizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slava</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on acoustics, speech, and signal processing</title>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A stochastic model of computer-human interaction for learning dialogue strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esther</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Pieraccini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth European Conference on Speech Communication and Technology</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Adversarial learning for neural dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A knowledge enhanced generative conversational service agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongsheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoran</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 6th Dialog System Technology Challenges (DSTC6) Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Incorporating unstructured textual knowledge sources into neural dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nissan</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems Workshop on Machine Learning for Spoken Language Understanding</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>David E Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive modeling</title>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Improving the compositionality of word embeddings</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>Universiteit van Amsterdam</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuldip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Signal Processing</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A survey of available corpora for building data-driven dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
