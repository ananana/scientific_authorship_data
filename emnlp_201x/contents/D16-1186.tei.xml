<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On-and Off-Topic Classification and Semantic Annotation of User-Generated Software Requirements</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dollmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Heinz Nixdorf Institute University of Paderborn</orgName>
								<address>
									<addrLine>Fürstenallee 11</addrLine>
									<postCode>33102</postCode>
									<settlement>Paderborn</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Geierhos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Heinz Nixdorf Institute University of Paderborn</orgName>
								<address>
									<addrLine>Fürstenallee 11</addrLine>
									<postCode>33102</postCode>
									<settlement>Paderborn</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On-and Off-Topic Classification and Semantic Annotation of User-Generated Software Requirements</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1807" to="1816"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Users prefer natural language software requirements because of their usability and accessibility. When they describe their wishes for software development, they often provide off-topic information. We therefore present REaCT 1 , an automated approach for identifying and semantically annotating the on-topic parts of requirement descriptions. It is designed to support requirement engineers in the elicitation process on detecting and analyzing requirements in user-generated content. Since no lexical resources with domain-specific information about requirements are available, we created a corpus of requirements written in controlled language by instructed users and uncontrolled language by uninstructed users. We annotated these requirements regarding predicate-argument structures, conditions , priorities, motivations and semantic roles and used this information to train clas-sifiers for information extraction purposes. REaCT achieves an accuracy of 92% for the on-and off-topic classification task and an F 1-measure of 72% for the semantic annotation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>"Requirements are what the software product, or hardware product, or service, or whatever you in- tend to build, is meant to do and to be" <ref type="bibr" target="#b19">(Robertson and Robertson, 2012)</ref>. This intuitive descrip- tion of requirements has one disadvantage. It is as vague as a requirement that is written by an un- trained user. More generally, functional require- ments define what a product, system or process, or <ref type="bibr">1</ref> Requirements Extraction and Classification Tool a part of it is meant to do <ref type="bibr" target="#b19">(Robertson and Robertson, 2012;</ref><ref type="bibr" target="#b22">Vlas and Robinson, 2011</ref>). Due to its ex- pressiveness, natural language (NL) became a pop- ular medium of communication between users and developers during the requirement elicitation pro- cess (de Almeida Ferreira and da <ref type="bibr" target="#b5">Silva, 2012;</ref><ref type="bibr" target="#b17">Mich et al., 2004</ref>). Especially in large ICT projects, re- quirements, wishes, and ideas of up to thousands of different users have to be grasped ( <ref type="bibr" target="#b2">Castro-Herrera et al., 2009)</ref>. For this purpose, requirement en- gineers collect their data, look for project-relevant concepts and summarize the identified technical fea- tures. However, this hand-crafted aggregation and translation process from NL to formal specifica- tions is error-prone ( <ref type="bibr" target="#b10">Goldin and Berry, 1994)</ref>. Since people are getting tired and unfocused during this monotonous work, the risk of information loss in- creases. Hence, this process should be automated as far as possible to support requirement engineers.</p><p>In this paper, we introduce our approach to iden- tify and annotate requirements in user-generated content. We acquired feature requests for open source software from SourceForge 2 , specified by (potential) users of the software. We divided these requests into off-topic information and (on-topic) requirements to train a binary text classifier. This allows an automated identification of new require- ments in user-generated content. In addition, we col- lected requirements in controlled language from the NFR corpus <ref type="bibr">3</ref> and from web pages with user-story explanations. We annotated the semantically rele-vant parts of the acquired requirements for infor- mation extraction purposes. This will support re- quirements engineers on requirement analysis and enables a further processing such as disambiguation or the resolution of incomplete expressions.</p><p>This paper is structured as follows: In Section 2, we discuss the notion of requirements. Then we pro- vide an overview of previous work (Section 3), be- fore we introduce lexical resources necessary for our method (Section 4). The approach itself is presented in Section 5 before it is evaluated in Section 6. Fi- nally, we conclude this work in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Nature of Requirements</head><p>Requirement engineers and software developers have to meet users' wishes in order to create new software products. Such descriptions of software functionalities can be expressed in different ways: For example, by using controlled languages or formal methods, clarity and completeness can be achieved. But non-experts can hardly apply them and therefore do not belong to the user group. For this reason, users are encouraged to express their in- dividual requirements for the desired software ap- plication in NL in order to improve user accep- tance and satisfaction <ref type="bibr" target="#b6">(Firesmith, 2005</ref>). In gen- eral, software requirements are expressed through active verbs such as "to calculate" or "to publish" <ref type="bibr" target="#b19">(Robertson and Robertson, 2012)</ref>. In this work, we distinguish requirements expressed in NL between controlled and uncontrolled language.</p><p>A controlled language is a subset of NL, which is characterized by a restricted grammar and/or limited vocabulary ( <ref type="bibr" target="#b24">Yue et al., 2010)</ref>. Requirements in con- trolled language do not suffer from ambiguity, re- dundancy and complexity <ref type="bibr" target="#b24">(Yue et al., 2010)</ref>. That is why these recommendations lead to a desirable input for text processing. <ref type="bibr" target="#b19">Robertson and Robertson (2012)</ref> therefore recommend specifying each requirement in a single sentence with one verb. Furthermore, they suggest the following start of record "The [sys- tem/product/process] shall ...", which focuses on the functionality and keeps the active form of a sen- tence. An example therefore is "The system shall display the Events in a graph by time." Another type of controlled requirements are user stories. They fol- low the form "As a [role], I want [something] so that <ref type="bibr">[benefit]</ref>" and describe software functionalities from the user's perspective <ref type="bibr" target="#b4">(Cohn, 2004</ref>). Compared to the previous ones, they do not focus on the tech- nical implementation but concentrate on the goals and resulting benefits. An example therefore is "As a Creator, I want to upload a video from my local machine so that any users can view it."</p><p>We also consider uncontrolled language in this work because requirements are usually specified by users that have not been instructed for any type of formulation. Requirements in uncontrolled lan- guage do not stick to grammar and/or orthographic rules and may contain abbreviations, acronyms or emoticons. There is no restriction how to express oneself. An example therefore is "Hello, I would like to suggest the implementation of expiration date for the master password :)".</p><p>In the following, the word "requirement" is used for a described functionality. We assume that its textualization is written within a single English sen- tence. Requirements are specified in documents like the Software Requirements Specification (SRS). We refer to SRS and other forms (e.g. e-mails, memos from workshops, transcripts of interviews or entries in bug-trackers) as requirement documentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Previous Work</head><p>It is quite common that requirement engineers elicit requirements together with users in interviews, group meetings, or by using questionnaires <ref type="bibr" target="#b18">(Mich, 1996)</ref>. Researchers developed (semi-) automated and collaborative approaches to support requirement engineers in this process ( <ref type="bibr" target="#b1">Ankori and Ankori, 2005;</ref><ref type="bibr" target="#b2">Castro-Herrera et al., 2009)</ref>. Besides the elicitation in interaction with the users, an identification of re- quirements from existing sources is possible. For example, <ref type="bibr" target="#b14">John and Dörr (2003)</ref> used documenta- tions from related products to derive requirements for a new product. <ref type="bibr" target="#b22">Vlas and Robinson (2011)</ref> used unstructured, informal, NL feature requests from the platform SourceForge to collect requirements for open source software. They presented a rule-based method to identify and classify requirements accord- ing to the quality criteria of the McCall's Quality Model <ref type="bibr">(McCall, 1977)</ref>. Analogous to their work, we want to automatically detect requirements in user- generated content. While they applied a rule-based method, we plan to identify requirements in user- generated content with a machine learning approach. Since those approaches automatically identify pat- terns for this classification task, we expect a higher recall and more reliable results. <ref type="bibr" target="#b10">Goldin and Berry (1994)</ref> identified so-called ab- stractions (i.e. relevant terms and concepts related to a product) of elicited requirements for a better com- prehension of the domain and its restrictions. Their tool AbstFinder is based on the idea that the signifi- cance of terms and concepts is related to the number of mentions in the text. However, in some cases, there is only a weak correlation between the term frequencies and their relevance in documents. This problem can be reduced by a statistical corpus anal- ysis, when the actual term frequency is similar to the expected ( <ref type="bibr" target="#b20">Sawyer et al., 2002;</ref><ref type="bibr" target="#b7">Gacitua et al., 2011</ref>). This approach eliminates corpus specific stopwords and misleading frequent terms. In our work, we in- tent to perform a content analysis of the previously detected requirements. However, instead of only identifying significant terms and concepts, we cap- ture the semantically relevant parts of requirements such as conditions, motivations, roles or actions (cf. <ref type="figure" target="#fig_0">Figure 1</ref>).</p><p>In addition to the identification of abstractions, there are methods to transform NL requirements into graphical models (e.g. in Unified Modeling Lan- guage) <ref type="bibr" target="#b11">(Harmain and Gaizauskas, 2003;</ref><ref type="bibr" target="#b0">Ambriola and Gervasi, 2006;</ref><ref type="bibr" target="#b16">Körner and Gelhausen, 2008)</ref>. A systematic literature review, done by <ref type="bibr" target="#b24">Yue et al. (2010)</ref>, aims at the modeling of requirements by comparing transformation techniques in such mod- els. Unlike those techniques, we aim to keep the ex- pressive aspect of the original textual requirements and semantically annotate them for filtering pur- poses. These results can be further used for dif- ferent NLP tasks such as disambiguation, resolu- tion of vagueness or the compensation of under- specification.</p><p>The semantic annotation task of this work is sim- ilar to semantic role labeling (SLR). According to <ref type="bibr" target="#b15">Jurafsky and Martin (2015)</ref>, the goal of SLR is un- derstanding events and their participants, especially being able to answer the question who did what to whom (and perhaps also when and where). In this work, we seek to adapt this goal to the requirements domain, where we want to answer the question what actions should be done by which component (and perhaps also who wants to perform that action, are there any conditions, what is the motivation for per- forming this action and is there a priority assigned to the requirement).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Gathering and Annotation of Controlled and Uncontrolled Requirements</head><p>There are benchmarks comparing automated meth- ods for requirement engineering ( <ref type="bibr" target="#b21">Tichy et al., 2015)</ref>. However, none of the published datasets is sufficient to train a text classifier, since annotated information is missing. For our purposes, we need a data set with annotated predicate-argument structures, conditions, priorities, motivations and semantic roles. We there- fore created a semantically annotated corpus by us- ing the categories shown in <ref type="figure" target="#fig_0">Figure 1</ref>, which repre- sent all information bits of a requirement. Since the approach should be able to distinguish between (on- topic) requirements and off-topic comments, we ac- quired software domain-specific off-topic sentences, too. Therefore, we acquired requirements in con- trolled language from the system's and the user's perspective. While requirements from the system's perspective are describing technical software func- tionalities, the requirements from the user's per- spective express wishes for software, to fulfill user needs. For instance, the NFR corpus 4 covers the sys- tem's perspective of controlled requirements spec- ifications. It consists of 255 functional and 370 non-functional requirements whereof we used the functional subset to cover the system's perspective. Since we could not identify any requirement corpus that describes a software at user's request, we ac- quired 304 user stories from websites and books that describe how to write user stories.</p><p>However, these requirements in controlled lan- guage have not the same characteristics as uncon- trolled requirements descriptions. For the acquisi- tion of uncontrolled requirements, we adapted the idea of <ref type="bibr" target="#b22">Vlas and Robinson (2011)</ref> that is based on feature requests gathered from the open-source soft- ware platform SourceForge 5 . These feature requests are created by users that have not been instructed for any type of formulation. Since these requests do not only contain requirements, we split them into sen- tences and manually classified them in requirements and off-topic information. Here, we consider social communication, descriptions of workflows, descrip- tions of existing software features, feedback, salu- tations, or greetings as off-topic information. In to- tal, we gathered 200 uncontrolled on-topic sentences (i.e. requirements) and 492 off-topic ones.</p><p>Then we analyzed the acquired requirements in order to identify the different possible semantic cat- egories to annotate their relevant content in our re- quirements corpus (cf. <ref type="figure" target="#fig_0">Figure 1)</ref>:</p><formula xml:id="formula_0">-component -refinement of component -action -argument of action -condition -priority -motivation -role -object -refinement of object -sub-action</formula><p>-argument of sub-action -sub-priority -sub-role -sub-object -refinement of sub-object The categories component or role, action and ob- ject are usually represented by subject, predicate and object of a sentence. In general, a description refers to a component, either to a product or sys- tem itself or to a part of the product/system. Ac- tions describe what a component should accomplish and affect. Actions have an effect on Objects. The authors of the requirements can refine the descrip- tion of components and objects, which is covered by the categories refinement of component and re- finement of object. For each action, users can set a certain priority, describe their motivation for a spe- cific functionality, state conditions, and/or even de- fine some semantic roles. Apart from the component and the object, additional arguments of the action (predicate of a sentence) are annotated with argu- ment of action. In some cases, requirements contain sub-requirements in subordinate clauses. The anno- tators took this into account when using the prede- fined sub-categories. An example of an annotated requirement is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. Two annotators independently labeled the cate- gories in the requirements. We define one of the annotation set as gold standard and the other as can- didate set. We will use the gold standard for training and testing purposes in Section 5 and 6 and the can- didate set for calculating an inter-annotator agree- ment. In total, our gold standard consists of 3,996 labeled elements (i.e. clauses, phrases, and even modality). The frequency distribution is shown in The inter-annotator agreement in multi-token an- notations is commonly evaluated by using F 1 -score <ref type="bibr">(Chinchor, 1998)</ref>. The two annotators achieve an agreement of 80%, whereby the comparison was in- voked from the gold standard.</p><p>Many information extraction tasks use the IOB encoding 6 for annotation purposes. When using the IOB encoding, the first token of an element is split into its head (first token) and its tail (rest of the ele- ment). That way, its boundaries are labeled with B (begin) and I (inside). This allows separating suc- cessive elements of the same category. Thus, we use the IOB encoding during the annotation step. How- ever, we want to discuss a drawback of this notation: When applying text classification approaches in in- formation extraction tasks with IOB encoding, the number of classes reduplicates and this reduces the amount of training data per class. During our an- notation process, successive elements of the same semantic category only occurred in the case of argu- ment of the action and argument of the sub-action. When we disregard the IOB encoding, we can eas- ily split up (sub-)actions by keywords such as "in", "by", "from", "as", "on", "to", "into", "for", and "through". So if we use IO encoding, it can be eas- ily transformed to the IOB encoding. The only dif- ference between IOB and IO encoding is that it does not distinguish between the head and tail of an el- ement and therefore does not double the number of classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">REaCT -A Two-Stage Approach</head><p>Requirement documentations are the input of our system. <ref type="figure" target="#fig_2">Figure 3</ref> illustrates the two-stage approach divided in two separate classification tasks. First, we apply an on-/off-topic classification to decide whether a sentence is a requirement or irrelevant for the further processing (cf. Section 5.1). Then, the previously identified requirements were automati- cally annotated (Section 5.2). As a result, we get filtered and semantically annotated requirements in XML or JSON.</p><p>The models for on-/off-topic classification and se- mantic annotation are trained on the gathered re- quirements (cf. Section 4). We split up the gold standard on sentence level in a ratio of 4:1 in a train- 6 I (inside), O (outside) or B (begin) of an element ing set of 607 requirements and test set of 152 re- quirements. Furthermore, we used 10-fold cross val- idation on the training set for algorithm configura- tion and feature engineering (cf. Section 5.1 and Section 5.2). Finally, our approach is evaluated on the test set (cf. Section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">On-/Off-Topic Classification Task</head><p>User requirement documentations often contain off- topic information. Therefore, we present a binary text classification approach that distinguishes be- tween requirements and off-topic content. Thus, we trained different classification algorithms and tested them using various features and parameter settings. We compared the results to select the best algorithm together with its best-suited parameter values and features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Features</head><p>To differentiate requirements from off-topic con- tent, the sentences will be transformed in numerical feature vectors using a bag-of-words approach with different settings <ref type="bibr">7</ref> . The features for the transforma- tion are listed along with their possible parameter settings in <ref type="table" target="#tab_2">Table 2</ref>. We can choose whether the fea- ture should be taken from word or character n-grams (a.1). For both versions, the unit can range between [n, m] (a.2), which can be specified by parameters. Here, we consider all combinations of n = <ref type="bibr">[1,</ref><ref type="bibr">5]</ref> and m = <ref type="bibr">[1,</ref><ref type="bibr">5]</ref> (where m ≥ n). If the feature should be build from word n-grams, stopword detection is pos- sible (a.3). Additionally, terms can be ignored that reach a document frequency below or above a given 7 Parameters; to be chosen during algorithm configuration threshold (e.g. domain-specific stopwords) (a.4 and a.5). Another threshold can be specified to only consider the top features ordered by term frequency (a.6). Besides, it is possible to re-weight the units in the bag-of-words model in relation to the inverse document frequency (IDF) (a.7). Moreover, the fre- quency vector can be reduced to binary values (a.8), so that the bag-of-words model only contains infor- mation about the term occurrence but not about its calculated frequency. We also consider the length of a sentence as feature (b). Furthermore, the fre- quency of the part-of-speech (POS) tags (c) and the dependencies between the tokens (d) can be added to the feature vector 8 . These two features are optional (c.1 and d.1). This set of features covers the domain- specific characteristics and should enable the identi- fication of the requirements.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head># Feature/Parameter Possible Values</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Selected Algorithms</head><p>We selected the following algorithms from the scikit-learn library 9 for binary classification: deci- sion tree (DecisionTreeClassifier), Naive Bayes (BernoulliNB and MultionmialNB), support vector machine (SVC and NuSVC) as well as ensemble methods (BaggingClassifier, RandomForestClassifier, ExtraTree- Classifier and AdaBoostClassifier). Finally, after evaluating these algorithms, we chose the best one for the classification task (cf. Section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Semantic Annotation Task</head><p>For each identified requirement, the approach should annotate the semantic components (cf. <ref type="figure" target="#fig_0">Figure 1)</ref>. Here, we use text classification techniques on token level for information extraction purposes. The ben- efit is that these techniques can automatically learn rules to classify data from the annotated elements (cf. Section 4). Each token will be assigned to one of the semantic categories presented in <ref type="figure" target="#fig_0">Figure 1</ref> or the additional class O (outside according IOB nota- tion).</p><p>We decided in favor of IO encoding during classification to reduce the drawback described in Section 4. We finally convert the classification re- sults into the IOB encoding by labeling the head of each element as begin and the tail as inside. By us- ing the keywords listed in Section 4 as separators, we further distinguish the beginning and the inner parts of arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Features</head><p>In the second classification step, we had to adapt the features to token level. The goal of feature en- gineering is to capture the characteristics of the to- kens embedded in their surrounding context. We di- vided the features in four groups: orthographic and semantic features of the token, contextual features, and traceable classification results.</p><p>Orthographic features of a token are its graphe- matic representation (a) and additional flags that de- cide if a token contains a number (b), is capitalized (c), or is somehow uppercased (d) (cf. <ref type="table" target="#tab_3">Table 3</ref>). For the graphematic representation, we can choose be- tween the token or the lemma (a.1). Another or- thographic feature provides information about the length of the token (e). Furthermore, we can use the pre-and suffix characters of the token as fea- tures (f and g). Their lengths are configurable (f.1 and g.1).  Furthermore, we consider the relevance (h), the POS tag (i) and the WordNet ID of a token (j) as its semantic features (cf.  As contextual features, we use sentence length (k), index of the token in the sentence (l), as well as the tagging and dependency parsing information of the surrounding tokens (m, n and o) (cf. <ref type="table" target="#tab_6">Table 5</ref>). Thus, the POS tags sequences of the n previous and the next m token are considered, where n and m are defined during algorithm configuration (l.1 and n.1). Moreover, it can be specified if each POS tag should be stored as a single feature or should be concate- nated (e.g. NOUN+VERB+NOUN) (l.2 and n.2).  The classification task is carried out from left to right in the sentence. This enables the considera- tion of previous classification results (cf. <ref type="table" target="#tab_8">Table 6</ref>). We implemented two slightly different variants that can be combined on demand: Firstly, we can de- fine a fixed number of previous classification results as independent or concatenated features (i.e. a slid- ing window (p)). Secondly, the number of token al- ready assigned to a particular class may be a valu- able information (q). This is especially of interest for the hierarchical structure of the categories: For instance, a sub-object should only occur if an object has already been identified. These two features are optional (p.1 and q.1). The size of the sliding win- dow will be specified during algorithm configuration (p.2).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head># Feature/Parameter Possible Values</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Selected Algorithms</head><p>In addition to the classifiers we already used in the on-/off-topic classification task, we considered three sequential learning algorithms: conditional random fields (FrankWolfeSSVM) from the PyS- truct-library 13 , multinomial hidden markov model (MultinomialHMM) as well as structured percep- tron from the seqlearn-library 14 . We could not esti- mate feasible parameter settings for the NuSVC clas- sifier, so that this classifier was ignored. We chose the algorithm with the best results on the test set for annotating the requirements (cf. Section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>As mentioned in Section 5, the data was separated in a ratio of 4:1 in a training and a test set. We trained all classifiers on the training set with their defined settings from the automated algorithm con- figuration. Subsequently, we evaluated these classi- fiers on the test set. Our results are shown in <ref type="table" target="#tab_10">Table 7</ref> that lists the accuracy for the best classifier per algo- rithm family of the on-/off-topic classification task. The ExtraTreeClassifier performs best on the test data with an accuracy of 92%. The accuracy was calculated with the following formula: accuracy = #true positives + #true negatives #classif ied requirements</p><p>The ExtraTreeClassifier is an implemen- tation of Extremely Randomized <ref type="bibr">Trees (Geurts et al., 2006</ref>). We achieved the best result when using char- acter n-grams as features in the model with a fixed length of 4. Thereby, we considered term occurrence instead of term frequency and IDF. Before creating the bag-of-words model, the approach removes stop- words. Furthermore, the frequency of the POS tags and their dependencies are used as features. In to- tal, the ExtraTreeClassifier used 167 esti- mators based on entropy in the ensemble (algorithm- specific parameters   <ref type="table" target="#tab_12">Table 8</ref> shows the values for precision, recall, and F 1 of the ExtraTreeClassifier. In brief, the introduced approach detects requirements in user- generated content with an average F 1 -score of 91%.   <ref type="table" target="#tab_14">Table 9</ref> provides an overview of the results of the semantic annotation task. To determine the F 1 -score, the agreement of the predicted and the a priori given annotations is necessary to count an element as true positive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class Precision</head><p>Again, the ExtraTreeClassifier achieves the best F 1 -score of 72%. We gained the best re- sults by using 171 randomized decision trees based on entropy (algorithm-specific parameters). As fea- tures, we took the POS tags from Universal Tag Set for the twelve previous and the three following to- kens. Traceable classification results are taken into account by a sliding window of size 1. Besides, we validate if a class label has already been assigned. For each considered token, the four prefix and the two suffix characters as well as the graphematic rep- resentation of the token are applied as features.</p><p>The sequential learning algorithms (FrankWolfeSSVM, MultinomialHMM and StructuredPerceptron) perform worse than the other classifiers. We assume that this is due to the small amount of available training data. However, the methods depending on de- cision trees, especially the ensemble methods (RandomForestClassifier, Bagging-Classifier and ExtraTreeClassifier), perform significantly better.  In <ref type="table" target="#tab_0">Table 10</ref>, we provide detailed results achieved with the ExtraTreeClassifier for the differ- ent semantic categories. The recognition of main aspects (component, action and object) reached F 1 - scores of 73%, 80% and 68%. The semantic cate- gories, that have only a few training examples, are more error-prone (e.g. sub-action or sub-object).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classifier</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic Category Precision Recall</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>Requirement engineers and software developers have to meet users' wishes to create new software products. The goal of this work was to develop a system that can identify and analyze requirements expressed in natural language. These are written by users unlimited in their way of expression. Our system REaCT achieves an accuracy of 92% in dis- tinguishing between on-and off-topic information in the user-generated requirement descriptions. The text classification approach for semantic annotation reaches an F 1 -score of 72% -a satisfying result compared to the inter-annotator agreement of 80%. One possibility to improve the quality of the seman- tic annotation is to expand the training set. Espe- cially the sequential learning techniques need more training data. Besides, this would have a positive im- pact on those semantic categories that only contain a small number of annotated elements. Developers and requirement engineers can facilely identify requirements written by users for products in different scenarios by applying our approach. Moreover, the semantic annotations are useful for further NLP tasks. User-generated software requirements adhere to the same quality standards as software requirements that are col- lected and revised by experts: They should be complete, unambiguous and consistent ( <ref type="bibr" target="#b12">Hsia et al., 1993)</ref>. Since there was no assistant system to check the quality for many years ( <ref type="bibr" target="#b13">Hussain et al., 2007)</ref> we plan to extend the provided system in order to provide some quality analysis of the extracted information. We have already developed concepts to generate suggestions for non-experts, how to complete or clarify their requirement descriptions <ref type="bibr" target="#b8">(Geierhos et al., 2015</ref>). Based on these insights, we want to implement a system for the resolution of vagueness and incompleteness of NL requirements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Semantic categories in our software requirements corpus used for annotation purposes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Annotated requirement sample</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Processing pipeline of the two-stage approach</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Semantic Category 
CR 
UR Total 

component 
241 
84 
325 
refinement of component 
6 
16 
22 

action 
526 
204 
730 
argument of action 
180 
104 
284 
condition 
94 
39 
133 
priority 
488 
209 
697 
motivation 
33 
19 
52 
role 
406 
42 
448 

object 
540 
195 
735 
refinement of object 
155 
48 
203 

sub-action 
76 
40 
116 
argument of sub-action 
27 
14 
41 
sub-priority 
22 
16 
38 
sub-role 
22 
11 
33 

sub-object 
78 
37 
115 
refinement of sub-object 
16 
8 
24 

Total 2,910 1,086 3,996 

Table 1: Number of annotated elements per category in our 

gold standard (CR=controlled requirements, UR=uncontrolled 

requirements) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Features for on-/off-topic classification together with 

their corresponding parameters 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : Orthographic features for semantic annotation</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 )</head><label>4</label><figDesc>. By checking the stopword status of a token, we can decide about its relevance. Besides, the POS tag of each token is used as feature. When applying the POS informa- tion, we can choose between the Universal Tag Set 10 (consisting of 17 POS tags) and the Penn</figDesc><table>Treebank 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 : Semantic features for semantic annotation</head><label>4</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 : Contextual features for semantic annotation</head><label>5</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 : Traceable classification results for semantic annotation</head><label>6</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Accuracy of best classifiers per algorithm family in the 

on-/off-topic classification task after algorithm configuration 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Evaluation results for the on-/off-topic classification 

with the ExtraTreeClassifier 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" validated="false"><head>Table 9 : F1-scores of best classifiers per algorithm family in the semantic annotation task after algorithm configuration</head><label>9</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" validated="false"><head>Table 10 :</head><label>10</label><figDesc></figDesc><table>Evaluation results for the semantic annotation with 

the ExtraTreeClassifier 

</table></figure>

			<note place="foot" n="2"> https://sourceforge.net 3 http://openscience.us/repo/ requirements/other-requirements/nfr</note>

			<note place="foot" n="4"> https://terapromise.csc.ncsu.edu/repo/ requirements/nfr/nfr.arff 5 https://sourceforge.net</note>

			<note place="foot" n="8"> We use spaCy (https://spacy.io) for POS tagging and dependency parsing 9 http://scikit-learn.org</note>

			<note place="foot" n="10"> http://universaldependencies.org/u/pos/ 11 http://www.ling.upenn.edu/courses/Fall_ 2003/ling001/penn_treebank_pos.html 12 https://wordnet.princeton.edu</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Special thanks to our colleagues Frederik S. Bäumer and David Kopecki for their support during the se-mantic annotation of the requirements. This work was partially supported by the German Research Foundation (DFG) within the Collaborative Re-search Centre "</p><p>On-The-Fly Computing" (SFB 901).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the Systematic Analysis of Natural Language Requirements with CIRCE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzo</forename><surname>Ambriola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzo</forename><surname>Gervasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automated Software Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="167" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic requirements elicitation in agile processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronit</forename><surname>Ankori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronit</forename><surname>Ankori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 IEEE International Conference on Software-Science</title>
		<meeting>the 2005 IEEE International Conference on Software-Science</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="101" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A recommender system for requirements elicitation in largescale software projects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Castro-Herrera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Clelandhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bamshad</forename><surname>Mobasher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 ACM Symposium on Applied Computing</title>
		<meeting>the 2009 ACM Symposium on Applied Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1419" to="1426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<title level="m">Proceedings of the Seventh Message Understanding Conference (MUC-7) Named Entity Task Definition</title>
		<editor>Nancy A. Chinchor</editor>
		<meeting>the Seventh Message Understanding Conference (MUC-7) Named Entity Task Definition<address><addrLine>Fairfax, VA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">User Stories Applied: For Agile Software Development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Cohn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Addison Wesley Longman Publishing Co</publisher>
			<pubPlace>Redwood City, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">RSLingo: An information extraction approach toward formal requirements specifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Almeida</forename><surname>David De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto Rodrigues Da</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Model-Driven Requirements Engineering Workshop</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Are Your Requirements Complete</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">G</forename><surname>Firesmith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Object Technology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="27" to="43" />
			<date type="published" when="2005-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Relevance-based abstraction identification: technique and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Gacitua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pete</forename><surname>Sawyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzo</forename><surname>Gervasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Requirements Engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="251" to="265" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">What did you mean? Facing the Challenges of User-generated Software Requirements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Geierhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederik</forename><forename type="middle">Simon</forename><surname>Bäumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Agents and Artificial Intelligence</title>
		<meeting>the 7th International Conference on Agents and Artificial Intelligence<address><addrLine>Lisbon. ISBN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-01" />
			<biblScope unit="page" from="978" to="989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extremely randomized trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Geurts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis</forename><surname>Wehenkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="3" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">AbstFinder, A Prototype Abstraction Finder for Natural Language Text for Use in Requirements Elicitation: Design, Methodology, and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leah</forename><surname>Goldin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Berry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automated Software Engineering</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="375" to="412" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">CM-Builder: A Natural Language-Based CASE Tool for ObjectOriented Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Harmain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Software-Science</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="157" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Hsia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Status Report: Requirements Engineering. IEEE Software</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="75" to="79" />
			<date type="published" when="1993-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatic Quality Assessment of SRS Text by Means of a Decision-Tree-Based Text Classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishrar</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Ormandjieva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leila</forename><surname>Kosseim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Quality Software, QSIC &apos;07</title>
		<meeting>the 7th International Conference on Quality Software, QSIC &apos;07</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="209" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Elicitation of Requirements from User Documentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Dörr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Requirements Engineering: Foundation of Software Quality</title>
		<meeting>the 9th International Workshop on Requirements Engineering: Foundation of Software Quality</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="17" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>James H Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech and Language Processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>3rd ed. draft edition</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving Automatic Model Creation using Ontologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Körner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gelhausen</surname></persName>
		</author>
		<ptr target="http://www.sqa.net/softwarequalityattributes.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Software Engineering &amp; Knowledge Engineering</title>
		<meeting>the 20th International Conference on Software Engineering &amp; Knowledge Engineering</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="691" to="696" />
		</imprint>
	</monogr>
	<note>Knowledge Systems Institute. Jim McCall. 1977. McCall&apos;s Quality Model</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Market research for requirements analysis using linguistic tools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Mich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariangela</forename><surname>Franch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pier Luigi Novi</forename><surname>Inverardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Requirements Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="151" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">NL-OOPS: from natural language to object oriented requirements using the natural language processing system LOLITA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Mich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="161" to="187" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Mastering the Requirements Process. Getting Requirements Right</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Robertson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Addison-Wesley Publishing</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">REVERE: support for requirements synthesis from documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Sawyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Rayson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Garside</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Systems Frontiers</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="343" to="353" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">nlrpBENCH: A Benchmark for Natural Language Requirements Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Tichy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><forename type="middle">J</forename><surname>Landhäußer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Körner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multikonferenz Software Engineering &amp; Management</title>
		<imprint>
			<publisher>GI</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A RuleBased Natural Language Technique for Requirements Discovery and Classification in Open-Source Software Development Projects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Vlas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">N</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th</title>
		<meeting>the 44th</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<title level="m">Hawaii International Conference on System Sciences</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A systematic review of transformation approaches between user requirements and analysis models. Requirements Engineering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lionel</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvan</forename><surname>Labiche</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="75" to="99" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
