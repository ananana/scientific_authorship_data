<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Human Evaluation of Grammatical Error Correction Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Computer Science</orgName>
								<orgName type="laboratory">Information Systems Laboratory</orgName>
								<orgName type="institution">Adam Mickiewicz University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Computer Science</orgName>
								<orgName type="laboratory">Information Systems Laboratory</orgName>
								<orgName type="institution">Adam Mickiewicz University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Gillian</surname></persName>
							<email>egillian@pwsz.pl</email>
							<affiliation key="aff1">
								<orgName type="department">Faculty of English</orgName>
								<orgName type="institution">Adam Mickiewicz University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Human Evaluation of Grammatical Error Correction Systems</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The paper presents the results of the first large-scale human evaluation of automatic grammatical error correction (GEC) systems. Twelve participating systems and the unchanged input of the CoNLL-2014 shared task have been reassessed in a WMT-inspired human evaluation procedure. Methods introduced for the Workshop of Machine Translation evaluation campaigns have been adapted to GEC and extended where necessary. The produced rankings are used to evaluate standard metrics for grammatical error correction in terms of correlation with human judgment.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The field of automatic grammatical error correc- tion (GEC) has seen a number of shared tasks of different scope and for different languages. The most impactful were the <ref type="bibr">CoNLL-2013</ref><ref type="bibr">and CoNLL-2014</ref><ref type="bibr" target="#b19">(Ng et al., 2013</ref><ref type="bibr" target="#b20">Ng et al., 2014</ref>) shared tasks on Grammatical Error Correction for ESL (English as a second language) learn- ers. They were preceded by the HOO shared tasks ( <ref type="bibr" target="#b6">Dale and Kilgarriff, 2011;</ref><ref type="bibr" target="#b7">Dale et al., 2012)</ref>. Shared tasks for other languages took place as well, including the QALB workshops for Arabic ( <ref type="bibr" target="#b17">Mohit et al., 2014</ref>) and NLP-TEA competitions for Chinese. These tasks use automatic metrics to determine the quality of the participating systems.</p><p>However, these efforts pale in comparison to competitions organized in other fields, e.g. dur- ing the annual Workshops for Machine Transla- tion (WMT). It is a central idea of the WMTs that automatic measures of machine translation quality are an imperfect substitute for human assessments. Therefore, manual evaluation of the system out- puts are conducted and their results are reported as the final rankings of the workshops. These human evaluation campaigns are an important driving fac- tor for the advancement of MT and produce in- sightful "by-products", such as a huge number of human assessments of machine translation outputs that have been used to evaluate automatic metrics.</p><p>We believe that the unavailability of this kind of quality assessment may stall the development of GEC, as all the shared tasks and the entire field have to cope with an inherent uncertainty of their methods and metrics. We hope to make a step to- wards alleviating this lack of confidence by pre- senting the results of the first 1 large-scale human evaluation of automatic grammatical error correc- tion systems submitted to the CoNLL-2014 shared task. Most of our inspiration is drawn from the re- cent WMT edition ( ) and its met- rics task <ref type="bibr" target="#b14">(Macháček and Bojar, 2014</ref>).</p><p>We also provide an analysis of correlation be- tween the standard metrics in GEC and human judgment and show that the commonly used pa- rameters for standard metrics in the shared task may not be optimal. The uncertainty about met- rics quality leads to proposals of new metrics, with Felice and Briscoe (2015) being a recent example. Based on human judgments we can show that this proposed metric maybe less useful than hoped.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evaluation of GEC systems</head><p>Madnani et al. (2011) addresses two problems of GEC evaluation: 1) a lack of informative metrics and 2) an inability to directly compare the per- formance of systems developed by different re- searchers. Two evaluation methodologies are pre- sented, both based on crowdsourcing which are used to grade types of errors rather than system performance as presented in this work. <ref type="bibr" target="#b3">Chodorow et al. (2012)</ref> draw attention to the many evalua-tion issues in error detection which make it hard to compare different approaches. The lack of con- sensus is due to the nature of the error detection task. The authors argue that the choice of the met- ric should take into account factors such as the skew of the data and the application that the sys- tem is used for.</p><p>The most recent addition is <ref type="bibr" target="#b10">Felice and Briscoe (2015)</ref> who present a novel evaluation method for grammatical error correction that scores systems in terms of improvement on the original text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The CoNLL-2014 shared task</head><p>The goal of the CoNLL-2014 shared task ( <ref type="bibr" target="#b20">Ng et al., 2014</ref>) was to evaluate algorithms and systems for automatically correcting grammatical errors in English essays written by second language learn- ers of English. Training and test data was anno- tated with 28 error types. Participating teams were given training data with manually annotated cor- rections of grammatical errors and were allowed to use publicly available resources for training.</p><p>Twenty-five student non-native speakers of En- glish were recruited to write essays to be used as test data. Each student wrote two essays. The 50 test essays were error-annotated by two English native speakers. The essays and error annotations were made available after the task. The MaxMatch (M 2 ) scorer <ref type="bibr" target="#b5">(Dahlmeier and Ng, 2012)</ref> has been used as the official shared task evaluation metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data collection 4.1 Sampling sentences for evaluation</head><p>The system outputs of the CoNLL-2014 shared task serve as evaluation data. The test set consists of 1312 sentences, there are twelve system out- puts available. The thirteenth participant NARA is missing from this set. However, in GEC eval- uation there is also the input to consider. Often system outputs are equal to the unmodified input, as it is most desirable if there are in fact no errors. We include INPUT as the thirteenth system.</p><p>Due to the small number of modifications that GEC systems apply to the input, there is not only a large overlap with the input, but also among all systems <ref type="figure" target="#fig_1">(Figure 1</ref>). If we sample systems uni- formly, we lose easily obtainable pairwise judg- ments for systems with the same output, and if we collapse before sampling we introduce a strong bias towards ties. To counter that bias, we aban- don uniform sampling of test set sentences and use  instead a parametrized distribution that favors di- verse sets of outputs.</p><p>The probability p i for a set of outputs O i is cal- culated as follows: N is the number of systems to be evaluated, M is the maximum number of sen- tences presented to the evaluator in a single rank- ing (we use M = 5). The set of system outputs to be evaluated E = {O 1 , . . . , O n } ∀ 1≤i≤n |O i | = N , consists of n (= 1312) sets O i of N output sentences each. Every sentence in O i can overlap with other sentences multiple times, so for each set O i we define the corresponding multiset of multi- plicities U i , such that</p><formula xml:id="formula_0">u∈U i u = N .</formula><p>We define c i (j) as the number of possible ways to choose at most M different sentences that cover j systems for the i-th set of outputs:</p><formula xml:id="formula_1">c i (j) = S ⊆ U i : |S| ≤ M ∧ u∈S u = j .</formula><p>Then the expected number C i of systems cov- ered by choosing at most M sentences is</p><formula xml:id="formula_2">C i = N j=M c i (j) · j N j=M c i (j)</formula><p>. The pseudo-probability p i of sampling the i-th sentence is defined as</p><formula xml:id="formula_3">p i = M 2 C i 2</formula><p>where</p><formula xml:id="formula_4">C i 2 = C i (C i − 1) 2</formula><p>which is the ratio of pairwise comparisons of M versus C i different systems. By normalizing over 462 (a) Screenshot of Appraise modified for GEC judgment.</p><p>A B C D E  the entire set of output sets we obtain the probabil- ity p i of sampling the i-th set of outputs as</p><formula xml:id="formula_5">p i = p i |E| j=1 p j .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Collecting system rankings</head><p>The sets of outputs sampled with the described method have been prepared for Appraise <ref type="bibr" target="#b9">(Federmann, 2010</ref>) and presented to the judges. Judges were asked to rank sentences from best to worse. Ties are allowed. Judges were aware that the ab- solute ranks bear no relevance as ranks are later turned into relative pairwise judgments. No notion of "better" or "worse" was imposed by the authors, we relied on the judges to develop their own intu- ition. All eight judges are English native speakers and have extensive backgrounds in linguistics. <ref type="figure" target="#fig_3">Figure 2a</ref> displays a screen shot of Appraise with a judged sentence. Several modifications to the Appraise framework 2 were implemented to ac- count for the specific nature of GEC:</p><p>Only the input sentence is displayed (top, bold), no reference correction is given. The input sen- tence is surrounded by one preceding and one fol-lowing sentence. Identical corrections are col- lapsed into one output, system names with the same output are recorded internally. Edited frag- ments are highlighted, blue for insertions and sub- stitutions, pale blue and crossed-out for deletions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Pairwise judgments</head><p>As conducted during the WMT campaigns, we turn rankings into sets of relative judgments of the form A&gt;B, A=B, A&lt;B where the lower ranked system scores a win. Absolute ranks and differ- ences are lost. As mentioned above, due to the col- lapsing of identical outputs we obtain significantly more data than the usual 10 pairs from one ranking with five sentences.  between systems (on average there are only 5.7 unique outputs among 13 systems).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Inter-and intra-annotator agreement</head><p>Again inspired by the WMT evaluation cam- paigns, we compute annotator agreement as a measure of reliability of the pairwise judgments with Cohen's kappa coefficient <ref type="bibr" target="#b4">(Cohen, 1960)</ref>:</p><formula xml:id="formula_6">κ = P (A) − P (E) 1 − P (E) .</formula><p>where P (A) is the proportion of times that anno- tators agree, and P (E) is the proportion of times that they would agree by chance. κ assumes values from 0 (no agreement) to 1 (perfect agreement). All probabilities are computed as ratios of em- pirically counted pairwise judgments. As the judges worked on collapsed outputs, we calculate agreement scores for unexpanded pairs; otherwise, the high overlap would unfairly increase agree- ment.</p><p>P (A) is calculated by examining all pairs of outputs which have been judged by two or more judges, and counting the proportion of times that they agreed that A&lt;B, A=B, or A&gt;B.</p><p>P (E) = P (A&lt;B) 2 +P (A=B) 2 +P (A&gt;B) 2 is the probability that two judges agree randomly. Intra- annotator agreement as a measure of consistency is calculated for output sets that have been judged more than one time by the same annotator.</p><p>The agreement numbers in <ref type="table" target="#tab_2">Table 2</ref> are in the lower range of values reported during WMT. How- ever, it should be noted that judges never saw the repeated outputs within one ranking which prob- ably decreases agreement compared to the MT- specific task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Agreement</head><p>Value Degree</p><p>Inter-annotator 0.29 Weak Intra-annotator 0.46 Moderate (a) Inter-annotator and intra-annotator agree- ment for all judges <ref type="formula">1 2 3 4 5 6 7 8</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Computing ranks</head><p>In this section, it is our aim to produce a system ranking from best to worse by computing the av- erage number of times each system was judged better than other systems based on the collected pairwise rankings. While previously introduced methods for producing rankings, total orderings, as well as partial orderings at chosen confidence- levels, can be directly applied to our data, deter- mining which ranking is more accurate turns out to be methodologically and computationally more involved due to the specific nature of GEC outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Ranking methods</head><p>We adapt two ranking methods applied during WMT13 and WMT14 to GEC evaluation: the Ex- pected Wins method and a version of TrueSkill.</p><p>Expected Wins. Expected Wins (EW) has been introduced for WMT13  and is based on an underlying model of "relative ability" proposed in <ref type="bibr" target="#b12">Koehn (2012)</ref>. One advantage of this method is its intuitiveness; the scores reflect the probability that a system S i will be ranked better than another system that has been randomly cho- sen from a pool of opponents {S j : j = i}. Defin- ing the function win(A, B) as the number of times system A is ranked better than system B, Bojar et   </p><note type="other">6 RAC 0.331 0.149 0.266 7 UMC 0.312 0.144 0.253 8 PKU 0.322 0.136 0.253 9 SJTU 0.301 0.051 0.151 10 UFC 0.700 0.017 0.078 11 IPN 0.112 0.028 0.071 12 IITB 0.307 0.013 0.059 13 INPUT 0.000 0.000 0.000 (a) Official CoNLL-2014 ranking without un- published NARA system. # Score Range System 1 0.628 1 AMU 2 0.566 2-3 RAC 0.561 2-4 CAMB 0.550 3-5 CUUI 0.539 4-5 POST 3 0.513 6-8 UFC 0.506 6-8 PKU 0.495 7-9 UMC 0.485 7-10 IITB 0.463 10-11 SJTU 0.456 9-12 INPUT 0.437 11-12 NTHU 4 0.300 13 IPN (b) Human ExpectedWins ranking (final manual ranking). # Score Range System 1 0.273 1 AMU 2 0.182 2 CAMB 3 0.114 3-4 RAC 0.105 3-5 CUUI 0.080 4-5 POST 4 -0.001 6-7 PKU -0.022 6-8 UMC -0.041 7-10 UFC -0.055 8-11 IITB -0.062 8-11 INPUT -0.074 9-11 SJTU 5 -0.142 12 NTHU 6 -0.</note><formula xml:id="formula_7">score EW (S i ) = 1 |{S j }| j,j =i win(S i , S j ) win(S i , S j ) + win(S j , S i ) .</formula><p>TrueSkill. . Maintaining uncertainty allows TS to make greater changes to the ability estimates at the beginning and smaller changes after a number of consistent matches has been played. Due to that TS can identify the abil- ity of individual players from a smaller number of pairwise comparisons.</p><p>A modification of this approach to the WMT manual evaluation procedure by <ref type="bibr" target="#b22">Sakaguchi et al. (2014)</ref> has been adopted as the official rank- ing method during WMT14 replacing EW. The TrueSkill scores are calculated as inferred means:</p><formula xml:id="formula_8">score T S (S i ) = µ S i .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Rank clusters</head><p>Both ranking methods produce total orderings without information on the statistical significance of the obtained ranks.  notice that the similarity of the participants in terms of methods and training data causes some of them to be very similar and group systems into equiv- alence classes as proposed by <ref type="bibr" target="#b12">Koehn (2012)</ref>.</p><p>Although the methods and training data among the systems examined in this paper are quite di- verse, a great similarity of produced outputs is an inherent property of GEC. Therefore, in this sec- tion, for each system S j placed on rank r j we also try to determine the true systems rank ranges [r j , . . . , r j ] at a confidence-level of 95% and clus- ters of equivalent systems by following the proce- dure outlined by <ref type="bibr" target="#b12">Koehn (2012)</ref>. This is accomplished by applying bootstrap re- sampling. Pairwise rankings are drawn from the set of judgments with multiple drawings. Based on this sample a new ranking is produced. After repeating this process a 1000 times the obtained 1000 ranks for S j are sorted, with the top 25 and bottom 25 ranks being discarded. The interval of the remaining ranks serves as the final rank range. Next, these rank ranges are used to produce clus- ters of overlapping rank ranges. This is the last step required to produce the rankings in <ref type="table" target="#tab_5">Tables 3b  and 3c</ref> for both methods, EW and TS, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Choosing the final ranking</head><p>Now, we face the question which ranking should be presented as the final result of the human eval- uation task. Again, we turn to  who choose their rankings based on the ranking model's ability to predict pairwise rankings. Ac- curacy is computed by 100-fold cross-validation. For each fold a new ranking is trained from 99 parts with the left-over part serving as test data.</p><p>In a first step, we calculate the accuracy of the unclustered total orderings discarding ties. A ranking based on model scores alone cannot pre- dict ties, this requires equivalence classes.  define a draw radius r such that systems whose scores differ by less than r are assigned to one cluster, r is tuned to maximize accuracy.</p><p>In our case, due to the large number of ties, their method of tuning r is trapped in local maxima and assigns all systems to a single cluster. Alterna- tively, we propose to calculate clusters according to the method described in the previous section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EW TS</head><p>Total ordering (non-ties) 58.18 58.15 Bootstrapped clusters 40.12 39.48 <ref type="table">Table 4</ref>: Accuracy for ranking-based prediction of pairwise judgments.</p><p>By fixing p ≤ 0.05 we directly evaluate rank- ings of the form given in <ref type="table" target="#tab_5">Table 3</ref>. The absolute values of scores and their different interpretations between methods become irrelevant which makes it unnecessary to tune a parameter like r. The main drawback of this approach is its computa- tional cost. For each of the 100 folds we boot- strap another 100 rankings with EW and TS, fix p ≤ 0.05 and calculate rank clusters. The single clustered ranking for each fold is then used to cal- culate accuracy for the held-out test data. For our data, contrary to the MT-specific re- sults from , EW beats TS in both cases <ref type="table">(Table 4)</ref>. We therefore present the ExpectedWins-based ranking <ref type="table" target="#tab_5">(Table 3b)</ref> as the fi- nal result of the human evaluation effort described in this work and refer to it in the remainder of the paper when the human ranking is mentioned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Analysis</head><p>The final human-created ranking <ref type="table" target="#tab_5">(Table 3b</ref>) con- sists of four non-overlapping rank clusters. Rank ranges have been calculated at a confidence level of 95%. Comparing the official CoNLL-2014 ranking <ref type="table" target="#tab_5">(Table 3a)</ref> with the manually created Ex- pectedWins ranking shows interesting differences.</p><p>The AMU system is judged to be a clear leader by human judges in its own rank cluster. For six out of eight judges, AMU has the highest score ( <ref type="table" target="#tab_11">Table 7)</ref>. The officially winning system CAMB occupies third place in terms of EW scores and is placed in the second cluster with four systems. Only one judge put CAMB in first place. RAC, a middling system, is elevated to second place oc- cupying a rank cluster with three other systems. NTHU, another middling system that based on M 2 should be similar to RAC, is put in the second to last position. Two systems are judged to be worse than INPUT. The rank cluster that includes INPUT is the largest among the four clusters.</p><p>We also include pairwise comparisons between all systems according to EW in <ref type="table" target="#tab_5">Table 3d</ref>. Each cell contains the percentage of times the system in that column was judged to be better than the system in that row. Bold values mark the winner. We ap- plied the Sign Test to measure statistically signifi- cant differences, indicates statistical significance at p ≤ 0.10, † at p ≤ 0.05, and ‡ at p ≤ 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Correlation with GEC metrics</head><p>Since WMT08 <ref type="bibr" target="#b2">(Callison-Burch et al., 2008</ref>) the "metrics task" has been part of the WMT. The aim of the metrics task is to assess the quality of auto- matic evaluation metrics for MT in terms of cor- relation with the collected human judgments. We attempt the same in the context of GEC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Measures of correlation</head><p>Based on <ref type="bibr" target="#b13">Macháček and Bojar (2013)</ref>, we use Spearman's rank correlation ρ and Pearson's r to compare the similarity of rankings produced by various metrics to the manual ranking from the previous section.</p><p>Spearman's rank correlation ρ. Spearman's ρ for rankings with no ties is defined as</p><formula xml:id="formula_9">ρ = 1 − 6 d 2 i n(n 2 − 1)</formula><p>where d i is the distance between human and met- ric rank for system i, n is the number of systems.</p><p>Pearson's r. <ref type="bibr" target="#b13">Macháček and Bojar (2013)</ref> find that Spearman's ρ is too harsh and propose to also use Pearson's r, calculated as</p><formula xml:id="formula_10">r = n i=1 (H i − ¯ H)(M i − ¯ M ) n i=1 (H i − ¯ H) 2 n i=1 (M i − ¯ M ) 2</formula><p>where H and M are the vectors of human and met- ric scores, ¯ H and ¯ M are corresponding means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Metrics</head><p>The inventory of evaluation metrics for GEC is significantly smaller than for MT. We hope that making our data available will fuel the interest in this area. The following metrics are assessed:</p><p>MaxMatch (M 2 ). Due to its adoption as the main evaluation metric of the CoNLL shared tasks and the QALB shared tasks (Mohit et al., 2014), the M 2 metric (Dahlmeier and Ng, 2012) can be seen as a de facto standard. Being an F β -score, M 2 results are most influenced by the choice of β. Be- tween the <ref type="bibr">CoNLL-2013 and</ref><ref type="bibr">CoNLL-2014</ref> shared tasks, the organizers changed β from 1.0 to 0.5, and motivate this with intuition alone. The QALB shared tasks for Arabic continue to use β = 1.0.   Machine translation evaluation metrics. Bas- ing most of our results on findings from MT, we also take a look at two machine translation eval- uation metrics, BLEU ( <ref type="bibr" target="#b21">Papineni et al., 2002</ref>) and METEOR ( <ref type="bibr" target="#b8">Denkowski and Lavie, 2011)</ref>. In order to use the CoNLL-2014 gold standard with these metrics, the edit-based annotation has been con- verted into two plain text files, one per annotator.</p><formula xml:id="formula_11">Metric Spearman's ρ Pearson's r M 2 F 1.0 0.648 0.610 M 2 F 0.5 * 0.692 0.627 M 2 F 0.25 0.720 0.680 M 2 F 0.18 0.758 0.701 M 2 F 0.1 0.670 0.652 I-WAcc -0.154 -0.098 BLEU -0.346 -0.240 METEOR -0.374 -0.241</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Analysis</head><p>The correlation results are collected in  human judgment and is on the brink of high cor- relation for values of β closer to 0.2. Compared to M 2 , the other metrics are weakly or moderately inversely correlated to human judgment. Inverse correlation with human judgments for metrics that all assign higher scores to better systems seems problematic. In the case of I-WAcc, we would go as far as to state an absence of correlation. It seems the conservative approach adopted for I- WAcc does not correspond to the notion of quality that our judges worked out for themselves. The switch to β = 0.5 from β = 1.0 for the CoNLL- 2014 shared task was a good choice, but a higher correlation can be achieved for β = 0.25, the max- imum is reached for β = 0.18. Correlation drops sharply for β = 0.1. The lack of positive corre- lation for the MT-metrics is interesting in the light of improvement that results from a shift towards precision for M 2 as BLEU is based on precision. <ref type="figure" target="#fig_6">Figure 3</ref> contains detailed plots of ρ and r with regard to β within the <ref type="bibr">[0,</ref><ref type="bibr">1]</ref> range. As the CoNLL- 2014 test data included edits from two annotators, we plot curves for both annotators separately and for the combined gold standard. In the case of Spearman's ρ having alternative error annotations, this leads to higher correlation values. Based on the plots we would recommend setting 0.2 ≤ β ≤ 0.3 instead of 0.5 or even 1.0.</p><p>Inter-annotator correlations of rankings com- puted for individual judges <ref type="table">(Table 6)</ref> can be treated as human-level upper bounds for metric correla- tion. The penultimate column and row contain correlations of rankings for individual judges with rankings computed from all judges minus the re- spective judge. The last column and row con- tain the respective weighted (w.r.t. judgments per judge) average of these correlations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and future work</head><p>We have successfully adapted methods from the WMT human evaluation campaigns to automatic grammatical error correction. The collected and produced data has been made available and should be useful for other researchers. Although we set out to provide answers, we probably ended up with more questions. The following (and more) might be investigated in the future: What makes the win- ning system special and why do the standard met- rics fail at identifying this system? Can we come up with better system-level metrics? Can mean- ingful sentence-level metrics be developed?</p><p>Outside the scope of the particular data, we need to wonder if our results generalize to other shared tasks and other languages. The CoNLL-2014 data concerns ESL learners only and may not be trans- ferable to systems for native speakers. This would be in line with the ideas developed by <ref type="bibr" target="#b3">Chodorow et al. (2012)</ref>. We would hope to see similar endeav- ors for the other shared tasks as this would enable the field to draw more general conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Obtaining the data</head><p>The presented data and tools are available from: https://github.com/grammatical/ evaluation   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Frequencies of distinct corrected sentences produced by 13 systems per input sentence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Displayed ranking and corresponding overlapping rankings.</figDesc><graphic url="image-1.png" coords="3,85.81,58.28,303.88,455.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 2a contains a ranking with overlapping outputs as displayed in the top graph of Figure 2b. Pairs from within overlaps re- sult in ties, pairs between overlaps are expanded as products, 6 2 = 15 pairwise judgments can be extracted. Greater overlap leads to more pairwise judgments (bottom, 13 2 = 78).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>6 :</head><label>6</label><figDesc>Inter-annotator correlation (Spearman's ρ above the diagonal, Pearson's r below). I-measure/Weighted Accuracy (I-WAcc). The recently proposed I-WAcc metric (Felice and Briscoe, 2015) tries to address the shortcomings of M 2 . The inclusion of true negatives into the for- mula makes this a very conservative metric; quite similar to the MT metrics described below. The metric assigns negative weights to systems that are harmful with regard to the input text, values from the range [1, −1] are possible. The reported corre- lation values have been calculated for the ranking presented in Felice and Briscoe (2015).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Spearman's ρ and Pearson's r correlation of M 2 with human judgment w.r.t. β. Dashed line marks official CoNLL-2014 choice β = 0.5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>#</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 lists</head><label>1</label><figDesc></figDesc><table>the full statistics for collected rank-
ings by individual annotators. Unexpanded pairs 
are WMT-style pairwise judgments before an out-
put A gets split into overlapping systems A 1 , A 2 , 
A 3 , etc. The large number of ties for expanded 
pairs is to be expected due to the high overlap </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Inter-annotator and intra-annotator agree-
ment (Cohen's κ) on unexpanded pairwise judg-
ments. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparison of official CoNLL-2014 ranking and human rankings. Ranges and clusters have 
been calculated with bootstrap resampling at p ≤ 0.05. 

al. (2013) calculate EW scores as follows: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Correlation results for various metrics 
and human ranking. 

1 2 3 4 5 6 7 8 ρ ¯ 
ρ 
1 -.70 .31 .76 .74 .19 .62 .48 .70 

.72 

2 .72 -.77 .84 .90 .57 .59 .64 .93 
3 .53 .89 -.66 .70 .58 .42 .64 .63 
4 .82 .79 .69 -.91 .42 .67 .54 .91 
5 .65 .85 .82 .87 -.63 .63 .51 .93 
6 .32 .71 .67 .56 .86 -.63 .39 .42 
7 .72 .74 .57 .76 .72 .63 -.63 .76 
8 .64 .85 .86 .69 .72 .57 .75 -.60 
r .67 .93 .82 .87 .92 .66 .80 .82 -
¯ 
r 
.80 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>table 5 .</head><label>5</label><figDesc></figDesc><table>The 
M 2 metric is generally moderately correlated with </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Rankings by individual annotators. Cluster ranks and rank ranges have been computed with 
bootstrap resampling at p ≤ 0.1 to accomodate for the reduced number of judgments per judge. </table></figure>

			<note place="foot" n="1"> During the camera-ready preparation phase, we learned about similar research by Napoles et al. (2015). After contacting the authors, it was agreed to treat both works as fully concurrent. Future work will compare the results.</note>

			<note place="foot" n="2"> A fork of the original source code with can be found at https://github.com/snukky/Appraise</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Partially funded by the Polish National Science Centre (Grant No. 2014/15/N/ST6/02330).</p><p>The authors would like to thank the following judges for their hard work on the ranking task: Sam Bennett, Peter Dunne, Stacia Levy, Kenneth Turner, and John Winward.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Findings of the 2013 Workshop on Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eighth Workshop on Statistical Machine Translation</title>
		<meeting>of the Eighth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Findings of the 2014 Workshop on Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Saint-Amand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>of the Ninth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="12" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Further meta-evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cameron</forename><surname>Fordyce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Third Workshop on Statistical Machine Translation</title>
		<meeting>of the Third Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="70" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Problems in evaluating grammatical error detection systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Israel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING 2012</title>
		<meeting>of COLING 2012</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="611" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Better evaluation for grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2012 Conference of the North American Chapter of the ACL: Human Language Technologies</title>
		<meeting>of the 2012 Conference of the North American Chapter of the ACL: Human Language Technologies</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="568" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Helping our own: The HOO 2011 pilot shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 13th European Workshop on Natural Language Generation</title>
		<meeting>of the 13th European Workshop on Natural Language Generation</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="242" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hoo 2012: A report on the preposition and determiner error correction shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Anisimoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Narroway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Seventh Workshop on Building Educational Applications Using NLP</title>
		<meeting>of the Seventh Workshop on Building Educational Applications Using NLP</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="54" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Meteor 1.3: Automatic Metric for Reliable Optimization and Evaluation of Machine Translation Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the EMNLP 2011 Workshop on Statistical Machine Translation</title>
		<meeting>of the EMNLP 2011 Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Appraise: An opensource toolkit for manual phrase-based evaluation of translations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)</title>
		<meeting>of the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>ELRA</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards a standard evaluation method for grammatical error detection and correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariano</forename><surname>Felice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2015 Conference of the North American Chapter of the ACL: Human Language Technologies (NAACL-HLT 2015). ACL</title>
		<meeting>of the 2015 Conference of the North American Chapter of the ACL: Human Language Technologies (NAACL-HLT 2015). ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Trueskill(tm): A bayesian skill rating system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="569" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simulating human judgment in machine translation evaluation campaigns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Spoken Language Translation</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="179" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Results of the WMT13 metrics shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matouš</forename><surname>Macháček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eighth Workshop on Statistical Machine Translation</title>
		<meeting>of the Eighth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="45" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Results of the WMT14 metrics shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matouš</forename><surname>Macháček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>of the Ninth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="293" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">They can help: using crowdsourcing to improve the evaluation of grammatical error detection systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the</title>
		<meeting>of the</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">49</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<title level="m">Annual Meeting of the ACL: Human Language Technologies</title>
		<imprint>
			<publisher>ACL</publisher>
			<biblScope unit="page" from="508" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The first QALB shared task on automatic text correction for arabic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behrang</forename><surname>Mohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wajdi</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ossama</forename><surname>Obeid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the EMNLP 2014 Workshop on Arabic Natural Language Processing</title>
		<meeting>of the EMNLP 2014 Workshop on Arabic Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="39" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ground truth for grammaticality correction metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="588" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The CoNLL2013 shared task on grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hwee Tou Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Siew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Hadiwinoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 17th Conference on Computational Natural Language Learning</title>
		<meeting>of the 17th Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The CoNLL-2014 shared task on grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hwee Tou Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Siew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">Hendy</forename><surname>Hadiwinoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">,</forename><surname>Susanto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Bryant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eighteenth Conference on Computational Natural Language Learning</title>
		<meeting>of the Eighteenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">BLEU: A method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 40th Annual Meeting on ACL</title>
		<meeting>of the 40th Annual Meeting on ACL</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient elicitation of annotations for human evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>of the Ninth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
