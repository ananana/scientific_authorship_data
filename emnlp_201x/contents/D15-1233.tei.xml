<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reversibility reconsidered: finite-state factors for efficient probabilistic sampling in parsing and generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="1990">1990-1995. September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xerox Research Centre Europe</orgName>
								<address>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Venkatapathy</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xerox Research Centre Europe</orgName>
								<address>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyang</forename><surname>Xiao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xerox Research Centre Europe</orgName>
								<address>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reversibility reconsidered: finite-state factors for efficient probabilistic sampling in parsing and generation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="1990">1990-1995. September 2015. 2015</date>
						</imprint>
					</monogr>
					<note>‡ Amazon, Machine Learning Team, Bangalore, India * † (Opinion Piece)</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We restate the classical logical notion of generation/parsing reversibility in terms of feasible probabilistic sampling, and argue for an implementation based on finite-state factors. We propose a modular decomposition that reconciles generation accuracy with parsing robustness and allows the introduction of dynamic contextual factors.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The objective of Natural Language Understanding (NLU) is to map linguistic utterances to semantic representations, that of Natural Language Genera- tion (NLG) to map semantic representations to lin- guistic utterances. In most of NLP practice, these two objectives are handled by different processes, and computational linguists rarely operate at the intersection of the two subdomains.</p><p>For a few years around the early nineties, based both on cognitive, linguistic, and engineering con- siderations, there was a surge of interest in so called reversible grammar approaches to NLP, where one and the same grammatical specification could serve both for parsing utterance x into logi- cal form z, but also for generating x from z ( <ref type="bibr">Strzalkowski, 1994)</ref>.</p><p>We start by a brief review of this historical non- probabilistic notion of reversibility and point out certain of its weaknesses, in particular regarding robustness; we then give in section 3 a new proba- bilistic definition of reversibility; then, in section 4 we argue for a reversibility model based on modu- lar weighted finite-state transducers. We end with a discussion of recent related work. * Work done while at XRCE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Classical reversibility</head><p>The most direct approaches to NLU attempt to de- sign procedures for semantic parsing that, given an input utterance x, produce a semantic repre- sentation z, by following a number of interme- diate steps where the surface form is gradually transformed into semantic structure. Such "pro- cedural" approaches to semantic parsing are typ- ically very hard or impossible to invert: start- ing from a semantic representation z, there is no simple process that is able to find an x which, when given to the parser, would produce z. For- mally, a Boolean relation r(x, z) can be such that the question ?∃z r(x, z) is decidable for all x's, while the reciprocal question ?∃x r(x, z) is unde- cidable for some z's <ref type="bibr" target="#b5">(Dymetman, 1991)</ref>. <ref type="bibr">1</ref> One of the motivations for the emerging paradigm of uni- fication grammars at the end of the eighties was the clean separation they promised between spec- ifying well-formed linguistic structures, both on the syntactic and semantic levels, through a for- mal description of the relation r(x, z), and pro- ducing efficient implementations of the specifi- cation; in particular, there was much hope that such formalisms would be conductive to effec- tive reversibility (by contrast to variable assign- ment, variable unification is inherently symmetri- cal), that is, to feasible (and if possible efficient) implementations of the parsing problem r(x, ?) and of the generation problem r(?, z).</p><p>To some extent, this hope was validated through a number of works at the time, mostly involving machine translation applications, and constrain- ing in more or less explicit ways the specifica- tion of r (van Noord, 1990). However, for the non-statistical approaches to parsing then strongly dominant, robustness was an issue: a parser had to either accept or reject a given input x, with no in- termediary options, and in order to be able to parse actual utterances, with all their empirical diversity, parsers had to be rather tolerant. In the procedural view of parsing, such robustness issues could of- ten be mitigated through engineering tricks such as ordering the rules from strict to lax, where gram- matical constructions were given preference over less conventional ones; however, when trying to move to reversible grammars, these tricks could not be reproduced: if the grammar was able to parse an x into z, then, by design, it was also able to generate x from z, and there was no obvious way, in these non-probabilistic approaches, to dis- tinguish between producing a linguistically correct x or producing a deviant or incorrect one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Probabilistic reversibility</head><p>In the classical non-probabilistic case, a (relative) consensus existed around the fact that a reversible grammar should be, as we indicated above, a for- mal specification of the relation r(x, z) such that the problems r(x, ?) and r(?, z) were effectively solvable.</p><p>Transposing this to the probabilistic world, we propose the following semi-formal Definition:</p><p>A probabilistic reversible grammar is a for- mal specification of a joint probability distribu- tion p(x, z) over logical forms z and utterance strings x such that the conditional distributions</p><formula xml:id="formula_0">p(z|x) def = p(x,z) z p(x,z ) (parsing) and p(x|z) def = p(x,z)</formula><p>x p(x ,z) (generation) can be efficiently sampled from. <ref type="bibr">2</ref> Why such focus on sampling? We could have chosen other definitions of parsing (and similarly for generation), for instance the ability to re- turn the most probable z given x, i.e. to return argmax z p(z|x); however sampling is the most di- rect way of providing a concrete view of the un- derlying probabilistic distribution, and has many applications to learning, so we think the definition above is reasonable (see also footnote 4 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Finite-state models for reversibility</head><p>Finite-state transducers have properties which make them uniquely suited to implementing re- versible linguistic specifications in the above sense. Consider a simple weighted string-to- string transducer τ (s, t), where s, t are strings, and where the underlying semiring is the "probabilis- tic semiring" over the nonnegative reals, addition and multiplication having their usual interpreta- tions. Such a transducer preserves regularity, both in the forward (resp. reverse) directions, meaning that the image through τ of any weighted regular language over s (resp. over t) is again a weighted regular language over t (resp. over s). In partic- ular the forward (resp. reverse) image of a fixed string s 0 (resp t 0 ) can be computed in a compact form as a weighted finite-state automaton (FSA) over t (resp. s), which we can denote by τ (s 0 , ·) (resp. τ (·, t 0 )). A weighted FSA can be easily nor- malized into a probabilistic FSA 3 and, from this probabilitic FSA exact samplers for the "parser" τ (s 0 , ·) and for the "generator" τ (·, t 0 )) are di- rectly obtained. <ref type="bibr">4</ref> In general, some of the properties that make weighted FSAs and FSTs -over strings or trees -specially relevant for probabilistic models of language are the following: (i) they allow com- pact representations of complex probability distri- butions over linguistic objects (automata) or pairs of linguistic objects (transducers), (ii) they permit efficient exact sampling (and efficient optimiza- tion over derivations (but not always over strings)), (iii) they support modularity: intersection of au- tomata, composition of transducers, projections of an automaton through a transducer. <ref type="bibr">5</ref> Conceptual architecture Armed with these general considerations, let us now propose a con- ceptual architecture based on a small number of finite-state modules, which attempts to satisfy the definition given above for probabilistic reversibil- ity, to address the problem of robustness that we described earlier, and can also support contex- tual preferences. We illustrate the approach with some simple examples of human-machine dia- logues (between a customer and a virtual agent), a domain for which reversibility has high relevance, due to effects such as self-monitoring <ref type="bibr" target="#b14">(Neumann, 1998;</ref><ref type="bibr" target="#b10">Levelt, 1983)</ref>, interleaving of understand- ing and generation <ref type="bibr" target="#b15">(Otsuka and Purver, 2003)</ref>, and lexical entrainment <ref type="bibr" target="#b2">(Brennan, 1996)</ref>. The conceptual architecture is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Formally, the figure represents a probabilistic graphical model in so-called factor form, where the factors are ω, κ, σ, λ (we have also indicated for future reference the "contextual" factors ζ, µ, that we ignore for now). The factors take as argu- ments three types of objects: z is a logical form, that is, a structured object which can be naturally represented as a tree, x is a surface string, and y is a latent "underlying" string that corresponds to one of a small collection of "canonical" texts for realizing the logical form z (more about that later). Each factor is realized through a weighted finite-state machine (acceptor or transducer) over strings or trees <ref type="bibr" target="#b13">(Mohri, 2009;</ref><ref type="bibr" target="#b6">Fülöp and Vogler, 2009;</ref><ref type="bibr" target="#b11">Maletti, 2010;</ref><ref type="bibr" target="#b7">Graehl et al., 2008)</ref>.</p><p>The λ factor is a string automaton that repre- sents a standard ngram language model (typically specific to domain), in other words a probability distribution over utterances x. Symmetrically, the regular tree automaton ω represents a distribution over logical forms z, which can be seen as play- ing a similar role to the language model, but at the semantic level, namely telling us what are the pos- sible/likely logical forms in a certain domain. <ref type="bibr">6</ref> The "canonical factor" κ is a weighted tree- to-string transducer ( <ref type="bibr" target="#b7">Graehl et al., 2008)</ref>, which implements a relation between logical forms z and a small number of latent "canonical" texts y realizing these logical forms. For example, κ may associate the logical form (dialog act) z = wad(batLife, iphone6) -with wad an abbrevi- ation for "what is the value of this attribute on this device?", and batLife an abbreviation for "bat- tery life" -, with such a canonical text (among a few others) as: What is the battery life of the Iphone 6?.</p><p>The "similarity factor" σ is a weighted string- to-string finite state transducer which gives scores to x, y according to a notion of similarity. It has the role of "bridging" the gap between the actual utterances x and the latent canonical utterances y. The intention behind the similarity factor is to "de- couple" the task of modeling some possible real- izations of a given logical form from the task of recognizing that a given more or less well-formed input is a variant of such a realization. This fac- tor relates the two strings y and x, where y is a possible canonical utterance in the limited reper- tory produced by κ, and x is an actual utterance, in particular any utterance that could be produced by a human speaker. So for instance suppose that the user's utterance is x = What about battery du- ration on this Iphone 6?, we would like this x to have a significant similarity with the canonical ut- terance y = What is the battery life of the Iphone 6? but a negligible similarity with another canon- ical utterance such as y = What is the screen size of the Galaxy Trend?.</p><p>Overall, the canonical factor κ(z, y) concen- trates more on a core "generation model", namely on producing some well-formed output y from a logical form z, while the similarity factor σ(y, x) allows relating an actual user input x to a possi- ble output y of the κ model. The main import of σ is then to allow to use the core generation model defined by κ to be exploited for robust semantic parsing.</p><p>Different instantiations of this scheme can be employed. In some preliminary experiments that we have performed, 7 σ is a simple edit-distance transducer <ref type="bibr" target="#b12">(Mohri, 2003)</ref> which penalizes differ- ently the discrepancies between x and y: strongly for some salient content words or named entities of the domain, weakly for less relevant content words and for non-content words, with limited use of lo- cal paraphrases (which can also be implemented through σ). This strategy seems to work reason- ably well when the semantical repertory of the do- main is restricted, because a large number of pos- sible variants for x are "attracted" to the same un- derlying semantics. In domains where small nu- ances of expression may result in distinct seman- tics, the division of work between κ and σ may be different.</p><p>Parsing and Generation To understand the re- versibility properties of the model of <ref type="figure" target="#fig_0">Figure 1</ref>, let us first simplify the description by assuming that z, instead of being a tree, is actually a string. Then both ω and λ are string automata, and both κ and σ string-to-string transducers. Such a spec- ification satisfies our definition of probabilistic re- versibility, exploiting well-known compositional- ity properties of weighted finite-state machines over strings <ref type="bibr" target="#b13">(Mohri, 2009)</ref>. For parsing, we start from a fixed x 0 , and can project it through σ into a weighted FSA over y; in turn we can project this automaton onto an FSA over z, and finally intersect this automaton with ω, obtaining a fi- nal weighted "x 0 -parser" automaton over z, rep- resenting a probability distribution from which we can draw exact samples as explained above. 8 Gen- eration works in exactly the reverse way, starting from a z 0 and eventually building a "z 0 -generator" automaton over x.</p><p>In the actual proposal, z is a tree, meaning that ω is a tree automaton, and κ a tree-to-string trans- ducer. While finite-state tree automata correspond to a single concept, and share all the nice proper- ties of string automata <ref type="bibr" target="#b4">(Comon et al., 2007)</ref>, the situation with tree-to-tree or tree-to-string trans- ducers is more complicated <ref type="bibr" target="#b11">(Maletti, 2010;</ref><ref type="bibr" target="#b7">Graehl et al., 2008)</ref>: several variants exist, only some of which support the operations that our conceptual model requires (composition with the string trans- ducer σ and intersection with the tree automaton ω). In particular, the "linear non-deleting top- down tree transducers" defined in <ref type="bibr" target="#b11">(Maletti, 2010)</ref>  <ref type="bibr">9</ref> have the requisite properties.</p><p>Contextual factors We now briefly come back to the factors ζ (tree automaton) and µ (string automaton) of <ref type="figure" target="#fig_0">Figure 1</ref>, which highlight the use-fulness of our modular finite-state architecture. These factors play similar roles to ω and λ, but they evolve dynamically with the context. In dia- logue applications, utterances can often only be in- terpreted by reference to the current dialogue state (e.g. "ten hours" in the context of a question about battery life), and the ζ factor can be used as a com- pact representation of the current expectations of the dialogue manager about the next logical form, to be combined with the actual customer's utter- ance. Symmetrically, the µ factor can be used to represent such phenomena as lexical entrain- ment <ref type="bibr" target="#b2">(Brennan, 1996)</ref>, where the agent's utterance is oriented towards using similar wordings to the customer's.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>The unique formal properties of finite-state ma- chines, which favor modular decompositions of complex tasks, have long been exploited in Com- putational Linguistics. Tree transducers in partic- ular have gained popularity in Statistical Machine Translation, starting with ( <ref type="bibr" target="#b24">Yamada and Knight, 2001</ref>), as described in the surveys <ref type="bibr" target="#b11">(Maletti, 2010;</ref><ref type="bibr" target="#b16">Razmara, 2011)</ref>.</p><p>The reversibility properties of finite-state trans- ducers have been exploited to a more limited ex- tent, starting with applications of non-weighted string-to-string transducers to morphological anal- ysis and generation <ref type="bibr" target="#b0">(Beesley, 1996)</ref>.</p><p>Concerning the application of weighted finite- state tree machines to NLU/NLG reversibility, our proposal is strongly related on the one hand to the approach of ( <ref type="bibr" target="#b8">Jones et al., 2012)</ref>, who ex- plicitely proposes tree-to-string transducers as a tool for modelling semantic parsing and for train- ing on semantically annotated data, and on the other hand to <ref type="bibr" target="#b23">(Wong, 2007;</ref><ref type="bibr" target="#b22">Wong and Mooney, 2007)</ref>, who focus more directly on the problem of inverting a semantic parser into a generator. Wong et al. do not explicitely use tree-based transducers, but rather a formalism inspired by SCFGs (syn- chronous context-free grammars), which essen- tially corresponds to a form of tree-to-string trans- ducer. In relation to reversibility considerations, presentations in terms of synchronous formalisms have the interest that they are intrinsically sym- metrical. Such formalisms have tight relations to tree-transducers <ref type="bibr" target="#b18">(Shieber, 2004)</ref>; one recently pro- posed generalization, "Interpreted Regular Tree Grammars" ( <ref type="bibr" target="#b9">Koller and Kuhlmann, 2011</ref>), allows multiple (possibly more than two) synchronized views of an underlying abstract derivation tree, and has the advantage of permitting a uniform treatment of strings and trees.</p><p>One important aspect in which our proposal dif- fers from these previous approaches is in propos- ing to decouple the "core" task of mapping logical forms to well-formed latent canonical realizations from the task of relating these realizations to ac- tual utterances, through an additional "similarity" transducer acting as a bridge.</p><p>This idea of a bridge is however close to another line of work in semantic parsing, not transducer based, namely <ref type="bibr" target="#b1">(Berant and Liang, 2014;</ref><ref type="bibr" target="#b21">Wang et al., 2015)</ref>. There, a simple generic grammar is used to generate canonical realizations from a repertory of possible logical forms (expressed in a variant of lambda calculus). Given an input to parse, simple heuristics are used to select a fi- nite list of potential logical forms which are then ranked according to the (paraphrase-based) simi- larity of their associated canonical realization with the input. Thus in this approach, a form of gener- ation plays an important role, not for its own sake, but as a tool for semantic parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Because of their unique compositional properties, finite-state modules are a natural choice for imple- menting our definition of reversibility as efficient bidirectional sampling from a common specifica- tion. In this piece we have argued in favor of an architecture realizing this definition and display- ing robustness and contextuality.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Reversible specification through finitestate factors.</figDesc></figure>

			<note place="foot" n="1"> Some intuition into the issue may be gained by considering typical techniques of public key cryptography, which rely on the difficulty of inverting some simple arithmetic computations.</note>

			<note place="foot" n="2"> We note the &quot;semi-formal&quot; aspect of this definition: contrarily to the classical case, which has a formal notion of effective computation, there is no universally accepted notion of effective sampling from a probability distribution. For many probability distributions, the only feasible sampling approaches are the MCMC techniques (Robert and Casella, 2004), which typically do not come with convergence guarantees; in some situations, exact sampling techniques are applicable, which come with much better guarantees. We will see that the approach proposed in section 4 allows such exact sampling to take place.</note>

			<note place="foot" n="3"> That is, into a weighted FSA such the weights of the transitions from each state sum to 1. 4 While sampling strings from a weighted finite-state automaton is simple, finding the most probable string (not path) in a probabilistic FSA is an NP-hard problem (Casacuberta and de la Higuera, 2000), and one has to resort to the socalled Viterbi approximation (assuming that the most probable path projects into the most probable string). Contrary to popular belief, sampling can sometimes be simpler than optimization. 5 Outside of the realm of finite-state machines, this modularity is typically impossible to obtain. Thus, in general, the availability of a sampler for a distribution p(x) (resp. a distribution q(x)) does not imply that we can efficiently sample from the product (i.e. intersection) p(x).q(x), but we can in case p and q are both represented by weighted FSAs.</note>

			<note place="foot" n="6"> In particular, the ω factor makes explicit the notion of a well-formed semantic representation, a notion often left implicit in semantic parsing.</note>

			<note place="foot" n="7"> In these experiments, we used string-based approximations of the logical forms, and only employed string-based transducers from the OpenFST library.</note>

			<note place="foot" n="8"> We could also have precompiled a generic parser for all x&apos;s by first marginalizing the latent variable y through a composition of the transducers κ and σ, and then intersecting the resulting transducer with the automaton ω. 9 The paper only defines tree-to-tree transducers, but treeto-string variants can be derived easily.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Arabic Finite-State Morphological Analysis and Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Beesley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coling</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="89" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Lexical entrainment in spontaneous dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Brennan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Symposium on Spoken Dialogue</title>
		<meeting>International Symposium on Spoken Dialogue</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
	<note>ISSD-96</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Computational complexity of problems on probabilistic grammars and transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Casacuberta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin De La</forename><surname>Higuera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICGI</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="15" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Tree automata techniques and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Comon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dauchet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gilleron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Löding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jacquemard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lugiez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tommasi</surname></persName>
		</author>
		<ptr target="http://www.grappa.univ-lille3.fr/tata.release" />
		<imprint>
			<date type="published" when="2007-10-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Inherently reversible grammars, logic programming and computability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop: Reversible Grammar in Natural Language Processing</title>
		<meeting>the ACL Workshop: Reversible Grammar in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Weighted tree automata and tree transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoltán</forename><surname>Fülöp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Vogler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Weighted Automata</title>
		<editor>Manfred Droste, Werner Kuich, and Heiko Vogler</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="313" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Training tree transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Graehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="391" to="427" />
			<date type="published" when="2008-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semantic parsing with bayesian tree transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keeley</forename><surname>Bevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="488" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A generalized view on parsing and translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Parsing Technologies, IWPT &apos;11</title>
		<meeting>the 12th International Conference on Parsing Technologies, IWPT &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2" to="13" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Monitoring and self-repair in speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Levelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="104" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Survey: Tree transducers in machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Maletti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>Universitat Rovira i Virgili</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Edit-Distance of Weighted Automata: General Definitions and Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Foundations of Computer Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="957" to="982" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Weighted automata algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Weighted Automata</title>
		<editor>Manfred Droste, Werner Kuich, and Heiko Vogler</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="213" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Interleaving natural language parsing and generation through uniform processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günter</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="121" to="163" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Incremental generation by incremental parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Otsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Purver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 6th CLUK Colloquium</title>
		<meeting>6th CLUK Colloquium</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Applications of tree transducers in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Majid Razmara</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>Simon Fraser University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Monte Carlo Statistical Methods (Springer Texts in Statistics)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Christian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Casella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Springer-Verlag New York, Inc</publisher>
			<pubPlace>Secaucus, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Synchronous grammars as tree transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Workshop on Tree Adjoining Grammar and Related Formalisms</title>
		<meeting>the Seventh International Workshop on Tree Adjoining Grammar and Related Formalisms<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05" />
			<biblScope unit="page" from="20" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Reversible Grammar in Natural Language Processing</title>
		<editor>Tomek Strzalkowski</editor>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reversible unification based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gertjan Van Noord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference on Computational Linguistics</title>
		<meeting>the 13th Conference on Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1990" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="299" to="304" />
		</imprint>
	</monogr>
	<note>COLING &apos;90</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Building a semantic parser overnight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generation by inverting a semantic parser that uses statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="172" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning for Semantic Parsing and Natural Language Generation Using Statistical Machine Translation Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<idno>AI07-343</idno>
		<imprint>
			<date type="published" when="2007-08" />
			<pubPlace>Austin, TX, August</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Sciences, University of Texas at Austin ; Artificial Intelligence Lab, University of Texas at Austin</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
	<note>Also appears as</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A syntaxbased statistical translation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, ACL &apos;01</title>
		<meeting>the 39th Annual Meeting on Association for Computational Linguistics, ACL &apos;01<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="523" to="530" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
