<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:18+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stance Detection with Bidirectional Conditional Encoding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
							<email>i.augenstein@ucl.ac.uk, t.rocktaschel@cs.ucl.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">University College London</orgName>
								<orgName type="institution" key="instit2">University of Sheffield</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">University College London</orgName>
								<orgName type="institution" key="instit2">University of Sheffield</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">University College London</orgName>
								<orgName type="institution" key="instit2">University of Sheffield</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">University College London</orgName>
								<orgName type="institution" key="instit2">University of Sheffield</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Stance Detection with Bidirectional Conditional Encoding</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="876" to="885"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Stance detection is the task of classifying the attitude Previous work has assumed that either the target is mentioned in the text or that training data for every target is given. This paper considers the more challenging version of this task, where targets are not always mentioned and no training data is available for the test targets. We experiment with conditional LSTM encoding, which builds a representation of the tweet that is dependent on the target, and demonstrate that it outperforms encoding the tweet and the target independently. Performance is improved further when the conditional model is augmented with bidi-rectional encoding. We evaluate our approach on the SemEval 2016 Task 6 Twitter Stance Detection corpus achieving performance second best only to a system trained on semi-automatically labelled tweets for the test target. When such weak supervision is added, our approach achieves state-of-the-art results.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of stance detection is to classify the attitude expressed in a text towards a given target, as "pos- itive", "negative", or "neutral". Such information can be useful for a variety of tasks, e.g. <ref type="bibr" target="#b11">Mendoza et al. (2010)</ref> showed that tweets stating actual facts were affirmed by 90% of the tweets related to them, while tweets conveying false information were pre- dominantly questioned or denied. In this paper we focus on a novel stance detection task, namely tweet stance detection towards previously unseen targets (mostly entities such as politicians or issues of pub- lic interest), as defined in the SemEval Stance De- tection for Twitter task <ref type="bibr" target="#b14">(Mohammad et al., 2016)</ref>. This task is rather difficult, firstly due to not having training data for the targets in the test set, and sec- ondly, due to the targets not always being mentioned in the tweet. For example, the tweet "@realDon- aldTrump is the only honest voice of the @GOP" expresses a positive stance towards the target Don- ald Trump. However, when stance is annotated with respect to Hillary Clinton as the implicit target, this tweet expresses a negative stance, since supporting candidates from one party implies negative stance towards candidates from other parties.</p><p>Thus the challenge is twofold. First, we need to learn a model that interprets the tweet stance towards a target that might not be mentioned in the tweet it- self. Second, we need to learn such a model without labelled training data for the target with respect to which we are predicting the stance. In the example above, we need to learn a model for Hillary Clinton by only using training data for other targets. While this renders the task more challenging, it is a more realistic scenario, as it is unlikely that labelled train- ing data for each target of interest will be available.</p><p>To address these challenges we develop a neu- ral network architecture based on conditional encod- ing ( <ref type="bibr">Rocktäschel et al., 2016)</ref>. A long-short term memory (LSTM) network <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997</ref>) is used to encode the target, followed by a second LSTM that encodes the tweet using the encoding of the target as its initial state. We show that this approach achieves better F1 than an SVM baseline, or an independent LSTM encoding of the tweet and the target. Results improve fur-ther (0.4901 F1) with a bidirectional version of our model, which takes into account the context on ei- ther side of the word being encoded. In the context of the shared task, this would have been the second best result, except for an approach which uses auto- matically labelled tweets for the test targets (F1 of 0.5628). Lastly, when our bidirectional conditional encoding model is trained on such data, it achieves state-of-the-art performance (0.5803 F1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Setup</head><p>The SemEval 2016 Stance Detection for Twitter shared task ( <ref type="bibr" target="#b14">Mohammad et al., 2016)</ref> consists of two subtasks, Task A and Task B. In Task A the goal is to detect the stance of tweets towards tar- gets given labelled training data for all test targets (Climate Change is a Real Concern, Feminist Move- ment, Atheism, Legalization of Abortion and Hillary Clinton). In Task B, which is the focus of this paper, the goal is to detect stance with respect to an un- seen target, Donald Trump, for which labeled train- ing/development data is not provided.</p><p>Systems need to classify the stance of each tweet as "positive" (FAVOR), "negative" (AGAINST) or "neutral" (NONE) towards the target. The official metric reported for the shared task is F1 macro- averaged over the classes FAVOR and AGAINST. Although the F1 of NONE is not considered, sys- tems still need to predict it to avoid precision errors for the other two classes.</p><p>Even though participants were not allowed to manually label data for the test target Donald Trump, they were allowed to label data automatically. The two best-performing systems submitted to <ref type="bibr">Task B, pkudblab (Wei et al., 2016)</ref> and <ref type="bibr">LitisMind (Zarrella and Marsh, 2016</ref>) made use of this, thus changing the task to weakly supervised seen target stance de- tection, instead of an unseen target task. Although the goal of this paper is to present stance detec- tion methods for targets for which no training data is available, we show that they can also be used successfully in a weakly supervised framework and outperform the state-of-the-art on the SemEval 2016 Stance Detection for Twitter dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>A common stance detection approach is to treat it as a sentence-level classification task similar to sen- timent analysis <ref type="bibr" target="#b15">(Pang and Lee, 2008;</ref><ref type="bibr" target="#b19">Socher et al., 2013)</ref>. However, such an approach cannot capture the stance of a tweet with respect to a particular tar- get, unless training data is available for each of the test targets. In such cases, we could learn that a tweet mentioning Donald Trump in a positive man- ner expresses a negative stance towards Hillary Clin- ton. Despite this limitation, we use two such base- lines, one implemented with a Support Vector Ma- chine (SVM) classifier and one with an LSTM net- work, in order to assess whether we are successful in incorporating the target in stance prediction.</p><p>A naive approach to incorporate the target in stance prediction would be to generate features con- catenating the target with words from the tweet. Ig- noring the issue that such features would be rather sparse, a classifier could learn that some words have target-dependent stance weights, but it still assumes that training data is available for each target.</p><p>In order to learn how to combine the stance target with the tweet in a way that generalises to unseen targets, we focus on learning distributed represen- tations and ways to combine them. The following sections develop progressively the proposed bidirec- tional conditional LSTM encoding model, starting from independently encoding the tweet and the tar- get using LSTMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Independent Encoding</head><p>Our initial attempt to learn distributed representa- tions for the tweets and the targets is to encode the target and tweet independently as k-dimensional dense vectors using two LSTMs <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997)</ref>.</p><formula xml:id="formula_0">H = x t h t−1 i t = σ(W i H + b i ) f t = σ(W f H + b f ) o t = σ(W o H + b o ) c t = f t c t−1 + i t tanh(W c H + b c ) h t = o t tanh(c t ) x 1 c → 1 c ← 1 h → 1 h ← 1 x 2 c → 2 c ← 2 h → 2 h ← 2 x 3 c → 3 c ← 3 h → 3 h ← 3 x 4 c → 4 c ← 4 h → 4 h ← 4 x 5 c → 5 c ← 5 h → 5 h ← 5 x 6 c → 6 c ← 6 h → 6 h ← 6 x 7 c → 7 c ← 7 h → 7 h ← 7 x 8 c → 8 c ← 8 h → 8 h ← 8 x 9 c → 9 c ← 9 h → 9 h ← 9</formula><p>Legalization of Abortion A foetus has rights too ! Target Tweet Here, x t is an input vector at time step t, c t denotes the LSTM memory, h t ∈ R k is an output vector and the remaining weight matrices and biases are train- able parameters. We concatenate the two output vec- tor representations and classify the stance using the softmax over a non-linear projection</p><formula xml:id="formula_1">softmax(tanh(W ta h target + W tw h tweet + b))</formula><p>into the space of the three classes for stance detec- tion where W ta , W tw ∈ R 3×k are trainable weight matrices and b ∈ R 3 is a trainable class bias. This model learns target-independent distributed repre- sentations for the tweets and relies on the non- linear projection layer to incorporate the target in the stance prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Conditional Encoding</head><p>In order to learn target-dependent tweet representa- tions, we use conditional encoding as previously ap- plied to the task of recognising textual entailment ( <ref type="bibr">Rocktäschel et al., 2016</ref>). We use one LSTM to en- code the target as a fixed-length vector. Then, we encode the tweet with another LSTM, whose state is initialised with the representation of the target. Finally, we use the last output vector of the tweet LSTM to predict the stance of the target-tweet pair.</p><p>Formally, let (x 1 , . . . , x T ) be a sequence of tar- get word vectors, (x T +1 , . . . , x N ) be a sequence of tweet word vectors and [h 0 c 0 ] be a start state of zeros. The two LSTMs map input vectors and a pre- vious state to a next state as follows:</p><formula xml:id="formula_2">[h 1 c 1 ] = LSTM target (x 1 , h 0 , c 0 ) . . . [h T c T ] = LSTM target (x T , h T −1 , c T −1 ) [h T +1 c T +1 ] = LSTM tweet (x T +1 , h 0 , c T ) . . . [h N c N ] = LSTM tweet (x N , h N −1 , c N −1 )</formula><p>Finally, the stance of the tweet w.r.t. the target is classified using a non-linear projection</p><formula xml:id="formula_3">c = tanh(Wh N )</formula><p>where W ∈ R 3×k is a trainable weight matrix. This effectively allows the second LSTM to read the tweet in a target-specific manner, which is crucial since the stance of the tweet depends on the target (recall the Donald Trump example above).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Bidirectional Conditional Encoding</head><p>Bidirectional LSTMs ( <ref type="bibr" target="#b6">Graves and Schmidhuber, 2005</ref>) have been shown to learn improved represen- tations of sequences by encoding a sequence from left to right and from right to left. Therefore, we adapt the conditional encoding model from Sec- tion 3.2 to use bidirectional LSTMs, which repre- sent the target and the tweet using two vectors for each of them, one obtained by reading the target and then the tweet left-to-right (as in the conditional LSTM encoding) and one obtained by reading them right-to-left. To achieve this, we initialise the state of the bidirectional LSTM that reads the tweet by the last state of the forward and reversed encoding of the target (see <ref type="figure" target="#fig_0">Figure 1</ref>). The bidirectional encod- ing allows the model to construct target-dependent representations of the tweet such that when a word is considered, both its left-and the right-hand side context are taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Unsupervised Pretraining</head><p>In order to counter-balance the relatively small amount of training data available (5,628 instances in total), we employ unsupervised pre-training by initialising the word embeddings used in the LSTMs with an appropriately trained word2vec model ( <ref type="bibr" target="#b12">Mikolov et al., 2013)</ref>. Note that these em- beddings are used only for initialisation, as we allow them to be optimised further during training.</p><p>In more detail, we train a word2vec model on a corpus of 395,212 unlabelled tweets, collected with the Twitter Keyword Search API 1 between Novem- ber 2015 and January 2016, plus all the tweets con- tained in the official SemEval 2016 Stance Detec- tion datasets <ref type="bibr" target="#b14">(Mohammad et al., 2016</ref>). The unla- belled tweets are collected so that they contain the targets considered in the shared task, using up to two keywords per target, namely "hillary", "clin- ton", "trump", "climate", "femini", "aborti". Note that Twitter does not allow for regular expression search, so this is a free text search disregarding pos- sible word boundaries. We combine this large unla- belled corpus with the official training data and train a skip-gram word2vec model (dimensionality 100, 5 min words, context window of 5).</p><p>Tweets and targets are tokenised with the Twitter- adapted tokeniser twokenize 2 . Subsequently, all to- kens are lowercased, URLs are removed, and stop- word tokens are filtered (i.e. punctuation characters, Twitter-specific stopwords ("rt", "#semst", "via").</p><p>As it will be shown in our experiments, unsuper- vised pre-training is quite helpful, since it is difficult to learn representations for all the words using only the relatively small training datasets available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus</head><p>Favor Against None All <ref type="table" target="#tab_0">TaskA Tr+Dv  1462  2684 1482 5628  TaskA Tr+Dv HC 224  722  332  1278  TaskB Unlab  - - - 278,013  TaskB Auto-lab* 4681  5095 4026 13,802  TaskB Test  148  299  260  707  Crawled Unlab*  - - - 395</ref>,212 Clinton only, which we use for development. TaskB Auto- lab is an automatically labelled version of TaskB Unlab.</p><p>Crawled Unlab is an unlabelled tweet corpus collected by us.</p><p>Finally, to ensure that the proposed neural net- work architectures contribute to the performance, we also use the word vectors from word2vec to de- velop a Bag-of-Word-Vectors baseline (BOWV), in which the tweet and target representations are fed into a logistic regression classifier with L2 regular- ization (Pedregosa et al., 2011).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Experiments are performed on the SemEval 2016 Task 6 corpus for Stance Detection on Twitter ( <ref type="bibr" target="#b14">Mohammad et al., 2016</ref>). We report experiments for two different experimental setups: one is the unseen target setup (Section 5), which is the main focus of this paper, i.e. detecting the stance of tweets towards previously unseen targets. We show that conditional encoding, by reading the tweets in a target-specific way, generalises to unseen targets better than base- lines which ignore the target. Next, we compare our approach to previous work in a weakly super- vised framework (Section 6) and show that our ap- proach outperforms the state-of-the-art on the Se- mEval 2016 Stance Detection Subtask B corpus. TaskB Unlab is an unlabelled corpus containing Donald Trump tweets supplied by the task organ- isers, and TaskB Auto-lab* is an automatically la- belled version of a small portion of the corpus for the weakly supervised stance detection experiments reported in Section 6. Finally, Crawled Unlab* is a corpus we collected for unsupervised pre-training (see Section 3.4).</p><p>For all experiments, the official task evalua- tion script is used. Predictions are post pro- cessed so that if the target is contained in a tweet, the highest-scoring non-neutral stance is chosen. This was motivated by the observation that in the training data most target-containing tweets express a stance, with only 16% of them being neutral. The code used in our experi- ments is available from https://github.com/ sheffieldnlp/stance-conditional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Methods</head><p>We compare the following baseline methods:</p><p>• SVM trained with word and character tweet n-grams features (SVM-ngrams-comb) Mo- to three versions of conditional encoding:</p><p>• target conditioned on tweet (TarCondTweet)</p><p>• tweet conditioned on target (TweetCondTar)</p><p>• a bidirectional encoding model (BiCond)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Unseen Target Stance Detection</head><p>As explained earlier, the challenge is to learn a model without any manually labelled training data for the test target, but only using the data from the Task A targets. In order to avoid using any la- belled data for Donald Trump, while still having a (labelled) development set to tune and evaluate our models, we used the tweets labelled for Hillary Clin- ton as a development set and the tweets for the re- maining four targets as training. We refer to this as  the development setup, and all models are tuned us- ing this setup. The labelled Donald Trump tweets were only used in reporting our final results. For the final results we train on all the data from the development setup and evaluate on the official Task B test set, i.e. the Donald Trump tweets. We refer to this as our test setup.</p><p>Based on a small grid search using the develop- ment setup, the following settings for LSTM-based models were chosen: input layer size 100 (equal to the word embedding dimension), hidden layer size of 60, training for max 50 epochs with initial learn- ing rate 1e-3 using ADAM ( <ref type="bibr" target="#b9">Kingma and Ba, 2014</ref>) for optimisation, dropout 0.1. Models were trained using cross-entropy loss. The use of one, relatively small hidden layer and dropout help to avoid over- fitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results and Discussion</head><p>Results for the unseen target setting show how well conditional encoding is suited for learning target- dependent representations of tweets, and crucially, how well such representations generalise to unseen targets. The best performing method on both de- velopment <ref type="table" target="#tab_3">(Table 2</ref>) and test setups <ref type="table" target="#tab_5">(Table 3)</ref>      that learn to condition the encoding of tweets on tar- gets outperform all baselines on the test set.</p><p>It is further worth noting that the Bag-of-Word- Vectors baseline achieves results comparable with TweetOnly, Concat and one of the conditional en- coding models, TarCondTweet, on the dev set, even though it achieves significantly lower performance on the test set. This indicates that the pre-trained word embeddings on their own are already very use- ful for stance detection. This is consistent with find- ings of other works showing the usefulness of such a Bag-of-Word-Vectors baseline for the related tasks of recognising textual entailment <ref type="bibr" target="#b2">Bowman et al. (2015)</ref> and sentiment analysis <ref type="bibr">Eisner et al. (2016)</ref>.</p><p>Our best result in the test setup with BiCond is the second highest reported result on the Twitter Stance Detection corpus, however the first, third and fourth best approaches achieved their results by automati- cally labelling Donald Trump training data. BiCond for the unseen target setting outperforms the third and fourth best approaches by a large margin (5 and 7 points in Macro F1, respectively), as can be seen in <ref type="table" target="#tab_11">Table 7</ref>. Results for weakly supervised stance de- tection are discussed in Section 6. <ref type="table" target="#tab_6">Table 4</ref> shows the effect of unsu- pervised pre-training of word embeddings with a word2vec skip-gram model, and furthermore, the re- sults of sharing of these representations between the tweets and targets, on the development set. The first set of results is with a uniformly Random embed- ding initialisation in [−0.1, 0.1]. PreFixed uses the pre-trained skip-gram word embeddings, whereas PreCont initialises the word embeddings with ones from SkipGram and continues training them dur- ing LSTM training. Our results show that, in the absence of a large labelled training dataset, pre- training of word embeddings is more helpful than random initialisation of embeddings. Sing vs Sep shows the difference between using shared vs two separate embeddings matrices for looking up the word embeddings. Sing means the word represen- tations for tweet and target vocabularies are shared, whereas Sep means they are different. Using shared embeddings performs better, which we hypothesise is because the tweets contain some mentions of tar- gets that are tested. <ref type="table" target="#tab_7">Table 5</ref> shows results on the development set for BiCond, com- pared to the best unidirectional encoding model, TweetCondTar and the baseline model Concat, split by tweets that contain the target and those that do not. All three models perform well when the target is mentioned in the tweet, but less so when the targets are not mentioned explicitly. In the case where the target is mentioned in the tweet, bicon- ditional encoding outperforms unidirectional encod- ing and unidirectional encoding outperforms Con- cat. This shows that conditional encoding is able to learn useful dependencies between the tweets and the targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-Training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target in Tweet vs Not in Tweet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Weakly Supervised Stance Detection</head><p>The previous section showed the usefulness of con- ditional encoding for unseen target stance detec- tion and compared results against internal baselines. The goal of experiments reported in this section is to compare against participants in the SemEval 2016 Stance Detection Task B. While we consider an unseen target setup, most submissions, includ- ing the three highest ranking ones for Task B, pkud- blab ( <ref type="bibr" target="#b22">Wei et al., 2016</ref>  Marsh, 2016) and INF-UFRGS ( <ref type="bibr" target="#b3">Dias and Becker, 2016</ref>) considered a different experimental setup. They automatically annotated training data for the test target Donald Trump, thus converting the task into weakly supervised seen target stance detection. The pkudblab system uses a deep convolutional neu- ral network that learns to make 2-way predictions on automatically labelled positive and negative training data for Donald Trump. The neutral class is pre- dicted according to rules which are applied at test time.</p><p>Since the best performing systems which partic- ipated in the shared task consider a weakly super- vised setup, we further compare our proposed ap- proach to the state-of-the-art using such a weakly supervised setup. Note that, even though pkudblab, LitisMind and INF-UFRGS also use regular expres- sions to label training data automatically, the result- ing datasets were not available to us. Therefore, we had to develop our own automatic labelling method and dataset, which are publicly available from our code repository.</p><p>Weakly Supervised Test Setup For this setup, the unlabelled Donald Trump corpus TaskB Unlab is annotated automatically. For this purpose we cre-ated a small set of regular expressions 3 , based on inspection of the TaskB Unlab corpus, expressing positive and negative stance towards the target. The regular expressions for the positive stance were:</p><p>• make( ?)america( ?)great( ?)again</p><formula xml:id="formula_4">• trump( ?)(for|4)( ?)president • votetrump • trumpisright</formula><p>• the truth • #trumprules The keyphrases for negative stance were: #dumptrump, #notrump, #trumpwatch, racist, idiot, fired A tweet is labelled as positive if one of the posi- tive expressions is detected, else negative if a nega- tive expressions is detected. If neither are detected, the tweet is annotated as neutral randomly with 2% chance. The resulting corpus size per stance is shown in <ref type="table" target="#tab_0">Table 1</ref>. The same hyperparameters for the LSTM-based models are used as for the unseen target setup described in the previous section. <ref type="table" target="#tab_9">Table 6</ref> lists our results in the weakly supervised set- ting. <ref type="table" target="#tab_11">Table 7</ref> shows all our results, including those using the unseen target setup, compared against the state-of-the-art on the stance detection corpus. Ta- ble 7 further lists baselines reported by <ref type="bibr" target="#b14">Mohammad et al. (2016)</ref>, namely a majority class base- line (Majority baseline), and a method using 1 to 3-gram bag-of-word and character n-gram features (SVM-ngrams-comb), which are extracted from the tweets and used to train a 3-way SVM classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results and Discussion</head><p>Bag-of-word baselines (BoWV, SVM-ngrams- comb) achieve results comparable to the majority baseline (F1 of 0.2972), which shows how diffi- cult the task is. The baselines which only extract features from the tweets, SVM-ngrams-comb and TweetOnly perform worse than the baselines which also learn representations for the targets <ref type="bibr">(BoWV, Concat)</ref>. By training conditional encoding models on automatically labelled stance detection data we achieve state-of-the-art results. The best result (F1 of 0.5803) is achieved with the bi-directional condi- tional encoding model (BiCond). This shows that <ref type="bibr">3</ref> Note that "|" indiates "or", ( ?) indicates optional space   <ref type="bibr" target="#b3">Dias and Becker (2016)</ref> such models are suitable for unseen, as well as seen target stance detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Stance Detection: Previous work mostly considered target-specific stance prediction in debates <ref type="bibr" target="#b7">(Hasan and Ng, 2013;</ref><ref type="bibr" target="#b21">Walker et al., 2012</ref>) or student essays <ref type="bibr" target="#b4">(Faulkner, 2014)</ref>. The task considered in this paper is more challenging than stance detec- tion in debates because, in addition to irregular lan- guage, the <ref type="bibr" target="#b14">Mohammad et al. (2016)</ref> dataset is of- fered without any context, e.g., conversational struc- ture or tweet metadata. The targets are also not always mentioned in the tweets, which is an addi- tional challenge <ref type="bibr" target="#b1">(Augenstein et al., 2016</ref>) and dis- tinguishes this task from target-dependent ( <ref type="bibr" target="#b0">Alghunaim et al., 2015</ref>) and open-domain target-dependent sen- timent analysis ( <ref type="bibr" target="#b13">Mitchell et al., 2013;</ref>. Related work on rumour stance detec- tion either requires training data from the same ru-mour <ref type="bibr" target="#b17">(Qazvinian et al., 2011</ref>), i.e., target, or is rule- based ( <ref type="bibr" target="#b10">Liu et al., 2015)</ref> and thus potentially hard to generalise. Finally, the target-dependent stance de- tection task tackled in this paper is different from that of <ref type="bibr" target="#b5">Ferreira and Vlachos (2016)</ref>, which while re- lated concerned with the stance of a statement in nat- ural language towards another statement. Conditional Encoding: Conditional encoding has been applied to the related task of recognising textual entailment <ref type="bibr">(Rocktäschel et al., 2016)</ref>, using a dataset of half a million training examples <ref type="bibr" target="#b2">(Bowman et al., 2015)</ref> and numerous different hypotheses. Our experiments here show that conditional encoding is also successful on a relatively small training set and when applied to an unseen testing target. Moreover, we augment conditional encoding with bidirectional encoding and demonstrate the added benefit of un- supervised pre-training of word embeddings on un- labelled domain data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions and Future Work</head><p>This paper showed that conditional LSTM encod- ing is a successful approach to stance detection for unseen targets. Our unseen target bidirectional con- ditional encoding approach achieves the second best results reported to date on the SemEval 2016 Twitter Stance Detection corpus. In the weakly supervised seen target scenario, as considered by prior work, our approach achieves the best results to date on the SemEval Task B dataset. We further show that in the absence of large labelled corpora, unsupervised pre- training can be used to learn target representations for stance detection and improves results on the Se- mEval corpus. Future work will investigate further the challenge of stance detection for tweets which do not contain explicit mentions of the target.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Bidirectional encoding of tweet conditioned on bidirectional encoding of target ([c → 3 c ← 1 ]). The stance is predicted using the last forward and reversed output representations ([h → 9 h ← 4 ]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>hammad et al. ( 2016 )</head><label>2016</label><figDesc>• a majority class baseline (Majority baseline), reported in (Mohammad et al., 2016) • bag of word vectors (BoWV) (see Section 3.4) • independent encoding of tweet and the target with two LSTMs (Concat) (see Section 3.1) • encoding of the tweet only with an LSTM (TweetOnly) (see Section 3.1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Data sizes of available corpora. TaskA Tr+Dv HC 

is the part of TaskA Tr+Dv with tweets for the target Hillary 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 lists</head><label>1</label><figDesc>the various corpora used in the ex- periments and their sizes. TaskA Tr+Dv is the official SemEval 2016 Twitter Stance Detection TaskA training and development corpus, which contain instances for the targets Legalization of Abortion, Atheism, Feminist Movement, Climate Change is a Real Concern and Hillary Clinton. TaskA Tr+Dv HC is the part of the corpus which contains only the Hillary Clinton tweets, which we use for development purposes. TaskB Test is the TaskB test corpus on which we report re- sults containing Donald Trump testing instances.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Results for the unseen target stance detection devel- opment setup.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 3 : Results for the unseen target stance detection test setup.</head><label>3</label><figDesc></figDesc><table>EmbIni 
NumMatr 
Stance 
P 
R 
F1 

Random 

Sing 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results for the unseen target stance detection develop-

ment setup using BiCond, with single vs separate embeddings 

matrices for tweet and target and different initialisations 

dependent encoding of the target and the tweets, 
does not achieve big F1 improvements over Twee-
tOnly, which learns a representation of the tweets 
only. This shows that it is not sufficient to just take 
the target into account, but is is important to learn 
target-dependent encodings for the tweets. Models 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Results for the unseen target stance detection devel- opment setup for tweets containing the target vs tweets not con- taining the target.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>), LitisMind (Zarrella and</head><label></label><figDesc></figDesc><table>Method 
Stance 
P 
R 
F1 

BoWV 

FAVOR 
0.5156 0.6689 0.5824 
AGAINST 0.6266 0.3311 0.4333 
Macro 
0.5078 

TweetOnly 

FAVOR 
0.5284 0.6284 0.5741 
AGAINST 0.5774 0.4615 0.5130 
Macro 
0.5435 

Concat 

FAVOR 
0.5506 0.5878 0.5686 
AGAINST 0.5794 0.4883 0.5299 
Macro 
0.5493 

TarCondTweet 

FAVOR 
0.5636 0.6284 0.5942 
AGAINST 0.5947 0.4515 0.5133 
Macro 
0.5538 

TweetCondTar 

FAVOR 
0.5868 0.6622 0.6222 
AGAINST 0.5915 0.4649 0.5206 
Macro 
0.5714 

BiCond 

FAVOR 
0.6268 0.6014 0.6138 
AGAINST 0.6057 0.4983 0.5468 
Macro 
0.5803 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Stance Detection test results for weakly super-

vised setup, trained on automatically labelled pos+neg+neutral 

Trump data, and reported on the official test set. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Stance Detection test results, compared against the 

state of the art. SVM-ngrams-comb and Majority baseline 

are reported in Mohammad et al. (2016), pkudblab in Wei et al. 

(2016), LitisMind in Zarrella and Marsh (2016), INF-UFRGS 

in </table></figure>

			<note place="foot" n="1"> https://dev.twitter.com/rest/public/ search 2 https://github.com/leondz/twokenize</note>

			<note place="foot" n="4"> http://www.pheme.eu</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partially supported by the European Union under grant agreement No. 611233 PHEME <ref type="bibr">4</ref> and by Microsoft Research through its PhD Scholar-ship Programme.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Vector Space Approach for Aspect Based Sentiment Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdulaziz</forename><surname>Alghunaim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitra</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cyphers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing</title>
		<meeting>the 1st Workshop on Vector Space Modeling for Natural Language Processing<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="116" to="122" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">USFD: Any-Target Stance Detection on Twitter with Autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Semantic Evaluation, SemEval &apos;16</title>
		<meeting>the International Workshop on Semantic Evaluation, SemEval &apos;16<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Matko Bošnjak, and Sebastian Riedel. 2016. emoji2vec: Learning Emoji Representations from their Description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcelo</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Natural Language Processing for Social Media, SocialNLP &apos;16</title>
		<meeting>the International Workshop on Natural Language Processing for Social Media, SocialNLP &apos;16<address><addrLine>San Diego, California, June. Ben Eisner, Tim Rocktäschel, Isabelle Augenstein; Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings of the International Workshop on Semantic Evaluation, SemEval &apos;16</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automated Classification of Stance in Student Essays: An Approach Using Stance Target Information and the Wikipedia Link-Based Measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Faulkner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FLAIRS Conference</title>
		<editor>William Eberle and Chutima BoonthumDenecke</editor>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Emergent: a novel data-set for stance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="1163" to="1168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional LSTM and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Stance Classification of Ideological Debates: Data, Models, Features, and Constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saidul</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Federation of Natural Language Processing / ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1348" to="1356" />
		</imprint>
	</monogr>
	<note>IJCNLP</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Real-time Rumor Debunking on Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaomo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armineh</forename><surname>Nourbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameena</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, CIKM &apos;15</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management, CIKM &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1867" to="1870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Twitter Under Crisis: Can We Trust What We RT?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcelo</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Poblete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Social Media Analytics (SOMA&apos;2010)</title>
		<meeting>the First Workshop on Social Media Analytics (SOMA&apos;2010)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="71" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Open Domain Targeted Sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacqui</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1643" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">SemEval-2016 Task 6: Detecting stance in tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Semantic Evaluation, SemEval &apos;16</title>
		<meeting>the International Workshop on Semantic Evaluation, SemEval &apos;16<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Opinion mining and sentiment analysis. Foundations and trends in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rumor Has It: Identifying Misinformation in Microblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Vahed Qazvinian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rosengren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1589" to="1599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Karl Moritz Hermann, Tomáš Kočisk`Kočisk`y, and Phil Blunsom. 2016. Reasoning about Entailment with Neural Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Conference on Learning Representations</title>
		<imprint/>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA,</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
	<note>October. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Target-Dependent Twitter Sentiment Classification with Rich Automatic Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duy-Tin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<editor>Qiang Yang and Michael Wooldridge</editor>
		<imprint>
			<biblScope unit="page" from="1347" to="1353" />
			<date type="published" when="2015" />
			<publisher>AAAI Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stance Classification using Dialogic Properties of Persuasion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><surname>Grant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="592" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuqin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengjiao</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>pkudblab at SemEval-2016</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Specific Convolutional Neural Network System for Effective Stance Detection</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Semantic Evaluation, SemEval &apos;16</title>
		<meeting>the International Workshop on Semantic Evaluation, SemEval &apos;16<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">MITRE at SemEval-2016 Task 6: Transfer Learning for Stance Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Zarrella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Marsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Semantic Evaluation, SemEval &apos;16</title>
		<meeting>the International Workshop on Semantic Evaluation, SemEval &apos;16<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural Networks for Open Domain Targeted Sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duy Tin</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="612" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Association for the Advancement of Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duy-Tin</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-02" />
		</imprint>
	</monogr>
	<note>Gated Neural Networks for Targeted Sentiment Analysis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
