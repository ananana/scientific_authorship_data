<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Taxonomy Construction Using Syntactic Contextual Evidence</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luu</forename><surname>Anh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Engineering</orgName>
								<orgName type="department" key="dep2">Institute for Infocomm Research</orgName>
								<orgName type="department" key="dep3">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan</forename><surname>#1</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Engineering</orgName>
								<orgName type="department" key="dep2">Institute for Infocomm Research</orgName>
								<orgName type="department" key="dep3">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Jae</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Engineering</orgName>
								<orgName type="department" key="dep2">Institute for Infocomm Research</orgName>
								<orgName type="department" key="dep3">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">See</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Engineering</orgName>
								<orgName type="department" key="dep2">Institute for Infocomm Research</orgName>
								<orgName type="department" key="dep3">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kiong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Engineering</orgName>
								<orgName type="department" key="dep2">Institute for Infocomm Research</orgName>
								<orgName type="department" key="dep3">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Taxonomy Construction Using Syntactic Contextual Evidence</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="810" to="819"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Taxonomies are the backbone of many structured, semantic knowledge resources. Recent works for extracting taxonomic relations from text focused on collecting lexical-syntactic patterns to extract the taxonomic relations by matching the patterns to text. These approaches, however, often show low coverage due to the lack of contextual analysis across sentences. To address this issue, we propose a novel approach that collectively utilizes contextual information of terms in syntactic structures such that if the set of contexts of a term includes most of contexts of another term, a subsumption relation between the two terms is inferred. We apply this method to the task of taxonomy construction from scratch, where we introduce another novel graph-based algorithm for taxonomic structure induction. Our experiment results show that the proposed method is well complementary with previous methods of linguistic pattern matching and significantly improves recall and thus F-measure.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Taxonomies that are backbone of structured on- tology knowledge have been found to be use- ful for many areas such as question answering ( <ref type="bibr" target="#b9">Harabagiu et al., 2003)</ref>, document clustering <ref type="bibr" target="#b5">(Fodeh et al., 2011</ref>) and textual entailment <ref type="bibr" target="#b7">(Geffet and Dagan, 2005</ref>). There have been an in- creasing number of hand-crafted, well-structured taxonomies publicly available, including WordNet <ref type="bibr" target="#b15">(Miller, 1995)</ref>, <ref type="bibr">OpenCyc (Matuszek et al., 2006</ref>), and Freebase ( <ref type="bibr" target="#b0">Bollacker et al., 2008)</ref>. However, the manual curation of those taxonomies is time- consuming and human experts may miss relevant terms. As such, there are still needs to extend ex- isting taxonomies or even to construct new tax- onomies from scratch.</p><p>The previous methods for identifying taxo- nomic relations (i.e. is-a relations) from text can be generally classified into two categories: statis- tical and linguistic approaches. The former in- cludes co-occurrence analysis <ref type="bibr" target="#b1">(Budanitsky, 1999)</ref>, term subsumption ( <ref type="bibr" target="#b6">Fotzo and Gallinari, 2004</ref>) and clustering ( <ref type="bibr" target="#b22">Wong et al., 2007</ref>). The main idea be- hinds these techniques is that the terms that fre- quently co-occur may have taxonomic relation- ships. Such approaches, however, usually suffer from low accuracy, though relatively high cover- age, and heavily depend on the choice of feature types and datasets. Most previous methods of the linguistic approach, on the other hand, rely on the lexical-syntactic patterns (e.g. A is a B, A such as B) <ref type="bibr" target="#b10">(Hearst, 1992)</ref>. Those patterns can be manu- ally created ( <ref type="bibr" target="#b12">Kozareva et al., 2008;</ref><ref type="bibr" target="#b20">Wentao et al., 2012)</ref>, chosen via automatic bootstrapping <ref type="bibr" target="#b21">(Widdows and Dorow, 2002</ref>; <ref type="bibr" target="#b8">Girju et al., 2003)</ref> or iden- tified from machine-learned classifiers <ref type="bibr" target="#b17">(Navigli et al., 2011</ref>). The pattern matching methods gen- erally achieve high precision, but low coverage due to the lack of contextual analysis across sen- tences. In this paper, we introduce a novel statisti- cal method and shows that when combined with a pattern matching method, it shows significant per- formance improvement.</p><p>The proposed statistical method, called syntac- tic contextual subsumption (SCS), compares the syntactic contexts of terms for the taxonomic re- lation identification, instead of the usage of bag- of-words model by the previous statistical meth- ods. We observe that the terms in taxonomic rela- tions may not occur in the same sentences, but in similar syntactic structures of different sentences, and that the contexts of a specific term are often found in the contexts of a general term but not vice versa. By context of a term, we mean the set of words frequently have a particular syntactic rela- tion (e.g. Subject-Verb-Object) with the term in a given corpus. Given two terms, the SCS method collects from the Web pre-defined syntactic rela- tions of each of the terms and checks if the syntac- tic contexts of a term properly includes that of the other term in order to determine their taxonomic relation. The method scores each taxonomic rela- tion candidate based on the two measures of Web- based evidence and contextual set inclusion, and as such, is able to find implicit subsumption rela- tions between terms across sentences. The SCS shows itself (Section 3.1) to be complementary to linguistic pattern matching.</p><p>After the relation identification, the identified taxonomic relations should be integrated into a graph for the task of taxonomy construction from scratch or associated with existing concepts of a given taxonomy via is-a relations ( <ref type="bibr" target="#b18">Snow et al., 2006</ref>). In this step of taxonomic structure con- struction, there is a need for pruning incorrect and redundant relations. Previous methods for the pruning task ( <ref type="bibr" target="#b13">Kozareva and Hovy, 2010;</ref><ref type="bibr" target="#b19">Velardi et al., 2012</ref>) treat the identified taxonomic relations equally, and the pruning task is thus reduced to finding the best trade-off between path length and the connectivity of traversed nodes. This assump- tion, however, is not always true due to the fact that the identified taxonomic relations may have different confidence values, and the relations with high confidence values can be incorrectly elimi- nated during the pruning process. We thus propose a novel method for the taxonomy induction by uti- lizing the evidence scores from the relation iden- tification method and the topological properties of the graph. We show that it can effectively prune redundant edges and remove loops while preserv- ing the correct edges of taxonomy.</p><p>We apply the proposed methods of taxonomic relation identification and taxonomy induction to the task of constructing a taxonomy from a given text collection from scratch. The resultant system consists of three modules: Term extraction and filtering (Section 2.1), taxonomic relation iden- tification (Section 2.2), and taxonomy induction (Section 2.3). The outputs of the term extrac- tion/filtering module are used as inputs of the tax- onomic relation identification, such that the tax- onomic relation identification module checks if there is a taxonomic relation between each pair of terms from the term extraction/filtering module. The taxonomy induction module gets the identi- fied taxonomic relation set as the input, and out- puts the final optimal taxonomy by pruning redun- dant and incorrect relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Term Extraction and Filtering</head><p>The first step to construct taxonomies is to col- lect candidate terms from text documents in the domain of interest. Like most of linguistic ap- proaches, we use pre-defined linguistic filters to extract candidate terms, including single-word terms and multi-word terms which are noun or noun phrases in sentences. These terms are then preprocessed by removing determiners and lemmatization.</p><p>The candidate terms collected are then filtered to select the terms that are most relevant to the domain of interest. Many statistical techniques are developed for the filtering, such as T F -IDF , domain relevance (DR), and domain consensus (DC) ( <ref type="bibr" target="#b16">Navigli and Velardi, 2004</ref> </p><formula xml:id="formula_0">T S(t, D i ) = α × T F IDF (t, D i ) + β × DR(t, D i ) + γ × DC(t, D i )<label>(1)</label></formula><p>We experimented (see Section 3) with different values of α, β and γ, and found that the method shows the best performance when the values for α and β are 0.2 and 0.8 and the value for γ is be- tween 0.15 and 0.35, depending on the size of the domain corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Taxonomic Relation Identification</head><p>In this section, we present three taxonomic rela- tion identification methods which are adopted in our system. First, two methods of string inclusion with WordNet and lexical-syntactic pattern match- ing, which were commonly used in the literature will be introduced with some modifications. Then, a novel syntactic contextual subsumption method to find implicit relations between terms across sen- tences by using contextual evidence from syntactic structures and Web data will be proposed. Finally, these three methods will be linearly combined to Notation Meaning t 1 ≫ t 2 t 1 is a hypernym of t 2 t 1 ≈ t 2 t 1 semantically equals or is sim- ilar to t 2 t 1 ≫ W N t 2 t 1 is a direct or inherited hyper- nym of t 2 according to WordNet t 1 ≈ W N t 2 t 1 and t 2 belong to the same synset of WordNet <ref type="table">Table 1</ref>: Notations form an integrating solution for taxonomic rela- tion identification. Given two terms t 1 and t 2 , Ta- ble 1 summarizes important notations used in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">String Inclusion with WordNet (SIWN)</head><p>One simple way to check taxonomic relation is to test string inclusion. For example, "terrorist orga- nization" is a hypernym of "foreign terrorist orga- nization", as the former is a substring of the lat- ter. We propose an algorithm to extend the string inclusion test by using WordNet, which will be named SIWN. Given a candidate general term t g and a candidate specific term t s , the SIWN al- gorithm examines t g from left to right (designat- ing each word in t g to be examined as w g ) to check if there is any word (w s ) in t s such that w g ≈ W N w s or w g ≫ W N w s , and identifies the taxonomic relation between two terms if ev- ery word of t g has a corresponding word in t s (with at least one ≫ W N relation). For example, consider two terms: "suicide attack" and "world trade center self-destruction bombing". Because "attack" ≫ W N "bombing" and "suicide" ≈ W N "self-destruction", according to SIWN algorithm, we conclude that "suicide attack" is the hypernym of "world trade center self-destruction bombing". Given two terms t 1 and t 2 , the evidence score for SIWN algorithm is calculated as follows:</p><formula xml:id="formula_1">Score SIW N (t 1 , t 2 ) = { 1 if t1 ≫ t 2 via SIWN 0 otherwise (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Lexical-syntactic Pattern</head><p>Extending the ideas of <ref type="bibr" target="#b13">Kozareva and Hovy (2010)</ref> and <ref type="bibr" target="#b17">Navigli et al. (2011)</ref>, we propose a method of extracting taxonomic relations by matching lexical-syntactic patterns to the Web data.</p><p>Definition 1 (Syntactic patterns). Given two terms t 1 and t 2 , Pat(t 1 , t 2 ) is defined as the set of the following patterns:</p><p>• "t 1 such as t 2 "</p><p>• "t 1 , including t 2 "</p><p>• "t 2 is [a|an] t 1 "</p><p>• "t 2 is a [kind|type] of t 1 "</p><p>• "t 2 , [and|or] other t 1 "</p><p>, where t 1 and t 2 are replaced with actual terms and [a|b] denotes a choice between a and b.</p><p>Given candidate general term t 1 and candi- date specific term t 2 , the lexical-syntactic pattern (LSP) method works as follows:</p><p>1. Submit each phrase in Pat(t 1 , t 2 ) to a Web search engine as a query. The number of the search results of the query is denoted as</p><formula xml:id="formula_2">WH(t 1 , t 2 ).</formula><p>2. Calculate the following evidence score:</p><formula xml:id="formula_3">Score LSP (t 1 , t 2 ) = log(W H(t 1 , t 2 )) 1 + log(W H(t 2 , t 1 ))<label>(3)</label></formula><p>3. If Score LSP (t 1 , t 2 ) is greater than a thresh- old value then t 1 ≫ t 2 .</p><p>While most lexical-syntactic pattern meth- ods in the literature only consider the value of WH(t 1 , t 2 ) in checking t 1 ≫ t 2 (Wentao et al., 2012), we take into account both WH(t 1 , t 2 ) and WH(t 2 , t 1 ). The intuition of formula <ref type="formula" target="#formula_3">(3)</ref> is that if t1 is a hypernym of t2 then the size of WH(t 1 , t 2 ) will be much larger than that of WH(t 2 , t 1 ), which means the lexical-syntactic patterns are more applicable for the ordered pair (t 1 , t 2 ) than (t 2 , t 1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Syntactic Contextual Subsumption</head><p>The LSP method performs well in recognizing the taxonomic relations between terms in the sentences containing those pre-defined syntactic patterns. This method, however, has a major shortcoming: it cannot derive taxonomic relations between two terms occurring in two different sentences. We thus propose a novel syntactic contextual subsumption (SCS) method which uti- lizes contextual information of terms in syntactic structure (i.e. Subject-Verb-Object in this study) and Web data to infer implicit taxonomic relations between terms across sentences. Note that the chosen syntactic structure Subject-Verb-Object is identical to the definition of non-taxonomic relations in the literature ( <ref type="bibr" target="#b2">Buitelaar et al., 2004</ref>), where the Verb indicate non-taxonomic relations between Subject and Object. In this subsection, we first present the method to collect those non-taxonomic relations. Then we present in detail the ideas of the SCS method and how we can use it to derive taxonomic relations in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Non-taxonomic Relation Identification</head><p>Following previous approaches to non- taxonomic relation identification, e.g. ( <ref type="bibr" target="#b3">Ciaramita et al., 2005</ref>), we use the Stanford parser ( <ref type="bibr" target="#b11">Klein and Manning, 2003)</ref> to identify the syntactic structures of sentences and extract triples of (Subject, Verb, Object), where Subject and Object are noun phrases.</p><p>We further consider the following issues: First, if a term (or noun phrase) includes a preposition, we remove the prepositional phrase. However, if the headword of a term is a quantitative noun like "lot", "many" or "dozen" and it is modified by the preposition "of", we replace it with the headword of the object of the preposition "of". For example, we can extract the triples (people, need, f ood) and (people, like, snow) from the following sen- tences, respectively:</p><p>• "People in poor countries need food"</p><p>• "A lot of people like snow" Second, if the object of a verb is in a verb form, we replace it with, if any, the object of the em- bedded verb. For example, we can extract the triple (soldier, attack, terrorist) from the fol- lowing sentence:</p><p>• "The soldiers continue to attack terrorists" Third, if a term has a coordinate structure with a conjunction like "and" or "or", we split it into all coordinated noun phrases and duplicate the triple by replacing the term with each of the coordinated noun phrases. For example, we can extract the triples of R(girl, like, dog) and R(girl, like, cat) from the following sentence:</p><p>• "The girl likes both dogs and cats" Given two terms t 1 , t 2 and a non-taxonomic re- lation r, some notations which will be used here- after are shown below:</p><p>• R(t 1 , r, t 2 ): t 1 , r, and t 2 have a (Subject, Verb, Object) triple.</p><p>• Θ(t 1 , t 2 ): the set of relations r such that there exists R(t 1 , r, t 2 ) or R(t 2 , r, t 1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Syntactic Contextual Subsumption Method</head><p>The idea of the SCS method derived from the following two observations. Observation 1. Given three terms t 1 , t 2 , t 3 , and a non-taxonomic relation r, if we have two triples R(t 1 , r, t 3 ) and R(t 2 , r, t 3 ) (or R(t 3 , r, t 1 ) and R(t 3 , r, t 2 )), t 1 and t 2 may be in taxonomic rela- tion.</p><p>For example, given two triples R(Al-Qaeda, at- tack, American) and R(Terrorist group, attack, American), a taxonomic relation Terrorist group ≫ Al-Qaeda can be induced. However, it is not always guaranteed to induce a taxonomic rela- tions from such a pair of triples, for example from R(animal, eat, meat) and R(animal, eat, grass). The second observation introduced hereafter will provide more chance to infer taxonomic relation- ship.</p><p>Definition 2 (Contextual set of a term). Given a term t 1 and a non-taxonomic relation r, S(t 1 , r, "subj") denotes the set of terms t 2 such that there exists triple R(t 1 , r, t 2 ). Similarly, S(t 1 , r, "obj") is the set of terms t 2 such that there exists triple R(t 2 , r, t 1 ).</p><p>Observation 2. Given two terms t 1 , t 2 , and a non- taxonomic relation r, if S(t 1 , r, "subj") mostly contains S(t 2 , r, "subj") but not vice versa, then most likely t 1 is a hypernym of t 2 . Similarly, if S(t 1 , r, "obj") mostly contains S(t 2 , r, 'obj") but not vice versa, then most likely t 1 is a hypernym of t 2 .</p><p>For example, assume that S(animal, eat, "subj") = {grass, potato, mouse, insects, meat, wild boar, deer, buffalo} and S(tiger, eat, "subj") = {meat, wild boar, deer, buffalo}.</p><p>Since S(animal, eat, "subj") properly contains S(tiger, eat, "subj"), we can induce animal ≫ tiger.</p><p>Based on Observation 2, our strategy to infer taxonomic relations is to first find the contextual set of terms via the evidence of syntactic structures and Web data, and then compute the score of the set inclusion. The detail of the method is presented hereafter. Definition 3. Given two terms t 1 , t 2 and a non- taxonomic relation r, C(t 1 , t 2 , r, "subj") denotes the number of terms t 3 such that there exists both triples R(t 1 , r, t 3 ) and R(t 2 , r, t 3 ). Simi- larly, C(t 1 , t 2 , r, "obj") is the number of terms t 3 such that there exists both relations R(t 3 , r, t 1 ) and R(t 3 , r, t 2 ).</p><p>Given the pair of a candidate general term t 1 and a candidate specific term t 2 , we extract their non-taxonomic relations from corpora extracted from the Web, and use them to determine the tax- onomic relation between t 1 and t 2 as follows:</p><p>1. Find from a domain corpus the relation r and type Γ such that:</p><formula xml:id="formula_4">C(t 1 , t 2 , r, Γ) = max r ′ ∈Θ(t 1 ,t 2 ) Γ ′ ∈{"subj","obj"} C(t 1 , t 2 , r ′ , Γ ′ )</formula><p>2. If type Γ is "subj", collect the first 1,000 search results of the query "t 1 r" using the Google search engine, designated as Corpus Γ t 1 . In the same way, construct Corpus Γ t 2 with the query "t 2 r". If Γ is "obj", two queries "r t 1 " and "r t 2 " are submitted instead to collect Corpus Γ t 1 and Corpus Γ t 2 , respectively.</p><p>3. Find the sets of S(t 1 , r, Γ) and S(t 2 , r, Γ) from Corpus Γ t 1 and Corpus Γ t 2 , respectively, using the non-taxonomic relation identifica- tion method above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Calculate the following evidence score for</head><p>SCS method:</p><formula xml:id="formula_5">Score SCS = [ |S(t 1 , r, Γ) ∩ S(t 2 , r, Γ)| |S(t 2 , r, Γ)| + ( 1 − |S(t 1 , r, Γ) ∩ S(t 2 , r, Γ)| |S(t 1 , r, Γ)| ) ] × log(|S(t 1 , r, Γ)| + |S(t 2 , r, Γ)|)<label>(4)</label></formula><p>The basic idea of the contextual subsumption score in our method is that if t 1 is a hyper- nym of t 2 then the set S(t 1 , r, Γ) will mostly contain S(t 2 , r, Γ) but not vice versa. The in- tuition of formula <ref type="formula">(5)</ref> is inspired by Jaccard similarity coefficient. We then multiply the score with the log value of total size of two sets to avoid the bias of small set inclusion.</p><p>5. If Score SCS (t 1 , t 2 ) is greater than a thresh- old value, then we have t1 ≫ t2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Combined Method</head><p>In our study, we linearly combine three methods as follows:</p><p>1. For each ordered pair of terms (t 1 , t 2 ) calcu- late the total evidence score:</p><formula xml:id="formula_6">Score(t 1 , t 2 ) = α × Score SIW N (t 1 , t 2 ) + β × Score LSP (t 1 , t 2 )</formula><p>+ γ × Score SCS (t 1 , t 2 ) (5) 2. If Score(t 1 , t 2 ) is greater than a threshold value, then we have t 1 ≫ t 2 .</p><p>We experimented with various combinations of values for α, β and γ, and found that the method shows the best performance when the value of α is 0.5, β is between 0.35 and 0.45, and γ is between 0.15 and 0.25, depending on the domain corpus size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Taxonomy Induction</head><p>The output of the taxonomic relation identifica- tion module is a set of taxonomic relations T . In this section, we will introduce a graph-based algorithm (Algorithm 1) to convert this set into an optimal tree-structured taxonomy, as well as to eliminate incorrect and redundant relations. Denote e(t 1 , t 2 ) as an directed edge from t 1 to t 2 , the algorithm consists of three steps which will be described hereafter with the corresponding lines in Algorithm 1.</p><p>Step 1: Initial hypernym graph creation (line 1 -16) This step is to construct a connected directed graph from the list of taxonomic rela- tions. The idea is to add each taxonomic relation t 1 ≫ t 2 as a directed edge from parent node t 1 to child node t 2 , and if t 1 does not have any hypernym term, t 1 will become a child node of ROOT node. The result of this step is a con- nected graph containing all taxonomic relations with the common ROOT node.</p><p>Step 2: Edge weighting (line 17) This step is to calculate the weight of each edge in the hypernym graph. Unlike the algorithm of <ref type="bibr" target="#b19">Velardi et al. (2012)</ref> and <ref type="bibr" target="#b13">Kozareva and Hovy (2010)</ref> where every taxonomic relation is treated equally, we assume the confidence of each taxonomic relation is different, depending on the amount of Algorithm 1 Taxonomy Induction Algorithm Input: T : the taxonomic relation set Output: V : the vertex set of resultant taxonomy; E: the edge set of resultant taxonomy; 1: Initialize V = {ROOT }, E = ∅; 2: for each taxonomic relation (t 1 ≫ t 2 ) ∈ T do 3:</p><formula xml:id="formula_7">E = E ∪ {e(t 1 , t 2 )} 4:</formula><p>if t 1 ̸ ∈ V then 5:</p><formula xml:id="formula_8">V = V ∪ {t 1 } 6: end if 7:</formula><p>if t 2 ̸ ∈ V then 8:</p><formula xml:id="formula_9">V = V ∪ {t 2 } 9:</formula><p>end if <ref type="bibr">10:</ref> if ∄ e(t 3 , t 1 ) ∈ E with t 3 ̸ = ROOT then 11:</p><formula xml:id="formula_10">E = E ∪ {e(ROOT, t 1 )} 12:</formula><p>end if</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13:</head><p>if ∃ e(ROOT, t 2 ) ∈ E then 14:</p><formula xml:id="formula_11">E = E \ {e(ROOT, t 2 )} 15:</formula><p>end if 16: end for 17: edgeWeighting(V, E); 18: graphPruning(V, E); evidence it has. Thus, the hypernym graph edges will be weighted as follows:</p><formula xml:id="formula_12">w(e(t 1 , t 2 )) = { 1 if t 1 = ROOT Score(t 1 , t 2 ) otherwise (6)</formula><p>Note that the Score value in formula (6) is de- termined by the taxonomic relation identification process described in Section 2.2.4.</p><p>Step 3: Graph pruning (line 18) The hy- pernym graph generated in Step 1 is not an optimal taxonomy as it may contain many redun- dant edges or incorrect edges which together form in a loop. In this step, we aim at producing an optimal taxonomy by pruning the graph based on our edge weighting strategy. A maximum spanning tree algorithm, however, cannot be applied as the graph is directed. For this purpose, we apply Edmonds' algorithm <ref type="bibr" target="#b4">(Edmonds, 1967)</ref> for finding a maximum optimum branching of a weighted directed graph. Using this algorithm, we can find a subset of the current edge set, which is the optimized taxonomy where every non-root node has in-degree 1 and the sum of the edge weights is maximized. <ref type="figure" target="#fig_0">Figure 1</ref> shows an example of the taxonomy induction process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment Results</head><p>We evaluated our methods for taxonomy construc- tion against the following text collections of five domains:</p><p>• Artificial Intelligence (AI) domain: 4,119 pa- pers extracted from the IJCAI proceedings from 1969 to 2011 and the ACL archives from year 1979 to 2010. The same dataset used in the work of <ref type="bibr" target="#b19">Velardi et al. (2012)</ref>.</p><p>• Terrorism domain: 104 reports of the US state department, titled "Patterns of Global Terrorism <ref type="bibr">(1991)</ref><ref type="bibr">(1992)</ref><ref type="bibr">(1993)</ref><ref type="bibr">(1994)</ref><ref type="bibr">(1995)</ref><ref type="bibr">(1996)</ref><ref type="bibr">(1997)</ref><ref type="bibr">(1998)</ref><ref type="bibr">(1999)</ref><ref type="bibr">(2000)</ref><ref type="bibr">(2001)</ref><ref type="bibr">(2002)</ref>)" 1 . A report contains about 1,500 words.</p><p>• Animals, Plants and Vehicles domains: Col- lections of Web pages crawled by using the bootstrapping algorithm described by <ref type="bibr" target="#b12">Kozareva et al. (2008)</ref>. <ref type="bibr" target="#b17">Navigli et al. (2011)</ref> and <ref type="bibr" target="#b13">Kozareva and Hovy (2010)</ref> used these datasets to compare their outputs against WordNet sub-hierarchies.</p><p>There are two experiments performed in this sec- tion: 1) Evaluating the construction of new tax- onomies for Terrorism and AI domains, and 2) Comparing our results with the gold-standard WordNet sub-hierarchies. Note that in the experi- ments, the threshold value we used for Score LSP is 1.9, Score SCS is 1.5 and Score is 2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Constructing new taxonomies for AI and Terrorism domains</head><p>Referential taxonomy structures such as WordNet or OpenCyc are widely used in semantic analyt- ics applications. However, their coverage is lim- ited to common well-known areas, and many spe- cific domains like Terrorism and AI are not well covered in those structures. Therefore, an auto- matic method which can induce taxonomies for those specific domains from scratch can greatly contribute to the process of knowledge discovery. First, we applied our taxonomy construction system to the AI domain corpus. We compared the taxonomy constructed by our system with that obtained by <ref type="bibr" target="#b19">Velardi et al. (2012)</ref>, and show the comparison results in <ref type="table" target="#tab_2">Table 2</ref>. Notice that in this comparison, to be fair, we use the same set of terms that was used in ( <ref type="bibr" target="#b19">Velardi et al., 2012</ref>). The result shows that our approach can extract 9.8% more taxonomic relations and achieve 7% better term coverage than Velardi's approach.  We also applied our system to the Terrorism corpus. The proposed taxonomic relation identifi- cation algorithm extracts a total of 976 taxonomic relations, from which the taxonomy induction al- gorithm builds the optimal taxonomy. The total number of vertices in the taxonomy is 281, and the total number of edges is 280. The average depth of the trees is 3.1, with the maximum depth 6. In addition, term coverage (the ratio of the number of terms in the final optimal trees to the number of terms obtained by the term suggestion/filtering method) is 85%.</p><p>To judge the contribution of each of taxonomic relation identification methods described in Sec- tion 2.2 to the overall system, we alternately run the system for the AI and Terrorism domains with different combinations of the three methods (i.e. SIWN, LSP, and SCS) as shown in  induction for this experiment. <ref type="table" target="#tab_3">Table 3</ref> shows the number of the taxonomic relations extracted by each of the combinations. Since SIWN and LSP are commonly used by previous taxonomic rela- tion identification systems, we consider the com- bination of SIWN + LSP as the baseline of the experiment. The results in <ref type="table" target="#tab_3">Table 3</ref> show that the three methods are all well complementary to each other. In addition, the proposed SCS method can contribute up to about 27% -29% of all the iden- tified taxonomic relations, which were not discov- ered by the other two baseline methods.</p><p>Percentage   <ref type="table" target="#tab_3">Precision  95%  98%  97% 95%  97%  97% 93%  99%  91%  Recall  56%  38%  44% 53%  39%  38% 69%  60%  49%  F-measure  71%  55%</ref> 61% 68% 56% 55% 79% 75% 64% We further evaluated the precision of each in- dividual taxonomic relation identification method. For AI and Terrorism domains, we again run the system with each of the three methods and with all together, and then randomly select 100 extracted taxonomic relations each time. These selected tax- onomic relations are then examined by two do- main experts to check the correctness. The evalua- tion results are given in <ref type="table" target="#tab_6">Table 4</ref>. Note that only the first two modules of term suggestion/filtering and taxonomic relation identification are employed for this experiment as well. The SIWN and LSP meth- ods achieve high precision because they are based on the gold-standard taxonomy hierarchy Word- Net and on the well-defined patterns, respectively. In contrast, the SCS method ambitiously looks for terms pairs that share similar syntactic con- texts across sentences, though the contextual ev- idence is restricted to certain syntactic structures, and thus has a slightly lower precision compared to the other two methods.</p><p>In short, the SCS method is complementary to the baseline methods, significantly improving the coverage of the combined methods, when its pre- cision is comparable to those of the baseline meth- ods. We performed next experiments to show that the SCS method overall has synergistic impact to improve the F-measure of the combined methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation against WordNet</head><p>In this experiment, we constructed taxonomies for three domains Animals, Plants and Vehicles, and then checked whether the identified relations can be found in the WordNet, and which relations in WordNet are not found by our method. Note that in this comparison, to be fair, we changed our algorithm to avoid using WordNet in identifying taxonomic relations. Specifically, in the SIWN algorithm, all operations of "≈ W N " are replaced with normal string-matching comparison, and all We also compared our results with those ob- tained by the approaches of <ref type="bibr" target="#b17">Navigli et al. (2011)</ref> and <ref type="bibr" target="#b13">Kozareva and Hovy (2010)</ref>, where they also compared their resultant taxonomies against WordNet. In this comparison, all the three ap- proaches (i.e. ours, the two previous methods) use the same corpora and term lists. The com- parison results are given in <ref type="table" target="#tab_7">Table 5</ref>. "N.A." value means that this parameter is not applicable to the corresponding method. The results show that our approach achieves better performance than the other two approaches, in terms of both the num- ber of correctly extracted taxonomic relations and the term coverage. Our system has a slightly lower precision than that of <ref type="bibr" target="#b17">(Navigli et al., 2011)</ref> and <ref type="bibr" target="#b13">(Kozareva and Hovy, 2010)</ref> due to the SCS method, but it significantly contributes to improve the recall and eventually the F-measure over the other two systems.</p><p>To judge the effectiveness of our proposed tax- onomy induction algorithm described in Section 2.3, we compared it with the graph-based algo- rithm of <ref type="bibr" target="#b19">Velardi et al. (2012)</ref>. Recall that in this al- gorithm, they treat all taxonomic relations equally, and the pruning task is reduced to finding the best trade-off between path length and the connectiv- ity of traversed nodes. For each of five domains (i.e. Terrorism, AI, Animals, Plants and Vehicles), we alternately run the two taxonomy induction algorithms over the same taxonomic relation set produced by our taxonomic relation identification process. For Terrorism and AI domains, we ran- domly pick up 100 edges in each resultant taxon-omy and ask two domain experts to judge for the correctness. For Animals, Plants and Vehicles do- mains, we check the correctness of the edges in re- sultant taxonomies by comparing them against the corresponding sub-hierarchies in WordNet. The evaluation is given in <ref type="table">Table 6</ref>. The results show that the proposed taxonomy induction algorithm can achieve better performance than the algorithm of <ref type="bibr" target="#b19">Velardi et al. (2012)</ref>. This may be due to the fact that our algorithm considers the scores of the iden- tified taxonomic relations from the relation identi- fication module, and thus is more precise in elim- inating incorrect relations during the pruning pro- cess.</p><p>Percentage of correct edges Our algorithm Velardi's algorithm Terrorism 94% 90% AI 93% 88% Animals 95% 93% Plants 95% 92% Vehicles 93% 92% <ref type="table">Table 6</ref>: Comparison of our taxonomy induction algorithms and that of <ref type="bibr" target="#b19">Velardi et al. (2012)</ref>.</p><p>In addition, when comparing <ref type="table" target="#tab_6">Tables 4 and 6</ref>, we can find that the precision of taxonomic relations after the pruning process is higher than that before the pruning process, which proves that the pro- posed taxonomy induction algorithm effectively trims the incorrect relations of Terrorism and AI taxonomies, leveraging the percentage of correct relations 2% -3% up.</p><p>For the SCS method, besides the triple Subject- Verb-Object, we also explore other syntactic structures like Noun-Preposition-Noun and Noun- Adjective-Noun. For example, from the sentence "I visited Microsoft in Washington", the triple (Microsoft, in, Washington) is extracted using Noun-Preposition-Noun structure. Similarly, from the sentence "Washington is a beautiful city", the triple (Washington, beautiful, city) is extracted us- ing Noun-Adjective-Noun structure. We then use the triples for the contextual subsumption method described in Section 2.2.3, and test the method against the Animals, Plants and Vehicles domains. The results are then compared against WordNet sub hierarchies. The experiment results in <ref type="table">Table  7</ref> show that the triples of Subject-Verb-Object give the best performance compared to the other syn- tactic structures. These can be explained as the <ref type="table" target="#tab_2">Precision  95%  68%  72%  Recall  56%  52%  47%  F-measure  71%  59%  57%  Plants domain  Precision  95%  63%  66%  Recall  53%  41%  43%  F-measure  68%  50%</ref> 52% Vehicles domain Precision 93% 59% 60% Recall 69% 45% 48% F-measure 79% 51% 53% <ref type="table">Table 7</ref>: Comparison of three syntactic struc- tures: S-V-O (Subject-Verb-Object), N-P-N (Noun-Preposition-Noun) and N-A-N (Noun- Adjective-Noun).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-V-O N-P-N N-A-N Animals domain</head><p>number of triples of two types Noun-Preposition- Noun and Noun-Adjective-Noun are smaller than that of Subject-Verb-Object, and the number of Verb is much greater than number of Preposition or Adjective.</p><p>All experiment results are available at http://nlp.sce.ntu.edu.sg/wiki/projects/taxogen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we proposed a novel method of iden- tifying taxonomic relations using contextual evi- dence from syntactic structure and Web data. This method is proved well complementary with pre- vious method of linguistic pattern matching. We also present a novel graph-based algorithm to in- duce an optimal taxonomy from a given taxo- nomic relation set. The experiment results show that our system can generally achieve better per- formance than the state-of-the-art methods. In the future, we will apply the proposed taxon- omy construction method to other domains such as biomedicine and integrate it into other frame- works such as ontology authoring.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of taxonomy induction. (a) Initial weighted hypernym graph. (b) Final optimal taxonomy, where we prune two redundant edges (group, International terrorist organization), (Militant group, Hezbollah) and remove the loop by cutting an incorrect edge (Al-Qaeda, Terrorist organization).</figDesc><graphic url="image-1.png" coords="7,83.45,67.57,212.59,158.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>"</head><label></label><figDesc>≫ W N " relations are falsified. The evaluation uses the following measures: P recision = #relations f ound in W ordN et and by the method #relations f ound by the method Recall = #relations f ound in W ordN et and by the method #relations f ound in W ordN et</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Comparison of our system with (Velardi 
et al., 2012) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table>Note 
that we employed only the first two modules of 
term suggestion/filtering and taxonomic relation 
identification except the last module of taxonomy 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>The number of taxonomic relations ex-
tracted by different methods. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Estimated precision of taxonomic relation 
identification methods in 100 extracted relations. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Comparison of (Navigli et al., 2011), (Kozareva and Hovy, 2010) and our system against Word-
Net in three domains: Animals, Plants and Vehicles. 

</table></figure>

			<note place="foot" n="1"> http://www.fas.org/irp/threat/terror.htm</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Lexical semantic relatedness and its application in natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Budanitsky</surname></persName>
		</author>
		<idno>CSRG-390</idno>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>Computer Systems Research Group, University of Toronto</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Protégé Plug-in for Ontology Extraction from Text Based on Linguistic Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Buitelaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Olejnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sintek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 1st European Semantic Web Symposium</title>
		<meeting>the 1st European Semantic Web Symposium</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="31" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Semantic Relations Between Concepts of a Molecular Biology Ontology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gangemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ratsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rojas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 19th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 19th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="659" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimum branchings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Edmonds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Research of the National Bureau of Standards</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="233" to="240" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">On Ontologydriven Document Clustering Using Core Semantic Features. Knowledge and information systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fodeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Punch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="395" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning &quot;Generalization/Specialization&quot; Relations between Concepts-Application for Automatically Building Thematic Document Hierarchies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">N</forename><surname>Fotzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gallinari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 7th International Conference on Computer-Assisted Information Retrieval</title>
		<meeting>the 7th International Conference on Computer-Assisted Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Distributional Inclusion Hypotheses and Lexical Entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geffet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 43rd Annual Meeting of the ACL</title>
		<meeting>the 43rd Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="107" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning Semantic Constraints for the Automatic Discovery of Part-Whole Relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Badulescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the NAACL</title>
		<meeting>the NAACL</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Open-Domain Textual Question Answering Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Maiorano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic Acquisition of Hyponyms from Large Text Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 14th Conference on Computational Linguistics</title>
		<meeting>the 14th Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="539" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Accurate Unlexicalized Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 41st Annual Meeting of the ACL</title>
		<meeting>the 41st Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 46th Annual Meeting of the ACL</title>
		<meeting>the 46th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1048" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Semi-supervised Method to Learn and Construct Taxonomies Using the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1110" to="1118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An Introduction to the Syntax and Content of Cyc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Witbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deoliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the AAAI Spring Symposium: Formalizing and Compiling Background Knowledge and Its Applications to Knowledge Representation and Question Answering</title>
		<meeting>the AAAI Spring Symposium: Formalizing and Compiling Background Knowledge and Its Applications to Knowledge Representation and Question Answering</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="44" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">WordNet: a Lexical Database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning Domain Ontologies from Document Warehouses and Dedicated Web Sites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="179" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Graphbased Algorithm for Inducing Lexical Taxonomies from Scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Faralli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 20th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 20th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1872" to="1877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantic Taxonomy Induction from Heterogenous Evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 21st International Conference on Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="801" to="808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ontolearn Reloaded: A Graph-based Algorithm for Taxonomy Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Faralli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="665" to="707" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Probase: A probabilistic taxonomy for text understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wentao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hongsong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Haixun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="481" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Graph Model for Unsupervised Lexical Acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Widdows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 19th International Conference on Computational Linguistics</title>
		<meeting>the 19th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Treetraversing ant algorithm for term clustering based on featureless similarities. Data Mining and Knowledge Discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="349" to="381" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
