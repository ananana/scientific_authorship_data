<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Polynomial-Time Dynamic Oracle for Non-Projective Dependency Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Gómez-Rodríguez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Departamento de Computación</orgName>
								<orgName type="department" key="dep2">Department of Information Engineering</orgName>
								<orgName type="institution">Universidade da Coruña</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Sartorio</surname></persName>
							<email>sartorio@dei.unipd.it</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
							<email>satta@dei.unipd.it</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Polynomial-Time Dynamic Oracle for Non-Projective Dependency Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="917" to="927"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The introduction of dynamic oracles has considerably improved the accuracy of greedy transition-based dependency parsers , without sacrificing parsing efficiency. However, this enhancement is limited to projective parsing, and dynamic oracles have not yet been implemented for parsers supporting non-projectivity. In this paper we introduce the first such oracle, for a non-projective parser based on At-tardi&apos;s parser. We show that training with this oracle improves parsing accuracy over a conventional (static) oracle on a wide range of datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Greedy transition-based parsers for dependency grammars have been pioneered by <ref type="bibr" target="#b15">Yamada and Matsumoto (2003)</ref> and <ref type="bibr" target="#b13">Nivre (2003)</ref>. These meth- ods incrementally process the input sentence from left to right, predicting the next parsing action, called transition, on the basis of a compact rep- resentation of the derivation history.</p><p>Greedy transition-based parsers can be very efficient, allowing web-scale parsing with high throughput. However, the accuracy of these meth- ods still falls behind that of transition-based pars- ers using beam-search, where the accuracy im- provement is obtained at the cost of a decrease in parsing efficiency; see for instance <ref type="bibr" target="#b16">Zhang and Nivre (2011)</ref>, <ref type="bibr" target="#b9">Huang and Sagae (2010)</ref>, <ref type="bibr" target="#b1">Choi and McCallum (2013)</ref>. As an alternative to beam- search, recent research on transition-based parsing has therefore explored possible ways of improving accuracy at no extra cost in parsing efficiency.</p><p>The training of transition-based parsers relies on a component called the parsing oracle, which maps parser configurations to optimal transitions with respect to a gold tree. A discriminative model is then trained to simulate the oracle's behavior, and is later used for decoding. Traditionally, so- called static oracles have been exploited in train- ing, where a static oracle is defined only for con- figurations that have been reached by computa- tions with no mistake, and it returns a single ca- nonical transition among those that are optimal.</p><p>Very recently, <ref type="bibr" target="#b5">Goldberg and Nivre (2012)</ref>, <ref type="bibr" target="#b6">Goldberg and Nivre (2013)</ref> and <ref type="bibr" target="#b7">Goldberg et al. (2014)</ref> showed that the accuracy of transition- based parsers can be substantially improved using dynamic oracles. A dynamic oracle returns the set of all transitions that are optimal for a given configuration, with respect to the gold tree, and is well-defined and correct for every configuration that is reachable by the parser.</p><p>Na¨ıveNa¨ıve implementations of dynamic oracles run in exponential time, since they need to simulate all possible computations of the parser for the in- put configuration. Polynomial-time implementa- tions of dynamic oracles have been proposed by the above mentioned authors for several project- ive dependency parsers. To our knowledge, no polynomial-time algorithm has been published for transition-based parsers based on non-projective dependency grammars.</p><p>In this paper we consider a restriction of a transition-based, non-projective parser originally presented by <ref type="bibr" target="#b0">Attardi (2006)</ref>. This restriction was further investigated by <ref type="bibr" target="#b10">Kuhlmann and Nivre (2010)</ref> and <ref type="bibr" target="#b2">Cohen et al. (2011)</ref>. We provide an im- plementation for a dynamic oracle for this parser running in polynomial time.</p><p>We experimentally compare the parser trained with the dynamic oracle to a baseline obtained by training with a static oracle. Significant ac- curacy improvements are achieved on many lan- guages when using our dynamic oracle. To our knowledge, these are the first experimental results on non-projective parsing based on a dynamic or- acle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminary Definitions</head><p>Transition-based dependency parsing was origin- ally introduced by <ref type="bibr" target="#b15">Yamada and Matsumoto (2003)</ref> and <ref type="bibr" target="#b13">Nivre (2003)</ref>. In this section we briefly sum- marize the notation we use for this framework and introduce the notion of dynamic oracle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Transition-Based Dependency Parsing</head><p>We represent an input sentence as a string w = w 0 · · · w n , n ≥ 1, where each w i with i = 0 is a lexical symbol and w 0 is a special symbol called root. Set V w = {i | 0 ≤ i ≤ n} denotes the sym- bol occurrences in w. For i, j ∈ V w with i = j, we write i → j to denote a grammatical depend- ency of some unspecified type between w i and w j , where w i is the head and w j is the dependent.</p><p>A dependency tree t for w is a directed tree with node set V w and with root node 0. An arc of t is a pair (i, j), encoding a dependency i → j; we will often use the latter notation to denote arcs.</p><p>A transition-based dependency parser typically uses a stack data structure to process the input string from left to right, in a way very similar to the classical push-down automaton for context- free languages <ref type="bibr" target="#b8">(Hopcroft et al., 2006</ref>). Each stack element is a node from V w , representing the root of a dependency tree spanning some portion of the input w, and no internal state is used. At each step the parser applies some transition that updates the stack and/or consumes one symbol from the input. Transitions may also construct new dependencies, which are added to the current configuration of the parser.</p><p>We represent the stack as an ordered sequence</p><formula xml:id="formula_0">σ = [h d , . . . , h 1 ], d ≥ 0, of nodes h i ∈ V w ,</formula><p>with the topmost element placed at the right. When d = 0, we have the empty stack σ = []. We use the vertical bar to denote the append operator for σ, and write σ = σ |h 1 to indicate that h 1 is the topmost element of σ.</p><p>The portion of the input string still to be pro- cessed by the parser is called the buffer. We represent the buffer as an ordered sequence β = [i, . . . , n] of nodes from V w , with i the first ele- ment of the buffer. We denote the empty buffer as β = []. Again, we use the vertical bar to de- note the append operator, and write β = i|β to indicate that i is the first symbol occurrence of β; consequently, we have β = [i + 1, . . . , n].</p><p>In a transition-based parser, the parsing pro- cess is defined through the technical notions of configuration and transition. A configuration of the parser relative to w is a triple c = (σ, β, A), where σ and β are a stack and a buffer, respect- ively, and A is the set of arcs that have been built so far. A transition is a partial function map- ping the set of parser configurations into itself. Each transition-based parser is defined by means of some finite inventory of transitions. We will later introduce the specific inventory of transitions for the parser that we investigate in this paper. We use the symbol to denote the binary relation formed by the union of all transitions of a parser.</p><p>With the notions of configuration and transition in place, we can define a computation of the parser on w as a sequence c 0 , c 1 , . . . , c m , m ≥ 0, of configurations relative to w, under the condition that c i−1 c i for each i with 1 ≤ i ≤ m. We use the reflexive and transitive closure of , written * , to represent computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Configuration Loss and Dynamic Oracles</head><p>A transition-based dependency parser is a non- deterministic device, meaning that a given con- figuration can be mapped into several configur- ations by the available transitions. However, in several implementations the parser is associated with a discriminative model that, on the basis of some features of the current configuration, always chooses a single transition. In other words, the model is used to run the parser as a pseudo-de- terministic device. The training of the discriminat- ive model relies on a component called the parsing oracle, which maps parser configurations to "op- timal" transitions with respect to some reference dependency tree, which we call the gold tree. Traditionally, so-called static oracles have been used which return a single, canonical transition and they do so only for configurations that can reach the gold tree, that is, configurations repres- enting parsing histories with no mistake. In re- cent work, <ref type="bibr" target="#b5">Goldberg and Nivre (2012)</ref>, <ref type="bibr" target="#b6">Goldberg and Nivre (2013)</ref> and <ref type="bibr" target="#b7">Goldberg et al. (2014)</ref> have introduced dynamic oracles, which return the set of all transitions that are optimal with respect to a gold tree, and are well-defined and correct for every configuration that is reachable by the parser. These authors have shown that the accuracy of transition-based dependency parsers can be sub- stantially improved if dynamic oracles are used in place of static ones. In what follows, we provide a mathematical definition of dynamic oracles, fol- lowing <ref type="bibr" target="#b7">Goldberg et al. (2014)</ref>.</p><formula xml:id="formula_1">(σ, k|β, A) sh (σ|k, β, A) (σ|i|j, β, A) la (σ|j, β, A ∪ {j → i}) (σ|i|j, β, A) ra (σ|i, β, A ∪ {i → j}) (σ|i|j|k, β, A) la 2 (σ|j|k, β, A ∪ {k → i})</formula><p>(σ|i|j|k, β, A) ra 2 (σ|i|j, β, A ∪ {i → k}) <ref type="figure">Figure 1</ref>: Transitions of the non-projective parser.</p><p>Let t 1 and t 2 be dependency trees for w, with arc sets A 1 and A 2 , respectively. The loss of t 1 with respect to t 2 is defined as</p><formula xml:id="formula_2">L(t 1 , t 2 ) = |A 1 \ A 2 | . (1) Note that L(t 1 , t 2 ) = L(t 2 , t 1 ), since |A 1 | = |A 2 |.</formula><p>Furthermore L(t 1 , t 2 ) = 0 if and only if t 1 and t 2 are the same tree. Let c be a configuration of a transition-based parser relative to w. Let also D(c) be the set of all dependency trees that can be obtained in a com- putation of the form c * c f , where c f is a final configuration, that is, a configuration that has con- structed a dependency tree for w. We extend the loss function in (1) to configurations by letting L(c, t 2 ) = min</p><formula xml:id="formula_3">t 1 ∈D(c) L(t 1 , t 2 ) .<label>(2)</label></formula><p>Let t G be the gold tree for w. Quantity L(c, t G ) can be used to define a dynamic oracle as follows. For any transition τ in the finite inventory of our parser, we use the functional notation τ (c) = c in place of c τ c . We then let</p><formula xml:id="formula_4">oracle(c, t G ) = {τ | L(τ (c), t G ) − L(c, t G ) = 0} . (3)</formula><p>In words, (3) provides the set of transitions that do not increase the loss of c; we call these transitions optimal for c.</p><p>A na¨ıvena¨ıve way of implementing (3) would be to explicitly compute the set D(c) in (2), which has exponential size. More interestingly, the im- plementation of dynamic oracles proposed by the above cited authors all run in polynomial time. These oracles are all defined for projective pars- ing. In this paper, we present a polynomial-time oracle for a non-projective parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Non-Projective Dependency Parsing</head><p>In this section we introduce a parser for non- projective dependency grammars that is derived from the transition-based parser originally presen- ted by <ref type="bibr" target="#b0">Attardi (2006)</ref>, and was further investigated by <ref type="bibr" target="#b10">Kuhlmann and Nivre (2010)</ref> and <ref type="bibr" target="#b2">Cohen et al. (2011)</ref>. Our definitions follow the framework in- troduced in Section 2.1.</p><p>We start with some additional notation. Let t be a dependency tree for w and let k be a node of t. Consider the complete subtree t of t rooted at k, that is, the subtree of t induced by k and all of the descendants of k in t. The span of t is the sub- sequence of tokens in w represented by the nodes of t . Node k has gap-degree 0 if the span of t forms a (contiguous) substring of w. A depend- ency tree is called projective if all of its nodes have gap-degree 0; a dependency tree which is not projective is called non-projective.</p><p>Given w as input, the parser starts with the ini- tial configuration ([], <ref type="bibr">[0, . . . , n]</ref>, ∅), consisting of an empty stack, a buffer with all the nodes repres- enting the symbol occurrences in w, and an empty set of constructed dependencies (arcs). The parser stops when it reaches a final configuration of the form ( <ref type="bibr">[0]</ref>, [], A), consisting of a stack with only the root node and of an empty buffer; in any such con- figuration, set A always implicitly defines a valid dependency tree (rooted in node 0).</p><p>The core of the parser consists of an invent- ory of five transitions, defined in <ref type="figure">Figure 1</ref>. Each transition is specified using the free variables σ, β, A, i, j and k. As an example, the schema (σ|i|j, β, A) la (σ|j, β, A ∪ {j → i}) means that if a configuration c matches the antecedent, then a new configuration is obtained by instantiating the variables in the consequent accordingly.</p><p>The transition sh , called shift, reads a new token from the input sentence by removing it from the buffer and pushing it into the stack. Each of the other transitions, collectively called reduce transitions, has the effect of building a dependency between two nodes in the stack, and then removing the dependent node from the stack. The removal of the dependent ensures that the output depend- ency tree is built in a bottom-up order, collecting all of the dependents of each node i before linking i to its head.</p><p>The transition la , called left-arc, creates a left- ward arc where the topmost stack node is the head and the second topmost node is the depend- ent, and removes the latter from the stack. The transition ra , called right-arc, is defined sym- metrically, so that the topmost stack node is at- tached as a dependent of the second topmost node. The combination of the shift, left-arc and right- arc transitions provides complete coverage of pro- jective dependency trees, but no support for non- projectivity, and corresponds to the so-called arc- standard parser introduced by <ref type="bibr" target="#b14">Nivre (2004)</ref>.</p><p>Support for non-projective dependencies is achieved by adding the transitions la 2 and ra 2 , which are variants of the left-arc and right-arc transitions, respectively. These new transitions create dependencies involving the first and the third topmost nodes in the stack. The creation of dependencies between non-adjacent stack nodes might produce crossing arcs and is the key to the construction of non-projective trees.</p><p>Recall that transitions are partial functions, meaning that they might be undefined for some configurations. Specifically, the shift transition is only defined for configurations with a non-empty buffer. Similarly, the left-arc and right-arc trans- itions can only be applied if the length of the stack is at least 2, while the transitions la 2 and ra 2 re- quire at least 3 nodes in the stack.</p><p>Transitions la 2 and ra 2 were originally intro- duced by <ref type="bibr" target="#b0">Attardi (2006)</ref> together with other, more complex transitions. The parser we define here is therefore more restrictive than <ref type="bibr" target="#b0">Attardi (2006)</ref>, meaning that it does not cover all the non-pro- jective trees that can be processed by the ori- ginal parser. However, the restricted parser has re- cently attracted some research interest, as it covers the vast majority of non-projective constructions appearing in standard treebanks <ref type="bibr" target="#b0">(Attardi, 2006</ref>; <ref type="bibr" target="#b10">Kuhlmann and Nivre, 2010)</ref>, while keeping sim- plicity and interesting properties like being com- patible with polynomial-time dynamic program- ming <ref type="bibr" target="#b2">(Cohen et al., 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Representation of Computations</head><p>Our oracle algorithm exploits a dynamic program- ming technique which, given an input string, com- bines certain pieces of a computation of the parser from Section 3 to obtain larger pieces. In order to efficiently encode pieces of computations, we borrow a representation proposed by <ref type="bibr" target="#b2">Cohen et al. (2011)</ref>, which is introduced in this section.</p><p>Let w = a 0 · · · a n and V w be specified as in Section 2, and let w be some substring of w. (The specification of w is not of our concern in this section.) Let also h 1 , h 2 , h 3 ∈ V w . We are inter- ested in computations of the parser processing the substring w and having the form c 0 , c 1 , . . . , c m , m ≥ 1, that satisfy both of the following condi- tions, exemplified in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>• For some sequence of nodes σ with |σ| ≥ 0, the stack associated with c 0 has the form σ|h 1 and the stack associated with c m has the form σ|h 2 |h 3 .</p><p>• For each intermediate configuration c i , 1 ≤ i ≤ m − 1, the stack associated with c i has the form σσ i , where σ i is a sequence of nodes with |σ i | ≥ 2.</p><p>An important property of the above definition needs to be discussed here, which is at the heart of the polynomial-time algorithm in the next section. If in c 0 , c 1 , . . . , c m we replace σ with a different sequence σ , we obtain a valid computation for w constructing exactly the same dependencies as the original computation. To see this, let c i−1 τ i c i for each i with 1 ≤ i ≤ m. Then τ 1 must be a shift, otherwise |σ 1 | ≥ 2 would be violated. Con- sider now a transition τ i with 2 ≤ i ≤ m that builds some dependency. From |σ i | ≥ 2 we derive |σ i−1 | ≥ 3. We can easily check from <ref type="figure">Figure 1</ref> that none of the nodes in σ can be involved in the constructed dependency.</p><p>Intuitively, the above property asserts that the sequence of transitions τ 1 , τ 2 , . . . , τm can be applied to parse substring w independently of the context σ. This suggests that we can group into an equivalence class all the computations satisfy- ing the conditions above, for different values of σ. We indicate such class by means of the tuple [h 1 , h 2 h 3 ], called item. It is easy to see that each item represents an exponential number of compu- tations. In the next section we will show how we can process items with the purpose of obtaining an efficient computation for dynamic oracles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>920</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Dynamic Oracle Algorithm</head><p>Our algorithm takes as input a gold tree t G for string w and a parser configuration c = (σ, β, A) relative to w, specified as in Section 2. We assume that t G can be parsed by the non-projective parser of Section 3 starting from the initial configuration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Basic Idea</head><p>The algorithm consists of two separate stages, in- formally discussed in what follows. In the first stage we identify some tree fragments of t G that can be constructed by the parser after reaching configuration c, in a way that does not depend on the content of σ. This means that these fragments can be precomputed by looking only into β. Fur- thermore, since these fragments are subtrees of t G , their computation has no effect on the overall loss of a computation on w.</p><p>For each fragment t with the above properties, we replace all the nodes in β that are also nodes of t with the root node of t itself. The result of the first stage is therefore a new node sequence shorter than β, which we call the reduced buffer β R .</p><p>In the second stage of the algorithm we use a variant of the tabular method developed by <ref type="bibr" target="#b2">Cohen et al. (2011)</ref>, which was originally designed to simulate all computations of the parser in Sec- tion 3 on an input string w. We run the above method on the concatenation of the stack and the reduced buffer, with some additional constraints that restrict the search space in two respects. First, we visit only those computations of the parser that step through configuration c. Second, we reach only those dependency trees that contain all the tree fragments precomputed in the first stage. We can show that such search space always con- tains at least one dependency tree with the desired loss, which we then retrieve performing a Viterbi search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Preprocessing of the Buffer</head><p>Let t be a complete subtree of t G , having root node k in β. Consider the following two condi- tions, defined on t.</p><p>• Bottom-up completeness: No arc i → j in t is such that i is a node in β, i = k, and j is a node in σ.</p><p>• Zero gap-degree: The nodes of t that are in β form a (contiguous) substring of w.</p><p>We claim that if t satisfies the above conditions, then we can safely reduce the nodes of t appearing in β, replacing them with node k. We only report here an informal discussion of this claim, and omit a formal proof. As a first remark, recall that our parser imple- ments a purely bottom-up strategy. This means that after a tree has been constructed, all of its nodes but the root are removed from the parser configuration. Then the Bottom-up completeness condition guarantees that if we remove from β all nodes of t but k, the nodes of t that are in σ can still be processed in a way that does not affect the loss, since their parent must be either k or a node that is neither in β nor in σ. Note that the nodes of t that are neither in β nor in σ are irrelevant to the pre- computation of t from β, since these nodes have already been attached and are no longer available to the parser.</p><p>As a second remark, the Zero gap-degree con- dition guarantees that the span of t over the nodes of β is not interleaved by nodes that do not belong to t. This is also an important requirement for the precomputation of t from β, since a tree fragment having a discontinuous span over β might not be constructable independently of σ. More specific- ally, parsing such fragment implies dealing with the nodes in the discontinuities, and this might re- quire transitions involving nodes from σ.</p><p>We can now use the sufficient condition above to compute β R . We process β from left to right. For each node k, we can easily test the Bottom-up completeness condition and the Zero gap-degree condition for the complete subtree t of t G rooted at k, and perform the reduction if both conditions are satisfied. Note that in this process a node k resulting from the reduction of t might in turn be removed from β if, at some later point, we reduce a supertree of t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Computation of the Loss</head><p>We describe here our dynamic programming al- gorithm for the computation of the loss of an in- put configuration c. We start with some additional notation. Let γ = σβ R be the concatenation of σ and β R , which we treat as a string of nodes. For integers i with 0 ≤ i ≤ |γ| − 1, we write γ[i] to denote the (i + 1)-th node of γ. Let also = |σ|. Symbol is used to mark the boundary between the stack and the reduced buffer in γ, thus γ[i] with i &lt; is a node of σ, while γ[i] with i ≥ is a node of β R .</p><p>Algorithm 1 computes the loss of c by pro- cessing the sequence γ in a way quite similar to the standard nested loop implementation of the CKY parser for context-free grammars <ref type="bibr" target="#b8">(Hopcroft et al., 2006</ref>). The algorithm uses a two-dimensional ar- ray T whose indexes range from 0 to |γ| = + |β R |, and only the cells T [i, j] with i &lt; j are filled.  </p><formula xml:id="formula_5">[h 1 , h 2 h 3 ] in T [i, k] and [h 3 , h 4 h 5 ] in T [k, j].</formula><p>Note that we require the index h 3 to match between both items, meaning that their computa- tions can be concatenated. In this way, for each reduce transition τ in our parser, we compute the loss contribution for a new piece of computation defined by concatenating a computation with min- imum loss contribution in the first item and a com- putation with minimum loss contribution in the second item, followed by the transition τ . The fact that the new piece of computation can be repres- ented by an item is exemplified in <ref type="figure" target="#fig_5">Figure 3</ref> for the case τ = ra 2 .  ... </p><note type="other">c +1 la : create arc h h and remove h from stack</note><formula xml:id="formula_6">δ G (i → j) = 0, if i → j is in t G ; 1, otherwise.<label>(4)</label></formula><p>We remark that the nature of our problem al- lows us to apply several shortcuts and optimiza- tions that would not be possible in a setting where we actually needed to parse the string γ. First, the range of variable i in the loop in line 8 starts at max{0, − d}, rather than at 0, because we do not need to combine pairs of items originating from nodes in σ below the topmost node, as the items resulting from such combinations correspond to computations that do not contain our input config- uration c. Second, when we have set values for i such that i+2 &lt; , we can omit calling PROCESS- CELL for values of the parameter k ranging from i+2 to −1, as those calls would use as their input one of the items described above, which are not of interest. Finally, when processing substrings that are entirely in β R (i ≥ ) we can restrict the trans- itions that we explore to those that generate arcs that either are in the gold tree t G , or have a parent node which is not present in γ (see conditions in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Computation of the loss function 1: T [0, 1]([$, $0]) ← 0</head><p>shift node 0 on top of empty stack symbol $ 2: for i ← 1 to − 1 do 3:</p><formula xml:id="formula_7">T [i, i + 1]([γ[i − 1], γ[i − 1]γ[i]]) ← 0 shift node γ[i]</formula><p>with γ[i − 1] on top of the stack 4: for i ← to |γ| do 5:</p><p>for h ← 0 to i − 1 do 6:</p><formula xml:id="formula_8">T [i, i + 1]([γ[h], γ[h]γ[i]]) ← 0 shift node γ[i] with γ[h]</formula><p>on top of the stack 7: for d ← 2 to |γ| do consider substrings of length d 8:</p><p>for i ← max{0, − d} to |γ| − d do i = beginning of substring 9:</p><formula xml:id="formula_9">j ← i + d j − 1 = end of substring 10: PROCESSCELL(T , i, i + 1, j)</formula><p>We omit the range k = i + 2 to max{i + 2, } − 1 11:</p><p>for k ← max{i + 2, } to j do factorization of substring at k 12:</p><p>PROCESSCELL(T , i, k, j)</p><formula xml:id="formula_10">13: return T [0, |γ|]([$, $0]) + i∈[0,,−1] Lc(σ[i], tG) 14: procedure PROCESSCELL(T , i, k, j) 15: for each key [h1, h2h3]) defined in T [i, k] do 16:</formula><p>for each key <ref type="bibr">[h3, h4h5]</ref>) defined in T [k, j] do h3 must match between the two entries 17:</p><formula xml:id="formula_11">loss la ← T [i, k]([h1, h2h3]) + T [k, j]([h3, h4h5]) + δG(h5 → h4) 18: if (i &lt; ) ∨ δG(h5 → h4) = 0 ∨ (h5 ∈ γ) then 19: T [i, j]([h1, h2h5]) ← min{loss la , T [i, j]([h1, h2h5])} cell update la 20: lossra ← T [i, k]([h1, h2h3]) + T [k, j]([h3, h4h5]) + δG(h4 → h5) 21: if (i &lt; ) ∨ δG(h4 → h5) = 0 ∨ (h4 ∈ γ) then 22: T [i, j]([h1, h2h4]) ← min{lossra, T [i, j]([h1, h2h4])} cell update ra 23: loss la 2 ← T [i, k]([h1, h2h3]) + T [k, j]([h3, h4h5]) + δG(h5 → h2) 24: if (i &lt; ) ∨ δG(h5 → h2) = 0 ∨ (h5 ∈ γ) then 25: T [i, j]([h1, h4h5]) ← min{loss la 2 , T [i, j]([h1, h4h5])} cell update la 2 26: lossra 2 ← T [i, k]([h1, h2h3]) + T [k, j]([h3, h4h5]) + δG(h2 → h5) 27: if (i &lt; ) ∨ δG(h2 → h5) = 0 ∨ (h2 ∈ γ) then 28: T [i, j]([h1, h2h4]) ← min{lossra 2 , T [i, j]([h1, h2h4])} cell update ra 2</formula><p>lines 18, 21, 24, 27), because we know that incor- rectly attaching a buffer node as a dependent of an- other buffer node, when the correct head is avail- able, can never be an optimal decision in terms of loss.</p><p>Once we have filled the table T , the loss for the input configuration c can be obtained from the value of the entry T [0, |γ|]( <ref type="bibr">[$, $0]</ref>), representing the minimum loss contribution among computa- tions that reach the input configuration c and parse the whole input string. To obtain the total loss, we add to this value the loss contribution accu- mulated by the dependency trees with root in the stack σ of c. This is represented in Algorithm 1 as</p><formula xml:id="formula_12">i∈[0,,−1] L c (σ[i], t G ), where L c (σ[i], t G )</formula><p>is the count of the descendants of σ[i] (the (i + 1)-th ele- ment of σ) that had been assigned the wrong head by the parser with respect to t G .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Sample Run</head><p>Consider the Czech sentence and the gold depend- ency tree t G shown in <ref type="figure" target="#fig_9">Figure 4(a)</ref>. Given the con- figuration c = (σ, β, A) where σ = [0, 1, 3, 4], β = <ref type="bibr">[5, . . . , 13]</ref> and A = {3 → 2}, we trace the two stages of the algorithm.</p><p>Preprocessing of the buffer The complete sub- tree rooted at node 7 satisfies the Bottom-up com- pleteness and the Zero gap-degree conditions in Section 5.2, so the nodes 5, . . . , 12 in β can be replaced with the root 7. Note that all the nodes in the span 5, . . . , 12 have all their (gold) dependents in that span, with the exception of the root 7, with its dependent node 1 still in the stack. No other reduction is possible, and we have β R = <ref type="bibr">[7,</ref><ref type="bibr">13]</ref>. The corresponding fragment of t G is represented in <ref type="figure" target="#fig_9">Figure 4(b)</ref>.  -Root-V běžném provozu však telefonní linky nermají takivou kvalitu jako v laboratoři <ref type="table">.  0  1  2  3  4  5  6  7  8  9  10 11  12  13</ref> (a) Non-projective dependency tree from the Prague Dependency Treebank.</p><p>-Root-V provozu však nermají .  Note that in our example the loss of c is 1, even though L c = 0, meaning that there are no wrong arcs in A. Indeed, given c, there is no single com- putation that builds all the remaining arcs in t G . This is reflected in T , where the path to reach the item with minimum loss has to go through either T <ref type="bibr">[3,</ref><ref type="bibr">5]</ref> or T <ref type="bibr">[2,</ref><ref type="bibr">4]</ref>, which implies building the erro- neous arc (w 7 → w 3 ) or (w 4 → w 3 ), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Computational Analysis</head><p>The first stage of our algorithm can be easily im- plemented in time O(|β| |t G |), where |t G | is the number of nodes in t G , which is equal to the length n of the input string.</p><p>For the worst-case complexity of the second stage (Algorithm 1), note that the number of cell updates made by calling PROCESS- CELL(T , i, k, j) with k &lt; is O(|σ| 3 |γ| 2 |β R |). This is because these updates can only be caused by procedure calls on line 10 (as those on line 12 always set k ≥ ) and therefore the index k always equals i + 1, while h 2 must equal h 1 because the item [h 1 , h 2 h 3 ] is one of the initial items created on line 3. The variables i, h 1 and h 3 must index nodes on the stack σ as they are bounded by k, while j ranges over β R and h 4 and h 5 can refer to nodes either on σ or on β R .</p><p>On the other hand, the number of cell updates triggered by calls to PROCESSCELL such that k ≥ is O(|γ| 4 |β R | 4 ), as they happen for four indices referring to nodes of β R (k, j, h 4 , h 5 ) and four indices that can range over σ or β R (i, h 1 , h 2 , h 3 ).</p><p>Putting everything together, we conclude that the overall complexity of our algorithm is O(|β| |t G | + |σ| 3 |γ| 2 |β R | + |γ| 4 |β R | 4 ).</p><p>In practice, quantities |σ|, |β R | and |γ| are signi- ficantly smaller than n, providing reasonable train- ing times as we will see in Section 7. For instance, when measured on the Czech treebank, the aver- age value of |σ| is 7.2, with a maximum of 87. Even more interesting, the average value of |β R | is 2.6, with a maximum of 23. Comparing this to the average and maximum values of |β|, 11 and 192, respectively, we see that the buffer reduction is crucial in reducing training time.</p><p>Note that, when expressed as a function of n, our dynamic oracle has a worst-case time com- plexity of O(n 8 ). This is also the time complexity of the dynamic programming algorithm of Cohen et al. (2011) we started with, simulating all com- putations of our parser. In contrast, the dynamic oracle of <ref type="bibr" target="#b7">Goldberg et al. (2014)</ref> for the projective case achieves a time complexity of O(n 3 ) from the dynamic programming parser by <ref type="bibr" target="#b11">Kuhlmann et al. (2011)</ref> running in time O(n 5 ).</p><p>The reason why we do not achieve any asymp- totic improvement is that some helpful properties that hold with projective trees are no longer satis- fied in the non-projective case. In the projective (arc-standard) case, subtrees that are in the buf- fer can be completely reduced. As a consequence, each oracle step always combines an inferred entry in the table with either a node from the stack or a node from the reduced buffer, asymptotically re- ducing the time complexity. However, in the non- projective (Attardi) case, subtrees in the buffer can not always be completely reduced, for the reasons mentioned in the second-to-last paragraph of Sec- tion 5.2. As a consequence, the oracle needs to make cell updates in a more general way, which includes linking pairs of elements in the reduced buffer or pairs of inferred entries in the table.</p><p>-Root-John was not as good for the job as Kate . An example of why this is needed is provided by the gold tree in <ref type="figure" target="#fig_10">Figure 5</ref>. Assume a config- uration c = (σ, β, A) where σ = [0, 1, 2, 3, 4], β = <ref type="bibr">[5, . . . , 11]</ref>, and A = ∅. It is easy to see that the loss of c is greater than zero, since the gold tree is not reachable from c: parsing the subtree rooted at node 5 requires shifting 6 into the stack, and this makes it impossible to build the arcs 2 → 5 and 2 → 6. However, if we reduced the subtree in the buffer with root 5, we would incorrectly obtain a loss of 0, as the resulting tree is parsable if we start with sh followed by la and ra 2 . Note that there is no way of knowing whether it is safe to reduce the subtree rooted at 5 without using non- local information. For example, the arc 2 → 6 is crucial here: if 6 depended on 5 or 4 instead, the loss would be zero. These complications are not found in the projective case, allowing for the men- tioned asymptotic improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Evaluation</head><p>For comparability with previous work on dynamic oracles, we follow the experimental settings repor- ted by <ref type="bibr" target="#b7">Goldberg et al. (2014)</ref>  tions rather than 15, as the increased search space and spurious ambiguity of Attardi's non-project- ive parser implies that more iterations are required to converge to a stable model. A more detailed description of the experimental settings follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Setup</head><p>Training We train a global linear model using the averaged perceptron algorithm and a labelled version of the parser described in Section 3. We perform on-line training using the oracle defined in Section 5: at each parsing step, the model's weights are updated if the predicted transition res- ults into an increase in configuration loss, but the process continues by following the predicted transition independently of the loss increase. As our baseline we train the model using the static oracle defined by <ref type="bibr" target="#b3">(Cohen et al., 2012)</ref>. This oracle follows a canonical computation that cre- ates arcs as soon as possible, and prioritizes the la transition over the la 2 transition in situations where both create a gold arc. The static oracle is not able to deal with configurations that can- not reach the gold dependency tree, so we con- strain the training algorithm to follow the zero-loss transition provided by the oracle. While this version of Attardi's parser has been shown to cover the vast majority of non-projective sentences in several treebanks <ref type="bibr" target="#b0">(Attardi, 2006;</ref><ref type="bibr" target="#b3">Cohen et al., 2012)</ref>, there still are some sentences which are not parsable. These sentences are skipped during training, but not during test and evaluation of the model. If a language is present in both datasets, we use the latest version. We also include res- ults over the Penn Treebank (PTB) <ref type="bibr" target="#b12">(Marcus et al., 1993</ref>) converted to Stanford basic dependen- cies <ref type="bibr" target="#b4">(De Marneffe et al., 2006</ref>). For the CoNLL datasets we use the provided part-of-speech tags and the standard training/test partition; for the PTB we use automatically assigned tags, we train on sections 2-21 and test on section 23.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Results and Analysis</head><p>In <ref type="table">Table 1</ref> we report the unlabelled (UAS) and la- belled (LAS) attachment scores for the static and the dynamic oracles. Each figure is an average over the accuracy provided by 5 models trained with the same setup but using a different random seed. The seed is only used to shuffle the sentences in random order during each iteration of training.</p><p>Our results are consistent with the results re- ported by <ref type="bibr" target="#b6">Goldberg and Nivre (2013)</ref> and <ref type="bibr" target="#b7">Goldberg et al. (2014)</ref>. For most of the datasets, we obtain a relevant improvement in both UAS and LAS. For Dutch, Czech and German, we achieve an error reduction of 5.2%, 11.2% and 4.5%, re- spectively. Exceptions to this general trend are Swedish and Bulgarian, where the accuracy differ- ences are negligible, and the Basque, Catalan and Hungarian datasets, where the performance actu- ally decreases.</p><p>If instead of testing on the standard test sets we use 10-fold cross-validation and average the res- ulting accuracies, we obtain improvements for all languages in <ref type="table">Table 1</ref>   <ref type="bibr">Catalan (88.33, 83.64) against (88.06, 83.13)</ref>. This suggests that the negligible or unfavourable results in <ref type="table">Table 1</ref> for these languages are due to statistical variability given the small size of the test sets.</p><p>As for Basque, we measure (75.54, 67.58) against <ref type="bibr">(76.77, 68.20)</ref>; similarly, for Hungarian we measure <ref type="bibr">(75.66, 67.66) against (77.22, 68.42)</ref>. Unfortunately, we have no explanation for these performance decreases, in terms of the typology of the non-projective patterns found in these two datasets. Note that <ref type="bibr" target="#b7">Goldberg et al. (2014)</ref> also observed a performance decrease on the Basque dataset in the projective case, although not on Hungarian.</p><p>The parsing times measured in our experiments for the static and the dynamic oracles are the same, since the oracle algorithm is only used during the training stage. Thus the reported improvements in parsing accuracy come at no extra cost for parsing time. In the training stage, the extra processing needed to compute the loss and to explore paths that do not lead to a gold tree made training about 4 times slower, on average, for the dynamic oracle model. This confirms that our oracle algorithm is fast enough to be of practical interest, in spite of its relatively high worst-case asymptotic complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We have presented what, to our knowledge, are the first experimental results for a transition-based non-projective parser trained with a dynamic or- acle. We have also shown significant accuracy im- provements on many languages over a static oracle baseline.</p><p>The general picture that emerges from our ap- proach is that dynamic programming algorithms originally conceived for the simulation of trans- ition-based parsers can effectively be used in the development of polynomial-time algorithms for dynamic oracles.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: General form of the computations associated with an item [h 1 , h 2 , h 3 ].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>We view each T</head><label></label><figDesc>[i, j] as an association list whose keys are items [h 1 , h 2 h 3 ], defined in the context of the substring γ[i] · · · γ[j − 1] of γ; see Section 4. The value stored at T [i, j]([h 1 , h 2 h 3 ]) is the minimum loss contribution due to the com- putations represented by [h 1 , h 2 h 3 ]. For technical reasons, we assume that our parser starts with a symbol $ ∈ V w in the stack, denoting the bottom of the stack.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>We</head><label></label><figDesc>initialize the table by populating the cells of the form T [i, i + 1] with information about the trivial computations consisting of a single sh transition that shifts the node γ[i] into the stack. These computations are known to have zero loss contribution, because a sh transition does not cre- ate any arcs. In the case where the node γ[i] be- longs to σ, i.e., i &lt; , we assign loss contribution 0 to the entry T [i, i + 1]([γ[i − 1], γ[i − 1]γ[i]]) (line 3 of Algorithm 1), because γ[i] is shifted with γ[i − 1] at the top of the stack. On the other hand, if γ[i] is in β, i.e., i ≥ , we assign loss contri- bution 0 to several entries in T [i, i + 1] (line 6) because, at the time γ[i] is shifted, the content of the stack depends on the transitions executed be- fore that point. After the above initialization, we consider pairs of contiguous substrings γ[i] · · · γ[k − 1] and γ[k] · · · γ[j − 1] of γ. At each inner iteration of the nested loops of lines 7-11 we update cell T [i, j] based on the content of the cells T [i, k] and T [k, j]. We do this through the procedure PRO- CESSCELL(T , i, k, j), which considers all pairs of keys</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Concatenation of two computations/items and transition ra 2 , resulting in a new computation/item.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Computation of the loss Let γ = σβ R . Al- gorithm 1 builds the two-dimensional array T in Figure 4(c). Each cell T [i, j] contains an asso- ciation list, whose (key:value) pairs map items to their loss contribution. Figure 4(c) only shows the pairs involved in the minimum-loss computation. Lines 1-6 of Algorithm 1 initialize the cells in the diagonal, T [0, 1], . . . , T [5, 6]. The boundary between stack and buffer is = 4, thus cells T [0, 1], T [1, 2], and T [2, 3] contain only one ele- ment, while T [3, 4], T [4, 5] and T [5, 6] contain as many as the previous elements in γ, although not all of them are shown in the figure. Lines 7-12 fill the superdiagonals until T [0, 6] is reached. The cells T [0, 2], T [0, 3] and T [1, 3]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>923</head><label>923</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>(</head><label></label><figDesc>c) Relevant portion of T computed by Algorithm 1, with the loss of c in the yellow entry.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Example of loss computation given the sentence in (a) and considering a configuration c with σ = [0, 1, 3, 4] and β = [5,. .. , 13].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Non-projective dependency tree adapted from the Penn Treebank.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Datasets</head><label></label><figDesc>We evaluate the parser performance over CoNLL 2006 and CoNLL 2007 datasets.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The first author has been partially funded by Min-isterio de Economía y Competitividad/FEDER (Grant TIN2010-18552-C03-02) and by Xunta de Galicia (Grant CN2012/008). The third author has been partially supported by MIUR under project PRIN No. 2010LYA9RH 006.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Experiments with a multilanguage non-projective dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Attardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the Tenth Conference on Computational Natural Language Learning (CoNLL)<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="166" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Transition-based dependency parsing with selectional branching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1052" to="1062" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exact inference for generative probabilistic non-projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK.</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="1234" to="1245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Elimination of spurious ambigu</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Satta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>ity in transition-based dependency parsing. CoRR, abs/1206.6735</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the 5th International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="449" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A dynamic oracle for arc-eager dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24 th COLING</title>
		<meeting>of the 24 th COLING<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Training deterministic parsers with non-deterministic oracles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A tabular method for dynamic oracles in transition-based parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Sartorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="119" to="130" />
			<date type="published" when="2014-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ullman</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">E</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Introduction to Automata Theory, Languages, and Computation</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AddisonWesley Longman Publishing Co., Inc</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>3rd Edition</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dynamic programming for linear-time incremental parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Transitionbased techniques for non-projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Northern European Journal of Language Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dynamic programming algorithms for transition-based dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="673" to="682" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An efficient algorithm for projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Workshop on Parsing Technologies (IWPT)</title>
		<meeting>the Eighth International Workshop on Parsing Technologies (IWPT)<address><addrLine>Nancy, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="149" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Incrementality in deterministic dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Incremental Parsing: Bringing Engineering and Cognition Together</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Statistical dependency analysis with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyasu</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Parsing Technologies (IWPT)</title>
		<meeting>the 8th International Workshop on Parsing Technologies (IWPT)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Transition-based dependency parsing with rich non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="188" to="193" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
