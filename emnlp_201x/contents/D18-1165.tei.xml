<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning a Policy for Opportunistic Active Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Padmakumar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Stone</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning a Policy for Opportunistic Active Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1347" to="1357"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1347</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Active learning identifies data points to label that are expected to be the most useful in improving a supervised model. Opportunis-tic active learning incorporates active learning into interactive tasks that constrain possible queries during interactions. Prior work has shown that opportunistic active learning can be used to improve grounding of natural language descriptions in an interactive object retrieval task. In this work, we use reinforcement learning for such an object retrieval task, to learn a policy that effectively trades off task completion with model improvement that would benefit future tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In machine learning tasks where obtaining labeled examples is expensive, active learning is used to lower the cost of annotation without sacrific- ing model performance. Active learning allows a learner to iteratively query for labels of unla- beled data points that are expected to maximally improve the existing model. It has been used in a number of natural language processing tasks such as text categorization ( <ref type="bibr" target="#b10">Lewis and Gale, 1994)</ref>, se- mantic parsing ( <ref type="bibr" target="#b32">Thompson et al., 1999</ref>) and infor- mation extraction <ref type="bibr" target="#b25">(Settles and Craven, 2008)</ref>.</p><p>The most commonly used framework for active learning is pool-based active learning, where the learner has access to the entire pool of unlabeled data at once, and can iteratively query for exam- ples. In contrast, sequential active learning is a framework in which unlabeled examples are pre- sented to the learner in a stream ( <ref type="bibr" target="#b10">Lewis and Gale, 1994)</ref>. For every example, the learner can decide whether to query for its label or not. This results in an additional challenge -since the learner cannot compare all unlabeled data points before choosing queries, each query must be chosen based on local information only.</p><p>Multilabel active learning is the application of active learning in scenarios where multiple labels, that are not necessarily mutually exclusive, are as- sociated with a data point <ref type="bibr" target="#b1">(Brinker, 2006</ref>). These setups often suffer from sparsity, both in the num- ber of labels that are positive for a data point, and in the number of positive data points per label.</p><p>Opportunistic active learning incorporates a form of multilabel sequential active learning into an interactive task. It was recently introduced for the task of interpreting natural-language object de- scriptions, motivated by the task of instructing a robot to retrieve a specific item ( . In this task, a human describes one of a set of objects in unrestricted natural language and the agent must determine which object was described. The agent is allowed to ask questions about other objects in the current environment to obtain la- bels that allow it to learn classifiers for concepts used in such descriptions. As the questions are re- stricted to the objects available in the current inter- action, the learning process across interactions can be seen as a form of multilabel sequential active learning. Further, the agent can either restrict itself to querying labels relevant to understanding the current description, or be opportunistic and query labels that can only aid future interactions -for example querying whether some object is "round" when trying to understand the description "a red box".</p><p>More generally, in opportunistic active learn- ing, an agent is engaged in a series of sequen- tial decision-making tasks. The agent uses one or more supervised models to complete each task. Each task involves some sampled examples from a given feature space, and the agent is allowed to query for labels of these examples to improve its models for current and future tasks. Queries in this setting have a higher cost than in traditional active learning as the agent may choose to query for la-bels that are not relevant for the current task, but expected to be of use for future tasks. Such op- portunistic queries enable an agent to learn from a greater number of interactions, by allowing it to ask queries that would aid future tasks when it is sufficiently confident of completing the current task. They also allow an agent to focus on con- cepts that could have more impact than those rele- vant to the current task -for example by choosing a frequently used concept as opposed to a rare one. Further, identifying which queries are optimal for model improvement is more difficult as the agent does not have access to the entire pool of unlabeled examples at any given time, similar to sequential active learning settings.</p><p>Another sample application of opportunistic ac- tive learning could be in a task oriented dialog system providing restaurant recommendations to a user. In this case, a possible opportunistic query would be to ask the user for a Chinese restaurant they liked, when the user is searching for an Ital- ian one. The query is not relevant to the imme- diate task of recommending an Italian restaurant but would improve the underlying recommenda- tion system.</p><p>Prior work on using opportunistic active learn- ing in understanding natural-language object de- scriptions has shown that an agent following an opportunistic policy, that queries for labels not necessarily relevant to the current interac- tion, learns to perform better at identifying ob- jects correctly over time ( ). However, this work only compares static policies that select actions based on manually-engineered heuristics. In this work, we focus on learning an optimal policy for this task using reinforcement learning, in the spirit of other recent attempts to learn policies for different types of active learn- ing <ref type="bibr" target="#b5">(Fang et al., 2017;</ref><ref type="bibr" target="#b37">Woodward and Finn, 2017)</ref>. This allows an agent to choose whether or not to be opportunistic based on the specific interaction as well as the overall statistics of the dataset.</p><p>Our learned policy outperforms a static base- line by improving its success rate on object re- trieval while asking fewer questions on average. The learned policy also learns to distribute queries more uniformly across concepts than the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Active learning methods aim to identify examples that are likely to be the most useful in improving a supervised model. A number of metrics have been proposed to evaluate examples, including uncer- tainty sampling ( <ref type="bibr" target="#b10">Lewis and Gale, 1994)</ref>, density- weighted methods <ref type="bibr" target="#b25">(Settles and Craven, 2008)</ref>, expected error reduction <ref type="bibr" target="#b21">(Roy and McCallum, 2001</ref>), query by committee ( <ref type="bibr" target="#b26">Seung et al., 1992)</ref>, and the presence of conflicting evidence <ref type="bibr" target="#b27">(Sharma and Bilgic, 2016)</ref>; as surveyed by <ref type="bibr" target="#b24">Settles (2010)</ref>. Some of these metrics can be extended to the mul- tilabel setting, by assuming that one-vs-all clas- sifiers are learned for each label, and that all the learned classifiers are comparable <ref type="bibr" target="#b1">(Brinker, 2006;</ref><ref type="bibr" target="#b29">Singh et al., 2009;</ref>. Label statistics have also been incorporated into heuristics for selecting instances to be queried ( <ref type="bibr" target="#b38">Yang et al., 2009;</ref><ref type="bibr" target="#b13">Li and Guo, 2013)</ref>. There have also been Bayesian ap- proaches that select both an instance and label to be queried ( <ref type="bibr" target="#b20">Qi et al., 2009;</ref><ref type="bibr" target="#b33">Vasisht et al., 2014</ref>). Our work aims to learn a policy for choosing be- tween queries that can use information from many such indicators, but learns to combine them appro- priately for a given task.  define the setting of op- portunistic active learning, and apply it to an in- teractive task of grounding natural language de- scriptions of objects. They compare two static policies to demonstrate that using opportunistic queries improves task performance. We try to learn the optimal policy for this task using rein- forcement learning, and compare to a policy simi- lar to theirs.</p><p>Recently, there has been interest in using re- inforcement learning to learn a policy for ac- tive learning. <ref type="bibr" target="#b5">Fang et al. (2017)</ref> use deep Q- learning to acquire a policy that sequentially ex- amines unlabeled examples and decides whether or not to query for their labels; using it to im- prove named entity recognition in low resource languages. Also, <ref type="bibr" target="#b0">Bachman et al. (2017)</ref> use meta- learning to jointly learn a data selection heuristic, data representation and prediction function for a distribution of related tasks. They apply this to one shot recognition of characters from different lan- guages, and in recommender systems. In contrast to these works, we learn a policy for a task that contains both possible actions that are active learn- ing queries, and actions that complete the cur- rent task, thus resulting in a greater exploration- exploitation trade-off.</p><p>More similar to our setup is that of Wood- ward and Finn (2017) which uses reinforcement learning with a recurrent-neural-network-based Q- function in a sequential one-shot learning task to decide between predicting a label and acquiring the true label at a cost. This setup also has a higher cost than standard active learning where the test set is separated out. This is a continuous task with- out clearly separated interactions or episodes. In our setting, each episode or interaction allows for querying and requires completion of an interac- tion, which further increases the trade-off between model improvement and exploitation. Further, we consider a multilabel setting, which increases the number of actions at each decision step.</p><p>There are other works that employ various types of turn-taking interaction to learn models for lan- guage grounding. Some of these use a restricted vocabulary <ref type="bibr" target="#b2">(Cakmak et al., 2010;</ref><ref type="bibr" target="#b9">Kulick et al., 2013)</ref>, or additional knowledge of predicates (for example that "red" is a color) ( <ref type="bibr" target="#b16">Mohan et al., 2012</ref>). Others do not use active learning ( <ref type="bibr" target="#b7">Kollar et al., 2013;</ref><ref type="bibr" target="#b18">Parde et al., 2015;</ref><ref type="bibr" target="#b4">De Vries et al., 2017;</ref><ref type="bibr" target="#b39">Yu et al., 2017</ref>), or do not learn a policy that guides the interaction ( <ref type="bibr" target="#b34">Vogel et al., 2010;</ref><ref type="bibr" target="#b31">Thomason et al., 2016</ref>.</p><p>Also related to our work is the use of rein- forcement learning in dialog tasks, such as slot- filling and recommendation <ref type="bibr" target="#b35">(Wen et al., 2015;</ref><ref type="bibr" target="#b19">Pietquin et al., 2011</ref>), understanding natural lan- guage instructions or commands ( <ref type="bibr" target="#b15">Misra et al., 2017)</ref>, and open domain conversation ( <ref type="bibr" target="#b23">Serban et al., 2016;</ref><ref type="bibr" target="#b3">Das et al., 2017)</ref>. These typically do not use active learning. In our task, the policy needs to trade-off model improve- ment against task completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Opportunistic Active Learning</head><p>Opportunistic Active Learning (OAL) is a setting that incorporates active learning queries into inter- active tasks. Let O = {o 1 , o 2 , . . . o n } be a set of examples, and M = {m 1 , m 2 , . . . m k } be super- vised models trained for different concepts, using these examples. For the problem of understand- ing natural-language object descriptions, O cor- responds to the set of objects, M corresponds to the set of possible concepts that can be used to describe the objects, for example their categories (such as ball or bottle) or perceptual properties (such as red or tall).</p><p>In each interaction, an agent is presented with some subset O A ⊆ O, and must make a decision based on some subset of the models M A ⊆ M . Given a set of objects O A and a natural language description l, M A would be the set of classifiers corresponding to perceptual predicates present in l. The decision made by the agent is a guess about which object is being described by l. The agent receives a score or reward based on this decision, and needs to maximize expected reward across a series of such interactions. In the task of object retrieval, this is a 0/1 value indicating whether the guess was correct, and the agent needs to maxi- mize the average guess success rate.</p><p>During the interaction, the agent may also query for the label of any of the examples present in the interaction o ∈ O A , for any model m ∈ M . The agent is said to be opportunistic when it chooses to query for a label m / ∈ M A , as this label will not affect the decision made in the current interaction, and can only help with future interactions. For example, given a description "the red box", ask- ing whether an object is red, could help the agent make a better guess, but asking whether an object is round, would be an opportunistic query. Queries have a cost, and hence the agent needs to trade-off the number of queries with the success at guessing across interactions.</p><p>The agent participates in a sequence of such in- teractions, and the models improve from labels ac- quired over multiple interactions. Thus the agent's expected reward per interaction is expected to im- prove as more interactions are completed.</p><p>This setting differs from the traditional applica- tion of active learning in the following key ways:</p><p>• The agent cannot query for the label of any example from the unlabeled pool. It is re- stricted to the set of objects available in the current interaction, O A .</p><p>• The agent is evaluated on the reward per in- teraction, rather than the final accuracy of the models in M .</p><p>• The agent may make opportunistic queries (for models m / ∈ M A ) that are not relevant to the current task.</p><p>Due to these differences, this setting provides challenges not seen in most active learning sce- narios:</p><p>• Since the agent never sees the entire pool of unlabeled examples, it can neither choose queries that are globally optimal, nor use variance reduction strategies that still use near-optimal queries (such as sampling from a beam of near globally optimal queries).</p><p>• Since the agent is evaluated on task comple- tion, it must learn to trade-off finishing the task with querying to improve the models.</p><p>• The agent needs to estimate the usefulness of a model across multiple interactions, to iden- tify good opportunistic queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Task Setup</head><p>We consider an interactive task where an agent tries to learn to ground natural-language object descriptions. Grounded language understand- ing is the process of mapping natural-language referring expressions to object referents in the world ( <ref type="bibr" target="#b31">Thomason et al., 2016</ref>). We consider a grounded-language problem based on object re- trieval -given a free form natural-language de- scription of an object, the agent needs to identify which of a set of objects is best described by the phrase ( <ref type="bibr" target="#b31">Thomason et al., 2016;</ref><ref type="bibr" target="#b6">Guadarrama et al., 2014)</ref>. In this work, objects are presented as im- ages, but the methods are applicable to any feature representation of objects. We consider a task of in- teractive object retrieval where the agent is given a natural-language object description, and allowed to interact with the user before it attempts to guess the object being referred to. In each interaction, the agent is presented with two sets of objects. The first set of objects is called the active training set, and is to be used by the agent to improve its model of object properties. The second set of objects is called the active test set, and the agent will have to retrieve an object from this set. The agent is provided with a natural language description of the object it is expected to retrieve.</p><p>Before guessing, the agent is allowed to ask queries of the following two types:</p><p>• Label queries -A yes/no question about whether a predicate can be used to describe one of the objects in the active training set, e.g. "Is this object yellow?".</p><p>• Example queries -Asking for an object, in the available training set, that can be described by a particular predicate, e.g. "Show me a white object in this set.". This is used for ac- quiring positive examples since most predi- cates tend to be sparse. 1 <ref type="bibr">1</ref> Alternately, we could return all positive examples for the A sample interaction is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The agent goes through a series of such interactions, and needs to learn to maximize the number of cor- rect guesses across interactions, without frustrat- ing the user with too many queries. The separate active training set and active test set ensures that the agent needs to learn models for object descrip- tors. If queries and guessing were performed on the same set of objects, the agent could simply query whether each specific object satisfies each predicate in the description, and use this to guess.</p><p>In our experiments, we simulate such di- alogs using the Visual Genome dataset ( <ref type="bibr" target="#b8">Krishna et al., 2017)</ref>; which contains images with regions (crops) annotated with natural-language descrip- tions. Bounding boxes of objects present in the image are also annotated, along with attributes of objects. Region descriptions, objects and at- tributes are annotated using unrestricted natural language, which leads to a diverse set of predi- cates. Using the annotations, we can associate a predicate in the active training set, but we chose to return a single example to allow the agent to minimize the amount of supervision obtained list of objects and attributes relevant to each im- age region, and use these to answer queries from the agent.</p><p>For each interaction, we uniformly sample 4 re- gions to form the active test set, and 8 regions to form the active training set. <ref type="bibr">2</ref> One region is then uniformly sampled from the active test set to be the target object. Its description, from annotations in the Visual Genome dataset, is provided to the agent to be grounded. The objects and attributes associated with active training regions are used to answer queries. A predicate is labeled as being applicable to a region if it is present in the list of objects and attributes associated with the region. In the rest of the paper, we use the terms object, image, and region interchangeably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Perceptual Predicates and Classifiers</head><p>We assume that the description provided is a con- junction of one-word predicates. Given a de- scription, the agent tokenizes it and removes stop- words. Each remaining word is stemmed and treated as a perceptual predicate. This method al- lows the agent to learn an open vocabulary of pred- icates, but unable to handle multi-word predicates or non-compositional phrases.</p><p>The agent learns a separate binary classifier for each predicate, and we represent images with a "deep" feature representation obtained from the penultimate layer of the VGG network <ref type="bibr" target="#b28">(Simonyan and Zisserman, 2014</ref>) pretrained on Im- ageNet ( <ref type="bibr" target="#b22">Russakovsky et al., 2015)</ref>. The agent has no initial classifiers for any predicate, and learns these classifiers purely from labels acquired dur- ing interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Grounding Descriptions</head><p>The learned perceptual classifiers are used to ground natural language descriptions as follows. Let p 1 , p 2 , . . . p k be the predicates obtained from the natural language description. Let d(p i , o) ∈ {−1, 1} be the decision from the classifier for predicate p i for object o, and C(p i ) be the esti- mated F1 of the classifier for p i . 3 Then the best guess, from the objects present, is chosen using the weighted sum of the decisions of the classi- fiers, using their estimated F1 as a weight:</p><formula xml:id="formula_0">o guess = argmax o∈O A k i=1 d(p i , o) * C(p i )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">MDP Formulation</head><p>We model the task as a Markov Decision Process (MDP). An MDP is a tuple S, A, T, R, γ, where S is a set of states, A is a set of actions, T is a transition function, R is a reward function and γ is a discount factor. Each interaction is an episode in the MDP. At any point, the agent is in a state s ∈ S, in our case consisting of the VGG features of the images in the current interaction, the pred- icates in the current description, and the agent's classifiers. The agent can choose from among ac- tions in A, which include an action for guessing, and an action for each possible query the agent can make, including both label and example queries. The guess action always terminates the episode, and query actions transition the agent to a state s ∈ S as one of the classifiers gets updated. The agent gets a reward for each action taken. Query actions have a small negative reward, and guessing results is a large positive reward when the guess is correct, and a large negative reward when the guess is incorrect. In our experiments, we treat the reward values as hyperparameters that can be tuned. The best results were obtained with a re- ward of 200 for a correct guess, -100 for an incor- rect guess and -1 for each query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Identifying Candidate Queries</head><p>In any interaction, the agent can make label or ex- ample queries. In a label query, the agent can ask for the label of any object for a specific predicate. If O A is the set of objects present in the active training set of the current interaction, and P is the set of predicates that have been seen by the agent in all interactions so far, then the set of possible label queries is P × O A . Once the agent chooses a predicate p and object o to be queried, it obtains the corresponding label and can update its classi- fier for p. In an example query, the agent asks for a positive example for any predicate p ∈ P . The agent will either receive a positive label for p for some object o ∈ O A or learn that the label is neg- ative ∀ o ∈ O A , and can appropriately update the classifier for p.</p><p>Since |P | grows across interactions as the agent encounters more predicates in descriptions, the number of candidate actions in a state increases over time, so searching the entire space of pos- sible queries can become intractable. Hence, we identify a beam of promising queries that are then provided as candidate actions for the policy to choose among. Uncertainty sampling is a com- mon method in pool-based active learning to iden- tify the best example to improve a classifier. For a given predicate p, we use this to choose the best label query involving that predicate, picking that object o ∈ O A which is closest to the hyperplane of the classifier for p.</p><p>However, it is more challenging to narrow down the number of predicates.  assume that an estimate of classifier accuracy is available, which is comparable across classifiers. They sample predicates with a probability in- versely proportional to the estimated accuracy of the classifier. However, if the space of possible predicates is large, then this results in no classifier obtaining a reasonable number of training exam- ples. In this scenario, it is desirable to focus on a small number of predicates, possibly stopping the improvement on a predicate once the classi- fier for it has been sufficiently improved. We sam- ple queries from a distribution designed to capture this intuition. The probability assigned to a pred- icate by this distribution increases linearly, for es- timated F1 below a threshold, and decreases lin- early thereafter. <ref type="bibr">4</ref> The number of queries sampled is a hyperparameter. We obtain the best results by sampling 3 queries of each type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Baseline Static Policy</head><p>As a baseline, we use a static policy similar to that used by . At each state, a single label query and example query are sam- pled. The agent asks a fixed number of queries be- fore guessing.  use thresh- olds that prevent queries from being asked when there are no predicates whose classifiers have suf- ficiently low estimated accuracy. Since we used a dataset with a much larger number of predicates, these thresholds were always crossed if the agent had even one candidate query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Policy Learning</head><p>We use the REINFORCE algorithm <ref type="bibr" target="#b36">(Williams, 1992)</ref> to learn a policy for the MDP. The agent learns a policy π(a|s; θ), parameterized with weights θ that computes the probability of taking action a in state s. Given a feature representation f (s, a) for a state-action pair <ref type="figure">(s, a)</ref>, the policy is of the form:</p><formula xml:id="formula_1">π(a|s; θ) = e θ T f (s,a) a e θ T f (s,a )</formula><p>where the denominator is a sum over all actions possible in state s. The weights are updated using a stochastic gradient ascent rule:</p><formula xml:id="formula_2">θ ← θ + α θ J(θ)</formula><p>where J(θ) is the expected return from the pol- icy according to the distribution over trajectories induced by the policy.</p><p>The state consists of the predicates in the cur- rent description, the candidate objects, and the cur- rent classifiers. Since both the number of candi- date objects and classifiers varies, and the latter is quite large, it is necessary to identify useful fea- tures for the task to obtain a vector representation needed by most learning algorithms. In our prob- lem setting, the number of candidate actions avail- able to the agent in a given state is variable. Hence we need to create features for state-action pairs, rather than just states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Features for Policy Learning</head><p>The object retrieval task consists of two parts - identifying useful queries to improve classifiers, and correctly guessing the image being referred to by a given description. The current dialog length is also provided to influence the trade-off between guessing and querying.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.1">Guess-success features</head><p>Let P A = {p 1 , p 2 , . . . p k } be the predicates ex- tracted from the current description. For each predicate p ∈ P A , we have the estimated F1 of the classifier C(p), and for each object o in the active test set, we have a decision d(p, o) ∈ {−1, 1} from the classifier. We refer to s(p, o) = d(p, o) * C(p) as the score of the classifier of p for object o. The following features are used to predict whether the current best guess is likely to be correct:</p><p>• Lowest, highest, second highest, and average estimated F1 among classifiers of predicates in P A -learned thresholds on these values can be useful to decide whether to trust the guess.</p><p>• Highest score among regions in the active test set, and the differences between this and the second highest, and average scores respec- tively -a good guess is expected to have a high score to indicate relevance to the de- scription, and substantial differences would indicate that the guess is discriminative. Sim- ilar features are also formed using the un- weighted sum of decisions.</p><p>• An indicator of whether the two most confi- dent classifiers agree on the decision of the top scoring region, which increases the like- lihood of its being correct.</p><p>We compared directly using these features to training a regressor that uses them to predict the probability of a successful guess, and then using this as a higher-level policy feature. We found no difference between the two methods and the results reported directly use these features in the vector provided to the policy learner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.2">Query-evaluation features</head><p>The following features are expected to be useful in predicting whether it is useful to query for the label of a particular predicate:</p><p>• Indicator of whether the predicate is new or already has a classifier -this allows the pol- icy to decide between strengthening exist- ing classifiers or creating classifiers for novel predicates.</p><p>• Current estimated F1 of the classifier for the predicate -as there is more to be gained from improving a poor classifier.</p><p>• Fraction of previous dialogs in which the predicate has been used, and the agent's suc- cess rate in these -as there is more to be gained from improving a frequently used predicate but less if the agent already makes enough correct guesses for it.</p><p>• Is the query opportunistic -as these will not help the current guess.</p><p>Label queries also have an image region speci- fied, and for these we have additional features that use the VGG feature space in which the region is represented for classification:</p><p>• Margin of the image region from the hyper- plane of the classifier of the predicate -moti- vated by uncertainty sampling.</p><p>• Average cosine distance of the image region to others in the dataset -motivated by density weighting to avoid outliers.</p><p>• Fraction of the k-nearest neighbors of the re- gion that are unlabeled for this predicate - motivated by density weighting to identify a data point that can influence many labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Dataset</head><p>The Visual Genome dataset contains a total of 108,077 images with 540,6592 annotated regions.</p><p>Since objects and attributes are annotated with free-form text rather than from a fixed, pre-defined vocabulary, there is considerable diversity in the language used for annotation. There are 80,908 unique objects annotated and 44,235 attributes. We assume that any objects that partially overlap with a region are present in it, as these are usually used in descriptions. Using the annotations, we can associate a list of objects and attributes rele- vant to each image region. We lower-case all an- notations, remove special characters and perform stemming to help normalize terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Sampling dialogs</head><p>We want the agent to learn a policy that is inde- pendent of the actual predicates present at policy training and policy test time. In order to be able to evaluate this, we divide the set of possible regions into policy training and policy test regions as fol- lows. We select all objects and attributes present in at least 1,000 regions. Half of these were ran- domly assigned to the policy test set. All regions that contain one of these objects or attributes are assigned to the policy test set, and the rest to the policy training set. Thus regions seen at test time may contain predicates seen during training, but will definitely contain at least one novel predicate. Further, the policy training and policy test sets are respectively partitioned into a classifier training and classifier test set using a uniform 60-40 split. During policy training, the active training set of each dialog is sampled from the classifier- training subset of the policy-training regions, and the active test set of the dialog is sampled from the classifier-test subset of the policy-training set.</p><p>During policy testing, the active training set of each dialog is sampled from the classifier training subset of the policy test regions, and the active test set of the dialog is sampled from the classifier test subset of the policy test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Experiment phases</head><p>For efficiency, we run dialogs in batches, and per- form classifier and policy updates at the end of each batch. We use batches of 100 dialogs each. Our experiment runs in 3 phases:</p><p>• Initialization -Since learning starting with a random policy can be difficult, we first run batches of dialogs on the policy training set using the static policy from section 5.5, and update the RL policy using states, actions and rewards seen in these dialogs. This "super- vised" learning phase is used to initialize the RL policy.</p><p>• Training -We run batches of dialogs on the policy training set using the RL policy, start- ing it without any classifiers. In this phase, the policy is updated using its own experi- ence.</p><p>• Testing -We fix the parameters of the RL policy, and run batches of dialogs on the pol- icy test set. During this phase, the agent is again reset to start with no classifiers. We do this to ensure that performance improve- ments seen at test time are purely from learn- ing a strategy for opportunistic active learn- ing, not from acquiring useful classifiers in the process of learning the policy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Results and Analysis</head><p>We initialize the policy with 10 batches of dialogs, and then train on another 10 batches of dialogs, both sampled from the policy training set. Fol- lowing this, the policy weights are fixed, the agent is reset to start with no classifiers, and we test on 10 batches of dialogs from the policy test set. Ta- ble 1 compares the average success rate (fraction of successful dialogs in which the correct object is identified), and average dialog length (average number of system turns) of the best learned policy, and the baseline static policy on the final batch of testing. We also compare the effect of ablating the two main groups of features. The learned agent guesses correctly in a significantly higher fraction of dialogs compared to the static agent, using a significantly lower number of questions per dia- log.</p><p>When either the group of guess or query fea- tures is ablated, the success rate clearly decreases. While the mean success rate still remains above the baseline, the difference is no longer statisti- cally significant. Further, at the end of the initial- ization phase, the average dialog length in all three conditions is about the same. In the two ablated conditions, the dialog length does not increase to become close to that of the static policy, which suggests that the agent does not learn that asking more queries improves dialog success. This is ex- pected because the agent is either not able to eval- uate the usefulness of queries, or the likelihood of success of a guess. However, in the learned policy with all features, the agent is able to identify a ben- efit in asking queries, and utilizes them to improve its success rate.</p><p>It is important to note that it is non-trivial to de- cide how to trade-off dialog success with dialog length. This should be decided for any given ap- plication by comparing the cost of an error with that of the user time involved in answering queries, and the reward function should be set appropri- ately based on this. Ideally, we would like to see an increase in dialog success rate and a decrease in dialog length, as is the case when comparing the learned and static policies. However, depend- ing on the application, it may also be beneficial to see a smaller increase in success rate with a larger decrease in dialog length, as is the case in the ab- lated conditions.</p><p>We also explored ablating individual features. We found that the effect of ablating most single features is similar to that of ablating a group of fea- tures. The mean success rate decreases compared to the full policy with all features. It remains bet- ter than that of the static policy, but in most cases the difference stops being statistically significant. Among features for evaluating the guess, the re- moval of the difference between the two highest scores in the active test set has a fairly large ef- fect, compared with the value of the highest score. This is expected because for retrieval it is suf- ficient if an object is simply scored higher than the other candidates. Further, since classifiers im- prove over time, the score threshold that indicates a good guess changes, and hence would be diffi- cult to learn. An interesting result is that removal of features involving the predictions of the second best classifier has more effect than that of the best classifier. This is possibly because when noisy classifiers are in use, support of multiple classi- fiers is helpful. Among query evaluation features, we find, unsurprisingly, that removal of the feature providing the margin of the object in a label query affects performance much more than removal of features such as density and fraction of labeled neighbors, which merely indicate whether the ob- ject is an outlier. The full results of this experiment are included in the supplementary material.</p><p>Qualitatively, we found that the dialog success rate was higher for both short, and very long di- alogs, with a decrease for dialogs of intermedi- ate length. This suggests that longer dialogs are used to accumulate labels via opportunistic off- topic questions, as opposed to on-topic questions. The learned policy still suffers from high variance in dialog length suggesting that trading off task completion against model improvement is a dif- ficult decision to learn. We find that the labels collected by the learned policy are more equitably distributed across predicates than the static policy, resulting in a tendency to have fewer classifiers of low estimated F1. There is relatively little differ- ence in the number of predicates for which clas- sifiers are learned. This suggests that the policy learns to focus on a few predicates, as the baseline does, but learn all of these equally well, in contrast to the baseline which has much higher variance in the number of labels collected per predicate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Future Work</head><p>It would be interesting to examine how a policy learned using a dataset such as Visual Genome generalizes to a different domain such as im- ages captured by a robot operating in an indoor environment, possibly with some fine-tuning us- ing a smaller in-domain dataset. The simulation could also potentially be improved using positive- unlabeled learning methods ( <ref type="bibr" target="#b14">Liu et al., 2002;</ref><ref type="bibr" target="#b12">Li and Liu, 2003</ref>) instead of assuming that an object or attribute not labeled in an image region is not present in the image. It would also be interesting to compare the effectiveness of the opportunistic active learning framework, as well as the policy learning, across a variety of applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>This paper has shown how to formulate an op- portunistic active learning problem as a reinforce- ment learning problem, and learn a policy that can effectively trade-off opportunistic active learn- ing queries against task completion. We evalu- ated this approach on the task of grounded object retrieval from natural language descriptions and learn a policy that retrieves the correct object in a larger fraction of dialogs than a previously pro- posed static baseline, while also lowering average dialog length.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A sample OAL interaction. Perceptual predicates are marked in bold.</figDesc><graphic url="image-1.png" coords="4,307.28,62.81,226.78,318.91" type="bitmap" /></figure>

			<note place="foot" n="2"> The regions in the dataset are divided into separate pools from which the active training and active test sets are sampled (described as classifier-training and classifier-test sets in section 6.2), to ensure that the agent needs to learn classifiers that generalize across objects. 3 F1 is estimated by cross-validation on the labels acquired for the predicate.</note>

			<note place="foot" n="4"> The equation for this distribution with some further discussion on its design is included in the supplementary material.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is supported by an NSF NRI grant <ref type="bibr">(IIS1637736)</ref>. A portion of this work has taken place in the Learning Agents Research Group (LARG) at UT Austin. LARG research is supported in part by NSF (CNS-1305287, IIS-1637736, IIS-1651089, IIS-1724157), TxDOT, Intel, Raytheon, and Lockheed Martin. Peter Stone serves on the Board of Directors of Cogitai, Inc. The terms of this arrangement have been reviewed and ap-proved by the University of Texas at Austin in ac-cordance with its policy on objectivity in research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning algorithms for active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, Australia. PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="301" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On active learning in multilabel classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Brinker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From Data and Information Analysis to Knowledge Engineering</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="206" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Designing interactions for robot active learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Cakmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Crystal</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">L</forename><surname>Thomaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Autonomous Mental Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="108" to="118" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satwik</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khushi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deshraj</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="326" to="335" />
		</imprint>
	</monogr>
	<note>Visual dialog</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Guesswhat?! visual object discovery through multi-modal dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Harm De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Pietquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning how to active learn: A deep reinforcement learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. ACL</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing. ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Open-vocabulary object retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Rodner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Toward interactive grounded language acqusition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grant</forename><surname>Strimel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems IX. Robotics: Science and Systems Foundation</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Visual genome: Connecting language and vision using crowdsourced dense image annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Kravitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="73" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Active learning for teaching a robot grounded relational symbols</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Kulick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Toussaint</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Third International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1451" to="1457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A sequential algorithm for training text classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval SIGIR &apos;94</title>
		<meeting>the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval SIGIR &apos;94<address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-label SVM active learning for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xachan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ternational Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2207" to="2210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to classify texts using positive and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Joint Conference on Artificial Intelligence, IJCAI&apos;03</title>
		<meeting>the 18th International Joint Conference on Artificial Intelligence, IJCAI&apos;03<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="587" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Active learning with multi-label svm classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Third International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1479" to="1485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Partially supervised classification of text documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee</forename><forename type="middle">Sun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoli</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth International Conference on Machine Learning, ICML &apos;02</title>
		<meeting>the Nineteenth International Conference on Machine Learning, ICML &apos;02<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="387" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mapping instructions and visual observations to actions with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipendra</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. ACL</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing. ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Acquiring grounded representations of words with situated interactive instruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiwali</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Mininger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">E</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cognitive Systems</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Integrated learning of dialog strategies and semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Padmakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2017)</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2017)<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="547" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Grounding the meaning of words through vision and interactive gameplay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><surname>Parde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Hair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michalis</forename><surname>Papakostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Tsiakas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Dagioglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vangelis</forename><surname>Karkaletsis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodney</forename><forename type="middle">D</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 24th International Joint Conference on Artificial Intelligence<address><addrLine>Buenos Aires, Argentina</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1895" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sampleefficient batch reinforcement learning for dialogue management optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Olivier Pietquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Senthilkumar</forename><surname>Geist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé Frezza-Buet</forename><surname>Chandramohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Two-dimensional multilabel active learning with an efficient online adaptation model for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Jiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1880" to="1897" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Toward optimal active learning through sampling estimation of error reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML &apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML &apos;01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="441" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ImageNet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Active learning literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page">11</biblScope>
			<pubPlace>Madison</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An analysis of active learning strategies for sequence labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language ProcessingEMNLP&apos;08. ACL</title>
		<meeting>the Conference on Empirical Methods in Natural Language ProcessingEMNLP&apos;08. ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Query by committee</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Opper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Annual Workshop on Computational Learning Theory, COLT &apos;92</title>
		<meeting>the Fifth Annual Workshop on Computational Learning Theory, COLT &apos;92<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="287" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evidencebased uncertainty sampling for active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manali</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Bilgic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="164" to="202" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Active learning for multi-label image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eoin</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pádraig</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Irish Conference on Artificial Intelligence and Cognitive Science</title>
		<meeting>the 19th Irish Conference on Artificial Intelligence and Cognitive Science</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Opportunistic active learning for grounding natural language descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Padmakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jivko</forename><surname>Sinapov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="67" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning multi-modal grounded linguistic semantics by playing &quot;I spy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jivko</forename><surname>Sinapov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Svetlik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the 25th International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3477" to="3483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Active learning for natural language parsing and information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><forename type="middle">A</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Elaine</forename><surname>Califf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth International Conference on Machine Learning (ICML-99)</title>
		<meeting>the Sixteenth International Conference on Machine Learning (ICML-99)<address><addrLine>Bled, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="406" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Active learning for sparse bayesian multilabel classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Vasisht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Damianou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manik</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Kapoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining-KDD&apos;14</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining-KDD&apos;14</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="472" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Eye spy: Improving vision through dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Jurafsky</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="175" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Semantically conditioned LSTM-based natural language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihao</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. ACL</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing. ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reinforcement Learning</title>
		<meeting><address><addrLine>US</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Active one-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Woodward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.06559</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Effective multi-label active learning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Tao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengjiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining-KDD&apos;09</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining-KDD&apos;09</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning how to learn: An adaptive dialogue agent for incrementally learning visually grounded word meanings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Eshghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Language Grounding for Robotics. ACL</title>
		<meeting>the First Workshop on Language Grounding for Robotics. ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
