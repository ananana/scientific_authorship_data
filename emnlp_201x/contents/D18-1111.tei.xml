<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Retrieval-Based Neural Code Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirley</forename><surname>Anugrah</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hayati</forename><surname>Raphael</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Pravalika</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avvaru</forename><surname>Pengcheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><forename type="middle">Anthony</forename><surname>Tomasic</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Retrieval-Based Neural Code Generation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="925" to="930"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>925</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In models to generate program source code from natural language, representing this code in a tree structure has been a common approach. However, existing methods often fail to generate complex code correctly due to a lack of ability to memorize large and complex structures. We introduce RECODE, a method based on subtree retrieval that makes it possible to explicitly reference existing code examples within a neural code generation model. First, we retrieve sentences that are similar to input sentences using a dynamic-programming-based sentence similarity scoring method. Next, we extract n-grams of action sequences that build the associated abstract syntax tree. Finally, we increase the probability of actions that cause the retrieved n-gram action subtree to be in the predicted code. We show that our approach improves the performance on two code generation tasks by up to +2.6 BLEU. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural language to code generation, a subtask of semantic parsing, is the problem of converting natural language (NL) descriptions to code <ref type="bibr" target="#b13">(Ling et al., 2016;</ref><ref type="bibr" target="#b19">Yin and Neubig, 2017;</ref><ref type="bibr" target="#b16">Rabinovich et al., 2017)</ref>. This task is challenging because it has a well-defined structured output and the in- put structure and output structure are in different forms.</p><p>A number of neural network approaches have been proposed to solve this task. Sequential ap- proaches ( <ref type="bibr" target="#b13">Ling et al., 2016;</ref><ref type="bibr" target="#b9">Jia and Liang, 2016;</ref><ref type="bibr" target="#b14">Locascio et al., 2016</ref>) convert the target code into a sequence of symbols and apply a sequence-to- sequence model, but this approach does not en- sure that the output will be syntactically correct. Tree-based approaches <ref type="bibr" target="#b19">(Yin and Neubig, 2017;</ref><ref type="bibr" target="#b16">Rabinovich et al., 2017</ref>) represent code as Ab- stract Syntax Trees (ASTs), which has proven ef- fective in improving accuracy as it enforces the well-formedness of the output code. However, representing code as a tree is not a trivial task, as the number of nodes in the tree often greatly ex- ceeds the length of the NL description. As a re- sult, tree-based approaches are often incapable of generating correct code for phrases in the corre- sponding NL description that have low frequency in the training data.</p><p>In machine translation (MT) problems <ref type="bibr" target="#b7">Gu et al., 2018;</ref><ref type="bibr" target="#b1">Amin Farajian et al., 2017;</ref><ref type="bibr" target="#b4">Li et al., 2018)</ref>, hybrid methods combin- ing retrieval of salient examples and neural models have proven successful in dealing with rare words. Following the intuition of these models, we hy- pothesize that our model can benefit from query- ing pairs of NL descriptions and AST structures from training data.</p><p>In this paper, we propose RECODE, and adap- tation of 's retrieval-based ap- proach neural MT method to the code genera- tion problem by expanding it to apply to gen- eration of tree structures. Our main contribu- tion is to introduce the use of retrieval methods in neural code generation models. We also pro- pose a dynamic programming-based sentence-to- sentence alignment method that can be applied to similar sentences to perform word substitution and enable retrieval of imperfect matches. These con- tributions allow us to improve on previous state- of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Syntactic Code Generation</head><p>Given an NL description q, our purpose is to gen- erate code (e.g. Python) represented as an AST a. In this work, we start with the syntactic code gen-eration model by <ref type="bibr" target="#b19">Yin and Neubig (2017)</ref>, which uses sequences of actions to generate the AST be- fore converting it to surface code. Formally, we want to find the best generated ASTâASTˆASTâ given by:</p><formula xml:id="formula_0">ˆ a = arg max a p(a|q) p(a|q) = T t=1 p(y t |y &lt;t , q)</formula><p>where y t is the action taken at time step t and y &lt;t = y 1 ...y t−1 and T is the number of total time steps of the whole action sequence resulting in AST a.</p><p>We have two types of actions to build an AST: APPLYRULE and GENTOKEN. APPLYRULE(r) expands the current node in the tree by applying production rule r from the abstract syntax gram- mar 2 to the current node. GENTOKEN(v) pop- ulates terminal nodes with the variable v which can be generated from vocabulary or by COPYing variable names or values from the NL description. The generation process follows a preorder traver- sal starting with the root node. <ref type="figure" target="#fig_3">Figure 1</ref> shows an action tree for the example code: the nodes cor- respond to actions per time step in the construction of the AST.</p><p>Interested readers can reference <ref type="bibr" target="#b19">Yin and Neubig (2017)</ref> for more detail of the neural model, which consists of a bidirectional LSTM <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997</ref>) encoder-decoder with action embeddings, context vectors, parent feeding, and a copy mechanism using pointer networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RECODE: Retrieval-Based Neural Code Generation</head><p>We propose RECODE, a method for retrieval- based neural syntactic code generation, using re- trieved action subtrees. Following 's method for neural machine translation, these retrieved subtrees act as templates that bias the generation of output code. Our pipeline at test time is as follows:</p><p>• retrieve from the training set NL descriptions that are most similar with our input sentence ( §3.1), • extract n-gram action subtrees from these retrieved sentences' corresponding target ASTs ( §3.2),</p><p>• alter the copying actions in these subtrees, by substituting words of the retrieved sentence with corresponding words in the input sen- tence ( §3.3), and • at every decoding step, increase the probabil- ity of actions that would lead to having these subtrees in the produced tree ( §3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Retrieval of Training Instances</head><p>For every retrieved NL description q m from train- ing set (or retrieved sentence for short), we com- pute its similarity with input q, using a sentence similarity formula ( <ref type="bibr" target="#b6">Gu et al., 2016;</ref>:</p><formula xml:id="formula_1">sim(q, q m ) = 1 − d(q, q m ) max(|q| ,|q m |)</formula><p>where d is the edit distance. We retrieve only the top M sentences according to this metric where M is a hyperparameter. These scores will later be used to increase action probabilities accordingly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Extracting N -gram Action Subtrees</head><p>In , they collect n-grams from the output side of the retrieved sentences and encourage the model to generate these n-grams. Word n-grams are obvious candidates when gen- erating a sequence of words as output, as in NMT. However, in syntax-based code generation, the generation target is ASTs with no obvious linear structure. To resolve this problem, we instead use retrieved pieces of n-gram subtrees from the tar- get code corresponding to the retrieved NL de- scriptions. Though we could select successive nodes in the AST as retrieved pieces, such as [assign; expr * (targets); expr] from <ref type="figure" target="#fig_3">Figure  1</ref>, we would miss important structural information from the rules that are used. Thus, we choose to exploit actions in the generation model rather than AST nodes themselves to be candidates for our re- trieved pieces.</p><p>In the action tree <ref type="figure" target="#fig_3">(Figure 1</ref>), we consid- ered only successive actions, such as sub- trees where each node has one or no chil- dren, to avoid overly rigid structures or com- binatorial explosion of the number of retrieved pieces the model has to consider.</p><p>For ex- ample, such an action subtree would be given by <ref type="bibr">[</ref> As the node in the action tree holds structural information about its children, we set the subtrees   to have a fixed depth, linear in the size of the tree. These can be considered "n-grams of ac- tions", emphasizing the comparison with machine translation which uses n-grams of words. n is a hyperparameter to be tuned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Word Substitution in Copy Actions</head><p>Using the retrieved subtree without modification is problematic if it contains at least one node cor- responding to a COPY action because copied to- kens from the retrieved sentence may be different from those in the input. <ref type="figure" target="#fig_3">Figure 1</ref> shows an ex- ample when the input and retrieved sentence have four common words, but the object names are dif- ferent. The extracted action n-gram would contain the rule that copies the second word ("lst") of the retrieved sentence while we want to copy the first word ("params") from the input. By computing word-based edit distance be- tween the input description and the retrieved sen- tence, we implement a one-to-one sentence align- ment method that infers correspondences between uncommon words. For unaligned words, we alter all COPY rules in the extracted n-grams to copy to- kens by their aligned counterpart, such as replace "params" with "lst", and delete the n-gram sub- tree, as it is not likely to be relevant in the pre- dicted tree. Thus, in the example in <ref type="figure" target="#fig_3">Figure 1</ref>, the GENTOKEN(LST) action in t 5 will not be exe- cuted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Retrieval-Guided Code Generation</head><p>N -gram subtrees from all retrieved sentences are assigned a score, based on the best similarity score  <ref type="bibr" target="#b19">Yin and Neubig (2017)</ref> of all instances where they appeared. We normal- ize the scores for each input sentence by subtract- ing the average over the training dataset.</p><p>At decoding time, incorporate these retrieval- derived scores into beam search: for a given time step, all actions that would result in one of the retrieved n-grams u to be in the prediction tree has its log probability log(p(y t | y t−1 1 )) increased by λ * score(u) where λ is a hyperparameter, and score(u) is the maximal sim(q, q m ) from which u is extracted. The probability distribution is then renormalized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Datasets and Evaluation Metrics</head><p>We evaluate RECODE with the Hearthstone (HS) ( <ref type="bibr" target="#b13">Ling et al., 2016</ref>) and Django ( <ref type="bibr" target="#b15">Oda et al., 2015</ref>) datasets, as preprocessed by <ref type="bibr" target="#b19">Yin and Neubig (2017)</ref>. HS consists of Python classes that imple- ment Hearthstone card descriptions while Django contains pairs of Python source code and English pseudo-code from Django web framework. <ref type="table">Table  1</ref> summarizes dataset statistics.</p><p>For evaluation metrics, we use accuracy of ex- act match and the BLEU score following <ref type="bibr" target="#b19">Yin and Neubig (2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>For the neural code generation model, we use the settings explained in <ref type="bibr" target="#b19">Yin and Neubig (2017)</ref>. For the retrieval method, we tuned hyperparameters and achieved best result when we set n max = 4 and λ = 3 for both datasets <ref type="bibr">3</ref> . For HS, we set M = 3 and M = 10 for Django.</p><p>We compare our model with <ref type="bibr" target="#b19">Yin and Neubig (2017)</ref>'s model that we call YN17 for brevity, and a sequence-to-sequence (SEQ2SEQ) model that we implemented. SEQ2SEQ is an attention- enabled encoder-decoder model ( <ref type="bibr" target="#b2">Bahdanau et al., 2015)</ref>. The encoder is a bidirectional LSTM and the decoder is an LSTM. <ref type="table" target="#tab_3">Table 2</ref> shows that RECODE outperforms the base- lines in both BLEU and accuracy, providing ev-idence for the effectiveness of incorporating re- trieval methods into tree-based approaches.  We ran statistical significance tests for RECODE and YN17, using bootstrap resampling with N = 10,000. For the BLEU scores of both datasets, p &lt; 0.001. For the exact match accuracy, p &lt; 0.001 for Django dataset, but for Hearthstone, p &gt; 0.3, showing that the retrieval-based model is on par with YN17. It is worth noting, though, that HS consists of long and complex code, and that gener- ating exact matches is very difficult, making exact match accuracy a less reliable metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HS</head><p>We also compare RECODE with <ref type="bibr" target="#b16">Rabinovich et al. (2017)</ref>'s Abstract Syntax Networks with supervision (ASN+SUPATT) which is the state-of-the-art system for HS. RECODE ex- ceeds ASN without extra supervision though ASN+SUPATT has a slightly better result. How- ever, ASN+SUPATT is trained with supervised attention extracted through heuristic exact word matches while our attention is unsupervised.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Discussion and Analysis</head><p>From our observation and as mentioned in <ref type="bibr" target="#b16">Rabinovich et al. (2017)</ref>, HS contains classes with sim- ilar structure, so the code generation task could be simply matching the tree structure and filling the terminal tokens with correct variables and val- ues. However, when the code consists of complex logic, partial implementation errors occur, lead- ing to low exact match accuracy <ref type="bibr" target="#b19">(Yin and Neubig, 2017)</ref>. Analyzing our result, we find this intuition to be true not only for HS but also for Django.</p><p>Examining the generated output for the Django dataset in <ref type="table">Table 3</ref>, we can see that in the first ex- ample, our retrieval model can successfully gen- erate the correct code when YN17 fails. This difference suggests that our retrieval model ben- efits from the action subtrees from the retrieved sentences. In the second example, although our generated code does not perfectly match the refer- ence code, it has a higher BLEU score compared Example 1 "if offset is lesser than integer 0, sign is set to '-', otherwise sign is '+' " Input sign = offset &lt; 0 or '-' YN17 sign = '-' if offset &lt; 0 else '+' RECODE sign = '-' if offset &lt; 0 else '+' Gold Example 2 "evaluate the function timesince with d, now and reversed set Input to boolean true as arguments, return the result." return reversed(d, reversed=now) YN17 return timesince(d, now, reversed=now) RECODE return timesince(d, now, reversed=True) Gold Example 3 "return an instance of SafeText , Input created with an argument s converted into a string ." return SafeText(bool(s)) YN17 return SafeText(s) RECODE return SafeString(str(s)) Gold <ref type="table">Table 3</ref>: Django examples on correct code and predicted code with retrieval (RECODE) and without retrieval (YN17).  to the output of YN17 because our model can predict part of the code (timesince(d, now, reversed)) correctly. The third example shows where our method fails to apply the correct action as it cannot cast s to str type while YN17 can at least cast s into a type (bool). Another common type of error that we found RECODE's generated outputs is incorrect variable copying, similarly to what is discussed in <ref type="bibr" target="#b19">Yin and Neubig (2017)</ref> and <ref type="bibr" target="#b16">Rabinovich et al. (2017)</ref>. <ref type="table" target="#tab_4">Table 4</ref> presents a result on the HS dataset <ref type="bibr">4</ref> . We can see that our retrieval model can handle com- plex code more effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NAME_BEGIN Earth Elemental NAME_END ATK_BEGIN 7 Input</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Several works on code generation focus on do- main specific languages ( <ref type="bibr" target="#b18">Raza et al., 2015;</ref><ref type="bibr" target="#b10">Kushman and Barzilay, 2013)</ref>. For general purpose code generation, some data-driven work has been done for predicting input parsers ( <ref type="bibr" target="#b11">Lei et al., 2013)</ref> or a set of relevant methods <ref type="bibr" target="#b17">(Raghothaman et al., 2016)</ref>. Some attempts using neural networks have used sequence-to-sequence models ( <ref type="bibr" target="#b13">Ling et al., 2016)</ref> or tree-based architectures <ref type="bibr" target="#b3">(Dong and Lapata, 2016;</ref><ref type="bibr" target="#b0">Alvarez-Melis and Jaakkola, 2017)</ref>. <ref type="bibr" target="#b13">Ling et al. (2016)</ref>; <ref type="bibr" target="#b9">Jia and Liang (2016)</ref>; <ref type="bibr" target="#b14">Locascio et al. (2016)</ref> treat semantic parsing as a se- quence generation task by linearizing trees. The closest work to ours are <ref type="bibr" target="#b19">Yin and Neubig (2017)</ref> and <ref type="bibr" target="#b16">Rabinovich et al. (2017)</ref> which represent code as an AST. Another close work is <ref type="bibr" target="#b4">Dong and Lapata (2018)</ref>, which uses a two-staged structure-aware neural architecture. They initially generate a low- level sketch and then fill in the missing informa- tion using the NL and the sketch.</p><p>Recent works on retrieval-guided neural ma- chine translation have been presented by <ref type="bibr" target="#b7">Gu et al. (2018);</ref><ref type="bibr" target="#b1">Amin Farajian et al. (2017)</ref>; <ref type="bibr" target="#b4">Li et al. (2018)</ref>; . <ref type="bibr" target="#b7">Gu et al. (2018)</ref> use the retrieved sentence pairs as extra inputs to the NMT model.  employ a sim- pler and faster retrieval method to guide neural MT where translation pieces are n-grams from re- trieved target sentences. We modify 's method from textual n-grams to n-grams over subtrees to exploit the code structural simi- larity, and propose methods to deal with complex statements and rare words.</p><p>In addition, some previous works have used subtrees in structured prediction tasks. For ex- ample, <ref type="bibr" target="#b5">Galley et al. (2006)</ref> used them in syntax- based translation models. In <ref type="bibr" target="#b5">Galley et al. (2006)</ref>, subtrees of the input sentence's parse tree are as- sociated with corresponding words in the output sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We proposed an action subtree retrieval method at test time on top of an AST-driven neural model for generating general-purpose code. The predicted surface code is syntactically correct, and the re- trieval component improves the performance of a previously state-of-the-art model. Our successful result suggests that our idea of retrieval-based gen- eration can be potentially applied to other tree- structured prediction tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>assign → expr * (targets), expr(value) ; expr(value) → List; List → epsilon].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The action sequence used to generate AST for the target code given the input example. Dashed nodes represent terminals. Each node is labeled with time steps. APPLYRULE action is represented as rule in this figure. Blue dotted boxes denote 3-gram action subtrees. Italic words are unedited words. Red bold words are different object names.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>ATK_END DEF_BEGIN 8 DEF_END COST_BEGIN 5 COST_END DUR_BEGIN -1 DUR_END TYPE_BEGIN Minion TYPE_END PLAYER_CLS_BEGIN Shaman PLAYER_CLS_END RACE_BEGIN NIL RACE_END RARITY_BEGIN Epic RARITY_END DESC_BEGIN Taunt . Overload : ( 3 ) DESC_END. class EarthElemental (MinionCard) : YN17 def __init__ (self) : super ( ).__init__ ("Earth Elemental", 5, CHARACTER_CLASS.SHAMAN, CARD_RARITY.EPIC, buffs=[Buff(ManaChange(Count (MinionSelector(None, BothPlayer())), -1))]) def create_minion (self, player) : return Minion(7, 8, taunt=True) class EarthElemental (MinionCard) : RECODE def __init__ (self) : super ( ).__init__ ("Earth Elemental", 5, CHARACTER_CLASS.SHAMAN, CARD_RARITY.EPIC, overload=3) def create_minion (self, player) : return Minion(7, 8, taunt=True) class EarthElemental (MinionCard) : Gold def __init__ (self) : super ( ).__init__ ("Earth Elemental", 5, CHARACTER_CLASS.SHAMAN, CARD_RARITY.EPIC, overload=1) def create_minion (self, player) : return Minion(7, 8, taunt=True)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>root ­&gt; assign assign ­&gt; expr*(targets), expr(value) expr*(targets) ­&gt; expr expr ­&gt; Name</head><label></label><figDesc></figDesc><table>0 

t 1 

t 2 

t 3 

t 4 

t 5 

t 6 

Name ­&gt; str 

GENTOKEN[params] 

GENTOKEN[/n] 

expr(value) ­&gt; List 

List ­&gt; epsilon 

Input       :  params is an empty list 
Target Code      : params = [ ] 

Action Flow 

Parent Feeding 

Apply Rule 

Generate Token 

Generate Token 
with Copy 

t 7 

t 8 

t9 

t i 

t i 

t i 

Retrieved: List lst is an empty list 
Retrieved Code: lst = [ ] 

GENTOKEN[lst] 

GENTOKEN[/n] 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>number of nodes of AST 136.6 17.2 Table 1: Dataset statistics as reported</head><label></label><figDesc></figDesc><table>Dataset 
HS 
Django 
Train 
533 
16,000 
Dev 
66 
1,000 
Test 
66 
1,805 
Avg. tokens in description 
39.1 
14.3 
Avg. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results compared to baselines. YN17 result is taken 

from Yin and Neubig (2017). ASN result is taken from Rabi-
novich et al. (2017) 
. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>HS examples on correct code and predicted code 

with retrieval (RECODE) and without retrieval (YN17). 

</table></figure>

			<note place="foot" n="2"> https://docs.python.org/2/library/ ast.html</note>

			<note place="foot" n="3"> n-gram subtrees are collected up to nmax-gram</note>

			<note place="foot" n="4"> More example of HS code is provided in the supplementary material.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are grateful to Lucile Callebert for insight-ful discussions, Aldrian Obaja Muis for helpful input on early version writing, and anonymous reviewers for useful feedback. This material is based upon work supported by the National Sci-ence Foundation under Grant No. 1815287.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tree structured decoding with doubly recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Alvarez-Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multi-Domain Neural Machine Translation through Unsupervised Adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>M Amin Farajian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fondazione Bruno</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Machine Translation (WMT)</title>
		<meeting>the Second Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<publisher>Research Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="127" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Language to logical form with neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="33" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Coarse-to-fine decoding for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="731" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Scalable inference and training of context-rich syntactic translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Graehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Deneefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Thayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="961" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incorporating copying mechanism in sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">O K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1631" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Search engine guided neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">O K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ThirtySecond AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the ThirtySecond AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Data recombination for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="12" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using semantic unification to generate regular expressions from natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="826" to="836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">From natural language specifications to program input parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">C</forename><surname>Rinard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1294" to="1303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">One Sentence One Model for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Latent predictor networks for code generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočiský</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fumin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="599" to="609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural generation of regular expressions from natural language with minimal domain knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Locascio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><forename type="middle">De</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1918" to="1923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to generate pseudo-code from source code using statistical machine translation (t)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Fudaba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideaki</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Toda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)</title>
		<meeting>the 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="574" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Abstract syntax networks for code generation and semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1139" to="1149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Swim: Synthesizing what i mean: Code search and idiomatic snippet synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mukund</forename><surname>Raghothaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youssef</forename><surname>Hamadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Software Engineering (ICSE)</title>
		<meeting>the 38th International Conference on Software Engineering (ICSE)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="357" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Compositional program synthesis from natural language and examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Raza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natasa</forename><surname>Milicfrayling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Artificial Intelligence</title>
		<meeting>the 24th International Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="792" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A syntactic neural model for general-purpose code generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 55th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="440" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Guiding neural machine translation with retrieved translation pieces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
