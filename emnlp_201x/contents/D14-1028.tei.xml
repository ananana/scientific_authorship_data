<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Two Improvements to Left-to-Right Decoding for Hierarchical Phrase-based Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maryam</forename><surname>Siahbani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University Burnaby BC</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Sarkar</surname></persName>
							<email>msiahban,anoop@cs.sfu.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University Burnaby BC</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Two Improvements to Left-to-Right Decoding for Hierarchical Phrase-based Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="221" to="226"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Left-to-right (LR) decoding (Watanabe et al., 2006) is promising decoding algorithm for hierarchical phrase-based translation (Hiero) that visits input spans in arbitrary order producing the output translation in left to right order. This leads to far fewer language model calls, but while LR decoding is more efficient than CKY decoding, it is unable to capture some hierarchical phrase alignments reachable using CKY decoding and suffers from lower translation quality as a result. This paper introduces two improvements to LR decoding that make it comparable in translation quality to CKY-based Hiero.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Hierarchical phrase-based translation (Hi- ero) <ref type="bibr" target="#b0">(Chiang, 2007</ref>) uses a lexicalized syn- chronous context-free grammar (SCFG) extracted from word and phrase alignments of a bitext. De- coding for Hiero is typically done with CKY-style decoding with time complexity O(n 3 ) for source input with n words. Computing the language model score for each hypothesis within CKY de- coding requires two histories, the left and the right edge of each span, due to the fact that the target side is built inside-out from sub-spans <ref type="bibr" target="#b6">Heafield et al., 2013)</ref>.</p><p>LR-decoding algorithms exist for phrase- based <ref type="bibr" target="#b12">(Koehn, 2004;</ref><ref type="bibr" target="#b4">Galley and Manning, 2010)</ref> and syntax-based ( <ref type="bibr" target="#b9">Huang and Mi, 2010;</ref><ref type="bibr" target="#b3">Feng et al., 2012</ref>) models and also for hierarchical phrase- based models ( <ref type="bibr" target="#b19">Watanabe et al., 2006;</ref><ref type="bibr" target="#b17">Siahbani et al., 2013)</ref>, which is our focus in this paper. <ref type="bibr" target="#b19">Watanabe et al. (2006)</ref> first proposed left-to- right (LR) decoding for Hiero (LR-Hiero hence- forth) which uses beam search and runs in O(n 2 b) in practice where n is the length of source sentence and b is the size of beam <ref type="bibr" target="#b9">(Huang and Mi, 2010)</ref>. To simplify target generation, SCFG rules are con- strained to be prefix-lexicalized on target side aka Griebach Normal Form (GNF). Throughout this paper we abuse the notation for simplicity and use the term GNF grammars for such SCFGs. This constraint drastically reduces the size of gram- mar for LR-Hiero in comparison to Hiero gram- mar ( <ref type="bibr" target="#b17">Siahbani et al., 2013)</ref>. However, the orig- inal LR-Hiero decoding algorithm does not per- form well in comparison to current state-of-the-art Hiero and phrase-based translation systems. <ref type="bibr" target="#b17">Siahbani et al. (2013)</ref> propose an augmented version of LR decoding to address some limitations in the original LR-Hiero algorithm in terms of transla- tion quality and time efficiency.</p><p>Although, LR-Hiero performs much faster than Hiero in decoding and obtains BLEU scores com- parable to phrase-based translation system on some language pairs, there is still a notable gap be- tween CKY-Hiero and LR-Hiero ( <ref type="bibr" target="#b17">Siahbani et al., 2013)</ref>. We show in this paper using instructive ex- amples that CKY-Hiero can capture some complex phrasal re-orderings that are observed in language pairs such as Chinese-English that LR-Hiero can- not (c.f. Sec.3).</p><p>We introduce two improvements to LR decod- ing of GNF grammars: (1) We add queue diversity to the cube pruning algorithm for LR-Hiero, and (2) We extend the LR-Hiero decoder to capture all the hierarchical phrasal alignments that are reach- able in CKY-Hiero (restricted to using GNF gram- mars). We evaluate our modifications on three language pairs and show that LR-Hiero can reach the translation scores comparable to CKY-Hiero in two language pairs, and reduce the gap between Hiero and LR-Hiero on the third one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">LR Decoding with Queue Diversity</head><p>LR-Hiero uses a constrained lexicalized SCFG which we call a GNF grammar: X → γ, ¯ b β where γ is a string of non-terminal and terminal symbols, ¯ b is a string of terminal symbols and β is a possibly empty sequence of non-terminals. This ensures that as each rule is used in a derivation, Algorithm 1: LR-Hiero Decoding 1: Input sentence: f = f0f1 . . . fn 2: F = FutureCost(f ) (Precompute future cost 1 for spans) 3: S0 = {} (Create empty initial stack) 4: h0 = (s, [ <ref type="bibr">[0, n]</ref>], ∅, F <ref type="bibr">[0,n]</ref> ) (Initial hypothesis 4-tuple) 5: Add h0 to S0</p><p>(Push initial hyp into first Stack) 6: for i = 1, . . . , n do 7: cubeList = {} (MRL is max rule length) 8:</p><p>for p = max(i − MRL, 0), . . . , i − 1 do 9: {G} = Grouped(Sp) (based on the first uncovered span) 10:</p><p>for g ∈ {G} do 11:</p><p>[u, v] = gspan 12:</p><formula xml:id="formula_0">R = GetSpanRules([u, v]) 13:</formula><p>for Rs ∈ R do 14: cube = [g hyps , Rs] 15:</p><p>Add cube to cubeList 16: Si = Merge(cubeList, F) (Create stack Si and add new hypotheses to it, see <ref type="figure">Figure 1</ref>) 17: return arg max <ref type="bibr">(Sn)</ref> 18: Merge(CubeList, F) 19: heapQ = {} 20:</p><p>for each (H, R) in cubeList do 21:</p><formula xml:id="formula_1">hypList = getBestHypotheses((H, R), F, d) (d best hypotheses of each cube) 22:</formula><p>for each h in hypList do 23:</p><formula xml:id="formula_2">push(heapQ, (h c , h , [H, R]) (Push new hyp in queue) 24: hypList = {} 25:</formula><p>while |heapQ| &gt; 0 and |hypList| &lt; K do 26: return hypList the target string is generated from left to right. The rules are obtained from a word and phrase aligned bitext using the rule extraction algorithm in ( <ref type="bibr" target="#b19">Watanabe et al., 2006</ref>). LR-Hiero decoding uses a top-down depth-first search, which strictly grows the hypotheses in tar- get surface ordering. Search on the source side follows an Earley-style search <ref type="bibr" target="#b2">(Earley, 1970)</ref>, the dot jumps around on the source side of the rules based on the order of nonterminals on the target side. This search is integrated with beam search or cube pruning to find the k-best translations.</p><formula xml:id="formula_3">(h c , h , [H, R]) = pop(heapQ) (</formula><p>Algorithm 1 shows the pseudocode for LR- Hiero decoding with cube pruning (Chiang, 2007) (CP). LR-Hiero with CP was introduced in <ref type="bibr" target="#b17">(Siahbani et al., 2013)</ref>. In this pseudocode, we have in- troduced the notion of queue diversity (explained below). However to understand our change we need to understand the algorithm in more detail. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S i</head><p>Figure 1: Cubes (grids) are fed to a priority queue (trian- gle) and generated hypotheses are iteratively popped from the queue and added to stack Si. Lower scores are better. Scores of rules and hypotheses appear on the top and left side of the grids respectively. Shaded entries are hypotheses in the queue and black ones are popped from the queue and added to Si.</p><p>Each source side non-terminal is instantiated with the legal spans given the input source string, e.g. if there is a Hiero rule aX 1 , a X 1 and if a only occurs at position 3 in the input then this rule can be applied to span <ref type="bibr">[3, i]</ref> for all i, 4 &lt; i ≤ n for in- put of length n and source side X 1 is instantiated to span <ref type="bibr">[4, i]</ref>. A worked out example of how the decoder works is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. Each partial hypothesis h is a 4-tuple (h t , h s , h cov , h c ): con- sisting of a translation prefix h t , a (LIFO-ordered) list h s of uncovered spans, source words coverage set h cov and the hypothesis cost h c . The initial hy- pothesis is a null string with just a sentence-initial marker s and the list h s containing a span of the whole sentence, <ref type="bibr">[0, n]</ref>. The hypotheses are stored in stacks S 0 , . . . , S n , where S p contains hypothe- ses covering p source words just like in stack de- coding for phrase-based SMT ( <ref type="bibr" target="#b10">Koehn et al., 2003</ref>).</p><p>To fill stack S i we consider hypotheses in each stack S p 2 , which are first partitioned into a set of groups {G}, based on their first uncovered span (line 9). Each group g is a 2-tuple (g span , g hyps ), where g hyps is a list of hypotheses which share the same first uncovered span g span . Rules matching the span g span are obtained from routine GetSpan- Rules. Each g hyps and possible R s create a cube which is added to cubeList.</p><p>The Merge routine gets the best hypotheses from all cubes (see <ref type="figure">Fig.1</ref>). Hypotheses (rows) and columns (rules) are sorted based on their scores. GetBestHypotheses((H, R), F, d) uses current hypothesis H and rule R to produce new hypothe- ses. The first best hypothesis, h along with its score h c and corresponding cube (H, R) is placed in a priority queue heapQ (triangle in <ref type="figure">Figure 1</ref> and line 23 in Algorithm 1). Iteratively the K best </p><formula xml:id="formula_4">G 1)T aiguo shi X1/T hailand X1 s Thailand [2,15] G 2)yao X1/wants X1 G 3)liyong X1/to utilize X1</formula><p>4)zhe bi qian X1/this money X1 5)X1zhuru geng duo X2/to inject more X2X1</p><formula xml:id="formula_5">6)liudong X1/circulating X1 G 7)zijin X1/capital X1 8)./.</formula><p>9)xiang jingji/to the economy sThailand wants <ref type="bibr">[3,</ref><ref type="bibr">15]</ref> sThailand wants to utilize <ref type="bibr">[4,</ref><ref type="bibr">15]</ref> sThailand wants to utilize this money <ref type="bibr">[7,</ref><ref type="bibr">15]</ref> sThailand wants to utilize this money to inject more <ref type="bibr">[12,</ref><ref type="bibr">15]</ref> <ref type="bibr">[7,</ref><ref type="bibr">9]</ref> sThailand wants to utilize this money to inject more circulating <ref type="bibr">[13,</ref><ref type="bibr">15]</ref> <ref type="bibr">[7,</ref><ref type="bibr">9]</ref> sThailand wants to utilize this money to inject more circulating capital <ref type="bibr">[14,</ref><ref type="bibr">15]</ref> <ref type="bibr">[7,</ref><ref type="bibr">9]</ref> sThailand wants to utilize this money to inject more circulating capital . <ref type="bibr">[7,</ref><ref type="bibr">9]</ref> sThailand wants to utilize this money to inject more circulating capital . to the economy/s  (b) <ref type="figure">Figure 3</ref>: Two Chinese-English sentence pairs from devset data in experiments. (a) Correct rule cannot be matched to <ref type="bibr">[6,</ref><ref type="bibr">18]</ref>, our modifications match the rule to the first subspan <ref type="bibr">[6,</ref><ref type="bibr">9]</ref> (b) LR-Hiero detects a wrong span for X2 <ref type="bibr">[12,</ref><ref type="bibr">15]</ref>, we modify the rule matching match X2 to all subspans <ref type="bibr">[12,</ref><ref type="bibr">13]</ref>, <ref type="bibr">[12,</ref><ref type="bibr">14]</ref> and <ref type="bibr">[12,</ref><ref type="bibr">15]</ref>, corresponding to 3 hypotheses.</p><p>hypotheses in the queue are popped (line 26) and for each hypothesis its neighbours in the cube are added to the priority queue (line 27). Decoding finishes when stack S n has been filled.</p><p>The language model (LM) score violates the hypotheses generation assumption of CP and can cause search errors. In <ref type="figure">Figure 1</ref>, the topmost and leftmost entry of the right cube has a score worse than many hypotheses in the left cube due to the LM score. This means the right cube has hypotheses that are ignored. This type of search error hurts LR-Hiero more than CKY- Hiero, due to the fact that hypotheses scores in LR-Hiero rely on a future cost, while CKY-Hiero uses the inside score for each hypothesis. To solve this issue for LR-Hiero we introduce the no- tion of queue diversity which is the parameter d in GetBestHypotheses((H, R), F, d). This pa- rameter guarantees that each cube will produce at least d candidate hypotheses for the priority queue. d=1 in standard cube pruning for LR-Hiero ( <ref type="bibr" target="#b17">Siahbani et al., 2013</ref>). We apply the idea of diver- sity at queue level, before generating K best hy- pothesis, such that the GetBestHypotheses rou- tine generates d best hypotheses from each cube and all these hypotheses are pushed to the prior- ity queue (line 22-23). We fill each stack differ- ently from CKY-Hiero and so queue diversity is different from lazy cube pruning <ref type="bibr" target="#b14">(Pust and Knight, 2009)</ref> or cube growing <ref type="bibr" target="#b8">(Huang and Chiang, 2007;</ref><ref type="bibr" target="#b18">Vilar and Ney, 2009;</ref><ref type="bibr" target="#b20">Xu and Koehn, 2012</ref>).  <ref type="figure" target="#fig_1">Figure 2</ref> where rule #5 is matched to span <ref type="bibr">[7,</ref><ref type="bibr">15]</ref>. Dur- ing decoding LR-Hiero maintains a stack (last- in-first-out) of yet-to-be-covered spans and tries to translate the first uncovered span (span <ref type="bibr">[7,</ref><ref type="bibr">15]</ref> in Step 5). LR-Hiero should match rule #5 to span <ref type="bibr">[7,</ref><ref type="bibr">15]</ref>, therefore X 2 is forced to match span <ref type="bibr">[12,</ref><ref type="bibr">15]</ref> which leads to the translation of span <ref type="bibr">[7,</ref><ref type="bibr">9]</ref> (corresponding to X 1 ) being reordered around it</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Capturing Missing Alignments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Train/Dev/Test Cs-En Europarl(v7) + CzEng(v0.9); News commentary(nc) 2008&amp;2009; nc 2011 7.95M/3000/3003</head><p>De-En Europarl(v7); WMT2006; WMT2006 1.5M/2000/2000 Zh-En HK + GALE phase-1; MTC part 1&amp;3;</p><p>MTC part 4 2.3M/1928/919  causing the incorrect translation in Step 9. If we use the same set of rules for translation in Hi- ero (CKY-based decoder), the decoder is able to generate the correct translation for span <ref type="bibr">[7,</ref><ref type="bibr">14]</ref> (it works bottom-up and generate best translation for each source span). Then it combines translation of <ref type="bibr">[7,</ref><ref type="bibr">14]</ref> with translation of spans <ref type="bibr">[0,</ref><ref type="bibr">7]</ref> and <ref type="bibr">[14,</ref><ref type="bibr">15]</ref> using glue rules (monotonic combination).</p><p>In <ref type="figure">Figure 3</ref>(a) monotonic translations after span <ref type="bibr">[6,</ref><ref type="bibr">9]</ref> are out of reach of the LR-Hiero decoder which has to use the non-terminals to support the reordering within span <ref type="bibr">[6,</ref><ref type="bibr">9]</ref>. In this exam- ple the first few phrases are translated monoton- ically, then for span <ref type="bibr">[6,</ref><ref type="bibr">18]</ref> we have to apply rule muqian X 1 wending, is now in stable X 1 to ob- tain the correct translation. But this rule cannot be matched to span <ref type="bibr">[6,</ref><ref type="bibr">18]</ref> and the decoder fails to generate the correct translation. While CKY- Hiero can apply this rule to span <ref type="bibr">[6,</ref><ref type="bibr">9]</ref>, generate correct translation for this span and monotonically combine it with translation of other spans ( <ref type="bibr">[0,</ref><ref type="bibr">6]</ref>, <ref type="bibr">[9,</ref><ref type="bibr">18]</ref>).</p><p>In both these cases, CKY-Hiero has no diffi- culty in reaching the target sentence with the same GNF rules. The fact that we have to process spans as they appear in the stack in LR-Hiero means that we cannot combine arbitrary adjacent spans to deal with such cases. So purely bottom-up de- coders such as CKY-Hiero can capture the align- ments in <ref type="figure">Figure 3</ref> but LR-Hiero cannot.</p><p>We extend the LR-Hiero decoder to handle such cases by making the GNF grammar more expres- sive. Rules are partitioned to three types based on the right boundary in the source and target side. The rhs after the ⇒ shows the new rules we create within the decoder using a new non-terminal X r to match the right boundary.</p><formula xml:id="formula_6">(a) γ¯ a, ¯ bβ ⇒ γ¯ aX r , ¯ bβX r (b) γX n , ¯ bβX n ⇒ γX n X r , ¯ bβX n X r (c) γX n , ¯ bβX m ⇒ γX n X r , ¯ bβX m X r (1)</formula><p>where γ is a string of terminals and non-terminals, ¯ a and ¯ b are terminal sequences of source and tar- get respectively, β is a possibly empty sequence of non-terminals and X n and X m are different non-terminals distinct from X r 3 . The extra non- terminal X r lets us add a new yet-to-be-covered span to the bottom of the stack at each rule appli- cation which lets us match any two adjacent spans just as in CKY-Hiero. This captures the missing alignments that could not be previously captured in the LR-Hiero decoder <ref type="bibr">4</ref> .</p><p>In <ref type="table" target="#tab_6">Table 4</ref> we translated devset sentences using forced decoding to show that our modifications to LR-Hiero in this section improves the alignment coverage when compared to CKY-Hiero.</p><p>We use a 5-gram LM trained on the Gigaword corpus and use <ref type="bibr">KenLM (Heafield, 2011</ref>). We tune weights by minimizing BLEU loss on the dev set through MERT <ref type="bibr" target="#b13">(Och, 2003)</ref> and report BLEU scores on the test set. Pop limit for Hiero and LR- Hiero+CP is 500 and beam size LR-Hiero is 500. Other extraction and decoder settings such as max- imum phrase length, etc. were identical across set- tings. To make the results comparable we use the same feature set for all baselines, Hiero as well (including new features proposed by <ref type="bibr" target="#b17">(Siahbani et al., 2013)</ref>).</p><p>We use 3 baselines: (i) our implementation of ( <ref type="bibr" target="#b19">Watanabe et al., 2006</ref>): LR-Hiero with beam search (LR-Hiero) and (ii) LR-Hiero with cube pruning ( <ref type="bibr" target="#b17">Siahbani et al., 2013)</ref>: (LR-Hiero+CP); and (iii) Kriya, an open-source implementation of Hiero in Python, which performs comparably to other open-source Hiero systems ( <ref type="bibr" target="#b16">Sankaran et al., 2012)</ref>. <ref type="table" target="#tab_5">Table 3</ref> shows model sizes for LR-Hiero (GNF) and Hiero (SCFG). Typical Hiero rule extraction excludes phrase-pairs with unaligned words on boundaries (loose phrases). We use similar rule extraction as Hiero, except that exclude non-GNF rules and include loose phrase-pairs as terminal rules. <ref type="table" target="#tab_4">Table 2a</ref> shows the translation quality of dif- ferent systems in terms of BLEU score. Row 3 is from ( <ref type="bibr" target="#b17">Siahbani et al., 2013)</ref>  <ref type="bibr">5</ref> . As we dis- cussed in Section 2, LR-Hiero+CP suffers from severe search errors on Zh-En (1.5 BLEU) but us- ing queue diversity (QD=15) we fill this gap. We use the same QD(=15) in next rows for Zh-en. For Cs-En and De-En we use regular cube prun- ing (QD=1), as it works as well as beam search (compare rows 4 and 2).</p><p>We measure the benefit of the new modified rules from Section 3: (ab): adding modifications for rules type (a) and (b); (abc): modification of all rules. We can see that for all language pairs (ab) constantly improves performance of LR- Hiero, significantly better than LR-Hiero+CP and LR-Hiero (p-value&lt;0.05) on Cs-En and Zh-En, evaluated by <ref type="bibr">MultEval (Clark et al., 2011</ref>). But modifying rule type (c) does not show any im- provement due to spurious ambiguity created by <ref type="bibr">5</ref> We report results on Cs-En and De-En in <ref type="bibr" target="#b17">(Siahbani et al., 2013</ref>). Row 4 is the same translation system as row 3 (LR-Hiero+CP). We achieve better results than our previous work <ref type="bibr" target="#b17">(Siahbani et al., 2013</ref>) (row 4 vs. row 3) due to bug corrections and adding loose phrases as terminal rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Cs-En De-En Zh-En Hiero 1,961.6 858.5 471.9 LR-Hiero 266.5 116.0 100.9  type (c) rules. <ref type="figure" target="#fig_1">Figure 2b</ref> shows the results in terms of average number of language model queries on a sample set of 50 sentences from test sets. All of the base- lines use the same wrapper to <ref type="bibr">KenLM (Heafield, 2011)</ref> to query the language model, and we have instrumented the wrapper to count the statistics. In ( <ref type="bibr" target="#b17">Siahbani et al., 2013)</ref> we discuss that LR-Hiero with beam search ( <ref type="bibr" target="#b19">Watanabe et al., 2006</ref>) does not perform at the same level of state-of-the-art Hi- ero (more LM calls and less translation quality). As we can see in this figure, adding new mod- ified rules slightly increases the number of lan- guage model queries on Cs-En and De-En so that LR-Hiero+CP still works 2 to 3 times faster than Hiero. On Zh-En, LR-Hiero+CP applies queue diversity (QD=15) which reduces search errors and improves translation quality but increases the number of hypothesis generation as well. LR- Hiero+CP with our modifications works substan- tially faster than LR-Hiero while obtain signifi- cantly better translation quality on Zh-En.</p><p>Comparing <ref type="table" target="#tab_4">Table 2a</ref> with <ref type="figure" target="#fig_1">Figure 2b</ref> we can see that overall our modifications to LR-Hiero decoder significantly improves the BLEU scores compared to previous LR decoders for Hiero. We obtain comparable results to CKY-Hiero for Cs-En and De-En and remarkably improve results on Zh-En, while at the same time making 2 to 3 times less LM calls on Cs-En and De-En compared to CKY- Hiero.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The process of translating the Chinese sentence in Figure 3(b) in LR-Hiero. Left side shows the rules used in the derivation (G indicates glue rules as defined in (Watanabe et al., 2006)). The hypotheses column shows the translation prefix and the ordered list of yet-to-be-covered spans.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 (a) and Figure 3 (</head><label>33</label><figDesc>Figure 3(a) and Figure 3(b) show two examples of a common problem in LR-Hiero decoding. The decoder steps for Figure 3(b) are shown in Figure 2. The problem occurs in Step 5 of Figure 2 where rule #5 is matched to span [7, 15]. During decoding LR-Hiero maintains a stack (lastin-first-out) of yet-to-be-covered spans and tries to translate the first uncovered span (span [7, 15] in Step 5). LR-Hiero should match rule #5 to span [7, 15], therefore X 2 is forced to match span [12, 15] which leads to the translation of span [7, 9] (corresponding to X 1 ) being reordered around it</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 1 : Corpus statistics in number of sentences. Tuning and test sets for Chinese-English has 4 references.</head><label>1</label><figDesc></figDesc><table>Model 
Cs-En De-En Zh-En 
Hiero 
20.77 
25.72 
27.65 
LR-Hiero (Watanabe et al., 2006) 
20.72 
25.10 
25.99 
LR-Hiero+CP (Siahbani et al., 2013) 
20.15 
24.83 
-
LR-Hiero+CP (QD=1) 
20.68 
25.14 
24.44 
LR-Hiero+CP (QD=15) 
-
-
26.10 
LR-Hiero+CP+(ab) 
20.88 
25.22 
26.55 
LR-Hiero+CP+(abc) 
20.89 
25.22 
26.52 

(a) BLEU scores for different baselines and modifications of this paper. 
QD=15 for Zh-En in last three rows. 
(b) Average number of language model queries. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 : (a) BLEU (b) LM calls</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 3 : Model sizes (millions of rules).</head><label>3</label><figDesc></figDesc><table>Model 
Cs-En De-En Zh-En 
Hiero 
318 
351 
187 
LR-Hiero 
278 
300 
132 
LR-Hiero+(abc) 
338 
361 
174 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>No. of sentence covered in forced decoding of a sam-
ple of sentences from the devset. We improve the coverage 
by 31% for Chinese-English and more than 20% for the other 
two language pairs. 

</table></figure>

			<note place="foot" n="1"> The future cost is precomputed in a way similar to the phrase-based models (Koehn et al., 2007) using only the terminal rules of the grammar.</note>

			<note place="foot" n="2"> As the length of rules are limited (at most MRL), we can ignore stacks with index less than i − MRL</note>

			<note place="foot" n="3"> In rule type (c) Xn will be in β and Xm will be in γ. 4 For the sake of simplicity, in rule type (b) we can merge Xn and Xr as they are in the same order on both source and target side.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate our modifications to LR-Hiero de-coder on three language pairs <ref type="table">(Table 1)</ref>: German-English (De-En), Czech-English (Cs-En) and Chinese-English (Zh-En).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was partially supported by NSERC, Canada RGPIN: 262313 and RGPAS: 446348 grants to the second author. The authors wish to thank Baskaran Sankaran for his valuable discus-sions and the anonymous reviewers for their help-ful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Hierarchical phrase-based translation. Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Better hypothesis testing for statistical machine translation: controlling for optimizer instability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="176" to="181" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An efficient context-free parsing algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Earley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="94" to="102" />
			<date type="published" when="1970-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Left-to-right tree-to-string decoding with prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1191" to="1200" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Accurate non-hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Los Angeles, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06" />
			<biblScope unit="page" from="966" to="974" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Left language model state for syntactic machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuo</forename><surname>Kiso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation</title>
		<meeting>the International Workshop on Spoken Language Translation<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Grouping language model boundary words to speed K-Best extraction from hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia, USA, 6</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">KenLM: Faster and smaller language model queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>of the Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Forest rescoring: Faster decoding with integrated language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 07</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient incremental decoding for tree-to-string translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Mi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Cambridge, MA, October</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="273" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Moses: open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07</title>
		<meeting>the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pharaoh: A beam search decoder for phrase-based statistical machine translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMTA</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
	<note>ACL &apos;03. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Faster mt decoding through pervasive laziness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Pust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The</title>
		<meeting>Human Language Technologies: The</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<title level="m">Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers</title>
		<meeting><address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="141" to="144" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Kriya-an end-to-end hierarchical phrase-based mt system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Majid</forename><surname>Baskaran Sankaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Razmara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Prague Bulletin of Mathematical Linguistics (PBML)</title>
		<imprint>
			<date type="published" when="2012-04" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="83" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient left-to-right hierarchical phrase-based translation with improved reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maryam</forename><surname>Siahbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baskaran</forename><surname>Sankaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, USA, October</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On lm heuristics for the cube growing algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference of the European Association for Machine Translation</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-05" />
			<biblScope unit="page" from="242" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Left-to-right target generation for hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taro</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajime</forename><surname>Tsukada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Extending hiero decoding in moses with cube growing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenduan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prague Bull. Math. Linguistics</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page">133</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
