<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">When science journalism meets artificial intelligence : An interactive demonstration</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghuram</forename><surname>Vadapalli</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bakhtiyar</forename><surname>Syed</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Prabhu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><forename type="middle">Vasan</forename><surname>Srinivasan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iiit</forename><surname>Hyderabad</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adobe</forename><surname>Research</surname></persName>
						</author>
						<title level="a" type="main">When science journalism meets artificial intelligence : An interactive demonstration</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations)</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations) <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="163" to="168"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an online interactive tool 1 that generates titles of blog titles and thus take the first step toward automating science journalism. Science journalism aims to transform jargon-laden scientific articles into a form that the common reader can comprehend while ensuring that the underlying meaning of the article is retained. In this work, we present a tool, which, given the title and abstract of a research paper will generate a blog title by mimicking a human science journalist. The tool makes use of a model trained on a corpus of 87, 328 pairs of research papers and their corresponding blogs, built from two science news aggre-gators. The architecture of the model is a two-stage mechanism which generates blog titles. Evaluation using standard metrics indicate the viability of the proposed system.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With approximately 2.5 million new scientific pa- pers being published every year <ref type="bibr" target="#b4">(Jinha, 2010)</ref>, there is an ever growing need to make this vast trove of scientific knowledge accessible to the common man. This accessibility of scientific knowledge plays an important role in key politi- cal, economic, cultural and social policy discus- sions and also in public dialogue. Websites like sciencedaily.com, phys.org, eurekalert.org aim to address this problem by aggregating and showcas- ing the top science news stories from the worlds leading universities and research organizations.</p><p>News-writing bots have captured the headlines in the recent past, leading to the growing popular- ity of "Robo Reporting" <ref type="bibr">2,</ref><ref type="bibr">3</ref> . However, extending * * The authors contributed equally. 1 https://irel.iiit.ac.in/science-ai/ 2 Washington Post's robot reporter has published 850 arti- cles.</p><p>3 New York Times is using bots to create more one-to-one experiences.</p><p>this framework to be used for science journalism is a non-trivial task as that would entail understand- ing scientific content and translating it to simpler language without distorting its underlying seman- tics. To our knowledge, there have been no prior attempts within the scientific community to extend "Robo Reporting" to science journalism, and this dearth of research in this area can be partially at- tributed to the lack of suitable data for AI algo- rithms to be trained. To address this lack of an appropriate training corpus, we have created a par- allel corpus of scientific paper titles and abstracts, and their corresponding blog titles with the aim of initiating this foray into automated science jour- nalism and engendering further research.</p><p>This initiative is an initial step towards the larger goal of understanding the entire research paper and generating a complete blog. The sys- tem makes use of a pipeline-based architecture that uses a combination of the title of the research paper and its abstract to generate the title of the blog. Sample of an abstract, paper title and its cor- responding blog title is given in <ref type="table" target="#tab_0">Table 1</ref>. Abstract: A primordial state of matter consist- ing of free quarks and gluons... Here we use supervised learning with a deep convolutional neural network to identify the EoS employed...</p><p>Our system models the blog title generation task via a two-stage process: first, it uses a heuris- tic function mechanism to extract relevant infor- mation from the title and abstract of the research <ref type="figure">Figure 1</ref>: Layout of the web application for our prototype, demonstrating blog title generation paper and then it it uses the extracted informa- tion to generate the blog title. The state-of-the- art sequence-to-sequence neural networks for nat- ural language generation like the Pointer Genera- tor Network ( <ref type="bibr" target="#b9">See et al., 2017)</ref> are used in the sec- ond stage of the pipeline. The generated blog titles are evaluated using all standard metrics for natu- ral language generation tasks and the results indi- cate the viability of the proposed model to produce semantically sound blog titles. Our contributions can be summed up as follows:</p><p>1. A new parallel corpus of 87, 328 pairs of re- search paper titles and abstracts and their cor- responding blog titles. 2. Demonstrating the web application, which uses a pipeline-based architecture that can generate blog titles in a step-by-step fashion, while enabling the user to choose between various heuristic functions as well as the neu- ral model to be used for generating the blog title. 3. Analyzing the outcomes of the experiments conducted to find the best heuristic function as well as network architecture. We have thus taken the first steps towards build- ing an automated science journalism system by generating blog titles with a long-term vision of generating an entire blog from a given research pa- per -thereby paving the way for future research in the area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Recently, a lot of activity in the space of ad- vances in natural language generation has resulted from pioneering works in building sequence-to- sequence neural networks. Among these ad- vances, two particular areas relevant to the prob- lem we have formulated are neural headline gen- eration and style transfer.</p><p>In the space of Neural Headline Genera- tion, Long Short Term Memory (LSTM) based sequence-to-sequence architectures for headline generation using the attention mechanism have been explored <ref type="bibr" target="#b1">(Ayana et al., 2017)</ref>. However, the authors generate headlines for the same domain which effectively means we cannot apply the ar- chitectures directly to our problem where the do- mains and vocabulary are very different. While di- rectly using seq2seq architectures was somewhat helpful in our case -as we will show later; cross domain headline generation requires the consider- ation of aspects such as style, readability, etc in the two different domains of study. In other recent works, <ref type="bibr" target="#b3">Fu et al. (2018)</ref> address the style-transfer problem by learning separate content and style representations using adversarial networks. Their reported results are on their cus- tom Paper-News Title dataset and the samples re- ported by the authors either copy the entire source text or replace a few words. Their evaluation crite- ria leaves a lot to be desired as they evaluate trans- fer strength using a classifier and content preser- vation using word embeddings. A lack of parallel data again presents a drawback. While <ref type="bibr" target="#b5">Kabbara and Cheung (2016)</ref> presented a variant of an auto- encoder where the latent representation had two separate components: one for style and one for content, the authors do not report results on any dataset and hence is not useful in our context.</p><p>One key assumption across all the non-parallel style transfer works is a significant overlap be- tween the vocabulary of the source and target style. On the other hand, in the context of sci- ence journalism -the overlap in vocabulary be- tween the source and the target is not significant which is one of the prime reasons why the non- parallel style transfer methods cannot be directly extended to our problem. This puts our problem in the bracket of content re-purposing, for which we give a demonstrable prototype.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Parallel Corpus for Science Journalism</head><p>In the process of building a solution to address the problem of automated science journalism, we built a corpus of parallel data consisting of sci- entific papers and their corresponding blog arti- cles from two science news aggregation websites: sciencedaily.com and phys.org. Both these web- sites publish articles explaining the latest scien- tific advancements and are rich sources of parallel data. Though we were able to obtain over 300, 000 blog titles, only around 100, 000 of those arti- cles had links to original research papers. These 100, 000 or so research papers were published on over 1000 different research publication websites and we used manual rules to extract abstracts and titles from the research papers that were published on the more frequent research publication web- sites like nature.com, pnas.org. Our final dataset comprises of 87, 328 (blog title, paper title, ab- stract) triples.</p><p>Out of 87, 328 triples, 77, 604 are obtained from sciencedaily.com, 9724 tuples are obtained from phys.org. The statistical analysis of the dataset is as presented below:</p><p>1. Average length of blog titles: 9.55 words 2. Average length of research paper titles: 12.07 words 3. Average length of research paper abstracts: 179.54 words 4. Average word overlap between blog titles and paper titles: 1.93 words 5. Average word overlap between the paper ab- stracts and blog titles: 3.64 words.</p><p>The models must therefore learn which words in the target vocabulary correspond to which words in the source, so that the generated output adheres to the target style. <ref type="figure" target="#fig_0">Figure 2</ref> illustrates the proposed architecture. Our demonstrable prototype consists of a two-stage pipeline, which is described in detail as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Blog Title Generation</head><p>1. A heuristic function takes the title and ab- stract of the research paper and extracts rel- evant information which is then used for fur- ther processing. 2. The output of the previous step is fed into a sequence-to-sequence neural generation model in order to generate the title of the blog post.</p><p>The dataset is of the format T = { (bt, pt, abs) }, where, bt is the blog ti- tle, pt is the paper title and abs is the abstract. We define a heuristic function H(pt, abs) which takes a paper title and abstract as param- eters and outputs a sequence s. The various heuristic functions H we explored are outlined below:</p><p>H(pt, abs) = pt : In this heuristic, we as- sume that the paper title will encapsulate sufficient information to generate the blog title.</p><p>H(pt, abs) = RP(abs) : TF-IDF based measure that selects the sentence that best repre- sents the abstract. ( <ref type="bibr" target="#b0">Allahyari et al., 2017)</ref> H(pt, abs) = RD(abs) : Flesch Reading Ease based measure that selects the most readable sentence in the abstract.</p><p>H(pt, abs) = RPD(abs) : Selects the sen- tence that maximizes the product of normalized RD(abs) and RP(abs) scores, where normal- ization is performed across all sentences.</p><p>We also experimented with different combina- tions of the above heuristics: H(pt, abs) = pt | RD(abs), H(pt, abs) = pt | RP(abs), H(pt, abs) = pt | RPD(abs) and H(pt, abs) = pt | abs; where | implies con- catenation of the associated heuristics.</p><p>In stage 2, neural natural language generation models are used to generate the blog title. The sys- tem provides a baseline attention network which defines 'attention' over the input sequence to allow the network to focus on specific parts of the input text and the pointer-generator ( <ref type="bibr" target="#b9">See et al., 2017)</ref> network which extends the attention-network to compute a probability P gen that decides whether the next word in sequence should be copied from the source or generated from the rest of the vo- cabulary. The pointer-generator aids in copying factual information from the source, and we hy- pothesize that this will be useful when generat- ing blog titles. Formally, the sequence s obtained from the first stage is the input to the neural natural language generation model which generates bt as output with a loss function L(bt, bt ), given by sum of cross entropy loss at all time-steps:</p><formula xml:id="formula_0">L(bt, bt ) = âˆ’ t=T t=0 P (bt t )</formula><p>5 Demonstration <ref type="figure">Figure 1</ref> illustrates the layout of our demonstra- ble web application. It can be accessed publicly at the following URL: https://irel.iiit. ac.in/science-ai. The layout of the web application is broadly divided into two parts. the left half of the page has the necessary text fields and drop down menus to accept inputs from the user and the right half of the page displays the outputs-both the intermediate sequence, which is the output of the first stage of the pipeline, and the blog title, which is the output of the second stage of the pipeline. The application accepts two text inputs from the user: the title of the research paper and the abstract of the research paper. The appli- cation also allows the user to select the heuristic function to be used in the first stage of the pipeline as well as the neural generation model to be used in the second stage of the pipeline. Running the engine will parse the inputs and pass them on to the appropriate heuristic function, which will pro- duce an intermediate sequence viewable on the right side of the page. This intermediate sequence is then passed on to the neural generation model that is selected by the user which then generates the final output, which can be viewed below the intermediate sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BLEU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROUGE L CIDEr</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SkipThought</head><p>Sim.    It is important to note that our research proto- type is still in a nascent stage and the problem of automated science journalism is far from being solved. The same heuristic function or neural gen- eration model might not exhibit the best results for all possible inputs. Thus, it is of exceptional im- portance to provide the users fine grained control over the individual components of the model. The system does this by allowing the user the freedom to select a heuristic function and neural genera- tion model of their choice. This allows for more flexibility for the users to experiment with vari- ous heuristic functions and neural generation mod- els and ensures better results than forcing the user to use one particular configuration for all inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Flesch</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reading Ease</head><formula xml:id="formula_1">H(pt, abs) PG Attn PG Attn PG Attn PG Attn PG Attn pt 0.157</formula><note type="other">40.761 pt | RD(abs) 0.139 0.152 0.129 0.145 0.351 0.754 0.435 0.444 49.504 42.964 pt | RP(abs) 0.142 0.153 0.137 0.144 0.372 0.745 0.431 0.448 40.856 35.311 pt | RPD(abs) 0.151 0.</note><p>If not selected by the user, the heuristic function H(pt, abs) = pt and the attention network neural generation model are used as defaults as this configuration has consistently exhibited good results.</p><p>In order to further facilitate experimentation by the user, the web application shows the perfor- mance of the user-selected configuration on our test dataset, it displays the readability scores of the generated output, and also highlights the words in the output that were copied from the source. All these features give anyone using this system a de- tailed view of how various configurations work and provide the flexibility to select the one that works best of their use-case. <ref type="figure" target="#fig_1">Figure 3</ref> showcases the above mentioned features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation and Analysis</head><p>We evaluate the generated titles using various met- rics surveyed by <ref type="bibr" target="#b10">Sharma et al. (2017)</ref> for task- oriented language generation.  <ref type="bibr" target="#b2">Flesch, 1948)</ref>: It mea- sures the readability of the sentence based on the number of syllables and words <ref type="table" target="#tab_3">Table 2</ref> shows the performance of our proposed input functions of the architecture contrasted with the proposed neural generation models pointer- generator (abbr. PG) and the attention-network (abbr. Attn).</p><p>The blogs had a Flesch Reading Ease of around 30-35, while the research paper's reading ease was between 15-20. Our generated samples have a reading ease (&gt;30) highlighting the transfer in style from research paper to the blog. The higher FRE indicates that the generated titles are easier to understand than the paper titles.</p><p>To further shed some light on the quality of the generated blog titles, <ref type="table">Table 3</ref> shows a few sampled sentences generated by the best performing mod- els in our architecture. Based on our experiments, we conclude that our system learns to generate ti- tles similar to a human expert for scientific blogs. <ref type="table">Table 3</ref>: Samples generated by our prototype</p><p>Blog title: Safer alternatives to nonsteroidal antinflamatory pain killers Model-generated title: New hope for treating inflammatory cardiovascular disease Blog title: The effects of soy and whey protein supplementation on acute hormonal responses to resistance exercise in men Model-generated title: Soy protein supple- mentation linked to resistance exercise in men Blog title: Scientists reconcile three unrelated theories of schizophrenia Model-generated title: A new way to fight psy- chiatric disorders</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>This work serves as a baseline first attempt toward automating science journalism. We proposed an architecture with a two stage pipeline and have de- veloped a demonstrable web application that ac- cepts the title and abstract of a research paper and outputs a blog title, while also giving the user the flexibility to tinker with the individual components of the system. Future work would include using more advanced architectures to generate the body of the blog.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model of pipeline architecture, describing the two stages in which we model blog title generation</figDesc><graphic url="image-2.png" coords="3,72.00,62.81,453.53,161.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results in the application</figDesc><graphic url="image-3.png" coords="5,72.00,292.13,218.27,237.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Sample -Blog Title, Paper Title and 
Abstract from our corpus 

Blog title: Applying machine learning to the 
universe's mysteries 
Paper title: An equation-of-state-meter of 
quantum chromodynamics transition from 
deep learning 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance of the various heuristic functions contrasted with the proposed 
sequence-to-sequence generation framework 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Text summarization techniques: A brief survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Allahyari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Seyed Amin Pouriyeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Assefi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><forename type="middle">D</forename><surname>Safaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">B</forename><surname>Trippe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Computer Science and Applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Gutierrez, and Krys Kochut</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Recent advances on neural headline generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi-Qi</forename><surname>Ayana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan-Kai</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cun-Chao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Yuan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mao-Song</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A new readability yardstick</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolph</forename><surname>Flesch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Psychology</title>
		<imprint>
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Style transfer in text: Exploration and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenxin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoye</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Article 50 million: an estimate of the number of scholarly articles in existence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jinha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Learned Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stylistic transfer in natural language generation systems using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jad</forename><surname>Kabbara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie Chi Kit</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods</title>
		<meeting>the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 28</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL workshop on Text Summarization Branches Out</title>
		<meeting>ACL workshop on Text Summarization Branches Out</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bleu: A method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">40th Annual Meeting on Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointergenerator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">55th Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Relevance of unsupervised metrics in task-oriented dialogue for evaluating natural language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Layla</forename><forename type="middle">El</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannes</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremie</forename><surname>Zumer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Style transfer from non-parallel text by cross-alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianxiao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cider: Consensus-based image description evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Ramakrishna Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
