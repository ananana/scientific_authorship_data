<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stochastic Top-k ListNet</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSLT</orgName>
								<orgName type="department" key="dep2">RIIT</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSLT</orgName>
								<orgName type="department" key="dep2">RIIT</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tsinghua National Lab for Information Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSLT</orgName>
								<orgName type="department" key="dep2">RIIT</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Huilan Limited</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqiao</forename><surname>Pan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSLT</orgName>
								<orgName type="department" key="dep2">RIIT</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Stochastic Top-k ListNet</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>ListNet is a well-known listwise learning to rank model and has gained much attention in recent years. A particular problem of ListNet, however, is the high computation complexity in model training, mainly due to the large number of object permutations involved in computing the gradients. This paper proposes a stochastic ListNet approach which computes the gradient within a bounded permutation subset. It significantly reduces the computation complexity of model training and allows extension to Top-k models, which is impossible with the conventional implementation based on full-set permutations. Meanwhile, the new approach utilizes partial ranking information of human labels , which helps improve model quality. Our experiments demonstrated that the s-tochastic ListNet method indeed leads to better ranking performance and speeds up the model training remarkably.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Learning to rank aims to learn a model to re- rank a list of objects, e.g., candidate documents in document retrieval. Recent studies show that listwise learning delivers better performance in general than traditional pairwise learning <ref type="bibr" target="#b5">(Liu, 2009)</ref>, partly attributed to its capability of learning human-labelled scores as a full rank list. A poten- tial disadvantage of listwise learning, however, is the high computation complexity in model train- ing, which is mainly caused by the large number of permutations of the objects to rank.</p><p>A typical listwise learning method is the List- Net model proposed by <ref type="bibr" target="#b0">Cao et al. (2007)</ref>. This model has been utilized to tackle many ranking problems, e.g. modeling the hiring behavior in on- line labor markets ( <ref type="bibr" target="#b3">Kokkodis et al., 2015)</ref>, rank- ing sentences in document summarization ( <ref type="bibr" target="#b2">Jin et al., 2010)</ref>, improving detection of musical con- cepts ( <ref type="bibr" target="#b8">Yang et al., 2009)</ref> and ranking the results in video search <ref type="bibr" target="#b7">(Yang and Hsu, 2008)</ref>. Basical- ly, ListNet implements the rank function as a neu- ral network (NN), with the objective function set to be the cross entropy between two probability distributions over the object permutations, one de- rived from the human-labelled scores and the other derived from the model prediction (network out- put). In order to deal with the high computation complexity associated with the large number of permutations, <ref type="bibr" target="#b0">Cao et al. (2007)</ref> proposed a Top-k approach, which clusters the permutations by the first k objects, so the number of distinct probabili- ties that need to evaluate in model training reduces from n! to n! (n−k)! , where n is the number of objects in the list.</p><p>To ensure efficiency, k = 1 was selected in the seminal paper <ref type="bibr" target="#b0">(Cao et al., 2007)</ref> and in the open source implementation of RankLib <ref type="bibr" target="#b1">(Dang, 2013)</ref>. This Top-1 approach is a harsh approximation to the full listwise learning and may constrain the power of the ListNet method. We therefore seek to extend the Top-1 approximation to Top-k ( k &gt; 1) models.</p><p>The major obstacle for the Top-k extension is the large number of permutations, or more pre- cisely, permutation classes in the Top-k setting. A key idea of this paper is that the rank information involved in the permutation classes is highly re- dundant and so a small number such permutation classes are sufficient to convey the rank informa- tion required to train the model. Meanwhile, the partial rank information associated with the sub- set of permutation classes may represent more de- tailed knowledge for model training, leading to better ListNet models.</p><p>Based on these two conjectures, we propose a s- tochastic ListNet method, which samples a subset of the permutation classes (object lists) in mod- el training and based on this subset to train the ListNet model. Three methods are proposed to conduct the sampling. In the uniform distribution method, the candidate objects are selected follow- ing a uniform distribution; in the fixed distribution method, the candidate objects are selected follow- ing a distribution derived from the human-labeled scores; in the adaptive distribution method, the candidates are selected following a distribution de- fined by the rank function, i.e., the neural network output. Experimental results demonstrated that the stochastic ListNet method can significantly reduce the computation cost in model training. In fact, if the size of the permutation subset is fixed, the computation complexity is bounded, which allows training Top-k models where k is large. Mean- while, better performance was obtained with the stochastic ListNet approach, probably due to the learning of partial rank information.</p><p>The contributions of the paper are three-fold: (1) proposes a stochastic ListNet method that sig- nificantly reduces the training complexity and de- livers better ranking performance; (2) investigates Top-k models based on the stochastic ListNet, and studies the impact of a large k; (3) provides an open source implementation based on RankLib.</p><p>The rest of the paper is organized as follows. Section 2 introduces some related works, and Sec- tion 3 presents the stochastic ListNet method. Sec- tion 4 presents the experiments, and the paper is concluded by Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>This work is an extension of the Top-k List- Net method proposed by <ref type="bibr" target="#b0">Cao et al. (2007)</ref>. The novelty is that we propose a stochastic learing method which not only speeds up the model train- ing but also produces stronger models. The code is based on the Top-1 ListNet implementation of RankLib <ref type="bibr" target="#b1">(Dang, 2013)</ref>.</p><p>Another related work is the SVM-based pair- wise learning to rank model based on stochastic gradient descent (SGD) <ref type="bibr" target="#b6">(Sculley, 2009)</ref>. In this approach, training instances (queries) are selected randomly and for each query, a number of object pairs are sampled from the object list. These pairs are used to train the SVM model. In the stochas- tic ListNet method proposed in this paper, the ran- domly selected training samples are permutation classes (object lists) rather than pairs of objects, and a set of object lists rather than a single pair forms a training sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Review of ListNet</head><p>The ListNet approach proposed by <ref type="bibr" target="#b0">Cao et al. (2007)</ref> trains a neural network which predicts the scores z (i) of a list of candidate objects x (i) given a query q (i) , formulated by z (i) = f w (x (i) ), where f w stands for the scoring function defined by the NN. The objective function is given by:</p><formula xml:id="formula_0">L = i L(y (i) , z (i) ) = i ∀g∈G k P y (i) (g)log(P z (i) (g)) (1)</formula><p>where y (i) denotes the human-labelled scores, and G k is the set of permutation classes defined by:</p><formula xml:id="formula_1">G k = {G k (j 1 , j 2 , ..., j k )|j t = 1, 2, ..., n, s.t. j u = j v f or ∀u = v} (2)</formula><p>where n is the number of candidate objects, j t is the object ranked at the t-th position, and</p><formula xml:id="formula_2">G k (j 1 , j 2 , ..., j k )</formula><p>is a permutation class which in- volves all the permutations whose first k object- s are exactly (j 1 , j 2 , ..., j k ). Following <ref type="bibr" target="#b0">Cao et al. (2007)</ref>, the probability of G k (j 1 , j 2 , ..., j k ) can be computed by:</p><formula xml:id="formula_3">P s (G (j 1 , j 2 , ..., j k )) = k t=1 e s j t n l=t e s j l . (3)</formula><p>where s jt is the score of object at position j t (t = 1, 2, , , k) at a certain permutation. By this defi- nition of permutation probability, Eq. (1) defines a cross entropy between the distributions over permutations (precisely, permutation classes) de- rived from the human-labelled scores and the NN- predicted scores. Therefore, optimizing the objec- tive function Eq. (1) with respect to the NN model f w leads to a scoring function that approximates the human-labelled ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Stochastic Top-k ListNet</head><p>A particular difficulty of the Top-k ListNet method is that it requires very demanding computation in model training. Refer to Eq. (2), the permu- tation set G k involves n! (n−k)! members, and for each member, computing its probability involves</p><formula xml:id="formula_4">(2n−k+1)k 2</formula><p>summations plus k multiplications and divisions. To let the algorithm practical, k=1 was selected in <ref type="bibr" target="#b0">(Cao et al., 2007)</ref>, as well as the pub- lic toolkit RankLib <ref type="bibr" target="#b1">(Dang, 2013)</ref>. Although this is a good solution and reduces computation dramat- ically, we argue that this approach largely buries the power of ListNet. In fact, setting k=1 effec- tively marginalizes all the probabilities over the candidate objects of a permutation class except the top one. By this approximation, Eq. (3) reduces to a softmax over the candidate objects, which mean- s that it actually focuses on how the probabilities are distributed over individual objects, rather than how the probabilities are distributed over objec- t lists. This potentially loses much rank informa- tion involved in the human labels.</p><p>Another disadvantage of the Top-1 model is that it learns the rank information of the full list, but ignores the rank information of partial sequences, which may lead to ineffective learning. As an ex- ample, considering an object list where the score of the most relevant object is much higher than the scores of others, then the learning is dominated by the highest score, and largely throws away the rank information conveyed by the scores of other objects. It would be quite helpful if the rank infor- mation involved in partial sequences of the candi- date objects can be learned. Top-k models place distributions over object lists (in length k), and so can learn partial sequences of objects.</p><p>We are interested in how to learn Top-k (k &gt; 1) models while keeping the computation tractable. To achieve the goal, we propose a stochastic List- Net approach, which samples a small set of the Top-k permutation classes (object lists), and train the Top-k model based on this small set instead of the full set of permutation classes. As a com- parison, the full set of permutation classes of the Top-k model is n! (n−k)! , which is computationally prohibitive if k &gt; 1. With stochastic ListNet, a subset of the permutation classes that involves on- ly l members are randomly selected. Training the Top-k model based on this subset greatly reduces the computation cost, even with a large k. In fact, the subset approach imposes a bound of the com- putation cost that is largely determined by the the size of the subset (l), while independent of the to- tal number of objects n and the model order k.</p><p>Interestingly, the stochastic approach offers not only quick learning, but also a chance of learning partial ranks. This is obvious because only a sub- set of the object lists are selected in model train- ing, and so the rank information involved in the subset of the permutation classes can be learned. With the Top-1 model, partial ranks reduces to par- tial sequences since each object list involves only one object. As we have discussed, learning partial sequences is an advantage of Top-k models with k &gt; 1. This means that stochastic Top-1 List- Net possesses some advantages of Top-k ListNet, while the computation cost is much lower.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sampling methods for stochastic ListNet</head><p>The training process of stochastic ListNet start- s from sampling l permutation classes, or object lists. For each object list, k objects are sampled following a particular distribution. As mentioned in Section 1, three distributions are studied in this paper: uniform distribution, fixed distribution and adaptive distribution. They are presented as fol- lows.</p><p>Uniform distribution sampling: In this method, all the k objects of a particular object list are sampled with an equal probability. This sam- pling method is simple but biased towards irrele- vant candidates, since there are much more irrele- vant objects than relevant ones in the training data. A re-sampling approach is proposed to remedy the bias, as will be discussed in Section 4.</p><p>Fixed distribution sampling: In this method, the objects are sampled following a distribution proportional to the human-labelled scores. For in- stance, in the LETOR dataset that is used in this s- tudy, each candidate object (document) is labelled as 2 (very relevant), 1 (relevant) or 0 (irrelevan- t). These scores are normalized by softmax and are used as the probability distribution when sam- pling objects. Because the probabilities of relevant objects are larger than those of irrelevant object- s, more relevant objects would be selected by this sampling approach in model training.</p><p>Adaptive distribution sampling: The fixed distribution sampling mentioned above relies on human-labelled scores, which may be impacted by label errors. Moreover, the absolute values of hu- man labels are not good measures of object rel- evance. To solve these problems, we choose the outputs of the 'current' neural network as the rel- evance scores, and sample the objects according to these scores. Note that the network outputs are natural measures of object relevance based on the present ranking model. As the model (the neural network) keeps updated during model training, the relevance scores are accordingly changed. In each iteration, the relevance scores are re-calculated, and the sampling is based on the new scores in the next iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Gradients with linear networks</head><p>Cao et al. <ref type="formula">(2007)</ref> optimized the ListNet model by gradient descent. For each query, the learn rule is formuated by:</p><formula xml:id="formula_5">w = w − η∆w</formula><p>where η is the learning rate, and w denotes the pa- rameters of the model f w . ∆w denotes the gradi- ent and it can be computed as follows:</p><formula xml:id="formula_6">∆w = ∀g∈G k ∂P z (i) (fw) (g) ∂w P y (i) (g) P z (i) (fw) (g) .</formula><p>For simplicity, a linear NN model was used by <ref type="bibr" target="#b0">Cao et al. (2007)</ref>. This has been adopted in our study as well, written by</p><formula xml:id="formula_7">z (i) = f w (x (i) j ) = w T x (i) j , where x (i)</formula><p>j denotes the feature vector of the j-th object of the i-th query. In the case of the Top-1 model, it shows that:</p><formula xml:id="formula_8">∆w = j [σ(z (i) , j) − σ(y (i) , j)]x (i) j</formula><p>where σ(s, j) is the j-th value of the softmax func- tion of the score vector s, given by:</p><formula xml:id="formula_9">σ(s (i) , j) = e s (i) j n (i) t=1 e s (i) t .</formula><p>In the case of the Top-k model, the gradien- t(Derivative of cross entropy between P z (i) and P y (i) when k &gt;= 2) is a bit complex, but still man- ageable:</p><formula xml:id="formula_10">∆w = g∈G k [( k t=1ˆσ t=1ˆ t=1ˆσ(y (i) , t))· ( k f =1 {x (i) j f − n (i) v=fˆσ v=fˆ v=fˆσ(z (i) , v)x (i) jv })]<label>(4)</label></formula><p>wherê σ(·) defines a 'partial' softmax(The partial softmax means that the σ(s, f ) has a similar for- m as softmax, however when computing the value for each f, the denominator is not the summation from 1 to n, instead a partial sequence from f to n.), given by:</p><formula xml:id="formula_11">ˆ σ(s (i) , f ) = e s (i) j f n (i) t=f e s (i) j t .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Stochastic Top-k ListNet algorithm</head><p>We present the stochastic Top-k ListNet algorith- m, by employing the techniques described above. The gradient descent (GD) approach is adopted. All the training samples are processed sequentially in an iteration. The training runs several iterations until the convergence criterion is reach. Another detail is that the learning rate is multiplied by 0.1 whenever the objective function is worse than the previous iteration. The procedure is illustrated in Algorithm 1, where L(t) denotes value of the ob- jective function after the t-th iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Stochastic Top-k ListNet</head><p>Require:</p><formula xml:id="formula_12">Input: D = {(q (1) , x (1) , y (1) ), ..., (q (m) , x (m) , y (m) )}:</formula><p>training data T: number of iterations η: learning rate Procedure:</p><p>1: Randomly initialize w 2: for t = 1 to T do 3:</p><formula xml:id="formula_13">for i = 1 to m do 4:</formula><p>select the i-th training instance</p><formula xml:id="formula_14">(q (i) , x (i) , y (i) ) ∈ D 5:</formula><p>Sample the permutation classes G k</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Compute ∆w according to <ref type="bibr">Eq. (4)</ref> 7:</p><p>Update f w : w = w − η∆w 8:</p><p>end for end if 12: end for 4 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>The proposed stochastic Top-k ListNet method is tested on the document retrieval task based on the MQ2008 dataset of LETOR 4.0 ( . This database was released in early 2007 and has been widely used in learning to rank studies. It contains queries and corresponding candidate doc- uments. The human-labelled scores are among three values {0, 1, 2}, representing little, medium, and strong relevance between queries and candi- date documents, respectively. The training set, validation set and test data all contain 784 queries. The document features used in this study include term frequency, inverse document frequency, B-M25, and language model scores for IR. Some new features proposed recently are also included, such as HostRank, feature propagation, and topi- cal PageRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment Setup</head><p>In our experiments, we consider Top-k model- s where k = 1, 2, 3, and 4. Although any k is possible with the proposed stochastic ListNet, we will show that simply increasing the model order k does not improve performance. The P@1 and P@10 performance is used as the evaluation met- ric.</p><p>Specially, for all the three distribution sam- pling methods, the sampling process involves t- wo steps: pre-selection and re-sampling. The pre- selection step samples a list of documents fol- lowing three distributions mentioned above, and in the re-sampling step, document lists including more relevant documents are retained with a high- er probability. For example, denoting the pre- selected document list by (v 1 ,v 2 ,...,v k ) where k is the length of the list, and denoting the correspond- ing human-labelled scores by (s 1 , s 2 ,...,s k ), the probability that the list is retained is given by</p><formula xml:id="formula_15">k i=1 s i kS</formula><p>where S is the maximum value of the human- labelled scores, which is 2 in our case. The re- sampling approach is designed to encourage doc- ument lists containing more relevant documents, which is the most important for the uniform distri- bution sampling.</p><p>In stochastic Top-k ListNet, the learning rate is set as 10 −3 for k = 1, and 10 −5 for k &gt; 1. These values are set to achieve the best performance on the validation set. Another important parameter of the stochastic Top-k ListNet approach is the num- ber of samples of the document lists (or the size of subset of permutation classes selected), denoted by l. Various settings of l are experimented with in this study. To eliminate randomness in the results, all the experiments are repeated 20 times and the averaged performance is reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental results</head><p>The P@1 results on the test dataset with different orders of Top-k ListNet are reported in <ref type="figure">Figure 1</ref> to <ref type="figure" target="#fig_3">Figure 4</ref>. In each figure, the number of docu- ment lists varies from 5 to 500. For comparison, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ADS ListNet (k = 1) FDS ListNet (k = 1) UDS ListNet (k = 1) Conventional ListNet (k = 1)</head><p>Figure 1: The P@1 performance on the test data with the Top-1 ListNet utilizing the three sampling approaches. The size of the permutation subset varies from 50 to 500.  the results with the conventional ListNet are al- so presented. Note that the re-sampling approach was not applied to the Top-1 model as we found it caused performance reduction. This is perhaps because the sampling space is small with the Top- 1 model, and so re-sampling tends to cause over- emphasis on relevant documents. From these results, we first observe that s- tochastic ListNet with either fixed or adaptive dis- tribution sampling tends to outperform the conven- tional ListNet approach, particularly with a large k. This confirms our argument that rank informa- tion can be learned from a subset of the permu- tation classes that are randomly selected, and the partial rank learning can lead to even better per- formance than the full rank learning, the case of conventional ListNet. This is an interesting result and demonstrates the stochastic ListNet is both faster and better than the conventional ListNet. It is also seen that the adaptive distribution sampling performs slightly better than the fixed distribution sampling. This is not surprising as the adaptive distribution sampling uses a more reasonable rel- evance score (neural network output) to balance relevant and irrelevant documents. The uniform distribution sampling performs a little worse than the other two sampling methods, probably caused by the less informative uniform distribution.</p><p>Another observation is that in all the four fig- ures, the performance of the stochastic ListNet methods increases with more samples of the ob- ject lists. However if there are too many samples, the performance starts to decrease. This can be explained by the fact that the sampling prefers rel- evant documents which are more informative. A larger sample set often includes more informative documents; however if the set is too large, many ir- relevant documents will be selected and the perfor- mance is reduced. In the case that the number of samples is very large (500 for example for Top-1), the stochastic ListNet falls back to the convention- al ListNet, and their performance becomes similar.</p><p>Comparing the results with different k, it can be seen that a larger k leads to a better perfor- mance with stochastic ListNet. This confirms that high-order Top-k models can learn more ranking information. However, this is not necessarily the case with the conventional ListNet. For example, the Top-2 model does not offer better performance than the Top-1 model. This is perhaps because high-order Top-k models consider a large num- ber of document lists and most of them are not informative, which leads to ineffective learning. Remind that the conventional ListNet is a special case of the stochastic ListNet with a very large sample set, and we have discussed that an over large sample set actually reduces performance.</p><p>The averaged training time and the performance in precession are presented in <ref type="table" target="#tab_1">Table 1</ref>. For pre- cession, both P@1 and P@10 results are report- ed, though we focus on P@1 since it is more con- cerned for applications such as QA. Note that for stochastic ListNet, the optimal number of samples (document lists) has been selected according to the P@1 performance on the validate set.</p><p>From these results, it can be seen that the con- ventional Top-1 ListNet is rather fast, however the Top-2 model is thousands of times slower. With k &gt; 2, the training time becomes prohibitive and so they are not listed in the Table. This is expected since the conventional ListNet considers the full set of permutations which is a huge number with a large k. With the stochastic ListNet, the training time is dramatically reduced. Even with a large k, the computation cost is still manageable, because the computation is mostly determined by the num- ber of object lists, rather than the value of k. When comparing the three sampling methods, it can be found the convergence speed of the uniform distri- bution approach is the slowest, probably due to the ineffective selection for relevant documents. The adaptive distribution sampling is the fastest, prob- ably attributed to the collaborative update of the model and the distribution.</p><p>As for the P@1 performance, the stochastic ListNet method generally outperforms its non- stochastic counterpart, particularly with the adap- tive distribution sampling. For example, the best P@1 results obtained on the test data with the s- tochastic Top-1 ListNet is 0.4127, which outper- forms the conventional Top-1 ListNet (0.4119). This advantage of stochastic ListNet, as we ar- gued, is largely attributed to its capability of learn- ing partial rank information with samples of par- tial sequences of the rank list.</p><p>Comparing the results with different k values, it can be seen that a larger k tends to offer better P@1 performance on the training set, with either the conventional ListNet or the stochastic ListNet. For example, with the conventional ListNet, the results are 0.4101 vs. 0.4119 with the Top-1 and Top-2 models respectively. However, the perfor- mance gap is rather marginal, and the advantage with the large k does not propagate to the results on the test data (as has been seen in <ref type="figure">Figure 1</ref> and <ref type="figure" target="#fig_1">Figure 2</ref>). This indicates that for the conventional ListNet, the Top-1 model is not the only choice in the sense of computation complexity, but also the best choice in the sense of P@1 performance.</p><p>For stochastic ListNet, the performance im- proves with k increases. In contrast to the con- ventional ListNet, this improvement propagates to the results on the test data. For example, with the adaptive distribution sampling, the P@1 results on the training set are 0.4102 vs. 0.4184 with the Top-1 and Top-3 models respectively, and the re- sults on the test data are 0.4121 vs. 0.4177 respec- tively.</p><p>Nevertheless, the P@1 performance improve- ment with a large k is rather marginal, and an over large k simply reduces the performance. To make it clear, we vary the value of k from 1 to 100 and plot the P@1 results in <ref type="figure" target="#fig_4">Figure 5</ref>). It can be seen that larger k (&gt; 4) does not offer any merit but causes performance instability, particu- larly with the adaptive sampling approach. As we have discussed, with the stochastic ListNet, par- tial rank information can be learned with simple Top-k models, even the Top-1 model. This capa- bility of partial rank learning with simple models reduces the necessity of employing complex Top-k models. This is a highly valuable conclusion, and it suggests that a simple Top-1 or Top-2 model is sufficient for the ListNet method, if the stochas- tic method is applied. Considering the trade-off between computation cost and model strength, we recommend stochastic Top-2 ListNet which deliv- ers better P@1 performance than the Top-1 model consistently, with sufficiently fast computing. If more computation is affordable, stochastic Top-3 ListNet can be used to obtain better performance.</p><p>Finally, we highlight that the conclusions ob-  tained from the P@1 results and the P@10 re- sults perfectly match. In fact, the P@10 results look more consistent between training and test da- ta, and the advantage of the stochastic approach seems more clear, particularly with the adaptive sampling. This is not surprising as the optimiza- tion goal of ListNet is essentially to form a good rank that involves multiple candidates, and so P@10 is apt to measure the superiority of a bet- ter rank approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>An interesting observation with the stochastic ListNet approach is that sampling more relevan- t documents improves performance. This can be explained by the data imbalance between relevan- t and irrelevant documents, i.e., there are much more irrelevant documents than relevant docu- ments in the training data. This imbalance lead- s to biased models that tend to classify all docu- ments as irrelevant. The re-sampling approach can be regarded as a way of balancing the two classes, and the fixed and adaptive distribution sampling can be regarded as another way to achieve the goal. Note that in the fixed distribution sampling, the distribution is solely dependent on the human- labeled scores. These scores are good measures of the rank of relevance but not good measures of the relevance itself. A possible way to solve this problem is to learn a scoring function that map- s human-labelled scores to more reasonable mea- sures of document relevance, though we took a d- ifferent way that employs the network outputs as the relevance measures, which is what the adaptive distribution sampling method does. Note that the network output is a natural measure of documen- t relevance, so the adaptive distribution sampling works the best in our experiments. Another related issue is the harsh labelling of the AM2008 dataset. In this dataset, documents are labelled by only three values {0, 1, 2}, which is rather imprecise and the rank information is very limited. This harsh labeling is another reason why the uniform distribution sampling does not work: by uniform distribution sampling, there is a large probability that the sampled object lists involve documents that are all labelled by 0. This lead- s to an inefficient learning. Another consequence of the harsh labeling is that the power of compli- cated ranking models is largely constrained. For example, with the Top-k (k &gt; 1) ListNet model, many of the k documents in a candidate list are la- belled as the same score, resulting in limited rank information for the Top-k model to learn. This is why Top-k models did not exhibit much superi- ority to the Top-1 model in our experiments. We argue that top-k models would provide more con- tributions with more thorough labels (e.g., scores in real values). This is an ongoing research of our group.</p><p>Finally, we highlight that the stochastic ap- proach is not limited to the ListNet model, but any model for listwise learning. It is well known that listwise learning outperforms pairwise learning, due to it is capability of learning full ranks <ref type="bibr" target="#b5">(Liu, 2009</ref>). However learning full ranks requires unaffordable computation and so is infeasible in practice, even with the Top-k approximation. Our work demonstrated that learning full ranks can be approximated by learning partial ranks, and a lim- ited number samples of such partial ranks is suf- ficient to convey the rank information. This s- tochastic learning is very fast, and even delivers better performance. It can be regarded as a gener- al framework that treats both the pair-wise learn- ing and the full rank learning as two special cases. In fact, if the set of partial ranks involves all the permutation classes, it reduces to the convention- al listwise learning, and if the set of partial ranks involves all object pairs, it resembles the pairwise learning. A wide range of listwise learning meth- ods can benefit from the idea of stochastic learning provided in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper proposed a stochastic ListNet method to speed up the training of ListNet models and im- prove the ranking performance. The basic idea is to approximate the full rank learning by learning a small number of partial ranks. Three sampling ap- proaches were proposed to select the partial ranks, and Top-k ListNet models with various complexi- ty (k values) were investigated.</p><p>Our preliminary results on the MQ2008 dataset confirmed that the stochastic ListNet approach can dramatically speeds up the model training, and more interestingly, it can produce better ranking performance than the conventional ListNet. Espe- cially, the adaptive distribution sampling method delivered the best P@1 performance. An appeal- ing observation is that the simple Top-2 model is very effective and more complex Top-k models seem not very necessary, considering the trade-off between training complexity and model strength. This observation, however, is purely based on the MQ2008 dataset. As have been discussed, more detailed human labels may require more complex models, for which the stochastic method proposed in this paper is essential to conduct the model training. For the future work, we plan to study Top-k ListNet models with other databases and ap- ply the stochastic learning approach to other list- wise learning to rank methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The P@1 performance on the test data with the Top-2 ListNet utilizing the three sampling approaches. The size of the permutation subset varies from 5 to 500.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The P@1 performance on the test data with the Top-3 ListNet utilizing the three sampling approaches. The size of the permutation subset varies from 5 to 500.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The P@1 performance on the test data with the Top-4 ListNet utilizing the three sampling approaches. The size of the permutation subset varies from 5 to 500.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The P@1 performance on the test data with the stochastic Top-k ListNet approach, where k varies from 1 to 100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Averaged training time (in seconds), P@1 and P@10 on training, validation (Val.) and test 
data with different Top-k methods. 'C-ListNet' stands for conventional ListNet, 'S-ListNet' stands for 
stochastic ListNet. </table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the National Science Foundation of China (NSFC) under the project No. 61371136, and the MESTDC PhD Foundation Project No. 20130002120011. It was also supported by Sinovoice and Pachira.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to rank: from pairwise approach to listwise approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Ranklib</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A comparative study on ranking and selection strategies for multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics: Posters</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="525" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hiring behavior models for online labor markets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marios</forename><surname>Kokkodis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panagiotis</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panagiotis G</forename><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Eighth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="223" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Letor: Benchmark dataset for research on learning to rank for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenying</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR 2007 workshop on learning to rank for information retrieval</title>
		<meeting>SIGIR 2007 workshop on learning to rank for information retrieval</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to rank for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="331" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large scale learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Advances in Ranking</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Video search reranking via online ordinal reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Winston H</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="285" to="288" />
		</imprint>
	</monogr>
	<note>Multimedia and Expo</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving musical concept detection by ordinal regression and context fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ching</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Homer H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMIR</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="147" to="152" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
