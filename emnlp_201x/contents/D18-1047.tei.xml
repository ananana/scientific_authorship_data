<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NORMA: Neighborhood Sensitive Maps for Multilingual Word Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ndapa</forename><surname>Nakashole</surname></persName>
							<email>nnakashole@eng.ucsd.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>San Diego La Jolla</addrLine>
									<postCode>92093</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">NORMA: Neighborhood Sensitive Maps for Multilingual Word Embeddings</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="512" to="522"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>512</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Inducing multilingual word embeddings by learning a linear map between embedding spaces of different languages achieves remarkable accuracy on related languages. However , accuracy drops substantially when translating between distant languages. Given that languages exhibit differences in vocabulary , grammar, written form, or syntax, one would expect that embedding spaces of different languages have different structures especially for distant languages. With the goal of capturing such differences, we propose a method for learning neighborhood sensitive maps, NORMA. Our experiments show that NORMA outperforms current state-of-the-art methods for word translation between distant languages.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The success of monolingual word embeddings has sparked interest in multilingual word embeddings. The goal is to learn word vectors where similar words have similar vector representations regard- less of their language. Multilingual word embed- dings are playing an increasingly prominent role in machine translation ( <ref type="bibr" target="#b49">Zou et al., 2013;</ref><ref type="bibr" target="#b13">Lample et al., 2018;</ref><ref type="bibr" target="#b5">Artetxe et al., 2018b</ref>). In addi- tion, they are a promising avenue for cross-lingual model transfer ( <ref type="bibr" target="#b18">Guo et al., 2015;</ref><ref type="bibr" target="#b40">Täckström et al., 2012)</ref>.</p><p>A prominent approach to learning multilingual word embeddings is to induce a mapping function between embedding spaces of different languages. However, there is a key assumption behind learn- ing such a mapping function: that the embedding spaces of different languages exhibit similar struc- tures ( <ref type="bibr" target="#b26">Mikolov et al., 2013a)</ref>. Evidence that this assumption holds has mostly been through extrin- sic evaluation metrics such as word translation ac- curacy. A notable exception is (Mikolov et al., <ref type="figure">Figure 1</ref>: Bottom: By learning a linear map between embedding spaces of related languages, e.g., en-es, cur- rent methods achieve high accuracy on word transla- tion. Top: For distant language pairs, e.g., en-ru, where differences are larger, word translation accuracy sub- stantially degrades. 2013a), who showed empirical evidence on ani- mals and numbers. Embeddings corresponding to a few numbers and animals in English and Span- ish were projected down to two dimensions us- ing PCA, and then manually rotated to accentuate similarity. Despite showing only these two con- cepts for two related languages, this work con- cluded that embedding spaces of different lan- guages exhibit similar geometric arrangements. Additionally, work in this line of inquiry has con- tinued to develop methods based on this assump- tion ( <ref type="bibr" target="#b4">Artetxe et al., 2018a;</ref><ref type="bibr" target="#b13">Conneau et al., 2018)</ref>. Given that languages differ along dimensions such as vocabulary, grammar, written form, and syntax, one would expect that embedding spaces of differ- ent languages exhibit different structures. Indeed, recent work showed that assumptions of isomor- phism and linearity do not hold ( <ref type="bibr" target="#b38">Søgaard et al., 2018;</ref><ref type="bibr" target="#b29">Nakashole and Flauger, 2018)</ref> While these assumptions do not substantially affect accuracy when translating between related languages, this is not the case for distant lan- guages, see <ref type="figure">Figure 1</ref>. There is no established quantitative metric for measuring distances be- tween languages. Language trees trace the evo- lution of languages but do not provide similar- ity scores. <ref type="bibr" target="#b12">(Chiswick and Miller, 2005</ref>) learned similarity scores of 43 different languages to En- glish by measuring how well Americans could learn a given language in a fixed period of time. Low scores on a standardized proficiency test were taken to indicate a large distance between the lan- guage and English. According to their scores, Japanese and Chinese are the most distant from English, Russian has a middle score, and French, Portuguese, Dutch, as expected, have some of the highest scores.</p><p>Additionally, linguists and psychologists have long studied the question of how language af- fects the way we think <ref type="bibr" target="#b7">(Birner, 1999;</ref><ref type="bibr" target="#b10">Boroditsky, 2011)</ref>. This influence would arise due to different languages organizing concepts differently.</p><p>We would like to model some aspects of the structural differences of languages when learning mapping functions between embedding spaces. To this end, we propose to learn neighborhood sensi- tive maps. We can, in principle, achieve neighbor- hood sensitive maps by training non-linear func- tions. However, training non-linear functions, in particular deep neural networks for this problem is difficult to optimize for this zero-shot <ref type="bibr">(Lazaridou et al., 2015</ref>) learning problem, as we show in our experiments. Prior work alludes to similar ob- servations( <ref type="bibr" target="#b26">Mikolov et al., 2013a</ref>). For example, ( <ref type="bibr" target="#b13">Conneau et al., 2018)</ref> found that using non-linear mapping functions made training unstable 1 .</p><p>In summary, our contributions are as follows:</p><p>• We propose a method for learning neighbor- hood sensitive maps, NORMA, which learns a single mapping function but in a departure from prior work, it discovers neighborhoods. NORMA avoids learning multiple mapping functions, thus enabling parameter sharing among neighborhoods. This is a more effi- cient use of training data than if we were to train multiple mapping functions for differ- ent neighborhoods as is done in ( <ref type="bibr" target="#b49">Zou et al., 2013</ref>).</p><p>• The neighborhoods are learned jointly while learning to translate, and we show that they 1 https://openreview.net/forum?id=H196sainb</p><p>are interpretable.</p><p>• Our experiments show that for word trans- lation between distant languages, NORMA substantially outperforms methods that achieve the best performance when translat- ing between related languages.</p><p>• Additionally, in the related language setting, we show that on rare words NORMA sub- stantially outperforms state-of-the-art meth- ods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The common approach to learning cross embed- ding space mapping functions is: first monolingual word embeddings for each language are trained in- dependently; and second, a mapping function is learned, using supervised or unsupervised meth- ods. The resulting mapping function enables translating words from the source to the target lan- guage.</p><p>Map Induction Methods. The earliest and sim- plest approach is to use a regularized least squares loss to induce a linear map M as follows:</p><formula xml:id="formula_0">ˆ M = arg min M ||MX − Y|| F + λ||M||,</formula><p>here X and Y are matrices that contain word em- bedding vectors for the source and target language ( <ref type="bibr" target="#b26">Mikolov et al., 2013a;</ref><ref type="bibr" target="#b14">Dinu et al., 2014;</ref><ref type="bibr" target="#b43">Vulic and Korhonen, 2016)</ref>. Improved results were ob- tained by imposing an orthogonality constraint on M ( <ref type="bibr" target="#b46">Xing et al., 2015;</ref><ref type="bibr" target="#b36">Smith et al., 2017)</ref>. Another loss function used in prior work is the max-margin loss, which has been shown to significantly outper- form the least squares loss ( <ref type="bibr">Lazaridou et al., 2015;</ref><ref type="bibr" target="#b30">Nakashole and Flauger, 2017)</ref>. Another approach is to use canonical correla- tion analysis (CCA) to map two languages to a shared embedding space ( <ref type="bibr" target="#b19">Haghighi et al., 2008;</ref><ref type="bibr" target="#b15">Faruqui and Dyer, 2014;</ref><ref type="bibr" target="#b25">Lu et al., 2015;</ref><ref type="bibr" target="#b1">Ammar et al., 2016</ref>).</p><p>Most of the prior methods can be characterized as a series of linear transformations. In particular, ( <ref type="bibr" target="#b4">Artetxe et al., 2018a</ref>) propose a framework to dif- ferentiate prior methods in terms of which trans- formations they perform: embedding normaliza- tion, whitening, re-weighting, de-whitening, and dimensionality reduction.</p><p>Work on phrase translation proposed to in- duce many local maps that are individually trained ( <ref type="bibr" target="#b48">Zhao et al., 2015</ref>) on local neighborhoods. In contrast, our approach trains a single function while taking into account neighborhood sensitiv- ity. Our underlying motivation of neighborhood sensitivity is similar in spirit to the use of lo- cally linear embeddings for nonlinear dimension- ality reduction <ref type="bibr" target="#b33">(Roweis and Saul, 2000</ref>).</p><p>Forms of Supervision. The methods we have described so far fall under supervised learning. In the supervised setting, a seed dictionary (5k word pairs is a typical size) is used to induce the mapping function. In ( <ref type="bibr" target="#b3">Artetxe et al., 2017</ref>) a semi-supervised approach is explored, whereby the method alternates between learning the map and generating an increasingly large dictionary. Completely unsupervised methods have recently been proposed using adversarial training <ref type="bibr" target="#b6">(Barone, 2016;</ref><ref type="bibr" target="#b47">Zhang et al., 2017;</ref><ref type="bibr" target="#b13">Conneau et al., 2018)</ref>. However, the underlying methods for learning the mapping function are similar to prior work such as ( <ref type="bibr" target="#b46">Xing et al., 2015)</ref>. The limitations and strengths of unsupervised methods are detailed in <ref type="bibr">(Søgaard et al., 2018)</ref> Although in our our experiments we work in the supervised setting, NORMA can work with any form of supervision.</p><p>Translation Retrieval Methods. The most commonly used way to obtain a translation t of a source language word s is nearest neighbor re- trieval, given by: t = arg max t cos(Mx s , y t ). Alternative retrieval methods have been pro- posed, such as the inverted nearest neighbor re- trieval( <ref type="bibr" target="#b14">Dinu et al., 2014</ref>), inverted softmax ( <ref type="bibr" target="#b36">Smith et al., 2017)</ref> and Cross-Domain Similarity Local Scaling (CSLS) ( <ref type="bibr" target="#b13">Conneau et al., 2018</ref>). Since we are interested in evaluating the quality of mapping functions, our experiments use standard nearest neighbor retrieval for all methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Local Maps in Embedding Space</head><p>Is it useful for maps to be neighborhood sensitive? To study this question we carried out experiments comparing performance of neighborhood-specific maps to global maps. A thorough analysis of this kind was carried out in our prior work <ref type="bibr" target="#b29">(Nakashole and Flauger, 2018)</ref> We created neighborhoods by first selecting the embeddings of a few words associated with specific topics such as diseases, or cities. We then added all nearby words, which are words whose cosine similarity to any of the selected words is &gt;=0.5 2 . We used three language pairs for local vs global map translation experiments: English to German, English to Portuguese, and English to Swedish. The neighborhoods and their train/test splits are: en − de: medication(3,415/500), cities(2,083/500), and animals(990/500); en − pt: diseases(1,670/300), chemi- cals(1,279/300), and names(1,986/300); en − sv: flowers(1,537/200), insects(1,271/200), and names(1,416/200). The training and test data was obtained from subsets of Facebook AI MUSE lexicons <ref type="bibr">3</ref> For each of the neighborhoods, we evaluated translation accuracy both when using a locally trained map and when using a globally trained map. The difference is that the locally trained map is only trained using training data from the neigh- borhood, whereas the global map is trained using training data from the neighborhood but also from all other neighborhoods and more (˜10000 word pairs). That is, the training data for global maps is a superset of the local training data.</p><p>We trained all maps using linear transforma- tions. As we will show in our experiments, opti- mizing neural network mapping functions for this problem fails. This is a similar observation to prior work ( <ref type="bibr" target="#b26">Mikolov et al., 2013a;</ref><ref type="bibr" target="#b13">Conneau et al., 2018)</ref>  <ref type="bibr">1</ref> . More details on models and experimental settings are described in Sections 4 and 5. <ref type="figure" target="#fig_0">Figure 2</ref> shows that for various neighbor- hoods, translation accuracy is higher when we train neighborhood-specific maps than one single global map. These results are similar to ( <ref type="bibr" target="#b49">Zou et al., 2013</ref>) who then trained many local maps. While we could also proceed to train many local maps, this requires identifying optimal neighborhoods. It also requires gathering sufficient training data for each of the neighborhoods independently. In our proposed method, NORMA, we avoid learn- ing multiple maps, creating a single map, while modeling neighborhood information and promot- ing parameter sharing.</p><p>Overall, the results in <ref type="figure" target="#fig_0">Figure 2</ref> are an indicator neighborhood sensitivity in maps is useful. This would particularly be useful for distant languages where a single global map that is linear might not suffice since the underlying embedding structure for distant languages might differ more than those of related languages as depicted in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>In this section we introduce our model for learn- ing neighborhood sensitive maps, NORMA. Our approach jointly discovers neighborhoods while learning to translate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reconstructive Neighborhood Discovery</head><p>Inspired by work on sparse coding ( <ref type="bibr" target="#b23">Lee et al., 2007</ref>), we discover neighborhoods by learning a reconstructive dictionary. We would like to learn a dictionary of neighborhoods on the source lan- guage side. To learn this dictionary, we set up a re- construction objective, where for any given word embedding x i ∈ R d , where d is the dimension- ality of the word embeddings, we want to recon- struct x i using a linear combination of K neigh- borhoods. Let D ∈ R K×d be the neighborhood matrix, each row of D represents a d-dimensional vector which can be interpreted as representing the center of the neighborhood. Let X ∈ R N ×d be a set of N embedding vectors corresponding to words in the source language vocabulary <ref type="bibr">4</ref> . We can learn a reconstructive dictionary of K neighbor- hoods with the following objective:</p><formula xml:id="formula_1">D, V = arg min D,V ||X − VD|| 2 2</formula><p>(1) D ∈ R K×d is the learned dictionary of neighbor- hoods, K &gt; d and thus the dictionary is over- complete; V ∈ R N ×K are the learned neighbor- hood membership weights for X. While we use the squared loss, other loss functions can be used ( <ref type="bibr" target="#b23">Lee et al., 2007)</ref>. To encourage neighborhoods to be different from each other, one can impose an orthogonality constraint : ||DD T − I|| where I is the identity matrix. The reconstruction error with an orthogonality penalty is:</p><formula xml:id="formula_2">R(θ) = ||X − VD|| 2 2 + λ||DD T − I||<label>(2)</label></formula><p>Where λ is a hyperparameter which controls the contribution of the orthogonality constraint to the reconstruction error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Joint Neighborhood Discovery and Translation</head><p>Our approach ties neighborhood discovery to the word translation task. First, we obtain neighbor- hood 'factorized' representations by multiplying the input vector X by the dictionary of neighbor- hoods:</p><formula xml:id="formula_3">X N = XD T ,</formula><p>where X N ∈ R N ×K . Here again N refers to words in the source language vocabulary, English in the case of en − de translation. And K is the number of neighborhoods. Second, we obtain an intermediate representa- tion of the input, which contains both the original input X and the neighborhood 'factorized' repre- sentations of the input X N , through vector con- catenation as follows:</p><formula xml:id="formula_4">X I = [X N ; X],</formula><p>where</p><formula xml:id="formula_5">X I ∈ R N ×(K+d) .</formula><p>To get the final representation of the input, we project X I into a low-dimensional vector of the same size as the original input:</p><formula xml:id="formula_6">X F = X I W f ,</formula><p>where W f ∈ R (K+d)×d is a set of learned pa- rameters. And X F ∈ R N ×d is the resulting final representation.</p><p>We use these neighborhood sensitive represen- tation X F as the input for learning the mapping function W, instead of the original X. We ex- plore different ways for learning the mapping W: first a linear mapping, and second, a single layer neural network with a leaky rectified linear unit (leaky ReLU 5 ) non-linearity and a highway layer ( <ref type="bibr" target="#b39">Srivastava et al., 2015</ref>). As we will show in our experiments, training neural networks with more layers fails on this zero-shot learning problem.</p><p>For the linear map, the translationˆytranslationˆ translationˆy i is given by:</p><formula xml:id="formula_7">ˆ y linear i = Wx F i<label>(3)</label></formula><p>where x F i ∈ X F is the neighborhood sensitive representation of x i .</p><p>For the neural network map, using a single layer neural network, and a highway layer, the transla- tionˆytionˆ tionˆy i is given by:</p><formula xml:id="formula_8">h i = σ 1 (x F i W) t i = σ 2 (x F i W t ) ˆ y nn i = t i × h i + (1.0 − t i ) × x F i<label>(4)</label></formula><p>where σ 1 is a non-linearity. We use a leaky-ReLU non-linearity. σ 2 is the sigmoid function. W t is another set of parameters in addition to W.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Objective Function</head><p>We use the max-margin loss function to learn the parameters of the model:</p><formula xml:id="formula_9">L(θ) = m ∑ i=1 k ∑ j̸ =i max ( 0, γ + d(y i , ˆ y g i ) − d(y j , ˆ y g i ) ) ,<label>(5)</label></formula><p>Where y i is the true label; ˆ y g i is the prediction, which is eitherˆyeitherˆ eitherˆy linear i orˆyorˆ orˆy nn i . The goal of the max-margin loss function is to rank correct train- ing data pairs (x i , y i ) higher than incorrect pairs (x i , y j ) with a margin of at least γ. The margin γ is a hyper-parameter and the incorrect labels, y j are selected randomly such that j ̸ = i. k is the number of incorrect examples per training in- stance, and d(x, y) = (x−y) 2 is the distance mea- sure.</p><p>The joint neighborhood discovery and word translation objective is given by:</p><formula xml:id="formula_10">J(θ) = L(θ) + R(θ)<label>(6)</label></formula><p>The neighborhood discovery part of the objec- tive, R(θ), does not depend on availability of su- pervised data and only requires monolingual data on the source language side. Thus, we can dis- cover neighborhoods in an unsupervised manner on a large set of monolingual word embeddings, then initialize using this pre-trained D which is then jointly optimized with the translation part of the objective L(θ). Importantly, this also means that our method can work with unsupervised meth- ods for learning mapping functions such as those using adversarial training <ref type="bibr" target="#b6">(Barone, 2016;</ref><ref type="bibr" target="#b13">Conneau et al., 2018</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Evaluation</head><p>In this section, we study the following questions: How does NORMA compare to state-of-the-art methods for learning mapping functions between embedding spaces of different languages? We study this question in three settings: when trans- lating between distant languages, when translat- ing between related languages, and lastly, when translating between related languages but on rare words. Additionally, we ask the following ques- tion: are the neighborhoods learned by NORMA meaningful?</p><p>To study these questions, we carried out experi- ments on word translation from English to two dis- tant languages, a Slavic language (Russian), and a Sino-Tibetan language (Chinese). In addition, we carried out experiments on word translation be- tween related languages (English, French, German and Portuguese).  5,000/1,500 word pairs for train/test data. Unless specified, we use the train/test split provided by MUSE. Development sets: the MUSE dictionar- ies that we used are very large. They contain over 100,000 entries for most language pairs, we tuned our models on data that was not part of the train and test sets. We obtained pre-trained word embeddings from FastText ( <ref type="bibr" target="#b9">Bojanowski et al., 2017)</ref>. In Equation 2, we did not find it helpful to encourage neighbor- hoods to be different, thus we set λ = 0. We set the margin γ in Equation 5 to be γ = 0.4. For the dictionary of neighborhoods D in Equation 1, we set the number of neighborhoods K = 2, 000 6 . We use N = 50 batch size. We estimate model parameters using stochastic gradient descent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and Experimental</head><p>Methods Under Comparison. We compare variations of NORMA to several previously pro- posed methods for generating mapping functions. The methods compared are: (Artetxe et al., 2018a; <ref type="bibr" target="#b13">Conneau et al., 2018;</ref><ref type="bibr" target="#b36">Smith et al., 2017;</ref><ref type="bibr" target="#b46">Xing et al., 2015;</ref><ref type="bibr">Lazaridou et al., 2015;</ref><ref type="bibr" target="#b15">Faruqui and Dyer, 2014;</ref><ref type="bibr" target="#b26">Mikolov et al., 2013a</ref>). More detailed descriptions of these prior methods can be found in the related work section.</p><p>Our primary goal is to evaluate the quality of maps produced. While a number of prior work proposed various approaches for retrieval, which have been shown to improve accuracy by a few points, we compare all methods using the same re- trieval method, nearest neighbor. Thus, for (Con- neau et al., 2018), we report the results for the vari- ant of their method called: adv -Refine -NN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">English to Slavic and Sino Tibetan</head><p>State-of-the-art methods have mostly focused word translation evaluation on English to Latin languages or other nearby languages. ( <ref type="bibr" target="#b4">Artetxe et al., 2018a</ref>) performed experiments on en-es, en- de, en-it and en-fi, where concepts might still be organized in a relatively similar way. In <ref type="figure" target="#fig_0">(Con- neau et al., 2018)</ref>, the adversarial training method proposed was evaluated on Chinese, Russian, and Esperanto, but thorough comparison experiments to prior work on word translation were only per- formed on English to Italian.</p><p>We carried out en-ru and en-zh comparison ex- periments, and present the results in the second and third columns of <ref type="table">Table 1</ref>. The two state- of-of-the art methods (Artetxe et al., 2018a) and ( <ref type="bibr" target="#b13">Conneau et al., 2018)</ref> are significantly outper- formed by NORMA-Linear. On English to Rus- sian, NORMA-Linear achieves 50.33 precision 1, outperforming both (Artetxe et al., 2018a) <ref type="bibr" target="#b13">(Conneau et al., 2018)</ref>, as well as other methods. On English to Chinese, NORMA-Linear achieves 43.37 precision 1, again ahead of other meth- ods. The best performing variant of our method is NORMA-Linear. The neural networks with more than a single layer prove difficult to optimize for this problem, and produce accuracy of 0. This could be because the problem of cross-embedding space mapping is a zero-shot learning problem, which is much more difficult to train than a super- vised problem, the setting in which deep learning methods have thrived so far.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">English to Related Languages</head><p>We show experiments on English to related lan- guages in the last three columns of <ref type="table">Table 1</ref>. On these languages, indeed the most recently pro- posed methods <ref type="bibr" target="#b4">(Artetxe et al., 2018a;</ref><ref type="bibr" target="#b13">Conneau et al., 2018</ref>) produce the best performing maps. However, NORMA-Linear is only 2-3 points be- hind these methods. This in contrast to English to Chinese where both (Artetxe et al., 2018a) and ( <ref type="bibr" target="#b13">Conneau et al., 2018</ref>) are behind NORMA -Lin- ear, by more than 10 points.</p><p>A promising line of future work is to get NORMA-Linear to bridge the 2-3 point gap on related languages by exploring a best of both worlds approach, combining neighborhood sensi- tivity with the methods that achieve superior per- formance on nearby languages.  <ref type="table">Table 3</ref>: Performance for en-pt on rare words (RARE), and the en-pt MUSE dataset, which as shown in <ref type="figure" target="#fig_1">Figure  3</ref> contains a lot of frequent words. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Accuracy by Part-of-Speech</head><p>We assigned each word its majority part-of-speech by tagging the ClueWeb 7 corpus, which contains over 500 million webpages. We then evaluated translation precision of NORMA-Linear stratified by part-of-speech. The results are shown in Ta- ble 5 We found that, nouns and verbs make up about 80 percent of the MUSE test dictionaries, followed by adjectives (˜10%). We found that while nouns and verbs make up a large chunk of the test data, nouns are translated with much higher accuracy than verbs, except for English to Chinese. This finding will serve as a guide for fu- ture improvements to our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">English to Languages: Rare Words</head><p>We analyzed the frequency distribution of the MUSE dictionaries. To get word frequency infor- <ref type="table" target="#tab_1">Neighborhood  51  134  162  7  drugs  criminally  chuanyao  khoisan  zonisamide  judicature  chuanyan  bantu  cocaine  prosecutory  zhiang  sepedi  ritalin  derogation  thanong  otjiherero  hospitalized  restitutionary  qiangbing  ndebeles  pheniprazine  derogative  pengpeng  hereros  overdose  jailable  nguyan  otjinene  disorientation  extradition  yuning  shona  focusyn  sodomy  liheng  hutu  alfaxalone</ref> crimes thanong witotoan mation, we processed documents in the ClueWeb 7 corpus and recorded word occurrence frequency. We discovered that the MUSE dictionaries contain a lot of frequent words. The top half of <ref type="figure" target="#fig_1">Figure 3</ref> shows frequency counts of the en-pt MUSE test dictionary. For readability we only show bins up to occurrence frequency of 50,000. We see that only about 50/1500 in the MUSE en-pt test data are infrequent, the rest are frequent words, occur- ring more than 10,000 times in the ClueWeb cor- pus.</p><p>We therefore created another test set for en-pt from the rest of the MUSE data which is not part of the train or test data, with the goal of creating a train/test of rare words. The bottom half of <ref type="figure" target="#fig_1">Figure  3</ref> is a plot of frequency counts of train and test data for these rare words.</p><p>We then compared variations of NORMA to the best performing method on English to related languages, which is ( <ref type="bibr" target="#b4">Artetxe et al., 2018a</ref>). The comparison was done both on the regular MUSE test dataset for en-pt and the rare word dataset for en-pt. Since our method uses a max-margin loss much like ( <ref type="bibr">Lazaridou et al., 2015)</ref>, we also com- pare to ( <ref type="bibr">Lazaridou et al., 2015)</ref>. <ref type="table">Table 3</ref> shows that NORMA-Linear outper- forms ( <ref type="bibr" target="#b4">Artetxe et al., 2018a</ref>) by over 10 points on the RARE words dataset. On the regular MUSE dictionary, ( <ref type="bibr" target="#b4">Artetxe et al., 2018a</ref>) is ahead by about 5 points. On RARE, ( <ref type="bibr">Lazaridou et al., 2015)</ref> is behind NORMA-Linear by 9 points, whereas on the MUSE dictionary performance of <ref type="bibr">(Lazaridou et al., 2015)</ref> and NORMA-Linear is about the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Neighborhood Interpretability</head><p>NORMA jointly discovers neighborhoods while learning to translate words. We now ask if the dis- covered neighborhoods semantically make sense. We can answer this question since each neighbor- hood vector can be seen as a "center" vector rep- resenting the words in the neighborhood. Thus we can consider words whose cosine similarity to the neighborhood vector is greater than some threshold, to be members of that neighborhood. As we mentioned, we found that setting the to- tal number of neighborhoods to be discovered to K = 2, 000 provided the best results. Of these 2,000 we show some of them in <ref type="table" target="#tab_3">Table 4</ref> obtained when training en − de. For each neighborhood, we show 10 words that appear among the top 100 words of that neighborhood. It can be seen that the neighborhoods represent some kind of "topics". For example, neighborhood number 51 appears to represent drugs, and drug-related concepts; num- ber 132 contains justice and crime-related con- cepts; number 162 contains mostly Asian concepts and names, number 7 contains mostly African and names. We can see that the granularity of neigh- borhoods and their specificity varies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We propose neighborhood sensitive maps for learning multilingual word embeddings, NORMA. Our method is motivated by the fact that languages differ along dimensions such as vocabulary, grammar, written form, and syntax, and therefore one would expect that embedding spaces of different languages exhibit differ- ent structures especially for distant languages.</p><p>Our method jointly discovers neighborhoods while learning to translate words. Experimental evaluation showed that NORMA substantially outperforms state-of-the-art (SOTA) methods on distant languages, while only being a few points behind on related languages. A promising line of future work is to explore a best of both worlds ap- proach, combining neighborhood sensitivity with the methods that achieve superior performance on nearby languages. <ref type="bibr" target="#b13">Guillaume Lample, Ludovic Denoyer, and Marc'Aurelio Ranzato. 2018</ref>. Unsupervised machine translation using monolingual corpora only. In ICLR.</p><p>Angeliki Lazaridou, Georgiana Dinu, and Marco Ba- roni. 2015. Hubness and pollution: Delving into cross-space mapping for zero-shot learning. In ACL, pages 270-280.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Accuracy of globally vs locally trained mapping functions for various neighborhoods on en−de, en−pt, and en − sv translation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Top: Frequency distribution of MUSE dictionary test and train sets for en-pt. Bottom: Frequency distribution of the RARE words dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Setup. The Facebook AI MUSE 3 project (Conneau et al., 2018) pro- vides train/test data for bilingual dictionaries of various language pairs, we use this data in our experiments. The MUSE dictionaries consist of</figDesc><table>Method 
Slavic &amp; Sino-Tibetan 

en-ru 
en-zh 
en-de 
en-es 
en-fr 

NORMA-Linear 
50.33 
43.27 
68.50 
77.47 
76.10 

NORMA-Highway-NN 
49.27 
33.10 
67.33 
77.65 
75.50 

1 layer-NN 
49.13 
30.66 
66.80 
77.60 
75.53 

2 layer-NN 
0 
0 
0 
0 
0 

1 layer-Highway-NN 
49.50 
30.91 
67.00 
77.50 
75.60 

2 layer-Highway-NN 
0 
0 
0 
0 
0 

Artetxe et al . 2018 
47.93 
20.4 
70.13 
79.6 
79.30 

Conneau et al. 2018 
37.30 
30.90 
71.30 
79.10 
78.10 

Smith et al. 2017 
46.33 
39.60 
69.20 
78.80 
78.13 

Xing et al. 2015 
44.50 
41.0 
67.07 
77.33 
75.47 

Lazaridou et al. 2015 
48.27 
29.60 
68.20 
77.60 
75.86 

Faruqui and Dyer (2014) 
35.47 
32.20 
55.67 
72.33 
69.27 

Mikolov et al. 2013 
42.47 
19.80 
60.07 
74.20 
71.60 

Table 1: Precision at 1 comparison of NORMA to previously proposed mapping functions. We used FAIR/MUSE 
word translation lexicons train/test splits. 

en-ru 
en-zh 
en-de 
en-es 
en-fr 
NOUN 
42% /55.1 
42% /42.1 
39% /74.6 
40% /82.3 
42% /80.0 
VERB 
41% /47.3 
39% /47.6 
38% /64.4 
40% /71.6 
41% /70.0 
ADJECTIVE 
10% /34.4 
11% /38.7 
10% /56.1 
9% /76.9 
10% /71.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Part-of-Speech (POS) distributions of the MUSE test sets. Listed are the top 3 parts of speech, which 
account for˜90%for˜90% of the test data for all language pairs. X% /Y means the POS tag makes up X% of the test set, 
with accuracy Y. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Sample neighborhoods discovered by NORMA during en-de translation: 51 appears to represent drugs, 
132: justice and crime; 162: Asian names, 7 : African names. 

</table></figure>

			<note place="foot" n="2"> We found a 0.5 cutoff to be a good compromise between neighborhood purity, and size. However, our final method (Section 4) on which all our comparison experiments were based, automatically discovers neighborhoods based on ideas from sparse coding. 3 https://github.com/facebookresearch/ MUSE</note>

			<note place="foot" n="4"> Since the vocabulary size can be very large, in our experiments, we work in batches of N=50</note>

			<note place="foot" n="5"> It outperformed other non-linearities such as tanh in our initial experiments.</note>

			<note place="foot" n="6"> We carried out experiments using different neighborhood sizes, and consistently found K ≈ 2000 to outperform other choices.</note>

			<note place="foot" n="7"> https://www.lemurproject.org/ clueweb09.php/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Raphael Flauger for useful discussions, and the anonymous reviewers for their construc-tive comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised word mapping using structural similarities in monolingual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanan</forename><surname>Aldarmaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahesh</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="185" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Massively multilingual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno>abs/1602.01925</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning principled bilingual mappings of word embeddings while preserving monolingual invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gorka</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2289" to="2294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning bilingual word embeddings with (almost) no bilingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gorka</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalizing and improving bilingual word embedding mappings with a multi-step framework of linear transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gorka</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gorka</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards crosslingual distributed representations without parallel text trained with adversarial autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio Valerio Miceli</forename><surname>Barone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1st Workshop on Representation Learning for NLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Does the language i speak influence the way i think</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Betty</forename><surname>Birner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multilingual distributed representations without word alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl Moritz</forename><surname>Hermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">How language shapes thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lera</forename><surname>Boroditsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<biblScope unit="volume">304</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="62" to="65" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An autoencoder approach to learning bilingual word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Sarath Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Lauly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaraman</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vikas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrita</forename><surname>Raykar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1853" to="1861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Linguistic distance: A quantitative measure of the distance between english and other languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul W</forename><surname>Chiswick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multilingual and Multicultural Development</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jégou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Word translation without parallel data</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Improving zero-shot learning by mitigating the hubness problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6568</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving vector space word representations using multilingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="462" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bilbowa: Fast bilingual distributed representations without word alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="748" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Simple task-specific bilingual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1386" to="1390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cross-lingual dependency parsing based on distributed representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1234" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning bilingual lexicons from monolingual corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="771" to="779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inducing crosslingual distributed representations of words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binod</forename><surname>Bhattarai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1459" to="1474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">`</forename><surname>Kočisk`y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.0947</idno>
		<title level="m">Learning bilingual word representations by marginalizing alignments</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning a translation lexicon from monolingual corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Workshop on Unsupervised Lexical Acquisition</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient sparse coding algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajat</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="801" to="808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning small-size dnn with outputdistribution-based criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jui-Ting</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1910" to="1914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep multilingual correlation for improved word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="250" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno>abs/1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Predicting human brain activity associated with the meanings of nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><forename type="middle">V</forename><surname>Tom M Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Shinkareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Min</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><forename type="middle">Adam</forename><surname>Robert A Mason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Just</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="issue">5880</biblScope>
			<biblScope unit="page" from="1191" to="1195" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Characterizing departures from linearity in word translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ndapa</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Flauger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Knowledge distillation for bilingual dictionary induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ndapandula</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Flauger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2487" to="2496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Automatic identification of word translations from unrelated english and german corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Rapp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Nonlinear dimensionality reduction by locally linear embedding. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence K</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning cross-lingual word embeddings via matrix co-factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd</title>
		<meeting>the 53rd</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<imprint>
			<publisher>Short Papers</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="567" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Offline bilingual word vectors, orthogonal transformations and the inverted softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Turban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><forename type="middle">Y</forename><surname>Hamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hammerla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Inverted indexing for cross-lingual NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeljko</forename><surname>Agic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Héctor Martínez Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johannsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1713" to="1722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">On the limitations of unsupervised bilingual dictionary induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh Kumar</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">Highway networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Cross-lingual word clusters for direct transfer of linguistic structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="477" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">From frequency to meaning: Vector space models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res. (JAIR)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cross-lingual models of word embeddings: An empirical comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">On the role of seed lexicons in learning bilingual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vulic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Bilingual word embeddings from non-parallel documentaligned data applied to bilingual lexicon induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vulic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="719" to="725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning translations via matrix completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Derry Tanti Wijaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marianna</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Apidianaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1452" to="1463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Normalized word embedding and orthogonal transform for bilingual word translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiye</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1006" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Adversarial training for unsupervised bilingual lexicon induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1959" to="1970" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning translation models from monolingual continuous representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1527" to="1536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Bilingual word embeddings for phrase-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Will</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1393" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
