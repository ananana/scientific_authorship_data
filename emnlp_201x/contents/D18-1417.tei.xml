<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Self-Attentive Model with Gate Mechanism for Spoken Language Understanding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changliang</forename><surname>Li</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Li</surname></persName>
							<email>liliang17@mails.tsinghua.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Qi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Kingsoft AI Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Self-Attentive Model with Gate Mechanism for Spoken Language Understanding</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3824" to="3833"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3824</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Spoken Language Understanding (SLU), which typically involves intent determination and slot filling, is a core component of spoken dialogue systems. Joint learning has shown to be effective in SLU given that slot tags and intents are supposed to share knowledge with each other. However, most existing joint learning methods only consider joint learning by sharing parameters on surface level rather than semantic level. In this work, we propose a novel self-attentive model with gate mechanism to fully utilize the semantic correlation between slot and intent. Our model first obtains intent-augmented embeddings based on neural network with self-attention mechanism. And then the intent semantic representation is utilized as the gate for labelling slot tags. The objectives of both tasks are optimized simultaneously via joint learning in an end-to-end way. We conduct experiment on popular benchmark ATIS. The results show that our model achieves state-of-the-art and outperforms other popular methods by a large margin in terms of both intent detection error rate and slot filling F1-score. This paper gives a new perspective for research on SLU.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One long-term goal in artificial intelligence field is to build an intelligent human-machine dialogue system, which is capable of understanding hu- man's language and giving smooth and correct re- sponses. A typical dialogue system is designed to execute the following components: (i) automatic speech recognition converts a spoken query into transcription, (ii) spoken language understanding component analyzes the transcription to extract se- mantic representations, (iii) dialogue manager in- terprets the semantic information and decides the best system action, according to which the system response is further generated either as a natural language output <ref type="bibr" target="#b12">(Jurafsky, 2000)</ref>.</p><p>In this paper, we focus on spoken language un- derstanding which is a core component of a spo- ken dialogue system. It typically involves two ma- jor tasks, intent determination and slot filling. In- tent determination aims to automatically identify the intent of the user as expressed in natural lan- guage. Slot filling aims to extract relevant seman- tic constituents from the natural language sentence towards achieving a goal.</p><p>Usually, intent detection and slot filling are car- ried out separately. However, separate modeling of these two tasks is constrained to take full ad- vantage of all supervised signals. Joint learning of intent detection and slot filling is worthwhile for three reasons. Firstly, the two tasks usually appear simultaneously in SLU systems. Secondly, the in- formation of one task can be utilized in the other task to promote each other and a joint prediction can be made <ref type="bibr" target="#b41">(Zhang and Wang, 2016)</ref>. For exam- ple, if the intent of a utterance is to find a flight, it is likely to contain the departure and arrival cities, and vice versa. Lastly, slot tags and intents, as semantics representations of user behaviours, are supposed to share knowledge with each other.</p><p>Recently, joint model for intent detection and slot filling has achieved much progress. ( <ref type="bibr" target="#b35">Xu and Sarikaya, 2013)</ref> proposed using CNN based trian- gular CRF for joint intent detection and slot fill- ing. ( <ref type="bibr" target="#b6">Guo et al., 2014</ref>) proposed using a recursive neural network that learns hierarchical represen- tations of the input text for the joint task. ( <ref type="bibr" target="#b19">Liu and Lane, 2016b</ref>) describes a recurrent neural net- work (RNN) model that jointly performs intent de- tection, slot filling and language modeling. The neural network models keep updating the intent prediction as word in the transcribed utterance ar- rives and uses it as contextual features in the joint model.</p><p>In this work, we propose a novel model for joint intent determination and slot filling by intro- ducing self-attention and gating mechanism. Our model can fully utilize the semantic correlation be- tween slot and intent. To the best of our knowl- edge, this is the first attempt to utilize intent- augmented embedding as a gate to guide the learn- ing of slot filling task. To fully evaluate the ef- ficiency of our model, we conduct experiment on Airline Travel Information Systems (ATIS) dataset ( <ref type="bibr" target="#b10">Hemphill et al., 1990)</ref>, which is popularly used as benchmark in related work. And empirical results show that our independent model outper- forms the previous best result by 0.54% in terms of F1-score on slot filling task, and gives excel- lent performance on intent detection task. Our joint model further promotes the performance and achieves state-of-the-art results on both tasks. The rest of our paper is structured as follows: Section 2 discusses related work, Section 3 gives a detailed description of our model, Section 4 presents experiments results and analysis, and Section 5 summarizes this work and the future di- rection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There is a long research history for spoken dia- logue understanding, which emerged in the 1990s from some call classification systems ( <ref type="bibr" target="#b5">Gorin et al., 1997</ref>) and the ATIS project. In this section, we de- scribe some typical works on intent classification and slot-filling, which are both core tasks of SLU <ref type="bibr" target="#b3">(De Mori, 2007</ref>).</p><p>For intent detection task, the early traditional method is to employ n-grams as features with generic entities, such as locations and dates <ref type="bibr" target="#b41">(Zhang and Wang, 2016)</ref>. This type of method is restricted to the dimensionality of the input space. Another line of popular approaches is to train machine learning models on labeled training data <ref type="bibr" target="#b39">(Young, 2002;</ref><ref type="bibr" target="#b8">Hahn et al., 2011</ref>). For ex- ample, SVM <ref type="bibr" target="#b7">(Haffner et al., 2003)</ref> and Adaboost <ref type="bibr" target="#b26">(Schapire and Singer, 2000</ref>) have been explored to improve intent detection. Approaches based on neural network architecture have shown good per- formance on intent detection task. Deep belief net- works (DBNs) have been first used in call routing classification <ref type="bibr" target="#b4">(Deoras and Sarikaya, 2013)</ref>. More recently, RNNs have shown excellent performance on the intent classification task <ref type="bibr" target="#b24">(Ravuri and Stolcke, 2015)</ref>. For slot-filling task, traditional approaches are based on conditional random fields (CRF) archi- tecture, which has strong ability on sequence la- belling <ref type="bibr" target="#b25">(Raymond and Riccardi, 2007)</ref>. Recently, models based on neural network and its extensions have shown excellent performance on the slot fill- ing task and outperform traditional CRF models. For example, ( <ref type="bibr" target="#b38">Yao et al., 2013)</ref> proposed to take words as input in a standard recurrent neural net- work language model, and then to predict slot la- bels rather than words on the output side. ( <ref type="bibr" target="#b37">Yao et al., 2014b</ref>) improved RNNs by using transition features and the sequence-level optimization cri- terion of CRF to explicitly model dependencies of output labels. ( <ref type="bibr" target="#b21">Mesnil et al., 2013</ref>) tried bi- directional and hybrid RNN to investigate using RNN for slot filling. ( <ref type="bibr" target="#b36">Yao et al., 2014a</ref>) introduced LSTM architecture for this task and obtained a marginal improvement over RNN. Besides, fol- lowing the success of attention based models in the NLP field, ( <ref type="bibr" target="#b27">Simonnet et al., 2015</ref>) applied the attention-based encoder-decoder to the slot filling task, but without LSTM cells.</p><p>Recently, there has been some work on learn- ing intent detection and slot filling jointly ex- ploited by neural networks. Slot labels and in- tents, as semantics of user behaviors, are supposed to share knowledge with each other. ( <ref type="bibr" target="#b6">Guo et al., 2014</ref>) adapted recursive neural networks (RNNs) for joint training of intent detection and slot fill- ing. ( <ref type="bibr" target="#b35">Xu and Sarikaya, 2013</ref>) described a joint model for intent detection and slot filling based on convolutional neural networks (CNN). The pro- posed architecture can be perceived as a neural network version of the triangular CRF model <ref type="bibr">(TriCRF)</ref>. <ref type="bibr" target="#b9">(Hakkani-Tür et al., 2016)</ref> proposed a sin- gle recurrent neural network architecture that in- tegrates the three tasks (domain detection, intent detection and slot filling for multiple domains) in a model. ( <ref type="bibr" target="#b18">Liu and Lane, 2016a)</ref> proposed an attention-based neural network model for joint in- tent detection and slot filling. Their joint model got the best performance of 95.98% slot filling F1-score and 1.57% intent error rate in the ATIS dataset.</p><p>Despite the great progress those methods have achieved, it is still a challenging and open task for intent detection and slot filling. Therefore, we are motivated to design a powerful model, which can improve the performance of SLU systems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>In this section, we present our model for the joint learning of intent detection and slot filling. <ref type="figure" target="#fig_0">Figure  1</ref> gives an overview of our model. The first layer maps input sequence into vec- tors by concatenating its word-level embeddings and character-level embeddings (obtained by con- volution). And we use these vectors as merged embeddings in downstream layers. In many situa- tions, contextual information is useful in sequence labelling. In this paper, we introduce an approach that leverages context-aware features at each time step. In particular, we make use of self-attention to produce context-aware representations of the embeddings. Then a bidirectional recurrent layer takes as input the embeddings and context-aware vectors to produce hidden states. In the last step, we propose to exploit the intent-augmented gat- ing mechanism to match the slot label. The gate for a specific word is obtained by taking a linear transformation of the intent embedding and an- other contextual representation of this word com- puted by self-attention. We apply element-wise dot-product between the gate and each BiLSTM output.</p><p>Finally, a softmax layer is added to classify the slot labels on top of the gate layer. For simplic- ity, we only take the weighted average of BiLSTM outputs to predict the intent label.</p><p>The design of this structure is motivated by the effectiveness of multiplicative interaction among vectors and by self-attention mechanism which has been used successfully in a variety of tasks ( <ref type="bibr" target="#b2">Cheng et al., 2016;</ref><ref type="bibr" target="#b33">Vaswani et al., 2017;</ref><ref type="bibr" target="#b16">Lin et al., 2017)</ref>. It also typically corresponds to our finding that the intent is highly correlated with slot label in some cases, so the semantics of intent should be useful for detecting the slot labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Embedding Layer</head><p>We first convert the indexed words w = (w 1 , w 2 , ..., w T ) to word-level embeddings</p><formula xml:id="formula_0">E w = [e w 1 , e w 2 , ..., e w T ]</formula><p>, and character-level embeddings</p><formula xml:id="formula_1">E c = [e c 1 , e c 2 , ..., e c T ]</formula><p>. Although word embed- dings are sufficient for many NLP task, pro- vided by a well-pretrained glove 1 or word2vec 2 , character-level information provides some more prior knowledge (e.g. morphemes) to the embed- ding learning procedure. Some morphemic corre- lated words are more close in vector space, which is useful for identifying the slot labels. Character embeddings also alleviate the out-of-vocabulary (OOV) problem in the testing phase. In this pa- per we focus on a character-aware convolution layer used in ( <ref type="bibr" target="#b13">Kim et al., 2016</ref>) for words. The character-level embeddings are generated by con- volution over characters in the word with multiple window size to extract n-gram features.</p><p>Let C be the vocabulary of characters, V be the vocabulary of words. The dimensions of character-level embedding and word-level embed- ding are denoted as d c and d w , respectively. For each word w t ∈ V, characters in w t constitute the matrix C t ∈ R dc×l , where the columns cor- responds to l character embeddings.</p><p>A narrow convolution is applied between C t and a filter (or kernel) H ∈ R dc×w . Here we sup- pose the filter width is w. After that, we obtain a feature map f t ∈ R l−w+1 by adding a nonlinearity activation. The final n-gram features is generated by taking the max-over-time:</p><formula xml:id="formula_2">f t [i] = relu(H · C t [:, i : i + w − 1] + b) (1) c t = max i f t [i]<label>(2)</label></formula><p>where</p><formula xml:id="formula_3">C t [:, i : i + w − 1]</formula><p>is the i-to-(i+w-1)-th column of C t , and the character-level embedding e c t is made up of multiple c t generated by different convolution kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Self-Attention</head><p>Attention mechanism is usually used to guide the forming of sentence embedding, extra knowledge is also used to weigh the CNN or LSTM hidden states (i.e. document words sometimes attend to question information). However in slot filling task, the input to our model is just one sequence. So the attention mechanism used here is called self- attention, that is to say, the word at each time step attends to the whole words in this sentence. And it helps to determine which region is likely to be a slot. Since the embedding at each time step con- sists of multiple parts (i.e. word embedding and character embeddings of different kernel width), each part has its own semantic meaning. As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, we divide the embedding into mul- tiple parts and the attention of each part is pro- cessed within its corresponding dimension. In this approach, we restrict the interaction among differ- ent aspects of the embedding. We hypothesize that different semantic parts are relatively independent and play different roles in our network.</p><p>Suppose  is to encode each hidden vector into a context- aware representation. We achieve that by using attention over all the sentence hidden vectors M . Firstly, We linearly map all the vectors in M to three feature spaces by different projection param- eters W a , W b and W c , so the resulting vectors are expressed as M a , M b and M c with the same shape as M . These matrices are shared across all time steps. Considering the structure of embed- ding which consists of K different parts (we use 4 kinds of embeddings with the same dimension), these transformed matrices are equally split into K parts. Furthermore, the attention weight is com- puted by dot product between M a and M b . Lastly, the attention output is a weighted sum of M c . Specifically, we consider different K parts in detail for k = 1, .., K:</p><formula xml:id="formula_4">  M a M b M c   =   W a M W b M W c M   (3) α k,t = softmax(m T k,a,t M k,b )<label>(4)</label></formula><formula xml:id="formula_5">S-Att(m t , M ) = [M 1,c α T 1,t , ..., M K,c α T K,t ]<label>(5)</label></formula><p>where M k,a ∈ R (dm/K)×T is the k-th part of M a which is transformed from M by W a . Index t is word position ranging over T time steps and m k,a,t ∈ R dm/K is the t-th column of M k,a . α k,t is the attention weights over M k,c . The output of self-attention module generated at time step t is the concatenation of K parts by using Equation 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">BiLSTM</head><p>Character embeddings and word embeddings are both important features in our task. To further uti- lize these features, we associate each embedding with a context-aware representation which is typ- ically implemented by self-attention mechanism. For current word w t , the input of the recurrent layer at time step t is represented as x t :</p><formula xml:id="formula_6">e a t = S-Att([e c t , e w t ], E) (6) x t = [e c t , e w t , e a t ]<label>(7)</label></formula><p>e a t is the context-aware vector of w t which is obtained by applying self-attention mechanism on the concatenated embeddings E = [e c 1 e w 1 , ..., e c T e w T ] . It was difficult to train RNNs to capture long- term dependencies because the gradients tend to either vanish or explode. Therefore, some more sophisticated activation functions with gating units were designed. We use LSTM <ref type="bibr" target="#b11">(Hochreiter and Schmidhuber, 1997</ref>) in this work:</p><formula xml:id="formula_7">i t = σ(W i x t + U i h t−1 + b i ) (8) f t = σ(W f x t + U f h t−1 + b f ) (9) o t = σ(W o x t + U o h t−1 + b o )<label>(10)</label></formula><formula xml:id="formula_8">c t = tanh(W c x t + U c h t−1 + b c ) (11) c t = i t c t + f t c t−1 (12) h t = o t tanh(c t )<label>(13)</label></formula><p>Where denotes element-wise product of two vectors. To consider both the previous history and the future history, we use BiLSTM as encoder in advance. The bi-directional LSTM (BiLSTM), a modification of the LSTM, consists of a forward and a backward LSTM. The encoder reads the in- put vectors x = (x 1 , x 2 , ..., x T ) and generates T hidden states by concatenating the forward and backward hidden states of BiLSTM:</p><formula xml:id="formula_9">− → h t = −−−−→ LST M (x t , − → h t−1 ) (14) ← − h t = ←−−−− LST M (x t , ← − h t+1 )<label>(15)</label></formula><formula xml:id="formula_10">h t = [ − → h t , ← − h t ]<label>(16)</label></formula><p>where ← − h t is the hidden state of backward pass in BLSTM and − → h t is the hidden state of forward pass in BLSTM at time t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Intent-Augmented Gating Mechanism</head><p>As described above, intent information is useful for slot filling task. To measure the probability of words in target slots and attend to the ones relevant to the intent, we add a gate to the out- put of BiLSTM layer. Let H ∈ R 2d×T be a matrix consisting of hidden vectors [h 1 , ..., h T ] produced by BiLSTM. For each word, we use self-attention mechanism to form another context- aware representation, the gate vector h * t is calcu- lated by linearly transforming the concatenation of the context-aware representation and the intent embedding vector v int with a multi-layer percep- tron (MLP) network. The intent label is provided by correct label during training phase, and by the output from intent classification layer in the test phase. Specifically, for t = 1, ...T :</p><formula xml:id="formula_11">s t = Self-Attention(h t , H)<label>(17)</label></formula><formula xml:id="formula_12">h * t = MLP([s t , v int ]) (18) o t = h t h * t (19)</formula><p>We use element-wise multiplication to model the interaction between BiLSTM outputs and the gate vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Task Learning</head><p>The bidirectional recurrent layer converts a se- quence of words w = (w 1 , w 2 , ..., w T ) into hid- den states H = [h 1 , ..., h T ] which are shared by two tasks. We use simple attention pooling func- tion denoted as f att over H to get an attention-sum vector for intent label classification. The classified label y int is transformed to an embedding v int by matrix E int for gate computing.</p><formula xml:id="formula_13">h int = f att (H)<label>(20)</label></formula><formula xml:id="formula_14">y int = softmax(W int h int + b int )<label>(21)</label></formula><p>During the training phase, model parameters are updated w.r.t. a cross-entropy loss between the predicted probabilities and the true label. The la- bel with maximum probability will be selected as the predicted intent during the testing phase. For another task, the hidden states processed by our gating layer are used for predicting slot labels.</p><formula xml:id="formula_15">y slot t = softmax(W slot o t + b slot )<label>(22)</label></formula><p>Slot filling can be defined as a sequence labelling problem which is to map a utterance sequence w = (w 1 , ..., w T ) to its corresponding slot label sequence y = (y 1 , ..., y T ). The objective is to maximize the likelihood of a sequence:</p><formula xml:id="formula_16">P (y slot |w) = T t=1 P (y slot t |w)<label>(23)</label></formula><p>It is equal to minimize Negative Log-likelihood (NLL) of the correct labels for the predicted se- quence y slot .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>In order to evaluate the efficiency of our proposed model, we conduct experiments on ATIS (Air- line Travel Information Systems) dataset, which is widely used as benchmark in SLU research <ref type="bibr" target="#b23">(Price, 1990)</ref>. <ref type="figure" target="#fig_3">Figure 3</ref> gives one example of sentence in ATIS dataset. The words are labelled with their value ac- cording to certain semantic frames. The slot labels of the words are represented in an In-Out-Begin (IOB) format and the intent is highlighted with a box surrounding it.  In this paper, we use the ATIS corpus set- ting following previous related works ( <ref type="bibr" target="#b18">Liu and Lane, 2016a;</ref><ref type="bibr" target="#b20">Mesnil et al., 2015;</ref><ref type="bibr" target="#b17">Liu and Lane, 2015;</ref><ref type="bibr" target="#b35">Xu and Sarikaya, 2013;</ref><ref type="bibr" target="#b30">Tur et al., 2010)</ref>. The training set contains 4978 utterances from ATIS-2 and ATIS-3 datasets, and test set contains 893 utterances from ATIS-3 NOV93 and DEC94 datasets. The number of slot labels is 127 and the intent has 18 different types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Metrics</head><p>The performance of slot filling task is measured by the F1-score, while intent detection task is evalu- ated with prediction error rate that is the ratio of the incorrect intent of the test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training Details</head><p>We preprocess the ATIS following <ref type="bibr" target="#b38">(Yao et al., 2013;</ref><ref type="bibr" target="#b18">Liu and Lane, 2016a</ref>). To deal with unseen words in the test set, we mark those words that ap- pear only once in the training set as UNK, and use this label to represent those unseen words in the test set. Besides, each number is converted to the string DIGIT.</p><p>The model is implemented in the Tensorflow framework ( <ref type="bibr" target="#b0">Abadi et al., 2016)</ref>. At training stage, we use LSTM cell as suggested in <ref type="bibr" target="#b29">(Sutskever et al., 2014</ref>) and the cell dimension d is set to be 128 for both the forward and backward LSTM.</p><p>We set the dimension of word embedding d w to be 64 and the dimension of character embed- ding d c to be 128. We generate three character- level embeddings using multiple widths and filters (the convolution kernel width w ∈ {2, 3, 4} with 64 filters each) followed by a max pooling layer over time. Then, the dimension of concatenated embeddings is 256. We make the dimensions of each parts equal for the convenience of dimension splitting during the self-attention in later stage. All the parameters in the network are randomly initial- ized with uniform distribution <ref type="bibr" target="#b28">(Sussillo and Abbott, 2014</ref>) which are fine-tuned during training. We use the stochastic gradient descent algorithm (SGD) for updating parameters. And the learning rate is controlled by Adam algorithm <ref type="bibr" target="#b14">(Kingma and Ba, 2014</ref>). The model is trained on all the train- ing data with mini-batch size of 16. In order to enhance our model to generalize well, the maxi- mum norm for gradient clipping is set to 5. We also apply layer normalization ( <ref type="bibr">Ba et al., 2016</ref>) on the self-attention layer after we add a residul con- nection between the output and input. Meanwhile, dropout rate 0.5 is applied on recurrent cell pro- jection layer ( <ref type="bibr">Zaremba et al., 2014</ref>) and on each attention activation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Independent Learning</head><p>The results of separate training for slot filling and intent detection are reported in <ref type="table" target="#tab_2">Table 1 and Table 2</ref> respectively. On the independent slot filling task, we fixed the intent information as the ground truth labels in the dataset. But on the independent in- tent detection task, there is no interaction with slot labels. <ref type="table" target="#tab_2">Table 1</ref> compares F1-score of slot filling be- tween our proposed architecture and some previ- ous works. Our model achieves state-of-the-art results and outperforms previous best model by 0.56% in terms of F1-score. We attribute the im- provement of our model to the following reasons: 1) The attention used in ( <ref type="bibr" target="#b18">Liu and Lane, 2016a</ref>) is vanilla attention, which is used to compute the de-Methods F1-score CRF <ref type="bibr" target="#b21">(Mesnil et al., 2013)</ref> 92.94 simple RNN ( <ref type="bibr" target="#b38">Yao et al., 2013)</ref> 94.11 CNN-CRF ( <ref type="bibr" target="#b35">Xu and Sarikaya, 2013)</ref> 94.35 LSTM ( <ref type="bibr" target="#b38">Yao et al., 2013)</ref> 94.85 RNN-SOP ( <ref type="bibr" target="#b17">Liu and Lane, 2015)</ref> 94.89 Deep LSTM ( <ref type="bibr" target="#b38">Yao et al., 2013)</ref> 95.08 RNN-EM ( <ref type="bibr" target="#b22">Peng et al., 2015)</ref> 95.25 Bi-RNN with Ranking Loss ( <ref type="bibr" target="#b34">Vu et al., 2016</ref>  coding states. It is not suitable for our model since the embeddings are composed of several parts. Self-attention allows the model to attend to infor- mation jointly from different representation parts, so as to better understand the utterance. 2) intent- augmented gating layer connects the semantics of sequence slot labels, which captures complex in- teractions between the two tasks. <ref type="table" target="#tab_3">Table 2</ref> compares the performance of our pro- posed model to previously reported results on in- tent detection task. Our model gives good per- formance in terms of classification error rate, but not as good as Attention Encoder-Decoder (with aligned inputs) method (Liu and Lane, 2016a). As their published state-of-the-art result described in (Liu and Lane, 2016a), their attention-based model is based on word-level embeddings. While in our model, we introduce character-level embed- dings to improve the performance of joint learn- ing. But independent learning for intent classifi- cation aims at capturing the global information of an utterance, not caring much about the details of specific word. The character-level embeddings in- troduced in our model bring very little hurt to inde- pendent learning of intent detection, as a trade-off in performance between both criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Joint Learning</head><p>We compare our model against the following base- line models based on joint learning:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Error(%) Recursive NN ( <ref type="bibr" target="#b6">Guo et al., 2014)</ref> 4.60 Boosting ( <ref type="bibr" target="#b30">Tur et al., 2010)</ref> 4.38 Boosting + Simplified sentences <ref type="bibr" target="#b32">(Tur et al., 2011)</ref> 3.02</p><p>Attention Enc-Dec ( <ref type="bibr" target="#b18">Liu and Lane, 2016a)</ref> 2.02</p><p>Our Model 2.69  • Recursive NN: (Guo et al., 2014) employed recursive neural networks for joint training of two tasks.</p><p>• Recursive NN + Viterbi: <ref type="bibr" target="#b6">(Guo et al., 2014</ref>) applied the Viterbi algorithm on Recursive NN to improve the result on slot filling.</p><p>• Attention Enc-Dec: (Liu and Lane, 2016a) proposed Attention Encoder-Decoder (with aligned inputs) which introduced context vector as the explicit aligned inputs at each decoding step.</p><p>• Attention BiRNN: (Liu and Lane, 2016a) introduced attention to the alignment-based RNN sequence labeling model. Such atten- tion provides additional information to the in- tent classification and slot label prediction.  achieves better results than separate learning. It can be interpreted that the two tasks are highly cor- related and boost the performance each other. The slot filling task enables the model to learn more meaningful representations which give more su- pervisory signals for the learning of shared param- eters. Similarly, intent is also useful to determine the slot label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Ablation Study</head><p>The ablation study is performed to evaluate whether and how each part of our model con- tributes to our full model. To further evaluate the advances of our gating architecture for joint learn- ing, we ablate some techniques used in our model. We ablate three important components and con- duct different approaches in this experiment. Note that all the variants are based on joint learning with intent-augmented gate:</p><p>• W/O char-embedding, where no character embeddings are added to the embedding layer. The embedding layer is composed of word embeddings only.</p><p>• W/O self-attention, where no self-attention is modelled after the embedding layer and in the intent-augmented gating layer. The intent gate is computed by the output of BiLSTM and intent embedding.</p><p>• W/O attention-gating, where no self- attention mechanism is performed in the intent-augmented gating layer. The gate is computed by the output of BiLSTM and intent embedding. But we still use the self-attention on top of embedding layer to augment the context information. <ref type="table" target="#tab_6">Table 4</ref> shows the joint learning performance of our model on ATIS data set by removing one mod- ule at a time. We find that all variants of our model perform well based on our gate mechanism. As listed in the table, all features contribute to both slot filling and intent classification task. If we remove the self-attention from the holistic model or just in the intent-augmented gating layer, the performance drops dramatically. The result can be interpreted that self-attention mechanism computes context representation separately and enhances the interaction of features in the same as- pect. We can see that self-attention does improve performance a lot in a large scale, which is consis- tent with findings of previous work <ref type="bibr" target="#b33">(Vaswani et al., 2017;</ref><ref type="bibr" target="#b16">Lin et al., 2017)</ref>.</p><p>If we remove character-level embeddings and only use word-level embeddings, we see 0.22% drop in terms of F1-score. Though word-level em- beddings represent the semantics of each word, character-level embeddings can better handle the out-of-vocabulary (OOV) problem which is essen- tial to determine the slot labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose a novel self-attentive model gated with intent for spoken language un- derstanding. We apply joint learning on both intent detection and slot filling tasks. In our model, self-attention mechanism is introduced to better represent the semantic of utterance, and gate mechanism is introduced to make full use of the semantic correlation between slot and intent. Ex- periment results on ATIS dataset have shown effi- ciency of our model and outperforms the state-of- the-art approach on both tasks. Besides, our model also shows consistent performance gain over the independent training models. In future works, we plan to improve our model by introducing extra knowledge.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of our proposed model for joint intent detection and slot filling. Red arrows represent the intent classification task based on the weighted average of BiLSTM outputs. The embeddings coloured with different intensity values denote word-level and char-level embeddings (three kinds of convolution kernels).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The structure of self-attention layer. Red coloured rectangles stand for matrices which map the input to different subspaces. These transformed vectors are divided into multiple parts for computing selfattention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example of sentence annotated by slots sampled from ATIS corpus, the black boxed word indicates the intent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Results of independent training for slot filling 
in terms of F1-score. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results of independent training for intent de-
tection in terms of error rate. 

Methods 
F1 
Error(%) 
Recursive NN (Guo et al., 
2014) 

93.22 
4.60 

Recursive 
NN+Viterbi 
(Guo et al., 2014) 

93.96 
4.60 

Attention Enc-Dec (Liu 
and Lane, 2016a) 

95.87 
1.57 

Attention BiRNN (Liu 
and Lane, 2016a) 

95.98 
1.79 

Our Model 
96.52 
1.23 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results of joint training for slot filling and 
intent detection. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 compares</head><label>3</label><figDesc>our joint model with reported results from previous works. We can see that our model achieves state-of-the-art results and outper- forms previous best result by 0.54% in terms of F1-score on slot filling, and by 0.34% in terms of error rate on intent detection. This improvement is statistically significant. Besides, the joint learning</figDesc><table>Methods 
F1-Score Error(%) 
W/O char-embedding 
96.30 
1.23 
W/O self-attention 
96.26 
1.34 
W/O attention-gating 
96.25 
1.46 
Full Model 
96.52 
1.23 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Feature ablation comparison of our proposed 
model on ATIS. slot filling and intent detection result 
are shown each row after after we exclude each feature 
from the full architecture 

</table></figure>

			<note place="foot" n="1"> http://nlp.stanford.edu/projects/glove/ 2 https://code.google.com/p/word2vec/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint/>
	</monogr>
<note type="report_type">ton. 2016. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Long short-term memory-networks for machine reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.06733</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spoken language understanding: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renato De</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition &amp; Understanding, 2007. ASRU. IEEE Workshop on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="365" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep belief network based semantic taggers for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Deoras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2713" to="2717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">How may i help you? Speech communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Allen L Gorin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy H</forename><surname>Riccardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="113" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Joint semantic utterance classification and slot filling with recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="554" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Optimizing svms for complex call classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry H</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings.(ICASSP&apos;03). 2003 IEEE International Conference on</title>
		<editor>I-I. IEEE</editor>
		<meeting>.(ICASSP&apos;03). 2003 IEEE International Conference on</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Acoustics, Speech, and Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Comparing stochastic approaches to spoken language understanding in multiple languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Dinarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrice</forename><surname>Lefevre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lehnen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renato</forename><forename type="middle">De</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Riccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1569" to="1583" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-domain joint semantic frame parsing using bi-directional rnn-lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gökhan</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeyi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="715" to="719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The atis spoken language systems pilot corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">J</forename><surname>Hemphill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George R Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the DARPA speech and natural language workshop</title>
		<meeting>the DARPA speech and natural language workshop</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="96" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Speech &amp; language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Pearson Education India</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Character-aware neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2741" to="2749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Leveraging sentencelevel information with encoder lstm for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gakuto</forename><surname>Kurata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cicero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03130</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Recurrent neural network structured output prediction for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS Workshop on Machine Learning for Spoken Language Understanding and Interactions</title>
		<meeting>NIPS Workshop on Machine Learning for Spoken Language Understanding and Interactions</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Attention-based recurrent neural network models for joint intent detection and slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.01454</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Joint online spoken language understanding and language modeling with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.01462</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using recurrent neural networks for slot filling in spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="530" to="539" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>TASLP)</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Investigation of recurrent-neuralnetwork architectures and learning methods for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3771" to="3775" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Recurrent neural networks with external memory for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Processing and Chinese Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Evaluation of spoken language systems: The atis domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley</title>
		<meeting><address><addrLine>Pennsylvania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-06-24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recurrent neural network and lstm models for lexical utterance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Suman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Ravuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="135" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generative and discriminative algorithms for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Riccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Boostexter: A boosting-based system for text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="135" to="168" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exploring the use of attention-based recurrent neural networks for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin</forename><surname>Simonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathalie</forename><surname>Camelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Deléglise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Estève</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Spoken Language Understanding and Interaction NIPS 2015 workshop</title>
		<imprint>
			<publisher>SLUNIPS</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Random walk initialization for training very deep feedforward networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sussillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abbott</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6558</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">What is left to be understood in atis?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="19" to="24" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sentence simplification for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarangarajan</forename><surname>Parthasarathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="5628" to="5631" />
		</imprint>
	</monogr>
	<note>2011 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bi-directional recurrent neural network with ranking loss for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="6060" to="6064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Convolutional neural network based triangular crf for joint intent detection and slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding (ASRU)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Spoken language understanding using long short-term memory neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyang</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="189" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Recurrent conditional random field for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4077" to="4081" />
		</imprint>
	</monogr>
	<note>2014 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Recurrent neural networks for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei-Yuh</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2524" to="2528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Talking to machines (statistically speaking)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>In INTERSPEECH</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.2329</idno>
		<title level="m">Ilya Sutskever, and Oriol Vinyals. 2014. Recurrent neural network regularization</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A joint model of intent determination and slot filling for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2993" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Encoder-decoder with focus-mechanism for sequence labelling based spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5675" to="5679" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
