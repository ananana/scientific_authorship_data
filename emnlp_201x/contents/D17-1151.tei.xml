<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Massive Exploration of Neural Machine Translation Architectures</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Britz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Goldie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Massive Exploration of Neural Machine Translation Architectures</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1442" to="1451"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Neural Machine Translation (NMT) has shown remarkable progress over the past few years, with production systems now being deployed to end-users. As the field is moving rapidly, it has become unclear which elements of NMT architec-tures have a significant impact on translation quality. In this work, we present a large-scale analysis of the sensitivity of NMT architectures to common hyper-parameters. We report empirical results and variance numbers for several hundred experimental runs, corresponding to over 250,000 GPU hours on a WMT English to German translation task. Our experiments provide practical insights into the relative importance of factors such as embedding size, network depth, RNN cell type, residual connections, attention mechanism, and decoding heuristics. As part of this contribution , we also release an open-source NMT framework in TensorFlow to make it easy for others to reproduce our results and perform their own experiments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural Machine Translation (NMT) <ref type="bibr" target="#b11">(Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b24">Sutskever et al., 2014;</ref><ref type="bibr" target="#b2">Cho et al., 2014</ref>) is an end-to-end approach to machine translation. NMT has shown impressive results ( <ref type="bibr" target="#b10">Jean et al., 2015;</ref><ref type="bibr" target="#b17">Luong et al., 2015b;</ref><ref type="bibr" target="#b19">Sennrich et al., 2016a;</ref><ref type="bibr">Wu et al., 2016</ref>) surpass- ing those of phrase-based systems while address- ing shortcomings, such as the need for hand- engineered features. The most popular approaches to NMT are based on sequence-to-sequence mod- els, an encoder-decoder architecture consisting of two recurrent neural networks (RNNs) and an attention mechanism that aligns target with source tokens ( <ref type="bibr" target="#b1">Bahdanau et al., 2015;</ref><ref type="bibr" target="#b16">Luong et al., 2015a)</ref>.</p><p>One drawback of current NMT architectures is the huge amount of compute required to train them. Training on real-world datasets of sev- eral million examples typically requires dozens of GPUs and convergence time is on the order of days to weeks ( <ref type="bibr">Wu et al., 2016)</ref>. While sweeping across large hyperparameter spaces is common in Com- puter Vision ( <ref type="bibr" target="#b9">Huang et al., 2016b</ref>), such explo- ration would be prohibitively expensive for NMT models, limiting researchers to well-established architecture and hyperparameter choices. Further- more, there have been no large-scale studies of how these hyperparameters affect the performance of NMT systems. As a result, it remains unclear why these models perform as well as they do or how we might improve them.</p><p>In this work, we present an extensive analysis of architectural hyperparameters for NMT systems. Using a total of more than 250,000 GPU hours, we explore common variations of NMT architec- tures and provide insights into which architectural choices matter most. We report BLEU scores, per- plexities, model sizes, and convergence time for all experiments, including variance numbers cal- culated across several runs of each experiment. In addition, we release the software framework that we wrote to facilitate this exploration.</p><p>In summary, the main contributions of this work are as follows:</p><p>• We provide immediately applicable insights into the optimization of NMT models, as well as promising directions for future research. For example, we found that deep encoders are more difficult to optimize than decoders, that dense residual connections yield better per- formance than regular residual connections, and that a well-tuned beam search is sur- prisingly critical to obtaining state-of-the-art results. By presenting practical advice for choosing baseline architectures, we help re- searchers avoid wasting time on unpromising model variations.</p><p>• We also establish the extent to which met- rics such as BLEU are influenced by ran- dom initialization and slight hyperparameter variation, allowing researchers to better dis- tinguish statistically significant results from noise.</p><p>• Finally, we release an open-source Ten- sorFlow package, specifically designed to implement reproducible state-of-the-art sequence-to-sequence models. All experi- ments were run using this framework and we include all configuration files and processing scripts needed to reproduce the experiments in this paper. We hope to accelerate future research by releasing this framework to the public.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Neural Machine Translation</head><p>Our models are based on an encoder-decoder ar- chitecture with attention mechanism ( <ref type="bibr" target="#b1">Bahdanau et al., 2015;</ref><ref type="bibr" target="#b16">Luong et al., 2015a</ref>), as shown in <ref type="figure">fig- ure</ref> 1. An encoder function f enc takes as input a sequence of source tokens x = (x 1 , ..., x m ) and produces a sequence of states h = (h 1 , ..., h m ). In our base model, f enc is a bi-directional RNN and the state h i corresponds to the concatenation of the states produced by the backward and for- ward RNNs,</p><formula xml:id="formula_0">h i = [ − → h i ; ← − h i ].</formula><p>The decoder f dec is an RNN that predicts the probability of a target sequence y = (y 1 , ..., y k ) based on h. The proba- bility of each target token y i ∈ 1, ...V is predicted based on the recurrent state in the decoder RNN s i , the previous words, y &lt;i , and a context vector c i . The context vector c i is also called the atten- tion vector and is calculated as a weighted average of the source states.</p><formula xml:id="formula_1">c i = j a ij h j (1) a ij = ˆ a ij j ˆ a ij (2) ˆ a ij = att(s i , h j )<label>(3)</label></formula><p>Here, att(s i , h j ) is an attention function that calculates an unnormalized alignment score be- tween the encoder state h j and the decoder state s i . In our base model, we use a function of the form att(s i , h j ) = W h h j , W s s i , where the ma- trices W are used to transform the source and tar- get states into a representation of the same size.</p><p>The decoder outputs a distribution over a vocab- ulary of fixed-size V :</p><formula xml:id="formula_2">P (y i |y 1 , ..., y i−1 , x) = softmax(W [s i ; c i ] + b)</formula><p>The whole model is trained end-to-end by min- imizing the negative log likelihood of the target words using stochastic gradient descent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Protocols</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets and Preprocessing</head><p>We run all experiments on the WMT'15 English→German task consisting of 4.5M sen- tence pairs, obtained by combining the Europarl v7, News Commentary v10, and Common Crawl corpora. We use newstest2013 as our validation set and newstest2014 and newstest2015 as our test sets. We focus on WMT English→German because it is a morphologically rich language therefore has been a standard benchmark in previous important work in Neural Machine Translation ( <ref type="bibr" target="#b10">Jean et al., 2015;</ref><ref type="bibr" target="#b16">Luong et al., 2015a;</ref><ref type="bibr" target="#b20">Sennrich et al., 2016b;</ref><ref type="bibr">Wu et al., 2016)</ref> To test for generality, we also ran a small num- ber of experiments on English→French transla- tion, and we found that the performance was highly correlated with that of English→German but that it took much longer to train models on the larger English→French dataset. Given that trans- lation from the morphologically richer German is also considered a more challenging task, we felt justified in using the English→German translation task for this hyperparameter sweep. We tokenize and clean all datasets with the scripts in Moses 1 and learn shared subword units using Byte Pair Encoding (BPE) ( <ref type="bibr" target="#b20">Sennrich et al., 2016b</ref>) using 32,000 merge operations for a final vocabulary size of approximately 37k. We discov- ered that data preprocessing can have a large im- pact on final numbers, and since we wish to enable reproducibility, we release our data preprocessing scripts together with the NMT framework to the public. For more details on data preprocessing pa- rameters, we refer the reader to the code release.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training Setup and Software</head><p>All of the following experiments are carried out using our own implementation based on Tensor- Flow ( <ref type="bibr" target="#b0">Abadi et al., 2016</ref>). We built this framework to enable reproducible state-of-the-art implemen- tations of Neural Machine Translation architec- tures. As part of our contribution, we are releasing the framework and all configuration files needed to reproduce our results. Training is performed on Nvidia Tesla K40m and Tesla K80 GPUs, dis- tributed over 8 parallel workers and 6 parameter servers per experiment. We use a batch size of 128 and decode using beam search with a beam width of 10 and the length normalization penalty of 0.6 described in ( <ref type="bibr">Wu et al., 2016)</ref>. BLEU scores are calculated on tokenized data using the multi- 1 https://github.com/moses-smt/mosesdecoder/ bleu.perl script in Moses. <ref type="bibr">2</ref> Each experiment is run for a maximum of 2.5M steps and replicated 4 times with different initializations. We save model checkpoints every 30 minutes and choose the best checkpoint based on the validation set BLEU score. We report mean and standard de- viation as well as highest scores (as per cross val- idation) for each experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Baseline Model</head><p>Based on a review of recent literature, we chose a baseline model that we knew would perform rea- sonably well. Our goal was to keep the baseline model simple and standard, not to advance the start of the art. The model (described in 2.1) con- sists of a 2-layer bidirectional encoder (1 layer in each direction), and a 2 layer decoder with a mul- tiplicative ( <ref type="bibr" target="#b16">Luong et al., 2015a</ref>) attention mecha- nism. We use 512-unit GRU ( <ref type="bibr" target="#b2">Cho et al., 2014</ref>) cells for both the encoder and decoder and apply Dropout of 0.2 at the input of each cell. We train using the Adam optimizer and a fixed learning rate of 0.0001 without decay. The embedding dimen- sionality is set to 512. A more detailed description of all model hyperparameters can be found in the supplementary material.</p><p>In each of the following experiments, the hy-perparameters of the baseline model are held con- stant, except for the one hyperparameter being studied. We hope that this allows us to isolate the effect of various hyperparameter changes. We rec- ognize that this procedure does not account for in- teractions between hyperparameters, and we per- form additional experiments when we believe such interactions are likely to occur (e.g., skip connec- tions and number of layers).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>For the sake of brevity, we only report mean BLEU, standard deviation, highest BLEU in parentheses, and model size in the following ta- bles. Log perplexity, tokens/sec and convergence times can be found in the supplementary material tables. All reported p-values were calculated with a two-sample t-test that assumed equal variances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Embedding Dimensionality</head><p>With a large vocabulary, the embedding layer may account for a significant fraction of the model parameters. Historically, researchers have used 620-dimensional ( <ref type="bibr" target="#b1">Bahdanau et al., 2015</ref>) or 1024- dimensional ( <ref type="bibr" target="#b16">Luong et al., 2015a</ref>) embeddings. We expected larger embeddings to result in bet- ter BLEU scores, or at least lower perplexities, but this wasn't always the case <ref type="table">. While table 1</ref> shows that 2048-dimensional embeddings yielded the overall best result, they only outperformed the smallest 128-dimensional embeddings by a nar- row yet statistically significant margin (p = 0.01), but took nearly twice as long to converge. Gradi- ent updates to both small and large embeddings did not differ significantly from each other and the norm of gradient updates to the embedding matrix stayed approximately constant throughout training, regardless of size. We did not observe overfitting with large embeddings and training log perplexity was almost equal across experiments, suggesting that the model does not make efficient use of the extra parameters and that there may be a need for better optimization techniques. Alterna- tively, it could be the case that models with large embeddings simply need far more than 2.5M steps to converge to the best solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">RNN Cell Variant</head><p>Both LSTM <ref type="bibr" target="#b7">(Hochreiter and Schmidhuber, 1997</ref>  <ref type="table">Table 2</ref>: BLEU scores on newstest2013, varying the type of encoder and decoder cell.</p><p>In our experiments, LSTM cells consistently outperformed GRU cells, a result which was sta- tistically significant (p &lt; 0.00001). Since the computational bottleneck in our architecture is the softmax operation, we did not observe large differ- ences in training speed between LSTM and GRU cells. Somewhat to our surprise, we found that the vanilla decoder is unable to learn nearly as well as the gated variant. This suggests that the decoder indeed passes information in its own state through multiple time steps instead of relying solely on the attention mechanism and current input (which in- cludes the previous attention context). It could also be the case that the gating mechanism is nec- essary to mask out irrelevant parts of the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Encoder and Decoder Depth</head><p>We generally expect deeper networks to converge to better solutions than shallower ones ( <ref type="bibr" target="#b6">He et al., 2016)</ref>. While some work ( <ref type="bibr" target="#b17">Luong et al., 2015b;</ref><ref type="bibr" target="#b15">Luong and Manning, 2016;</ref><ref type="bibr">Wu et al., 2016</ref>) has achieved state-of-the-art results using deep networks, others <ref type="bibr" target="#b10">(Jean et al., 2015;</ref><ref type="bibr" target="#b3">Chung et al., 2016;</ref><ref type="bibr" target="#b20">Sennrich et al., 2016b</ref> <ref type="formula" target="#formula_4">(4)</ref>, we insert residual connections be- tween consecutive layers. If h</p><note type="other">) have produced similar results with far shallower ones. Therefore, it is unclear how important depth is, and whether shallow networks are capable of pro- ducing results competitive with those of deep net- works. Here, we explore the effect of both encoder and decoder depth up to 8 layers. For the bidi- rectional encoder, we separately stack the RNNs in both directions. For example, the Enc-8 model corresponds to one forward and one backward 4- layer RNN. For deeper networks, we also exper- iment with two variants of residual connections (He et al., 2016; Srivastava et al., 2015) to encour- age gradient flow. In the standard variant, shown in equation</note><formula xml:id="formula_3">(l) t (x (l) t , h (l)</formula><p>t−1 ) is the RNN output of layer l at time step t, then:</p><formula xml:id="formula_4">x (l+1) t = h (l) t (x (l) t , h (l) t−1 ) + x (l) t<label>(4)</label></formula><p>where x (0) t are the embedded input tokens. We also explore a dense ("ResD" below) variant of residual connections similar to those used by <ref type="bibr" target="#b8">(Huang et al., 2016a</ref>) in Image Recognition. In this variant, we add skip connections from each layer to all other layers:</p><formula xml:id="formula_5">x (l+1) t = h (l) t (x (l) t , h (l) t−1 ) + l j=0 x (j) t<label>(5)</label></formula><p>Our implementation differs from ( <ref type="bibr" target="#b8">Huang et al., 2016a</ref>) in that we use addition instead of concate- nation in order to keep the state size constant. <ref type="table">Table 3</ref> shows results of varying encoder and decoder depth with and without residual connec- tion. We found no benefit to increasing encoder depth beyond two layers, as we observed no statis- tically significant improvement from going to four layers and even deeper models generally diverged during training. The best deep residual models achieved good results, but only one of four runs converged, as suggested by the large standard de- viation.  <ref type="table">Table 3</ref>: BLEU scores on newstest2013, varying the encoder and decoder depth and type of residual connections.</p><p>On the decoder side, deeper models outper- formed shallower ones by a small but statisti- cally significant margin (p &lt; 0.00001), but with- out residual connections, we were unable to train decoders with 8 or more layers. Across the deep decoder experiments, dense residual connections consistently outperformed regular residual con- nections (p &lt; 0.00001) and converged much faster in terms of step count, as shown in <ref type="figure">figure 2</ref>. We ex- pected deep models to perform better <ref type="bibr" target="#b24">(Sutskever et al., 2014;</ref><ref type="bibr">Wu et al., 2016)</ref> across the board, and we believe that our experi- ments demonstrate the need for more robust tech- niques for optimizing deep sequential models. For example, we may need a better-tuned SGD opti- mizer or some form of batch normalization, in or- der to robustly train deep networks with residual connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Unidirectional vs. Bidirectional Encoder</head><p>In the literature, we see bidirectional encoders ( <ref type="bibr" target="#b1">Bahdanau et al., 2015)</ref>, unidirectional encoders ( <ref type="bibr" target="#b16">Luong et al., 2015a)</ref>, and a mix of both ( <ref type="bibr">Wu et al., 2016</ref>) being used. Bidirectional encoders are able to create representations that take into ac- count both past and future inputs, while unidirec- tional encoders can only take past inputs into ac- count. The benefit of unidirectional encoders is that their computation can be easily parallelized on GPUs, allowing them to run faster than their bidi- rectional counterparts. We are not aware of any studies that explore the necessity of bidirectional- Step <ref type="table">2   4   6   8   10   12   14   16</ref> Log Perplexity depth_dec_8 depth_dec_8_res depth_dec_8_res_dense</p><p>Figure 2: Training plots for deep decoder with and without residual connections, showing log per- plexity on the eval set.</p><p>ity. In this set of experiments, we explore unidirec- tional encoders of varying depth with and without reversed source inputs, as this is a commonly used trick that allows the encoder to create richer repre- sentations for earlier words. Given that errors on the decoder side can easily cascade, the correct- ness of early words has disproportionate impact.  <ref type="table">Table 4</ref>: BLEU scores on newstest2013, varying the type of encoder. The "R" suffix indicates a reversed source sequence. <ref type="table">Table 4</ref> shows that bidirectional encoders gen- erally outperform unidirectional encoders, but not by a statistically significant margin. The encoders with reversed source consistently outperform their non-reversed counterparts (p = 0.009 for one layer models, p = 0.0003 for two layers, p = 0.2751 for four layers), but do not beat shallower bidirec- tional encoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Attention Mechanism</head><p>The two most commonly used attention mecha- nisms are the additive ( <ref type="bibr" target="#b1">Bahdanau et al., 2015</ref>) vari- ant, equation <ref type="formula">(6)</ref> below, and the computationally less expensive multiplicative variant ( <ref type="bibr" target="#b16">Luong et al., 2015a</ref>), equation <ref type="formula" target="#formula_6">(7)</ref> below. Given an attention key h j (an encoder state) and attention query s i (a de- coder state), the attention score for each pair is cal- culated as follows:</p><formula xml:id="formula_6">score(h j , s i ) = v, tanh(W 1 h j + W 2 s i ) (6) score(h j , s i ) = W 1 h j , W 2 s i<label>(7)</label></formula><p>We call the dimensionality of W 1 h j and W 2 s i the "attention dimensionality" and vary it from 128 to 1024 by changing the layer size. We also experiment with using no attention mechanism by initializing the decoder state with the last encoder state (None-State), or concatenating the last en- coder state to each decoder input (None-Input).</p><p>The results are shown in  <ref type="table" target="#tab_3">Table 5</ref>: BLEU scores on newstest2013, varying the type of attention mechanism.</p><p>We found that the parameterized additive atten- tion mechanism slightly but consistently outper- formed the multiplicative one (p = 0.013 for 128 units, p = 0.5 for 256 units, p = 0.0012 for 512 units, and p &lt; 0.00001 for 1024/8 units), with the attention dimensionality having little effect.</p><p>While we did expect the attention-based mod- els to significantly outperform those without an attention mechanism, we were surprised by just how poorly the "Non-Input" models fared, given that they had access to encoder information at each time step. Furthermore, we found that the attention-based models exhibited significantly larger gradient updates to decoder states through- out training. This suggests that the attention mech- anism acts more like a "weighted skip connection" that optimizes gradient flow than like a "memory" that allows the encoder to access source states, as is commonly stated in the literature. We believe that further research in this direction is necessary to shed light on the role of the attention mecha-nism and whether it may be purely a vehicle for easier optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Beam Search Strategies</head><p>Beam Search is a commonly used technique to find target sequences that maximize some scoring function s(y, x) through tree search. In the sim- plest case, the score to be maximized is the log probability of the target sequence given the source. Recently, extensions such as coverage penalties ( <ref type="bibr" target="#b26">Tu et al., 2016</ref>) and length normalizations ( <ref type="bibr">Wu et al., 2016</ref>) have been shown to improve decod- ing results. It has also been observed ( <ref type="bibr" target="#b25">Tu et al., 2017</ref>) that very large beam sizes, even with length penalty, perform worse than smaller ones. Thus, choosing the correct beam width can be crucial to achieving the best results.  <ref type="table">Table 6</ref>: BLEU scores on newstest2013, varying the beam width and adding length penalties (LP). <ref type="table">Table 6</ref> shows the effect of varying beam widths and adding length normalization penalties. A beam width of 1 corresponds to greedy search. We found that a well-tuned beam search is crucial to achieving good results, and that it leads to consis- tent gains of more than one BLEU point. Similar to ( <ref type="bibr" target="#b25">Tu et al., 2017)</ref> we found that very large beams yield worse results and that there is a "sweet spot" of optimal beam width. We believe that further re- search into the robustness of hyperparameters in beam search is crucial to progress in NMT. We also experimented with a coverage penalty, but found no additional gain over a sufficiently large length penalty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Final System Comparison</head><p>Finally, we compare our best performing model across all experiments, as chosen on the new- stest2013 validation set, to historical results found in the literature in <ref type="table">Table 8</ref>. Interestingly, the best performing model turned out to be nearly equiva- lent to the base model (described in Section 3.3), differing only in that it used 512-dimensional ad- ditive attention. While not the focus on this work, we were able to achieve further improvements by combining all of our insights into a single model described in <ref type="table" target="#tab_6">Table 7</ref>.    Although we do not offer architectural innova- tions, we do show that through careful hyperpa- rameter tuning and good initialization, it is pos- sible to achieve state-of-the-art performance on standard WMT benchmarks. Our model is outper- formed only by ( <ref type="bibr">Wu et al., 2016)</ref>, a model which is significantly more complex and lacks a public implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperparameter Value</head><p>To test whether our findings generalize to other languages, we also trained a model with the same hyperparameter configurations on the AS- PEC Japanese to English translation task and achieved a BLEU score of 38.87, which is state- of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Open-Source Release</head><p>We demonstrated empirically how small changes to hyperparameter values and different initializa- tion can affect results, and how factors such as a well-tuned beam search are critical to high qual- ity translation results. To move towards repro- ducible research, we believe it is important that researchers start building upon common frame- works and data processing pipelines. With this goal in mind, we built a modular software frame- work that allows researchers to explore novel ar- chitectures with minimal code changes, and define experimental parameters in a reproducible man- ner. While our initial experiments are in Ma- chine Translation, our framework can easily be adapted to problems in Summarization (e.g., <ref type="bibr" target="#b18">Nallapati et al. (2016)</ref>), Conversational Modeling (e.g., <ref type="bibr" target="#b27">Vinyals and Le (2015)</ref>; <ref type="bibr" target="#b21">Shang et al. (2015)</ref>; <ref type="bibr" target="#b22">Sordoni et al. (2015)</ref>; <ref type="bibr" target="#b21">Li et al. (2015)</ref>) or Image- To-Text (e.g., ; <ref type="bibr" target="#b12">Karpathy and Fei-Fei (2015)</ref>; <ref type="bibr" target="#b31">Xu et al. (2015)</ref>).</p><p>Although there exist open-source libraries such as OpenNMT ( <ref type="bibr" target="#b13">Klein et al., 2017</ref>) that share simi- lar goals, they have not yet achieved state-of-the- art results (see <ref type="table">table 8</ref>) and lack some important features, such as support for distributed training. We hope that by open sourcing our experimental toolkit, we can help to accelerate research in neu- ral machine translation and sequence-to-sequence modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We conducted a large-scale empirical analysis of architecture variations for Neural Machine Trans- lation, teasing apart the key factors to achieving state-of-the-art results. We demonstrated a num- ber of surprising insights, including the fact that beam search tuning is just as crucial as most archi- tectural variations, and that with current optimiza- tion techniques deep models do not always out- perform shallow ones. Here, we summarize our practical findings:</p><p>• Large embeddings with 2048 dimensions achieved the best results, but only by a small margin. Even small embeddings with 128 di- mensions seem to have sufficient capacity to capture most of the necessary semantic infor- mation.</p><p>• LSTM Cells consistently outperformed GRU Cells.</p><p>• Bidirectional encoders with 2 to 4 layers per- formed best. Deeper encoders were signifi- cantly more likely to diverge, but show po- tential if they can be optimized well.</p><p>• Deep 4-layer decoders slightly outperformed shallower decoders. Residual connections were necessary to train decoders with 8 lay- ers and dense residual connections offer ad- ditional robustness.</p><p>• Parameterized additive attention yielded the overall best results.</p><p>• A well-tuned beam search with length penalty is crucial. Beam widths of 5 to 10 along with a length penalty of 1.0 seemed to work well.</p><p>We highlighted several important research ques- tions, including the efficient use of embedding pa- rameters (4.1), the role of attention mechanisms as weighted skip connections (4.5) as opposed to memory units, the need for better optimization methods for deep recurrent networks (4.3), and the need for a better beam search (4.6) robust to hyper- parameter variations.</p><p>Finally, given the recent surge in new applica- tions for sequence-to-sequence models, we believe our new findings and state-of-the-art open-source package can significantly accelerate the pace of re- search in this domain.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Encoder-Decoder architecture with attention module. Section numbers reference experiments corresponding to the components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>8 :</head><label>8</label><figDesc>Comparison to RNNSearch (Jean et al., 2015), RNNSearch-LV (Jean et al., 2015), BPE (Sennrich et al., 2016b), BPE-Char (Chung et al., 2016), Deep-Att (Zhou et al., 2016), Luong (Lu- ong et al., 2015a), Deep-Conv (Gehring et al., 2016), GNMT (Wu et al., 2016), and OpenNMT (Klein et al., 2017). Systems with an * do not have a public implementation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>cells, such as the GRU and LSTM. Using vanilla RNN cells, deep networks cannot efficiently propagate information and gradients through multiple layers and time steps. We ini- tialize the decoder state to zero instead of passing the encoder state, and we experiment with using a vanilla RNN cell in the decoder only (Vanilla-Dec below). For the LSTM and GRU variants, we vary cell types in both the encoder and decoder. We use LSTM cells without peephole connections and ini- tialize the forget bias of both LSTM and GRU cells to 1.</figDesc><table>) 
and GRU (Cho et al., 2014) cells are commonly 
used in NMT architectures. While there exist stud-

Dim newstest2013 
Params 
128 
21.50 ± 0.16 (21.66) 36.13M 
256 
21.73 ± 0.09 (21.85) 46.20M 
512 
21.78 ± 0.05 (21.83) 66.32M 
1024 21.36 ± 0.27 (21.67) 106.58M 
2048 21.86 ± 0.17 (22.08) 187.09M 

Table 1: BLEU scores on newstest2013, varying 
the embedding dimensionality. 

ies (Greff et al., 2016) that explore cell variants on 
small sequence tasks of a few thousand examples, 
we are not aware of any such studies in large-scale 
NMT settings. 
The vanishing gradient problem is a motiva-
tion for gated Cell 
newstest2013 
Params 
LSTM 
22.22 ± 0.08 (22.33) 68.95M 
GRU 
21.78 ± 0.05 (21.83) 66.32M 
Vanilla-Dec 15.38 ± 0.28 (15.73) 63.18M 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>table 5 .</head><label>5</label><figDesc></figDesc><table>Attention 
newstest2013 
Params 
Mul-128 
22.03 ± 0.08 (22.14) 65.73M 
Mul-256 
22.33 ± 0.28 (22.64) 65.93M 
Mul-512 
21.78 ± 0.05 (21.83) 66.32M 
Mul-1024 
18.22 ± 0.03 (18.26) 67.11M 
Add-128 
22.23 ± 0.11 (22.38) 65.73M 
Add-256 
22.33 ± 0.04 (22.39) 65.93M 
Add-512 
22.47 ± 0.27 (22.79) 66.33M 
Add-1024 
22.10 ± 0.18 (22.36) 67.11M 
None-State 9.98 ± 0.28 (10.25) 
64.23M 
None-Input 11.57 ± 0.30 (11.85) 64.49M 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Hyperparameter settings for our final 
combined model, consisting of all of the individu-
ally optimized values. 

Model 
newstest14 newstest15 
Ours (best performing) 22.03 
24.75 
Ours (combined) 
22.19 
25.23 
OpenNMT 
19.34 
-
Luong 
20.9 
-
BPE-Char 
21.5 
23.9 
BPE 
-
20.5 
RNNSearch-LV 
19.4 
-
RNNSearch 
-
16.5 
Deep-Att * 
20.6 
-
GNMT * 
24.61 
-
Deep-Conv * 
-
24.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>

			<note place="foot">* Both authors contributed equally to this work. † Work done as a member of the Google Brain Residency program (g.co/brainresidency).</note>

			<note place="foot" n="2"> https://github.com/mosessmt/mosesdecoder/blob/master/scripts/generic/multibleu.perl</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">TensorFlow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajat</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherry</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pete</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A character-level decoder without explicit segmentation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A convolutional encoder model for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<idno>CoRR abs/1611.02344</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">LSTM: A search space odyssey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh</forename><forename type="middle">Kumar</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Koutník</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Steunebrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems PP</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>abs/1608.06993</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Speed/accuracy trade-offs for modern convolutional object detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Korattikara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<idno>CoRR abs/1611.10012</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On using very large target vocabulary for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recurrent continuous translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep visualsemantic alignments for generating image descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">OpenNMT: Open-source toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno>CoRR abs/1701.02810</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03055</idno>
		<title level="m">A diversity-promoting objective function for neural conversation models</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Achieving open vocabulary neural machine translation with hybrid word-character models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effective approaches to attentionbased neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Addressing the rare word problem in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Abstractive text summarization using sequence-to-sequence rnns and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.06023</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Edinburgh neural machine translation systems for wmt 16</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02364</idno>
		<title level="m">Neural responding machine for short-text conversation</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.06714</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh Kumar</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">Highway networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural machine translation with reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Modeling coverage for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05869</idno>
		<title level="m">A neural conversational model</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<imprint>
			<pubPlace>Qin Gao, Klaus</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apurva</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshikiyo</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideto</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<idno>CoRR abs/1609.08144</idno>
	</analytic>
	<monogr>
		<title level="j">Oriol Vinyals</title>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Greg Corrado, Macduff Hughes, and Jeffrey Dean</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Deep recurrent models with fast-forward connections for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
