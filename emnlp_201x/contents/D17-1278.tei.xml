<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MinIE: Minimizing Facts in Open Information Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universität Mannheim</orgName>
								<address>
									<settlement>Mannheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universität Mannheim</orgName>
								<address>
									<settlement>Mannheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Max-Planck-Institut für Informatik</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MinIE: Minimizing Facts in Open Information Extraction</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2630" to="2640"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The goal of Open Information Extraction (OIE) is to extract surface relations and their arguments from natural-language text in an unsupervised, domain-independent manner. In this paper, we propose MinIE, an OIE system that aims to provide useful, compact extractions with high precision and recall. MinIE approaches these goals by (1) representing information about polarity, modality, attri-bution, and quantities with semantic annotations instead of in the actual extraction, and (2) identifying and removing parts that are considered overly specific. We conducted an experimental study with several real-world datasets and found that MinIE achieves competitive or higher precision and recall than most prior systems, while at the same time producing shorter, semantically enriched extractions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open Information Extraction (OIE) ( <ref type="bibr" target="#b2">Banko et al., 2007</ref>) is the task of generating a structured, machine-readable representation of information expressed in natural language text in an unsuper- vised, domain-independent manner. In contrast to traditional IE systems, OIE systems do not require an upfront specification of the target schema (e.g., target relations) or access to background knowl- edge (e.g., a knowledge base). Instead, extractions are (usually) represented in the form of surface subject-relation-object triples. OIE serves as input for deeper understanding tasks such as relation ex- traction ( <ref type="bibr" target="#b21">Riedel et al., 2013;</ref><ref type="bibr" target="#b19">Petroni et al., 2015)</ref>, knowledge base construction ( <ref type="bibr" target="#b8">Dong et al., 2014</ref>), question answering <ref type="bibr" target="#b10">(Fader et al., 2014</ref>), word anal- ogy ( <ref type="bibr" target="#b25">Stanovsky et al., 2015)</ref>, or information re- trieval ( <ref type="bibr">Löser et al., 2012)</ref>.</p><p>Consider, for example, the sentence "Superman was born on Krypton." An OIE system aims to extract the triple (Superman, was born on, Kryp- ton), which most of the available systems will cor- rectly produce. As another example, consider the more involved sentence "Pinocchio believes that the hero Superman was not actually born on beau- tiful Krypton", and the corresponding extractions of various systems in <ref type="table" target="#tab_1">Table 1</ref>, extractions 1-6. Al- though most of the extractions are correct, they are often overly specific in that their constituents con- tain specific modifiers or even complete clauses. Such extractions severely limit the usefulness of OIE results (e.g., they are often pruned in relation extraction tasks). The main goals of OIE should be (i) to provide useful, compact extractions and (ii) to produce extractions with high precision and recall. The key challenge in OIE is how to achieve both goals simultaneously. In fact, most of the available systems (often implicitly) focus on either compactness (e.g., <ref type="bibr">ReVerb (Fader et al., 2011)</ref>) or precision/recall (e.g., <ref type="bibr">ClausIE (Del Corro and Gemulla, 2013)</ref>).</p><p>We propose MinIE, an OIE system that aims to address and trade-off both goals. MinIE is built on top of ClausIE, a state-of-the-art OIE system that achieves high precision and recall, but of- ten produces overly-specific extractions. To gen- erate more useful and semantically richer extrac- tions, MinIE (i) provides semantic annotations for each extraction, (ii) minimizes overly-specific constituents, and (iii) produces additional extrac- tions that capture implicit relations. <ref type="table" target="#tab_1">Table 1</ref> shows the output of (variants of) MinIE for the example sentence. Note that MinIE's extractions are signif- icantly more compact but retain correctness.</p><p>MinIE's semantic annotations represent infor- mation about polarity, modality, attribution, and quantities. The idea of using annotations has al-Pinocchio believes that the hero Superman was not actually born on beautiful Krypton.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OLLIE</head><p>1 (Pinocchio, believes that, the hero [...] beautiful Krypton) 2 (Superman, was not actually born on, beautiful Krypton) 3 (Superman, was not actually born on beau. Krypton in, the hero) A annotation; + positive polarity, -negative polarity; PS possibility, CT certainty; fact. factuality; attrib. attribution; MinIE follows OLLIE, but adds semantic anno- tations that make the extraction itself more com- pact and useful (as opposed to capturing context). For example, MinIE detects negations in the rela- tion, removes them from the extraction, and adds a "negative polarity" (-) annotation. In fact, MinIE treats surface relations such as was born on and was not born on as equivalent up to polarity. The absence of negative evidence is a major concern for relation extraction and knowledge base con- struction tasks-e.g., addressed by using a local closed world assumption ( <ref type="bibr" target="#b8">Dong et al., 2014</ref>) or negative sampling ( <ref type="bibr" target="#b21">Riedel et al., 2013;</ref><ref type="bibr" target="#b19">Petroni et al., 2015</ref>)-and MinIE's annotations can help to alleviate this problem.</p><p>In addition to the semantic annotations, MinIE minimizes its extractions by identifying and re- moving parts that are considered overly specific. In general, such minimization is inherently limited in scope due to the absence of domain knowledge. Thus MinIE does not and cannot correctly mini- mize all its extractions in all cases. Instead, MinIE supports multiple minimization modes, which dif- fer in their aggressiveness and effectively control the usefulness-precision trade-off. In particular, MinIE's complete mode (C) does not perform any minimizations. MinIE's safe mode (S) only per- forms minimizations that are considered univer- sally safe. MinIE's dictionary mode (D) makes use of corpus-level statistics to inform the minimiza- tion process. Finally, MinIE's aggressive mode (A) only keeps parts that are considered univer- sally necessary. The use of corpus-level statis- tics by MinIE-D is inspired by the pruning tech- niques of ReVerb, although we use these statistics for minimization instead of pruning (see Sec. 2). Tab. 1 shows the output of MinIE's various modes.</p><p>We conducted an experimental study with sev- eral real-world datasets and found that the vari- ous modes of MinIE produced much shorter ex- tractions than most prior systems, while simul- taneously achieving competitive or higher preci- sion (depending on the mode being used). MinIE sometimes fell behind prior systems in terms of the total number of extractions. We found that in almost all of these cases, MinIE became competi- tive once redundant extractions were removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>OIE was introduced by <ref type="bibr" target="#b2">Banko et al. (2007)</ref>. Since then, many different OIE systems have been proposed. Earlier systems-e.g., <ref type="bibr" target="#b9">Fader et al. (2011)</ref>-relied mostly on shallower NLP tech- niques such as POS tagging and chunking, while later systems often use dependency parsing in ad- dition ( <ref type="bibr" target="#b11">Gamallo et al., 2012;</ref><ref type="bibr" target="#b26">Wu and Weld, 2010)</ref>. Most OIE systems represent extractions in the form of triples, although some also produce n-ary extractions <ref type="bibr" target="#b0">(Akbik and Löser, 2012;</ref><ref type="bibr" target="#b7">Del Corro and Gemulla, 2013)</ref> or nested representations <ref type="bibr" target="#b3">(Bast and Haussmann, 2013;</ref><ref type="bibr" target="#b4">Bhutani et al., 2016)</ref>. Some systems focus on non-verb-mediated rela- tions ( <ref type="bibr" target="#b27">Yahya et al., 2014</ref>). MinIE is based on the state-of-the-art OIE system ClausIE <ref type="bibr" target="#b7">(Del Corro and Gemulla, 2013)</ref>.</p><p>A general challenge in OIE is to avoid both un- informative and overly-specific extractions. Re- Verb <ref type="bibr" target="#b9">(Fader et al., 2011</ref>) proposed to avoid overly- specific relations by making use of lexical con- straints: relations that occur infrequently in a large corpus were considered overly-specific and pruned. MinIE's dictionary mode also makes use of the corpus frequency of constituents. In con- trast to ReVerb, MinIE uses frequency to inform minimization (instead of to prune) and applies it to subjects and arguments as well. Perhaps the clos- est system in spirit to MinIE is Stanford OIE <ref type="bibr" target="#b1">(Angeli et al., 2015)</ref>, which uses aggressive minimiza- tion. Stanford OIE deletes all subconstituents con- nected by certain typed dependencies (e.g., amod). For some dependencies (e.g., prep or dobj), it uses a frequency constraint along the lines of ReVerb. MinIE differs from Stanford OIE in that it (i) sepa- rates out polarity, modality, attribution, and quan- tities; (ii) uses a different, more principled (and more precise) approach to minimization.</p><p>Annotated OIE extractions were introduced by OLLIE ( <ref type="bibr" target="#b14">Mausam et al., 2012)</ref>, which uses two types of annotations: attribution (the supplier of information) and clause modifier (a clause modi- fying the triple). MinIE extends OLLIE's attribu- tion by additional semantic annotations for polar- ity, modality, and quantities. Such annotations are not provided by prior OIE systems. CSD-IE ( <ref type="bibr" target="#b3">Bast and Haussmann, 2013)</ref> introduced the notion of nested facts (termed "minimal" in their paper) and produce extractions with "pointers" to other ex- tractions. NestIE ( <ref type="bibr" target="#b4">Bhutani et al., 2016</ref>) takes up this idea. OLLIE's clause modifier has a similar purpose. MinIE currently does not handle nested extractions.</p><p>Another line of research explores the integra- tion of background knowledge into OIE <ref type="bibr" target="#b17">(Nakashole et al., 2012;</ref><ref type="bibr">Navigli, 2012, 2013)</ref>. In general, OIE systems should use background knowledge when available, but remain open when not. MinIE currently does not use background knowledge, although it allows providing domain- dependent dictionaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overview</head><p>The goal of MinIE is to provide minimized, se- mantically annotated OIE extractions. While the techniques employed here can potentially be in- tegrated into any OIE system, we built MinIE on top of ClausIE. We chose ClausIE because (i) it separates the identification of the extractions from the generation of propositions, (ii) it detects clause types, which are also useful for MinIE, and (iii) it is a state-of-the-art OIE system with high preci- sion and recall.</p><p>As ClausIE, MinIE focuses on extractions ob- tained from individual clauses (with the exception of attribution; Sec. 5.3). Each clause consists of one subject (S), one verb (V) and alternatively an indirect object (O i ), a direct object (O), a comple- ment (C) and one or more adverbials (A). ClausIE identifies the clause type, which indicates which constituents are obligatory or optional from a syn- tactic point of view. <ref type="bibr" target="#b20">Quirk et al. (1985)</ref> identified seven clause types for English: SV, SVA, SVC, SVO, SVOO, SVOA, and SVOC, where letters re- fer to obligatory constituents and each clause can be accompanied by additional optional adverbials.</p><p>MinIE consists of three phases. (1) Each input sentence is run through ClausIE and a separate ex- tractor for implicit facts (Sec. 4.2). We rewrite ClausIE's extractions to make relations more in- formative (Sec. 4.1). We refer to the resulting ex- tractions as input extractions. (2) MinIE then de- tects information about polarity (Sec. 5.1), modal- ity (Sec. 5.2), attribution (Sec. 5.3), and quan- tities (Sec. 5.4) and represents it with semantic annotations. <ref type="formula">(3)</ref> To further minimize the result- ing annotated extractions, MinIE provides vari- ous minimization modes (Sec. 6) with increas- ing levels of aggressiveness: MinIE-C(omplete), MinIE-S(afe), MinIE-D(ictionary), and MinIE- A(ggressive). The modes differ in the amount of minimizations being applied. The result of this phase is a minimized extraction.</p><p>Finally, MinIE outputs each minimized extrac- tion along with its annotations. Semantic annota- tions (such as polarity) are crucial to correctly rep-resent the extraction, whereas other annotations (such as original relation) provide additional in- formation about the minimization process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Input Extractions</head><p>We first describe how MinIE obtains meaningful input extractions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Enriching Relations</head><p>As mentioned before, MinIE uses ClausIE as its underlying OIE system. The relations extracted by ClausIE consist of only verbs and negation parti- cles (cf. Tab. 1). <ref type="bibr" target="#b9">Fader et al. (2011)</ref> argue that such an approach can lead to uninformative relations. For example, from the sentence "Faust made a deal with the Devil", ClausIE extracts triple (Faust, made, a deal with the Devil), whereas the extraction (Faust, made a deal with, the Devil) has a more informative relation and a shorter ar- gument. Indeed, the relation made is highly poly- semous (49 synsets in WordNet), whereas made a deal with is not. MinIE aims to produce informa- tive relations by deciding which constituents of the input sentence should be pushed into the relation. Our goal is to retain only one of the constituents of the input clause in the argument of the extrac- tion whenever possible, while simultaneously re- taining coherence. In particular, our approach uses the clause types detected by ClausIE to ensure that MinIE never removes obligatory constituents from a clause (which would lead to incoherent ex- tractions); it instead may opt to move such con- stituents to the relation. Our approach is inspired by the syntactic patterns of ReVerb-which is similar to our handling of the SVA and SVO clause types-but, in contrast, applies to all clause types. Note that the relations produced in this step may sometimes be considered overly specific; they will be minimized further in subsequent steps.</p><p>SVA. If the adverbial is a prepositional com- plement, we push the preposition into the rela- tion. For example, we rewrite (Superman, lives, in Metropolis) to (Superman, lives in, Metropolis). This allows us to distinguish live in from relations such as live during, live until, live through, and so on.</p><p>SVO i O, SVOC. We generally push the indirect object (SVO i O) or direct object (SVOC) into the relation. In both cases, the verb requires two addi- tional constituents: we use the first one to enrich the relation and the second one as an argument.</p><p>For example, we rewrite (Superman, declared, the city safe) to (Superman, declared the city, safe). As this example indicates, this rewrite is some- what unsatisfying; further exploration is an inter- esting direction for future work.</p><p>SVOA. If the adverbial consists of a single ad- verb, we push it to the relation and use the object as an argument. This approach retains coherence because such adverbials are "fluent", i.e., they do not have a fixed position. Otherwise, we pro- ceed as in SVOC, but additionally push the starting preposition (if present) of the adverbial to the rela- tion. For example, (Ana, turned, the light off) be- comes (Ana, turned off, the light), and (The door- man, leads, visitors to their destination) becomes (The doorman, leads visitors to, their destination).</p><p>Optional adverbials. If the clause contains op- tional adverbials, ClausIE creates one extraction without any optional adverbial and one additional extraction per optional adverbial. The former ex- tractions are processed as above. The latter ex- tractions are treated as if the adverbial were oblig- atory. For example, the extraction (Faust, made, a deal with the Devil) becomes (Faust, made a deal with, the Devil). Here the actual clause type is SVO, but we process it as if it were SVOA.</p><p>Infinitive forms. If the argument starts with a to-infinitive verb, we move it to the relation. For example, (Superman, needs, to defeat Lex) be- comes (Superman, needs to defeat, Lex).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implicit Extractions</head><p>ClausIE produces non-verb-mediated extractions from appositions and possessives. We refer to these extractions as implicit extractions. MinIE makes use of additional implicit extractors. In par- ticular, we use the patterns of FINET ) to detect explicit type mentions. For example, if the sentence contains "president Barack Obama", we obtain (Barack Obama, is, president). We also include certain patterns in- volving named entities: pattern ORG IN LOC for extraction (ORG, is IN, LOC); pattern "Mr." PER for (PER, is, male) (similarly, Ms. or Mrs.); and pattern ORG POS? NP PER for (PER, is NP of, ORG) from RelNoun ( <ref type="bibr" target="#b18">Pal and Mausam, 2016)</ref>. Apart from providing additional high-quality ex- tractions, we use implicit extractions as a signal for minimization (Sec. 6.2). The extractors above have thus been included both to increase recall and to be able to provide more effective minimizations. Sentence Factuality S. does live in Metropolis.</p><p>(+, CT) S. does not live in M.</p><p>( <ref type="table">Table 2</ref>: Factuality examples. MinIE extracts triple (Superman; does live in; Metropolis) from each sentence but the factuality annotations differ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>-[not], CT) S. does probably live in M. (+, PS [probably]) S. probably does not live in M. (-[not], PS [probably])</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Semantic Annotations</head><p>Once input extractions have been created, MinIE detects information about polarity (Sec. 5.1), modality (Sec. 5.2), attribution (Sec. 5.3), and quantities (Sec. 5.4) and represents it using se- mantic annotations. Our focus is on simple, rule- based methods that are both domain-independent and (considered) safe to use in that they do not harm the accuracy of the extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Polarity</head><p>MinIE annotates each extraction with information about its factuality. Following Saurí and Puste- jovsky (2012), we represent the factuality of an extraction with two pieces of information: polar- ity (+ or -) and modality (CT or PS; for certainty or possibility, resp.). Tab. 2 lists some examples.</p><p>The polarity indicates whether or not a triple oc- curred in negated form. In order to assign a po- larity value to a triple, we aim to detect whether the relation indicates a negative polarity. If so, we assign negative polarity to the whole triple. We detect negations using a small lexicon of negation words (e.g., no, not, never, none). If a word from the lexicon is detected, it is dropped from the re- lation and the triple is annotated with negative po- larity (-) and the negation word. In Tab. 2, the ex- tractions from sentences 2 and 4 are annotated as negative.</p><p>We found that this simple approach successfully spots many negations present in the input rela- tions. Note that whenever a negation is present but not detected, MinIE still produces correct results because such negations are retained in the triple. For example, if a negations occurs in the subject or argument of the extraction, MinIE does not detect it. E.g., from sentence "No people were hurt in the fire", MinIE extracts (Q 1 people, were hurt in; fire) with quantity Q 1 =no (see Sec. 5.4). This ex- traction is correct, but can be further minimized to (people; were hurt in; fire) with a negative polarity annotation. We consider such advanced minimiza- tions too dangerous to use.</p><p>Generally, negation detection is a hard prob- lem and involves questions such as negation scope resolution, focus detection, and double nega- tion ( <ref type="bibr" target="#b5">Blanco and Moldovan, 2011</ref>). MinIE does not address these problems, but restricts attention to the simple, safe cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Modality</head><p>The modality indicates whether the triple is a cer- tainty (CT) or a possibility (PS) according to the clause in which it occurs. We proceed similarly as for the detection of negations and consider a triple certain unless we find evidence of possibility.</p><p>To find such evidence, MinIE searches the re- lation for (1) modal verbs such as may or can, (2) possibility-indicating words, and (3) certain infini- tive verb phrases. For (2) and (3), we make use of a small domain-independent lexicon. Our lex- icon is based on the lexicon of Saurí and Puste- jovsky (2012) and the words in the corresponding WordNet synsets. It mainly contains adverbs such as probably, possibly, maybe, likely and infinitive verb phrases such as is going to, is planning to, or intends to. Whenever words indicating possi- bility are detected, we remove these words from the triple and annotate the triple as possible (PS) along with the words just removed. For example, sentences 3 and 4 in Tab. 2 are annotated PS with the possibility-indicating word probably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Attribution</head><p>The attribution of a triple is the supplier of infor- mation given in the input sentence, if any. We adapt our attribution annotation from the notion of source of Saurí and Pustejovsky (2012), i.e., the attribution consists of a supplier of information (as in OLLIE) and an additional factuality (polar- ity and modality). The factuality is independent from the factuality of the extracted triple; it indi- cates whether the supplier expresses a negation or a possibility. Tab. 1 shows some examples.</p><p>We extract attributions from subordinate clauses and from "according to" patterns.</p><p>Subordinate clauses. MinIE searches for ex- tractions that contain entire clauses as arguments. We then compare the relation against a domain- independent dictionary of relations indicating at- tributions (e.g., say or believe). 1 If we find a match, we create an attribution annotation and use the subject of the extraction as the supplier of in- formation. Each entry in the attribution dictionary is annotated with a modality. For example, rela- tions such as know, say, or write express certainty, whereas relations such as believe or guess express possibility. If the relation is modified by a nega- tion word, we mark the attribution with negative polarity (e.g., never said that). After the attribu- tion has been established, we run ClausIE on the main clause and add the attribution to each ex- tracted triple.</p><p>"according to" adverbial patterns. We search for adverbials that start with according to and take whatever follows as the supplier with factuality (+, CT). The remaining part of the clause is processed as before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Quantities</head><p>A quantity is a phrase that expresses an amount (or the absence) of something. It either modifies a noun phrase (e.g., 9 cats) or is an independent complement (e.g., I have 3). Quantities include cardinals (9), determiners (all) or phrases (almost 10). If we detect a quantity, we replace it by a placeholder Q and add an annotation with the orig- inal quantity. The goal of this step is to unify ex- tractions that only differ in quantities. For exam- ple, the phrases 9 cats, all cats and almost about 100 cats are all rewritten to Q cats, only the quan- tity annotation differs.</p><p>We detect quantities by looking for numbers (NER types such as NUMBER or PERCENT) or words expressing quantities (such as all, some, many). We then extend these words via relevant typed dependencies, such as quantity modifiers (quantmod) and adverbial modifiers (advmod).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Minimization</head><p>After adding semantic annotations, MinIE mini- mizes extractions by dropping additional words. Since such minimization is risky, MinIE employs various minimization modes with different levels of aggressiveness, which effectively control the minimality-precision trade-off.</p><p>MinIE represents each constituent of an anno- tated extraction by its words, its dependency struc- ture, its POS tags, and its named entities (de- tected by a named-entity recognizer). In general, each mode defines a set of stable subconstituents, <ref type="bibr" target="#b23">Pustejovsky (2012)</ref> plus WordNet synonyms. which will always be fully retained, and subse- quently searches for candidate words to drop out- side of the stable subconstituents. Whenever a word is dropped from a constituent, we add an an- notation with the original, unmodified constituent.</p><p>In all of MinIE's modes, noun sequences (which include the head) and named entities (from NER) are considered stable subconstituents. MinIE's minimization can be augmented with domain knowledge by providing information about addi- tional stable subconstituents (e.g., collocations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Complete Mode (MinIE-C)</head><p>MinIE's complete mode (MinIE-C) prunes all the extractions that contain subordinate clauses but does not otherwise modify the annotated extrac- tions. The rationale is that extractions containing subordinate clauses are almost always overly spe- cific. MinIE-C serves as a baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Safe Mode (MinIE-S)</head><p>MinIE's safe mode only drops words which we consider universally safe to drop. We first drop all constituents that are covered by the implicit ex- tractions discussed in Sec. 4.2 (e.g., "Mr." before persons). We then drop all determiners, posses- sive pronouns, adverbs modifying the verb in the relation, as well as adjectives and adverbs modi- fying words tagged as PERSON by the NER. An exception to these rules is given by named entities, which we consider as stable subconstituents (e.g., we do not drop "Mr." in (Joe, cleans with, Mr. Muscle)).</p><p>Note that this procedure cannot be considered safe when used on input extractions. We consider it safe, however, when applied to annotated extrac- tions. In particular, all determiners, pronouns, and adverbs indicating negation, modality, or quanti- ties are already processed and captured in annota- tions. The safe mode thus only performs simple rewrites such as the great city to great city, his car to car, had also to had, and the eloquent president Mr. Barack Obama to Barack Obama.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Dictionary Mode (MinIE-D)</head><p>Our dictionary mode uses a dictionary D of stable constituents. We first discuss how the dictionary is being used and subsequently how we construct it. An example is given in <ref type="figure" target="#fig_1">Fig. 1</ref>.</p><p>MinIE-D first performs all the minimizations of the safe mode and then searches for maximal noun phrases of the form P ≡ [adverbial|adjective] + [noun + |ner]. For each instance of P , we drop a certain subset of its words. For example, a suitable minimization for very infamous cold war symbol (i.e., the Berlin wall) is cold war symbol, i.e., we consider cold as essential to the meaning of the constituent and very infamous as overly specific.</p><p>The decision of what is considered essential and what overly specific is informed by dictionary D. Note that in order to minimize mistakes, we con- sider for dropping only words in instances of pat- tern P . In particular, we do not touch subcon- stituents that contain prepositions because these are notoriously difficult to handle (e.g., we do not want to minimize Bill of Rights to Bill).</p><p>Our goal is to retain phrases occurring in D, even if they occur in different order or with ad- ditional modifiers. We proceed as follows for each instance I of P . We first mark all nouns modify- ing the root (or the named entity) as stable. After- wards, we create a set of potentially stable sub- constituents (PSS). Each PSS is queried against dictionary D. If it occurs in D, all of its words are marked as stable. Once all PSS have been processed, we drop all words from I that are not marked stable. In our example, if {cold war} ∈ D, we obtain cold war symbol.</p><p>To generate the set of PSS, we enumerate all syntactically valid subconstituents of I. For ex- ample, infamous symbol or cold infamous war are syntactically valid, whereas very symbol or very cold war are not. Conceptually, <ref type="bibr">2</ref> we enumerate all subsequences of I and check whether (1) at least one noun (or named entity) is retained, and (2) whenever an adverb or adjective is not retained, neither are its modifiers. For each such subse- quence, we generate all permutations of adverbial and adjective modifiers originating from the same dependency node, and each result as a PSS. This step ensures that the order of modifiers in I does influence whether or not a word is marked stable. The set of PSS for very infamous cold war symbol contains 22 entries.</p><p>The construction of dictionary D is inspired by the lexical constraint of Fader et al. (2011): Our assumption is that everything sufficiently frequent in a large corpus is not overly specific. To ob- tain D, we process the entire corpus using the safe mode and include all frequent (e.g., frequency ≥ 10) subjects, relations, and arguments into D. Ap- <ref type="bibr">2</ref> We generate both instances of P as well as the set of PSS directly from the dependency structure of the constituent. very infamous cold war symbol RB JJ JJ NN NN initially:</p><p>(stable) (stable) ultimately:</p><p>(stable) (stable) (stable)  plications can extend the dictionary using suitable collocations, either from domain-dependent dic- tionaries or by using methods to automatically ex- tract collocations from a corpus (Gries, 2013).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Aggressive Mode (MinIE-A)</head><p>All previous modes aimed to be conservative. MinIE-A proceeds the other way around: all words for which we are not sure if they need to be retained are dropped. For every word in a constituent of an annotated extraction, we drop all adverbial, adjective, possessive, and temporal modifiers (along with their modifiers). We also drop prepositional attachments (e.g., man with ap- ples becomes man), quantities modifying nouns, auxiliary modifiers to the main verb (e.g., have escalated becomes escalated), and all compound nouns that have a different named-entity type than their head word (e.g., European Union official be- comes official). In most cases, after applying these steps, only a single word, named entity, or a se- quence of nouns remains for subject and argument constituents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Study</head><p>The goal of our experimental study was to investi- gate the differences in the various modes of MinIE w.r.t. precision, recall, and extraction length as well as to compare it with popular prior methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Setup</head><p>Source code, dictionaries, datasets, extractions, la- bels, and labeling guidelines are made available. <ref type="bibr">3</ref> Datasets. We used (1) 10,000 random sen- tences from the New York Times Corpus (NYT-10k) <ref type="bibr" target="#b22">(Sandhaus, 2008)</ref>, (2) a random sample of 200 sentences from the same corpus (NYT), and (3) a random sample of 200 sentences from Wikipedia (Wiki). NYT and Wiki were used in the evaluation of ClausIE and NestIE. <ref type="bibr">4</ref> Methods. We used ClausIE, OLLIE, and Stan- ford OIE as baseline systems. We adapted the publicly available version of ClausIE to Stanford CoreNLP 3.8.0 and implemented MinIE on top. For MinIE-D, we built dictionary D from the en- tire NYT and Wikipedia corpus, respectively.</p><p>Labeling. Labelers provided two labels per ex- traction of NYT and Wiki: one for the triple (with- out attribution) and one for the attribution. A triple is labeled as correct if it is entailed by its corresponding clause; here factuality annotations are taken into account but attribution errors are ig- nored. For example, all triples except #3 of Tab. 1 are considered correct. An attribution is incorrect if there is an attribution in the sentence which is neither present in the triple nor in the attribution annotation. In Tab. 1, the attribution is incorrect for extractions #2, #3, #5, and #6. Attribution is labeled only when the fact triple is labeled correct. See the labeling guidelines for further details.</p><p>Overall, there were more than 9,400 distinct ex- tractions on NYT and Wiki. Each extraction was labeled by two independent labelers. We treat an extraction as correct if both labelers labeled it as correct. The inter-annotator agreement was mod- erate (NYT: Cohen's κ = 0.53, 78% of labels agree; Wiki: κ = 0.5, 79% of labels agree).</p><p>Measures. For each system, we measured the total number of extractions, the total number of correct triples (recall), the fraction of correct triples out of all extractions (factual precision), and the fraction of correct triples that have correct attributions (attribution precision). We also deter- mined the mean word count per triple (µ) and its standard deviation (σ) as a proxy for minimality. Finally, as some systems produced a large number of redundant extractions, we also report the num- ber of non-redundant extractions. For simplicity, we consider a triple t 1 redundant if it appears as subsequence in some other triple t 2 produced by the same extractor from the same sentence (e.g., extraction #5 in Tab. 1 is redundant given extrac-tion #6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Extraction Statistics</head><p>In our first experiment, we used the larger but un- labeled NYT-10k dataset. The goal of this exper- iment was to investigate the total number of re- dundant and non-redundant extractions produced by each system and how frequently semantic an- notations were produced (Tab. 3). For MinIE, we show the fraction of negative polarity and possi- bility annotations for triples only (i.e., we exclude the attribution polarity annotations).</p><p>In terms of number of extractions, MinIE (all modes) and Stanford OIE were roughly on par; OLLIE fell behind and ClausIE went ahead. The reason why ClausIE has more extractions than MinIE is that different (partly redundant) extrac- tions from ClausIE may lead to the same mini- mized extraction. This is also also the reason why extraction numbers drop in the more aggressive modes of MinIE. We also determined the num- ber of non-redundant extractions produced by each system and found that most systems produced only a moderate number of redundant extractions. A notable exception is Stanford OIE, which pro- duced many extraction variants by dropping dif- ferent subsets of words.</p><p>We observed that all modes of MinIE achieved significantly smaller extractions than ClausIE (its underlying OIE system), and that the average extraction length indeed dropped as we used more aggressive modes. Only MinIE-A produced shorter extractions than Stanford OIE. The main reason for the short extraction length of Stanford OIE is its aggressive creation of short redundant extractions (at the cost of precision; see below). We also found that to further minimize the extrac- tions of MinIE-D, it is often necessary to minimize subjects and objects with prepositional modifiers (which MinIE currently avoids).</p><p>Only OLLIE and MinIE make use of annota- tions. The fraction of extracted attribution anno- tations was significantly smaller for OLLIE than for MinIE, mainly because OLLIE's attribution detection is limited to the ccomp dependency re- lation. Our results also indicate that MinIE fre- quently provides semantic annotations (with the notable exception of negative polarity).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OLLIE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ClausIE</head><p>Stanford MinIE-C MinIE-S MinIE-D <ref type="table" target="#tab_1">MinIE-A   # non-redundant extr.  20,557  36,173  16,350  37,465  37,093  36,921  36,474  # with redundant extr.  24,316  58,420  43,360  47,637  45,492  45,318</ref> 42,842 µ ± σ 9.9 ± 5.8 10.9 ± 7.0 6.6 ± 3.0 8.3 ± 4.9 7.2 ± 4.2 7.0 ± 4.1 4.7 ± 1.9 with attributions 6.8% - - 10.8% 10.8% 10.7% 10.8% with negative polarity - - - 3.8% 3.7% 3.7% 3.8% with possibility - - - 10.1% 9.9% 10.0% 9.7% with quantity - - - 17.6% 17.8% 17.8% 1.9%  We found that Stanford OIE had the lowest fac- tual precision and recall for non-redundant extrac- tions throughout; it produced many incorrect and many redundant extractions (e.g., Stanford OIE produced 400 extractions from five sentences on NYT). For MinIE, the factual precision dropped as expected when we use more aggressive modes. In- terestingly, the drop in precision between MinIE- C and MinIE-D was quite low, even though ex- tractions get shorter. The aggressive minimization of MinIE-A led to a more severe drop in preci- sion. Surprisingly to us, even MinIE's aggressive mode achieved precision comparable to ClausIE and higher than Stanford OIE. Note that MinIE- C, MinIE-S, and MinIE-D had higher precision than ClausIE. Reasons include that MinIE pro- duces additional high-precision implicit extrac- tions and breaks up very long and thus error-prone extractions.We also tried enriching the dictionary of MinIE-D with WordNet and Wiktionary collo- cations; the precision was almost the same.</p><p>As for attribution precision, most of the sen- tences in our samples did not contain attribu- tions; these numbers thus have low accuracy. OL- LIE and MinIE achieved similar results, even though MinIE additionally annotated attributions with factuality information.</p><p>Errors. For all modes, errors in dependency parsing transfer over to errors in MinIE, which we believe was the main source of error in MinIE-C and MinIE-S. For MinIE-D, we sometimes drop adjectives which in fact form collocations (e.g., "assistant director") with the noun they are mod- ifying. This happens when the collocation is not present in the dictionary; better collocation dictio- naries may address this problem. Another source of error stems from the NER (e.g., the first word of the entity Personal Ensign was not recognized).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We believe that the use of minimized extractions with semantic annotations are a promising direc- tion for OIE. The techniques presented here can be seen as a step towards this goal, but there are still many open questions. Important directions include additional annotation types (e.g., tempo- ral/spatial), use of background knowledge, better handling of collocations, the use of nested repre- sentations, and multilingual OIE.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>advmod amod amod nn head word PSS include: cold war symbol, cold symbol, cold war, infamous war symbol, infamous symbol, . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of PSS generation in MinIED. Initially stable words are marked blue. Entries in dictionary D are printed in bold face.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Example extractions and annotations from various OIE systems 

ready been explored by OLLIE (Mausam et al., 
2012) for capturing the context of an extraction. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results on the unlabeled NYT-10k dataset (µ=avg. extraction length, σ=standard deviation) 

OLLIE 
ClausIE 
Stanford 
MinIE-C 
MinIE-S 
MinIE-D 
MinIE-A 

NYT 
# non-redundant (correct/total) 
246/414 
505/821 
178/342 
581/785 
574/781 
569/777 
439/753 
# w/ redundant (correct/total) 
302/497 
792/1300 530/1052 
727/970 
690/924 
681/916 
505/860 
factual prec. 
(0.61) 
(0.61) 
(0.5) 
(0.75) 
(0.75) 
(0.74) 
(0.59) 
attr. prec. 
(0.9) 
-
-
(0.94) 
(0.93) 
(0.93) 
(0.93) 

Wiki 
# non-redundant (correct/total) 
229/479 
424/704 
217/398 
500/666 
489/661 
486/669 
401/658 
# w/ redundant (correct/total) 
284/565 
628/1002 651/1519 
635/851 
602/816 
593/816 
474/783 
factual prec. 
(0.50) 
(0.63) 
(0.43) 
(0.75) 
(0.74) 
(0.73) 
(0.61) 
attr. prec. 
(0.97) 
-
-
(0.97) 
(0.96) 
(0.96) 
(0.97) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results on the labeled NYT and Wiki datasets 

smaller NYT and Wiki datasets. Our results are 
summarized in Tab. 4. 
</table></figure>

			<note place="foot" n="1"> As with modality, the dictionary is based on Saurí and</note>

			<note place="foot" n="3"> http://dws.informatik.uni-mannheim. de/en/resources/software/minie/</note>

			<note place="foot" n="4"> We did not use the OIE benchmark of Stanovsky and Dagan (2016) because it treats an extraction as correct if the heads of each constituent match the ones of a gold extraction. This is not suitable for us because it does not account for minimization (which does not change grammatical heads).</note>

			<note place="foot" n="7">.3 Precision In our second experiment, we compared the precision and recall of the various systems on the</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Simone Paolo Ponzetto, Goran Glavaš, Stefano Faralli, Daniel Ruffinelli, and the anonymous reviewers for their invaluable feedback and support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Kraken: Nary facts in open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Löser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction</title>
		<meeting>the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="52" to="56" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Leveraging linguistic structure for open domain information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><forename type="middle">Johnson</forename><surname>Premkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Open information extraction from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Broadhead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2670" to="2676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Open information extraction via contextual sentence decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Bast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Haussmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Semantic Computing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="154" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Nested propositions in open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Bhutani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Some issues on detecting negation from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">I</forename><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Florida Artificial Intelligence Research Society Conference</title>
		<meeting>the Twenty-Fourth International Florida Artificial Intelligence Research Society Conference</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="228" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Finet: Context-aware fine-grained named entity typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdalghani</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="868" to="878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Clausie: clause-based open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
		<meeting>the 22nd international conference on World Wide Web</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="355" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geremy</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilko</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Open question answering over curated and extracted knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1156" to="1165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dependency-based open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Gamallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Fernández-Lanza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Unsupervised and Semi-Supervised Learning in NLP</title>
		<meeting>the Joint Workshop on Unsupervised and Semi-Supervised Learning in NLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">50-something years of work on collocations: what is or should be next</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Th</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gries</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Corpus Linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="137" to="166" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The goolap fact retrieval framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Löser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tillmann</forename><surname>Fiehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Business Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="84" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Open language learning for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Wisenet: Building a wikipedia-based semantic network with ontologized relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM international conference on Information and knowledge management</title>
		<meeting>the 21st ACM international conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1672" to="1676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Integrating syntactic and semantic analysis into the open information extraction paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Patty: a taxonomy of relational patterns with semantic types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ndapandula</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1135" to="1145" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Demonyms and compound relational nouns in nominal open ie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harinder</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mausam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Automated Knowledge Base Construction</title>
		<meeting>Workshop on Automated Knowledge Base Construction</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="35" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Core: Context-aware open relation extraction with factorization machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1763" to="1773" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A comprehensive grammar of the English language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randolph</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sidney</forename><surname>Greenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Leech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Svartvik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crystal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<publisher>Cambridge Univ Press</publisher>
			<biblScope unit="volume">397</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin M</forename><surname>Marlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Sandhaus</surname></persName>
		</author>
		<title level="m">The new york times annotated corpus. Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">26752</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Are you sure that this happened? assessing the factuality degree of events in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Saurí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="261" to="299" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Creating a large benchmark for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Open ie as an intermediate structure for semantic tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="303" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Open information extraction using wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel S Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="118" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Renoun: Fact extraction for nominal attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon Y</forename><surname>Halevy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="325" to="335" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
