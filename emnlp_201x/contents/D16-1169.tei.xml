<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Context-Sensitive Lexicon Features for Neural Sentiment Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyang</forename><surname>Teng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duy-Tin</forename><surname>Vo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Context-Sensitive Lexicon Features for Neural Sentiment Analysis</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1629" to="1638"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Sentiment lexicons have been leveraged as a useful source of features for sentiment analysis models, leading to the state-of-the-art accuracies. On the other hand, most existing methods use sentiment lexicons without considering context, typically taking the count, sum of strength, or maximum sentiment scores over the whole input. We propose a context-sensitive lexicon-based method based on a simple weighted-sum model, using a recurrent neural network to learn the sentiments strength, intensification and negation of lexicon sentiments in composing the sentiment value of sentences. Results show that our model can not only learn such operation details, but also give significant improvements over state-of-the-art recurrent neural network baselines without lexical features, achieving the best results on a Twitter benchmark.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentiment lexicons ( <ref type="bibr" target="#b36">Hu and Liu, 2004;</ref><ref type="bibr" target="#b65">Wilson et al., 2005;</ref><ref type="bibr" target="#b30">Esuli and Sebastiani, 2006</ref>) have been a useful resource for opinion mining ( <ref type="bibr" target="#b40">Kim and Hovy, 2004;</ref><ref type="bibr" target="#b19">Agarwal et al., 2011;</ref><ref type="bibr" target="#b47">Moilanen and Pulman, 2007;</ref><ref type="bibr" target="#b24">Choi and Cardie, 2008;</ref><ref type="bibr" target="#b46">Mohammad et al., 2013;</ref><ref type="bibr" target="#b34">Guerini et al., 2013;</ref><ref type="bibr" target="#b63">Vo and Zhang, 2015)</ref>. Contain- ing sentiment attributes of words such as polarities and strengths, they can serve to provide a word-level foundation for analyzing the sentiment of sentences and documents. We investigate an effective way to use sentiment lexicon features.</p><p>A traditional way of deciding the sentiment of a document is to use the sum of sentiment values of  all words in the document that exist in a sentiment lexicon <ref type="bibr" target="#b62">(Turney, 2002;</ref><ref type="bibr" target="#b36">Hu and Liu, 2004</ref>). This simple method has been shown to give surprisingly competitive accuracies in several sentiment analysis benchmarks ( , and is still the standard practice for specific research commu- nities with mature domain-specific lexicons, such as finance ( <ref type="bibr" target="#b39">Kearney and Liu, 2014</ref>) and product re- views ( <ref type="bibr" target="#b27">Ding et al., 2008</ref>).</p><p>More sophisticated sentence-level features such as the counts of positive and negative words, their total strength, and the maximum strength, etc, have also been exploited ( <ref type="bibr" target="#b40">Kim and Hovy, 2004;</ref><ref type="bibr" target="#b65">Wilson et al., 2005;</ref><ref type="bibr" target="#b19">Agarwal et al., 2011</ref>). Such lexicon fea- tures have been shown highly effective, leading to the best accuracies in the SemEval shared task <ref type="bibr" target="#b46">(Mohammad et al., 2013</ref>). On the other hand, they are typically based on bag-of-word models, hence suf- fering two limitations. First, they do not explicitly handle semantic compositionality <ref type="bibr" target="#b51">(Polanyi and Zaenen, 2006;</ref><ref type="bibr" target="#b47">Moilanen and Pulman, 2007;</ref><ref type="bibr" target="#b58">Taboada et al., 2011)</ref>, some examples of which are shown in <ref type="figure" target="#fig_1">Figure 1</ref>. The composition effects can exhibit in- tricacies such as negation over intensification (e.g. not very good), shifting (e.g. not terrific) vs flip-ping negation (e.g. not acceptable), content word negation (e.g. removes my doubts) and unbounded dependencies (e.g. No body gives a good perfor- mance).</p><p>Second, they cannot effectively deal with word sense variations <ref type="bibr" target="#b26">(Devitt and Ahmad, 2007;</ref><ref type="bibr" target="#b25">Denecke, 2009</ref>). <ref type="bibr" target="#b34">Guerini et al. (2013)</ref> show chal- lenges in modeling the correlation between context- dependent posterior word sentiments and their con- text independent priors. For example, the sentiment value of "cold" varies between "cold beer", "cold pizza" and "cold person" due to sense and context differences. Such variations raise difficulties for a sentiment classifier with bag-of-word nature, since they can depend on semantic information over long phrases or the full sentence.</p><p>We investigate a method that can potentially ad- dress the above issues, by using a recurrent neu- ral network to capture context-dependent seman- tic composition effects over sentences. Shown in <ref type="figure" target="#fig_4">Figure 2</ref>, the model is conceptually simple, us- ing a weighted sum of lexicon sentiments and a sentence-level bias to estimate the sentiment value of a sentence. The key idea is to use a bi-directional long-short-term-memory (LSTM) <ref type="bibr" target="#b35">(Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr" target="#b33">Graves et al., 2013</ref>) model to capture global syntactic dependencies and seman- tic information, based on which the weight of each sentiment word together with a sentence-level sen- timent bias score are predicted. Such weights are context-sensitive, and can express flipping negation by having negative values.</p><p>The advantages of the recurrent network model over existing semantic-composition-aware discrete models such as <ref type="bibr" target="#b24">(Choi and Cardie, 2008)</ref> include its capability of representing non-local and subtle se- mantic features without suffering from the challenge of designing sparse manual features. On the other hand, compared with neural network models, which recently give the state-of-the-art accuracies ( <ref type="bibr" target="#b16">Li et al., 2015;</ref>, our model has the ad- vantage of leveraging sentiment lexicons as a useful resource. To our knowledge, we are the first to in- tegrate the operation into sentiment lexicons and a deep neural model for sentiment analysis.</p><p>The conceptually simple model gives strong em- pirical performances. Results on standard sentiment benchmarks show that our method gives competitive <ref type="figure" target="#fig_4">Figure 2</ref>: Overall model structure. The sentiment score of the sentence "not a bad movie at all" is a weighted sum of the scores of sentiment words "not", "bad" and a sentence-level bias score b. score(not) and score(bad) are prior scores obtained from sentiment lexicons. γ1 and γ3 are context-sensitive weights for sentiment words "not" and "bad", respectively.</p><p>accuracies to the state-of-the-art models in the liter- ature. As a by-product, the model can also correctly identify the compositional changes on the sentiment values of each word given a sentential context.</p><p>Our code is released at https://github.com/zeeeyang/lexicon rnn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There exist many statistical methods that exploit sentiment lexicons ( <ref type="bibr" target="#b40">Kim and Hovy, 2004;</ref><ref type="bibr" target="#b19">Agarwal et al., 2011;</ref><ref type="bibr" target="#b46">Mohammad et al., 2013;</ref><ref type="bibr" target="#b34">Guerini et al., 2013;</ref><ref type="bibr" target="#b61">Tang et al., 2014b;</ref><ref type="bibr" target="#b63">Vo and Zhang, 2015;</ref><ref type="bibr" target="#b22">Cambria, 2016)</ref>. <ref type="bibr" target="#b46">Mohammad et al. (2013)</ref> leverage a large sentiment lexicon in a SVM model, achiev- ing the best results in the SemEval 2013 bench- mark on sentence-level sentiment analysis <ref type="bibr" target="#b49">(Nakov et al., 2013</ref>). Compared to these methods, our model has two main advantages. First, we use a recurrent neural network to model context, thereby exploiting non-local semantic information. Second, our model offers context-sensitive operational details on each word.</p><p>Several previous methods move beyond bag-of- word models in leveraging lexicons. Most notably, <ref type="bibr" target="#b47">Moilanen and Pulman (2007)</ref> introduce the ideas from compositional semantics <ref type="bibr" target="#b48">(Montague, 1974)</ref> into sentiment operations, developing a set of com- position rules for handling negations. Along the line, Taboada et al. (2011) developed a lexicon and a collection of sophisticated rules for addressing in- tensification, negation and other phenomena. Differ-ent from these rule-based methods, <ref type="bibr" target="#b24">Choi and Cardie (2008)</ref> use a structured linear model to learn seman- tic compositionality relying on a set of manual fea- tures. In contrast, we leverage a recurrent neural model for inducing semantic composition features automatically. Our weighted-sum representation of semantic compositionality is formally simpler com- pared with fine-grained rules such as <ref type="bibr" target="#b58">(Taboada et al., 2011</ref>). However, it is sufficient for describing the resulting effect of complex and context-dependent operations, with the semantic composition process being modeled by LSTM. Our sentiment analyzer also enjoys a more competitive LSTM baseline com- pared to a traditional discrete models.</p><p>Our work is also related to recent work on us- ing deep neural networks for sentence-level senti- ment analysis, which exploits convolutional <ref type="bibr" target="#b52">Ren et al., 2016</ref>), recursive <ref type="bibr" target="#b28">Dong et al., 2014;</ref><ref type="bibr">Nguyen and Shirai, 2015)</ref> and recurrent neural net- works ( <ref type="bibr" target="#b64">Liu et al., 2015;</ref>, giving highly competitive accuracies. As our baseline, LSTM ) stands among the best neural methods. Our model is different from these prior methods in mainly two aspects. First, we introduce sentiment lexicon fea- tures, which effectively improve classification ac- curacies. Second, we learn extra operation details, namely the weights on each word, automatically as hidden variables. While the baseline uses LSTM features to perform end-to-end mapping between sentences and sentiments, our model uses them to in- duce the lexicon weights, via which word level sen- timent are composed to derive sentence level senti- ment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>Formally, given a sentence s = w 1 w 2 ...w n and a sentiment lexicon D, denote the subjective words in</p><formula xml:id="formula_0">s as w D j 1 w D j 2 ...w D jm .</formula><p>Our model calculates the senti- ment score of s according to D in the form of</p><formula xml:id="formula_1">Score(s) = m t=1 γ jt score(w D jt ) + b,<label>(1)</label></formula><p>where Score(w D jt ) is the sentiment value of w jt , γ jt are sentiment weights and b is a sentence-level bias.</p><p>The sentiment values of words and sentences are real numbers, with the sign indicating the polarity and the absolute value indicating the strength.</p><p>As shown in <ref type="figure" target="#fig_4">Figure 2</ref>, our neural model consists of three main layers, namely the input layer, the feature layer and the output layer. The input layer maps each word in the input sentence into a dense real-value vector. The feature layer exploits a bi- directional LSTM ( <ref type="bibr" target="#b32">Graves and Schmidhuber, 2005;</ref><ref type="bibr" target="#b33">Graves et al., 2013</ref>) to extract non-local semantic in- formation over the sequence. The output layer cal- culates a weight score for each sentiment word, as well as an overall sentiment bias of the sentence.</p><p>In this figure, the score of the sentence "not a bad movie at all" is decided by a weighted sum of the sentiments of "bad" and "not" 1 , and a sentiment shift bias based on the sentence structure. Ideally, the weight on "not" should be a small negative value, which results in a slightly positive sentiment shift. The weight on "bad" should be negative, which rep- resents a flip in the polarity. These weights jointly model a negation effect that involves both shifting and flipping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Bidirectional LSTM</head><p>We use LSTM <ref type="bibr" target="#b35">(Hochreiter and Schmidhuber, 1997)</ref> for feature extraction, which recurrently processes sentence s token by token. For each word w t , the model calculate a hidden state vector h t . A LSTM cell block makes use of an input gate i t , a memory cell c t , a forget gate f t and an output gate o t to con- trol information flow from the history x 1 ...x t and h 1 ...h t−1 to the current state h t . Formally, h t is computed as follows:</p><formula xml:id="formula_2">i t = σ(W i x t + U i h t−1 + V i c t−1 + b i ) f t = 1.0 − i t g t = tanh(W g x t + U g h t−1 + b g ) c t = f t c t−1 + i t g t o t = σ(W o x t + U o h t−1 + V o c t + b o ) h t = o t tanh(c t )</formula><p>Here x t is the word embedding of word w t , σ de- notes the sigmoid function, is element-wise mul- tiplication.</p><formula xml:id="formula_3">W i , U i , V i , b i , W g , U g , b g , W o , U o , V o and b o are LSTM parameters.</formula><p>We apply a bidirectional extension of LSTM (BiLSTM) ( <ref type="bibr" target="#b32">Graves and Schmidhuber, 2005;</ref><ref type="bibr" target="#b33">Graves et al., 2013</ref>), shown in <ref type="figure" target="#fig_4">Figure 2</ref>, to encode the input sentence s both left-to-right and right-to-left. The BiLSTM model maps each word w t to a pair of hidden vectors h L t and h R t , which denote the hid- den vector of the left-to-right LSTM and right-to- left LSTM, respectively. We use different parame- ters for the left-to-right LSTM and the right-to-left LSTM. These state vectors are used as features for calculating the sentiment weights γ.</p><p>In addition, we append a sentence end marker w &lt;e&gt; to the left-to-right LSTM and a sentence start marker w &lt;s&gt; to the right-to-left LSTM. The hidden state vector of w &lt;s&gt; and w &lt;e&gt; are denoted as h R s and h L e , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Output Layer</head><p>The base score. Given a lexicon word w jt in the sentence s (w jt ∈ D), we use the hidden state vec- tors h L j t and h R j t in the feature layer to calculate a weight value τ jt . As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, a two-layer neural network is used to induce τ jt . In particular, a hidden layer combines h L t and h R t using a non- linear tanh activation</p><formula xml:id="formula_4">p s j t = tanh(W L ps h L j t + W R ps h R j t + b ps )<label>(2)</label></formula><p>The resulting hidden vector p s j t is then mapped into τ jt using another tanh layer.</p><formula xml:id="formula_5">τ s jt = 2 tanh(W pw p s j t + b pw )<label>(3)</label></formula><p>We choose the 2tanh function to make the learned weights conceptually useful. The factor 2 is in- troduced for modelling the effect of intensification. Since the range of tanh function is</p><formula xml:id="formula_6">[−1, 1], the range of 2tanh is [−2, 2].</formula><p>Intuitively, a weight value of 1 maps the word sentiment directly to the sentence sentiment, such as the weight for "good" in "This is good". A weight value in (1, 2] represents intensifi- cation, such as the weight for "bad" in "very bad". Similarly, a weight value in (0, 1) represents weak- ening, and a weight in (−2, 0) represents various scales of negations. Given all lexicon words w D jt in the sentence, we calculate a base score for the sentence By averaging the score of each word, the resulting S base is confined to <ref type="bibr">[−2α, 2α]</ref>, where α is the maxi- mum absolute value of word sentiment. In the above equations, W L ps , W R ps , b ps , W pw and b pw are model parameters.</p><formula xml:id="formula_7">S base = m t=1 τ jt score(w D jt ) m<label>(4)</label></formula><p>The bias score. We use the same neural network structure in <ref type="figure" target="#fig_2">Figure 3</ref> to calculate the overall bias of the input sentence. The input to the neural network includes h R s and h L e , and the output is a bias score S bias . Intuitively, the calculation of S bias relies on information of the full sentence. h R s and h L e are chosen because they have commonly been used in the research literature to represent overall sentential information ( <ref type="bibr" target="#b33">Graves et al., 2013;</ref>).</p><p>We use a dedicated set of parameters for calculat- ing the bias, where</p><formula xml:id="formula_8">p B = tanh(W L pb h L e + W R pb h R s + b pb )<label>(5)</label></formula><p>and</p><formula xml:id="formula_9">S bias = 2 tanh(W b p B + b p )<label>(6)</label></formula><formula xml:id="formula_10">W L pb , W R pb , b pb , W b and b L p are parameters.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Final Score Calculation</head><p>The base S base and bias S bias are linearly interpo- lated to derive the final sentiment value for the sen- tence s. </p><formula xml:id="formula_11">Score(s) = λS base + (1 − λ)S bias (7) λ ∈ [0, 1</formula><formula xml:id="formula_12">λ = σ(W sλ h base + W bλ h bias + b λ )<label>(8)</label></formula><p>where</p><formula xml:id="formula_13">h bias = h L e ⊕ h R s<label>(9)</label></formula><p>and </p><formula xml:id="formula_14">h base = m t=1 h L j t ⊕ h R j t m<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Training and Testing</head><p>Our training data contains two different settings. The first is binary sentiment classification. In this task, every sentence s i is annotated with a sentiment label l i , where l i = 0 and l i = 1 to indicate negative and positive sentiment, respectively. We apply logis- tic regression on the output layer. Denote the proba- bility of a sentence s i being positive and negative as p 1 s i and p 0 s i respectively. p 0 s i and p 1 s i are estimated as</p><formula xml:id="formula_15">p 1 s i = σ(Score(s i )) p 0 s i = 1 − p 1 s i<label>(11)</label></formula><p>Suppose that there are N training sentences, the loss function over the training set is defined as</p><formula xml:id="formula_16">L(Θ) = − N i=1 log p l i s i + λ r 2 ||Θ|| 2 ,<label>(12)</label></formula><p>where Θ is the set of model parameters. λ r is a pa- rameter for L2 regularization. The second setting is multi-class classification. In this task, every sentence s i is assigned a sentiment label l i from 0 to 4, which represent very negative, negative, neutral, positive and very positive, respec- tively. We apply least square regression on the out- put layer. Since the output range of 2tanh is <ref type="bibr">[-2, 2]</ref>, the value of the base score and the bias score both belongs to <ref type="bibr">[-2, 2]</ref>. The final score is a weighted sum of the base score and the bias score, also belonging to <ref type="bibr">[-2, 2]</ref>. However, the gold sentiment label ranges Positive Negative <ref type="table" target="#tab_1">Total  Train  3,009  1,187  4,196  Dev  483  283  766  Test  1,313  490</ref> 1,803  from 0 to 4. We add an offset -2 to every gold sen- timent label to both adapt our model to the train- ing data and to increase the interpretability of the learned weights. The loss function for this problem is then defined as</p><formula xml:id="formula_17">L(Θ) = N i=1 (Score(s i ) − l i ) 2 + λ r 2 ||Θ|| 2 (13)</formula><p>During testing, we predict the sentiment label l * i of a sentence s i by </p><formula xml:id="formula_18">l * i =               </formula><p>4 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>Data. We test our model on three datasets, includ- ing a dataset on Twitter sentiment classification, a dataset on movie review and a dataset with mixed domains. The Twitter dataset is taken from Se- mEval 2013 <ref type="bibr" target="#b49">(Nakov et al., 2013</ref>). We downloaded the dataset according to the released ids. The statis- tics of the dataset are shown in <ref type="table" target="#tab_1">Table 1</ref>. The movie review dataset is Stanford Sentiment Treebank 2 (SST) ). For each sen- tence in this treebank, a corresponding constituent Polarity books dvds electronics music videogames <ref type="table" target="#tab_1">Positive 19 19  19  20  20  Negative 29 20  19  20  20   Table 3</ref>: Document distribution of the mixed domain dataset.</p><p>tree is given. Each internal constituent node is an- notated with a sentiment label ranging from 0 to 4. We follow Socher et al. (2011) and  to perform five-class and binary classification, with the data statistics being shown in <ref type="table" target="#tab_2">Table 2</ref>.</p><p>In order to examine cross-domain robustness, we apply our model on a product review cor- pus <ref type="bibr" target="#b59">(Täckström and McDonald, 2011</ref>), which con- tains 196 documents covering 5 domains: books, dvds, electronics, music and videogames. The doc- ument distribution is listed in <ref type="table">Table 3</ref>.</p><p>Lexicons. We use four sentiment lexicons, namely TS-Lex, S140-Lex, SD-Lex and SWN-Lex. TS-Lex 3 is a large-scale sentiment lexicon built from Twitter by <ref type="bibr" target="#b61">Tang et al. (2014a)</ref> for learning sentiment-specific phrase embeddings. S140-Lex 4 is the Sentiment140 lexicon, which is built from point-wise mutual information using distant super- vision ( <ref type="bibr" target="#b31">Go et al., 2009;</ref><ref type="bibr" target="#b46">Mohammad et al., 2013)</ref>. SD-Lex is built from SST. We construct a sen- timent lexicon from the training set by excluding all neutral words and adding the aforementioned offset -2 to each entry. SWN-Lex is a sentiment lexicon extracted from SentimentWordNet3.0 ( <ref type="bibr" target="#b20">Baccianella et al., 2010)</ref>. For words with different part- of-speech tags, we keep the minimum negative score or the maximum positive score. The original score in the SentimentWordNet3.0 is a probability value between 0 and 1, and we scale it to <ref type="bibr">[-2, 2]</ref>  <ref type="bibr">5</ref> .</p><p>When building these lexicons, we only use the sentiment scores for unigrams. Ambiguous words are discarded. Both TS-Lex and S140-Lex are Twitter-specific sentiment lexicons. They are used in the Twitter sentiment classification task. SD-Lex and SWN-Lex are exploited for the Stanford dataset. The statistics of lexicons are listed in <ref type="table">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lexicon</head><p>Positive <ref type="table" target="#tab_1">Negative Total  SD-Lex  2,547  2,448  4,995  SWN-Lex 15,568  17,412  32,980  TS-Lex  33,997  32,026  66,023  S140-Lex  24,156  38,312  62,468   Table 4</ref>: Statistics of sentiment lexicons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We implement our model based on the CNN toolkit. <ref type="bibr">6</ref> Parameters are optimized using stochastic gradient descent with momentum ( <ref type="bibr" target="#b57">Sutskever et al., 2013</ref>). The decay rate is 0.1. For initial learning rate, L2 and other hyper-parameters, we adopt the default values provided by the CNN toolkits. We select the best model parameter according to the classification accuracy on the development set.</p><p>For the Twitter data, we use the glove.twitter.27B 7 as pretrained word embeddings. For the Stan- ford dataset, following , we use glove.840B.300d 8 as pretrained word embeddings. Words that do not exist in both the training set and the pretrained lookup table are treated as out- of-vocabulary (OOV) words. Following <ref type="bibr" target="#b29">Dyer et al. (2015)</ref>, singletons in the training data are ran- domly mapped to UNK with a probability p unk dur- ing training. We set p unk = 0.1. All word em- beddings are fine-tuned. We use dropout ( <ref type="bibr" target="#b56">Srivastava et al., 2014</ref>) in the input layer to prevent overfitting during training.</p><p>One-layered BiLSTM is used for all tasks. The dimension of the hidden vector in LSTM is 150. The size of the second layer in <ref type="figure" target="#fig_2">Figure 3</ref> is 64. <ref type="table" target="#tab_3">Table 5</ref> shows results on the Twitter development set. Bi-LSTM is our model using the bias score S bias only, which is equivalent to bidirectional LSTM model of  and , since they use same features and only dif- fer in the output layer. Bi-LSTM+avg.lexicon is a baseline model integrating the average sen- timent scores of lexicon words as a feature, and Bi-LSTM+flex.lexicon is our final model, which considers both the Bi-LSTM score (S bias ) and the context-sensitive score (S base ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Development Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dict</head><p>Dev(%) Bi-LSTM None 84.2 Bi-LSTM+avg.lexicon S140-Lex 84.9 Bi-LSTM+flex.lexicon S140-Lex 86.4  Bi-LSTM+avg.lexicon improves the classifica- tion accuracy over Bi-LSTM by 0.7 point, which shows the usefulness of sentiment lexicons to re- current neural models using a vanilla method. It is consistent with previous research on discrete models. By considering context-sensitive weight- ing for sentiment words Bi-LSTM+flex.lexicon fur- ther outperforms Bi-LSTM+avg.lexicon, improv- ing the accuracy by 1.5 points (84.9 → 86.4), which demonstrates the strength of context-sensitive scor- ing. Base on the development results, we use Bi- LSTM+flex.lexicon for the remaining experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Main Results</head><p>Twitter. <ref type="table" target="#tab_4">Table 6</ref> shows results on the Twitter test set. SVM6 is our implementation of , which extracts six types of manual features from TS- Lex for SVM classification. The features include: (1) the number of sentiment words in the sentence; (2) the total sentiment scores of the sentence; (3) the maximum sentiment score; (4) the total positive and negative sentiment scores; (5) the sentiment score of the last word in the sentence. The system of <ref type="bibr" target="#b61">Tang et al. (2014a)</ref> is a state-of-the-art system that ex- tracts various manually designed features from TS- Lex, such as bag-of-words, term frequency, parts-of- speech, the sum of sentiment scores of all words in a tweet, etc, for SVM. The Bi-LSTM rows are our final models with different lexicons. Both SVM6 and Tang et al. (2014a) exploit dis- crete features. Compared to them, Bi-LSTM gives better accuracies without using lexicons, which demonstrates the relative strength of deep neural net- work for sentiment analysis. Compared with <ref type="bibr" target="#b61">Tang et al. (2014a)</ref>, our Bi-LSTM+TS-Lex model improves the sentiment classification accuracy from 82.4 to 87.6, which again shows the strength of context- sensitive features. S140-Lex gives slight improve- ments over TS-Lex.</p><p>SST. <ref type="table" target="#tab_5">Table 7</ref> shows the results on SST. We in- clude various results of recursive (the first block), convolutional (the second block), and sequential LSTM models (the fourth block). These neural mod- els give the recent state-of-the-art on this dataset. Our method achieves highly competitive accuracies. In particular, compared to sequential LSTMs, our best model gives the top result both on the binary and fine-grained classification task. This shows the usefulness of lexicons to neural models. In addition, SWN-Lex gives better results compared with SD- Lex. This is intuitive because SD-Lex is a smaller lexicon compared to SWN-Lex (4,999 entries v.s. 32,980 entries). SD-Lex does not bring external knowledge to this dataset, while SWN-Lex does.</p><p>Cross-domain Results. Lexicon-based methods can be robust for cross-domain sentiment analy- sis <ref type="bibr" target="#b58">(Taboada et al., 2011</ref>). We test the robustness of our model in the mixed domain dataset of prod- uct reviews <ref type="bibr" target="#b59">(Täckström and McDonald, 2011</ref>   of sentences to the document level. We compare the effects of different lexicons over a baseline Bi- LSTM trained on SST (movie domain). <ref type="table" target="#tab_7">Table 8</ref> shows the results. Introducing the sen- timent lexicons SD-Lex and SWN-Lex consistently improves the classification accuracy across five do- mains compared with the baseline Bi-LSTM model. When trained and tested using the same lexicon, SWN-Lex gives better performances on three out of five domains. SD-Lex gives better results only on Electronics. This shows that the results are sensi- tive to the domain of the sentiment lexicon, which is intuitive.</p><p>We also investigate a model trained using SD- Lex but tested by replacing SD-Lex with SWN-Lex. This is to examine the generalizability of a source- domain model on different target domains by plug- ging in relevant domain-specific lexicons, without being retrained. Results show that the mode still out- performs the SD-Lex lexicon on two out of five do- mains, but is less accurate than full retraining using SWN-Lex. <ref type="figure" target="#fig_5">Figure 4</ref> shows the details of sentiment composition for two sentences in the SST, learned automatically by our model. For the first sentence, the three sub- jective words in the lexicon "pure", "excitement"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ID Sentence</head><p>Bi-LSTM SWN-Lex</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>The issue of faith is not explored very deeply 0 -1 2 Steers turns in a snappy screenplay that curls at the edges; it 's so clever you want to hate it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">1</head><p>3 A film so tedious that it is impossible to care whether that boast is true or not. -2 -1 and "not" receives weights of 1.6, 1.9 and −0.6, respectively, and the overall bias of the sentence is positive. A λ value (0.58) that slightly biases to- wards the base score leads to a final sentiment score is 1.8, which is close to the gold label 2. In the second example, both negation words re- ceived positive weight values, and the bias over the sentence is negative. A λ (0.3) value that biases towards the bias score results in a final score of −1.2, which is close to the gold label −1. These results demonstrate the capacity of the model to de- cide how word-level sentiments composite accord- ing to sentence-level context. <ref type="table" target="#tab_8">Table 9</ref> shows three sentences in the Stanford test set which are incorrectly classified by Bi- LSTM model, but correctly labeled by our Bi- LSTM+SWN-Lex model. These examples show that our model is more sensitive to context- dependent sentiment changes, thanks to the use of lexicons as a basis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We proposed a conceptually-simple, yet empirically effective method of introducing sentiment lexicon features to state-of-the-art LSTM models for sen- timent analysis. Compared to the simple averag-ing method in traditional bag-of-word models, our system leverages the strength of semantic feature learning by LSTM models to calculate a context- dependent weight for each word given an input sen- tence. The method gives competitive results on var- ious sentiment analysis benchmarks. In addition, thanks to the use of lexicons, our model can im- prove the cross-domain robustness of recurrent neu- ral models for sentiment analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>It</head><label></label><figDesc>'s an insignificant [criticism] −1→−0.5 . Nobody gives a [good] +3→−1 performance in this movie She's not [terrific] +5→+1 but not [terrible] −5→−1 either. It's not a very [good] +3→−0.25 movie song! It removes my [doubts] −3→+1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example sentiment compositions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Weight score calculation.</figDesc><graphic url="image-2.png" coords="4,379.80,57.83,93.60,105.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Here</head><label></label><figDesc>σ denotes the sigmoid activation function and ⊕ denotes vector concatenation. W sλ , W bλ and b λ are model parameters. The final score of the sentence is Score(s) = λS base + (1 − λ)S bias = λ m m t=1 τ jt score(w D jt ) + (1 − λ)S bias This corresponds to the original Equation 1 by γ jt = λ m τ jt and b = (1 − λ)S bias .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>− 2 if</head><label>2</label><figDesc>Score(s i ) ≤ −1.5 −1 if − 1.5 &lt; Score(s i ) ≤ −0.5 0 if − 0.5 &lt; Score(s i ) ≤ 0.5 1 if 0.5 &lt; Score(s i ) ≤ 1.5 2 if Score(s i ) &gt; 1.5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Sentiment composition examples.</figDesc><graphic url="image-3.png" coords="8,72.00,150.83,234.00,125.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Statistics of the Twitter dataset.</head><label>1</label><figDesc></figDesc><table>Task 
Label 
Training 
Sentences 
Dev 
Sentences 
Test 
Sentences 

5-class 

-2 
1,092 
139 
279 
-1 
2,218 
289 
633 
0 
1,624 
229 
389 
1 
2,322 
279 
510 
2 
1,288 
165 
399 

2-class 
0 
3,310 
444 
909 
1 
3,610 
428 
912 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Statistics of SST.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 5 : Results on the Twitter development set.</head><label>5</label><figDesc></figDesc><table>Method 
Test(%) 
SVM6 (Zhu et al., 2014) 
78.5 
Tang et al. (2014a) 
82.4 
Bi-LSTM 
86.7 
Bi-LSTM + TS-Lex 
87.6 
Bi-LSTM + S140-Lex 
88.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 6 :</head><label>6</label><figDesc>Results on the Twitter test set.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 7 :</head><label>7</label><figDesc>Results on SST. 5-class shows fine-grained classifica- tion. The last block lists our results.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head></head><label></label><figDesc>). This dataset contains document level sentiments. We take the majority voting strategy to transform sentiment</figDesc><table>Model 

Train 
Test 
Books Dvds Electronics Music Videogames Average 
Bi-LSTM 
None 
None 71.79 89.74 65.79 
95 
85 
81.63 
Bi-LSTM+flex.lexicon SD-Lex SD-Lex 76.92 84.62 78.95 
92.5 
80 
82.65 
Bi-LSTM+flex.lexicon SD-Lex SWN-Lex 82.05 92.31 73.68 
92.5 
80 
84.18 
Bi-LSTM+flex.lexicon SWN-Lex SWN-Lex 84.62 92.31 68.42 
100 
85 
86.22 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 8 : Cross-domain sentiment analysis. Training domain is movie review.</head><label>8</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Example predictions made by the Bi-LSTM model and 

our Bi-LSTM+SWN-Lex model for fine-grained classification 

task. Red words and blue words are positive and negative entries 

in the SentimentWordNet3.0 lexicon, respectively. 

</table></figure>

			<note place="foot" n="1"> Most sentiment lexicons assign a negative score to the word &quot;not&quot;.</note>

			<note place="foot" n="2"> http://nlp.stanford.edu/sentiment/index.html</note>

			<note place="foot" n="3"> http://ir.hit.edu.cn/ dytang/paper/14coling/data.zip 4 http://saifmohammad.com/Lexicons/Sentiment140Lexicon-v0.1.zip 5 Taboada et al. (2011) also mentioned two methods to derive sentiment score for a sentiment word from SentimentWordNet. We leave them for future work.</note>

			<note place="foot" n="6"> https://github.com/clab/cnn 7 http://nlp.stanford.edu/data/glove.twitter.27B.zip 8 http://nlp.stanford.edu/data/glove.840B.300d.zip</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Yue Zhang is the corresponding author. Thanks to anonymous reviewers for their helpful com-ments and suggestions. Yue Zhang is supported by NSFC61572245 and T2MOE201301 from Sin-gapore Ministry of Education.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rae (</forename><surname>Socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="43" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mv-Rnn (</forename><surname>Socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="44" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rntn (</forename><surname>Socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="45" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cardie</forename><surname>Drnn (irsoy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dependency</forename><surname>Treelstm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Tai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="48" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constituency</forename><surname>Treelstm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Tai</surname></persName>
		</author>
		<idno>0 88.0</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">51</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constituency</forename><surname>Treelstm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="50" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S-Lstm (</forename><surname>Zhu</surname></persName>
		</author>
		<idno>49.9 88.0</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Le and Zuidema</publisher>
			<biblScope unit="volume">50</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<idno>48.0 87.2</idno>
		<title level="m">CNN-non-static</title>
		<meeting><address><addrLine>Kim</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cnn-Multichannel (</forename><surname>Kim</surname></persName>
		</author>
		<idno>47.4 88.1</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dcnn (kalchbrenner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="48" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Paragraph-Vec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikolov</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nbow (kalchbrenner</surname></persName>
		</author>
		<idno>42.4 80.5</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Svm (socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="40" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Bilstm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="49" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Bilstm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hier-Sequence (li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Lstm+sd-Lex</forename><surname>Bi</surname></persName>
		</author>
		<idno>50.0 88.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Lstm+swn-Lex</forename><surname>Bi</surname></persName>
		</author>
		<idno>51.1 89.2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sentiment analysis of twitter data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyi</forename><surname>References Apoorv Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilia</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Vovsha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Languages in Social Media</title>
		<meeting>the Workshop on Languages in Social Media</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="30" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Baccianella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="2200" to="2204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Affective computing and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="102" to="107" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning with compositional semantics as structural inference for subsentential sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="793" to="801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Are sentiwordnet scores suited for multi-domain sentiment classification? In ICDIM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kerstin</forename><surname>Denecke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Sentiment polarity identification in financial news: A cohesionbased approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Devitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khurshid</forename><surname>Ahmad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A holistic lexicon-based approach to opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 International Conference on Web Search and Data Mining</title>
		<meeting>the 2008 International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="231" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adaptive recursive neural network for target-dependent twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="49" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Transitionbased dependency parsing with stack long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sentiwordnet: A publicly available lexical resource for opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="417" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Twitter sentiment classification using distant supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richa</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">12</biblScope>
			<pubPlace>Stanford, 1</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">CS224N Project Report</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Speech recognition with deep recurrent neural networks</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sentiment analysis: How to derive prior polarities from SentiWordNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Gatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1259" to="1269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD, KDD &apos;04</title>
		<meeting>KDD, KDD &apos;04</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep recursive neural networks for compositionality in language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2096" to="2104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="655" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Textual sentiment in finance: A survey of methods and models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colm</forename><surname>Kearney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sha</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Review of Financial Analysis</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="171" to="185" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Determining the sentiment of opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Soo-</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics</title>
		<meeting>the 20th international conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">1367</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Sentiment analysis of short informal texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res. (JAIR)</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="723" to="762" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Mohammad</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
		<idno>abs/1405.4053</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Compositional distributional semantics with long short term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willem</forename><surname>Zuidema</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the Fourth Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="10" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multi-timescale long shortterm memory neural network for modelling sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eudard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">When are tree structures necessary for deep learning of representations? Pengfei Liu, Xipeng Qiu, Xinchi Chen, Shiyu Wu, and Xuanjing Huang</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2326" to="2335" />
		</imprint>
	</monogr>
	<note>Proceedings of EMNLP</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Nrc-canada: Building the state-of-theart in sentiment analysis of tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval-2013</title>
		<meeting>SemEval-2013</meeting>
		<imprint>
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karo</forename><surname>Moilanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Pulman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Sentiment composition</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Formal Philosophy: Selected Papers of Richard Montague</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Montague</surname></persName>
		</author>
		<editor>Richmond H. Thomason</editor>
		<imprint>
			<date type="published" when="1974" />
			<publisher>Yale University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Semeval-2013 task 2: Sentiment analysis in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second Joint Conference on Lexical and Computational Semantics (*SEM)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="312" to="320" />
		</imprint>
	</monogr>
	<note>Proceedings of SemEval-2013</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Phrasernn: Phrase recursive neural network for aspect-based sentiment analysis</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<editor>Thien Hai Nguyen and Kiyoaki Shirai</editor>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Contextual valence shifters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livia</forename><surname>Polanyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Zaenen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing attitude and affect in text: Theory and applications</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Context-sensitive twitter sentiment classification using neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafeng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Semantic compositionality through recursive matrix-vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brody</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1201" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th international conference on machine learning (ICML-13)</title>
		<meeting>the 30th international conference on machine learning (ICML-13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Lexicon-based methods for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maite</forename><surname>Taboada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Tofiloski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimberly</forename><surname>Voll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="307" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Discovering fine-grained sentiment with latent variable structured prediction models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="368" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Improved semantic representations from tree-structured long short-term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai Sheng</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1556" to="1566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Building large-scale twitter-specific sentiment lexicon : A representation learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<editor>Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Liu, and Bing Qin</editor>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="1555" to="1565" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Target-dependent twitter sentiment classification with rich automatic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duy-Tin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="1347" to="1353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Predicting polarities of tweets by composing word embeddings with long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanchao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sun</forename><surname>Chengjie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1343" to="1353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity in phrase-level sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-EMNLP</title>
		<meeting>HLT-EMNLP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Gated neural networks for targeted sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duy-Tin</forename><surname>Vo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Nrc-canada-2014: Recent improvements in the sentiment analysis of tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohammad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Long short-term memory over tree structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Guo</surname></persName>
		</author>
		<idno>abs/1503.04881</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
