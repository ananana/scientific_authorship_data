<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">QuaSE: Sequence Editing under Quantifiable Guidance *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab 3 Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piji</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Shi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab 3 Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab 3 Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">QuaSE: Sequence Editing under Quantifiable Guidance *</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3855" to="3864"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3855 * The work described in this paper was done when Yi Liao was an intern at Tencent AI Lab. The work is partially supported by a grant from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Code: CUHK413510) 1 Our code and data are available at https:// bitbucket.org/leoeaton/quase/src/master/</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose the task of Quantifiable Sequence Editing (QuaSE): editing an input sequence to generate an output sequence that satisfies a given numerical outcome value measuring a certain property of the sequence, with the requirement of keeping the main content of the input sequence. For example, an input sequence could be a word sequence, such as review sentence and advertisement text. For a review sentence, the outcome could be the review rating; for an advertisement, the outcome could be the click-through rate. The major challenge in performing QuaSE is how to perceive the outcome-related wordings, and only edit them to change the outcome. In this paper , the proposed framework contains two latent factors, namely, outcome factor and content factor, disentangled from the input sentence to allow convenient editing to change the outcome and keep the content. Our framework explores the pseudo-parallel sentences by modeling their content similarity and outcome differences to enable a better disentan-glement of the latent factors, which allows generating an output to better satisfy the desired outcome and keep the content. The dual reconstruction structure further enhances the capability of generating expected output by exploiting the couplings of latent factors of pseudo-parallel sentences. For evaluation, we prepared a dataset of Yelp review sentences with the ratings as outcome. Extensive experimental results are reported and discussed to elaborate the peculiarities of our framework. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Typical neural text generation is observed suffer- ing from the problems of repetitions in word n- grams, producing monotonous language, and gen- erating short common sentences ( <ref type="bibr" target="#b9">Li et al., 2017)</ref>.</p><p>To solve these problems, some researchers branch out into the way of post-editing (could be under some guidance, say sentiment polarity) a given message to generate text of better quality. For example, skeleton-based text generation first out- lines a skeleton in the form of phrases/words, and then starts from the skeleton to generate text ( <ref type="bibr" target="#b21">Wang et al., 2017;</ref><ref type="bibr" target="#b22">Xiao et al., 2016)</ref>. Another line of works conduct editing on an existing sen- tence and expect that the output will serve particu- lar purposes better ( <ref type="bibr" target="#b5">Guu et al., 2018)</ref>. Similarly in conversation, some systems post-edit the retrieval results to generate new sentences as the response ( <ref type="bibr" target="#b19">Song et al., 2016)</ref>. The third type is to perform editing on the input under the guidance of specific style. For example,  take a sen- tence with negative sentiment as input, and edit it to transfer its sentiment polarity into positive.</p><p>In this paper, we generalize the third type of post-editing into a more general scenario, named Quantifiable Sequence Editing (QuaSE). Specif- ically, in the training stage, each input sentence is associated with a numeric outcome. For exam- ple, the outcome of a review sentence is its rating, ranging from 1 to 5; the outcome of each adver- tisement is its click-through rate. In the test stage, given an input sentence and a specified outcome target, a model needs to edit the input to generate a new sentence that will satisfy the outcome tar- get with high probability. Meanwhile, the output sentence should keep the content described by the input. For example, given the input sentence "The food is terrible", a desired output sentence could be "The food is OK" under the expected outcome "3.1" (a neutral sentiment), and "The food is de- licious" under the expected outcome "4.0". If no outcome target is given, the model could generate "The food is extremely delicious", by defaulting the best outcome, or "The food is extremely terri- ble", by defaulting the worst outcome.</p><p>Our problem setting is more general than pre- vious works in two major aspects: (1) The out- come here is numerical, and it can be regarded as a generalization of the categorical outcome in <ref type="bibr" target="#b6">Hu et al., 2017;</ref><ref type="bibr" target="#b3">Gao et al., 2018)</ref>. With such numerical outcome, it is impossible to construct two corpora as counterpart of each other as done in <ref type="bibr" target="#b3">Gao et al., 2018)</ref>. <ref type="formula">(2)</ref> The editing operation is under a quantifiable guidance, i.e. the specified outcome or the de- faulted extrema. For example, we can specify a particular target rating, such as 3.1 or 4.0, as the expected outcome. Although <ref type="bibr" target="#b14">Mueller et al. (2017)</ref> also take outcome-associated sentences for train- ing, their model does not perform such outcome- guided editing for sentence generation.</p><p>Considering that the goal of the task is to gen- erate an output that satisfies a specified outcome and keeps the content unchanged, QuaSE is chal- lenging in a few aspects. Firstly, a model should be able to perceive the association between an out- come and its relevant wordings. For the previous example "The food is terrible", the model needs to figure out that the low rating is indicated by the word "terrible", instead of "food". Secondly, when performing editing, the model should keep the content, and only edits the outcome-related wordings. Moreover, the model needs to take a specified outcome into account and generate an output that satisfies the specified outcome value with high probability. Continuing the running ex- ample, given the expected outcome 3.1, "The food is OK" is an appropriate output, but "The food is extremely delicious" and "The service is OK" are not. Thirdly, we do not have readily available data, such as data points like [input sentence: "The food is terrible", expected outcome: 4.0, output sen- tence: "The food is delicious"] to show the model what the revised output should look like, that meet our need to train models.</p><p>We propose a framework to address this task. The fundamental module of our framework is a Variational Autoencoder (VAE) <ref type="bibr" target="#b8">(Kingma and Welling, 2013)</ref> to encode each input sentence into a latent content factor and a latent outcome fac- tor, capturing the content and the outcome related wordings respectively. We propose to leverage pseudo-parallel sentence pairs (i.e, the two sen- tences in a pair have the same or very similar con- tent, but different outcome values) to enhance our model's capability of disentangling the two fac- tors, which allows attributing the wording differ- ence of the sentences in a pair to the outcome factor, and the wording similarity to the content factor. For sentence reconstruction, we employ a Recurrent Neural Network (RNN) based decoder ( <ref type="bibr" target="#b20">Sutskever et al., 2014</ref>) that takes as input the com- bination of a content factor and an outcome fac- tor. To further enhance the capability of generat- ing expected output, we introduce a dual recon- struction structure which exploits the couplings of latent factors of pseudo-parallel sentences. Specif- ically, it attempts to reconstruct one sentence in a pair from the combination of its outcome fac- tor and the other sentence's content factor, based on the intuition that the wording difference in a pair is outcome-related. In the test stage, taking a sentence and a specified outcome target as in- put, our model generates a revised sentence which likely satisfies the specified target, and meanwhile the content is preserved as much as possible.</p><p>To evaluate the efficacy of our framework, we prepared a dataset of Yelp review sentences with the ratings as outcome. Compared with state- of-the-art methods handling similar tasks, exper- imental results show that our framework can gen- erate more accurate revisions to satisfy the target outcome and transfer the sentiment polarity, mean- while it keeps the original content better. Ablation studies illustrate the effectiveness of the designed components for enhancing the performance. We have released the prepared dataset and the code of our model to facilitate other researchers to do fur- ther research along this line, refer to Footnote 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Setting and Model Overview</head><p>In the task of Quantifiable Sequence Editing (QuaSE), the aim is to edit an input sentence X 0 under the guidance of an expected outcome value R * to generate a new sentence X * that will satisfy R * with high probability. For training a model, we are given a set of sentence-outcome tuples (X, R).</p><p>Our proposed model for training is depicted in <ref type="figure">Figure 1</ref>. The left hand side models individual sentences. Specifically, it employs two encoders,</p><formula xml:id="formula_0">R Y X Z y x z y x z f (x, x ) h(y, y ) E 1 D F D E 2 E 1 E 1 E 2 E 2 L d−rec L sim L dif f Figure 1: Model Overview.</formula><p>i.e. E 1 and E 2 , to encode a single sentence X into two latent factors Y and Z which capture the out- come and content properties respectively. In con- trast, <ref type="bibr" target="#b14">Mueller et al. (2017)</ref> employ a single fac- tor for capturing these two properties, which lim- its the capability of distinguishing one property from the other. As a consequence, when editing a sentence towards a given outcome, the sentence content is likely to be changed, which should be suppressed as much as possible. An RNN-based decoder D takes the concatenation of Y and Z to reconstruct the input X. Moreover, a transforma- tion function F predicts R with Y . The right hand side models pseudo-parallel sentence pairs (automatically generated from the above tuples), so we first introduce the concept of pseudo-parallel sentences as follows. Let (x, x ) denote a pair of pseudo-parallel sentences, x and x should describe the same or similar con- tent, but their outcomes are different. Note that we use lowercase letters to denote variables re- lated to sentence pairs for better clarity. For two sentences in a pair, the difference of their outcome factors h(y, y ) is attributed to their wording dif- ference f (x, x ), resulting in the loss L dif f ; the similar contents of two sentences should result in similar content factors, i.e. minimizing the loss L sim ; moreover, a dual reconstruction loss L d−rec is minimized to enhance the capability of generat- ing expected output.</p><p>Overall, the model minimizes the losses from modeling single sentences and sentence pairs. Af- ter the model is trained, a separated component is applied for editing an input sentence to output a revision that satisfies a specified outcome target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Modeling Single Sentences</head><p>In probabilistic theory, we need to maximize the log-likelihood of observing the training sentence- outcome tuples (X,R), denoted as follows:</p><formula xml:id="formula_1">log p(X, R) = log p(X|Y, Z)p(Y, Z)dY dZ + log p(R|Y )p(Y )dY<label>(1)</label></formula><p>However, the integration in the first term on the right hand side is intractable. Inspired by the idea of VAE ( <ref type="bibr" target="#b8">Kingma and Welling, 2013)</ref>, we al- ternatively maximize the Evidence Lower Bound (ELBO) ( <ref type="bibr" target="#b0">Blei et al., 2016</ref>) incorporating varia- tional distributions, i.e. q(Y |X) and q(Z|X). Thus, this term is approximated as follows:</p><formula xml:id="formula_2">log p(X|Y, Z)p(Y, Z)dY dZ ≥ −[L rec + L kl ] L rec = −E Y,Z∼q(Y |X),q(Z|X) [log p(X|Y, Z)] L kl = KL[q(Y |X)|p(Y )] + KL[q(Z|X)|p(Z)] (2)</formula><p>where, the term L rec denotes the error of re- constructing X.</p><p>As advocated by <ref type="bibr" target="#b8">(Kingma and Welling, 2013)</ref> and <ref type="bibr" target="#b1">(Bowman et al., 2016)</ref>, the variational distributions q(Y |X) and q(Z|X) are modelled as Gaussian distributions, i.e.</p><formula xml:id="formula_3">q(Y |X) = G(µ Y |X , σ Y |X )</formula><p>, and q(Z|X) = G(µ Z|X , σ Z|X ). The expectation E(·) can be effi- ciently approximated using one Monte-Carlo sam- ple, for example, Y ∼ q(Y |X) and Z ∼ q(Z|X). In practise, we can alternatively employ Y = µ Y |X and Z = µ Z|X instead of sampling since they are the means of the Gaussian distributions. We employ two encoder networks E 1 and E 2 to generate µ Y |X and µ Z|X respectively from the sentence X, i.e. µ Y |X = E 1 (X) and µ Z|X = E 2 (X). p(X|Y, Z) is the probability of observing the sentence X given Y and Z, which is modelled by a decoder network D. Thus, the reconstruction loss can be rewritten as:</p><formula xml:id="formula_4">L rec = H(X, D(E 1 (X), E 2 (X))) (3)</formula><p>where H is the cross entropy loss for the decoder.</p><p>The term L kl in Equation 2 denotes the KL- divergence between the variational posterior dis- tribution and the prior distribution. Following pre- vious works <ref type="bibr" target="#b14">(Mueller et al., 2017)</ref>, the priors p(Y ) and p(Z) are defined as a zero-mean Gaussian dis- tribution, i.e. p(Y ) = p(Z) = G(0, I). The loss L kl serves as a regularization term enforcing that the variational posterior distribution resembles the prior distribution, which also avoids overfitting.</p><p>The second term in Equation 1 models the log- likelihood of the outcomes. We adopt the usu- ally used Taylor approximation for the calculation, where this term is approximated by an affine trans- formation from the outcome factor Y to the out- come R, denoted as F (Y ). Then, we define the loss as the square error between R and F (Y ):</p><formula xml:id="formula_5">L mse = (R − F (Y )) 2<label>(4)</label></formula><p>Although <ref type="bibr" target="#b14">Mueller et al. (2017)</ref> also model in- dividual sentences and their outcomes, in their model, each sentence is only encoded into one la- tent factor to capture both outcome and content properties. In contrast, we disentangle two la- tent factors from a single sentence to model the outcome and the content separately to provide more flexibility. Moreover, such design allows the incorporation of the pseudo-parallel sentences, which will be described in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Exploiting Pseudo-Parallel Sentences</head><p>As mentioned above, pseudo-parallel sentences are similar in terms of the content but different in terms of the outcome. E.g., <ref type="table">Table 1</ref> shows a pair of pseudo-parallel sentences, where both talk about "the restaurant", but with different sentiments (i.e. ratings). For the pair (x, x ), let y and y denote their outcome factors, z and z denote their content factors. We design three components to leverage pseudo-parallel sentences to enhance our model's capabilities of disentangling the two types of fac- tors and generating the desired output sentences.</p><p>x I will never come back to the restaurant. x I will definitely come back to the restaurant, recommend! <ref type="table">Table 1</ref>: A pair of pseudo-parallel sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Modeling Outcome Difference</head><p>We exploit the wording difference f (x, x ) be- tween x and x . Note that the preparation (dis- cussed in Section 4.1) determines that a pair of pseudo-parallel sentences are very likely to dif- fer in the outcome factors, denoted as h(y, y ). Thus, by aligning the surface wording difference of two sentences in a pair and the difference in their outcome factors, we intend to improve the performance of the encoder E 1 for generating the outcome factor. f (x, x ) and h(y, y ) are defined as follows:</p><formula xml:id="formula_6">f (x, x ) =inc(x, x ) ⊕ dec(x, x ) h(y, y ) =y − y = E 1 (x) − E 1 (x )<label>(5)</label></formula><p>where inc(x, x ) and dec(x, x ) are embeddings capturing the wording difference between x and x . inc(x, x ) denotes the "increment" from x to x , i.e. the terms that appear in x but not in x. dec(x, x ) denotes the "decrement". If there are multiple terms in the difference, we sample one term for inc or dec. For the example in <ref type="table">Ta- ble 1</ref>, dec(x, x ) is the embedding of "never", and inc(x, x ) could be the embedding of "definitely" or "recommend". The effect of outliers during sampling anneals since the training data contain sufficient pairs of sentences. The symbol ⊕ de- notes concatenation. h(y, y ) is defined as the sub- traction between the outcome factors.</p><p>We employ a regression network U to align f (x, x ) and h(y, y ), and the loss L dif f is:</p><formula xml:id="formula_7">L dif f = ||h(y, y ) − U [f (x, x )]|| 2<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Modeling Content Similarity</head><p>Another property of two pseudo-parallel sentences is that they share similar content. To capture it, we design a loss function minimizing the square error between the content factors.</p><formula xml:id="formula_8">L sim = ||z − z || 2 = ||E 2 (x) − E 2 (x )|| 2 (7)</formula><p>Minimizing L sim helps the encoder E 2 generate the content factor more accurately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Dual Reconstruction</head><p>The decoder D is not only used in Section 2.2 to reconstruct a single training sentence, but also em- ployed for generating output sentences in the test stage (Section 3). To improve the robustness of D, we propose a dual reconstruction component based on the pseudo-parallel sentences. Different from reconstructing an original sentence in Sec- tion 2.2, in the dual reconstruction, given a sen- tence x, we reconstruct its dual sentence x . Specifically, we first encode x and x into their outcome factors y/y and content factors z/z . Since x shares similar content with x , its content factor z, when combined with the outcome factor y of x , should nearly reconstruct x . For such dual reconstruction, the loss is written as:</p><formula xml:id="formula_9">L d−rec x ;x =H(x , D(E 1 (x ), E 2 (x))) =H(x , D(y , z))<label>(8)</label></formula><p>The same dual reconstruction process applies to the counterpart of x , i.e. x. Thus, the whole dual reconstruction loss is as follows:</p><formula xml:id="formula_10">L d−rec = L d−rec x ;x + L d−rec x;x<label>(9)</label></formula><p>Note that the encoders E 1 /E 2 and the decoder D here refer to exactly the same networks (i.e., the parameters are shared) as used in Section 2.2. The specific design of the networks are as fol- lows. E 1 /E 2 : RNNs of GRUs with a fully con- nected neural network appended to the last state to add some noise, which is</p><note type="other">a reparameterization alternative for sampling. Their outputs are the out- come and content factors, respectively. D: An RNN of GRU cells. The RNN takes the concate- nation of an outcome factor and a content factor as the initial state for decoding. F : A fully con- nected network. It takes an outcome factor as in- put and outputs an outcome value. U : A fully con- nected network. It takes f (x, x ) as input to pre- dict h(y, y ).</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Joint Training</head><p>Considering all the aforementioned components, we define a joint loss function as:</p><formula xml:id="formula_11">L joint =λ rec L rec + λ kl L kl + λ mse L mse + λ dif f L dif f + λ sim L sim + λ d−rec L d−rec<label>(10)</label></formula><p>in which each component is associated with a weight. Following the sigmoid annealing schedule (Bowman et al., 2016), we design the following strategy to tune the weights: (1) Tune the weights λ rec and λ mse on the validation dataset under the metric MAE (refer to Section 4.3), while fixing the other weights to zeros. We set λ rec +λ mse = 1; (2) Fixed the weights tuned in the first step. For each remaining loss, gradually increase the weight from 0 to 1 during the training, until the reconstruction loss L rec or the outcome prediction loss L mse be- comes worse. The strategy prioritizes L rec and L mse , since they are the core components for gen- erating the revised sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Editing under Quantifiable Guidance</head><p>In the test, the trained model edits an input sen- tence X 0 and outputs a revision X * that is likely to satisfy the specified outcome target R * , and mean- while preserves the content as much as possible.</p><p>We first encode X 0 with E 1 and E 2 to get Y 0 and Z 0 respectively. The next step is to modify Y 0 to get a new outcome factor Y * that is likely to generate the target outcome R * . The process to determine a suitable Y * is as follows. We first assume Y follows the Gaussian distribution Y ∼ G(Y 0 = E 1 (X 0 ), σ), the mean of which is Y 0 .</p><p>Then we choose C = {Y : G(Y |E 1 (X 0 ), σ) &gt; τ } as the feasible range for Y * , where τ is a thresh- old. C will expand if τ is set smaller, and thus al- lowing more revisions. Finally, Y * is determined as follows:</p><formula xml:id="formula_12">Y * = arg min Y ∈C (F (Y ) − R * ) 2<label>(11)</label></formula><p>Note that in ( <ref type="bibr" target="#b14">Mueller et al., 2017</ref>), Y * is deter- mined as arg max Y ∈C F (Y ), which does not con- sider an outcome target. The revised sentence X * is generated from X 0 and Y * via the decoder D:</p><formula xml:id="formula_13">X * = D(Y * , Z 0 )<label>(12)</label></formula><p>Thus, the content of X 0 is preserved with Z 0 , and the expected outcome is achieved with Y * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments 4.1 Dataset Preparation</head><p>Our dataset contains sentences extracted from Yelp reviews 2 , where each review is associated with a rating in {1, 2, 3, 4, 5}. Specifically, we employ the sentences with sentiment polarity (i.e. positive or negative) used in (  as the primary portion of our data. After some clean- ing, we obtain about 520K sentences. To add neu- tral sentences, we randomly select 80K sentences from the original reviews with neutral sentiment (i.e. rating 3). To make sure that the neural sen- tences added by us are describing the same do- main, we only pick neural sentences whose tokens are all in the vocabulary of the primary data. The vocabulary size of the dataset is 9,625. In total, our dataset contains 599K sentences, and we ran- domly hold 50K for test, 10K for validation, and the remaining for training. For training, we need each input sentence be- ing associated with a rating value, and for test, we need to measure the rating of a generated sen- tence to check if the generated sentence satisfies the specified outcome target. Therefore, an au- tomatic method is needed for measuring the rat- ing values of training sentences and generated sen- tences. We employ the sentiment analyzer in Stan- ford CoreNLP ( <ref type="bibr" target="#b12">Manning et al., 2014</ref>) to do so. Specifically, we first invoke CoreNLP to output the probability of each rating in {1, 2, 3, 4, 5} for a sentence, then we take the sum of the probability- multiplied ratings as the sentence rating. Some statistics of the data is given in <ref type="table" target="#tab_0">Table 2</ref>. Hereafter, we use "rating" and "outcome" interchangeably.  One may think that would it be possible to use the original rating given by Yelp users as outcome for training? We did not use it for two reasons: (1) We want the ratings of training sentences and generated sentences are measured with a consis- tent method; (2) In fact, we find that the predicted rating with CoreNLP has a Pearson correlation of 0.85 with the rating given by users. Note that the original Yelp data only has ratings for entire re- views. We derived the sentence ratings by users like this: a sentence takes as its rating the average of the ratings of those reviews where it appears in. Human evaluation in  shows that a similar method for deriving polarity is basically reasonable as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rating interval [1, 2) [2, 3) [3, 4) [4, 5]</head><p>For preparing the pseudo-parallel sentences, we first follow the ideas in ( <ref type="bibr" target="#b5">Guu et al., 2018</ref>) to gen- erate some initial pairs. Specifically, we first cal- culate the Jaccard Index (JI) for each pair of sen- tences, and keep those with JI values no less then 0.5 as the initial pairs. Note that such initial pairs could contain many false positives (roughly 10% as manually evaluated on the Yelp corpus in ( <ref type="bibr" target="#b5">Guu et al., 2018)</ref>), because the JI calculation does not distinguish content words and outcome words. To solve this problem, we add another constraint: for an initial pair to be regarded as a pseudo-parallel sentence pair, the difference of the two sentences' ratings should be no less than 2. Here, the idea is that given the two sentences are similar enough in wordings (JI ≥ 0.5), if their rating scores are dissimilar enough, it looks plausible to conjec- ture that their wording difference is more likely outcome-related and causes the rating difference. In fact, such wording difference is exactly what we want to capture with pseudo-parallel sentence pairs. In total, we obtain about 604K sentence pairs from the single training sentences. For con- ducting the joint training with both single sen- tences and pseudo-parallel pairs, we make each data point composed of a single sentence and a sentence pair. To do so, we couple each sen- tence pair with a single sentence, thus we can use all pairs for training. Note that because we have more sentence pairs, some single sentences are used twice randomly in composing the data points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparative Methods</head><p>Our model is compared with two state-of-the-art models handling similar tasks.</p><p>Sequence to Better Sequence (S2BS) <ref type="bibr" target="#b14">(Mueller et al., 2017)</ref>: For training, S2BS also requires each sentence is associated with an outcome. For test, S2BS only revises a sentence such that the output is associated with a higher outcome, which is not a specified value. For comparison, we adapt our revision method for S2BS, by which their trained model is able to conduct quantifiable sentence re- vision. We tune the parameters for S2BS by fol- lowing the suggestions in their source code.</p><p>Text Style Transfer (TST) : In TST, the sentiment of each sentence is labelled as negative or positive. The model is able to revise a negative sentence into positive, or vice versa. Their task can be treated as a special case of our QuaSE task: we set the outcome target to 1 for the input sentences that are associated with out- comes larger than the neutral rating 3, thus, our task is equal to revising a positive sentence into negative. We follow the suggested parameters re- ported in ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Metric and Parameter Setting</head><p>Considering that our model's task is to revise a sentence such that its outcome (predicted by Stan- ford CoreNLP) satisfies a specified target, we de- fine the metric as the mean absolute error (MAE) between the specified target outcome and the out- comes of revised sentences.</p><formula xml:id="formula_14">M AE = 1 |S| X i ∈S |R i − R * | (13)</formula><p>where S is the set of revised sentences X i , R * is the target outcome, and R i is the outcome of X i . After tuning on the validation set, the deter- mined parameters are: λ rec = 0.75, λ kl = 0.6, λ mse = 0.25, λ dif f = 0.2, λ sim = 0.2, λ d−rec = 0.1, and the dimensions of the two factors are both 50. The parameter τ for revision takes exp(−100000) for both our model and S2BS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Automatic Evaluation</head><p>We compare our model with S2BS by specify- ing five target ratings, namely 1, 2, 3, 4, and 5. Both our model and S2BS are fed the sentences in the testing dataset. For each sentence, both models are required to generate five revised sen- tences, each satisfying one of the target ratings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAE</head><p>Edit <ref type="table" target="#tab_0">Distance  T=1  T=2  T=3  T=4  T=5  T=1  T=2  T=3  T=4  T=5  Original  2.2182 1</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.2379 0.8259 0.9279 1.7818 N/A N/A N/A N/A N/A S2BS</head><p>1.6839 0.9444 0.7567 0.7572 1.3024 6.6439 5.342 4.9390 5.005 6.2290 Our Model 1.4162 0.6298 0.7408 0.5377 0.9408 7.9191 4.7 3.4505 4.13 8.0094 <ref type="table">Table 3</ref>: MAE and Edit Distance for our proposed model and S2BS. T refers to the target outcome.</p><p>We evaluate the MAE between the target outcome and the outcome of the revised sentences. Each model is trained for three times and the average results are reported in <ref type="table">Table 3</ref>. "Original" refers to the MAE between the targets and the ratings of in- put sentences. We can observe that the MAE val- ues of both our model and S2BS are smaller than Original. It demonstrates that both models are able to revise the sentences towards the outcome targets. Furthermore, compared with S2BS, our model achieves smaller MAE values. One major reason is that we disentangle a content factor and an outcome factor, and design three components to leverage pseudo-parallel sentences. By mod- eling the wording difference, our model captures the keywords that cause the difference in the out- come. By enforcing the content factors of pseudo- parallel sentences to be similar, the model is capa- ble to generate the content factor more precisely. Moreover, the dual reconstruction can guide the editing procedure with the hints from the paral- lel sentences. In contrast, S2BS only disentangles one factor for capturing both content and outcome properties, and thus it cannot perform the same op- erations on sentence pairs. The MAE for T=5 is smaller than that for T=1. This is partially due to the fact that the outcomes of the test sentences are closer to 5, refer to <ref type="table" target="#tab_0">Table 2</ref>. We also report the average Edit Distance between the input sen- tences and the generated sentences to measure the degree of revisions. For T=1 and T=5, our model conducts more editing than S2BS, which brings in better MAE, while for T={2, 3, 4}, our model gen- erates more accurate sentences (i.e. better MAE) with less editing. This observation coincides with the fact that we need more editing to revise a sen- tence towards an extreme target (i.e., 1 and 5), such as including degree adverbs "very" and "ex- tremely".</p><p>We also compare our model with TST for senti- ment polarity transfer. We employ the same eval- uation metric as used in : the sentiment accuracy of the transferred sentences.   We define the revised sentences with ratings larger than 3 as positive, smaller than 3 as negative. The results are given in <ref type="table" target="#tab_2">Table 4</ref>, where two accuracy values are reported: negative to positive, and the reverse. The results show that our model achieves better accuracy than TST in both transfer direc- tions. One reason is that our method models the associations between each sentence and its out- come, and thus captures the sentiment wordings better. Our model is far better for transferring neg- ative sentences into positive, moreover, both mod- els achieve better performance for this transfer di- rection. We can probably attribute the reason to the imbalanced training data: 55% positive sen- tences v.s. 45% negative sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Manual Evaluation</head><p>We hire five workers to manually evaluate the quality of 500 sentences generated by each of our model and the compared models. The result is shown in <ref type="table" target="#tab_3">Table 5</ref>. "Content Preservation" mea- sures whether the generated sentence preserves the content of the input sentence. The score range is {2: fully preserved, 1: partially preserved, 0: not preserved}. "Content Preservation" is an impor- tant metric in this task since it is required that the output sentence and the original sentence should describe the same content subject. "Fluency" mea- sures the grammatical quality of a sentence, which Generated sentence E.g. 1 this tire center is amazing . T=1 this tire center is horrible . T=3 this tire center is really good . T=5 this tire center is amazing . E.g. 2 horrible food ! T=1 horrendous T=3 their food amazing ! T=5 amazing delicious food ! recommend ! E.g. 3 decent food and wine selection , but nothing i will rush back for . T=1 decent food and wine selection , but nothing i will rush for no . T=3 decent food and wine selection , but i will never look back for . T=5 decent food and wine selection , but excellent service, will return ! E.g. 4 our first time and we had a great meal , wonderful service . T=1 our first time and we had a terrible meal , stale service . T=3 our first time and we had a great meal , we have service . T=5 our first time and we had a great meal , wonderful service . E.g. 5 food is very addiction tasty ! T=1 food is just horrible here ? T=3 food is just addiction here ! T=5 food is very yummy addiction ! ranges from 1 (bad) to 4 (good), by following the definition in TST ( ).</p><p>The result shows that our model achieves the best content preservation score. Our editing pro- cedure explicitly fixes the content factor and only modifies the outcome factor, which helps better preserve the content. In contrast, S2BS and TST include only one shared factor for both the content and the outcome, thus fail to distinguish one from the other. For the "Fluency" metric, S2BS and TST are slightly better than our model. Generally speaking, it is because our model introduces more powerful components for modeling the outcome differences between pseudo-parallel sentences, so as to achieve our goal of editing an input sen- tence to satisfy the expected outcome. However, these components do not contribute to the lan- guage quality of generated sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Case Study</head><p>We show some examples produced by our model in <ref type="table" target="#tab_4">Table 6</ref>. For each input, we specify three tar- gets: 1, 3, and 5. For the first and the forth exam- ples, the original sentences are not revised when the target rating is set to 5 (i.e., T=5) since the original sentences are already quite positive. For the first example, when T=3, "amazing" is revised to a relatively less positive phrase "really good". This case demonstrates that our model is able to capture the subtle difference in word sentiments, so that it can revise sentences reasonably accord- ing to the quantifiable rating guidance. Moreover, for the second example, we notice that our model revises the original sentence "horrible food !" to "amazing delicious food ! recommend !" for T=5. This case shows that our model not only changes one word with another having different sentiment, e.g. "horrible" to "amazing delicious", but also creatively introduces words from a new perspec- tive, e.g. "recommend".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Ablation and Tuning Behavior Discussions</head><p>Recall that our model is a combination of a re- vised VAE, which disentangles two factors from a sentence to enable the subsequent design, and a coupling component modeling pseudo-parallel sentence pairs. For the three losses of the coupling component, we show their effects under the MAE metric in <ref type="table" target="#tab_6">Table 7</ref>. "None" refers to all three losses are removed, and it is basically worse than S2BS, which implies only using the revised VAE does not work well. As more losses added, the performance is gradually improved. Moreover, the dual recon- struction is more effective than the others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T=1</head><p>T=3 T=5 S2BS</p><p>1.6839 0.7567 1.3024 None 1.6639 0.7684 1.5434 L sim</p><p>1.6090 0.8258 1.5233  In the weight tuning, the first step only tunes the weights of L rec and L mse . We observe that solely minimizing L rec and L mse also decreases L sim , because in this process, the encoder E 2 becomes more capable of disentangling the content factor, and thus z and z become similar as they come from two similar input sentences, i.e. pseudo- parallel sentences. Another observation is that solely minimizing L rec and L mse increases L d−rec after some training epochs. To analyze the reason, let us assume there is a sentence x in the training set. Thus, the loss of reconstructing x from y and z is included in L rec . Assume that x is also included in a pseudo-parallel pair, and thus the loss of re- constructing x from y and z is included in L d−rec . The only difference between the two losses lies in the content factors z and z . Given that z and z are not enforced to resemble each other when L sim is excluded from this tuning step, L rec and L d−rec cannot be minimized simultaneously. Moreover, when we minimize L sim in the second step with the weights of L rec and L mse fixed, we observe that L d−rec also decreases, which complies with the above analysis.</p><formula xml:id="formula_15">L dif f 1.6793 0.8017 1.3140 L d−rec 1.5191 0.7784 1.1218 L sim , L dif f 1.4991 0.8218 1.3705 L sim , L d−rec 1.4101 0.8027 1.1246 L dif f , L d−</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Works</head><p>Inspired by the task of image style transfer ( <ref type="bibr" target="#b4">Gatys et al., 2016;</ref><ref type="bibr" target="#b11">Liu and Tuzel, 2016</ref>), researchers proposed the task of text style transfer and ob- tained some encouraging results ( <ref type="bibr" target="#b2">Fu et al., 2018;</ref><ref type="bibr" target="#b6">Hu et al., 2017;</ref><ref type="bibr" target="#b7">Jhamtani et al., 2017;</ref><ref type="bibr" target="#b13">Melnyk et al., 2017;</ref><ref type="bibr" target="#b23">Zhang et al., 2018;</ref><ref type="bibr" target="#b10">Li et al., 2018;</ref><ref type="bibr" target="#b16">Prabhumoye et al., 2018;</ref><ref type="bibr" target="#b15">Niu and Bansal, 2018)</ref>. Existing studies on text style transfer mainly aim at transferring text from an original style into a tar- get style, e.g., from negative to positive, from male to female, from rude/normal to polite; from mod- ern text to Shakespeare style, etc. In contrast, our proposed task QuaSE assumes each sentence is as- sociated with an outcome pertaining to continues values, and the editing is under the guidance of a specific target.</p><p>To transfer the style of a sentence, the paradigm of most works <ref type="bibr" target="#b14">Mueller et al., 2017;</ref><ref type="bibr" target="#b16">Prabhumoye et al., 2018</ref>) first learns the latent representation of the original sentence and then applies a decoder to generate the transferred sentence. A line of works ( <ref type="bibr" target="#b14">Mueller et al., 2017</ref>), including the studied task in this paper, assume that only non-parallel data is available for training. In such settings, VAEs <ref type="bibr" target="#b8">(Kingma and Welling, 2013</ref>) are employed to learn the latent representations of sentences.  assume a shared latent content distribution across text corpora belonging to different styles, and leverages the alignment of latent representa- tions from different styles to perform style trans- fer. <ref type="bibr" target="#b14">Mueller et al. (2017)</ref> associate the latent rep- resentations with a numerical outcome, which is a measurement of the style. A transferred sen- tence is generated from a modified latent represen- tation. Different from the aforementioned works based on latent representations, <ref type="bibr" target="#b10">Li et al. (2018)</ref> propose a simpler method that achieves attribute transfer by changing a few attribute marker words or phrases in the sentence that are indicative of a particular attribute, while leaving the rest of the sentence largely unchanged. The simple method is able to generate better-quality sentences than the aforementioned works. Besides style transfer, sen- tence editing models can be developed for other tasks. For example, <ref type="bibr" target="#b17">Schmaltz et al. (2017)</ref> pro- pose neural sequence-labelling models for correct- ing the grammatical errors of sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We proposed a new task namely Quantifiable Se- quence Editing (QuaSE), where a model needs to edit an input sentences towards the direction of a numerical outcome target. To tackle this task, we proposed a novel framework that simultaneously exploits the single sentences and pseudo-parallel sentence pairs. For evaluation, we prepared a dataset with Yelp sentences and their ratings. Ex- perimental results show that our framework out- performs the compared methods under the mea- sures of sentiment polarity accuracy and target value errors. Case studies show that our frame- work can generate some interesting sentences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 : Numbers of sentences in each rating interval.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 4 : Accuracy comparison with TST.</head><label>4</label><figDesc></figDesc><table>Content Preservation 
Fluency 
(Range: [0, 2]) 
(Range: [1, 4]) 
TST 
1.02 
2.56 
S2BS 
0.70 
2.53 
Our Model 
1.38 
2.48 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 : Manual evaluation.</head><label>5</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 6 : Case study.</head><label>6</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 7 : Ablation study.</head><label>7</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2"> https://www.yelp.com/dataset/challenge</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alp</forename><surname>Kucukelbir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><forename type="middle">D</forename><surname>Mcauliffe</surname></persName>
		</author>
		<idno>abs/1601.00670</idno>
		<title level="m">Variational inference: A review for statisticians. arXiv</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generating sentences from a continuous space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Józefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>the 20th SIGNLL Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="10" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Style transfer in text: Exploration and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenxin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoye</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd AAAI Conference on Artificial Intelligence</title>
		<meeting>the 32nd AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Difficulty controllable question generation for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<idno>abs/1807.03586</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image style transfer using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2016 Conference on Computer Vision and Pattern Recognition</title>
		<meeting>2016 Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2414" to="2423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generating sentences by editing prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Oren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Toward controlled generation of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1587" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Shakespearizing modern language using copy-enriched sequence-to-sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harsh</forename><surname>Jhamtani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Gangal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<idno>arXiv, abs/1707.01161</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno>abs/1312.6114</idno>
		<title level="m">Autoencoding variational bayes. arXiv</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adversarial learning for neural dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2157" to="2169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Delete, retrieve, generate: A simple approach to sentiment and style transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Coupled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="469" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL) System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Melnyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cícero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kahini</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkit</forename><surname>Wadhawan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Padhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Improved neural text attribute transfer with nonparallel data. arXiv, abs/1711.09395</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sequence to better sequence: Continuous revision of combinatorial structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gifford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2536" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Polite dialogue generation without parallel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Style transfer through back-translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Shrimai Prabhumoye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adapting sequence models for sentence correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><surname>Schmaltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><forename type="middle">M</forename><surname>Shieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2807" to="2813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Style transfer from non-parallel text by cross-alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianxiao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6833" to="6844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Two are better than one: An ensemble of retrieval-and generation-based dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<idno>arXiv, abs/1610.07149</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Skeleton key: Image captioning by skeleton-attribute decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrison</forename><forename type="middle">W</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2017 Conference on Computer Vision and Pattern Recognition</title>
		<meeting>2017 Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7378" to="7387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Syntactic skeleton-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongran</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2856" to="2862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Shaped: Shared-private encoder-decoder for text style adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
