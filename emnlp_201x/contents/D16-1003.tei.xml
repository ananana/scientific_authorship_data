<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Neural Network for Coordination Boundary Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>November 1-5, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Ficler</surname></persName>
							<email>jessica.ficler@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department Bar</orgName>
								<orgName type="institution">Ilan University</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
							<email>yoav.goldberg@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Ilan University</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Neural Network for Coordination Boundary Prediction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="23" to="32"/>
							<date type="published">November 1-5, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a neural-network based model for coordination boundary prediction. The network is designed to incorporate two signals: the similarity between conjuncts and the observation that replacing the whole coordination phrase with a conjunct tends to produce a coherent sentences. The modeling makes use of several LSTM networks. The model is trained solely on conjunction annotations in a Treebank, without using external resources. We show improvements on predicting coordination boundaries on the PTB compared to two state-of-the-art parsers; as well as improvement over previous coordination boundary prediction systems on the Genia corpus.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Coordination is a common syntactic phenomena, ap- pearing in 38.8% of the sentences in the Penn Tree- bank (PTB) <ref type="bibr" target="#b13">(Marcus et al., 1993)</ref>, and in 60.71% of the sentences in the Genia Treebank ( <ref type="bibr" target="#b15">Ohta et al., 2002</ref>). However, predicting the correct conjuncts span remain one of the biggest challenges for state- of-the-art syntactic parsers. Both the Berkeley and Zpar phrase-structure parsers ( <ref type="bibr" target="#b16">Petrov et al., 2006</ref>; <ref type="bibr" target="#b19">Zhang and Clark, 2011</ref>) achieve F1 scores of around 69% when evaluated on their ability to recover coor- dination boundaries on the PTB test set. For exam- ple, in:</p><p>"He has the government's blessing to <ref type="bibr">[build churches]</ref> and <ref type="bibr">[spread Unificationism]</ref> in that country." In this work we focus on coordination boundary prediction, and suggest a specialized model for this task. We treat it as a ranking task, and learn a scor- ing function over conjuncts candidates such that the correct candidate pair is scored above all other can- didates. The scoring model is a neural network with two LSTM-based components, each modeling a dif- ferent linguistic principle: (1) conjuncts tend to be similar ("symmetry"); and (2) replacing the coor- dination phrase with each of the conjuncts usually result in a coherent sentence ("replacement"). The symmetry component takes into account the con- juncts' syntactic structures, allowing to capture sim- ilarities that occur in different levels of the syntac- tic structure. The replacement component considers the coherence of the sequence that is produced when connecting the participant parts. Both of these sig- nals are syntactic in nature, and are learned solely based on information in the Penn Treebank. Our model substantially outperforms both the Berkeley and Zpar parsers on the coordination prediction task, while using the exact same training corpus. Seman- tic signals (which are likely to be based on resources external to the treebank) are also relevant for coor- dination disambiguation <ref type="bibr" target="#b12">(Kawahara and Kurohashi, 2008;</ref><ref type="bibr" target="#b10">Hogan, 2007)</ref> and provide complementary in- formation. We plan to incorporate such signals in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Coordination is a very common syntactic construc- tion in which several sentential elements (called con- juncts) are linked. For example, in:</p><p>"The Jon Bon Jovi Soul Foundation [was founded in 2006] and 1 [exists to combat issues that force (fam- ilies) and 2 (individuals) into economic despair]."</p><p>The coordinator and 1 links the conjuncts surrounded with square brackets and the coordinator and 2 links the conjuncts surrounded with round brackets.</p><p>Coordination between NPs and between VPs are the most common, but other grammatical functions can also be coordinated:</p><formula xml:id="formula_0">"[relatively active] ADJP but [unfocused] ADJP " ; "[in] IN and [out] IN the market".</formula><p>While coordination mostly occurs be- tween elements with the same syntactic category, cross-category conjunctions are also possible: ("Al- ice will visit Earth  <ref type="bibr" target="#b3">(Dowty, 1988</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Symmetry between conjuncts</head><p>Coordinated conjuncts tend to be semantically re- lated and have a similar syntactic structure. For ex- ample, in (a) and (b) the conjuncts include similar words (China/Asia, marks/yen) and have identical syntactic structures. Symmetry holds also in larger conjuncts, such as in: Similarity between conjuncts was used as a guiding principle in previous work on coordination disam- biguation <ref type="bibr" target="#b10">(Hogan, 2007;</ref><ref type="bibr" target="#b18">Shimbo and Hara, 2007;</ref><ref type="bibr" target="#b8">Hara et al., 2009</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Replaceability</head><p>Replacing a conjunct with the whole coordination phrase usually produce a coherent sentence <ref type="bibr" target="#b11">(Huddleston et al., 2002</ref>). For example, in "Ethan has developed [new products] and [a new strategy]", replacement results in: "Ethan has developed new products"; and "Ethan has developed a new strat- egy", both valid sentences. Conjuncts replace- ment holds also for conjuncts of different syntac- tic types, e.g.: "inactivation of tumor-suppressor genes, <ref type="bibr">[alone]</ref> or [in combination], appears crucial to the development of such scourges as cancer.".</p><p>While both symmetry and replacebility are strong characteristics of coordination, neither principle holds universally. Coordination between syntacti- cally dissimilar conjuncts is possible ("tomorrow and for the entirety of the next decade"), and the replacement principle fails in cases of ellipsis, gap- ping and others ("The bank employs <ref type="bibr">[8,000 people in Spain]</ref> and [2,000 abroad]").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Coordination in the PTB</head><p>Coordination annotation in the Penn Treebank <ref type="bibr" target="#b13">(Marcus et al., 1993</ref>) is inconsistent <ref type="bibr" target="#b10">(Hogan, 2007)</ref> and lacks internal structure for NPs with nominal mod- ifiers ( <ref type="bibr">Bies et al., 1995)</ref>. In addition, conjuncts in the PTB are not explicitly marked. These deficien- cies led previous works on coordination disambigua- tion ( <ref type="bibr" target="#b18">Shimbo and Hara, 2007;</ref><ref type="bibr" target="#b8">Hara et al., 2009;</ref><ref type="bibr" target="#b7">Hanamoto et al., 2012</ref>) to use the Genia treebank of biomedical text ( <ref type="bibr" target="#b15">Ohta et al., 2002</ref>) which explic- itly marks coordination phrases. However, using the Genia corpus is not ideal since it is in a specialized domain and much smaller than the PTB. In this work we rely on a version of the PTB released by <ref type="bibr" target="#b5">Ficler and Goldberg (2016)</ref> in which the above deficiencies are manually resolved. In particular, coordinating elements, coordination phrases and conjunct bound- aries are explicitly marked with specialized function labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Neural Networks and Notation</head><p>We use w 1:n to indicate a list of vectors w 1 , w 2 , . . . w n and w n:1 to indicate the reversed list. We use • for vector concatenation. When a discrete symbol w is used as a neural network's input, the corresponding embedding vector is assumed.</p><p>A multi-layer perceptron (MLP) is a non linear classifier. In this work we take MLP to mean a classifier with a single hidden layer:</p><formula xml:id="formula_1">M LP (x) = V · g(W x + b)</formula><p>where x is the network's input, g is an activation function such as ReLU or Sigmoid, and W , V and b are trainable parameters. Recurrent Neural Networks (RNNs) <ref type="bibr" target="#b4">(Elman, 1990)</ref> allow the representation of arbitrary sized sequences. In this work we use LSTMs <ref type="bibr" target="#b9">(Hochreiter and Schmidhuber, 1997)</ref>, a variant of RNN that was proven effective in many NLP tasks. LSTM(w 1:n ) is the outcome vec- tor resulting from feeding the sequence w 1:n into the LSTM in order. A bi-directional LSTM (biLSTM) takes into account both the past w 1:i and the future w i:n when representing the element in position i:</p><formula xml:id="formula_2">biLST M (w 1:n , i) = LST M F (w 1:i ) • LST M B (w n:i )</formula><p>where LST M F reads the sequence in its regular or- der and LST M B reads it in reverse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Definition and Architecture</head><p>Given a coordination word in a sentence, the coor- dination prediction task aims to returns the two con- juncts that are connected by it, or NONE if the word does not function as a coordinating conjunction of a relevant type. 1 <ref type="figure" target="#fig_4">Figure 1</ref> provides an example.</p><p>Our system works in three phases: first, we deter- mine if the coordinating word is indeed part of a con- junction of a desired type. We then extract a ranked list of candidate conjuncts, where a candidate is a</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence:</head><p>And 1 the city decided to treat its guests more like royalty or 2 rock stars than factory owners.</p><p>Expected output: and 1 : NONE or 2 : (11-11) royalty ; (12-13) rock stars Sentence:</p><p>The president is expected to visit Minnesota, New York and 1 North Dakota by the end of the year.</p><p>Expected output: and 1 : (9-10) New York ; (12-13) North Dakota pair of spans of the form ((i, j), (l, m)). The can- didates are then scored and the highest scoring pair is returned. Section 4 describes the scoring model, which is the main contribution of this work. The coordination classification and candidate extraction components are described in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Candidate Conjunctions Scoring</head><p>Our scoring model takes into account two signals, symmetry between conjuncts and the possibility of replacing the whole coordination phrase with its par- ticipating conjuncts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Symmetry Component</head><p>As noted in Section 2.1, many conjuncts spans have similar syntactic structure. However, while the sim- ilarity is clear to human readers, it is often not easy to formally define, such as in:</p><formula xml:id="formula_3">"about/IN half/NN its/PRP$ revenue/NN and/CC more/JJR than/IN half/NN its/PRP$ profit/NN"</formula><p>If we could score the amount of similarity be- tween two spans, we could use that to identify cor- rect coordination structures. However, we do not know the similarity function. We approach this by training the similarity function in a data-dependent manner. Specifically, we train an encoder that en- codes spans into vectors such that vectors of similar spans will have a small Euclidean distance between them. This architecture is similar to Siamese Net- works, which are used for learning similarity func- tions in vision tasks ( <ref type="bibr" target="#b2">Chopra et al., 2005</ref>). Given two spans of lengths k and m with cor- responding vector sequences u 1:k and v 1:m we en- code each sequences using an LSTM, and take the euclidean distance between the resulting representa- tions:</p><formula xml:id="formula_4">Sym(u 1:k , v 1:m ) = ||LST M (u 1:k ) − LST M (v 1:m )||</formula><p>The network is trained such that the distance is min- imized for compatible spans and large for incompat- ible ones in order to learn that vectors that represent correct conjuncts are closer than vectors that do not represent conjuncts.</p><p>What are the elements in the sequences to be com- pared? One choice is to take the vectors u i to cor- respond to embeddings of the ith POS in the span. This approach works reasonably well, but does not consider the conjuncts' syntactic structure, which may be useful as symmetry often occurs on a higher level than POS tags. For example, in: the similarity is more substantial in the third level of the tree than in the POS level.</p><p>A way to allow the model access to higher levels of syntactic symmetry is to represent each word as the projection of the grammatical functions from the word to the root. <ref type="bibr">2</ref> For example, the projections for the first conjunct in <ref type="figure" target="#fig_5">Figure 2</ref>  This decomposition captures the syntactic context of each word, but does not uniquely determine the structure of the tree. To remedy this, we add to the paths special symbols, R and L, which marks the lowest common ancestors with the right and left words respectively. These are added to the path above the corresponding nodes. For example con- sider the following paths which corresponds to the above syntactic structure: The lowest common ancestor of "their" and "risks" is NP. Thus, R is added after NP in the path of "their" and L is added after NP in the path of "risks". Similarly, L and R are added after the VP in the "their" and "cut" paths.</p><p>The path for each word is encoded using an LSTM receiving vector embeddings of the elements in the path from the word to the root. We then use the resulting encodings instead of the POS-tag embed- dings as input to the LSTMs in the similarity func- tion. <ref type="figure" target="#fig_5">Figure 2</ref> depicts the complete process for the spans "cut their risks" and "take profits".</p><p>Using syntactic projections requires the syntactic structures of the conjuncts. This is obtained by run- ning the Berkeley parser over the sentence and tak- ing the subtree with the highest probability from the Sentence:</p><p>Rudolph Agnew, <ref type="bibr">[55 years old]</ref> and [former chairman of CGF PLC] ,was named a nonexecutive director.</p><formula xml:id="formula_5">w i−1 w i w j w k w l w m w m+1 P re Conj1 Conj2 P ost</formula><p>Expansions:</p><p>Rudolph Agnew, 55 years old ,was named a nonexecutive director. Rudolph Agnew, former chairman of CGF PLC ,was named a nonexecutive director. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Replacement Component</head><p>The replacement component is based on the obser- vation that, in many cases, the coordination phrase can be replaced with either one of its conjuncts while still preserving a grammatical and semantically co- herent sentence (Section 2.2) When attempting such a replacement on incorrect conjuncts, the resulting sentence is likely to be either syntactically or semantically incorrect. For exam- ple, in the following erroneous analysis: "Rudolph Agnew, [55 years old] and [former chairman] of Consolidated Gold Fields PLC" replacing the con- junction with the first conjunct results in the se- mantically incoherent sequence "Rudolph Agnew, 55 years old of Consolidated Golden Fields, PLC". <ref type="bibr">4</ref> Our goal is to distinguish replacements resulting from correct conjuncts from those resulting from er- roneous ones. To this end, we focus on the connec- tion points. A connection point in a resulting sen- tence is the point where the sentence splits into two sequences that were not connected in the original sentence. For example, consider the sentence in <ref type="figure" target="#fig_9">Fig- ure 3</ref>. It has four parts, marked as Pre, Conj1, Conj2 and Post. Replacing the coordination phrase Conj1 and Conj2 with Conj2 results in a connection point <ref type="bibr">3</ref> The parser's CKY chart did not include a tree for 10% of the candidate spans, which have inside probability 0 and outside probability &gt; 0. For those, we obtained the syntactic structure by running the parser on the span words only. <ref type="bibr">4</ref> While uncommon, incorrect conjuncts may also result in valid sentences, e.g. "He paid $ 7 for cold <ref type="bibr">[drinks]</ref> and <ref type="bibr">[pizza]</ref> that just came out of the oven."</p><p>between Pre and Conj2. Likewise, replacing the co- ordination phrase with Conj1 results in connection point between <ref type="bibr">Conj1 and Post.</ref> In order to model the validity of the connection points, we represent each connection point as the concatenation of a forward and reverse LSTMs cen- tered around that point. Specifically, for the spans in Formally, assuming words w 1:n in a sentence with coordination at position k and conjuncts w i:j and w l:m , 5 the connection points are between w 1:j and w m+1:n ; and between w 1:i−1 and w l:n . The two connection points representations are then concate- nated, resulting in a replacement vector: REPL(w 1:n , i, j, l, m) = CONPOINT(w 1:n , i − 1, l) • CONPOINT(w 1:n , j, m + 1) where:</p><formula xml:id="formula_6">CONPOINT(w 1:n , i, j) = LST M F (w 1:i ) • LST M B (w n:j )</formula><p>We use two variants of the replacement vectors, corresponding to two levels of representation. The first variant is based on the sentence's words, while the second is based on its POS-tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Parser based Features</head><p>In addition to the symmetry and replacement sig- nals, we also incorporate some scores that are de- rived from the Berkeley parser. As detailed in Sec- tion 5, a list of conjuncts candidates are extracted from the CKY chart of the parser. The candidates are then sorted in descending order according to the multiplication of inside and outside scores of the candidate's spans: 6 I (i,j) × O (i,j) × I (l,m) × O (l,m) . Each candidate {(i, j), (l, m)} is assigned two nu- merical features based on this ranking: its position in the ranking, and the ratio between its score and the score of the adjacent higher-ranked candidate. We add an additional binary feature indicating whether the candidate spans are in the 1-best tree predicted by the parser. These three features are denoted as F eats(i, j, l, m).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Final Scoring and Training</head><p>Finally, the score of a candidate {(i, j), (l, m)} in a sentence with words w 1:n and POS tags p 1:n is com- puted as:</p><formula xml:id="formula_7">SCORE(w 1:n , p 1:n , {(i, j), (l, m)}) = M LP ( Sym(v P ath i:j , v P ath l:m ) • Repl(w 1:n , i, j, l, m) • Repl(p 1:n , i, j, l, m) • F eats(i, j, l, m) )</formula><p>where v P ath i:j and v P ath l:m are the vectors resulting from the path LSTMs, and Sym, Repl and F eats are the networks defined in Sections 4.1 -4.3 above. The network is trained jointly, attempting to minimize a pairwise ranking loss function, where the loss for each training case is given by:</p><formula xml:id="formula_8">loss = max(0, 1 − (ˆ y − y g )) wherê</formula><p>y is the highest scoring candidate and y g is the correct candidate. The model is trained on all the coordination cases in Section 2-21 in the PTB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Candidates Extraction and Supporting Classifiers</head><p>Candidates Extraction We extract candidate spans based on the inside-outside probabilities as- signed by the Berkeley parser. Specifically, to obtain 6 Inside-Outside probabilities <ref type="bibr" target="#b6">(Goodman, 1998</ref>) represent the probability of a span with a given non-terminal symbol. The inside probability I <ref type="figure">(N,i,j)</ref> is the probability of generating words wi, wi+1, ..., wj given that the root is the non-terminal N . The outside probability O <ref type="figure">(N,i,j)</ref> is the probability of gen- erating words w1, w2, ..., wi−1, the non-terminal N and the words wj+1, wj+2, ..., wn with the root S.</p><p>candidates for conjunct span we collect spans that are marked with COORD, are adjacent to the coor- dinating word, and have non-zero inside or outside probabilities. We then take as candidates all possi- ble pairs of collected spans. On the PTB dev set, this method produces 6.25 candidates for each co- ordinating word on average and includes the correct candidates for 94% of the coordinations.</p><p>Coordination Classification We decide whether a coordination word w k in a sentence w 1:n functions as a coordinator by feeding the biLSTM vector cen- tered around w k into a logistic classifier:</p><formula xml:id="formula_9">σ(v · biLSTM(w 1:n , k) + b).</formula><p>The training examples are all the coordination words (marked with CC) in the PTB training set. The model achieves 99.46 F1 on development set and 99.19 F1 on test set.</p><p>NP coordinations amount to about half of the coordination cases in the PTB, and previous work is often evaluated specifically on NP coordination. When evaluating on NP coordination, we depart from the unrealistic scenario used in most previous work where the type of coordination is assumed to be known a-priori, and train a specialized model for predicting the coordination type. For a coordination candidate {(i, j), (l, m)} with a coordinator w k , we predict if it is NP coordination or not by feeding a logistic classifier with a biLSTM vector centered around the coordinator and constrained to the candi- date spans:</p><formula xml:id="formula_10">σ(v · biLSTM(w i:m , k) + b).</formula><p>The training examples are coordinations in the PTB training set, where where a coordinator is consid- ered of type NP if its head is labeled with NP or NX. Evaluating on gold coordinations results in F1 scores of 95.06 (dev) and 93.89 (test).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We evaluate our models on their ability to identify conjunction boundaries in the extended Penn Tree- bank <ref type="bibr" target="#b5">(Ficler and Goldberg, 2016)</ref> and Genia Tree- bank ( <ref type="bibr" target="#b15">Ohta et al., 2002</ref>) <ref type="bibr">7</ref> .</p><p>When evaluating on the PTB, we compare to the conjunction boundary predictions of the generative <ref type="bibr">7</ref>    Berkeley parser ( <ref type="bibr" target="#b16">Petrov et al., 2006</ref>) and the discrim- inative Zpar parser ( <ref type="bibr" target="#b19">Zhang and Clark, 2011</ref>). When evaluating on the Genia treebank, we compare to the results of the discriminative coordination-prediction model of <ref type="bibr" target="#b8">Hara et al. (2009)</ref>. 8</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation on PTB</head><p>Baseline Our baseline is the performance of the Berkeley and Zpar parsers on the task presented in Section 3, namely: for a given coordinating word, determine the two spans that are being conjoined by it, and return NONE if the coordinator is not conjoining spans or conjoins spans that are not of the expected type. We convert predicted trees to conjunction predictions by taking the two phrases that are immediately adjacent to the coordinator on both sides (ignoring phrases that contain solely punctuation). For example, in the following Zpar- predicted parse tree the conjunct prediction is <ref type="bibr">("Feb. 8, 1990</ref><ref type="bibr">","May 10, 1990</ref>. Cases in which the coordination word is the left- most or right-most non-punctuation element in its phrase (e.g. (PRN (P -)(CC and)(S it's been painful)(P -))) are considered as no- coordination ("None").</p><p>We consider two setups. In the first we are inter- ested in all occurrences of coordination, and in the second we focus on NP coordination. The second scenario requires typed coordinations. We take the type of a parser-predicted coordination to be the type of the phrase immediately dominating the coordina- tion word. Evaluation Metrics We measure precision and re- call compared to the gold-annotated coordination spans in the extended PTB, where an example is considered correct if both conjunct boundaries match exactly. When focusing on NPs coordina- tions, the type of the phrase above the CC level must match as well, and phrases of type NP/NX are con- sidered as NP coordination.</p><p>Results <ref type="table" target="#tab_1">Tables (1)</ref> and <ref type="formula">(2)</ref> summarize the results. The Berkeley and Zpar parsers perform similarly on the coordination prediction task. Our proposed model outperforms both parsers, with a test-set F 1 score of 72.7 (3.78 F 1 points gain over the better parser) when considering all coordinations, and test- set F 1 score of 76.1 (4.77 F 1 points gain) when con- sidering NP coordination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation on Genia</head><p>To compare our model to previous work, we evalu- ate also on the Genia treebank (Beta), a collection of constituency trees for 4529 sentences from Med- line abstracts. The Genia treebank coordination an- notation explicitly marks coordination phrases with a special function label (COOD), making the cor- pus an appealing resource for previous work on co- ordination boundary prediction <ref type="bibr" target="#b18">(Shimbo and Hara, 2007;</ref><ref type="bibr" target="#b8">Hara et al., 2009;</ref><ref type="bibr" target="#b7">Hanamoto et al., 2012)</ref>. Following <ref type="bibr" target="#b8">Hara et al. (2009)</ref>, we evaluate the mod- els' ability to predict the span of the entire coordi- nation phrase, disregarding the individual conjuncts. For example, in "My plan is to visit Seychelles, ko Samui and Sardinia by the end of the year" the goal is to recover "Seychelles, ko Samui and Sardinia". This is a recall measure. We follow the exact proto- col of <ref type="bibr" target="#b8">Hara et al. (2009)</ref> and train and evaluate the model on 3598 coordination phrases in Genia Tree- bank Beta and report the micro-averaged results of a five-fold cross validation run. <ref type="bibr">9</ref> As shown by Hara Retail sales volume was [down 0.5% from the previous three months] and [up 1.2% from a year earlier]. Incorrect: Everyone was concerned about the [general narrowness of the rally] and [failure of the OTC market] to get into plus territory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rep w</head><p>Correct:</p><p>The newsletter said [she is 44 years old] and [she studied at the University of Puerto Rico School of Medicine]. Incorrect: But Robert Showalter said no special <ref type="bibr">[bulletins]</ref> or [emergency meetings of the investors' clubs] are planned .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rep p</head><p>Correct:</p><p>[On the Big Board floor] and [on trading desks], traders yelped their approval. Incorrect: It suddenly burst upward 7.5 as Goldman, <ref type="bibr">Sachs &amp; Co.</ref> [stepped in] and [bought almost] every share offer, traders said.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Technical Details</head><p>The neural networks (candidate scoring model and supporting classifiers) are implemented using the pyCNN package. <ref type="bibr">10</ref> .</p><p>In the supporting models we use words embed- ding of size 50 and the Sigmoid activation function. The LSTMs have a dimension of 50 as well. The models are trained using SGD for 10 iterations over the train-set, where samples are randomly shuffled before each iteration. We choose the model with the highest F1 score on the development set.</p><p>All the LSTMs in the candidate scoring model have a dimension of 50. The input vectors for the <ref type="bibr">10</ref>    <ref type="bibr">(100,</ref><ref type="bibr">300)</ref>. We train for 20 iterations over the train set, randomly shuffling the examples before each itera- tion. We choose the model that achieves the highest F1 score on the dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Analysis</head><p>Our model combines four signals: symmetry, word- level replacement, POS-level replacement and fea- tures from Berkeley parser. <ref type="table" target="#tab_6">Table 4</ref> shows the PTB dev-set performance of each sub-model in isolation.</p><p>On their own, each of the components' signals is relatively weak, seldom outperforming the parsers. However, they provide complementary information, as evident by the strong performance of the joint model. <ref type="figure" target="#fig_13">Figure 4</ref> lists correct and incorrect predic- tions by each of the components, indicating that the individual models are indeed capturing the patterns they were designed to capture -though these pat- terns do not always lead to correct predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related Work</head><p>The similarity property between conjuncts was ex- plored in several previous works on coordination disambiguation. <ref type="bibr" target="#b10">Hogan (2007)</ref> incorporated this principle in a generative parsing model by changing the generative process of coordinated NPs to condi- tion on properties of the first conjunct when gener- ating the second one. <ref type="bibr" target="#b18">Shimbo and Hara (2007)</ref> pro- posed a discriminative sequence alignment model to detect similar conjuncts. They focused on disam- biguation of non-nested coordination based on the learned edit distance between two conjuncts. Their work was extended by <ref type="bibr" target="#b8">Hara et al. (2009)</ref> to han- dle nested coordinations as well. The discrimina- tive edit distance model in these works is similar in spirit to our symmetry component, but is restricted to sequences of POS-tags, and makes use of a se- quence alignment algorithm. We compare our re- sults to Hara et al.'s in Section 6.2. <ref type="bibr" target="#b7">Hanamoto et al. (2012)</ref> extended the previous method with dual de- composition and HPSG parsing. In contrast to these symmetry-directed efforts, <ref type="bibr" target="#b12">Kawahara et al. (2008)</ref> focuses on the dependency relations that surround the conjuncts. This kind of semantic information provides an additional signal which is complemen- tary to the syntactic signals explored in our work. Our neural-network based model easily supports in- corporation of additional signals, and we plan to ex- plore such semantic signals in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusions</head><p>We presented an neural-network based model for re- solving conjuncts boundaries. Our model is based on the observation that (a) conjuncts tend to be sim- ilar and (b) that replacing the coordination phrase with a conjunct results in a coherent sentence. Our models rely on syntactic information and do not incorporate resources external to the training tree- banks, yet improve over state-of-the-art parsers on the coordination boundary prediction task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>the conjuncts are incorrectly predicted by both parsers: Berkeley: "He has the government's blessing to [build churches] and [spread Unificationism in that country]." Zpar: "He [has the government's blessing to build churches] and [spread Unificationism in that country]."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>[tomorrow] N P or [in the next decade] P P "). Less common coordinations involve non-constituent elements "[equal to] or [higher than]", argument clusters ("Alice visited [4 plan- ets] [in 2014] and [3 more] [since then]"), and gap- ping ("[Bob lives on Earth] and [Alice on Saturn]")</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The coordination prediction task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of the symmetry scoring component that takes into account the conjuncts syntactic structures. Each conjunct tree is decomposed into paths that are fed into the path-LSTMs (squares). The resulting vectors are fed into the symmetry LSTM function (circles). The outcome vectors (blue circles) are then fed into the euclidean distance function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The correct conjuncts spans of the coordinator and in the sentence and the outcome expansions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 3 the</head><label>3</label><figDesc>two connection points are represented as: LST M F (Rudolph,...,old)•LST M B (director,...,was,,) and LST M F (Rudolph,Agnew,,)•LST M B (director,...,former)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Correct in incorrect predictions by the individual components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Coordination prediction on PTB (All coordinations).</head><label>1</label><figDesc></figDesc><table>Dev 
Test 
P 
R 
F 
P 
R 
F 
Berkeley 67.53 70.93 69.18 69.51 72.61 71.02 
Zpar 
69.14 72.31 70.68 69.81 72.92 71.33 
Ours 
75.17 74.82 74.99 76.91 75.31 76.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Coordination prediction on PTB (NP coordinations). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Recall on the Beta version of Genia corpus. Numbers 

for Hara et al. are taken from their paper. 

et al. (2009), syntactic parsers do not perform well 
on the Genia treebank. Thus, in our symmetry com-
ponent we opted to not rely on predicted tree struc-
tures, and instead use the simpler option of repre-
senting each conjunct by its sequence of POS tags. 
To handle coordination phrases with more than two 
conjuncts, we extract candidates which includes up 
to 7 spans and integrate the first and the last span 
in the model features. Like Hara et al., we use gold 
POS. 
Results Table 3 summarizes the results. Our pro-
posed model achieves Recall score of 64.14 (2.64 
Recall points gain over Hara et al.) and significantly 
improves the score of several coordination types. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Performance of the individual components on PTB 

section 22 (dev). Sym: Symmetry. Repp: POS replace-
ment. Repw: Word replacement. Feats: features extracted from 
Berkeley parser. Joint: the complete model. 

symmetry LSTM is of size 50 as well. The MLP 
in the candidate scoring model uses the Relu acti-
vation function, and the model is trained using the 
Adam optimizer. The words and POS embeddings 
are shared between the symmetry and replacment 
components. The syntactic label embeddings are for 
the path-encoding LSTM, We perform grid search 
with 5 different seeds and the following: [1] MLP 
hidden layer size (100, 200, 400); [2] input embed-
dings size for words, POS and syntactic labels </table></figure>

			<note place="foot" n="1"> We consider and, or, but, nor as coordination words. In case of more than two coordinated elements (conjuncts), we focus on the two conjuncts which are closest to the coordinator.</note>

			<note place="foot" n="2"> Similar in spirit to the spines used in Carreras et al. (2008) and Shen et al. (2003).</note>

			<note place="foot" n="5"> Usually j = k − 1 and l = k + 1, but in some cases punctuation symbols may interfere.</note>

			<note place="foot" n="8"> Another relevant model in the literature is (Hanamoto et al., 2012), however the results are not directly comparable as they use a slightly different definition of conjuncts, and evaluate on a subset of the Genia treebank, containing only trees that were properly converted to an HPSG formalism.</note>

			<note place="foot" n="9"> We thank Kazuo Hara for providing us with the exact details of their splits.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by The Israeli Science Foundation (grant number 1555/15) as well as the German Research Foundation via the German-Israeli Project Cooperation (DIP, grant DA 1600/1-1).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Mary Ann Marcinkiewicz, and Britta Schasberger. 1995. Bracketing guidelines for treebank ii style penn treebank project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Macintyre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Tredinnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page">100</biblScope>
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Conference on Computational Natural Language Learning</title>
		<meeting>the Twelfth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Type raising, functional composition, and non-constituent conjunction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dowty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Categorial grammars and natural language structures</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1988" />
			<biblScope unit="page" from="153" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Finding structure in time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeffrey L Elman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="179" to="211" />
		</imprint>
	</monogr>
	<note>Cognitive science</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Coordination annotation extension in the penn tree bank. Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Ficler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Goodman</surname></persName>
		</author>
		<idno>cmp-lg/9805007</idno>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
<note type="report_type">Parsing inside-out. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Coordination structure analysis using dual decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Hanamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="430" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Coordinate structure analysis with global structural constraints and alignment-based local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuo</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Shimbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideharu</forename><surname>Okuma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="967" to="975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Coordinate noun phrase disambiguation in a generative parsing model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deirdre</forename><surname>Hogan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The cambridge grammar of english. Language. Cambridge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodney</forename><surname>Huddleston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">K</forename><surname>Pullum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page">1275</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Coordination disambiguation without any similarities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="425" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Mitchell P Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The genia corpus: An annotated research abstract corpus in molecular biology domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second international conference on Human Language Technology Research</title>
		<meeting>the second international conference on Human Language Technology Research</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="82" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning accurate, compact, and interpretable tree annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Thibaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="433" to="440" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Using ltag based features in parse reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind K</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 conference on Empirical methods in natural language processing</title>
		<meeting>the 2003 conference on Empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A discriminative learning model for coordinate conjunctions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Shimbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuo</forename><surname>Hara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="610" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Syntactic processing using the generalized perceptron and beam search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="151" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
