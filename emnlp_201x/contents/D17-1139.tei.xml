<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Rank Semantic Coherence for Topic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>MOE</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<settlement>Xuzhou</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
							<email>lvyajuan@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>MOE</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>MOE</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<settlement>Xuzhou</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Rank Semantic Coherence for Topic Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1340" to="1344"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Topic segmentation plays an important role for discourse parsing and information retrieval. Due to the absence of training data, previous work mainly adopts un-supervised methods to rank semantic coherence between paragraphs for topic seg-mentation. In this paper, we present an intuitive and simple idea to automatically create a &quot;quasi&quot; training dataset, which includes a large amount of text pairs from the same or different documents with different semantic coherence. With the training corpus, we design a symmetric CNN neural network to model text pairs and rank the semantic coherence within the learning to rank framework. Experiments show that our algorithm is able to achieve competitive performance over strong base-lines on several real-world datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of topic segmentation is to segment a document into several topically coherent parts, with different parts corresponding to different top- ics. Topic segmentation enables better understand- ing of document structure, and makes long doc- ument much easier to navigate. It also provides helpful information for tasks such as information retrieval, topic tracking etc <ref type="bibr" target="#b15">(Purver, 2011)</ref>.</p><p>Due to the lack of large scale annotated topic segmentation dataset, previous work mainly focus on unsupervised models to measure the coherence between two textual segments. The intuition be- hind unsupervised models is that two adjacent seg- ments from the same topic are more coherent than those from different topics. Under this intuition, one direction of research attempts to measure co- herence by computing text similarity. The typi- cal methods include TextTiling (Hearst, 1997) and its variants, such as C99 <ref type="bibr" target="#b2">(Choi, 2000</ref>), TopicTil- ing ( <ref type="bibr" target="#b17">Riedl and Biemann, 2012b)</ref> etc. The other di- rection of research develops topic modeling tech- niques to explore topic representation of text and topic change between textual segments <ref type="bibr" target="#b19">(Yamron et al., 1998;</ref><ref type="bibr" target="#b4">Eisenstein and Barzilay, 2008;</ref><ref type="bibr" target="#b16">Riedl and Biemann, 2012a;</ref><ref type="bibr" target="#b3">Du et al., 2013;</ref><ref type="bibr" target="#b7">Jameel and Lam, 2013)</ref>. With carefully designed gen- erative process and efficient inference algorithm, topic models are able to model coherence as latent variables and outperform lexical similarity based models.</p><p>Though unsupervised models make progress in modeling text coherence, they mostly suffer from one of the following two limitations. First, it is not precise to measure coherence with text sim- ilarity, since text similarity is just one aspect to influence coherence. Second, many assumptions and manually set parameters are usually involved in the complex modeling techniques, due to the absence of supervised information. To overcome aforementioned limitations, we prefer to directly model the text coherence by exploring possible su- pervised information. Then, we can learn a func- tion f (s1, s2) which takes two textual segments s1 and s2 as input, and directly measure their se- mantic coherence.</p><p>As we know, it is hard to directly compile and collect a large number of samples with coher- ence scores labeling. Here we propose an intu- itive and simple strategy to automatically create a "quasi" training corpus for supervision. It is a common sense that the original documents writ- ten by human are generally more coherent than a patchwork of sentences or paragraphs randomly extracted from different documents. In such cases, two textual segments from the same document are more coherent than those from different docu- ments, and two segments from the same paragraph are more coherent than those from different para- graphs. Then, we can get a large set of text pairs with partial ordering relations, which denote some text pairs are more coherent than other text pairs. With these ordering information, we propose to apply the learning to rank framework to model the semantic coherence function f (s1, s2), based on which topic boundaries are identified.</p><p>The next key problem is how to model and rep- resent text pairs. It is fortunate that neural net- works have emerged as a powerful tool for model- ing text pairs ( <ref type="bibr" target="#b12">Lu and Li, 2013;</ref><ref type="bibr" target="#b18">Severyn and Moschitti, 2015;</ref><ref type="bibr" target="#b20">Yin et al., 2015;</ref><ref type="bibr" target="#b6">Hu et al., 2014</ref>), free- ing us from feature engineering. In this paper, we develop a symmetric convolutional neural network (CNN) framework, whose main idea is to jointly model text representation and interaction between texts. With our acquired large amount of training data, our CNN-based method is capable of reason- ably rank semantic coherence and further conduct topic segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Coherence Ordering between Text Pairs</head><p>In our work, we define f (s1, s2) as a function, which returns a real number as semantic coherence score of the text pair &lt;s1,s2&gt;. To model f (s1, s2) of any text pair, we aim to explore the partial ordering relations of coherence between different text pairs, since it is hard to get a corpus with la- beled coherence scores.</p><p>Next, we exploit the two types of ordering rela- tions stated in Section 1. To formalize, we notate a collection of documents as D. Each document d i ∈ D consists of several paragraphs, and each paragraph p j ∈ d i consists of several sentences. We use T s:(s+k) ij to represent a text segment cover- ing k sentences starting from the s-th sentence in document d i 's j-th paragraph. To make symbols less cluttered, we omit k and simply use T s ij for the same meaning. A text pair &lt; T s ij , T s i j &gt; is a tuple of two text segments.</p><p>The first one ordering relation is: coherence score of a text pair from different documents is lower than that from the same document. For- mally, its mathematical expression is shown be- low:</p><formula xml:id="formula_0">f (&lt; T · i· , T · i · &gt;) &lt; f ( &lt; T · jm , T · jm &gt;), i = i , m = m<label>(1)</label></formula><p>where dot · means arbitrary value.</p><p>The second one is: coherence score of text pair from different paragraphs is lower than those from the same paragraph, as represented below.</p><formula xml:id="formula_1">f (&lt; T · ip , T · ip &gt;) &lt; f (&lt; T n jq , T n+k jq &gt;), p = p<label>(2</label></formula><p>) As our defined relations are partially ordering, they have the properties of reflexivity, transitivity, and antisymmetry, Then we can easily infer that coherence score of a text pair from different docu- ments is also lower than that from the same para- graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning to Rank Semantic Coherence</head><p>Learning to rank is a widely used learning frame- work in the field of information retrieval ( <ref type="bibr" target="#b11">Liu et al., 2009</ref>). There are generally three formu- lations (Li, 2011): pointwise ranking, pairwise ranking, and listwise ranking. The goal is to learn a ranking function f (w, tp i ) → y i where tp i de- notes a text pair &lt;s1,s2&gt;. f maps tp i to a real value y i which is semantic coherence score in this paper, w is weight vector. We examine both point- wise ranking and pairwise ranking methods, list- wise ranking is not naturally fit for our task, so it is not discussed here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Pointwise Ranking</head><p>For pointwise formulation, y i = f (w, tp i ) ∈ [0, 1] computes inner product between weight vec- tor w and text pair tp i 's representation vector h i . Here we apply a sigmoid non-linearity function.</p><formula xml:id="formula_2">y i = σ(w · h i )<label>(3)</label></formula><p>Representation vectors h i of the text pair can be jointly learned through a neural network, which will be introduced in next subsection.</p><p>To conform to the partial ordering relations, we score each training instance tp i as follows. where 0 &lt; α &lt; 1 and α is a hyper-parameter chosen to maximize performance on validation dataset.</p><formula xml:id="formula_3">y * i =      0,</formula><p>With N training instances, we formulate the co- herence scoring as a regression problem and use cross entropy as loss function:</p><formula xml:id="formula_4">min − 1 N N i=1 (y i log y * i +(1−y i ) log(1−y * i ))<label>(4)</label></formula><p>Generally speaking, pointwise ranking is sim- ple, scalable and efficient to train.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Pairwise Ranking with Sampling</head><p>Pairwise formulation explicitly compares each pair of training instance and requires a minimal margin between their ranking score.</p><formula xml:id="formula_5">f (w, tp i ) &gt; f (w, tp j ) +<label>(5)</label></formula><p>Here, the text pair tp i has a higher ranking score than tp j , and y i = f (w, tp i ) ∈ (−∞, +∞). Without loss of generality, we set = 1 and use squared hinge loss as optimization function.</p><formula xml:id="formula_6">min − 1 M i,j max(0, 1 + y j − y i ) 2 (6)</formula><p>where M is the number of pairs we need to com- pare. As we can see, in our problem setting, M ≈ N 2 , which makes M an extremely large number when N ≈ 10 5 .</p><p>To make training feasible, we adopt a straight- forward sampling mechanism, which randomly samples pairs from different groups to construct a mini-batch on the fly during training.</p><p>Pairwise ranking is reported to have better per- formance than pointwise ranking, but it is less ef- ficient to train.  To model the text pair instances, we develop a symmetric convolutional neural network (CNN) architecture, as shown in <ref type="figure" target="#fig_1">Figure 1</ref>. Our model consists of two symmetric CNN models, and the two CNNs share their network configuration and parameters. Each CNN converts one text into a low-dimensional representation, and two gener- ated text representation vectors are finally concate- nated and fed into the scoring layer to get a real value as the coherence score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Semantic Coherence Neural Network</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Inference</head><p>At test time, coherence scores between any two adjacent paragraphs are computed. T − 1 para- graph boundaries with lowest semantic coherence score are chosen as topic boundaries, where T is ground-truth number of topics.</p><p>This inference procedure is computationally ef- ficient. Unlike TextTiling, it doesn't need to calcu- late a so-called "depth score".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head><p>In order to train our ranking neural net- work, we use full English Wikipedia dump, which consists of more than 5 million documents, to au- tomatically construct text pairs.</p><p>For performance evaluation, we use topic seg- mentation dataset from (Jeong and Titov, 2010) <ref type="bibr">1</ref> . This dataset consists of 864 manually labeled doc- uments from four different areas, as shown in Ta- ble 1.</p><p>News Lecture Report Biography #documents 184 120 160 400 <ref type="table">Table 1</ref>: Overview of four datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines</head><p>To compare with our method, TextTiling (Hearst, 1997), TopicTiling ( <ref type="bibr" target="#b17">Riedl and Biemann, 2012b)</ref> and <ref type="bibr">BayesSeg (Eisenstein and Barzilay, 2008</ref>) are adopted as three baselines. We use open source implementations of TextTiling 2 and TopicTiling 3 , and results of BayesSeg are from <ref type="bibr" target="#b8">(Jeong and Titov, 2010)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperparameters</head><p>Our neural network imple- mentation is based on Tensorflow ( <ref type="bibr" target="#b0">Abadi et al., 2015)</ref>. We use pre-trained 50 dimensional Glove vectors ( <ref type="bibr" target="#b13">Pennington et al., 2014)</ref>  <ref type="bibr">4</ref> for word em- beddings initialization. Each text pair consists of 2 text segments, and each text segment consists of 0.180 0.181 0.570 0.200 0.202 0.560 0.263 0.263 0.492 0.223 0.228 0.448 Ours-point-finetune 0.182 0.183 0.572 0.197 0.200 0.569 0.245 0.247 0.511 0.229 0.232 0.442 Ours-pair-static 0.176 0.178 0.580 0.177 0.180 0.600 0.252 0.253 0.518 0.220 0.224 0.472 Ours-point-static 0.173 0.175 0.587 0.176 0.179 0.608 0.240 0.241 0.529 0.216 0.219 0.479  <ref type="bibr" target="#b14">(Pevzner and Hearst, 2002</ref>) and F 1 score. P k and W D are calculated based on sliding windows, and can assign partial score to incorrect segmentation. Note that P k and W D are penalty metrics, smaller value means bet- ter performance.</p><formula xml:id="formula_7">News Lecture Report Biography P k W D F 1 P k W D F 1 P k W D F 1 P k W D F 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results and Analysis</head><p>Experimental results are shown in <ref type="table" target="#tab_2">Table 2</ref>. Our proposed model is examined in 4 different set- tings, including whether to use pointwise ranking or pairwise ranking algorithm, and whether to fine-tune word embeddings or not. The best model Ours-pointwise-static is able to achieve better or competitive performance compared to BayesSeg and TopicTiling according to all three metrics, especially on News dataset. TopicTiling is reported to perform well on heuristically constructed dataset ( <ref type="bibr" target="#b17">Riedl and Biemann, 2012b</ref>), but behave mediocre on manually labeled dataset in our experiments.</p><p>One interesting phenomenon is that fine-tuned word embeddings has negative impact on over- all performance, which is generally not the case in many NLP tasks. The reason may be that our task involves domain adaptation, and word embed- dings should generalize well across different do- mains rather than adapt to Wikipedia text. Though our proposed sampling mechanism enables easier training of pairwise ranking model, it inevitably loses some ordering information, which makes pairwise ranking model perform slightly worse than pointwise ranking model.  To illustrate what the model has learned, we show some typical examples of coherence score for text pair &lt;A,B&gt; in <ref type="table" target="#tab_3">Table 3</ref>. There is almost no lexical overlap for all the three text pairs, cosine similarity between one-hot vectors would surely fail to rank them, even though "canonization" and "commemorations", "respond" and "responses", "environment" and "environmental" are closely related semantically. As we expect, our proposed model is able to capture such semantic related- ness and assign reasonable score to each text pair, which is a key to topic boundary detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper proposes a novel approach for topic segmentation by learning to rank semantic coher- ence. Symmetric convolutional neural network is used for text pair modeling. Training data can be automatically constructed from unlabeled docu- ments, and no labeled data is needed. Experiments show promising performance on dataset from var- ious domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Semantic Coherence Neural Network</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>A variety of techniques have been directed toward the study of blood group antibodies. B: If I'd work on my place-kicking he thought he could use me. 0.022 A: A second miracle is required for her to proceed to canonization. B: Mother Teresa inspired a variety of commemorations. 0.587 A: Plants have an amazing ability to respond to stimuli from their environment. B: These responses to environmental factors are known as tropisms. 0.861</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Experimental results. (a) Ours-pair-finetune is pairwise ranking model with word embedding 
fine-tuning. (b) Ours-point-static is pointwise ranking model without word embedding fine-tuning, etc. 

no more than 3 sentences. Stop words and dig-
its are removed from input text, and all words are 
converted to lowercase. We pad input sequence 
to 40 tokens. In order to capture information of 
different granularity, convolution window size of 
both 2 and 3 are used, with 64 filters for each win-
dow size. L2 regularization coefficient is set to 
0.001. Adam algorithm (Kingma and Ba, 2014) is 
used for loss function minimization. We set α to 
0.7 for pointwise ranking. 
Evaluation 
System performance is evaluated 
according to three metrics: P k (Beeferman et al., 
1999), WindowDiff(W D) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : Coherence Score between Text Pairs.</head><label>3</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2"> https://github.com/nltk/nltk/tree/develop/nltk/tokenize 3 https://github.com/ldulcic/text-segmentation 4 http://nlp.stanford.edu/projects/glove/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their in-sightful comments on this paper. This work was partially supported by National Natural Science Foundation of China (61572049 and 61333018) and Baidu-Peking University Joint Project. The correspondence author of this paper is Sujian Li.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martın</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Software available from tensorflow. org 1</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Statistical models for text segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Beeferman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="177" to="210" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Advances in domain independent linear text segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Freddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference. Association for Computational Linguistics</title>
		<meeting>the 1st North American chapter of the Association for Computational Linguistics conference. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Topic segmentation with a structured topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Wray L Buntine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="190" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bayesian unsupervised topic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="334" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Texttiling: Segmenting text into multi-paragraph subtopic passages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marti A Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="64" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2042" to="2050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An unsupervised topic segmentation model incorporating word order</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoaib</forename><surname>Jameel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 36th international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="203" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-document topic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM international conference on Information</title>
		<meeting>the 19th ACM international conference on Information</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1119" to="1128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A short introduction to learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE TRANSACTIONS on Information and Systems</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1854" to="1862" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning to rank for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="331" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A deep architecture for matching short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1367" to="1375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A critique and improvement of an evaluation metric for text segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Pevzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="36" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Topic segmentation. Spoken language understanding: systems for extracting semantic information from speech pages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Purver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="291" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Text segmentation with topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal for Language Technology and Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="69" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Topictiling: a text segmentation algorithm based on lda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2012 Student Research Workshop</title>
		<meeting>ACL 2012 Student Research Workshop</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning to rank short text pairs with convolutional deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A hidden markov model approach to text segmentation and event tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Jonathan P Yamron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Carp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Mulbregt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 IEEE International Conference on</title>
		<meeting>the 1998 IEEE International Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="333" to="336" />
		</imprint>
	</monogr>
	<note>Acoustics, Speech and Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Abcnn: Attention-based convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Wenpeng Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.05193</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
