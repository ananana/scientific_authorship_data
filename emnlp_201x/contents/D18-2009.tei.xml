<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Demonstrating PAR4SEM-A Semantic Writing Aid with Adaptive Paraphrasing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seid</forename><forename type="middle">Muhie</forename><surname>Yimam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="laboratory">Language Technology Group</orgName>
								<orgName type="institution">Universität Hamburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="laboratory">Language Technology Group</orgName>
								<orgName type="institution">Universität Hamburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Demonstrating PAR4SEM-A Semantic Writing Aid with Adaptive Paraphrasing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations)</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations) <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="48" to="53"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>48</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we present PAR4SEM, a semantic writing aid tool based on adaptive paraphrasing. Unlike many annotation tools that are primarily used to collect training examples, PAR4SEM is integrated into a real word application , in this case a writing aid tool, in order to collect training examples from usage data. PAR4SEM is a tool, which supports an adap-tive, iterative, and interactive process where the underlying machine learning models are updated for each iteration using new training examples from usage data. After motivating the use of ever-learning tools in NLP applications , we evaluate PAR4SEM by adopting it to a text simplification task through mere usage.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural language processing and semantic appli- cations that depend on a machine learning com- ponent require training data, i.e. examples from which the machine learning algorithm learns from. The training datasets require, most of the time, manual annotation. Usually, such annotations are conducted in a predefined cycle of annotation ac- tivities. Once the annotation problem is identi- fied, a standalone annotation tool along with the annotation guideline is developed. At the end of the annotation cycle, the collected dataset is fed to the machine learning component, which produces a static model that can be used thereafter in an ap- plication.</p><p>Possible limitations of these annotation ap- proaches are: 1) Developing a standalone anno- tation tool is costly, sometimes expert or specially trained annotators are required. 2) There is no di- rect way to evaluate the dataset towards its effec- tiveness for the real-world application. 3) It suf- fers from what is known as concept drift, as the annotation process is detached from the target ap- plication, the dataset might get obsolete over time.</p><p>In this regard, we have dealt specifically with the semantic annotation problem, using an adap- tive, integrated, and personalized annotation pro- cess. By adaptive, we mean that target appli- cations do not require pre-existing training data, rather it depends on the usage data from the user. The machine learning model then adapts towards the actual goal of the application over time. In- stead of developing a standalone annotation tool, the collection of training examples is integrated inside a real-world application. Furthermore, our approach is personalized in a sense that the train- ing examples being collected are directly related to the need of the user for the application at hand. Af- ter all, the question is not: how good is the system today? It is rather: how good will it be tomorrow after we use it today? Thus, such adaptive approaches have the fol- lowing benefits: Suggestion and correction options: Since the model immediately starts learning from the usage data, it can start predicting and suggesting recom- mendations to the user immediately. Users can evaluate and correct suggestions that in turn help the model to learn from these corrections. Less costly: As the collection of the training data is based on usage data, it does not need a separate annotation cycle. Personalized: It exactly fits the need of the target application, based on the requirement of the user. Model-Life-Long Learning: As opposed to static models that once deployed on the basis of training data, adaptive models incorporate more training data the longer they are used, which should lead to better performance over time.</p><p>We have developed PAR4SEM, a semantic writ- ing aid tool using an adaptive paraphrasing com- ponent, which is used to provide context-aware lexical paraphrases while composing texts. The tool incorporates two adaptive models, namely target identification and candidate ranking. The adaptive target identification component is a clas-sification algorithm, which learns how to automat- ically identify target units (such as words, phrases or multi-word expressions), that need to be para- phrased. When the user highlights target words (usage data), it is considered as a training exam- ple for the adaptive model. The adaptive ranking model is a learning-to- rank machine learning algorithm, which is used to re-rank candidate suggestions provided for the tar- get unit. We rely on existing paraphrase resources such as PPDB 2.0, WordNet, distributional the- saurus and word embeddings (see Section 2.1.1) to generate candidate suggestions.</p><p>Some other examples for adaptive NLP setups include: 1) online learning for ranking, example <ref type="bibr" target="#b16">Yogatama et al. (2014)</ref> who tackle the pairwise learning-to-ranking problem via a scalable online learning approach, 2) adaptive machine translation (MT), e.g. <ref type="bibr" target="#b2">Denkowski et al. (2014)</ref> describe a framework for building adaptive MT systems that learn from post-editor feedback, and 3) incremen- tal learning for spam filtering, e.g. <ref type="bibr" target="#b8">Sheu et al. (2017)</ref> use a window-based technique to estimate for the condition of concept drift for each incom- ing new email.</p><p>We have evaluated our approach with a lexical simplification task use-case. The lexical simplifi- cation task contains complex word identification (adaptive target identification) and simpler candi- date selection (adaptive ranking) components.</p><p>As far as our knowledge concerned, PAR4SEM is the first tool in the semantic and NLP research community, where adaptive technologies are inte- grated into a real-world application. PAR4SEM is open source 1 and the associated data collected for the lexical simplification use-case are publicly available. The live demo of PAR4SEM is avail- able at https://ltmaggie.informatik. uni-hamburg.de/par4sem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture of PAR4SEM</head><p>The PAR4SEM system consists of backend, fron- tend, and API components. The backend compo- nent is responsible for NLP related pre-processing, adaptive machine learning model generation, data storage, etc. The frontend component sends re- quests to the backend, highlights target units, presents candidate suggestions, sends user inter- action to the database and so on. The API compo- nent transforms the frontend requests to the back-end and returns responses to the frontend. <ref type="figure" target="#fig_0">Figure  1</ref> shows the three main components of PAR4SEM and their interactions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Backend Component</head><p>The backend component consists of several mod- ules. For the adaptive paraphrasing system, the first component is to identify possible target units (such as single words, phrases, or multi-word ex- pressions). For our lexical simplification use-case, the target units identification component is instan- tiated with the datasets obtained from <ref type="bibr" target="#b14">Yimam et al. (2017a</ref><ref type="bibr">Yimam et al. ( ,b, 2018</ref>. The adaptive target identification unit then keeps on learning from the usage data (when the user highlights portions of the text to get paraphrase candidate suggestions).</p><p>Once target units are marked or recognized (by the target unit identification system), the next step is to generate possible candidate suggestion for the target unit (paraphrase candidates). The candidate suggestion module includes candidate generation and candidate ranking sub-modules. Section 2.1.1 discusses our approaches to generating and rank- ing paraphrase candidates in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Paraphrasing Resources</head><p>Paraphrase resources are datasets where target units are associated with a list of candidate units equivalent in meaning, possibly ranked by their meaning similarity. One can refer to the work of <ref type="bibr" target="#b4">Ho et al. (2014)</ref> about the details on how para- phrase resources are produced, but we will briefly discuss the different types of paraphrase resources that are used in generating candidate suggestions for PAR4SEM. PPDB 2.0: The Paraphrase Database (PPDB) is a collection of over 100 million paraphrases that was automatically constructed using a bilin- gual pivoting method. Recently released PPDB 2.0 includes improved paraphrase rankings, en-tailment relations, style information, and distribu- tional similarity measures for each paraphrase rule <ref type="bibr" target="#b7">(Pavlick et al., 2015)</ref>. WordNet: We use WordNet synonyms, which are described as words that denote the same con- cept and are interchangeable in many contexts <ref type="bibr" target="#b6">(Miller, 1995)</ref> <ref type="bibr" target="#b3">Graff, 2002</ref>). <ref type="bibr" target="#b5">Mikolov et al. (2013)</ref> pointed out that it is possible to extend the word based embed- dings model to phrase-based model using a data- driven approach where each phrase or multi-word expressions are considered as individual tokens during the training process. We have used a to- tal of 79,349 multiword expression and phrase re- sources as given in <ref type="bibr" target="#b13">Yimam et al. (2016)</ref>. We train the Phrase2Vec embeddings with 200 dimensions using skip-gram training and a window size of 5. We have retrieved the top 10 similar words to the target units as candidate suggestions.</p><note type="other">, to produce candidate suggestions for a given target unit. Distributional Thesaurus -JoBimText: We use JoBimText, an open source platform for large- scale distributional semantics based on graph rep- resentations (Biemann and Riedl, 2013), to extract candidate suggestions that are semantically simi- lar to the target unit. Phrase2Vec: We train a Phrase2Vec model (Mikolov et al., 2013) using English Wikipedia and the AQUAINT corpus of English news text (</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Adaptive Machine Learning</head><p>PAR4SEM incorporates two adaptive machine learning models. The first one is used to identify target units (target adaption) in a text while the second one is used to rank candidate suggestions (ranking adaption). Both models make use of us- age data as a training example. The target adaption model predicts target units based on the usage data (training examples) and sends them to the fron- tend component, which are then highlighted for the user. If the user replaced the highlighted tar- get units, they are considered as positive training examples for the next iteration.</p><p>The ranking adaption model first generates can- didate paraphrases using the paraphrase resource datasets (see Section 2.1.1). As all the candidates generated from the paraphrase resources might not be relevant to the target unit at a context, or as the number of candidates to be displayed might be excessively large (for example the PPDB 2.0 resource alone might produce hundreds of candi- dates for a target unit), we re-rank the candidate suggestions using a learning-to-rank adaptive ma- chine learning model. <ref type="figure" target="#fig_1">Figure 2</ref> displays the pro- cess of the adaptive models while <ref type="figure" target="#fig_2">Figure 3</ref> dis- plays the pipeline (as a loop) used in the gener- ations of the adaptive models.  The whole process is iterative, interactive, and adaptive in a sense that the underlying models (both target adaption and ranking adaption) get us- age data continuously from the user. The models get updated for each iteration, where n examples conducted in a batch mode without model update, and provide better suggestions (as target units or candidate suggestions) for the next iteration. The user interacts with the tool, probably accepting or rejecting tool suggestions, which is fed as a train- ing signal for the next iterations model. <ref type="figure" target="#fig_3">Figure 4</ref> shows the entirety of interactions, iterations, and adaptive processes of the PAR4SEM system. In the first iteration, the ranking is provided using a base- line language model while for the subsequent iter- ations, the usage data from the previous batches (t-1) is used to train a model that is used to rank the current batch (t). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Backend Technologies</head><p>The backend components are fully implemented using the Java programming language. Text seg- mentation such as sentence splitting, tokenization, lemmatization, and parts of speech tagging is han- dled using the Apache OpenNLP 2 library.</p><p>For the target unit identification system, we have used <ref type="bibr">Datumbox 3</ref> , a powerful open-source machine learning framework written in Java. We have used specifically the Adaboost classification algorithm.</p><p>For the ranking model, RankLib, which is the well-known library for the learning to rank algo- rithms from the Lemur 4 project is integrated. All the data related to PAR4SEM interactions (usage data, time, and user details) are stored in a MySQL database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Frontend Components</head><p>The frontend component of PAR4SEM is designed where document composing with a semantic para- phrasing capability is integrated seamlessly. It is a web-based application allowing access either on a local installation or over the internet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">UI Components for Paraphrasing</head><p>The frontend part of PAR4SEM comprises differ- ent modules. The most important UI component is the text editing interface ( <ref type="figure" target="#fig_4">Figure 5</ref>) that allows for adding text, highlighting target units, and display- ing candidate suggestions. 1 is the main area to compose (or paste) texts. The operational buttons ( 2 ) are used to perform some actions such as to undo and redo (composing, target unit highlight- ing, and paraphrase ranking), automatically high- lighting target units, and clear the text area. Target units are underlined in cyan color and highlighted in yellow background color as a link ( 3 ) which enables users to click, display, and select candidate suggestions for a replacement ( 4 ). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Frontend Technologies</head><p>The frontend components are implemented using HTML, CSS and JavaScript technologies. For the text highlighting and candidate suggestion re- placement, the jQuery Spellchecker 5 module is slightly modified to incorporate the semantic high- lighting (underline in cyan and a yellow back- ground). The accompanied documentation and datasets of PAR4SEM 6 are hosted at Github pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">RESTful API Component</head><p>Semantic technologies, those like PAR4SEM in- corporates highly dynamic dimensions. One di- mension is that the paraphrase resources can be varied depending on the need of the application. Another dimension is that the application can be in different languages. If the backend and the frontend technologies are highly coupled, it will be difficult to reuse the application for different languages, resources, and applications. To solve this problem, we have developed PAR4SEM using a RESTful API (aka. microservices) as a middle- ware between the backend and the frontend com- ponents.</p><p>The API component consumes requests (get- ting target units and candidate suggestions) or re- sources (saving usage data such as selection of new target units, user's preference for candidate ranking, user and machine information) from the frontend and transfers them to the backend. The backend component translates the requests or re- sources and handles them accordingly. Spring Boot 7 is used to implement the API services.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Installation and Deployment</head><p>As PAR4SEM consists of different technologies, machine learning setups, resources, and configura- tions, we opted to provide a Docker-based installa- tion and deployment options. While it is possible to fully install the tool on ones own server, we also provide an API access for the whole backend ser- vices. This allows users to quickly and easily in- stall the frontend component and relay on our API service calls for the rest of the communications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Use-case -Adaptive Text</head><p>Simplification using Crowdsourcing</p><p>An appropriate use case for adaptive paraphrasing is lexical text simplification. Lexical simplifica- tion aims to reduce the complexity of texts due to difficult words or phrases in the text <ref type="bibr" target="#b9">(Siddharthan, Advaith, 2014</ref>). We have used PAR4SEM particu- larly for text simplification task with an emphasis of making texts accessible for language learners, children, and people with disabilities. We conducted the experiment by integrating the tool into the Amazon Mechanical Turk (MTurk) 8 crowdsourcing and employ workers to simplify texts using the integrated adaptive paraphrasing system. While PAR4SEM is installed and run on our local server, we make use of the MTurk's external HIT functionality to embed and conduct the text simplification experiment. Once workers have access to our embedded tool in the MTurk browser, they will be redirected to our local instal- lation to complete the simplification task. <ref type="figure" target="#fig_4">Figure 5</ref> shows the PAR4SEM user interface to perform text simplification task by the workers while <ref type="figure">Figure 7</ref> shows the instructions as they appeared inside the MTurk's browser.</p><p>We asked workers to simplify the text for the target readers, by using the embedded paraphras- ing system. Difficult words or phrases are auto- matically highlighted so that workers can click and see possible candidate suggestions. The experi- ment was conducted over 9 iterations, where the ranking model is updated using the training dataset (usage data) collected in the previous iterations. The first iteration does not use ranking model but candidates are presented using a default language- model-based ranking. In ) we have shown that the adaptive paraphras- ing system adopts very well to text simplification, improving the NDCG ( <ref type="bibr" target="#b10">Wang et al., 2013</ref>) score from 60.66 to 75.70. <ref type="figure" target="#fig_5">Figure 6</ref> shows the learning curve for the different iterations conducted in the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we have described PAR4SEM, a se- mantic writing aid tool based on an embedded adaptive paraphrasing system. Unlike most an- notation tools, which are developed exclusively to collect training examples for machine learning applications, PAR4SEM implements an adaptive paraphrasing system where training examples are obtained from usage data.</p><p>To the best of our knowledge, PAR4SEM is the first of its kind where machine learning models are improved based on usage data and user feedback (correction of suggestions) for semantic applica- tions. PAR4SEM is used in a text simplification use-case. Evaluation of the system showed that the adaptive paraphrasing system for text simplifi- cation successfully adapted to the target task in a small number of iterations.</p><p>For future work, we would like to evaluate the system in an open task setting where users can paraphrase resp. simplify self-provided texts, and explore how groups of similar users can be uti- lized to provide adaptations for their respective sub-goals.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The main components of PAR4SEM</figDesc><graphic url="image-1.png" coords="2,307.28,113.78,218.20,108.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The main and sub-processes of target and ranking adaption components of PAR4SEM.</figDesc><graphic url="image-2.png" coords="3,307.28,142.85,218.20,95.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The loop for the generation of the adaptive models of PAR4SEM.</figDesc><graphic url="image-3.png" coords="3,307.28,299.61,218.20,175.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The iterative and adaptive interaction of PAR4SEM.</figDesc><graphic url="image-4.png" coords="4,72.00,62.84,218.20,101.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The PAR4SEM text editing component that is used to compose texts, highlight target units, and display candidate suggestions for the target units.</figDesc><graphic url="image-5.png" coords="4,307.28,132.71,218.20,118.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Learning curve showing the increase of NDCG@10 score over 9 iterations.</figDesc><graphic url="image-6.png" coords="5,307.28,62.85,218.20,120.00" type="bitmap" /></figure>

			<note place="foot" n="1"> https://uhh-lt.github.io/par4sem/</note>

			<note place="foot" n="2"> https://opennlp.apache.org/ 3 http://www.datumbox.com/ 4 https://sourceforge.net/p/lemur/wiki/ RankLib/</note>

			<note place="foot" n="5"> http://jquery-spellchecker.badsyntax. co/ 6 https://uhh-lt.github.io/par4sem/</note>

			<note place="foot" n="7"> https://projects.spring.io/ spring-boot/ 8 https://www.mturk.com/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Text: Now in 2D! a framework for lexical expansion with contextual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JLM</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="95" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Figure 7: The instructions for the text simplification task using PAR4SEM</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Real Time Adaptive Machine Translation for Post-Editing with cdec and TransCenter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Lacruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EACL 2014 Workshop on HCAT</title>
		<meeting>EACL 2014 Workshop on HCAT<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="72" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The AQUAINT Corpus of English News Text LDC2002T31</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web Download. Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Extracting lexical and phrasal paraphrases: a review of the literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chukfong</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masrah</forename><surname>Azrifah Azmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyamala</forename><surname>Murad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rabiah Abdul</forename><surname>Doraisamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kadir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="851" to="894" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ANIPS/ACNIPS</title>
		<meeting><address><addrLine>Stateline, Nevada, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">WordNet: A Lexical Database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">PPDB 2.0: Better paraphrase ranking, finegrained entailment relations, word embeddings, and style classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpendre</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL/IJCNLP</title>
		<meeting>ACL/IJCNLP<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="425" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An efficient incremental learning mechanism for tracking concept drift in spam filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jyh-Jian</forename><surname>Sheu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ko-Tsung</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nien-Feng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Chi</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A survey of research on text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJAL</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="298" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Theoretical Analysis of Normalized Discounted Cumulative Gain (NDCG) Ranking Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MLR</title>
		<meeting><address><addrLine>Princeton, New Jersey, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="25" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Par4sim-adaptive paraphrasing for text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Seid Muhie Yimam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING 2018</title>
		<meeting>of COLING 2018<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="331" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A report on the complex word identification shared task 2018</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Seid Muhie Yimam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana¨ısana¨ıs</forename><surname>Sanjaštajnersanjaˇsanjaštajner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Tack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zampieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 13th BEA</title>
		<meeting>of the 13th BEA<address><addrLine>Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="66" to="78" />
		</imprint>
	</monogr>
	<note>New Orleans</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning Paraphrasing for Multiword Expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Héctor Martínez</forename><surname>Seid Muhie Yimam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 12th Workshop on MWE</title>
		<meeting>of the 12th Workshop on MWE<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">CWIG3G2-Complex Word Identification Task across Three Text Genres and Two User Groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seid Muhie Yimam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sanjaštajnersanjaˇsanjaštajner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCNLP-17</title>
		<meeting>IJCNLP-17<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="401" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multilingual and crosslingual complex word identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seid Muhie Yimam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sanjaštajnersanjaˇsanjaštajner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PROC. of RANLP</title>
		<meeting><address><addrLine>Varna, Bulgaria. INCOMA Ltd</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="813" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamic language models for streaming text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><forename type="middle">R</forename><surname>Routledge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="181" to="192" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
