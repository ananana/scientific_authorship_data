<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Interface for Annotating Science Questions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Boratko</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harshit</forename><surname>Padigela</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divyendra</forename><surname>Mikkilineni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pritish</forename><surname>Yuvraj</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Chang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achille</forename><surname>Fokoue</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><surname>Kapanipathi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Mattei</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Musa</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Talamadupula</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Witbrock</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Interface for Annotating Science Questions</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations)</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (System Demonstrations) <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="102" to="107"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>102</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent work introduces the AI2 Reasoning Challenge (ARC) and the associated ARC dataset that partitions open domain, complex science questions into an Easy Set and a Challenge Set. That work includes an analysis of 100 questions with respect to the types of knowledge and reasoning required to answer them. However, it does not include clear definitions of these types, nor does it offer information about the quality of the labels or the annotation process used. In this paper, we introduce a novel interface for human annotation of science question-answer pairs with their respective knowledge and reasoning types, in order that the classification of new questions may be improved. We build on the classification schema proposed by prior work on the ARC dataset, and evaluate the effectiveness of our interface with a preliminary study involving 10 participants.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent work by <ref type="bibr" target="#b4">Clark et al. (2018)</ref> introduces the AI2 Reasoning Challenge (ARC) <ref type="bibr">1</ref> and the asso- ciated ARC dataset. This dataset contains science questions from standardized tests that are sepa- rated into an Easy Set and a Challenge Set. The Challenge Set comprises questions that are an- swered incorrectly by two solvers based on Point- wise Mutual Information (PMI) Information Re- trieval (IR). In addition to this division, a survey of the various types of knowledge as well as the types of reasoning that are required to answer var- ious questions in the ARC dataset was presented. This survey was based on an analysis of 100 ques- tions chosen at random from the Challenge Set. However, very little detail is provided about the questions chosen, the annotations provided, or the methodology used. These questions surround the very core of the paper, since the main contribution is a dataset that contains complex questions.</p><p>In this work, in order to overcome some of the limitations of <ref type="bibr" target="#b4">Clark et al. (2018)</ref> described above, we present a detailed annotation interface for the ARC dataset that allows a distributed set of annotators to label the knowledge and rea- soning types ( <ref type="bibr" target="#b0">Boratko et al., 2018)</ref>. Following an annotation round involving over ten people at two institutions, we measure and report statistics such as inter-rater agreement, and the distribu- tion of knowledge and reasoning type labels in the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Annotation Interface</head><p>The annotation interface introduced in this paper is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The text of the science question is displayed at the top of the left side, followed by the answer options. Each of the answer options is preceded by a radio button: each button is initially transparent, but the annotator can click on a but- ton to check whether the corresponding option is the answer to the question. This facility is to help annotators with extra information if it is needed in labeling the question; however, we leave it blank initially to avoid biasing the annotations.</p><p>Clicking on a specific answer option executes a search on the ARC corpus, with the query text of that search set to be the last sentence of the ques- tion appended with the entire text of the clicked answer option. The retrieved search results are shown in the bottom left half of the interface. Annotators have the option of labeling retrieved search results as irrelevant or relevant to answer- ing the question at hand. The query box also ac- cepts free text, and annotators who wish to craft more specific queries are free to do so. We collect all the queries executed, as well as the annotations pertaining to the relevance of the returned results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Question Annotation</head><p>The right hand side of the interface deals with the annotation of a given question. There are two boxes for annotating knowledge and reasoning types respectively. The labels are populated from the knowledge and reasoning type tables in <ref type="bibr" target="#b0">Boratko et al. (2018)</ref> (more on these types in Sec- tion 3). The annotator can also provide optional information on the quality of the retrieved search results if they choose to run a query. Finally, the annotator can use the optional field below quality to enter additional notes about the question; these notes are stored and can be retrieved for subse- quent discussion and refinement of the labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Search Result Retrieval &amp; Annotation</head><p>In addition to labeling the knowledge and reason- ing types systematically, we demonstrate yet an-other capability of our interface: given a corpus of knowledge, we are able to retrieve and display search results that may be relevant to the ques- tion (and its corresponding options) at hand. This is useful because it gives a solution technique an additional signal as it tries to identify the cor- rect answer to a given question. In open-domain question answering, the retriever plays as impor- tant a role as the machine reader <ref type="bibr" target="#b2">(Chen et al., 2017</ref>). In the past few years, there has been a lot of effort in designing sophisticated neural archi- tectures for reading a small piece of text (e.g. para- graph) ( <ref type="bibr" target="#b12">Wang and Jiang, 2016;</ref><ref type="bibr" target="#b14">Xiong et al., 2016;</ref><ref type="bibr" target="#b11">Seo et al., 2016;</ref><ref type="bibr" target="#b10">Lee et al., 2016</ref>, inter alia). How- ever, most work in open domain settings <ref type="bibr" target="#b2">(Chen et al., 2017;</ref><ref type="bibr" target="#b3">Clark and Gardner, 2017;</ref><ref type="bibr" target="#b13">Wang et al., 2018</ref>) only uses simple retrievers (such as TF-IDF based ones). As a result, there is a notable decrease in the performance of the QA system. One road- block for training a sophisticated retriever is the lack of available training data which annotates the relevance of a retrieved context with respect to the question. We believe our annotated retrieval data can be used to train a better ranker/retriever with- out obliging annotators to explicitly connect the supporting passages <ref type="bibr" target="#b7">(Jansen et al., 2018)</ref>.</p><p>The underlying retriever in our interface is a simple Elasticsearch, similar to the one used by <ref type="bibr" target="#b4">Clark et al. (2018)</ref>. The interface is populated by default with the top ranked sentences that are re- trieved with the given question as the input query. However, we noticed that results thus retrieved were often irrelevant to answering the question. To address this, our labeling interface also al- lows annotators to input their own custom queries. We found that reformulating the initial query sig- nificantly improved the quality of the retrieved context (results). We encouraged the annotators to mark the contexts (results) that they thought were relevant to answering the question at hand. For example, in <ref type="figure" target="#fig_0">Figure 1</ref>, the annotator came up with a novel query -'metals are solid at room temperatures' -and also marked the relevant sentences which are needed to answer this question. Note that sometimes we need to rea- son over multiple sentences to arrive at the answer. For example, the question in <ref type="figure" target="#fig_0">Figure 1</ref> can be an- swered by combining the first and third sentences in the 'Relevant Results' tab.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Knowledge &amp; Reasoning Types</head><p>In previous work <ref type="bibr" target="#b4">(Clark et al., 2018)</ref>, the stan- dardized test questions under consideration were split into various categories based on the kinds of knowledge and reasoning that are needed to answer those questions. The idea of classifying questions by these two types is central to the no- tion of standardized testing, which endeavors to test students on various kinds of knowledge, as well as various problem types and solution tech- niques. These categories allow for the classifica- tion of questions, which makes it easier to partition them into subsets to measure performance and im- prove solution strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Knowledge Types</head><p>In most question-answering (QA) scenarios, the knowledge that is present with the system (or the agent) determines whether a given question can be answered. The full list of the revised knowledge labels (types) -along with the instructions given to annotators and respective exemplars from the ARC question set -can be found in our comple- mentary work ( <ref type="bibr" target="#b0">Boratko et al., 2018)</ref>. For the an- notation of knowledge types using our interface, annotators were given the following instructions:</p><p>You are to answer the question, "In a perfect world given an ideal knowledge source, what types of knowledge would you as a human need to answer this question?" You are allowed to se- lect multiple labels for this type which will be recorded as an ordered list. You are to assign la- bels in the order of importance to answering the questions at hand.</p><p>In order to level the field among annotators, we in- cluded phrasing about an ideal knowledge source. Additionally, displaying the retrieved search re- sults in the interface provides another way for the annotators to share some common ground with re- spect to the typical kind of knowledge that is likely to be available. We also provide instruction-based definitions for each class, as opposed to the sin- gle exemplars provided previously. We believe this greatly simplifies the annotation task for new an- notators, since they no longer need to perform a preliminary manual analysis of the QA set in order to understand the distinctions between the classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Reasoning Types</head><p>The annotation instructions for reasoning types follow a similar pattern to the knowledge types described in the previous section. The annotators were given the following instructions when anno- tating the reasoning types:</p><p>You are to answer the question, "What types of reasoning or problem solving would a competent student with access to Wikipedia need to answer this question?" You are allowed to select multiple labels for this type which will be recorded as an ordered list. You are to assign labels in the order of importance to answering the questions at hand.</p><p>You may use the search results to help dif- ferentiate between the linguistic and multi-hop reasoning types. Any label other than these should take precedence if they apply. For example, a question that requires using a mathe- matical formula along with linguistic matching should be labeled algebraic, linguistic.</p><p>Notice that the instructions in this case refer to be- ing able to access a specific knowledge corpus, and allow for the selection of multiple labels in decreasing order of applicability. We also provide specific instructions on the order of precedence as relates to linguistic and multi-hop reasoning types: this is based on our empirical observation that many questions can be classified trivially into these reasoning categories, and we would prefer (for downstream application use) a clean split into as many distinct categories as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Members of the annotation group were given ac- cess to the annotation interface (which includes the question, answers, query search results and more information as described above). Each anno- tator was shown the questions in a random order, and was allowed to skip or pass any question.</p><p>Statistics. We collected labels from at least 3 unique annotators (out of the possible 10) for 192 distinct questions. This annotation process pro- duced 1.42 knowledge type labels and 1.7 reason- ing type labels per question. <ref type="figure">Figure 2</ref> and <ref type="figure">Figure 3</ref> shows the distribution of annotation labels by all raters at any position. While Basic Facts domi- nates the knowledge type labels, there is no clear cut consensus for the reasoning type. Indeed, qn logic, linguistic, and explanation occur most fre- quently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Inter-Rater Agreement</head><p>A comprehensive look at the labels and inter-rater agreement can be found in <ref type="table" target="#tab_1">Table 1 and Table 2</ref>. Fleiss' κ is often used to measure inter-rater agree- ment <ref type="bibr" target="#b5">(Cohen, 1995)</ref>. Informally, this measures the amount of agreement, beyond chance, based on the number of raters, objects and classes. κ &gt; 0.2 is typically taken to denote good agreement be- tween raters, while a negative value means that there was little to no agreement. Since Fleiss' κ is only defined for a single set of labels, we con- sider only the first (most important) label for each question in the statistic we report. In addition to Fleiss' κ we also use the Kemeny voting rule <ref type="bibr" target="#b8">(Kemeny, 1959)</ref> to measure the con- sensus by the annotators. The Kemeny voting rule minimizes the Kendall Tau ( <ref type="bibr">Kendall, 1938) (flip)</ref> distance between the output ordering and the or- dering of all annotators. One theory of voting (ag- gregation) is that there is a true or correct ordering and all voters provide a noisy observation of the ground truth. This method of thinking is largely credited to Condorcet ( <ref type="bibr" target="#b1">de Caritat, 1785;</ref><ref type="bibr" target="#b15">Young, 1988)</ref> and there is recent work in characterizing other voting rules as maximum likelihood estima- tors (MLEs) <ref type="bibr" target="#b6">(Conitzer et al., 2009</ref>). The Kemeny voting rule is the MLE of the Condorcet Noise Model, in which pairwise inversions of the pref- erence order happen uniformly at random <ref type="bibr" target="#b15">(Young, 1988</ref><ref type="bibr" target="#b16">(Young, , 1995</ref>. Hence, if we assume all annotators make pairwise errors uniformly at random then Kemeny is the MLE of label orders they report.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Label</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Knowledge Labels</head><p>We achieve κ = 0.342, which means that our raters did a reasonable job of independently agreeing on the types of knowledge required to answer the questions. The mean Kemeny score of the con- sensus ranking for each question is 2.57, meaning that on average there are less than three flips re- quired to get from the consensus ranking to each of the annotators' rankings. The most frequent label in the first position was basic facts, followed by causes. Overall, there was a reasonable amount of consensus between the raters for knowledge type: 64 /192 questions had a consensus amongst all the raters. Taken together, our results on knowledge type indicate that most questions deal with basic facts, causes, and definitions; and that labeling can be done reliably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Reasoning Labels</head><p>The inter-rater agreement score for the reasoning labels tells a very different story from the knowl- edge labels. The agreement was κ = −0.683, which indicates that raters did not agree above chance on their labels. Strong evidence for this comes from the fact that only 27 /192 questions had a consensus label. This may be due to the fact that we allow multiple labels, and the annotators sim- ply disagree on the order of the labels. However, the score of the consensus ranking for each ques- tion is 6.57, which indicates that on average the ordering of the labels is quite far apart.</p><p>Considering the histogram in <ref type="figure">Figure 3</ref>, we see that qn logic, linguistic, and explanation are the most frequent label types; this may indicate that getting better at understanding the questions them- selves could lead to a big boost for reasoners. For <ref type="figure" target="#fig_3">Figure 4</ref>, we have merged the first and second la- bel (if present) for all annotators. Now, the set of all possible labels is all singletons as well as all pairs of labels. Comparing this histogram to the one in <ref type="figure">Figure 3</ref>, we see that while linguistic and explanation remain somewhat unchanged, the qn logic label becomes very spread out across the types. This is more support for our hypothesis that annotators may be disagreeing on the ordering of the labels, rather than the content itself.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Search Results</head><p>To quantitatively measure the efficacy of the an- notated context (search results) from the inter- face, we evaluated 47 questions and their respec- tive human-annotated relevant sentences with a pretrained DrQA model ( <ref type="bibr" target="#b2">Chen et al., 2017)</ref>. We compared this to a baseline which only returned the sentences retrieved by using the text of the question plus given options as input queries. Since DrQA returns a span from the input sentences, we picked the multiple choice option that maxi- mally overlapped with the returned answer span. Our baseline results are 7 correct out of 47 ques- tions. With the annotated context, the performance increased to 27 correctly answered questions -a 42% increase in accuracy. Encouraged by these re- sults, we posit that the community should focus a lot of attention on improving the retrieval portions of the various QA systems available; we think that annotated context will certainly help in training a better ranker. We conclude that the community should focus on improving the retrieval portion of their QA system and we think that the annotated context would help in training a better ranker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion &amp; Future Work</head><p>In this paper, we introduce a novel annotation in- terface and define annotation instructions for the knowledge and reasoning type labels that are used for question analysis for standardized tests. We an- notate approximately 200 questions from the ARC Challenge Set shared by AI2 with the types of knowledge and reasoning required to answer the respective questions. Each question has at least 3 annotators, with high agreement on the require- ments for knowledge type. We will leverage the knowledge and reasoning type annotations, as well as the search annotations, to improve the perfor- mance of QA systems. We will also release these annotations to the community to complement the ARC Dataset, and make our annotation interface available to interested researchers for use with other question-answering (QA) tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A screenshot of the interface to our annotation system, described in Section 2.</figDesc><graphic url="image-1.png" coords="2,74.27,62.81,448.99,529.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Histogram of the first (most important) knowledge label for each question; the Y-axis refers to annotations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Histogram of the reasoning labels when we combine the first and (if present) second label of every annotator. The count refers to annotations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Pairwise inter-rater agreement for Knowledge La-

bels, along with the mean and Fleiss' κ for survey responses. 

Label 
Appears 
Majority 
Consensus 

linguistic 
66 
31 
8 
algebraic 
15 
8 
3 
explanation 
80 
22 
4 
hypothetical 
62 
21 
6 
multihop 
45 
6 
0 
comparison 
46 
13 
3 
qn logic 
78 
33 
2 
physical 
18 
3 
0 
analogy 
4 
1 
1 

Fleiss' κ = −0.683 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Pairwise inter-rater agreement for Reasoning La-

bels, along with the mean and Fleiss' κ for survey responses. 

</table></figure>

			<note place="foot" n="1"> http://data.allenai.org/arc/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Systematic Classification of the Knowledge, Reasoning, and Context within the ARC Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Boratko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harshit</forename><surname>Padigela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divyendra</forename><surname>Mikkilineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pritish</forename><surname>Yuvraj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achille</forename><surname>Fokoue-Nkoutche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><surname>Kapanipathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Mattei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Musa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Talamadupula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Witbrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2018 Workshop on Machine Reading for Question Answering (MRQA)</title>
		<meeting>the ACL 2018 Workshop on Machine Reading for Question Answering (MRQA)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Essai sur l&apos;application de l&apos;analysè a la probabilité des décisions: renduesà rendues`renduesà la pluralité des voix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J A N</forename><surname>De Caritat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">L&apos;Imprimerie Royale</title>
		<meeting><address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Reading wikipedia to answer open-domain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00051</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10723</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Think you have solved question answering? Try ARC, the AI2 Reasning Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<idno>ArXiv e-prints 1803.05457</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Empirical Methods for Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Preference functions that score rankings and maximum likelihood estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Conitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rognlie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the 21st International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="109" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">WorldTree: A Corpus of Explanation Graphs for Elementary Science Questions supporting Multi-hop Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Marmorstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Morrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mathematics without numbers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Kemeny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Daedalus</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="577" to="591" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A new measure of rank correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="93" />
			<date type="published" when="1938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning recurrent span representations for extractive question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimi</forename><surname>Salant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01436</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Bi-directional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01603</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Machine comprehension using match-lstm and answer pointer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.07905</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">R3: Reinforced ranker-reader for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Dynamic coattention networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01604</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Condorcet&apos;s theory of voting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1231" to="1244" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimal voting rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Economic Perspectives</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="64" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
