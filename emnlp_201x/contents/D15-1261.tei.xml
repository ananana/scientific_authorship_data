<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Estimation of Discourse Segmentation Labels from Crowd Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziheng</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="laboratory">Center for Computational Learning Systems Columbia University</orgName>
								<orgName type="institution" key="instit1">Columbia University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialu</forename><surname>Zhong</surname></persName>
							<email>jialu.zhong@columbia.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="laboratory">Center for Computational Learning Systems Columbia University</orgName>
								<orgName type="institution" key="instit1">Columbia University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="laboratory">Center for Computational Learning Systems Columbia University</orgName>
								<orgName type="institution" key="instit1">Columbia University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Estimation of Discourse Segmentation Labels from Crowd Data</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>For annotation tasks involving independent judgments, probabilistic models have been used to infer ground truth labels from data where a crowd of many annotators labels the same items. Such models have been shown to produce results superior to taking the majority vote, but have not been applied to sequential data. We present two methods to infer ground truth labels from sequential annotations where we assume judgments are not independent, based on the observation that an annotator&apos;s segments all tend to be several utterances long. The data consists of crowd labels for annotation of discourse segment boundaries. The new methods extend Hidden Markov Models to relax the independence assumption. The two methods are distinct, so positive labels proposed by both are taken to be ground truth. In addition, results of the models are checked using metrics that test whether an annotator&apos;s accuracy relative to a given model remains consistent across different conversations.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A single, spontaneous, spoken interaction can consist of multiple activities, such as to plan a future event, to complain about a past situation, or to carry out a transaction that might consist of subtasks. Speakers shift from one activity to the next with more or less awareness and explicit demarcation. To treat such con- versational activities as a sequence of discrete units is a convenient oversimplification that is often resorted to ( <ref type="bibr" target="#b2">Bokaei et al., 2015;</ref><ref type="bibr" target="#b12">Galley et al., 2003;</ref><ref type="bibr" target="#b23">Passonneau and Litman, 1997)</ref>. Systems that provide auto- mated access to spoken language data often rely on segmentation of spoken discourse into sequential units for summarization ( <ref type="bibr" target="#b36">Wang and Cardie, 2012;</ref><ref type="bibr" target="#b8">Dielmann and Renals, 2005</ref>) or information retrieval ( <ref type="bibr" target="#b37">Ward et al., 2015)</ref>. Research on the organization of spoken dis- course also relies directly or indirectly on identifica- tion of such units to detect agreement among partici- pants ( <ref type="bibr" target="#b14">Hillard et al., 2003;</ref><ref type="bibr" target="#b34">Somasundaran et al., 2007;</ref><ref type="bibr" target="#b13">Germesin and Wilson, 2009)</ref>, multiparty meeting ac- tion items <ref type="bibr" target="#b27">(Purver et al., 2007</ref>), decisions <ref type="bibr" target="#b10">(Fernández et al., 2008)</ref>, or answers to questions <ref type="bibr" target="#b35">(Sun and Chai, 2007;</ref><ref type="bibr" target="#b3">Bosma, 2005</ref>). To support such research, there is a need for annotation methods to segment conversa- tional interaction into sequential, multi-utterance units. We present and compare two methods to derive such data from crowdsourced annotations.</p><p>Crowdsourced annotation, where each item is la- beled by a crowd of many independent annotators, is becoming more common in natural language process- ing. Examples include word sense <ref type="bibr" target="#b5">(Bruce and Wiebe, 1999;</ref><ref type="bibr" target="#b33">Snow et al., 2008;</ref><ref type="bibr" target="#b22">Passonneau and Carpenter, 2014)</ref>, named entities ( <ref type="bibr" target="#b11">Finin et al., 2010)</ref>, and sev- eral other tasks in ( <ref type="bibr" target="#b33">Snow et al., 2008)</ref>, including tex- tual entailment. Three advantages to corpus annotation through application of a probabilistic model to crowd- sourced labels, rather than reliance on interannotator agreement computed for a small number of trained an- notators, are higher quality, lower cost, and a poste- rior probability for each ground truth label <ref type="bibr" target="#b31">(Sheng et al., 2008;</ref><ref type="bibr" target="#b33">Snow et al., 2008</ref>; <ref type="bibr" target="#b22">Passonneau and Carpenter, 2014</ref>). The latter serves as a confidence measure, which contrasts with interannotator agreement mea- sures and with majority-voted labels, neither of which provides quality information for the ground truth la- bels on individual items. Previous work has demon- strated that model estimation of ground truth labels from crowd labels produces results superior to the crowd's majority vote, due to differences among anno- tators in the quality of their labels <ref type="bibr" target="#b6">(Dawid and Skene, 1979;</ref><ref type="bibr" target="#b33">Snow et al., 2008;</ref><ref type="bibr" target="#b22">Passonneau and Carpenter, 2014)</ref>. No previous work, however, provides model- based estimation of labels for sequential annotation from crowd labels.</p><p>For the discourse segmentation data presented here, annotators were presented with audio files of conversa- tions and corresponding transcriptions into utterances. The annotation task was to identify each utterance that completes a discourse segment spanning one or more utterances, based on the speakers' conversational ac- tivities or intentions, as in ( <ref type="bibr" target="#b23">Passonneau and Litman, 1997</ref>). The annotations from y annotators for a conver- sation with x utterances can be represented as a y × x matrix, with cell values n ij ∈ {0, 1} to represent the binary segment boundary label assigned by annotator y i at utterance x j . <ref type="figure" target="#fig_0">Figure 1</ref> illustrates part of such a matrix. The eight annotators for this conversation are on the y-axis and utterances 80 through 180 are on the x-axis. Colored bars represent positive labels, and each color represents a distinct annotator. The label distri- bution shown here is typical of our dataset: an annota- tor's positive labels are typically separated by several utterances, and annotators agree much more often on non-boundaries than on boundaries. Full consensus on a positive label is rare, but does occur. Here, all eight annotators assigned a positive label at utterance 120, six at utterance 178, and five at utterance 140.</p><p>Our work assumes that unobserved true labels con- dition the annotators' observed labels, and can be mod- eled as hidden states in a Markov-type process. Be- cause an annotator rarely assigns positive labels for ad- jacent utterances, we assume that neither the true labels nor the observations are conditionally independent, and therefore are not generated by a simple Markov pro- cess. Our first model adapts the Double Chain Markov Model <ref type="bibr" target="#b1">(Berchtold, 1999</ref>), designed to account for such cases. We then propose a second model that assumes that each annotator's labels are drawn from a Bernoulli distribution, that annotator performance is a parame- ter of the model, and that the state transitions are con- ditioned by an empirical distribution of discourse seg- ment lengths. The two methods are quite distinct. Each thus serves as an evaluation of the other. The seg- ment boundaries proposed by both models include all the majority vote cases, and in addition, cases voted on by a minority of relatively accurate annotators. We take segment boundaries proposed by both methods as ground truth. To further assess the results of the mod- els, we assume that an annotator's accuracies should be consistent across the conversations she annotates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Previous work on annotation of discourse into lin- ear segments has used a variety of methods to de- rive ground truth segment boundaries. In <ref type="bibr" target="#b23">(Passonneau and Litman, 1997)</ref>, seven annotators annotated narra- tive monologues for segments based on speaker inten- tion. Agreement levels for ground truth boundaries were based on statistical significance using Cochran's Q. In ( <ref type="bibr" target="#b12">Galley et al., 2003)</ref>, three annotators segmented the ICSI meeting corpus into topical units, and ma- jority agreement was taken as ground truth. A func- tional segmentation of meetings from the AMI mul- tiparty meeting corpus based on involved participants was segmented by one annotator and finalized by a sec- ond annotator <ref type="bibr" target="#b2">(Bokaei et al., 2015)</ref>. Task-based seg- mentation of patron-librarian interactions <ref type="bibr" target="#b25">(Passonneau et al., 2011</ref>) measured agreement among two annota- tors using Krippendorff's Alpha at an average of 0.77 <ref type="bibr" target="#b16">(Krippendorff, 1980)</ref>. The annotation task here mostly closely resembles <ref type="bibr" target="#b23">(Passonneau and Litman, 1997)</ref>, and uses a similar number of annotators. No prior work, however, applies a probabilistic model to crowd labels for discourse segmentation.</p><p>Estimation of ground truth from crowd labels has been applied to many tasks, but is especially useful where judgments are subjective, making ground truth difficult to arrive at. Application areas include dis- ease prevalence estimation <ref type="bibr" target="#b0">(Albert and Dodd, 2008)</ref>, identification of craters in images of Venus ( <ref type="bibr" target="#b32">Smyth et al., 1995)</ref>, curation of biological data ( <ref type="bibr" target="#b30">Rzhetsky et al., 2009)</ref>, computer vision ( <ref type="bibr" target="#b38">Whitehill et al., 2009)</ref>, pa- tient history <ref type="bibr" target="#b6">(Dawid and Skene, 1979)</ref>, and clinical re- ports (2010). <ref type="bibr" target="#b32">Smyth et al. (1995)</ref>, <ref type="bibr" target="#b29">Rogers et al., and (2010)</ref> and <ref type="bibr" target="#b28">Raykar et al. (2010)</ref> discuss the advan- tages of probabilistically annotated corpora over ma- jority vote. Much of this work is motivated by the ob- servation that annotators have different accuracies, and the fact that when annotators have known accuracies it can be shown that a majority of inaccurate annota- tors can be wrong ( <ref type="bibr" target="#b28">Raykar et al., 2010;</ref><ref type="bibr" target="#b22">Passonneau and Carpenter, 2014)</ref>. Equally important, information from inaccurate annotators informs the model inference. For example, an inaccurate annotator might be biased to- wards label m whenever the true label is z. <ref type="bibr" target="#b6">Dawid and Skene (1979)</ref> present a joint model of true labels, observed labels, and annotator perfor- mance. Perhaps its first application to NLP data was the Bruce and Wiebe (1999) investigation of word sense. It has also been applied to more fine-grained word sense with a direct comparison to trained annotator la- bels in ( <ref type="bibr" target="#b22">Passonneau and Carpenter, 2014</ref>). <ref type="bibr" target="#b33">Snow et al. (2008)</ref> showed that application of the same model to noisy crowd annotations produced data of equal qual- ity to five distinct published gold standards. <ref type="bibr" target="#b15">Hovy et al. (2013)</ref> apply a simple and effective model to iden- tify untrustworthy annotators and test it on the same datasets used in ( <ref type="bibr" target="#b33">Snow et al., 2008</ref>). As they point out, when ties occur among an even number of annotators, it's necessary to resort to a tie-breaking procedure, e.g., for utterance 155 in <ref type="figure" target="#fig_0">Figure 1</ref> where four annotators as- sign a positive label and four do not.</p><p>In experiments on an existing dataset of word sense annotation, <ref type="bibr" target="#b9">Dligach et al. (2010)</ref> compare singly anno- tated data with doubly annotated adjudicated data, us- ing trained annotators. They find that with the same amount of data, machine learning performance im- proves with the doubly annotated adjudicated data by a small amount, but that investing in more singly an- notated labels leads to greater improvements. Their re- sults on trained annotators, however, would not apply to our use case involving untrained annotators. In pre- vious work, we found the cost per ground truth label of singly annotated data with trained annotators to be more than twice that for multiply annotated data with twenty untrained annotators ( <ref type="bibr" target="#b22">Passonneau and Carpenter, 2014</ref>). Half that many would have been sufficient for the Dawid &amp; Skene model used there, which would reduce the cost by half again as much. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data and Annotation Task</head><p>The data consists of digital recordings and transcripts of fifty telephone calls between family members and friends who were native speakers of Tagalog. These were collected for the Babel program, sponsored by the Intelligence Advanced Research Projects Activ- ity (IARPA). The calls ranged in length from about seven to ten minutes (µ = 9.67 minutes, σ=0.68 min- utes). Transcripts provided by IARPA had an average of 364.66 utterances (min=239; max=475; σ=60.80).</p><p>The annotations were collected using Amazon Me- chanical Turk. The task name and instructions were in English. The instructions were provided through a short video and text. Proficiency in Tagalog was as- sessed through a vocabulary test. Those who passed the vocabulary test were paid to do an initial annotation so we could ensure they understood the task. The ini- tial task was based on a short Tagalog conversation that had been translated, annotated by a bilingual speaker of Tagalog and English, and verified by Passonneau. Annotators who understood the task and whose labels and descriptions seemed reasonable were admitted into the pool of annotators. A pool of nine annotators com- pleted the qualifications. Each conversation was anno- tated by at least five annotators. Altogether, annotators assigned 5,567 labels to 164,097 utterances. Annota- tors' segments had a mean length of 21.85 utterances with a high standard deviation (σ = 19.32).</p><p>The interface designed for the annotation task is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. Through the interface, annotators could read the transcript of a recorded conversation, and could play, pause or stop the audio. Each utterance had a checkbox for assigning a positive label if the an- notator judged it to be the end of a segment. As shown, selection of a checkbox opened a text box for the anno- tator to enter a brief description of the segment. <ref type="table">Table 1</ref> in section 8 illustrates the descriptions assigned by six annotators to several segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Assumptions</head><p>Given the many labels from annotators, our goal is to estimate a ground truth label for each utterance posi- tion, where the label values represent a binary classi- fication of segment boundaries. Our two models each assume there is a hidden true label that conditions an annotator's observed labels, and that can be estimated from the observed labels. How well the estimated ground truth fits the data thus depends on how well the model assumptions accord with the phenomenon of interest. The models do not account for annotator differences in the level of granularity they apply; cf. the contrast between lumpers and splitters in taxonomic classification of the natural world <ref type="bibr" target="#b4">(Branch, 2014)</ref>. Fur- ther, neither model takes linguistic features into ac- count that annotators consider in deciding on segments, such as speaker attitude towards utterance content or speaker role in the conversational activity <ref type="bibr" target="#b20">(Niekrasz and Moore, 2009)</ref>. We find, however, much agree- ment between the two models on the proposed segment boundaries, and leave for future work the question of whether more complex models could accoount for dif- ferences in granularity or utterance features.</p><p>As discussed in section 2, we assume that annotators are not equally accurate, and that a probabilistic model based on the distribution of observed labels can do bet- ter than majority vote. Inspired by the type of prob- abilistic model proposed in <ref type="bibr" target="#b6">(Dawid and Skene, 1979)</ref> and extended in <ref type="bibr" target="#b5">(Bruce and Wiebe, 1999;</ref><ref type="bibr" target="#b22">Passonneau and Carpenter, 2014)</ref>, annotator accuracy is a parame- ter of our second model. As described in detail in sub- sequent sections, the two models proposed here rely on distinct assumptions and inference methods. They nev- ertheless propose many of the same labels. We take each model to provide independent evidence for the ground truth labels, thus the final labels are those voted on by both models.   In addition, we assume that annotators' accuracies should be relatively consistent across conversations, and we measure how well each model's results support this assumption. We base the assumption on the obser- vation that the annotation task is the same for all con- versations, and an annotator's relative ability to do the task should not change significantly. The annotators all had the same initial training, and did about the same number of conversations. The conversations all had similar conditions of collection, similar participants, and similarly mundane topics and conversational activ- ities that most annotators would be familiar with. The subjects that were discussed included parties, watch- ing tv, siblings, money, jobs, spouses, medical issues, birthdays, and so on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Double Chain Dynamic Hidden</head><p>Markov Model</p><p>The first model we propose combines the Double Chain Markov Model (Berchtold, 1999) and dynamic Bayesian networks ( <ref type="bibr" target="#b18">Martinez and Sucar, 2008)</ref>. The double chaining involves the dependence of observa- tions on immediately prior observations. <ref type="figure" target="#fig_3">Figure 3</ref> shows that for all y tl , t ≥ 2, observation y tl depends on observation y (t−1)l . The emission matrix at the first utterance x 1 is thus a 2×2 matrix, while all subsequent emission matrices are 2 × 2 × 2. As in ( <ref type="bibr" target="#b18">Martinez and Sucar, 2008)</ref>, the observed states can be regarded as a composition of m independent chains, where m is the number of annotators for the conversation. Also, the l th annotator's observation at the t th utterance depends not only on the same hidden state x t , but also on the last observation y (t−1)l . Assume in a conversation, there are m annotators and n utterances. The model Θ = {π, γ, A, B} can be described as follows:</p><p>• a set of hidden states, i.e the true labels: x t ∈ {0, 1}, t ∈ {1, 2, . . . , n}. x t = 1 represents the t th utterance is a true boundary and 0 otherwise;</p><p>• a set of observed variables: y tl ∈ {0, 1}, l ∈ {1, 2, . . . , m} annotators, t ∈ {1, 2, . . . , n} utter- ances. y tl = 1 represents that the l th annotator annotates t th utterance to a true boundary and 0 otherwise;</p><p>• Θ is a vector of parameters. To be more specific, the elements are:</p><p>-the probability of the initial hidden state: π x1 , x 1 ∈ {0, 1}. Note π 0 + π 1 = 1. -the probabilities of the initial emission ma- trix. Note that the initial emission matrix is a 2 × 2 matrix: γ l ∈ {c x1,y 1l }, x 1 , y 1l ∈ {0, 1}, l ∈ {1, 2, . . . , m}. For annotator l, c x1,y 1l is the probability of emitting from x 1 to y 1l . -the transition matrix between hidden states, A ∈ {a xt−1,xt }, x t−1 , x t ∈ {0, 1}, t ∈ {2, 3, . . . , n}. a xt−1,xt is the probability of transitioning from x t−1 to x t . -the emission matrices, B l ∈ {b xt,y (t−1)l ,y tl }, x t , y (t−1)l , y tl ∈ {0, 1}, l ∈ {1, 2, . . . , m}, t ∈ {2, 3, . . . , n}. Note that the emis- sion matrix is a 2 × 2 × 2 matrix as each observed state depends on current hidden state as well as the previous observation, i.e., b xt,y (t−1)l ,y tl is the probability of emitting from x t to y tl and transitioning from y (t−1)l to y tl .</p><p>A graphical sketch of the DCD HMM model is shown in <ref type="figure" target="#fig_3">Figure 3</ref>. The target function F = P (x, y|Θ) is:</p><formula xml:id="formula_0">F = π x1 m l=1 c x1,y 1l n t=2 a xt−1,xt m l=1 n t=2 b xt,y (t−1)l ,y tl</formula><p>We can derive a marginal distribution over y and have the likelihood as:</p><formula xml:id="formula_1">L(Θ) = P (y|Θ) = x P (x, y|Θ)</formula><p>Our goal is to find the parameters (Θ) that maximize the above function. Bayes Net Toolbox for Matlab <ref type="bibr" target="#b19">(Murphy, 2001</ref>) is used for the inference. Expectation- Maximization (EM) with Junction Tree inference for the E-step is used for learning the parameters. The Junction Tree Algorithm is a method to calculate marginals by propagation on the graph. It runs as fol- lows: 1) Initialize: Pick a proper root and initialize all variables; 2) Collect: Pass message from each child of a node through separators to the parent node and update the node with collected evidence; 3) Distribute: Send back message to each child of the node through separa- tors and update the child with distributed evidence; 4) Normalize: Normalize cliques connected by a separa- tor so they agree with each other: e.g., for {AB} and {BC}, if we have A {AB} = C {AB}, propaga- tion is complete.</p><p>After convergence from EM, junction tree propaga- tion is again used for inference, and the model produces a probability for each ground truth label. We take the label to be positive if the posterior probability is greater than 0.5; as shown in section 8, probabilities tend to be very high or very low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Interval-dependent HMM</head><p>The second model, Interval-dependent HMM, imposes a constraint on the state transitions between two posi- tive labels based on the empirical distribution of inter- vals between observed labels. Initially, we examined known distributions. The Poisson, for example, repre- sents the probability of events in an interval as an av- erage rate. The model based on the Poisson did not perform particularly well. Histograms of interval sizes from different conversations have similar shapes, how- ever, as illustrated in <ref type="figure" target="#fig_4">Figure 4</ref>. Although more of the probability is towards 20 to 40 utterances in <ref type="figure" target="#fig_4">Figure 4a</ref>, and between 15 and 35 utterances in <ref type="figure" target="#fig_4">Figure 4b</ref>, we as- sume these small differences in the two distributions are mainly due to sampling variation. As discussed in preceding sections, the model we present here assumes that the probability of a true label at time t i is a func- tion of the interval length t i − t j , where t j is the most recent time of a true label. The observed data for all annotators on all conversations provides a set of time intervals to construct the empirical distribution. To assess whether we have sufficient data to reliably construct the empirical distribution, we performed fifty iterations of random divisions of the data into two sam- ples. For each pair of samples, we measured the max- imum distance between pairs of cumulative distribu- tion function (CDF) curves, and used the two-sample Kolmogorov-Smirnov test to measure the goodness of fit of the two curves. <ref type="figure" target="#fig_5">Figure 5</ref> shows an example com- parison of two CDF curves which have a maximum gap of 0.0175 and a K-S p-value of 0.7866. The mean max- imum distance between pairs of curves was 0.014, with a standard deviation of 0.009, both of which are quite small. The p-values for the K-S test ranged from 0.4 to 0.96, which fail to reject the hypothesis that the pairs of samples are from the same distribution. While the two measures are not conclusive evidence that we have suf- ficient data to construct the empirical distribution, they are supportive. Further, reliance on estimates of the empirical distribution are preferable to a known distri- bution that does not fit the data, such as the Poisson.</p><p>The model can be described as follows:</p><p>• the observations Y ij ∈ 0, 1, i ∈ 1, 2, · · · , N , j ∈ 1, 2, · · · , J;</p><p>• the true labels Z i ∈ 0, 1, i ∈ 1, 2, · · · , N ;</p><p>• the 2 × 2 annotator performance matrices B j ;</p><p>• the initial state probability π Given N utterances, J annotators, the initial state prob- ability π and four cells in each annotator's performance matrix B j , where B j11 represents the true positives (the probability that given a ground truth positive la- bel, annotator a j assigns a positive label), B j10 rep- resents false negatives, B j01 represents false positives, and B j00 represents true negatives. π = 1 is the proba- bility that the first hidden state is a boundary and π = 2 means it is not. Our objective is to find the param- eter vector θ = (π, B) that maximize the likelihood P (Y |θ), and to use this θ to estimate the true labels Z.</p><p>To solve:</p><formula xml:id="formula_2">Argmax θ log [P (Y |θ)] = Argmax θ log Z P (Y, Z|θ)</formula><p>we use expectation-maximization (EM).</p><p>E step First, we should find the lower bound of our optimization object: Argmax</p><formula xml:id="formula_3">θ log Z P (Y, Z|θ)</formula><p>; by Jensen's inequality, we have:</p><formula xml:id="formula_4">log Z P (Y, Z|θ) = log Z P (Y, Z|θ) Q θ (Z) Q θ (Z) ≥ Z Q θ (Z) log P (Y, Z|θ) Q θ (Z) Q θ (Z)</formula><p>is a function of θ which satisfies that Z Q θ (Z) = 1. The equality holds if and only if</p><formula xml:id="formula_5">P (Y, Z|θ) Q θ (Z) = c for all Z</formula><p>Note that c is a constant. In the E step we need to calculate the Q function to maintain the equality. By straightforward algebra, we get Q θ = P (Z|Y, θ).</p><p>M step In this part, we should maximize our lower bound:</p><formula xml:id="formula_6">Argmax θ Z Q θ (n) (Z) log P (Y, Z|θ) Q θ (n) (Z)</formula><p>Since log [Q θ (Z)] is a term not related to θ, P (Z|Y, θ) ∝ P (Z, Y |θ). Our problem becomes:</p><formula xml:id="formula_7">Argmax θ Z P (Y, Z|θ (n) ) log [P (Y, Z|θ)]</formula><p>θ (n) is the parameter we get from the last iteration, and the Q function is fixed in this M step. We cannot use the forward-backward algorithm to optimize, because the first order Markov property does not hold: P (Z i = 1) is a function of the last positive label Z j = 1 at time j such that j &lt; i, and for all k such that j &lt; k &lt; i, Z k = 0. To make use of the Markov property, we rely on a hidden variable U i to save the interval length between i and j. The hidden parameter space is then expanded to X t = (Z t , U t ), where U t denotes the size of the interval between the current position t i and the most recent t j with a positive label. If the true label Z ti = 0, then U ti = t i − t j , and if Z ti = 1, then U ti = 0. This gives t + 1 possible states for each t: the t states for Z t = 0, and one state for Z t = 1. In this problem, given a length N conversation, there are N +1 hidden states at each moment. X t = 1 means (Z t = 1, U t = 0), X t = 2 means (Z t = 0, U t = 1), X t = 3 means (Z t = 0, U t = 2), and so on.</p><p>The transition matrix at each t for the cases repre- sented by P (X t = k|X t−1 = l), which is with size (t + 1) × (t + 2), will necessarily be very sparse. For example, given an empirical function f (n) = P (x = n|x ≥ n), the transition matrix from t = 4 to t = 5 can be written:</p><formula xml:id="formula_8">     f (1) 1 − f (1) 0 0 0 0 f (2) 0 1 − f (2) 0 0 0 f (3) 0 0 1 − f (3) 0 0 f (4) 0 0 0 1 − f (4) 0 f (5) 0 0 0 0 1 − f (5)     </formula><p>After this transformation, X t+1 is independent to all X k for any k &lt; t provided that X t is given. With X as the new hidden state, we can estimate the HMM parameter by adding some constraints. Replacing the Z in the object function with X, we can rewrite the object function as:</p><formula xml:id="formula_9">X P (Y, X|θ (n) ) log [P (Y, X|θ)] = X P (Y, X|θ (n) ) LogP (X 1 ) + N −1 t=1 log P (X t+1 |X t )+ N t=1 log P (Y t |X t ) = X P (Y, X|θ (n) ) log [π X1 ] + N −1 t=1 log A Xt,Xt+1 + N t=1 log [B Xt,Yt ]</formula><p>The object is split into three independent parts: the first part is for the initial state distribution π, the second for the transition probability matrix A, and the third is the emission matrix B. For the first term, because in the moment t = 1, X t can just be 1 or 2, we have the optimization problem:</p><formula xml:id="formula_10">Argmax π 2 i=1 P (Y, X 1 = i|θ (n) ) log [π i ] s.t π 1 + π 2 = 1 π 3 = π 4 = ... = π N +1 = 0</formula><p>We can easily solve this optimization problem by the Lagrange multiplier: we have the update formula:</p><formula xml:id="formula_11">π (n+1) 1 = P (X 1 = 1|Y, θ (n) ) π (n+1) 2 = P (X 1 = 2|Y, θ (n) ) π (n+1) i = 0 for i &gt; 2</formula><p>Both can be solved by the traditional forward-backward algorithm after this transformation. θ (n) is the parame- ter set we get from the last iteration. The second term can be ignored, since we use the known empirical distribution as the transition matrix; it is therefore a constant term.</p><p>The third term can be rewritten as:</p><formula xml:id="formula_12">N t=1 P (Y, X|θ (n) ) log [B Xt,Yt ] = N t=1 N +1 i=1 J j=1 1 k=0 I(Y t,j = k)P (X t = i, Y |θ (n) ) log [B j,i,k ]</formula><p>So our problem is:</p><formula xml:id="formula_13">Argmax B N t=1 J j=1 N +1 i=1 1 k=0 I(Y t,j = k) P (X t = i, Y |θ (n) ) log B j,i,k s.t 1 k=0 B j,i,k = 1 For all i, j B j,i1,k = B j,i2,k</formula><p>For all j, k and i 1 , i 2 ≥ 2</p><p>The second constraint here means that, if this is not a true boundary, a given annotator j will have the same emission matrix no matter what U is. This optimization can also be solved by Lagrange multiplier, where the update formula is as follows. For i = 1:</p><formula xml:id="formula_14">B (n+1) j,i=1,k = N t=1 P (Y, Z t = 1|θ (n) )I(Y t,j = k) N t=1 P (Y, Z t = 1|θ (n)</formula><p>) For any i = 1, the matrix B is the same given j:</p><formula xml:id="formula_15">B (n+1) j,i =1,k = N t=1 P (Y, Z t = 1|θ (n) )I(Y t,j = k) N t=1 P (Y, Z t = 1|θ (n) )</formula><p>Now we have the update function for θ. After con- vergence, we will have π and B. It is straightforward to transfer these parameters for the new space to our original HMM problem. This completes the M step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Model Checking</head><p>No ground truth labels are available to evaluate our models. We check the model results, however, in three ways. One, we consider labels proposed by both mod- els to be stronger evidence than labels proposed only by one. Two, we measure the consistency of annotators on the assumption that the same annotator should have relatively consistent performance across conversations, relative to the same model. The third way we can check the models is to examine the descriptive labels that an- notators assign to segments to determine whether de- scriptions for the same segment from different annota- tors are consistent. In this section, we describe the two consistency metrics.</p><p>We measure how consistently the label quality from annotator a i surpasses that for a j , i = j, for all pairs of annotators using a metric to measure inconsistency and strength of inconsistency (I&amp;SI) ( <ref type="bibr" target="#b7">de Vries, 1998</ref>). We also apply a variant we refer to as Directional Con- sistency (DC), which takes into account how often an- notator a i surpasses annotator a j . To measure anno- tators' performance relative to the inferred true labels, we use F-score, the harmonic mean of recall and preci- sion. Recall is the ratio of true positives to the sum of true positives and false negatives; precision is the ratio of true positives to the sum of true positives and false positives. A square matrix of annotator dominance is first constructed to give a count of how many conver- sations there are where a i has a higher F measure than a j , i = j. A linear dominance ordering &gt; of all anno- tators has an inconsistency score I that is incremented by 1 for each pair of annotators where a i &gt; a j in the linear ordering and (a i , a j ) = (a j , a i ) in the matrix. I is minimal if no other ordering has fewer inconsisten- cies. The strength of the inconsistency IS for a linear ordering is incremented by the difference in rank be- tween a i and a j for every inconsistent pair in the linear ordering. The I&amp;SI method finds an ordering that mini- mizes I and SI. To check the results of our models, we compare the I&amp;SI value of the dominance matrix asso- ciated with the model results against a simulated ran- dom matrix. If the model results are significantly more consistent than the simulation, the model produces a consistent ranking of annotators.</p><p>We propose a Directional Consistency index (DC ∈ [0, 1]) which considers the number of times a i has a higher F measure than a j ( <ref type="bibr" target="#b17">Leiva et al., 2008)</ref>. Where X is the dominance matrix:</p><formula xml:id="formula_16">DC = n i=1 n j=i+1 |x ij − x ji | N N = n i=1 n j=1,j =i x ij</formula><p>DC values closer to zero indicate less consistency in differences among annotators, and the converse for val- ues closer to 1. High DC values for the results of our models thus indicates better performance of the model in predicting consistent annotator behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Results and Model Checking</head><p>The results consist of the true labels assigned by each model to each conversation, and estimates of the anno- tators' performance relative to the model's ground truth labels. Note that as the conversation is not a parame- ter of either model, after estimation of the empirical distribution of segment lengths, the data for each con- versation is treated separately. To provide a concrete illustration, we first review the data for a typical conversation. <ref type="table">Table 1</ref> presents the segments derived from both models for an extract from conversation 945, which had six annotators, and the an- notator's segment descriptions. We selected a conver- sation with an even number of annotators to illustrate that an arbitrary choice must be made, given a 50/50 vote split. We take ties as true positives to provide a more conservative baseline. We first discuss this exam- ple conversation in detail to explain the kinds of cases where the models differ from majority voting. Then we present summary results on the fifty conversations for majority voting compared with the two models.</p><p>In <ref type="table">Table 1</ref> a description at n gives the annotator's in- terpretation of the kind of conversational activity that ends with n. When annotators agree on a positive la- bel that ends a segment, they might not agree on the utterance that starts the segment, so their descriptions will not necessarily be about the same segments. From Utt Description 191 C: S1 and S2 are talking about the status of their children's studies I: S1 and S2 are talking about their children's education 216 A: S1 and S2 spoke about their children's studies E: S2 then shared that he's going to Laguna- Muntinlupa tomorrow. S1 said that S2 has many orders. S2 shared that he's striving hard in order for her kids to graduate college. . . . The two laughed at each other about S1's children not getting traits from S1 I: S1 and S2 are talking about who their children took after 217 C: S1 and S2 are joking about the traits their children got from them D: They are talking about S1s daughter that she is good at academics and that she got her being smart from her mom and nothing from S1. S1 said even if she got nothing from him as long as she will just study hard its okay 241 A: S1 and S2 spoke about their time of sleeeping C: S1 and S2 tell each other what time they usually go to sleep D: They are talking about the time that they go to sleep. S2 said sometimes by ten, eleven or twelve midnight. S1 said sometimes he goes out one in the morning. Sometimes he goes to sleep at ten or eleven in the evening too <ref type="table">Table 1</ref>: Annotator descriptions for conversation 945 for a sequence of four segment boundaries hypothesized by both models. A description from annotator ai at utterance n indi- cates ai assigned a positive label, and gives the annotator's interpretation of the kind of interaction that ended at utter- ance n. Underlined utterance numbers indicate cases where at least six annotators assigned a positive label.</p><p>the table, however, we see a a pattern that is consistent for most of the data: abstracting over the descriptions gives a good indication of what's going on in the seg- ments that are defined by the positive labels assigned by both models. The descriptions from C and I at 191, for example, describe the first segment as the speak- ers talking about their children's education. A's similar description at 216 indicates that A ended the segment later than C and I. E and I describe the second segment as being about the children, including who they take after. C's description about who the children take after occurs at a later utterance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Utt Annotators DCD HMM ID HMM 11 2 (A,I) 1.00 0.99 42 3 (B,E,I) 1.00 1.00 43 3 (A,C,D) 1.00 1.00 67 6 (A,B,C,D,E,I) 1.00 1.00 114 2 (A,C) 1.00 0.98 126 2 (D,E) 1.00 1.00 127 1 (C)</head><p>0.63 0. <ref type="figure" target="#fig_0">02  144 2 (A,D)</ref> 1.00 0.98 147 2 (C,I) 0.90 0.65 191 2 (C,I) 0.90 0.73 216 3 (A,E,I)</p><p>1.00 1.00 217 2 (C,D)</p><p>1.00 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.66 241 3 (A,C,D) 1.00 1.00 276 3 (B,C,D)</head><p>1.00 1.00 282 1 (A)</p><p>1.00</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0.29">300 5 (A,B,D,E,I) 1.00 1.00 356 2 (C,I)</head><p>0.98 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.27 357 4 (A,B,D,E)</head><p>1.00 1.00 Because all the ID HMM labels are also identified by DCD HMM, these are the final labels we propose. <ref type="table" target="#tab_3">Table 3</ref> shows the positive labels predicted for con- versation 945 by majority vote, and by our two models. Column one is the utterance number, and again, under- lining indicates cases where the voted baseline would assign a positive label. Column two lists the annota- tors who assigned a positive label, and columns three and four show the posteriors assigned by the two mod- els; for all utterances not listed in the table, the posteri- ors are below 0.  For each model, the annotator can be ranked by the F-scores relative to the model predictions. When one of the models agrees with a minority of annotators, <ref type="table" target="#tab_2">Model   I&amp;SI  DC  Majority I=1, SI=3, p=0.008 p=0.0600  DCD HMM I=2, SI=5, p=0.02  p=0.0014  ID HMM I=0, SI=0, p=0</ref> p=0.0001 <ref type="table">Table 5</ref>: Consistency of annotators the minority consists of the annotators considered by the model to have higher performance, as given by F- measure. The three sets of F-scores for the six anno- tators in 945 are shown in <ref type="table" target="#tab_5">Table 4</ref>. Annotator perfor- mance given the two models is very similar; the Pear- son correlation is 0.80. F-scores based on the major- ity baseline, however, do not correlate well with DCD (ρ = −0.5) or ID (ρ = 0.49). In eight cases where DCD posits a true label for conversation 945, and only 2 annotators voted positive, the pair never includes B, the least accurate annotator by DCD (see <ref type="table" target="#tab_5">Table 4</ref>), and always includes one of the top three annotators (A,C,D). In the two cases where only one annotator voted positive, it was A or C, one of the two top DCD HMM annotators. Both models consider A to be the best annotator. C is relatively good in the DCD HMM model and relatively poor in the ID HMM model. I&amp;SI tests whether there exists a linear ordering of the annotators such that their relative performance across conversations is consistent. DC tests whether an ordering a i &gt; a j is based on relatively more frequent dominance of a i over a j . <ref type="table">Table 5</ref> shows that major- ity vote and the two models produce results that lead to high I&amp;SI consistency, based on the statistically sig- nificant p-values. The majority vote p-value for DC, however, is not statistically significant. By the more stringent DC measure, the labels from the two HMM variants are superior to the majority vote labels.</p><p>The list of descriptions from annotators at utterance n represents the semantics of the hypothesized segment ending at n. Semantic consistency for a given segment serves as another check on the output of the model, be- cause the human descriptions of the activity within the segment do not conflict. In general, this is the case for both models, but less so for DCD HMM. For conversa- tion 945 illustrated in <ref type="table" target="#tab_3">Table 3</ref>, there are three positive labels proposed by DCD HMM that are missing from the ID HMM predictions. These are at 127 where only annotator C had a positive label, 282 where only anno- tator A had a positive label, and 356 where annotators C and I had a positive label. Annotators B, C and D, for example, describe a segment ending at utterance 276 as the speakers discussing Facebook, whereas annotator A locates the end of the Facebook segment at utterance 282. The DCD HMM model posits a true label at 276 but not at 282, in contast to ID HMM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Discussion</head><p>The two models for estimating ground truth labels from crowd labels advance previous work on probabilistic models for annotation by handling sequential data. We have argued that for our data, the Markov assumption must be relaxed. The two models handle this in distinct ways. The first model assumes that each state can be decomposed into multiple aspects, and that states and observations are conditionally dependent on the previ- ous point in time. The second model builds in a pa- rameter for annotator performance, as in previous work that adopts the <ref type="bibr" target="#b6">Dawid and Skene (1979)</ref> model. Both assign more ground truth labels than majority voting, and avoid the problem with the majority vote method of ties where there are an even number of annotators. The results of the two models are very similar, but DCD HMM hypothesizes more boundaries, and there- fore ranks some annotators differently.</p><p>Here we check the models by comparing them to each other, through analysis of each annotator's con- sistency across multiple conversations, and through in- spection of the semantics of annotators' descriptions. Our future work will use the models generatively to predict a subset of the data for a given annotator, based on a model fit to all but the held out data. To do so, we would extend the models with an additional parameter for the conversation, to account for the observation that while all conversations seem to fit the same empirical distribution, there are differences across conversations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Annotation labels from eight annotators (A-G, I) on utterances 80 through 180 of a sample conversation. Vertical bars represent positive labels, with a different color for each annotator. Annotator H did not do this conversation.</figDesc><graphic url="image-1.png" coords="2,72.29,62.81,217.69,117.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The annotation interface presented the audio control button on the upper left and the transcript below, with a scroll bar (not shown). Utterances from the two speakers are on the right and left sides, respectively. Each utterance had a checkbox; when selected, a textbox appeared to allow annotators to enter their segment descriptions.</figDesc><graphic url="image-2.png" coords="3,117.36,62.81,362.83,82.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Graphical model of Double Chain Dynamic Hidden Markov Model for a conversation with m annotators and n utterances. The xt are the hidden states, and the y jl are the observed labels from annotator l at utterance j.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Histograms of interval lengths between all observed labels for two conversations.</figDesc><graphic url="image-4.png" coords="5,101.94,495.50,158.39,102.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: A plot of two CDF curves for a random split of the data. The curves are almost identical; the maximum gap is 0.0175. A two sample K-S test has a p-value of 0.79.</figDesc><graphic url="image-5.png" coords="5,326.41,62.81,179.99,138.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Total positive labels assigned by each method.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparison of positive predictions from majority 

voting (N=8, underlined; ties are taken as positive), DDC 
HMM (N=18), and the ID HMM (N=15) for conversation 
945. Probabilities in bold are for boundaries proposed by 
only one model; italics are for probabilities below the 0.5 
threshold to be considered true boundaries. 

method are in Table 2. Wherever the majority vote 
predicts a true label, both models always do. If ID 
HMM posits a boundary at an utterance, DCD HMM 
also does, but DCD HMM predicts additional ones. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>5. Low posteriors for ID HMM where DCD HMM proposed a boundary are in italics.</figDesc><table>Ann Maj DCD HMM ID HMM 
A 
0.68 
0.71 
0.68 
B 
0.57 
0.36 
0.38 
C 
0.40 
0.63 
0.46 
D 
0.59 
0.56 
0.55 
E 
0.73 
0.50 
0.52 
I 
0.43 
0.55 
0.49 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>F-measure for annotators in conversation 945 for 

majority vote labels and both models; recall that the true la-
bels for each model are different, and that DCD HMM hy-
pothesizes more true labels than ID HMM. 

</table></figure>

			<note place="foot" n="1"> Twenty labels per item were collected in order to provide tight estimates for item difficulty. This, however, requires a model with a parameter for item difficulty, which had not yet been implemented for this data.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>Annotation and machine learning of discourse segmen-tation covers several types of units, including topical segments ( <ref type="bibr" target="#b12">Galley et al., 2003)</ref>, meeting units in which action items are identified or decisions made <ref type="bibr" target="#b27">(Purver et al., 2007;</ref><ref type="bibr" target="#b10">Fernández et al., 2008)</ref>, transaction subtasks for ordering library books ( ), or speaker involvement ( <ref type="bibr" target="#b2">Bokaei et al., 2015)</ref>. This work relies on manual transcription, and draws on many sources of knowledge for machine learned models, in-cluding turn-taking, prosody, and linguistic features. The segmentation annotation can be linear ( <ref type="bibr" target="#b12">Galley et al., 2003;</ref><ref type="bibr" target="#b2">Bokaei et al., 2015;</ref><ref type="bibr" target="#b23">Passonneau and Litman, 1997;</ref>) or hierarchical ( <ref type="bibr" target="#b27">Purver et al., 2007;</ref><ref type="bibr" target="#b10">Fernández et al., 2008;</ref><ref type="bibr" target="#b25">Passonneau et al., 2011</ref>). The differences in methods and results across this body of work, points to a need for more datasets for research on the organization of discourse into ac-tivity units. The results presented here support this re-search agenda by providing a reliable and cost-effective method to estimate ground truth discourse segment la-bels from crowd labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Bob Carpenter for discussions dur-ing the early stages of the data analysis, and for helpful feedback on the paper. We thank the IARPA Babel pro-gram manager, Mary Harper, for giving us permission to annotate the Babel data.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On estimating diagnostic accuracy from studies with multiple raters and partial gold standard evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lori</forename><forename type="middle">E</forename><surname>Dodd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">481</biblScope>
			<biblScope unit="page" from="61" to="73" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Double Chain Markov Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><surname>Berchtold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics: Theory and Methods</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">348</biblScope>
			<biblScope unit="page" from="2569" to="2589" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Linear discourse segmentation of multiparty meetings based on local and global information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Hadi Bokaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Sameti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1879" to="1891" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Extending answers using discourse structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wauter</forename><surname>Bosma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RANLP Workshop on Crossing Barriers in Text Summarization Research</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Whence lumpers and splitters?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glenn</forename><surname>Branch</surname></persName>
		</author>
		<ptr target="http://ncse.com/blog/2014/11/whence-lumpers-splitters-0016004" />
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recognizing subjectivity: a case study of manual tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">F</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><forename type="middle">M</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximum likelihood estimation of observer error-rates using the EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dawid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Skene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series C (Applied Statistics)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="28" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Finding a dominance order most consistent with a linear hierarchy: a new procedure and review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vries</forename><surname>Han De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Animal Behavior</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="827" to="843" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multistream dynamic Bayesian network for meeting segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Dielmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Renals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Multimodal Interaction</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="76" to="86" />
		</imprint>
	</monogr>
	<note>Samy Bengio and Herv Bourlard</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">To annotate more accurately or to annotate more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodney</forename><forename type="middle">D</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Linguistic Annotation Workshop (LAW IV)</title>
		<meeting>the Fourth Linguistic Annotation Workshop (LAW IV)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="64" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modelling and detecting decisions in multi-party dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Frampton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ehlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Purver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue</title>
		<meeting>the 9th SIGdial Workshop on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Annotating named entities in twitter data with crowdsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Murnane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Karandikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Martineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&apos;s Mechanical Turk, CSLDAMT &apos;10</title>
		<meeting>the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&apos;s Mechanical Turk, CSLDAMT &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="80" to="88" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Discourse segmentation of multi-party conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Foslerlussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003-07" />
			<biblScope unit="page" from="562" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Agreement detection in multiparty conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Germesin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 International Conference on Multimodal Interfaces, ICMI-MLMI &apos;09</title>
		<meeting>the 2009 International Conference on Multimodal Interfaces, ICMI-MLMI &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="7" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Detection of agreement vs. disagreement in meetings: Training with unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Hillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Shriberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: Companion Volume of the Proceedings of HLTNAACL 2003-short Papers</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: Companion Volume of the HLTNAACL 2003-short Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="34" to="36" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning whom to trust with MACE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="1120" to="1130" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Content analysis: An introduction to its methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Krippendorff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Sage Publications</publisher>
			<pubPlace>Beverly Hills, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Testing reciprocity in social interactions: A comparison between the directional consistency and skew-symmetry statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Leiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Solanas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluis</forename><surname>Salafranca</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="626" to="634" />
		</imprint>
	</monogr>
<note type="report_type">Behavior Research Methods</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning dynamic Naive Bayesian classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Enrique</forename><surname>Sucar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-First International FLAIRS Conference</title>
		<meeting>the Twenty-First International FLAIRS Conference</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="655" to="659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bayes Net toolbox for Matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing Science and Statistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1024" to="1034" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Participant subjectivity and involvement as a basis for discourse segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Niekrasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johanna</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL</title>
		<meeting>the SIGDIAL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Conference</surname></persName>
		</author>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="54" to="61" />
			<pubPlace>London, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The benefits of a model of annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">311326</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Discourse segmentation by human and automated means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="103" to="139" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Special Issue on Empirical Studies in Discourse Interpretation and Generation</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PARADISE-style evaluation of a human-human library corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Alvarado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Crone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Jerome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2011 Conference</title>
		<meeting>the SIGDIAL 2011 Conference<address><addrLine>Portland, Oregon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="325" to="331" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Aspectual properties of conversational activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxuan</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho</forename><surname>Ho Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Conner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</title>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)<address><addrLine>Philadelphia, PA, U.S.A.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="228" to="237" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Detecting and summarizing action items in multi-party dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Purver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Dowding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Niekrasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ehlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharareh</forename><surname>Noorbaloochi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue</title>
		<meeting>the 8th SIGdial Workshop on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning from crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vikas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shipeng</forename><surname>Raykar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><forename type="middle">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerardo</forename><forename type="middle">Hermosillo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Valadez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Florin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><surname>Bogoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1297" to="1322" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semi-parametric analysis of multi-rater data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Girolami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Polajnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Computing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="317" to="334" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">How to get the most out of your curation effort</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Rzhetsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hagit</forename><surname>Shatkay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. John</forename><surname>Wilbur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Get another label? Improving data quality and data mining using multiple, noisy labelers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Foster</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panagiotis</forename><forename type="middle">G</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth ACM International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the Fourteenth ACM International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Inferring ground truth from subjectively-labeled images of Venus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padhraic</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Usama</forename><surname>Fayyad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Burl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1085" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cheap and fast-but is it good? Evaluating non-expert annotations for natural language tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Honolulu</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="254" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Detecting arguing and sentiment in meetings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swapna</forename><surname>Somasundaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue</title>
		<meeting>the 8th SIGdial Workshop on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">2634</biblScope>
		</imprint>
	</monogr>
	<note>SIGdial 07</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Discourse processing for context question answering based on linguistic knowledge. Know.-Based Syst</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007-08" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="511" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Focused meeting summarization via unsupervised relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, SIGDIAL &apos;12</title>
		<meeting>the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, SIGDIAL &apos;12<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="304" to="313" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A prosody-based vectorspace model of dialog activity for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><forename type="middle">G</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">D</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilio</forename><surname>Sanchis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="85" to="96" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Whose vote should count more: Optimal integration of labels from labelers of unknown expertise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Whitehill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Ruvolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingfan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Movellan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual Conference on Advances in Neural Information Processing Systems</title>
		<meeting>the 24th Annual Conference on Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
