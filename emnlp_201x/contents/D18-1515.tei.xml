<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A strong baseline for question relevancy ranking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><forename type="middle">V</forename><surname>González-Garduño</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dpt. of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gardu˜</forename><surname>Garduño</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dpt. of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dpt. of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dpt. of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A strong baseline for question relevancy ranking</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="4810" to="4815"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The best systems at the SemEval-16 and SemEval-17 community question answering shared tasks-a task that amounts to question relevancy ranking-involve complex pipelines and manual feature engineering. Despite this, many of these still fail at beating the IR base-line, i.e., the rankings provided by Google&apos;s search engine. We present a strong baseline for question relevancy ranking by training a simple multi-task feed forward network on a bag of 14 distance measures for the input question pair. This baseline model, which is fast to train and uses only language-independent features, outperforms the best shared task systems on the task of retrieving relevant previously asked questions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Community question-answer fora are great re- sources, collecting answers to frequently and less- frequently asked questions on specific topics, but these are often not moderated and contain many irrelevant answers. Community Question Answer- ing (CQA), cast as a question relevancy ranking problem, was the topic of two shared tasks at Se- mEval 2016-17. This is a non-trivial retrieval task, typically evaluated using mean average precision (MAP). We present a strong baseline for this task, on par with or surpassing state-of-the-art systems.</p><p>The English subtasks of the SemEval CQA ( <ref type="bibr" target="#b9">Nakov et al., 2015</ref><ref type="bibr" target="#b8">Nakov et al., , 2017</ref>) consist of Question- Question Similarity, Question-Comment Similar- ity, and Question-External Comment Similarity. In this study, we focus on the core subtask of Question-Question similarity, defined as follows: Given a question, rank other relevant questions by their relevancy to that question. This proved to be a difficult task in both <ref type="bibr">SemEval-16 and SemEval17</ref> as it is the one with the least amount of data available. The baseline was the ranking retrieved by performing a Google search, which proved to be a strong baseline beating a large portion of the systems submitted.</p><p>Contribution Our baseline is a simple multi- task feed-forward neural network taking distance measures between pairs of questions as input. We use a question-answer dataset as auxiliary task; but we also experiment with datasets for pairwise clas- sification tasks such as natural language inference and fake news detection. This simple, easy-to- train model is on par or better than state-of-the- art systems for question relevancy ranking. We also show that this simple model outperforms a more complex model based on recurrent neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Model</head><p>We present a simple baseline model for question relevancy ranking. 1 It is a deep feed-forward net- work with a hidden layer that is shared with an auxiliary task model. The input to the network is extremely simple and consists of five distance measures of the input question-question pair. §2.1 discusses these distance measures, and how they relate. §2.2 introduces the multi-task learning ar- chitecture that we propose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Features</head><p>We use four similarity metrics and three sentence representations (averaged word embeddings, bi- nary unigram vectors, and trigram vectors). The cosine distance between the sentence representa- tions of query x and query y is</p><formula xml:id="formula_0">i x i y i i x 2 + i y 2</formula><p>The Manhattan distance is</p><formula xml:id="formula_1">i |x i − y i | The Bhattacharya distance is − ln( i √ x i y i )</formula><p>and is a measure of divergence, and the Euclidean distance is</p><formula xml:id="formula_2">i (x i − y i ) 2</formula><p>Note that the squared Euclidean distance is pro- portional to cosine distance and Manhattan dis- tance. The Bhattacharya and Jaccard metrics, on the other hand, are sensitive to the number of types in the input (the 1 norm of the vector encodings). So, for example, only the cosine, Euclidean, and Manhattan distances will be the same for The Jaccard index is the only metric that can only be applied to two of our representations, unigrams and n-grams: It is defined over m- dimensional binary (indicator) vectors and there- fore not applicable to averaged embeddings. It is defined as x · y m</p><p>We represent each query pair by these 14 numeri- cal features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MTL Architecture</head><p>Our architecture is a simple feed-forward, multi- task learning (MTL) architecture. Our architec- ture is presented in <ref type="figure" target="#fig_1">Figure 1</ref> and is a Multi-Layer Perceptron (MLP) that takes a pair of sequences as input. The sequences can be sampled from the main task or the auxiliary task. The MLP has one shared hidden layer, a task-specific hidden layer and, finally, a task-specific classification layer for each output. The hyper-parameters, after doing grid search, optimizing performance on the vali- dation data, are given in <ref type="figure">Figure 2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">LSTM baseline</head><p>We compare our MLP ranker to a bidirec- tional LSTM (Hochreiter and Schmidhuber, 1997) model. It takes two sequences inputs: sequence 1 and sequence 2, and a stack of three bidirec- tional LSTM layers, which encode sequence 1 and sequence 2, respectively. The outputs are then concatenated, to enable representing the differ- ences between the two sequences. Instead of re- lying only on this presentation ( <ref type="bibr" target="#b4">Bowman et al., 2015;</ref><ref type="bibr" target="#b0">Augenstein et al., 2016)</ref>, we also concate- nate our distance features and feed everything into our MLP ranker described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Datasets</head><p>For our experiments, we use data from SemEval shared tasks, but we also take advantage of poten- tial synergies with other existing datasets for clas- sification of sentence pairs. Below we present the datasets used for our main and auxiliary tasks. We provide some summary statistics for each dataset in <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SemEval 2016 and 2017</head><p>As our main dataset we use the queries from SemEval's subtask B which consists of an original query and 10 pos- sibly related queries. As an auxiliary task, we use the data from subtask A, which is a question- related comment ranking task.</p><p>Hyperparameter Best <ref type="table" target="#tab_1">Value  Tested Values  Num. of Epochs  100  10, 20, 40, 60, 80, 100  Batch Size  100</ref> 10, 50, 100 Learning rate 0.001 0.001, 0.01, 0.1, 0.2, 0.3 Momentum 0.9 0.0, 0.2, 0.4, 0.6, 0.8, 0.9 Dropout 0.02 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9  Our model is not built to be a strong NLI system; we use the similarity between premise and hypothesis as a weak signal to im- prove the generalization on our main task.</p><p>Fake News Challenge The Fake News Chal- lenge 2 (FNC) was introduced to combat mislead- ing and false information online. This task has been used before in a multi-task setting as a way to utilize general information about pairwise rela- tions ( <ref type="bibr" target="#b1">Augenstein et al., 2018)</ref>. Formally, the FNC task consists in, given a headline and the body of 2 http://www.fakenewschallenge.org/ text which can be from the same news article or not, classify the stance of the body of text relative to what is claimed in the headline. There are four labels:</p><p>• We include fake news detection as a weak aux- iliary signal that can lead to better generalization of our question-question ranking model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation</head><p>We evaluate our performance on the main task of question relevancy ranking using the official</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Train <ref type="table" target="#tab_1">Dev Test   SemEval 16 2000 500 700  SemEval 17  - - 880  FNC  49k  - - MNLI  433k</ref> - - <ref type="figure">Figure 3</ref>: Size of datasets used for the experiments.</p><p>Here we present the full size of FNC and MultiNLI training sets, however for our MTL experiments we used a random sample of the same size of the train, test and dev sets of the SemEval data as auxiliary data. The SemEval 17 shared task uses the same train and dev set as SemEval 16</p><p>SemEval-2017 Task 3 evaluation scripts ( <ref type="bibr" target="#b8">Nakov et al., 2017)</ref>. The scripts provide a variety of metrics; however, in accordance with the shared task, we report Mean Average Precision (MAP) (the official metric for the SemEval 2016 and 2017 shared tasks); Mean Reciprocal Rank (MRR), which has being thoroughly used for IR and QA; Average Recall; and, finally, the accuracy of pre- dicting relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>The results from our experiments are shown in Ta- ble 1. We present the official metric from the Se- mEval task, as well as other common metrics. For the SemEval-16 data, our multitask MLP archi- tecture with a question-answer auxiliary task per- formed best on all metrics, except accuracy, where the multi-task MLP using all auxiliary tasks per- formed best. We outperform the winning systems of both the SemEval 2016 and 2017 campaigns. In addition, our improvements from single-task to multi-task are significant (p &lt; 0.01). We also out- perform the official IR baseline used in the Se- mEval 2016 and 2017 shared tasks. We discuss the STL-LSTM-SIM results in §5. Furthermore, in <ref type="table" target="#tab_3">Table 2</ref>, we show the performance of our mod- els when training on feature combinations, while in <ref type="table">Table 3</ref>, we present an ablation test where we remove one feature at a time.</p><p>Learning curve In <ref type="figure" target="#fig_3">Figure 4</ref>, we also present our learning curves for the development set when in- crementally increasing the training set size. We observe that when using an auxiliary task, the learning is more stable across training set size.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>For the SemEval shared tasks on CQA, several authors used complex recurrent and convolutional neural network architectures <ref type="bibr" target="#b11">(Severyn and Moschitti, 2015;</ref><ref type="bibr" target="#b3">Barrón-Cedeno et al., 2016</ref>). For ex- ample, Barrón-Cedeno et al. used a convolutional neural network in combination with feature vec- tors representing lexical, syntactic, and semantic similarity as well as tree kernels. Their perfor- mance was slightly lower than the best system (SemEval-Best for 2016 in <ref type="table" target="#tab_1">Table 1</ref>). The best system used lexical and semantic similarity mea- sures in combination with a ranking model based on support vector machines (SVMs) ( <ref type="bibr" target="#b5">Filice et al., 2016;</ref><ref type="bibr" target="#b6">Franco-Salvador et al., 2016</ref>  <ref type="table">Table 3</ref>: We perform an ablation test, where we remove one feature at a time and report performance on devel- opment data of our single-task baseline. We observe that our baseline suffers most from removing the Eu- clidean distance over trigrams and the cosine similarity over unigrams. Note also that the Jaccard index over unigrams seems to carry a strong signal, albeit a very simple feature.</p><p>distributed representations of words, knowledge graphs and frames from FrameNet ( <ref type="bibr" target="#b2">Baker et al., 1998</ref>) as some of their features, and used SVMs for ranking. For a more direct comparison, we also train a more expressive model than the simple MTL- based model we propose. This architecture is based on bi-directional LSTMs <ref type="bibr" target="#b7">(Hochreiter and Schmidhuber, 1997</ref>). For this model, we input sequences of embedded words (using pre-trained word embeddings) from each query into indepen- dent BiLSTM blocks and output a vector repre- sentation for each query. We then concatenate the vector representations with the similarity fea- tures from our MTL model and feed it into a dense layer and a classification layer. This way we can evaluate the usefulness of the flexible, expressive LSTM network directly (as our MTL model be- comes an ablation instance of the full, more com- plex architecture). We use the same dropout regu- larization and SGD values as for the MLP. Tuning all parameters on the development data, we do not manage to outperform our proposed model, how- ever. See lines MTL-LSTM-SIM in <ref type="table" target="#tab_1">Table 1</ref> for results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We show that simple feature engineering, com- bined with an auxiliary task and a simple feedfor- ward neural architecture is appropriate for a small dataset and manages to beat the baseline and the best performing systems for the Semeval task of question relevancy ranking. We observe that in- troducing pairwise classification tasks leads to sig- nificant improvements in performance and a more stable model. Overall, our simple model intro- duces a new strong baseline which is particularly useful when there is a lack of labeled data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The architecture of the multi task learning MLP</figDesc><graphic url="image-1.png" coords="2,307.28,62.81,198.43,240.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>AGREES: The body of the article is in agree- ment with the headline • DISAGREES: The body of the article is in dis- agreement with the headline • DISCUSSES: The body of the article does not take a position • UNRELATED: the body of the article dis- cusses a different topic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Learning curves for single-and multi-task learning. All MTL models outperform the STL model with very few training samples, and learning curves are more stable for MTL models than for STL.</figDesc><graphic url="image-2.png" coords="4,307.28,62.81,240.94,198.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>The results show that learning pairwise classification tasks simultaneously with the main task leads 
to improvements over the baselines and the best SemEval systems. We show results for three auxiliary tasks, 
Question-Comment relevancy prediction, Fake News detection and Natural Language Inference. The asterisks 
for the MTL results represent the significance of the improvements over the STL systems with ** representing a 
p-value of &lt; 0.01 and * representing a p-value between 0.01 and 0.05 

Natural Language Inference Natural Lan-
guage Inference (NLI), consists in predicting EN-
TAILMENT, CONTRADICTION or NEUTRAL, given 
a hypothesis and a premise. We use the MNLI 
dataset as opposed to the SNLI data (Bowman 
et al., 2015; Nangia et al., 2017), since it contains 
different genres. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance on development set of SemEval-
16 when training only on certain feature combinations. 
MTL uses QA as auxiliary data. 

</table></figure>

			<note place="foot" n="1"> Code available at http://anavaleriagonzalez/FAQ rank.</note>

			<note place="foot" n="3"> http://www.botxo.co/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The first author of this paper is funded by a BotXO PhD Award; 3 the last author by an ERC Starting Grant. We gratefully acknowledge the support of the NVIDIA Corporation with the donation of the Titan Xp GPU used for this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stance Detection with Bidirectional Conditional Encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="876" to="885" />
		</imprint>
	</monogr>
	<note>EMNLP</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multi-task learning of pairwise sequence classification tasks over disparate label spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Berkeley Framenet project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Collin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John B</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th international conference on Computational linguistics</title>
		<meeting>the 17th international conference on Computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="86" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ConvKN at SemEval-2016 task 3: Answer and question selection for question answering on Arabic and English fora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barrón-Cedeno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Alobaidli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Romeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="896" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.05326</idno>
		<title level="m">A large annotated corpus for learning natural language inference</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">KELP at SemEval2016 task 3: Learning semantic relations between questions and answers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Filice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1116" to="1123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Uh-prhlt at semeval-2016 task 3: Combining lexical and semantic-based features for community question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudipta</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thamar</forename><surname>Solorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval</title>
		<meeting>SemEval</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="814" to="821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semeval-2017 task 3: Community question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doris</forename><surname>Hoogeveen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamdy</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Verspoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</title>
		<meeting>the 11th International Workshop on Semantic Evaluation (SemEval-2017)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="27" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 3: Answer selection in community question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walid</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Randeree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="269" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.08172</idno>
		<title level="m">The repeval 2017 shared task: Multi-genre natural language inference with sentence representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning to rank short text pairs with convolutional deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
