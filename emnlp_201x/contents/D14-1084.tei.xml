<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:27+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Chinese Zero Pronoun Resolution: An Unsupervised Probabilistic Model Rivaling Supervised Resolvers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Human Language Technology Research Institute University of Texas at Dallas Richardson</orgName>
								<address>
									<postCode>75083-0688</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Human Language Technology Research Institute University of Texas at Dallas Richardson</orgName>
								<address>
									<postCode>75083-0688</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Chinese Zero Pronoun Resolution: An Unsupervised Probabilistic Model Rivaling Supervised Resolvers</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="763" to="774"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>State-of-the-art Chinese zero pronoun resolution systems are supervised, thus relying on training data containing manually resolved zero pronouns. To eliminate the reliance on annotated data, we present a generative model for unsuper-vised Chinese zero pronoun resolution. At the core of our model is a novel hypothesis: a probabilistic pronoun resolver trained on overt pronouns in an unsuper-vised manner can be used to resolve zero pronouns. Experiments demonstrate that our unsupervised model rivals its state-of-the-art supervised counterparts in performance when resolving the Chinese zero pronouns in the OntoNotes corpus.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A zero pronoun (ZP) is a gap in a sentence that is found when a phonetically null form is used to refer to a real-world entity. An anaphoric zero pronoun (AZP) is a ZP that corefers with one or more preceding noun phrases (NPs) in the asso- ciated text. Below is an example taken from the Chinese TreeBank (CTB), where the ZP (denoted as *pro*) refers to 俄罗斯 (Russia).</p><p>[俄罗斯] 作为米洛舍夫维奇一贯的支持者， *pro* 曾经提出调停这场政治危机。 ( <ref type="bibr">[Russia]</ref> is a consistent supporter of Milošević, *pro* has proposed to mediate the political crisis.)</p><p>As we can see, ZPs lack grammatical attributes that are useful for overt pronoun resolution such as number and gender. This makes ZP resolution more challenging than overt pronoun resolution.</p><p>Automatic ZP resolution is typically composed of two steps. The first step, AZP identification, in- volves extracting ZPs that are anaphoric. The sec- ond step, AZP resolution, aims to identify an an- tecedent of an AZP. State-of-the-art ZP resolvers have tackled both of these steps in a supervised manner, training a classifier for AZP identification and another one for AZP resolution (e.g., <ref type="bibr" target="#b26">Zhao and Ng (2007)</ref>, <ref type="bibr" target="#b2">Chen and Ng (2013)</ref>).</p><p>In this paper, we focus on the second task, AZP resolution, designing a model that assumes as in- put the AZPs in a document and resolves each of them. Note that the task of AZP resolution alone is by no means easy: even when gold-standard AZPs are given, state-of-the-art supervised resolvers can only achieve an F-score of 47.7% for resolving Chinese AZPs <ref type="bibr" target="#b2">(Chen and Ng, 2013)</ref>. For the sake of completeness, we will evaluate our AZP resolu- tion model using both gold-standard AZPs as well as AZPs automatically identified by a rule-based approach that we propose in this paper.</p><p>Our contribution lies in the proposal of the first unsupervised probabilistic model for AZP resolu- tion that rivals its supervised counterparts in per- formance when evaluated on the Chinese portion of the OntoNotes 5.0 corpus. Its main advan- tage is that it does not require training data with manually resolved AZPs. This, together with the fact that its underlying generative process is not language-dependent, enables it to be applied to languages where such annotated data is not read- ily available. At its core is a novel hypothesis: we can apply a probabilistic pronoun resolution model trained on overt pronouns in an unsuper- vised manner to resolve zero pronouns. Moti- vated by <ref type="bibr" target="#b4">Cherry and Bergsma's (2005)</ref> and <ref type="bibr" target="#b1">Charniak and Elsner's (2009)</ref> work on unsupervised English pronoun resolution, we train our unsu- pervised resolver on Chinese overt pronouns us- ing the Expectation-Maximization (EM) algorithm <ref type="bibr" target="#b6">(Dempster et al., 1977</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Chinese ZP resolution. Early approaches to Chinese ZP resolution are rule-based. <ref type="bibr" target="#b5">Converse (2006)</ref> applied <ref type="bibr">Hobbs' algorithm (Hobbs, 1978)</ref> to resolve the ZPs in the CTB documents. <ref type="bibr" target="#b25">Yeh and Chen (2007)</ref> hand-engineered a set of rules for ZP resolution based on Centering The- ory ( <ref type="bibr" target="#b8">Grosz et al., 1995)</ref>.</p><p>In contrast, virtually all recent approaches to this task are based on supervised learning. <ref type="bibr" target="#b26">Zhao and Ng (2007)</ref> are the first to employ a supervised learning approach to Chinese ZP resolution. They trained an AZP resolver by employing syntactic and positional features in combination with a de- cision tree learner. Unlike Zhao and Ng, <ref type="bibr" target="#b18">Kong and Zhou (2010)</ref> employed context-sensitive con- volution tree kernels ( <ref type="bibr" target="#b28">Zhou et al., 2008)</ref> in their resolver to model syntactic information. More re- cently, we extended Zhao and Ng's feature set with novel features that encode the context surrounding a ZP and its candidate antecedents, and exploited the coreference links between ZPs as bridges to find textually distant antecedents for ZPs <ref type="bibr" target="#b2">(Chen and Ng, 2013)</ref>.</p><p>ZP resolution for other languages. There have been rule-based and supervised machine learning approaches for resolving ZPs in other languages. For example, to resolve ZPs in Spanish texts, <ref type="bibr" target="#b7">Ferrández and Peral (2000)</ref> proposed a set of hand- crafted rules that encode preferences for candidate antecedents. In addition, supervised approaches have been extensively employed to resolve ZPs in Korean (e.g., <ref type="bibr" target="#b9">Han (2006)</ref>), Japanese (e.g., <ref type="bibr" target="#b23">Seki et al. (2002)</ref>, <ref type="bibr" target="#b16">Isozaki and Hirao (2003)</ref>, <ref type="bibr" target="#b12">Iida et al. (2006;</ref>, <ref type="bibr" target="#b14">Imamura et al. (2009)</ref>, <ref type="bibr" target="#b11">Iida and Poesio (2011)</ref>, <ref type="bibr" target="#b22">Sasano and Kurohashi (2011)</ref>), and Italian (e.g., <ref type="bibr" target="#b11">Iida and Poesio (2011)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Chinese Overt Pronouns</head><p>Since our approach relies heavily on Chinese overt pronouns, in this section we introduce them by describing their four grammatical attributes, namely Number, Gender, Person and Ani- macy. Number has two values, singular and plural. Gender has three values, neuter, mascu- line and feminine. Person has three values, first, second and third. Finally, Animacy has two val- ues, animate and inanimate.</p><p>We exploit ten personal pronouns that have well-defined grammatical attribute values, namely 你 (singular you), 我 (I), 他 (he), 她 (she), 它 (it), 你 们 (plural you), 我 们 (we), 他 们 (masculine they), 她们 (feminine they), and 它们 (impersonal they). As can be seen in <ref type="table">Table 1</ref>, each of them can be uniquely identified using these four attributes.   <ref type="table">Table 1</ref>: Attribute values of Chinese overt pronouns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Generative Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Notation</head><p>Let p be an overt pronoun in P R, the set of the 10 overt pronouns described in Section 3. C, the set of candidate antecedents of p, contains all and only those maximal or modifier NPs that precede p in the associated text and are at most two sen- tences away from it. 1 k is the context surround- ing p as well as every candidate antecedent c in C; k c is the context surrounding p and candidate antecedent c; and l is a binary variable indicat- ing whether c is the correct antecedent of p. The set A = {N um, Gen, P er, Ani} has four ele- ments, which correspond to Number, Gender, Person and Animacy respectively. a is an at- tribute in A. Finally, p a and c a are the attribute values of p and c with respect to a respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training</head><p>Our model estimates P (p, k, c, l), the probability of seeing (1) the overt pronoun p; (2) the context k surrounding p and its candidate antecedents; (3) a candidate antecedent c of p; and (4) whether c is the correct antecedent of p. Since we estimate this probability from a raw, unannotated corpus, we are effectively treating p, k, and c as observed data and l as hidden data.</p><p>Owing to the presence of hidden data, we es- timate the model parameters using the EM algo- rithm. Specifically, we use EM to iteratively es- timate the model parameters from data in which each overt pronoun is labeled with the probability it corefers with each of its candidate antecedents and apply the resulting model to re-label each overt pronoun with the probability it corefers with each of its candidate antecedents. Below we describe the details of the E-step and the M-step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">E-Step</head><p>The goal of the E-step is to compute P (l=1|p, k, c), the probability that a candi- date antecedent c is the correct antecedent of p given context k. Assuming that exactly one of the p's candidate antecedents is its correct antecedent, we can rewrite P (l=1|p, k, c) as follows:</p><formula xml:id="formula_0">P (l=1|p, k, c) = P (p, k, c, l=1) ∑ c ′ ∈C P (p, k, c ′ , l=1)<label>(1)</label></formula><p>Applying Chain Rule, we can rewrite P (p, k, c, l=1) as follows:</p><formula xml:id="formula_1">P (p, k, c, l=1) = P (p|k, c, l=1) * P (l=1|k, c) * P (c|k) * P (k)</formula><p>(2) Next, given l = 1 (i.e., c is the antecedent of p), we assume that we can generate p from c without looking at the context. <ref type="bibr">2</ref> Then we represent p using its grammatical attributes A. We further assume that p's value with respect to attribute a ∈ A is independent of the value of each of its remaining attributes given the antecedent's value with respect to a. So we can rewrite P (p|k, c, l=1) as follows:</p><formula xml:id="formula_2">P (p|k, c, l=1) ≈ P (p|c, l=1) ≈ P (p N um , p Gen , p P er , p Ani |c, l=1) ≈ ∏ a∈A P (p a |c a , l=1)<label>(3)</label></formula><p>Moreover, we assume that (1) given p and c's context, the probability of c being the antecedent of p is not affected by the context of the other can- didate antecedents; and (2) k c is sufficient for de- termining whether c is the antecedent of p. So,</p><formula xml:id="formula_3">P (l=1|k, c) ≈ P (l=1|k c , c) ≈ P (l=1|k c ) (4)</formula><p>Furthermore, we assume that given context k, each candidate antecedent of p is generated with equal probability. In other words,</p><formula xml:id="formula_4">P (c|k) ≈ P (c ′ |k) ∀ c, c ′ ∈ C<label>(5)</label></formula><p>Given Equations (2), (3), (4) and (5), we can rewrite P (l=1|p, k, c) as:</p><formula xml:id="formula_5">P (l=1|p, k, c) = P (p, k, c, l=1) ∑ c ′ ∈C P (p, k, c ′ , l=1) ≈ ∏ a∈A P (p a |c a , l=1) * P (l=1|k c ) ∑ c ′ ∈C ∏ a∈A P (p a |c ′ a , l=1) * P (l=1|k c ′ )<label>(6)</label></formula><p>As we can see from Equation (6), our model has two groups of parameters, namely P (p a |c a , l=1) and P (l=1|k c ). Since we have four grammatical attributes, P (p a |c a , l=1) contains four sets of pa- rameters, with one set per attribute. Using Equa- tion (6) and the current parameter estimates, we can compute P (l=1|p, k, c).</p><p>Two points deserve mention before we describe the M-step. First, we estimate P (l=1|p, k, c) from all and only those overt pronouns p ∈ P R that are surface or deep subjects in their correspond- ing sentences. This condition is motivated by our observation that 99.56% of the ZPs in our evalu- ation corpus (i.e., OntoNotes 5.0) are surface or deep subjects. In other words, we impose this con- dition so that we can focus our efforts on learn- ing a model for resolving overt pronouns that are subjects. This is by no means a limitation of our model: if we were given a corpus in which many ZPs occur as grammatical objects, we could sim- ilarly train another model on overt objects. Sec- ond, since in the E-step we attempt to probabilisti- cally label every overt pronoun p that satisfies the condition above, our model is effectively making the simplifying assumption that every overt pro- noun is anaphoric. This is clearly an overly sim- plistic assumption. One way to relax this assump- tion, which we leave as future work, is to first iden- tify those pronouns that are anaphoric and then use EM to estimate the joint probability only from the anaphoric pronouns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">M-Step</head><p>Given P (l=1|p, k, c), the goal of the M-step is to (re)estimate the model parameters, P (p a |c a , l=1) and P (l=1|k c ), using maximum likelihood esti- mation. Specifically, P (p a |c a , l=1) is estimated as follows:</p><formula xml:id="formula_6">P (p a |c a , l=1) = Count(p a , c a , l=1) + θ Count(c a , l=1) + θ * |a| (7)</formula><p>where Count(c a , l=1) is the expected number of times c has attribute value c a when it is the an- tecedent of p; |a| is the number of possible values of attribute a; θ is the Laplace smoothing param- eter, which we set to 1; and Count(p a , c a , l=1) is the expected number of times p has attribute value p a when its antecedent c has attribute value c a . Given attribute values p ′ a and c ′ a , we compute</p><formula xml:id="formula_7">Count(p ′ a , c ′ a , l=1)</formula><p>as follows:</p><formula xml:id="formula_8">Count(p ′ a , c ′ a , l=1) = ∑ p,c:pa=p ′ a ,ca=c ′ a P (l=1|p, k, c)</formula><p>(8) Similarly, P (l=1|k c ) is estimated as follows:</p><formula xml:id="formula_9">P (l=1|k c ) = Count(k c , l=1) + θ Count(k c ) + θ * 2 (9)</formula><p>where Count(k c ) is the number of times k c ap- pears in the training data, and Count(k c , l=1) is the expected number of times k c is the context sur- rounding a pronoun and its antecedent c. Given</p><formula xml:id="formula_10">context k ′ c , we compute Count(k ′ c , l=1) as fol- lows: Count(k ′ c , l=1) = ∑ k:kc=k ′ c P (l=1|p, k, c) (10)</formula><p>To start the induction process, we initialize all parameters with uniform values. Specifically, P (p a |c a , l=1) is set to 1 |a| , and P (l=1|k c ) is set to 0.5. Then we iteratively run the E-step and the M-step until convergence.</p><p>There are two important questions we have not addressed. First, how can we compute the four at- tribute values of a candidate antecedent (i.e., c a for each attribute a), which we need to estimate P (p a |c a , l=1)? Second, what features should we use to represent context k c , which we need to esti- mate P (l=1|k c )? We defer the discussion of these questions to Sections 5 and 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Inference</head><p>After training, we can apply the resulting model to resolve AZPs. Given an AZP z, we determine its antecedent as follows:</p><formula xml:id="formula_11">(ˆ c, ˆ p) = arg max c∈C, p∈P R P (l=1|p, k, c)<label>(11)</label></formula><p>where P R is our set of 10 Chinese overt pronouns and C is the set of candidate antecedents of z. In other words, we apply Formula (11) to each AZP z, searching for the candidate antecedent c and overt pronoun p that maximize P (l=1|p, k, c) when p is used to fill the ZP gap left behind by z. The c that results in the maximum probability value over all overt pronouns in P R is chosen as the antecedent of z. In essence, since the model is trained on overt pronouns but is applied to ZPs, we have to exhaustively fill the ZP's gap under consideration with each of the 10 overt pronouns in P R during inference.</p><p>Although we can now apply our generative model to resolve AZPs, the resolution procedure can be improved further. The improvement is motivated by a problem we observed previously ( <ref type="bibr" target="#b2">Chen and Ng, 2013)</ref>: an AZP and its closest an- tecedent can sometimes be far away from each other, thus making it difficult to correctly resolve the AZP. To address this problem, we employ the following resolution procedure in our experiments. Given a test document, we process its AZPs in a left-to-right manner. As soon as we resolve an AZP to a preceding NP c, we fill the correspond- ing AZP's gap with c. Hence, when we process an AZP z, all of its preceding AZPs in the associ- ated text have been resolved, with their gaps filled by the NPs they are resolved to. To resolve z, we create test instances between z and its candidate antecedents in the same way as described before. The only difference is that the set of candidate an- tecedents of z may now include those NPs that are used to fill the gaps of the AZPs resolved so far. In other words, this incremental resolution procedure may increase the number of candidate antecedents of each AZP z. Some of these additional candidate antecedents are closer to z than the original candi- date antecedents, thereby facilitating the resolution of z. If the model resolves z to the additional can- didate antecedent that fills the gap left behind by, say, AZP z ′ , we postprocess the output by resolv- ing z to the NP that z ′ is resolved to. <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Attributes of Candidate Antecedents</head><p>In this section, we describe how we determine the four grammatical attribute values (Number, Gender, Person and Animacy) of a candidate antecedent c, as they are used to represent c when estimating P (p a |c a , l=1) for each attribute a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">ANIMACY</head><p>We determine the Animacy of a candidate an- tecedent c heuristically. Specifically, we first check the NP type of c. If c is a pronoun, we look up its Animacy in <ref type="table">Table 1</ref>. If c is a named en- tity, there are two cases to consider: if c is a per- son 4 , we label it as animate; otherwise, we label it as inanimate. If c is a common noun, we look up the Animacy of its head noun in an automatically constructed word list W L. If the head noun is not in W L, we set its Animacy to unknown.</p><p>Our method for constructing W L is motivated by an observation of measure words in Chinese: some of them only modify inanimate nouns while others only modify animate nouns. For example, the nouns modified by the measure word 张 are al- ways inanimate, as in 一张纸 (one piece of paper). On the other hand, the nouns modified by the mea- sure word 位 are always animate, as in 一位工人 (one worker).</p><p>Given this observation, we first define two lists, M ani and M inani . M ani is a list of measure words that can only modify animate nouns. M inani is a list of measure words that can only modify inan- imate nouns. <ref type="bibr">5</ref> There exists a special measure word in Chinese, 个, which can be used to mod- ify most of the common nouns regardless of their Animacy. As a result, we remove 个 from both lists. After constructing M ani and M inani , we (1) parse the Chinese Gigaword corpus <ref type="bibr" target="#b19">(Parker et al., 2009)</ref>, which contains 4,370,600 documents, using an efficient dependency parser, ctbparser <ref type="bibr">6 (Qian et al., 2010)</ref>, and then (2) collect all pairs of words (m, n), where m is a measure word, n is a com- mon noun, and there is a NMOD dependency re- lation between m and n. Finally, we determine the Animacy of a given common noun n as fol- lows. First, we retrieve all of the pairs contain- ing n. Then, we sum over all occurrences of m in M ani (call the sum C ani ), as well as all occur- rences of m in M inani (call the sum C inani ). If C ani &gt; C inani , we label this common noun as an- imate; otherwise, we label it as inanimate. <ref type="table" target="#tab_2">Table 2</ref> shows the learned values of P (p Ani |c Ani , l=1). These results are consis- tent with our intuition: an animate (inanimate) pronoun is more likely to be generated from an animate (inanimate) antecedent than from an inanimate (animate) antecedent. Note that animate pronouns are more likely to be generated than inanimate pronouns regardless of the antecedent's Animacy. This can be attributed to the fact that 94.6% of the pronouns in our corpus are animate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">GENDER</head><p>We determine the Gender of a candidate an- tecedent c as follows. If c is a pronoun, we look up its Gender in <ref type="table">Table 1</ref>. Otherwise, we determine ` ` ` ` ` ` ` ` ` `   <ref type="formula" target="#formula_5">(2006)</ref>, we define a dependency path as the sequence of non-terminal nodes and dependency labels between two potentially coreferent entities in a dependency parse tree. From the parsed Chi- nese Gigaword corpus, we first collect every de- pendency path that connects two pronouns. For each path P collected, we compute CL(P ), the coreference likelihood of P , as follows:</p><formula xml:id="formula_12">CL(P ) = N I (P ) N I (P ) + N D (P )<label>(12)</label></formula><p>where N I (P ) is the number of times P connects two identical pronouns, and N D (P ) is the number of times it connects two different pronouns. As- suming that two identical pronouns in a sentence are coreferent ( <ref type="bibr" target="#b0">Bergsma and Lin, 2006</ref>), we can see that the larger a path's CL value is, the more likely it is that the two NPs it connects are corefer- ent. To ensure that we have dependency paths that are strongly indicative of coreference relations, we consider a dependency path P a coreferent path if and only if CL(P ) &gt; 0.8. Given these coreferent paths, we can compute the Gender of a noun n as follows. First, we com- pute (1) N M (n), the number of coreferent paths connecting n with a masculine pronoun; and (2) N F (n), the number of coreferent paths connect- ing n with a feminine pronoun. Then, if N F (n) &gt; N M (n), we set n's gender to feminine; otherwise, we set it to masculine. <ref type="table" target="#tab_4">Table 3</ref> shows the learned values of P (p Gen |c Gen , l=1).</p><p>These results are con- sistent with our intuition: a pronoun is a lot more likely to be generated from an antecedent with the same Gender than one with a different Gender.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>767``</head><p>767`767`` ` ` ` ` ` ` ` `   <ref type="table">Table 4</ref>: Learned values of P (p N um |c N um , l=1). modified by a quantity word (e.g., 一些, 许多), c is plural; otherwise, c is singular. <ref type="table">Table 4</ref> shows the learned values of P (p N um |c N um , l=1). These results are con- sistent with our intuition: a pronoun is more likely to be generated from an antecedent with the same Number than one with a different Number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">NUMBER</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">PERSON</head><p>Finally, we compute the Person of a candi- date antecedent c. Similar to Charniak and El- sner (2009), we set 我 (I) and 我们 (we) to first person, 你 (singular you) and 你们 (plural you) to second person, and everything else to third person. We estimate two sets of probabilities P (p P er |c P er , l=1), one where p and c are from the same speaker, and the other where they are from different speakers. 7 This is based on our observa- tion that P (p P er |c P er , l=1) could be very different in these two cases. <ref type="bibr">7</ref> We employ a simple heuristic to identify the speaker of NPs occurring in direct speech: we assume that the speaker is the subject of the speech's reporting verb. So for example, we identify Jack as the speaker of This book in the sentence "This book is good," Jack said.</p><p>` ` ` ` ` ` ` ` ` `   <ref type="table">Table 6</ref>: Learned values of P (p P er |c P er , l=1) (different speakers). <ref type="table" target="#tab_7">Tables 5 and 6</ref> show the learned values of these two sets of probabilities. These results are consis- tent with our intuition. In the same-speaker case, a pronoun is a lot more likely to be generated from an antecedent with the same speaker than one with a different speaker. In the different-speaker case, a first (second) person pronoun is most likely to be generated from a second (first) person pronoun.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Context Features</head><p>To fully specify our model, we need to describe how to represent k c , which is needed to compute P (l=1|k c ). Recall that k c encodes the context sur- rounding candidate antecedent c and the associated pronoun p. As described below, we represent k c using eight features, some of which are motivated by previous work on supervised AZP resolution (e.g., <ref type="bibr" target="#b26">Zhao and Ng (2007)</ref>, <ref type="bibr" target="#b2">Chen and Ng (2013)</ref>). Note that (1) all but feature 1 are computed based on syntactic parse trees, and (2) features 2, 3, 6, and 8 are ternary-valued features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">the sentence distance between c and p;</head><p>2. whether the node spanning c has an ancestor NP node; if so, whether this NP node is a de- scendant of c's lowest ancestor IP node;</p><p>3. whether the node spanning c has an ancestor VP node; if so, whether this VP node is a de- scendant of c's lowest ancestor IP node;</p><p>4. whether vp has an ancestor NP node, where vp is the VP node spanning the VP that fol- lows p;</p><p>5. whether vp has an ancestor VP node;  6. whether p is the first word of a sentence; if not, whether p is the first word of an IP clause;</p><p>7. whether c is a subject whose governing verb is lexically identical to the verb governing p;</p><p>8. whether c is the closest candidate antecedent with subject grammatical role and is seman- tically compatible with p's governing verb; if not, whether c is the first semantically com- patible candidate antecedent 8 .</p><p>Our approach to determine semantic compatibil- ity (in feature 8) resembles <ref type="bibr">Kehler et al.'s (2004)</ref> and <ref type="bibr">Yang et al.'s (2005)</ref> methods for computing se- lectional preferences. Specifically, for each verb and each noun that serves as a subject in Chinese Gigaword, we compute their mutual information (MI). Now, given a pronoun p and a candidate an- tecedent c in the training/test corpus, we retrieve the MI value of c and p's governing verb. We then consider them semantically compatible if and only if their MI value is greater than zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Setup</head><p>Datasets. We employ the Chinese portion of the OntoNotes 5.0 corpus that was used in the official CoNLL-2012 shared task ( <ref type="bibr" target="#b20">Pradhan et al., 2012</ref>). In the CoNLL-2012 data, the training set and de- velopment set contain ZP coreference annotations, but the test set does not. Therefore, we train our models on the training set and perform evaluation on the development set. Statistics on the datasets are shown in <ref type="table" target="#tab_9">Table 7</ref>. The documents in these datasets come from six sources, namely Broadcast News (BN), Newswire (NW), Broadcast Conver- sation (BC), Telephone Conversation (TC), Web Blog (WB) and Magazine (MZ). <ref type="bibr">8</ref> We sort the candidate antecedents of p as follows. We first consider the subject candidate antecedents in the same sentence as p from right to left, then the other candidate an- tecedents in the same sentence from right to left. Next, we consider the candidate antecedents in the previous sentence, also preferring candidates that are subjects, but in left-to-right order. Finally, we consider the candidate antecedents two sentences back, following the subject-first, left-to-right order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation measures. We express the results of ZP resolution in terms of recall (R), precision (P)</head><p>and F-score (F). Evaluation settings. Following <ref type="bibr" target="#b2">Chen and Ng (2013)</ref>, we evaluate our model in three settings. In Setting 1, we assume the availability of gold syntactic parse trees and gold AZPs. In Setting 2, we employ gold syntactic parse trees and system (i.e., automatically identified) AZPs. Finally, in Setting 3, we employ system syntactic parse trees and system AZPs. The gold and system syntactic parse trees, as well as the gold AZPs, are obtained from the CoNLL-2012 shared task dataset, while the system AZPs are identified by the rule-based approach described in the Appendix. <ref type="bibr">9</ref> Since our AZP identification approach does not rely on any labeled data, we are effectively evaluating an end- to-end unsupervised AZP resolver in Setting 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Results</head><p>Baseline systems. We employ seven resolvers as baseline systems. To gauge the difficulty of the task, we employ four simple rule-based re- solvers, which resolve an AZP z to (1) the can- didate antecedent closest to z (Baseline 1); (2) the subject NP closest to z (Baseline 2); (3) the clos- est candidate antecedent that is semantically com- patible with z (Baseline 3); and (4) the first can- didate antecedent that is semantically compatible with z, where the candidate antecedents are vis- ited according to the order described in Footnote 8 (Baseline 4). These four baselines allow us to study the role of (1) recency, (2) salience, (3) re- cency combined with semantic compatibility, and (4) salience combined with semantic compatibil- ity in AZP resolution respectively. The remaining three baselines are state-of-the-art supervised AZP resolvers, which include our own resolver <ref type="bibr" target="#b2">(Chen and Ng, 2013)</ref> as well as our re-implementations of <ref type="bibr" target="#b26">Zhao and Ng's (2007)</ref> resolver and Kong and Zhou's (2010) resolver.</p><p>The test set results of these seven baseline re- solvers when evaluated under the three afore- mentioned evaluation settings are shown in Ta- ble 8. The system AZPs employed by the rule- based resolvers are obtained using our rule-based <ref type="table">Baseline  R  P  F  R  P  F  R  P  F  Selecting closest candidate antecedent</ref> 25.0 25.2 25.1 18.3 10.8 13.6 10.3 6.7 8.1 Selecting closest subject 42.0 43.6 42.8 31.8 19.2 23.9 18.0 11.9 14.4 Selecting closest semantically compatible candidate antecedent 28.5 28.8 28.7 20.5 12.2 15.3 11.7 7.6 9.2 Selecting first semantically compatible candidate antecedent 45.2 45.7 45.5 33.6 20.0 25.1 18.9 12.3 14.9 <ref type="bibr" target="#b26">Zhao and Ng (2007)</ref> 41.5 41.5 41.5 22.4 24.4 23.3 12.7 14.2 13.4 <ref type="bibr" target="#b18">Kong and Zhou (2010)</ref> 44.9 44.9 44.9 33.0 19.3 24.4 18.7 11.9 14.5 <ref type="bibr" target="#b2">Chen and Ng (2013)</ref> 47.7 47.7 47.7 25.3 27.6 26.4 14.9 16.7 15.7  <ref type="table">Table 9</ref>: AZP resolution results of the best baseline and our unsupervised model on the test set.</p><note type="other">Setting 1: Setting 2: Setting 3: Gold Parses, Gold Parses, System Parses, Gold AZPs System AZPs System AZPs</note><p>AZP identification system. On the other hand, since our supervised resolvers are meant to be re- implementations of existing resolvers, we follow previous work and let them employ a supervised AZP identification system. In particular, we em- ploy the one described in <ref type="bibr" target="#b2">Chen and Ng (2013)</ref>. Several observations can be made about these results. First, among the rule-based resolvers, Baseline 4 achieves the best performance, outper- forming Baselines 1, 2, and 3 by 12.9%, 1.5%, and 10.8% in F-score respectively when averaged over the three evaluation settings. From their relative performance, which remains the same in the three settings, we can conclude that as far as AZP resolution is concerned, (1) salience plays a greater role than recency; and (2) semantic com- patibility is useful. Second, among the super- vised baselines, our supervised resolver <ref type="bibr" target="#b2">(Chen and Ng, 2013</ref>) achieves the best performance, outper- forming Zhao and Ng's resolver and Kong and Zhou's resolver by 3.9% and 2.0% in F-score re- spectively when averaged over the three evalua- tion settings. Finally, comparing the rule-based resolvers and the learning-based resolvers, we can see that the best rule-based baseline (Baseline 4) performs even better than Zhao and Ng's resolver and Kong and Zhou's resolver.</p><p>In the rest of this subsection, we will compare our unsupervised model against the best baseline, <ref type="bibr" target="#b2">Chen and Ng's (2013)</ref> supervised resolver.</p><p>Our model. Results of the best baseline and our model on the entire test set and each of the six sources are shown in <ref type="table">Table 9</ref>. As we can see, our model achieves the same overall F-score as the best baseline under all three settings, despite the fact that it is unsupervised. In fact, our model even out- performs the best baseline on NW, WB and BN in Setting 1, NW, WB, BN and BC in Setting 2, and NW, WB and BC in Setting 3.</p><p>It is worth mentioning that while the two re- solvers achieved the same overall performance, their outputs differ a lot from each other. Specifi- cally, the two models only agree on the antecedents of 55% of the AZPs in Setting 1. <ref type="bibr">10</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Ablation Experiments</head><p>Impact of P (p a |c a , l=1) and P (l=1|k c ). Re- call that our model is composed of five probability terms, P (p a |c a , l=1) for each of the four grammat- ical attributes and P (l=1|k c ), the context proba- bility. To investigate the contribution of context and each attribute to overall performance, we con- duct ablation experiments. Specifically, in each ablation experiment, we remove exactly one prob- ability term from the model and retrain it. <ref type="bibr">10</ref> Note that it is difficult to directly compare the outputs produced under Settings 2 and 3: the AZPs identified by the best baseline are quite different from those identified by our rule-based system, as can be inferred from the AZP identifi- cation results in  Ablation results under Settings 1 and 3 are shown in <ref type="table" target="#tab_12">Table 10</ref>. As we can see, under Set- ting 1, after Number is ablated, performance does not drop. We attribute this to the fact that al- most all candidate antecedents are singular. On the other hand, when we ablate any of the remaining three attributes, performance drops significantly by 2.3−3.0% in overall F-score. 11 Similar trends can be observed with respect to Setting 3: after Number is ablated, performance only decreases by 0.2%, while ablating any of the other three at- tributes results in a drop of 0.6%.</p><p>Results after ablating context are shown in the last row of <ref type="table" target="#tab_12">Table 10</ref>. As we can see, the F-score drops significantly by 14.7% and 3.8% under Set- tings 1 and 3 respectively. These results illustrate the importance of context features in our model. Context feature ablation. Recall that we em- ployed eight context features to encode the rela- tionship between a pronoun and a candidate an- tecedent. To determine the relative contribution of these eight features to overall performance, we conduct ablation experiments under Settings 1 and 3. In these ablation experiments, all four gram- matical attributes are retained in the model.</p><p>Ablation results are shown in rows 2−9 of Ta- ble 11. To facilitate comparison, the F-score of the model in which all eight context features are used is shown in row 1. As we can see, feature 8 (the rule-based feature) is the most useful feature: its removal causes the F-scores of our resolver to drop significantly by 6.4% under Setting 1 and 1.5% un- der Setting 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Error Analysis</head><p>To gain additional insights into our full model, we examine its major sources of error below. To focus on errors attributable to AZP resolution, we ana- lyze our full model under Setting 1.</p><p>Specifically, we randomly select 100 AZPs that our model incorrectly resolves under Setting 1. 11 All significance tests are paired t-tests, with p &lt; 0.05.  The model incorrectly resolves the AZP *pro* to 行政区 (Its administrative area). The reason is that the correct antecedent, 八里乡 (Bali Town), is far from *pro*: there are five candidate an- tecedents between *pro* and 八里乡 (Bali Town). Note, however, that it is easy for a human to re- solve *pro* to 八里乡 (Bali Town) because the whole passage is discussing 八里乡 (Bali Town). Hence, to correctly handle such cases, one may construct a topic model over the passage and as- sign each candidate antecedent a prior probability so that the resulting system favors the selection of candidates representing the topics as antecedents. Errors in computing semantic compatibility. This type of error contributes to 28 of the incor- rectly resolved AZPs. When computing seman- tic compatibility in our model, we only consider the mutual information between a candidate an- tecedent and the pronoun's governing verb, but in some cases, additional context needs to be taken into account. Consider the following example:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setting 1 Setting 3 System</head><p>[一支海军陆战队] 杀死了约 <ref type="bibr">[24 名手无寸铁的 伊拉克人]</ref>，*pro* 包括妇女和六名儿童。 ( <ref type="bibr">[Marines]</ref> killed about <ref type="bibr">[24 unarmed Iraqis]</ref>, *pro* include women and six children.)</p><p>There are two candidate antecedents in this ex- ample, 一支海军陆战队 (Marines) and 24 名手无 寸铁的伊拉克人 (24 unarmed Iraqis), which we denote as c 1 and c 2 respectively. The correct an- tecedent of *pro* is c 2 , while our model wrongly resolves *pro* to c 1 . Note that both c 1 and c 2 are compatible with the AZP's governing verb 包括 (include). However, if the object of the govern- ing verb, i.e., 妇女和六名儿童 (women and six children), were also considered, the model could determine that c 1 is not compatible with the object while c 2 is, and then correctly resolve *pro* to c 2 . Failure to recognize and exploit semantically similar sentences. This type of error contributes to 23 wrongly resolved AZPs. Recall that an AZP is omitted for brevity, so the sentence it appears in often expresses similar meaning to an earlier sen- tence. However, our model fails to handle such cases. Consider the following example:</p><p>[指挥部和突进的部队] 之间也会失去联络。..... The above example shows two sentences that are separated by some other sentences. The AZP under consideration is in the last sentence, while the first sentence contains the correct antecedent 指挥部和突进的部队 (the command and the on- rush troops), denoted as c 1 . Our model fails to re- solve *pro* to c 1 , because there are many com- peting candidate antecedents between c 1 and AZP. However, if our model were aware of the similarity between the constructions appearing after c 1 and *pro*, i.e., 之间也会失去联络 (lost connection with each other) and 就联络不上了 (cannot con- nect with each other), then it might be able to cor- rectly resolve the AZP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We proposed an unsupervised model for Chinese zero pronoun resolution, investigating the novel hypothesis that an unsupervised probabilistic re- solver trained on overt pronouns can be applied to resolve ZPs. To our knowledge, this is the first un- supervised probabilistic model for this task. Ex- periments on the OntoNotes 5.0 corpus showed that our unsupervised model rivaled its state-of- the-art supervised counterparts in performance.  To gauge the performance of our rule-based AZP identification system, we compare it with our supervised AZP identification system <ref type="bibr" target="#b2">(Chen and Ng, 2013)</ref>. Results of the two systems on our test set are shown in <ref type="table" target="#tab_2">Table 12</ref>. As we can see, the F- scores achieved by the rule-based system is com- parable to those of the supervised system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Pronouns</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>*pro* 就联络不上了。 ([The command and the onrush of troops] lost con- nection with each other. ... *pro* cannot connect with each other.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Learned values of P (p Ani |c Ani , l=1).</head><label>2</label><figDesc></figDesc><table>its Gender based on its Animacy. Specifically, 
if c is inanimate, we set its Gender to neuter. 
Otherwise, we determine its gender by looking up 
a gender word list constructed by Bergsma and 
Lin's (2006) approach. If the word is not in the 
list, we set its Gender to masculine by default. 
Next, we describe how the aforementioned gen-
der word list is constructed. Following Bergsma 
and Lin </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 3 : Learned values of P (p Gen |c Gen , l=1).</head><label>3</label><figDesc></figDesc><table>` ` ` ` ` ` ` ` ` ` 

Antecedent 
Pronoun singular plural 

singular 
0.861 
0.139 
plural 
0.26 
0.74 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Learned values of P (p P er |c P er , l=1) 
(same speaker). 

` ` ` ` ` ` ` ` ` ` 

Antecedent 

Pronoun 
first 
second 
third 

first 
0.417 
0.525 
0.057 
second 
0.75 
0.23 
0.02 
third 
0.437 
0.229 
0.334 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Statistics on the training and test sets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>AZP resolution results of the baseline systems on the test set. 

Setting 1: Gold Parses, Gold AZPs 
Setting 2: Gold Parses, System AZPs 
Setting 3: System Parses, System AZPs 

Best Baseline 
Our Model 
Best Baseline 
Our Model 
Best Baseline 
Our Model 
Source R 
P 
F 
R 
P 
F 
R 
P 
F 
R 
P 
F 
R 
P 
F 
R 
P 
F 
Overall 47.7 47.7 47.7 47.5 47.9 47.7 25.3 27.6 26.4 35.4 21.0 26.4 14.9 16.7 15.7 19.9 12.9 15.7 
NW 
38.1 38.1 38.1 41.7 41.7 41.7 15.5 21.7 18.1 29.8 24.8 27.0 6.0 12.2 8.0 
11.9 13.0 12.4 
MZ 
34.6 34.6 34.6 34.0 34.2 34.1 18.5 19.6 19.0 24.1 14.5 18.1 6.2 9.4 7.5 
6.2 5.2 5.7 
WB 
46.1 46.1 46.1 47.9 47.9 47.9 21.8 22.0 21.8 37.3 18.7 24.9 8.5 11.4 9.7 
19.0 11.3 14.2 
BN 
47.2 47.2 47.2 52.8 52.8 52.8 21.8 33.2 26.3 31.5 28.1 29.7 14.6 26.3 18.8 18.2 19.5 18.8 
BC 
52.7 52.7 52.7 49.8 50.3 50.0 23.3 30.7 26.5 38.0 21.0 27.0 12.7 16.2 14.3 20.6 12.4 15.5 
TC 
51.2 51.2 51.2 45.2 46.7 46.0 43.1 28.2 34.1 42.4 20.3 27.4 33.2 17.1 22.5 32.2 13.3 18.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 12 .</head><label>12</label><figDesc></figDesc><table>770 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 10 :</head><label>10</label><figDesc></figDesc><table>Probability term ablation results. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" validated="false"><head>Table 11 :</head><label>11</label><figDesc></figDesc><table>Context feature ablation results. 

We found that 17 errors are attributable to dis-
course disfluency, lack of background knowledge 
and subject detection, while the remaining 83 er-
rors can be divided into three types: 
Failure to recognize the topics of a document. 
Our model incorrectly resolves 32 AZPs that are 
coreferent with NPs corresponding to the topics of 
the associated documents. Consider the following 
example: 

[八里乡] 位于台北盆地西北端。行政区隶属于 
台北县，*pro* 为台北县廿九个乡镇市之一。 
([Bali Town] is located in the Northwest of Taipei 
Basin. Its administrative area is affiliated with 
Taipei County, *pro* is one of Taipei County's 29 
towns and cities.) 12 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" validated="true"><head>Table 12 : AZP identification results on the test set.</head><label>12</label><figDesc></figDesc><table>Rule 7. Remove z if vp's lowest IP ancestor has 
(1) a VP node as its parent and (2) a VV node as 
its left sibling. 
Rule 8. Remove z if it begins a document. 

</table></figure>

			<note place="foot" n="1"> Only 8% of the overt pronouns in our corpus, the Chinese portion of the OntoNotes 5.0 corpus, do not have any antecedent in the preceding two sentences.</note>

			<note place="foot" n="2"> This assumption is reasonable because it is fairly easy to determine which pronoun can be used to refer to a given NP.</note>

			<note place="foot" n="3"> This postprocessing step is needed because the additional candidate antecedents are only gap fillers. 4 A detailed description of our named entity recognizer can be found in Chen and Ng (2014).</note>

			<note place="foot" n="5"> We create these two lists with the help of this page: http://chinesenotes.com/ref_measure_words.htm 6 http://code.google.com/p/ctbparser/</note>

			<note place="foot" n="9"> One may wonder why we do not train a supervised system for identifying AZPs and instead experiment with a rulebased AZP identification system. The reason is that employing labeled data defeats the whole purpose of having an unsupervised AZP resolution model: if annotated data is available for training an AZP identification system, the same data can be used to train an AZP resolution system.</note>

			<note place="foot" n="12"> The pronoun Its in the phrase Its administrative area is inserted into the English translation for the sake of grammaticality and correct understanding of the sentence. The corresponding Chinese phrase does not contain any pronoun.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the three anonymous reviewers for their detailed comments. This work was supported in part by NSF Grants IIS-1147644 and IIS-1219142.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Automatic AZP Identification</head><p>Our automatic AZP identification system employs an ordered set of rules. The first rule is a positive rule that aims to extract as many candidate AZPs as possible. It is followed by seven negative rules that aim to improve precision by filtering out er- roneous candidate AZPs. Below we first describe the rules and then evaluate this rule-based system. Rule 1. Add candidate AZP z if it occurs before the leftmost word spanned by a VP node vp. Rule 2. Remove z if its associated vp is in a coor- dinate structure or modified by an adverbial node.   <ref type="formula">(1)</ref> z does not begin a sen- tence, (2) the highest node whose spanning word sequence ends with the left non-comma neighbor word of z is either NP, QP or IP, and (3) the parent of this node is VP.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bootstrapping path-based pronoun resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">EM works for pronoun anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha</forename><surname>Elsner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 12th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Chinese zero pronoun resolution: Some recent advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1360" to="1365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SinoCoreferencer: An end-to-end Chinese event coreference resolver</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Language Resources and Evaluation</title>
		<meeting>the 9th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4532" to="4538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An expectation maximization approach to pronoun resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Conference on Natural Language Learning</title>
		<meeting>the Ninth Conference on Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="88" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Pronominal Anaphora Resolution in Chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Converse</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
	<note>Rubin</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A computational approach to zero-pronouns in Spanish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Ferrández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><surname>Peral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 38th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="166" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Centering: A framework for modeling the local coherence of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Weinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="226" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Korean Zero Pronouns: Analysis and Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Na-Rae</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Resolving pronoun references</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><surname>Hobbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lingua</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="311" to="338" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A cross-lingual ILP solution to zero anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="804" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting syntactic patterns as clues in zero-anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Zero-anaphora resolution by learning rich syntactic pattern features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Asian Language Information Processing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Discriminative approach to predicateargument structure analysis with zero-anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Imamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniko</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Izumi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-IJCNLP</title>
		<meeting>the ACL-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Conference Short Papers</title>
		<imprint>
			<biblScope unit="page" from="85" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Japanese zero pronoun resolution based on ranking rules and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsutomu</forename><surname>Hirao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2003 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="184" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The (non)utility of predicate-argument frequencies for pronoun interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Kehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Appelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lara</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Simma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2004 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>2004 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="289" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A tree kernelbased unified framework for Chinese zero anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="882" to="891" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Chinese Gigaword fourth edition. Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">CoNLL2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning: Shared Task</title>
		<meeting>2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning: Shared Task</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">2d trie for fast parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuangjing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lide</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="904" to="912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A discriminative approach to Japanese zero anaphora resolution with large-scale lexicalized case frames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryohei</forename><surname>Sasano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Joint Conference on Natural Language Processing</title>
		<meeting>the 5th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="758" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A probabilistic method for analyzing Japanese anaphora integrating zero pronoun detection and resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuhiro</forename><surname>Seki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuya</forename><surname>Ishikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Computational Linguistics</title>
		<meeting>the 19th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improving pronoun resolution using statistics-based semantic compatibility information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew Lim</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="165" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Zero anaphora resolution in Chinese with shallow parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Long</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Chun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chinese Language and Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="56" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Identification and resolution of Chinese zero pronouns: A machine learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<title level="m">Joint Conference on Empirical Methods on Natural Language Processing and Computational Natural Language Learning</title>
		<imprint>
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Context-sensitive convolution tree kernel for pronoun resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoming</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Joint Conference on Natural Language Processing</title>
		<meeting>the 3rd International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="25" to="31" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
