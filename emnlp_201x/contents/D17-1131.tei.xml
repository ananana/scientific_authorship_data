<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An End-to-End Deep Framework for Answer Triggering with a Novel Group-Level Objective</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Su</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Guan</surname></persName>
							<email>ziyuguan@nwu.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Sun</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The Ohio State University</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<address>
									<settlement>Santa Babara</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Northwest University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An End-to-End Deep Framework for Answer Triggering with a Novel Group-Level Objective</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1276" to="1282"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Given a question and a set of answer candidates, answer triggering determines whether the candidate set contains any correct answers. If yes, it then outputs a correct one. In contrast to existing pipeline methods which first consider individual candidate answers separately and then make a prediction based on a threshold , we propose an end-to-end deep neu-ral network framework, which is trained by a novel group-level objective function that directly optimizes the answer triggering performance. Our objective function penalizes three potential types of error and allows training the framework in an end-to-end manner. Experimental results on the WIKIQA benchmark show that our framework outperforms the state of the arts by a 6.6% absolute gain under F 1 measure 1 .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question Answering (QA) aims at automatically responding to natural language questions with di- rect answers <ref type="bibr" target="#b14">(Heilman and Smith, 2010;</ref><ref type="bibr">Severyn and Moschitti, 2013;</ref><ref type="bibr" target="#b23">Yao et al., 2013;</ref><ref type="bibr" target="#b4">Berant and Liang, 2014;</ref><ref type="bibr" target="#b17">Sun et al., 2015;</ref><ref type="bibr">Miller et al., 2016;</ref><ref type="bibr" target="#b16">Sun et al., 2016</ref>). Most existing QA systems always output an answer for any ques- tion, no matter whether their answer candidate set contains correct answers or not <ref type="bibr" target="#b10">(Feng et al., 2015;</ref><ref type="bibr" target="#b15">Severyn and Moschitti, 2015;</ref><ref type="bibr" target="#b21">Yang et al., 2016;</ref><ref type="bibr">Rao et al., 2016)</ref>. In practice, however, this can greatly hurt user experience, especially when it is hard for users to judge answer correctness. In this paper, we study the critical yet under-addressed Answer Triggering ( <ref type="bibr" target="#b22">Yang et al., 2015)</ref> problem: Given a question and a set of answer candidates, determine whether the candidate set contains any correct answer, and if so, select a correct answer as system output.</p><p>The answer triggering problem can be logi- cally divided into two sub-problems: P 1 : Build an individual-level model to rank answer candi- dates so that a correct one (if it exists) gets the highest score. P 2 : Make a group-level binary pre- diction on the existence of correct answers within the candidate set. Previous work ( <ref type="bibr" target="#b22">Yang et al., 2015;</ref><ref type="bibr">Jurczyk et al., 2016</ref>) attack the problem via a pipeline approach: First solve P 1 as a ranking task and then solve P 2 by choosing an optimal threshold upon the previous step's highest ranking score. However, the yielded answer triggering per- formance is far from satisfactory, with F 1 between 32% and 36%. An alternative pipeline approach is to first solve P 2 and then P 1 , i.e., first determine whether there's a correct answer in the candidate set and then rank all candidates to find a correct one. However, as we will show using state-of-the- art Multiple Instance Learning (MIL) algorithms in Section 4, P 2 by itself is currently a very chal- lenging task, partly because of the difficulty of ex- tracting features from a set of candidate answers that are effective for answer triggering. Because both P 1 and P 2 performances are far from perfect, the above pipeline approaches also suffer from er- ror propagation ( <ref type="bibr" target="#b11">Finkel et al., 2006;</ref><ref type="bibr" target="#b28">Zeng et al., 2015</ref>).</p><p>We propose Group-level Answer Triggering (GAT), an end-to-end framework for jointly opti- mizing P 1 and P 2 . Our key contribution in GAT is a novel group-level objective function, which aggregates individual-level information and penal- izes three potential error types in answer triggering as a group-level task. By optimizing this objec- tive function, we can directly back-propagate the final answer triggering errors to the entire frame- work and learn all the parameters simultaneously. We conduct evaluation using the same dataset and measure as in previous work <ref type="bibr" target="#b22">(Yang et al., 2015;</ref><ref type="bibr">Jurczyk et al., 2016)</ref>, and our framework improves the F 1 score by 6.6% (from 36.65% to 43.27%), compared with the state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Framework</head><p>Notations. Let i and j respectively be the index of question and answer candidate, l i,j be the binary label of the j-th answer candidate for question q i , and l i be the group label of the answer candidate set of q i (1 if it contains any correct answer; 0 oth- erwise). m i,j denotes an individual-level match- ing score, measuring how likely question q i can be correctly addressed by its j-th answer candidate.</p><p>The GAT framework is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, which consists of three components: (1) Encoder. Two separate encoders process questions and an- swer candidates respectively, mapping them from token sequences into two different vector spaces. (2) QA Matching. For each question and answer candidate pair, we concatenate their encoded vec- tors, and pass it through a feed forward neural network with a binary softmax output layer. The output is an individual-level matching score, i.e., m i,j . (3) Signed Max Pooling. Max pooling is applied on all the matching scores in a candidate set. During training when each candidate is posi- tively/negatively labeled on whether they can an- swer the question or not, we use the labels to di- vide the scores into two disjoint subsets and per- form max pooling separately:</p><formula xml:id="formula_0">m + i = max j:l i,j =1 m i,j , m − i = max j:l i,j =0 m i,j ,</formula><p>where m + i is the maximum score among correct answers (if there's any) and m − i is that among wrong ones. At testing time when labels are un- available, it reduces to normal max pooling and pools a single score m i = max j m i,j . The an- swer triggering prediction is then made by com- paring m i with a predefined threshold (0.5) to de- cide whether to return the top-scored answer can- didate to the user.</p><p>The GAT framework design is generic in that the Encoder component can be instantiated with different network architectures. In this paper, we implement it with Bidirectional RNNs (Bi-RNN) <ref type="bibr">(Schuster and Paliwal, 1997</ref>) with GRU cells <ref type="bibr" target="#b8">(Cho et al., 2014</ref>  over the hidden states as the encoding represen- tation. We choose Bi-RNN mainly because of its good performance in many QA problems ( <ref type="bibr" target="#b20">Wang and Nyberg, 2015;</ref><ref type="bibr" target="#b19">Wang et al., 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Learning</head><p>The cost function for negative groups (answer can- didate sets without correct answers) and positive groups (those with correct answers) are treated dif- ferently. For each negative group, the highest QA matching score is penalized by a hinge loss:</p><formula xml:id="formula_1">O 1 = 1 N neg i: l i =0 max(0, d − − (0.5 − m − i )),</formula><p>where the maximum matching score m − i is com- pared with 0.5, a fixed threshold for our frame- work. The variable d − here, as well as d + and d ± that will appear shortly after, are all margin hyper- parameters. O 1 is normalized by N neg , which is the number of negative groups (with l i = 0). We use O 1 to reduce false-positive answer existence predictions by penalizing the top matching score that is not safely below the 0.5 threshold.</p><p>For a positive group, it is more complicated be- cause answer triggering prediction can have the following two error types: (1) the top matching score is below the threshold, or (2) the top ranked answer candidate is a wrong answer. We design loss terms O 2 and O 3 to penalize these two types of error, respectively. O 2 is a hinge loss that pe- nalizes the case where the highest score among the correct answers in a group is not large enough to signify answer existence. O 3 is to penalize the case where the highest score is obtained by an in- correct candidate answer. Formally:</p><formula xml:id="formula_2">O 2 = 1 N pos i: l i =1 max(0, d + − (m + i − 0.5)) O 3 = 1 N pos i: l i =1 max(0, d ± − (m + i − m − i ))</formula><p>Finally, the overall objective function in Equa- tion 1 is a linear combination of the three loss terms and a standard 2 -regularization. Θ denotes all the trainable parameters in the framework. α, β and λ are hyper-parameters.</p><formula xml:id="formula_3">O = O 1 + αO 2 + βO 3 + λΘ 2</formula><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">A Naive Objective Baseline</head><p>For comparison, we provide an alternative objec- tive formulation, which equivalently treats posi- tive and negative groups, and does not explicitly penalize cases where an incorrect candidate an- swer obtains the highest QA matching score in a positive group.</p><formula xml:id="formula_4">O * 2 = 1 N pos i: l i =1 max(0, d + − (m i − 0.5)) O * 1 = O 1 ; O * = O * 1 + α * O * 2 + λ * Θ 2<label>(2)</label></formula><p>Here d + is a margin and α * , λ * are weights. We hypothesize this formulation will work worse than the objective in Equation 1, and will use experi- ments to verify it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>We use the WIKIQA dataset ( <ref type="bibr" target="#b22">Yang et al., 2015</ref>) for evaluation. It contains 3,047 questions from Bing query logs, each associated with a group of candi- date answer sentences from Wikipedia and manu- ally labeled via crowdsourcing. Several intuitive features are also included in WIKIQA: two word matching features (IDF-weighted and unweighted word-overlapping counts between questions and candidate answers, denoted as Cnt), the length of a question (QLen), and the length of a candi- date answer (SLen). As in previous works, we also test the effect of these features, by combining them with other features as input into the Softmax layer in our framework. We use the standard 70% (train), 10% (dev), and 20% (test) split of WIK- IQA. We also use the same data pre-processing steps for fair comparison: Truncate questions and sentences to a maximum of 40-token long and initialize the 300-dimensional word vectors using pretrained word2vec embedding (Mikolov et al., 2013).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>We implement our full framework using Tensor- Flow ( <ref type="bibr" target="#b0">Abadi et al., 2016</ref>) and train it using the AdaDelta optimizer (Zeiler, 2012) with learning rate 0.1 and decay factor 0.95. Dropout is used during training to prevent overfitting. The default threshold in Signed Max Pooling is set at 0.5. We select the hyper-parameters using the dev set and set α=1.2, β=1.0, d + =0.2, d − =0.3, d ± =0.5, λ=1e −4 . The RNN's hidden state size is 200 in both directions. The feed-forward network in QA Matching has two layers of 400 hidden units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation Metrics</head><p>We use precision, recall, and F 1 , defined in the same way as in previous work. A question is treated as a positive case only if it contains one or more correct answers in its candidate set. For the prediction of a question, only the candidate with the highest matching score is considered. A true positive prediction shall meet two criteria: (1) the score is above a threshold (0.5 for our framework; tuned on dev set in other work), and (2) the candi- date is labeled as a correct answer to the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results a. Comparison with Baselines</head><p>We evaluate the effectiveness of the proposed GAT framework by comparing with several baseline models. To the best of our knowledge, there has only been limited work so far on answer trigger- ing, and they are the first two baselines below.  <ref type="bibr">2</ref> , denoted as GAT w/ CNN, and train it with our objective. From the first two rows in <ref type="table" target="#tab_3">Table 2</ref>, we observe that: (1) Using our current design Bi- RNN and feed-foward NN improves from 35.03% to 43.27%, in comparison with the CNN based model, partly because their CNN only consists of one convolution layer and one average pooling layer. However, we leave more advanced encoder and QA matching design for future work, and an- ticipate that more complex CNN based models can achieve similar or better results than our current design, as in many other QA-related work ( <ref type="bibr">Hu et al., 2014;</ref><ref type="bibr" target="#b13">He and Lin, 2016)</ref>. <ref type="formula" target="#formula_4">(2)</ref> Compared with the best result from ( <ref type="bibr" target="#b22">Yang et al., 2015</ref>) in <ref type="table">Table 1</ref>, training the CNN based model end-to-end using our objective improves from 32.17% to 35.03%. This directly shows an end-to-end learning strat- egy works better than the pipeline approach in ( <ref type="bibr" target="#b22">Yang et al., 2015</ref>  from our end-to-end full framework. To obtain semantic vectors of questions and candidate an- swers as input to the subsequent QA Matching component, we leverage <ref type="bibr" target="#b22">Yang et al.(2015)</ref>'s re- leased code to train the Encoder component (with CNN) through their well-tuned individual-level optimization, and use their learnt semantic vec- tors. Then our framework without ENC, i.e., -ENC, is trained and tested as before. We fur- ther detach the QA matching component QAM in a similar way: We directly use the matching score between a question and a candidate answer obtained by <ref type="bibr" target="#b22">Yang et al. (2015)</ref>, and concate- nate it with Cnt features as input to the Soft- max layer, which is our framework without ENC or QAM, denoted as -ENC -QAM, and trained by our group-level objective. By comparing them with our end-to-end frameworks on both dev and test sets, we can see that it is beneficial to jointly train the entire framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Error Analysis</head><p>We now demonstrate some typical mistake types made by our framework to inspire future improve- ments.</p><p>Q: What city was the convention when Gerald Ford was nominated? A: Held in Kemper arena in Kansas City , Mis- souri , the convention nominated president Gerald Ford for a full term, but only after narrowly de- feating a strong challenge from former California governor Ronald Reagan. In this case, A is correct, but our framework made a false negative prediction. Although al- ready being the highest ranked in a set of 4 can- didate answers, A only got a score of 0.134, pos- sibly due to its complicated semantic structure (at- tribute clause) and the extra irrelevant information (defeating Reagan).</p><p>Q: What can SQL 2005 do? A1: Microsoft SQL server is a relational database management system developed by Microsoft. A2: As a database , it is a software product whose primary function is to store and retrieve data as re- quested by other software applications, be it those on the same computer or those running on another computer across a [TRUNCATED END]</p><p>The incorrect answer A1 is ranked higher than the correct answer A2, both with scores above 0.5. This is a false positive case, with incorrect rank- ing as well. Possible reasons are that the detailed functionality of SQL explained in A2 is hard to be captured and related to the question, and A2 gets truncated to 40 tokens long in our experiments. On the other hand, the "database management sys- tem" phrase in A1 sounds close to an explanation of functionality, if not carefully distinguished.</p><p>Both cases above show that the semantic rela- tion between a question and its answer is hard to capture. For future research, more advanced mod- els can be incorporated in the Encoder and QA Matching components of our framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Answer Selection. Answer selection (a.k.a., an- swer sentence selection) is the task of assigning answer candidates with individual-level ranking scores given a question, which is similar to P1 de- fined in Section 1. Existing QA systems based on answer selection just select the top-scored candi- date as answer, without considering the possibility that the true answer doesn't even exist. However, many neural network models recently explored in the answer existence literature ( <ref type="bibr">Hu et al., 2014;</ref><ref type="bibr" target="#b20">Wang and Nyberg, 2015;</ref><ref type="bibr" target="#b10">Feng et al., 2015</ref>) could be utilized for answer selection as well in the fu- ture. For example, <ref type="bibr" target="#b18">Tan et al. (2016)</ref> explore the respective advantages of different network archi- tectures such as Long Short-Term Memory Net- works (LSTMs) and CNNs. They also develop hybrid models for answer selection. Various at- tention mechanisms have been proposed such as ( <ref type="bibr" target="#b19">Wang et al., 2016</ref>) for RNNs and ( <ref type="bibr" target="#b25">Yin et al., 2015;</ref><ref type="bibr" target="#b18">dos Santos et al., 2016</ref>) for CNNs. Answer se- lection is also formulated as a sentence similar- ity measurement problem <ref type="bibr" target="#b13">(He and Lin, 2016;</ref>) or a pairwise ranking problem as in ( <ref type="bibr" target="#b15">Severyn and Moschitti, 2015;</ref><ref type="bibr" target="#b21">Yang et al., 2016;</ref><ref type="bibr">Rao et al., 2016)</ref>.</p><p>Multiple Instance Learning We have briefly mentioned MIL ( <ref type="bibr" target="#b3">Babenko et al., 2011;</ref><ref type="bibr" target="#b1">Amores, 2013;</ref><ref type="bibr" target="#b7">Cheplygina et al., 2015</ref>) in Section 1. Many MIL algorithms can not be directly applied for an- swer triggering, because individual-level annota- tions and predictions are often assumed unavail- able and unnecessary in MIL <ref type="bibr">(Maron and LozanoPérez, 1998;</ref><ref type="bibr" target="#b3">Babenko et al., 2011;</ref><ref type="bibr" target="#b1">Amores, 2013;</ref><ref type="bibr" target="#b7">Cheplygina et al., 2015)</ref>, but not in the an- swer triggering setting, where the correctness of each answer candidate is annotated during train- ing and needs to be predicted during testing. We experimented with two popular MIL algo- rithms that explicitly discriminate individual-level labels: MI-SVM( <ref type="bibr" target="#b2">Andrews et al., 2003)</ref> and Sb- MIL ( <ref type="bibr" target="#b5">Bunescu and Mooney, 2007)</ref> implemented in one of the state-of-the-art MIL toolkits <ref type="bibr" target="#b9">(Doran and Ray, 2014</ref>), where we represented each question/answer with encoder vectors as in Sec- tion 3.4. Unfortunately, both algorithms predict no correct answer exists for any question, possibly because the training data are biased towards nega- tive groups and the input features are not effective enough. This indicates that using MIL for answer triggering is challenging and still open for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In conclusion, we address the critical answer triggering challenge with an effective framework based on deep neural networks. We propose a novel objective function to optimize the entire framework end-to-end, where we focus more on the group-level prediction and take into account multiple important factors. In particular, the ob- jective function explicitly penalizes three potential errors in answer triggering: (1) false-positive and (2) false-negative predictions of the existence of a correct answer, as well as <ref type="formula" target="#formula_5">(3)</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: GAT: An end-to-end deep framework to be trained with a novel group-level objective function. Rounded rectangles at the bottom represent input data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>), and use the temporal average pooling</head><label></label><figDesc></figDesc><table>DNN 
Encoder 

QA Matching 

Signed Max Pooling 

best answer 

max pooling 

Y 

Feed Forward NN 

answer existence ? 

softmax 

question 
answer candidate 
answer candidate 
answer candidate 

DNN 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>GAT framework breakdown. All variants are trained 
with our proposed objective function (Equation 1). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>ranking incorrect an- swers higher than correct ones. We experimented with different objective function settings and show that our GAT framework outperforms the previous state of the arts by a remarkable margin.</figDesc><table>Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai 
Chen. 2014. Convolutional neural network architec-
tures for matching natural language sentences. In 
Advances in neural information processing systems, 
pages 2042-2050. 

Tomasz Jurczyk, Michael Zhai, and Jinho D Choi. 
2016. Selqa: A new benchmark for selection-
based question answering. 
arXiv preprint 
arXiv:1606.08513. 

Oded Maron and Tomás Lozano-Pérez. 1998. A frame-
work for multiple-instance learning. Advances in 
neural information processing systems, pages 570-
576. 

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing 
systems, pages 3111-3119. 

Alexander Miller, Adam Fisch, Jesse Dodge, Amir-
Hossein Karimi, Antoine Bordes, and Jason We-
ston. 2016. 
Key-value memory networks for 
directly reading documents. 
arXiv preprint 
arXiv:1606.03126. 

Jinfeng Rao, Hua He, and Jimmy Lin. 2016. Noise-
contrastive estimation for answer selection with 
deep neural networks. In Proceedings of the 25th 
ACM International on Conference on Information 
and Knowledge Management, pages 1913-1916. 
ACM. 

Cícero Nogueira dos Santos, Ming Tan, Bing Xiang, 
and Bowen Zhou. 2016. Attentive pooling net-
works. CoRR, abs/1602.03609. 

Mike Schuster and Kuldip K Paliwal. 1997. Bidirec-
tional recurrent neural networks. IEEE Transactions 
on Signal Processing, 45(11):2673-2681. 

Aliaksei Severyn and Alessandro Moschitti. 2013. Au-
tomatic feature engineering for answer selection and 
extraction. In EMNLP, volume 13, pages 458-467. </table></figure>

			<note place="foot" n="1"> Our code is available at https://github.com/ jiez-osu/answer-triggering.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous review-ers for valuable comments. The computing re-sources in this work are supported by Ohio Su-percomputer Center <ref type="bibr" target="#b6">(Center, 1987)</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiple instance classification: Review, taxonomy and comparative study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaume</forename><surname>Amores</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">201</biblScope>
			<biblScope unit="page" from="81" to="105" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Support vector machines for multiple-instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Robust object tracking with online multiple instance learning. IEEE transactions on pattern analysis and machine intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1619" to="1632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1415" to="1425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multiple instance learning for sparse positive bags</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Razvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ohio Supercomputer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Center</surname></persName>
		</author>
		<ptr target="http://osc.edu/ark:/19495/f5s1ph73" />
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multiple instance learning with bag dissimilarities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronika</forename><surname>Cheplygina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Tax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Loog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="264" to="275" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A theoretical and empirical analysis of support vector machine methods for multiple-instance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Doran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="79" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Applying deep learning to answer selection: A study and an open task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidan</forename><surname>Michael R Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding (ASRU)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="813" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Solving the problem of cascading errors: Approximate bayesian inference for linguistic annotation pipelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-perspective sentence similarity modeling with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1576" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Pairwise word interaction modeling with deep neural networks for semantic similarity measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="937" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Tree edit models for recognizing textual entailments, paraphrases, and answers to questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1011" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to rank short text pairs with convolutional deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Table cell search for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web</title>
		<meeting>the 25th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="771" to="782" />
		</imprint>
	</monogr>
	<note>ternational World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Open domain question answering via semantic enrichment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1045" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved representation learning for question answer matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Inner attention based recurrent neural networks for answer selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A long short-term memory model for answer sentence selection in question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="707" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">anmm: Ranking short answer texts with attention-based neural matching model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Wikiqa: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2013" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Answer extraction as sequence tagging with tree edit distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callisonburch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLTNAACL</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="858" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Semantic parsing via staged query graph generation: Question answering with knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Abcnn: Attention-based convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Wenpeng Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.05193</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Deep learning for answer sentence selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Pulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.1632</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthew D Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<title level="m">Adadelta: an adaptive learning rate method</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction via piecewise convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In EMNLP</title>
		<imprint>
			<biblScope unit="page" from="1753" to="1762" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
