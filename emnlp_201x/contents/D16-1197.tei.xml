<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Generation of Regular Expressions from Natural Language with Minimal Domain Knowledge</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Locascio</surname></persName>
							<affiliation key="aff0">
								<address>
									<settlement>Microsoft</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
							<affiliation key="aff0">
								<address>
									<settlement>Microsoft</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Deleon</surname></persName>
							<affiliation key="aff0">
								<address>
									<settlement>Microsoft</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
							<affiliation key="aff0">
								<address>
									<settlement>Microsoft</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>MIT</roleName><forename type="first">Regina</forename><forename type="middle">Barzilay</forename><surname>Csail</surname></persName>
							<email>regina@csail.mit.edu</email>
							<affiliation key="aff0">
								<address>
									<settlement>Microsoft</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Generation of Regular Expressions from Natural Language with Minimal Domain Knowledge</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1918" to="1923"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper explores the task of translating natural language queries into regular expressions which embody their meaning. In contrast to prior work, the proposed neural model does not utilize domain-specific crafting, learning to translate directly from a parallel corpus. To fully explore the potential of neural models , we propose a methodology for collecting a large corpus 1 of regular expression, natural language pairs. Our resulting model achieves a performance gain of 19.6% over previous state-of-the-art models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper explores the task of translating natu- ral language text queries into regular expressions which embody their meaning. Regular expressions are built into many application interfaces, yet most users of these applications have difficulty writing them <ref type="bibr" target="#b2">(Friedl, 2002</ref>). Thus a system for automat- ically generating regular expressions from natural language would be useful in many contexts. Fur- thermore, such technologies can ultimately scale to translate into other formal representations, such as program scripts <ref type="bibr">(Raza et al., 2015)</ref>.</p><p>Prior work has demonstrated the feasibility of this task. <ref type="bibr" target="#b4">Kushman and Barzilay (2013)</ref> proposed a model that learns to perform the task from a parallel corpus of regular expressions and the text descrip- tions. To account for the given representational dis- parity between formal regular expressions and natu- ral language, their model utilizes a domain specific <ref type="bibr">1</ref> The corpus and code used in this paper is available at https: //github.com/nicholaslocascio/deep-regex component which computes the semantic equiva- lence between two regular expressions. Since their model relies heavily on this component, it cannot be readily applied to other formal representations where such semantic equivalence calculations are not possible.</p><p>In this paper, we reexamine the need for such spe- cialized domain knowledge for this task. Given the same parallel corpus used in <ref type="bibr" target="#b4">Kushman and Barzilay (2013)</ref>, we use an LSTM-based sequence to se- quence neural network to perform the mapping. Our model does not utilize semantic equivalence in any form, or make any other special assumptions about the formalism. Despite this and the relatively small size of the original dataset (824 examples), our neu- ral model exhibits a small 0.1% boost in accuracy.</p><p>To further explore the power of neural networks, we created a much larger public dataset, NL-RX. Since creation of regular expressions requires spe- cialized knowledge, standard crowd-sourcing meth- ods are not applicable here. Instead, we employ a two-step generate-and-paraphrase procedure that circumvents this problem. During the generate step, we use a small but expansive manually-crafted grammar that translates regular expression into nat- ural language. In the paraphrase step, we rely on crowd-sourcing to paraphrase these rigid descrip- tions into more natural and fluid descriptions. Using this methodology, we have constructed a corpus of 10,000 regular expressions, with corresponding ver- balizations.</p><p>Our results demonstrate that our sequence to se- quence model significantly outperforms the domain specific technique on the larger dataset, reaching a gain of 19.6% over of the state-of-the-art technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Regular Expressions from Natural Language There have been several attempts at generating reg- ular expressions from textual descriptions. Early re- search into this task used rule-based techniques to create a natural language interface to regular expres- sion writing <ref type="bibr" target="#b6">(Ranta, 1998)</ref>. Our work, however, is closest to <ref type="bibr" target="#b4">Kushman and Barzilay (2013)</ref>. They learned a semantic parsing translation model from a parallel dataset of natural language and regular ex- pressions. Their model used a regular expression- specific semantic unification technique to disam- biguate the meaning of the natural language descrip- tions. Our method is similar in that we require only description and regex pairs to learn.r However, we treat the problem as a direct translation task without applying any domain-specific knowledge.</p><p>Neural Machine Translation Recent advances in neural machine translation (NMT) ( <ref type="bibr">Bahdanau et al., 2014;</ref><ref type="bibr" target="#b1">Devlin et al., 2014</ref>) using the framework of se- quence to sequence learning ( <ref type="bibr" target="#b7">Sutskever et al., 2014</ref>) have demonstrated the effectiveness of deep learn- ing models at capturing and translating language se- mantics. In particular, recurrent neural networks augmented with attention mechanisms ( <ref type="bibr" target="#b5">Luong et al., 2015</ref>) have proved to be successful at handling very long sequences. In light of these successes, we chose to model regular expression generation as a neural translation problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Regex Generation as Translation</head><p>We use a Recurrent Neural Network (RNN) with at- tention ( <ref type="bibr">Mnih et al., 2014</ref>) for both encoding and decoding ( <ref type="figure" target="#fig_0">Figure 1</ref>).</p><p>Let W = w 1 , w 2 ...w m be the input text descrip- tion where each w i is a word in the vocabulary. We wish to generate the regex R = r 1 , r 2 , ...r n where each r i is a character in the regex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>We</head><p>use Long Short-Term Memory (LSTM) <ref type="bibr">(Hochreiter and Schmidhuber, 1997</ref>) cells in our model, the transition equations for which can be summarized as:</p><formula xml:id="formula_0">i t = σ(U (i) x t + V (i) h t−1 + b (i) ), f t = σ(U (f ) x t + V (f ) h t−1 + b (f ) ), o t = σ(U (o) x t + V (o) h t−1 + b (o) ) z t = tanh(U (z) x t + V (z) h t−1 + b (z) ) c t = i t z t + f t c t−1 h t = o t tanh(c t ) (1)</formula><p>where σ represents the sigmoid function and is el- ementwise multiplication. i t refers to the input gate, f t is the forget gate, and o t is the output gate at each time step. The U and V variables are weight matri- ces for each gate while the b variables are the bias parameters. The input x t is a word (w t ) for the en- coder and the previously generated character r t−1 for the decoder.</p><p>The attention mechanism is essentially a 'soft' weighting over the encoder's hidden states during decoding:</p><formula xml:id="formula_1">α t (e) = exp(score(h t , h e )) e exp(score(h t , h e ))</formula><p>where h e is a hidden state in the encoder and score is the scoring function. We use the general attention matrix weight (as described in ( <ref type="bibr" target="#b5">Luong et al., 2015)</ref>) for our scoring function. The outputs of the decoder r t are generated using a final softmax layer.</p><p>Our model is six layers deep, with one word em- bedding layer, two encoder layers, two decoder lay- ers, and one dense output layer. Our encoder and de- coder layers use a stacked LSTM architecture with a width of 512 nodes. We use a global attention mechanism ( <ref type="bibr">Bahdanau et al., 2014</ref>), which consid- ers all hidden states of the encoder when comput- ing the model's context vector. We perform standard dropout during training ( <ref type="bibr" target="#b7">Srivastava et al., 2014</ref>) after every LSTM layer with dropout probability equal to 0.25. We train for 20 epochs, utilizing a minibatch size of 32, and a learning-rate of 1.0. The learning rate is decayed by a factor 0.5 if evaluation perplex- ity does not increase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Creating a Large Corpus of Natural Language / Regular Expression Pairs</head><p>Previous work in regular expression generation has used fairly small datasets for training and evaluation.  In order to fully utilize the power of neural transla- tion models, we create a new large corpus of regular expression, natural language pairs titled NL-RX.</p><p>The challenge in collecting such corpora is that typical crowdsourcing workers do not possess the specialized knowledge to write regular expressions. To solve this, we employ a two-step generate-and- paraphrase procedure to gather our data. This tech- nique is similar to the methods used by <ref type="bibr" target="#b8">Wang et al. (2015)</ref> to create a semantic parsing corpus.</p><p>In the generate step, we generate regular expres- sion representations from a small manually-crafted grammar <ref type="table" target="#tab_0">(Table 1)</ref>. Our grammar includes 15 non- terminal derivations and 6 terminals and of both basic and high-level operations. We identify these via frequency analysis of smaller datasets from pre- vious work <ref type="bibr" target="#b4">(Kushman and Barzilay, 2013)</ref>. Ev- ery grammar rule has associated verbalizations for both regular expressions and language descriptions. We use this grammar to stochastically generate reg- ular expressions and their corresponding synthetic language descriptions. This generation process is shown in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>While the automatically generated descriptions are semantically correct, they do not exhibit rich- ness and variability of human-generated descrip- tions. To obtain natural language (non-synthetic) descriptions, we perform the paraphrase step. In this step, Mechanical Turk (Amazon, 2003) human workers paraphrase the generated synthetic descrip-  <ref type="table" target="#tab_0">Table 1</ref> are applied to a node's children and the resulting string is passed to the node's parent.  NL-RX Using the procedure described above, we create a new public dataset (NL-RX) comprising of 10,000 regular expressions and their corresponding natural language descriptions. <ref type="table" target="#tab_1">Table 2</ref> shows an ex- ample from our dataset.</p><p>Our data collection procedure enables us to create a substantially larger and more varied dataset than previously possible. Employing standard crowd- source workers to paraphrase is more cost-efficient and scalable than employing professional regex pro- grammers, enabling us to create a much larger dataset. Furthermore, our stochastic generation of regular expressions from a grammar results in a more varied dataset because it is not subject to the bias of human workers who, in previous work, wrote many duplicate examples (see Results).</p><p>Corpora Statistics Our seed regular expression grammar <ref type="table" target="#tab_0">(Table 1)</ref>, covers approximately 85% of the original KB13 regular expressions. Addition- ally, NL-RX contains exact matches with 30.1% of the original KB13 dataset regular expressions. This means that 248 of the 824 regular expressions in the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Verbalization Frequency</head><p>'the word x' 12.6% 'x before y' 9.1% 'x or y' 7.7% 'x, at least once' 6.2%</p><p>'a vowel' 5.3% KB13 dataset were also in our dataset. The aver- age length of regular expressions in NL-RX is 25.9 characters, the average in the KB13 dataset is 19.7 characters. We also computed the grammar break- down of our NL-RX. The top 5 occurring terminals in our generated regular expressions are those cor- responding with the verbalizations shown in <ref type="table" target="#tab_2">Table  3</ref>.</p><p>Crowdsourcing details We utilize Mechanical Turk for our crowdsource workers. A total of 243 workers completed the 10,000 tasks, with an average task completion time of 101 seconds. The workers proved capable of handling complex and awkward phrasings, such as the example in <ref type="table" target="#tab_1">Table 2</ref>, which is one of the most difficult in the set.</p><p>We applied several quality assurance measures on the crowdsourced data. Firstly, we ensured that our workers performing the task were of high quality, re- quiring a record of 97% accuracy over at least 1000 other previous tasks completed on Mechanical Turk. In addition, we ran automatic scripts that filtered out bad submissions (e.g. submissions shorter than 5 characters). In all, we rejected 1.1% of submissions, which were resubmitted for another worker to com- plete. The combination of these measures ensured a high quality dataset, and we confirmed this by per- forming a manual check of 100 random examples. This manual check determined that approximately 89% of submissions were a correct interpretation, and 97% were written in fluent English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Datasets We split the 10,000 regexp and descrip- tion pairs in NL-RX into 65% train, 10% dev, and 25% test sets.</p><p>In addition, we also evaluate our model on the dataset used by <ref type="bibr">Kushman and Barzilay (2013) (KB13)</ref>, although it contains far fewer data points <ref type="bibr">(824)</ref>. We use the 75/25 train/test split used in their work in order directly compare our performance to theirs.</p><p>Training We perform a hyper-parameter grid- search (on the dev set), to determine our model hyper-parameters: learning-rate = 1.0, encoder- depth = 2, decoder-depth = 2, batch size = 32, dropout = 0.25. We use a Torch ( <ref type="bibr" target="#b1">Collobert et al., 2002</ref>) implementation of attention sequence to se- quence networks from <ref type="bibr" target="#b3">(Kim, 2016)</ref>. We train our models on the train set for 20 epochs, and choose the model with the best average loss on the dev set.</p><p>Evaluation Metric To accurately evaluate our model, we perform a functional equality check called DFA-Equal. We employ functional equality because there are many ways to write equivalent reg- ular expressions. For example, (a|b) is functionally equivalent to (b|a), despite their string representa- tions differing. We report DFA-Equal accuracy as our model's evaluation metric, using <ref type="bibr" target="#b4">Kushman and Barzilay (2013)</ref>'s implementation to directly com- pare our results.</p><p>Baselines We compare our model against two baselines:</p><p>BoW-NN: BoW-NN is a simple baseline that is a Nearest Neighbor classifier using Bag Of Words representation for each natural language description. For a given test example, it finds the closest cosine- similar neighbor from the training set and uses the regexp from that example for its prediction.</p><p>Semantic-Unify: Our second baseline, Semantic- Unify, is the previous state-of-the-art model from <ref type="bibr" target="#b4">(Kushman and Barzilay, 2013)</ref>, explained above. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Our model significantly outperforms the baselines on the NL-RX dataset and achieves comparable per- formance to Semantic Unify on the KB13 dataset <ref type="table" target="#tab_4">(Table 4)</ref>. Despite the small size of KB13, our model achieves state-of-the-art results on this very resource-constrained dataset (824 examples). Using NL-RX, we investigate the impact of training data size on our model's accuracy. <ref type="figure" target="#fig_4">Figure 3</ref> shows how    Differences in Datasets Keeping the previous section in mind, a seemingly unusual finding is that the model's accuracy is higher for the smaller dataset, KB13, than for the larger dataset, NL-RX- Turk. On further analysis, we learned that the KB13 dataset is a much less varied and complex dataset than NL-RX-Turk. KB13 contains many dupli- cates, with only 45% of its regular expressions be- ing unique. This makes the translation task easier because over half of the correct test predictions will be exact repetitions from the training set. In con- trast, NL-RX-Turk does not suffer from this vari- ance problem and contains 97% unique regular ex- pressions. The relative easiness of the KB13 dataset is further illustrated by the high performance of the Nearest-Neighbor baselines on the KB13 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper we demonstrate that generic neu- ral architectures for generating regular expressions outperform customized, heavily engineered mod- els. The results suggest that this technique can be employed to tackle more challenging problems in broader families of formal languages, such as mapping between language description and program scripts. We also have created a large parallel corpus of regular expressions and natural language queries using typical crowd-sourcing workers, which we make available publicly.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Deep-Regex Encoder-Decoder setup. Blue cells represent the encoder and the green ones represent the decoder.</figDesc><graphic url="image-1.png" coords="3,72.00,57.83,226.79,59.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Process for generating Synthetic Descriptions from Regular Expressions. Grammar rules from Table 1 are applied to a node's children and the resulting string is passed to the node's parent.</figDesc><graphic url="image-2.png" coords="3,313.20,57.83,226.79,173.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Synthetic: lines not words with starting with a capital letter Paraphrased: lines that do not contain words that begin with a capital letter Regex: ∼ (\b([A-Z])(.*)\b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Models</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Our model's performance, like many deep learning models, increases significantly with larger datasets. String-Equal:Accuracy on direct string match, DFA-Equal:Accuracy using the DFA-Equal evaluation.</figDesc><graphic url="image-3.png" coords="5,72.00,189.78,226.80,185.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Regex → Synthetic Grammar for Data Genera-
tion 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>NL-RX Text Descriptions and Regular Expres- sion tions into the fluent verbalizations.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Top Frequent Verbalizations from NL-RX 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>DFA-Equal accuracy on different datasets. 
KB13: Dataset from Kushman and Barzilay(2013), NL-
RX-Synth: NL Dataset with original synthetic descrip-
tions, NL-RX-Turk: NL Dataset with Mechanical Turk 
paraphrased descriptions. Best scores are in bold. 

</table></figure>

			<note place="foot" n="2"> We trained and evaluated Semantic-Unify in consultation with the original authors.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their helpful feedback and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amazon</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
		<ptr target="https://mturk.com" />
		<imprint>
			<date type="published" when="2003" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Bahdanau et al.2014] Dzmitry Bahdanau</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast and robust neural network joint models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collobert</surname></persName>
		</author>
		<ptr target="https://torch.ch" />
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1370" to="1380" />
		</imprint>
	</monogr>
	<note>Torch: A modular machine learning software library</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mastering regular expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Friedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sepp Hochreiter and Jürgen Schmidhuber</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
		</imprint>
	</monogr>
	<note>Long short-term memory</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<ptr target="https://github.com/harvardnlp/seq2seq-attn" />
		<title level="m">Seq2seq-attn</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using semantic unification to generate regular expressions from natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Luong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal; Alex Graves</addrLine></address></meeting>
		<imprint>
			<publisher>Nicolas Heess</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2204" to="2212" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A multilingual naturallanguage interface to regular expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aarne</forename><surname>Ranta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mohammad Raza, Sumit Gulwani, and Natasa Milic-Frayling. 2015. Compositional program synthesis from natural language and examples. International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="79" to="90" />
		</imprint>
	</monogr>
	<note>Proceedings of the International Workshop on Finite State Methods in Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
	<note>Ilya Sutskever, Oriol Vinyals,</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Building a semantic parser overnight</title>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
