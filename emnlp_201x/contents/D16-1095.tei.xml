<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A General Regularization Framework for Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>November 1-5, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
							<email>luwei@sutd.edu.sg, chaileon@dso.org.sg,</email>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology</orgName>
								<address>
									<country>Design</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><forename type="middle">Leong</forename><surname>Chieu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">DSO National Laboratories</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Löfgren</surname></persName>
							<email>lofgren021@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Uppsala University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A General Regularization Framework for Domain Adaptation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="950" to="954"/>
							<date type="published">November 1-5, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a domain adaptation framework, and formally prove that it generalizes the feature augmentation technique in (Daumé III, 2007) and the multi-task regularization framework in (Evgeniou and Pontil, 2004). We show that our framework is strictly more general than these approaches and allows practitioners to tune hyper-parameters to encourage transfer between close domains and avoid negative transfer between distant ones.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Domain adaptation (DA) is an important problem that has received substantial attention in natural lan- guage processing <ref type="bibr" target="#b0">(Blitzer et al., 2006;</ref><ref type="bibr" target="#b4">Daumé III, 2007;</ref><ref type="bibr" target="#b6">Finkel and Manning, 2009;</ref><ref type="bibr" target="#b3">Daumé III et al., 2010)</ref>. In this paper, we propose a novel regular- ization framework which allows DA practitioners to tune hyper-parameters to encourage transfer be- tween close domains, and avoid negative transfer ( <ref type="bibr" target="#b13">Rosenstein et al., 2005</ref>) between distant ones. In our framework, model parameters in multiple do- mains are learned jointly and constrained to remain close to one another. In the transfer learning tax- onomy ( <ref type="bibr" target="#b12">Pan and Yang, 2010)</ref>, our framework falls under the parameter-transfer category for multi-task inductive learning. We show that our framework generalizes the frustratingly easy domain adapta- tion (FEDA) in <ref type="bibr" target="#b4">Daumé III (2007)</ref>, <ref type="bibr" target="#b6">Finkel and Manning (2009)</ref>, and the regularised multi-task learning of <ref type="bibr" target="#b5">Evgeniou and Pontil (2004)</ref>. At the same time, it provides us with hyper-parameters to control the amount of transfer between domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Domain Adaptation Framework</head><p>Given labeled data from N domains, D 1 , . . . , D N , traditional machine learning maximizes the follow- ing objective function for each domain D i :</p><formula xml:id="formula_0">O(D i ; w i ) = L i (D i ; w i ) − λ i ||w i || 2 ,<label>(1)</label></formula><p>and we maximize L i by tuning the parameter vector w i . For example, L i can be the log-likelihood or the negative hinge loss. The term λ i ||w i || 2 is the L 2 - regularization term where λ i is a positive scalar. In our framework, we propose to maximize</p><formula xml:id="formula_1">N i=1 L i (D i ; w i ) − N i=1 η 0,i ||w i || 2 − 1≤j&lt;k≤N η j,k ||w j − w k || 2 ,<label>(2)</label></formula><p>where η j,k are parameters controlling the transfer between domains. In the next sections, we show how our framework generalizes existing works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Frustratingly Easy DA</head><p>The FEDA approach was introduced by Daumé III (2007) and later formalized by Finkel and Man- ning (2009) within a hierarchical Bayesian DA framework. While simple, the approach has often been shown to be effective. In this section, we show that our framework generalizes the FEDA approach.</p><p>The FEDA approach defines a new augmented feature space by duplicating each feature in D i to a "general" domain. Therefore each parameter in w i has a corresponding parameter in w 0 , and:</p><formula xml:id="formula_2">L i (D i ; w i , w 0 ) = L i (D i ; w i + w 0 )<label>(3)</label></formula><p>This directly leads to the following remark:</p><formula xml:id="formula_3">Remark For all i, for any w i , w 0 , d ∈ R m : L i (D i ; w i + d, w 0 − d) = L i (D i ; w i , w 0 )</formula><p>The complete objective function involving N (N ≥ 2) domains is defined as follows:</p><formula xml:id="formula_4">O (D; , w 0 , w 1 , . . . , w N ) = N i=1 L i (D i ; w i , w 0 ) − N i=0 λ i ||w i || 2</formula><p>We first prove the following relation:</p><formula xml:id="formula_5">Lemma 2.1 Assume (w * 0 , ..., w * N ) = arg max w 1 ,...,w N ,w 0 N i=1 L i (D i ; w i , w 0 ) − λ 0 ||w 0 || 2 + N i=1 λ i ||w i || 2 ,</formula><p>where λ 0 , λ 1 , . . . , λ N &gt; 0, then:</p><formula xml:id="formula_6">λ 0 w * 0 = N i=1 λ i w * i (4)</formula><p>Proof Let's introduce the vector d as follows:</p><formula xml:id="formula_7">d = 1 N i=0 λ i λ 0 w * 0 − N i=1 λ i w * i (5) Denote (w 0 , . . . , w N ) such that ∀ 0 ≤ i ≤ N , w i = w * i + d, and w 0 = w * 0 − d. Based on the remark, L i (D i ; w i , w 0 ) = L i (D i ; w * i , w * 0 ). Let ∆ = O (D; w 0 , . . . , w N ) − O (D; w * 0 , . . . , w * N ). Since (w * 0 , . . . , w * N ) is optimal, ∆ ≤ 0. Moreover, ∆ = N i=1 L i (D i ; w i , w 0 ) − N i=0 λ i ||w i || 2 − N i=1 L i (D i ; w * i , w * 0 ) + N i=0 λ i ||w * i || 2 = λ 0 ||w * 0 || 2 − λ 0 ||w * 0 − d|| 2 + N i=1 λ i ||w * i || 2 − N i=1 λ i ||w * i + d|| 2 = − N i=0 λ i ||d|| 2 + 2d · λ 0 w * 0 − N i=1 λ i w * i = − N i=0 λ i ||d|| 2 + 2d · N i=0 λ i d = N i=0 λ i ||d|| 2 ≥ 0</formula><p>Hence, ∆ = 0 implying ||d|| = 0 and so d = 0. From the definition of d, Equation 4 holds.</p><p>Next we state the following lemma (see supple- mentary material for the proof).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2.2 For any vectors</head><formula xml:id="formula_8">v 1 , v 2 , . . . , v N ∈ R m , any scalars λ 0 , λ 1 , . . . , λ N ∈ R + , let v 0 = ( N i=1 λ i v i )/λ 0</formula><p>, then the following always holds:</p><formula xml:id="formula_9">λ 0 ||v 0 || 2 + N i=1 λ i ||v i || 2 = N i=1 η 0,i ||v i + v 0 || 2 + 1≤j&lt;k≤N η j,k ||v j − v k || 2 ,</formula><p>where</p><formula xml:id="formula_10">η i,j = λ i λ j N l=0 λ l , ∀ 0 ≤ i &lt; j ≤ N.</formula><p>Now we state and prove the following theorem, which shows our framework generalizes FEDA.</p><formula xml:id="formula_11">Theorem 2.3 For λ 0 , λ 1 , . . . , λ N ∈ R + , define ∀0 ≤ i &lt; j ≤ N, η i,j = λ i λ j N l=0 λ l ,</formula><p>the following holds:</p><formula xml:id="formula_12">max w 1 ,w 2 ,...,w N ,w 0 N i=1 L i (D i ; w i , w 0 ) − λ 0 ||w 0 || 2 + N i=1 λ i ||w i || 2 = max w 1 ,w 2 ,...,w N N i=1 L i (D i ; w i ) −   N i=1 η 0,i ||w i || 2 + 1≤j&lt;k≤N η j,k ||w j − w k || 2     Proof Let (w * 0 , . . . , w * N )</formula><p>be a solution to the first optimization problem. We have:</p><formula xml:id="formula_13">LHS = N i=1 L i (D i ; w * i , w * 0 ) − λ 0 ||w * 0 || 2 + N i=1 λ i ||w * i || 2<label>(6)</label></formula><p>Lemma 2.1 gives</p><formula xml:id="formula_14">w * 0 = N i=1 λ i w * i /λ 0 . In- troduce w i = w * i + w * 0 . Using Lemma 2.2, we have: LHS = N i=1 L i (D i ; w * i , w * 0 ) −   N i=1 η 0,i ||w * i + w * 0 || 2 + 1≤j&lt;k≤N η j,k ||w * j − w * k || 2   = N i=1 L i (D i ; w i ) −   N i=1 η 0,i ||w i || 2 + 1≤j&lt;k≤N η j,k ||w j − w k || 2   ≤ RHS Now, let (w * 1 , w * 2 , . . . , w * N )</formula><p>be an optimal so- lution to the second problem. Given the rela- tion between η i,j and λ 0 , λ 1 , . . . , λ N , let</p><formula xml:id="formula_15">w 0 = N i=1 λ i w * i / N l=0 λ l</formula><p>, and w i = w * i − w 0 . We show in the supplementary material that</p><formula xml:id="formula_16">w 0 = 1 λ 0 N i=1 λ i w i<label>(7)</label></formula><p>Based on these and Lemma 2.2, we have:</p><formula xml:id="formula_17">RHS = N i=1 L i (D i ; w * i ) −   N i=1 η 0,i ||w * i || 2 + 1≤j&lt;k≤N η j,k ||w * j − w * k || 2   = N i=1 L i (D i ; w i + w 0 ) −   N i=1 η 0,i ||w i + w 0 || 2 + 1≤j&lt;k≤N η j,k ||w j − w k || 2   = N i=1 L i (D i ; w i , w 0 ) − λ 0 ||w 0 || 2 + N i=1 λ i ||w i || 2 ≤ LHS</formula><p>Therefore we must have LHS = RHS.</p><p>This formally shows that FEDA is equivalent to solving the objective function given in Equation 2. In this new optimization problem, if we drop the terms involving η j,k for j = 0, we have:</p><formula xml:id="formula_18">N i=1 L i (D i ; w i ) − η 0,i ||w i || 2<label>(8)</label></formula><p>This is learning without domain adaptation. The ad- ditional regularization terms allow us keep the pa- rameters from different domains close to one other. In the special case with two domains, if we use the same λ for all regularization terms, we have the fol- lowing corollary:</p><p>Corollary 2.4 For any λ &gt; 0:</p><formula xml:id="formula_19">max w 1 ,w 2 ,w 0 L 1 (D 1 ; w 1 , w 0 ) + L 2 (D 2 ; w 2 , w 0 ) −λ ||w 1 || 2 + ||w 2 || 2 + ||w 0 || 2 = max w 1 ,w 2 L 1 (D 1 ; w 1 ) + L 2 (D 2 ; w 2 ) − 1 3 λ ||w 1 || 2 + ||w 2 || 2 + ||w 1 − w 2 || 2</formula><p>Hence, the FEDA feature augmentation tech- nique indirectly introduces a regularization term that pushes the source and target parameters as close as possible. This is related to the technique of <ref type="bibr" target="#b2">Chelba and Acero (2006)</ref> where they regularize the model parameters for the target domain using the term λ||w − w s ||, where w s is the parameter vec- tor learned from the source domain. The difference here is, in their work the parameters for the source domain are learned first and then fixed. The rela- tion between their work and the feature augmenta- tion technique was also briefly discussed in the paper of <ref type="bibr" target="#b4">Daumé III (2007)</ref>. We formally showed a precise relation here in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Regularized Multi-task Learning</head><p>Evgeniou and Pontil (2004) proposed multi-task regularized learning using support vector machines (SVM). They decomposed the model weight vector as a sum of domain-specific vectors and a general vector, in much the same way as FEDA 1 . Hence, both Lemma 2.1 and Theorem 2.3 of this paper ap- ply, and our framework also generalizes multi-task regularized learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>In this section we apply our framework to both struc- tured and un-structured tasks. For structured pre- diction, we use the named-entity recognition (NER) ACE-2005 dataset with 7 classes and 6 domains. We apply the linear chain CRF ( <ref type="bibr" target="#b8">Lafferty et al., 2001</ref>), and show results using standard and softmax- margin CRF (SM-CRF) ( <ref type="bibr" target="#b7">Gimpel and Smith, 2010)</ref>, with features consisting of word shape features, neighboring words, previous prediction and pre- fixes/suffixes. The second task is sentiment classi- fication on the Amazon review data set <ref type="bibr" target="#b1">(Blitzer et al., 2007</ref>) from 4 domains, labeled positive or neg- ative. We apply logistic regression (LR) and SVM using unigram and bigram features. All the mod- els used in this section are implemented on top of a common framework, which was also used to im- plement various structured prediction models previ- ously <ref type="bibr" target="#b10">(Lu, 2015;</ref><ref type="bibr" target="#b9">Lu and Roth, 2015;</ref><ref type="bibr" target="#b11">Muis and Lu, 2016</ref>   AUG The FEDA approach, and RF Our proposed regularization framework.</p><p>We use a 40/30/30 train-development-test split and report the results on the test set. The regularization parameters were tuned on the development set over a logarithmic scale between 10 −3 to 10 3 . For our framework, we used random search to tune the pa- rameters, since an exhaustive search is too expen- sive (21 parameters for 6 domains). We choose the within-domain η 0,i to be close to those used for the ALL and AUG model, while choosing the other η j,k to be 1-2 orders of magnitude higher. A good model could quickly be found that generally beats the base- lines on the development set and also generalizes well to the test set. We show the results for NER in <ref type="table" target="#tab_1">Table 1</ref> and the sentiment task in <ref type="table" target="#tab_2">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>953</head><p>Our proof did not require any assumption about L, as long as L 2 regularization is used. This means our result is applicable to a variety of models such as SVM, LR, and CRF (where L 2 regularization is used for the latter two models). Theoretically, we have shown the equivalence of DA optimiza- tion problems. Empirically, for non-convex objec- tives, different approaches may arrive at different solutions. However, for convex loss functions, our objective (Equation 2) is also convex, and all ap- proaches should share the same solution. We have shown that we can map the FEDA opti- mization problem to our framework. The converse is false: for any problem in this family (with arbi- trary choices of η), we can only solve it using FEDA if there are only 2 domains, or if all regularization hyper-parameters are equal. Some parameter con- figurations in this family are "unreachable" by the feature augmentation technique. This is because in Theorem 2.3, the values of η's are defined based on λ's and therefore possess certain properties. For ex- ample, they must at least satisfy such constraints as η i,k η k,j = η i,l η l,j for any i ≤ k, l ≤ j. We have seen that some of those unreachable problems could give us better empirical results. Can we find an alterna- tive simple adaptation method such that all problems in this family are "reachable"? This is a question that needs to be addressed in future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we presented a framework for do- main adaptation that generalizes several previous works <ref type="bibr" target="#b4">(Daumé III, 2007;</ref><ref type="bibr" target="#b6">Finkel and Manning, 2009;</ref><ref type="bibr" target="#b5">Evgeniou and Pontil, 2004</ref>). Our approach allows practitioners to specify the amount of transfer be- tween domains via regularization hyper-parameters. These parameters could be tuned based on intu- ition or using held-out data. In future work we could also seek to find methods that can auto- matically optimize these parameters. The sup- plementary material of this paper is available at http://statnlp.org/research/ml/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>F-score on the ACE NER task. The domains are 
broadcast conversations (bc), broadcast news (bn), conversa-
tional telephone speech (cts), newswire (nw), usenet (un) and 
weblog (wl). The macro-average (avg) over the 6 domains is 
also shown in the table. 

Model Dom. 
TGT 
ALL 
AUG 
RF 

LR 

book 
75.83 79.33 79.00 
80.67 
dvd 
82.17 82.83 
83.83 83.83 
elec. 
84.67 84.67 
84.83 84.83 
kit. 
83.83 86.33 86.17 
87.33 
avg 
81.63 83.29 83.46 
84.17 

SVM 

book 
76.83 80.67 80.33 
81.00 
dvd 
83.17 83.17 82.50 
84.00 
elec. 
85.00 
86.50 
85.83 85.67 
kit. 
86.33 85.83 
88.33 
87.83 
avg 
82.83 84.04 84.25 
84.63 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Accuracies on the sentiment classification task. The 
domains are books (book), dvds (dvd), electronics (elec.) and 
kitchen (kit.). The macro-average (avg) over the four domains 
are also shown in the table. 

</table></figure>

			<note place="foot" n="1"> They proved in Lemma 2.1 in their paper a similar relationship to Equation 4, but their proof assumes a SVM framework, and that λ1=λ2=.. . =λN .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank the anonymous reviewers for their helpful comments, and Zhanming Jie for his help on this work. The experiments of this work were done when Jonathan Löfgren was a visiting student at Singapore University of <ref type="bibr">Technology and Design (SUTD)</ref>. This work is supported by MOE Tier 1 grant SUTDT12015008.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Domain adaptation with structural correspondence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adaptation of maximum entropy capitalizer: Little data can help a lot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciprian</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="382" to="399" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Frustratingly easy semi-supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avishek</forename><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2010 Workshop on Domain Adaptation for Natural Language Processing</title>
		<meeting>2010 Workshop on Domain Adaptation for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Regularized multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodoros</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hierarchical bayesian domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Softmaxmargin crfs: Training log-linear models with cost functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint mention extraction and classification with mention hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Constrained semantic forests for improved discriminative semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL/IJCNLP</title>
		<meeting>ACL/IJCNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Weak semimarkov crfs for noun phrase chunking in informal text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldrian</forename><surname>Obaja Muis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">To transfer or not to transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">T</forename><surname>Rosenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zvika</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Pack Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;05 Workshop, Inductive Transfer: 10 Years Later</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
