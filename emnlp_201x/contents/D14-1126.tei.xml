<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Sentiment-aligned Topic Model for Product Aspect Rating Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computing Science</orgName>
								<orgName type="department" key="dep2">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University Burnaby</orgName>
								<address>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
							<email>ester@sfu.ca</email>
							<affiliation key="aff1">
								<orgName type="institution">Simon Fraser University Burnaby</orgName>
								<address>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Sentiment-aligned Topic Model for Product Aspect Rating Prediction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1192" to="1202"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Aspect-based opinion mining has attracted lots of attention today. In this paper, we address the problem of product aspect rating prediction, where we would like to extract the product aspects, and predict aspect ratings simultaneously. Topic models have been widely adapted to jointly model aspects and sentiments, but existing models may not do the prediction task well due to their weakness in sentiment extraction. The sentiment topics usually do not have clear correspondence to commonly used ratings, and the model may fail to extract certain kinds of sentiments due to skewed data. To tackle this problem , we propose a sentiment-aligned topic model(SATM), where we incorporate two types of external knowledge: product-level overall rating distribution and word-level sentiment lexicon. Experiments on real dataset demonstrate that SATM is effective on product aspect rating prediction, and it achieves better performance compared to the existing approaches.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Online reviews have become an important source of information for consumers. People tend to read reviews to help them compare products, and make informed decisions. As the volume of product re- views continues to grow, it is often impossible to read all of them, which calls for efficient methods for opinion mining. Nowadays, for each product, many websites aggregate the overall rating of re- views, and display its distribution. However, this cannot provide detailed information. For exam- ple, two products may have similar overall rating distributions, while people talk about different un- satisfactory aspects. This problem has inspired a new line of research on aspect-level opinion min- ing( <ref type="bibr" target="#b8">Hu and Liu, 2004</ref>).</p><p>An aspect refers to a rateable feature, such as staff and location in hotel reviews, or size and battery for digital camera reviews. In this paper, we deal with the problem of product aspect rat- ing prediction. The input is a collection of prod- ucts, and each product is associated with a set of reviews. The goal is to extract the corpus-level as- pects, and predict the aspect ratings for each prod- uct. This kind of fine-grained sentiment analysis will help users efficiently digest the reviews, and gain more insight into the product quality.</p><p>The product aspect rating prediction problem usually involves two subtasks: aspect extraction and sentiment identification <ref type="bibr" target="#b30">(Titov and McDonald, 2008b)</ref>. Given some text, we would like to know what aspects it talks about, and what kind of sen- timents are expressed. For example, given a sen- tence "the room is filthy", we would like to know that it talks about the aspect "room". Also, "filthy" is a sentiment word, and it expresses strongly neg- ative sentiment towards the aspect "room".</p><p>Topic models( <ref type="bibr" target="#b3">Blei et al., 2003;</ref><ref type="bibr" target="#b7">Hofmann, 1999</ref>) have been popular in aspect-based opinion min- ing( <ref type="bibr" target="#b16">Liu, 2012)</ref>. Existing works have used topic models to extract only aspects <ref type="bibr" target="#b29">(Titov and McDonald, 2008a;</ref><ref type="bibr" target="#b4">Brody and Elhadad, 2010;</ref>), or jointly model aspects and sentiments <ref type="bibr" target="#b19">(Mei et al., 2007;</ref><ref type="bibr" target="#b15">Lin and He, 2009;</ref><ref type="bibr" target="#b10">Jo and Oh, 2011;</ref><ref type="bibr" target="#b21">Moghaddam and Ester, 2011;</ref><ref type="bibr" target="#b12">Lakkaraju et al., 2011;</ref><ref type="bibr" target="#b27">Sauper et al., 2011;</ref><ref type="bibr" target="#b24">Mukherjee and Liu, 2012;</ref><ref type="bibr" target="#b13">Lazaridou et al., 2013;</ref><ref type="bibr" target="#b23">Moghaddam and Ester, 2013;</ref><ref type="bibr" target="#b11">Kim et al., 2013</ref>). In the joint modelling approaches, a sentiment topic is usually modelled as a sentiment label-word dis- tribution, analogous to the topic-word distribution in standard topic models. However, the difference is that the sentiment topics need to be ordered. If the model is to be applied for aspect rating predic- tion, the sentiment topics should have clear cor-respondence to the ratings. Suppose there are 5 sentiment topics with sentiment labels from 1 to 5. The sentiment topic with label i is expected to correspond to the rating i on the 1-5 rating scale. For example, the sentiment topic with label 5 should have high probability over positive sen- timent words, so it expresses highly positive sen- timent, which matches our natural interpretation for the rating 5. In this case, sentiment labels and ratings are aligned. However, in a standard topic model, the learned sentiment topics may not have clear correspondence with different ratings. Also, if the positive reviews are dominant in the data, the topic model may fail to capture the negative sen- timents with any sentiment topic, so no sentiment labels are matched with low ratings. If the senti- ment labels are not correctly aligned to the ratings, we cannot use these sentiment labels to predict as- pect ratings. Consequently, the aspect rating pre- diction accuracy is compromised, and the method is less practical. We call this the sentiment label alignment problem. To tackle this problem, mod- els in the literature usually use some seed words for each sentiment topic to define Dirichlet priors with asymmetric concentration parameter vectors <ref type="bibr" target="#b27">(Sauper et al., 2011;</ref><ref type="bibr" target="#b11">Kim et al., 2013)</ref>, or use seed words to initialize word assignment to sentiment topic( <ref type="bibr" target="#b15">Lin and He, 2009)</ref>, or both( <ref type="bibr" target="#b10">Jo and Oh, 2011</ref>). However, these seed words are usually arbitrarily selected, and how to define asymmetric priors is not clear, especially when we would like to capture more than two (positive and negative) kinds of sentiments.</p><p>In this paper, we propose a sentiment-aligned topic model(SATM) for product aspect rating pre- diction, which focuses the sentiment label align- ment problem. We use two kinds of external knowledge: the product overall rating distribution, and a sentiment lexicon. For each product, the overall rating distribution is available on most on- line review websites. It provides the big picture of the product-level sentiments. In SATM, for each product and each aspect, we define a multinomial distribution over sentiment labels, with prior pa- rameterized by the overall rating distribution. Sen- timent lexicon is constructed by linguistic experts, and every word in the lexicon is associated with a sentiment polarity score <ref type="bibr" target="#b28">(Taboada et al., 2011</ref>). We treat the polarity score as an extra word feature in a semi-supervised framework. By incorporat- ing both product-level and word-level knowledge into the model, the sentiment labels can be aligned with ratings, and the extracted sentiment topics can capture different kinds of sentiments, ranging from highly positive to highly negative. Experi- ments on a TripAdvisor dataset demonstrate that our method can effectively deal with the sentiment label alignment problem, and outperforms state- of-the-art methods in terms of product aspect rat- ing prediction accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Several methods have been proposed for product aspect rating prediction, and many of them are based on topic models.</p><p>In ( <ref type="bibr" target="#b18">Lu et al., 2009)</ref>, the authors studied the prob- lem of generating an aspect rating summary for short comments. The text was first preprocessed into phrases of the format &lt;headterm, sentiment word&gt;, and the headterms are clustered by Struc- tured PLSA to find K major aspects. Then, phrase ratings are predicted by either Local Prediction or Global Prediction, and they are aggregated to get aspect ratings. The method in <ref type="bibr" target="#b4">(Brody and Elhadad, 2010</ref>) also first uses topic models to find as- pects. Then, for each aspect, it extracts all the rel- evant adjectives, and builds a conjunction graph. A label propagation algorithm( <ref type="bibr" target="#b35">Zhu and Ghahramani, 2002</ref>) is used on the graph to learn the senti- ment polarity score of adjective words. Although this approach is not proposed for aspect rating pre- diction, it can be used for this task if the polar- ity scores of adjective words are aggregated for each aspect. All the methods above perform as- pect extraction and sentiment identification sepa- rately, while our approach takes a joint modelling approach so that different subtasks can potentially reinforce with each other. To demonstrate this, we use these methods as baselines in our experiments.</p><p>Wang et al. worked on the Latent Aspect Rat- ing Analysis problem( <ref type="bibr" target="#b32">Wang et al., 2010;</ref><ref type="bibr" target="#b33">Wang et al., 2011</ref>), the task of inferring aspect ratings for each review and the relative weights review- ers have placed on each aspect. In ( <ref type="bibr" target="#b32">Wang et al., 2010)</ref>, aspect keywords are provided as user input, and a two-stage method, called Latent Rating Re- gression(LRR), is proposed. The first stage uses a bootstrapping algorithm to obtain more related words for each aspect, and segments the document content. In the second stage, the overall rating is "generated" as weighted combination of the latent aspect ratings, and LRR is used to infer both the weights and aspect ratings. Their follow-up work ( <ref type="bibr" target="#b33">Wang et al., 2011</ref>) does not need keyword speci- fication from users, and replaces the bootstrapping method with a topic model. However, both meth- ods implicitly require that each review talks about all aspects, which is not always true due to the data sparsity in online reviews.</p><p>In ( <ref type="bibr" target="#b21">Moghaddam and Ester, 2011</ref>), ILDA was proposed for product aspect rating prediction. Later, it was extended to FLDA <ref type="bibr" target="#b23">(Moghaddam and Ester, 2013)</ref> to address the cold start prob- lem, when there are few reviews associated with a product. Similar to ( <ref type="bibr" target="#b18">Lu et al., 2009)</ref>, in ILDA and FLDA, a preprocessing step parses the text into phrases of the format &lt;headterm, sentiment word&gt;, and a review is modelled as a bag of phrases. We also adopt this assumption in our model. The method in <ref type="bibr" target="#b27">(Sauper et al., 2011;</ref><ref type="bibr" target="#b26">Sauper and Barzilay, 2013</ref>) does not use phrases, but in- stead uses "snippets", and an snippet is a short sentence or phrase. However, the sentiment label alignment problem is not well addressed in these models, which limits their practicality. ILDA and FLDA did not deal with this problem. The model in <ref type="bibr" target="#b27">(Sauper et al., 2011;</ref><ref type="bibr" target="#b26">Sauper and Barzilay, 2013</ref>) follows the most common approach of using seed words to define asymmetric priors. It supports only two kinds of sentiment topics: pos- itive and negative, while how to define asymmet- ric priors for more sentiment topics becomes un- clear. More importantly, the prior approach may not work well in practice(see Experiment Section). Lakkaraju et al. try to tackle the sentiment label alignment problem by assuming that the overall rating is generated as response variable( <ref type="bibr" target="#b12">Lakkaraju et al., 2011)</ref>, with the sentiment topic propor- tions as features. However, how the sentiment la- bels are related to ratings is still unknown until learned, and we may not get the desired alignment. Lazaridou et al. attempt to connect sentiment la- bels with ratings by Kronecker symbol, but this method only applies to three sentiment polarities: −1(negative), 0(neutral), +1(positive), and it does not explore the word-level lexicon, which is also an important source of knowledge.</p><p>Another line of research on product aspect rat- ing prediction or summarization does not use topic models, but relies mainly on word frequency and grammatical relations( <ref type="bibr" target="#b8">Hu and Liu, 2004;</ref><ref type="bibr" target="#b25">Popescu and Etzioni, 2005;</ref><ref type="bibr" target="#b2">Blair-goldensohn et al., 2008)</ref>, or specialized review selection( <ref type="bibr" target="#b17">Long et al., 2014</ref>).</p><p>In this case, the extracted aspect words need to be clustered manually. For example, picture and photo may refer to the same aspect in digital cam- era reviews. By comparison, topic modelling ap- proaches extract aspect words and cluster them si- multaneously.</p><p>Our method incorporates the product overall rating distributions and sentiment lexicons into the model, so it is also related to topic models which use observed features or domain knowl- edge( <ref type="bibr" target="#b20">Mimno and McCallum, 2008;</ref><ref type="bibr" target="#b0">Andrzejewski et al., 2009;</ref><ref type="bibr" target="#b1">Andrzejewski et al., 2011</ref>). Mimno et al. introduces two general frameworks to integrate observed features into the generative process: downstream and upstream topic models <ref type="bibr" target="#b20">(Mimno and McCallum, 2008)</ref>. In the context of aspect- based opinion mining, MaxEnt-LDA( <ref type="bibr" target="#b34">Zhao et al., 2010</ref>) integrates a discriminative maximum en- tropy component to help separate aspect words and sentiment words. The SAS model (Mukherjee and Liu, 2012) uses seed words to provide guid- ance for aspect discovery, and MC-LDA ( ) uses must-links and cannot-links to ex- tract coherent aspects. However, MaxEnt-LDA, SAS and MC-LDA cannot be used for aspect rat- ing prediction, since they fail to identify the senti- ment polarity of sentiment words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminaries</head><p>We first introduce several key concepts used in our model.</p><p>Products: Let P = {P 1 , P 2 , . . . } be a set of products. Each product P i is associated with a set of reviews D i = {d 1 , d 2 , . . . d N i }, and also an overall rating distribution Y i . Y i is a multinomial distribution on R ratings. It is available on most online review websites, and usually R = 5.</p><p>Aspects: An aspect is a rateable feature of a product, and each aspect is modelled as a distribu- tion over aspect words. The number of aspects is predefined as K.</p><p>Sentiment topics: A sentiment topic is mod- elled as a distribution over sentiment words, and each sentiment topic is associated with a sentiment label. To make it consistent with commonly used rating scale, we assume there are R sentiment la- bels, corresponding to the R ratings. The chal- lenge is that sentiment labels with higher values are expected to be associated with sentiment top- ics which express more positive sentiments, so that we can match sentiment labels with ratings.</p><p>Phrases: An opinion phrase f =&lt; h, m &gt; is a pair of aspect word h and sentiment word m, such as &lt; room, f ilthy &gt;( <ref type="bibr" target="#b18">Lu et al., 2009;</ref><ref type="bibr" target="#b21">Moghaddam and Ester, 2011</ref>). For each product P i , we first parse the related reviews D i into phrases F i , and each product can be modelled as a bag of phrases.</p><p>Sentiment lexicons : A sentiment lexicon L is a list of sentiment words, and each word m ∈ L is associated with a sentiment polarity score s m . s m can take T values. Note that the lexicon L usually only covers a small subset of sentiment words in the whole vocabulary.</p><p>Sentiment association: The sentiment label takes R values, and there are T different values for the polarity score in the sentiment lexicon. How- ever, the relation between sentiment labels and po- larity scores are unknown. If we have training in- stances where a sentiment word m is associated with both a sentiment label r m and polarity score s m , we can build a classifier, where the explana- tory variable for the classifier is a sentiment label, and outcome is the polarity score. In this case, H(s m |r m ) can be interpreted as the probability of observing a polarity score s m , given its sentiment label r m . We refer to this probability H as senti- ment association. This is a key component in our model. It naturally bridges the gap between sen- timent labels and polarity scores, and captures the uncertainty in their relations. Note that H can be trained independent of the topic model part. For each training instance, suppose the sentiment word is m ∈ L, we need to know its sentiment label r m and polarity score s m . s m can be retrieved di- rectly from the sentiment lexicon, and r m can be either manually or automatically annotated. For example, suppose the word m appears in review d, we can assign the overall rating of d as its sen- timent label. In this case, each word m ∈ L can be associated with multiple training instances that have the same value for s m but different sentiment labels r m . We adopt this approach to automati- cally annotate sentiment labels, and details are de- scribed in the Experiments section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Problem definition</head><p>The product aspect rating prediction problem can be defined as follows. The input is a set of prod- ucts P . Each product P i has a bag of phrases F i , and an overall rating distribution Y i over R rat- ings. The output is the K corpus-level aspects, and for each product, we predict its ratings on the K aspects, also in the <ref type="bibr">[1, R]</ref> rating scale. We as- sume products in P are in the same category so they share the same aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The SATM model</head><p>We introduce the Sentiment-aligned Topic Model(SATM) in this section, and its graphical representation is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Note that the sentiment association H is observed, because it is trained independently of the topic model part.</p><p>At the word level, each observed phrase &lt; h, m &gt; is associated with two latent variables: aspect z and sentiment label r. Aspect z models what aspect this phrase talks about, and r deter- mines the sentiment of m. If m is in the senti- ment lexicon, we assume r is also responsible for generating a word feature v m , based on the senti- ment association H, which is equal to its polarity score s m in the lexicon. In this case, the observed data becomes (&lt; h, m &gt;, v m ), and the latent sen- timent label r is responsible for generating both word m, and word feature v m . For example, for the phrase &lt;room, filthy&gt;, we observe a word fea- ture v = −5, since the sentiment polarity score for the word "filthy" is −5. Given H, sentiment labels 1 or 2 are more likely to generate a word feature −5. Also, people tend to use "filthy" to express low ratings, like 1 or 2, so the sentiment labels and ratings can be aligned.</p><p>At the product level, for each product p and each aspect k, we define a multinomial distribu- tion λ p,k over R sentiment labels. Since Y p already gives us the big picture about the overall senti-ment expressed on this product, we assume λ p,k is drawn from a dirichlet distribution Dir(π p,k ) with asymmetric concentration parameters, where π p,k = f (Y p , ω k , ω b ). We can use a linear parametrization, and set</p><formula xml:id="formula_0">f (Y p , ω k , ω b ) = ω 1 k Y p + ω 0 k + ω b<label>(1)</label></formula><p>ω 1 k captures the influence of the product overall rating distribution, and can favour certain sen- timent labels in the prior. ω 0 k and ω b are the aspect-specific and corpus-level bias, respectively. Through this linear parametrization, we build a di- rect matching between sentiment label i and rating i. For example, for a product p, if its overall rat- ing distribution Y p has high probability over rat- ing 4, for aspect k, we assume its product-aspect- sentiment label distribution also has high probabil- ity on sentiment label 4 in the prior. The actual as- pect rating is affected by both the text which talks about aspect k, and also the prior.</p><p>To sum up, we assume the generative process as follows:</p><p>• For each aspect k = 1, 2, . . . K,</p><formula xml:id="formula_1">-draw an aspect-word distribution ϕ a k ∼ Dir(β a ) -For each sentiment label r = 1, 2, . . . R, draw an aspect-sentiment label-word distribution ϕ s k,r ∼ Dir(β s ) • For each product p ∈ P , -draw a product-aspect distribution θ p ∼ Dir(α) -for each aspect k, draw a product- aspect-sentiment label distribu- tion λ p,k ∼ Dir(π p,k ) where π p,k = f (Y p , ω k , ω b )</formula><p>• For each phrase f =&lt; h, m &gt; of product p, By integrating out θ, ϕ and λ, the joint proba- bility can be defined as:</p><formula xml:id="formula_2">P (z, r, h, m, v|α, β a , β s , π, H) = P (z|α)P (r|z, π)P (h|z, β a ) P (m|z, r, β s )P (v|r, H) (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Inference</head><p>We use Gibbs Sampling( <ref type="bibr" target="#b6">Griffiths and Steyvers, 2004</ref>) to estimate the posterior distribution given the observed data.</p><p>We jointly sample the aspect z and sentiment label r for the ith phrase &lt; h, m &gt; of product p, given the assignments of other phrases:</p><formula xml:id="formula_3">P (z i = k, r i = l|z −i , r −i , h, m, v) ∝ (n p,k + α) n a k,h + β a ∑ h ′ (n a k,h ′ + β a ) n p,k,l + π p,k,l ∑ l ′ (n p,k,l ′ + π p,k,l ′ ) n s k,l,m + β s ∑ m ′ (n s k,l,m ′ + β s ) g(m, l)<label>(3)</label></formula><p>where g(m, l) = H(v m |l) if m ∈ L. In this case, when we sample the sentiment label r for this phrase, the probability of generating word feature v m from r is also considered. For example, the word "excellent" has a word feature value v m = 5. Based on H, the probability of generating a word feature 5 is higher for sentiment labels with larger values. If m / ∈ L, there is no g(m, l) term, since no word feature is associated with this phrase. In Equation 3, n p,k is the number of times aspect k is assigned to phrases of product p, and n a k,h is the number of times aspect word h is assigned to aspect k. n p,k,l is the number of times sentiment label l is assigned to aspect k for product p, and n s k,l,m is the number of times sentiment word m is assigned to aspect k and sentiment label l. All these counts exclude assignments for the current phrase &lt; h, m &gt;.</p><p>Based on the samples, we can estimate λ p,k,r as:</p><formula xml:id="formula_4">λ p,k,r = n p,k,r + π p,k,r ∑ r ′ (n p,k,r ′ + π p,k,r ′ )<label>(4)</label></formula><p>Since sentiment labels and atings are aligned, the aspect rating t pk of product p on aspect k can be simply calculated as the expectation of λ p,k :</p><formula xml:id="formula_5">t pk = ∑ r λ p,k,r · r<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we describe the experiments and analyze the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We use the TripAdvisor dataset 1 ( <ref type="bibr" target="#b32">Wang et al., 2010</ref>) for evaluation, since in this dataset, reviews are not only associated with overall ratings, but also with ground truth aspect ratings on 7 aspects: value, room, location, cleanliness, check in/front desk, service, business service. All the ratings in the dataset are in the range from 1 star to 5 stars. We first remove reviews with any missing aspect ratings or very short reviews(less than three sen- tences). Then we adopt the dependency parser technique to identify opinion phrases, and collect phrases with adjective sentiment words. The de- pendency parser can deal with conjunctions, nega- tions and bigram aspect words, and it results in the best performance according to <ref type="bibr" target="#b22">(Moghaddam and Ester, 2012</ref>). Some sample phrases are shown in <ref type="table">Table 1</ref>. All words are converted into lower case, and we remove phrases containing words that ap- pear no more than 10 times or stop words. Since we are only interested in product-level aspect rat- ing prediction, for each product, we aggregate all the review overall ratings to get the overall rating distribution. The statistics of the dataset is shown in <ref type="table" target="#tab_1">Table 2</ref>. The average rating is the rating av- eraged over all reviews and all products. As we can see, positive reviews are dominant in the data, which raises the challenge of discovering negative sentiment topics.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentences</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Metrics</head><p>We use three evaluation metrics for comparison.</p><p>RMSE: Root-mean-square error is used to mea- sure the difference between the predicted aspect ratings and ground truth aspect ratings. It is de- fined as:</p><formula xml:id="formula_6">RM SE = √ ∑ p ∑ k (t pk − ˆ t pk ) 2 |P | × K (6)</formula><p>where t pk is the predicted aspect rating for product p on aspect k, andˆtandˆ andˆt pk is the ground truth. Precision@N: For each aspect k, we rank the hotels based on their predicted aspect ratings, and get the top N results. A hotel is considered rele- vant if its ground truth aspect rating is in the top 10% of the ground truth aspect ratings of all ho- tels. Precision@N is defined as the percentage of the top N results that are relevant:</p><formula xml:id="formula_7">P recision@N = |{relevant hotels} ∩ {top N ranked hotels}| N<label>(7)</label></formula><p>We use N = 10, and the result is averaged over K aspects.</p><p>ρ hotel : Pearson correlation across hotels( <ref type="bibr" target="#b32">Wang et al., 2010</ref>) is defined as:</p><formula xml:id="formula_8">ρ hotel = ∑ k ρ(t k , ˆ t k ) K (8)</formula><p>where t k is the predicted aspect rating vector for all hotels on aspect k, andˆtandˆ andˆt k is the corresponding ground truth vector. ρ(t k , ˆ t k ) is the Pearson cor- relation between these two vectors. It measures how the predicted ratings of aspect k can preserve the order in the ground truth( <ref type="bibr" target="#b32">Wang et al., 2010)</ref>. If we can predict an aspect-specific ranking sim- ilar to the ground truth, we can use the predicted aspect ratings to answer questions like "Is hotel a better than hotel b on aspect k?"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>The first three baselines are Local Prediction, Global Prediction and Graph Propagation. They all separate aspect extraction and sentiment identification. For each phrase f =&lt; h, m &gt; from review d of product p, we first find the aspect as- signment of this phrase. Then, we use three meth- ods to get the phrase rating. Local Prediction( <ref type="bibr" target="#b18">Lu et al., 2009</ref>) simply uses the overall rating of d as its phrase rating. Global Prediction( <ref type="bibr" target="#b18">Lu et al., 2009</ref>) trains a multi-class classifier to classify the senti- ment word m into a rating category r ∈ 1, 2 . . . R, <ref type="figure">Figure 2</ref>: Method for aspect extraction in Local Prediction, Global Prediction and Graph Propaga- tion then assigns r as the phrase rating. Graph Prop- agation( <ref type="bibr" target="#b4">Brody and Elhadad, 2010</ref>) builds a con- junction graph for sentiment words, and uses a La- bel Propagation algorithm on the graph to learn the sentiment polarity score for each sentiment word. The score of m is set as phrase rating. Finally, we aggregate all the phrases of each aspect to pre- dict the aspect ratings. To apply these methods in our experiments, in the aspect extraction step, we adapt our model to extract only aspects, as shown in <ref type="figure">Figure 2</ref>. In this simplified model, no sentiment labels is involved, and the latent aspect explains both the aspect word and sentiment word.</p><p>ILDA( <ref type="bibr" target="#b21">Moghaddam and Ester, 2011</ref>) was pro- posed for aspect rating prediction, but it fails to deal with the sentiment label alignment problem, so it cannot be directly used for this task. We adopt the common approach of providing seed words to set priors for each sentiment topic.</p><p>LRR( <ref type="bibr" target="#b32">Wang et al., 2010</ref>) was proposed to pre- dict aspect ratings for each review, but it can also be used to predict product aspect ratings by ag- gregating all the reviews of a product into a single "h-review"( <ref type="bibr" target="#b33">Wang et al., 2011</ref>). First, we can run a topic model to learn aspects, and annotate each sentence with an aspect. Then LRR is applied on the annotated sentences to predict aspect ratings. This approach provided the best result, according to ( <ref type="bibr" target="#b33">Wang et al., 2011</ref>). In the first step we use the sentence-LDA( <ref type="bibr" target="#b10">Jo and Oh, 2011</ref>) to annotate sen- tences, which is slightly different from the original method, but still provides a good analogy.</p><p>We also test two simplified version of the SATM model. First, we remove the part which involves sentiment lexicons, so we only use the product overall rating distribution. We call this method SATM-O. Second, we use only sentiment lexi- cons, ignoring the influence of overall rating dis- tribution. We call it SATM-L. These two baselines can help us identify how the sentiment lexicon and overall rating distribution can improve the results, if used separately.</p><p>Our last baseline simply uses the overall rating of a hotel as its aspect ratings. For each hotel, its overall rating is defined as the average overall rat- ing of its reviews. This method is referred to as Overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experimental Setup</head><p>For all topic modelling based approaches, the number of aspects is set to 7. Since we can evalu- ate aspect rating prediction only on the predefined aspects, we need to ensure the discovered aspects match the predefined aspects. To do this, we adopt the common approach of providing a few seed words for each aspect as priors, as in ( <ref type="bibr" target="#b32">Wang et al., 2010)</ref>. The seed words are listed in <ref type="table" target="#tab_3">Table 3</ref>. There may be better methods to use seed words for as- pect discovery ( <ref type="bibr" target="#b9">Jagarlamudi et al., 2012;</ref><ref type="bibr" target="#b24">Mukherjee and Liu, 2012)</ref>, and it would be interesting to combine their methods with ours. However, this is beyond the scope of this paper, and we list it as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aspects</head><p>Seed  We use 5 sentiment labels in SATM, SATM- L and SATM-O, as this is the number of dis- tinct ratings. The lexicon L used in our experi- ment is part of (Taboada et al., 2011) where words are associated with polarity scores in the range [−5, −1] ∪ <ref type="bibr">[1,</ref><ref type="bibr">5]</ref>. We observe that words with po- larity score 1 and −1 express too weak sentiments, so we discard them in our experiment. To get training instances for sentiment association H, we treat each appearance of word m ∈ L in the data as one training instance. The polarity score s m is di- rectly retrieved from L, and the sentiment label r m is the overall rating of review d where m appears. This approach avoids the need for manual annota- tion of sentiment labels, and the annotation result captures the characteristics of the dataset. How-ever, all training instances in a review will have the same sentiment label, which means that we as- sume all sentiment words in a review express the same sentiment, no matter what aspects they talk about. This is not true, thus will introduce noise to the training. To reduce noise, for words with pos- itive polarity score, we ignore their appearance in reviews with rating 1 and 2, since we assume pos- itive sentiment words rarely express negative sen- timents, even if they appear in negative reviews. Therefore, H(s m |r m ) = 0 for r m = 1, 2 and s m in the range <ref type="bibr">[2,</ref><ref type="bibr">5]</ref>. A similar method is used to deal with words with negative polarity score.</p><p>For Global Prediction, in ( <ref type="bibr" target="#b18">Lu et al., 2009)</ref>, the prior for the multi-class classifier is uniform, while in our experiment, for product p, we used product overall rating distribution on r as the prior for rat- ing category r, which achieves better results than uniform prior.</p><p>The Graph Propagation method requires a small set of sentiment words as seeds, from which the al- gorithm can learn sentiment score for other words. The method in (Brody and Elhadad, 2010) con- structs these seed words based on morphology in an unsupervised way, and can only support two kinds of sentiment: positive and negative. In our experiment, since the sentiment lexicon is avail- able, the sentiment seed words are from the lexi- con, and we update the polarity score for those not in the lexicon.</p><p>For ILDA, since we need to provide seed words as priors for sentiment topics, we have two op- tions, and we use both for experiment. First, we can employ the common approach of using two sentiment labels(R=2, positive and negative). Then, words with positive polarity scores in lexi- con L are used as priors for the positive sentiment topic, and similarly words with negative polarity scores for negative sentiment topic. An alternative approach is to use 5 sentiment labels(R=5). It pro- vides finer grained sentiment extraction, but raises the question of how to choose seed words for each sentiment topic. To do this, we use the full senti- ment lexicon in <ref type="bibr" target="#b28">(Taboada et al., 2011)</ref>, where sen- timent words have polarity score in the range of [−5, −1] ∪ <ref type="bibr">[1,</ref><ref type="bibr">5]</ref>. We divide the lexicon, and use words with polarity score 4 and 5 as prior for the sentiment topic with label 5. Then, words with po- larity score 2 and 3 are used for the sentiment topic with label 4, and so on.</p><p>For all topic modelling based approaches, we set the number of iterations for Gibbs Sampling to 3000, and take samples from the markov chain every 50 iterations after a burn-in period of 1000 iterations. In SATM and SATM-O, for all aspects k, we need to choose the parameters ω k and also w b . We use a small portion of dataset with ground truth to choose the best value, and we set ω 1 k = 20, w 0 k = 0.01, w b = 0. Automatically learning these parameters are feasible. One possible option is to use stochastic EM sampling scheme, as in ( <ref type="bibr" target="#b20">Mimno and McCallum, 2008)</ref>. For the LRR implementa- tion 2 , we use the default parameters included in the package, and train the model with seed words provided by the author( <ref type="bibr" target="#b32">Wang et al., 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Results</head><p>The experimental results are listed in <ref type="table" target="#tab_5">Table 4</ref>. For RMSE, the smaller the better, while for the other two measures, the larger the better. Graph Prop- agation, ILDA and SATM-L do not use the over- all ratings(except for training sentiment associa- tion H), so we group them together. Similarly we group Local Prediction, Global Prediction, SATM-O and SATM. The Overall method is a spe- cial baseline that does not do any aspect based pre- diction. For the LRR method, after the first step of sentence annotation, we notice that sentence-LDA fails to annotate the "h-review" of some hotel with all 7 aspects, mainly because these hotels are as- sociated with less reviews. In this case, the LRR model will fail in the second step, so we do not include LRR in <ref type="table" target="#tab_5">Table 4</ref>. Instead, we compared our method with LRR on a subset of products that comment on all aspects based on the sentence an- notation. There are 1533 hotels in this subset, and the result is shown in <ref type="table" target="#tab_6">Table 5</ref>. Note that our exper- imental results for LRR are far worse than those reported in the original paper( <ref type="bibr" target="#b33">Wang et al., 2011</ref>). We believe this maybe due to different parameter settings, or due to the choice of different reviews.</p><p>We observe that SATM achieves the best RMSE value, i.e., it produces the most accurate aspect rat- ing prediction. The Overall method does better in ranking all the hotels(ρ hotel ), but SATM is better at ranking top hotels(P @10). When we compare the results of SATM with SATM-L and SATM- O, we find that the good performance of SATM is mainly due to the use of the overall rating distri- bution. On one hand, this is reasonable, since in-  <ref type="table" target="#tab_1">Top sentiment words  1  old, dirty, worn, older, dark, stained, broken, dated, outdated, bad  2  small, tiny, little, noisy, single, double, uncomfortable, smaller, larger, narrow  3  large, double, big, mini, hard, main, huge, twin, single, jacuzzi  4</ref> nice, comfortable, modern, clean, new, good, great, flat, big, comfy 5 large, huge, great, beautiful, big, lovely, separate, spacious, wonderful, excellent   tuitively aspect ratings usually do not diverge too far from the overall rating, especially for hotels with higher overall ratings. As we can see from the result of Overall, the overall rating has good correlation with aspect ratings, and using overall rating only is already a strong predictor for as- pect ratings. Also, in most cases, methods using overall ratings(Overall and the four methods in the middle of <ref type="table" target="#tab_5">Table 4</ref>) are better than others(first four methods). On the other hand, we should not rely only on the overall rating distribution. By incor- porating the sentiment lexicon, for RMSE, SATM achieves 10% improvement over SATM-O and 7% improvement than Overall. Also, the overall rating may not always be a good aspect rating predictor, depending on the dataset. To take a closer look at cases where the over- all rating is not a good aspect rating predictor, we evaluate the RMSE on different subsets of ho- tels. We divide the hotels into different overall rat- ing ranges: [1.2), [2,3), <ref type="bibr">[3,</ref><ref type="bibr">4)</ref> and <ref type="bibr">[4,</ref><ref type="bibr">5]</ref>. The re- sults are shown in <ref type="table" target="#tab_7">Table 7</ref>. Going from the <ref type="bibr">[4,</ref><ref type="bibr">5]</ref> group to <ref type="bibr">[1,</ref><ref type="bibr">2)</ref> group, the overall rating becomes less and less reliable to predict aspect ratings, and the gain of SATM increases compared to SATM-  O and Overall. For a hotel with higher overall rating(good hotel), its aspect ratings are closer to the overall rating. This matches our intuition that good hotels are expected to be good on most as- pects, if not on all aspects. For a hotel with av- erage and lower overall rating, the average differ- ence between aspect ratings and overall rating is larger. In this case, the overall rating can not tell us the whole story, which calls for aspect based prediction. Our method achieves the best RMSE gain on this group of hotels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Qualitative analysis</head><p>To provide a qualitative analysis, we can list the top words for the aspect-sentiment label-word dis- tributions. In <ref type="table" target="#tab_4">Table 6</ref>, we list them for the aspect "room", with 5 different sentiment labels. We ob- serve that, as the sentiment label value increases, the sentiment topics express more and more pos- itive sentiments. This means the sentiment labels and ratings are indeed aligned, so that we can use these sentiment labels to predict ratings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and future work</head><p>In this paper, we proposed a sentiment aligned topic model(SATM) for product aspect rating pre- diction. By incorporating the overall rating distri- bution and a sentiment lexicon, our SATM model can align sentiment labels with ratings. Experi- ments on a TripAdvisor dataset demonstrate the effectiveness of SATM on aspect rating prediction. In SATM, for each product and each aspect, the multinomial distribution over sentiment labels has prior parameterized by product overall rating dis- tribution. We assume linear dependency, but it will be interesting to explore other dependencies. An- other direction is to learn the parameters ω k auto- matically, so that ω k can be different for different k, capturing the influence of the overall rating on different aspects.</p><p>Finally, we assume each phrase is associated with one latent aspect. However, aspects may be correlated. For example, the phrase &lt;room, filthy&gt; gives us information about the aspect room and also the aspect cleanliness. To deal with this problem, we can relax the assumption that one phrase talks about one aspect, or we can model correlation among aspects.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graphical model of SATM</figDesc><graphic url="image-1.png" coords="4,307.27,62.81,205.70,174.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 .</head><label>1</label><figDesc>Draw an aspect z from θ p 2. Draw a sentiment label r from λ p,z 3. Draw an aspect word h from ϕ a z 4. Draw a sentiment word m from ϕ s z,r . If m ∈ L, generate a word feature v m based on H.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Statistics of the dataset</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : Seed words for aspect discovery</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Top sentiment words for aspect "room" with different sentiment labels 

Methods 
RMSE P@10 ρ hotel 
ILDA,R=2 
1.202 
0.30 
0.193 
ILDA,R=5 
1.096 0.257 0.222 
Graph Propagation 0.718 0.271 0.442 
SATM-L 
0.774 0.443 0.483 
Local Prediction 
0.572 0.486 0.761 
Global Prediction 
0.625 
0.30 
0.778 
SATM-O 
0.429 
0.80 
0.841 
SATM 
0.384 0.814 0.854 
Overall 
0.415 
0.80 
0.863 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 4 : Experimental results except LRR</head><label>4</label><figDesc></figDesc><table>Methods RMSE P@10 ρ hotel 
LRR 
1.018 
0.3 
0.404 
SATM 
0.373 0.829 0.849 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 : Experimental comparison with LRR</head><label>5</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc>RMSE on hotels with different overall rating ranges</figDesc><table></table></figure>

			<note place="foot" n="1"> http://sifaka.cs.uiuc.edu/ ˜ wang296/ Data/index.html</note>

			<note place="foot" n="2"> http://sifaka.cs.uiuc.edu/ ˜ wang296/ Codes/LARA.zip</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is supported by NSERC Discovery Grant. The authors thank Dr. Maite Taboada for providing the sentiment lexicon.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Incorporating domain knowledge into topic modeling via dirichlet forest priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Andrzejewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning, ICML &apos;09</title>
		<meeting>the 26th Annual International Conference on Machine Learning, ICML &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A framework for incorporating general domain knowledge into latent dirichlet allocation using first-order logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Andrzejewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<idno>IJ- CAI&apos;11</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Second International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">Two</biblScope>
			<biblScope unit="page" from="1171" to="1177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Building a sentiment summarizer for local service reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Blair-Goldensohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Neylon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kerry</forename><surname>Hannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Reynar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW Workshop on NLP in the Information Explosion Era</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An unsupervised aspect-sentiment model for online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noemie</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT &apos;10</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="804" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploiting domain knowledge in aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meichun</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malú</forename><surname>Castellanos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riddhiman</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1655" to="1667" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Finding scientific topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="5228" to="5235" />
			<date type="published" when="2004-04" />
		</imprint>
	</monogr>
	<note>Suppl. 1</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;99</title>
		<meeting>the 22Nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;99<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;04</title>
		<meeting>the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Incorporating lexical priors into topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jagadeesh</forename><surname>Jagarlamudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghavendra</forename><surname>Udupa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL &apos;12</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL &apos;12<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="204" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Aspect and sentiment unification model for online review analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohan</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, WSDM &apos;11</title>
		<meeting>the Fourth ACM International Conference on Web Search and Data Mining, WSDM &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="815" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A hierarchical aspectsentiment model for online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixia</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Seventh AAAI Conference on Artificial Intelligence<address><addrLine>Bellevue, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-07-14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting coherence for the simultaneous discovery of latent facets and associated sentiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himabindu</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiranjib</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Indrajit</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srujana</forename><surname>Merugu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh SIAM International Conference on Data Mining, SDM 2011</title>
		<meeting>the Eleventh SIAM International Conference on Data Mining, SDM 2011<address><addrLine>Mesa, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-04-28" />
			<biblScope unit="page" from="498" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A bayesian model for joint unsupervised induction of sentiment, aspect and discourse representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics, ACL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013-08-09" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1630" to="1639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sentiment analysis with global topics and local dependency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangtao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2010</title>
		<meeting>the Twenty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2010<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Joint sentiment/topic model for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM &apos;09</title>
		<meeting>the 18th ACM Conference on Information and Knowledge Management, CIKM &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="375" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sentiment Analysis and Opinion Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Estimating feature ratings through an effective review selection approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="419" to="446" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rated aspect summarization of short comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neel</forename><surname>Sundaresan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on World Wide Web, WWW &apos;09</title>
		<meeting>the 18th International Conference on World Wide Web, WWW &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Topic sentiment mixture: Modeling facets and opinions in weblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Wondra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on World Wide Web, WWW &apos;07</title>
		<meeting>the 16th International Conference on World Wide Web, WWW &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Topic models conditioned on arbitrary features with dirichlet-multinomial regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="411" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ilda: Interdependent lda model for learning latent aspects and their ratings from online product reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samaneh</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;11</title>
		<meeting>the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="665" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the design of lda models for aspect-based opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samaneh</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM International Conference on Information and Knowledge Management, CIKM &apos;12</title>
		<meeting>the 21st ACM International Conference on Information and Knowledge Management, CIKM &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="803" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The flda model for aspect-based opinion mining: Addressing the cold start problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samaneh</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd International Conference on World Wide Web, WWW &apos;13</title>
		<meeting>the 22Nd International Conference on World Wide Web, WWW &apos;13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="909" to="918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Aspect extraction through semi-supervised modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="339" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Extracting product features and opinions from reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana-Maria</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT &apos;05</title>
		<meeting>the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT &apos;05<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="339" to="346" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automatic aggregation by joint modeling of aspects and values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Sauper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Int. Res</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="127" />
			<date type="published" when="2013-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Content models with attitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Sauper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="350" to="358" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Lexiconbased methods for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maite</forename><surname>Taboada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Tofiloski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimberly</forename><surname>Voll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="307" />
			<date type="published" when="2011-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling online reviews with multi-grain topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on World Wide Web, WWW &apos;08</title>
		<meeting>the 17th International Conference on World Wide Web, WWW &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A joint model of text and aspect ratings for sentiment summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2008, Proceedings of the 46th</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Columbus, Ohio, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="308" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Latent aspect rating analysis on review text data: A rating regression approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;10</title>
		<meeting>the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="783" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Latent aspect rating analysis without aspect keyword supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;11</title>
		<meeting>the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Jointly modeling aspects and opinions with a maxent-lda hybrid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Learning from labeled and unlabeled data with label propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno>CMU- CALD-02-107</idno>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
