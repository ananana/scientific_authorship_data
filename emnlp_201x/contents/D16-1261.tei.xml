<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSAIL</orgName>
								<address>
									<region>MIT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Yala</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSAIL</orgName>
								<address>
									<region>MIT</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
							<email>regina@csail.mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">CSAIL</orgName>
								<address>
									<region>MIT</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2355" to="2365"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Most successful information extraction systems operate with access to a large collection of documents. In this work, we explore the task of acquiring and incorporating external evidence to improve extraction accuracy in domains where the amount of training data is scarce. This process entails issuing search queries, extraction from new sources and reconciliation of extracted values, which are repeated until sufficient evidence is collected. We approach the problem using a reinforcement learning framework where our model learns to select optimal actions based on con-textual information. We employ a deep Q-network, trained to optimize a reward function that reflects extraction accuracy while penalizing extra effort. Our experiments on two databases-of shooting incidents, and food adulteration cases-demonstrate that our system significantly outperforms traditional extractors and a competitive meta-classifier baseline. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In many realistic domains, information extraction (IE) systems require exceedingly large amounts of annotated data to deliver high performance. In- creases in training data size enable models to han- dle robustly the multitude of linguistic expressions that convey the same semantic relation. Consider, for instance, an IE system that aims to identify en- tities such as the perpetrator and the number of vic- <ref type="bibr">1</ref> Code is available at http://people.csail.mit. edu/karthikn/rl-ie/ ShooterName: Scott Westerhuis NumKilled: 6 A couple and four children found dead in their burning South Dakota home had been shot in an apparent murder-suicide, officials said Monday. ... Scott Westerhuis's cause of death was "shotgun wound with manner of death as suspected sui- cide," it added in a statement. tims in a shooting incident <ref type="figure" target="#fig_0">(Figure 1</ref>). The docu- ment does not explicitly mention the shooter (Scott Westerhuis), but instead refers to him as a suicide victim. Extraction of the number of fatally shot vic- tims is similarly difficult, as the system needs to in- fer that "A couple and four children" means six peo- ple. Even a large annotated training set may not pro- vide sufficient coverage to capture such challenging cases.</p><p>In this paper, we explore an alternative approach for boosting extraction accuracy, when a large train- ing corpus is not available. Instead, the proposed method utilizes external information sources to re- solve ambiguities inherent in text interpretation. Specifically, our strategy is to find other documents that contain the information sought, expressed in a form that a basic extractor can "understand". For instance, <ref type="figure" target="#fig_1">Figure 2</ref> shows two other articles describ- ing the same event, wherein the entities of interest</p><p>The six members of a South Dakota family found dead in the ruins of their burned home were fa- tally shot, with one death believed to be a suicide, authorities said Monday.</p><p>AG Jackley says all evidence supports the story he told based on preliminary findings back in September: Scott Westerhuis shot his wife and children with a shotgun, lit his house on fire with an accelerant, then shot himself with his shotgun. -the number of people killed and the name of the shooter -are expressed explicitly. Processing such stereotypical phrasing is easier for most extraction systems, compared to analyzing the original source document. This approach is particularly suitable for extracting information from news where a typical event is covered by multiple news outlets.</p><p>The challenges, however, lie in (1) performing event coreference (i.e. retrieving suitable articles de- scribing the same incident) and (2) reconciling the entities extracted from these different documents. Querying the web (using the source article's title for instance) often retrieves documents about other inci- dents with a tangential relation to the original story. For example, the query "4 adults, 1 teenager shot in west Baltimore 3 april 2015" yields only two rele- vant articles among the top twenty results on Bing search, while returning other shooting events at the same location. Moreover, the values extracted from these different sources require resolution since some of them might be inaccurate.</p><p>One solution to this problem would be to perform a single search to retrieve articles on the same event and then reconcile values extracted from them (say, using a meta-classifier). However, if the confidence of the new set of values is still low, we might wish to perform further queries. Thus, the problem is in- herently sequential, requiring alternating phases of querying to retrieve articles and integrating the ex- tracted values.</p><p>We address these challenges using a Reinforce- ment Learning (RL) approach that combines query formulation, extraction from new sources, and value reconciliation. To effectively select among possible actions, our state representation encodes informa- tion about the current and new entity values along with the similarity between the source article and the newly retrieved document. The model learns to select good actions for both article retrieval and value reconciliation in order to optimize the reward function, which reflects extraction accuracy and in- cludes penalties for extra moves. We train the RL agent using a Deep Q-Network (DQN) ( <ref type="bibr" target="#b11">Mnih et al., 2015)</ref> that is used to predict both querying and rec- onciliation choices simultaneously. While we use a maximum entropy model as the base extractor, this framework can be inherently applied to other extrac- tion algorithms. We evaluate our system on two datasets where available training data is inherently limited. The first dataset is constructed from a publicly available database of mass shootings in the United States. The database is populated by volunteers and includes the source articles. The second dataset is derived from a FoodShield database of illegal food adulter- ations. Our experiments demonstrate that the final RL model outperforms basic extractors as well as a meta-classifier baseline in both domains. For in- stance, in the Shootings domain, the average accu- racy improvement over the meta-classifier is 7%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Open Information Extraction Existing work in open IE has used external sources from the web to improve extraction accuracy and cover- age <ref type="bibr">(Agichtein and Gravano, 2000;</ref><ref type="bibr" target="#b20">Wu and Weld, 2010)</ref>. Such research has focused on identifying multiple instances of the same relation, independent of the context in which this information appears. In con- trast, our goal is to extract information from addi- tional sources about a specific event described in a source article. Therefore, the novel challenge of our task resides in performing event coreference ( <ref type="bibr" target="#b9">Lee et al., 2012;</ref><ref type="bibr">Bejan and Harabagiu, 2014</ref>) (i.e identify- ing other sources describing the same event) while simultaneously reconciling extracted information. Moreover, relations typically considered by open IE systems have significantly higher coverage in on- line documents than a specific incident described in a few news sources. Hence, we require a different mechanism for finding and reconciling online infor- mation.</p><p>Entity linking, multi-document extraction and event coreference Our work also relates to the task of multi-document information extraction, where the goal is to connect different mentions of the same entity across input documents <ref type="bibr" target="#b10">(Mann and Yarowsky, 2005;</ref><ref type="bibr" target="#b5">Han et al., 2011;</ref><ref type="bibr">Durrett and Klein, 2014)</ref>. Since this setup already includes multiple in- put documents, the model is not required to look for additional sources or decide on their relevance. Also, while the set of input documents overlap in terms of entities mentioned, they do not necessarily describe the same event. Given these differences in setup, the challenges and opportunities of the two tasks are distinct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge Base Completion and Online Search</head><p>Recent work has explored several techniques to per- form Knowledge Base Completion (KBC) such as vector space models and graph traversal <ref type="bibr" target="#b14">(Socher et al., 2013;</ref><ref type="bibr" target="#b22">Yang et al., 2014;</ref><ref type="bibr" target="#b3">Gardner et al., 2014;</ref><ref type="bibr" target="#b13">Neelakantan et al., 2015;</ref><ref type="bibr" target="#b4">Guu et al., 2015</ref>). Though our work also aims at increasing extraction recall for a database, traditional KBC approaches do not require searching for additional sources of informa- tion. <ref type="bibr" target="#b19">West et al. (2014)</ref> explore query reformula- tion in the context of KBC. Using existing search logs, they learn how to formulate effective queries for different types of database entries. Once query learning is completed, the model employs several se- lected queries, and then aggregates the results based on retrieval ranking. This approach is complemen- tary to the proposed method, and can be combined with our approach if search logs are available. <ref type="bibr" target="#b8">Kanani and McCallum (2012)</ref> also combine search and information extraction. In their task of faculty directory completion, the system has to find documents from which to extract desired informa- tion. They employ reinforcement learning to address computational bottlenecks, by minimizing the num- ber of queries, document downloads and extraction action. The extraction accuracy is not part of this optimization, since the baseline IE system achieves high performance on the relations of interest. Hence, given different design goals, the two RL formula- tions are very different. Our approach is also close in spirit to the AskMSR system ( <ref type="bibr">Banko et al., 2002</ref>) which aims at using information redundancy on the web to better answer questions. Though our goal is similar, we learn to query and consolidate the dif- ferent sources of information instead of using pre- defined rules. Several slot-filling methods have ex- perimented with query formulation over web-based corpora to populate knowledge bases ( <ref type="bibr" target="#b15">Surdeanu et al., 2010;</ref><ref type="bibr" target="#b7">Ji and Grishman, 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Framework</head><p>We model the information extraction task as a markov decision process (MDP), where the model learns to utilize external sources to improve upon extractions from a source article (see <ref type="figure" target="#fig_3">Figure 3</ref>). The MDP framework allows us to dynamically incorpo- rate entity predictions while also providing flexibil- ity to choose the type of articles to extract from. At each step, the system has to reconcile extracted val- ues from a related article (e new ) with the current set of values (e cur ), and decide on the next query for retrieving more articles.</p><p>We represent the MDP as a tuple S, A, T, R, where S = {s} is the space of all possible states, A = {a = (d, q)} is the set of all actions, R(s, a) is the reward function, and T (s |s, a) is the transition function. We describe these in detail below.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>State 1 State 2</head><p>Current Values:</p><formula xml:id="formula_0">ShooterName → Scott Westerhuis NumKilled → 4 NumWounded → 2 City → Platte New Values: ShooterName → Scott Westerhuis NumKilled → 6 NumWounded → 0 City → Platte State: 0.3, 0.2, 0.5, 0.1, ← currentConf 0.4, 0.6, 0.2, 0.4, ← newConf 1, 0, 0, 1, 0, 1, 1, 0, ← matches 0.2, 0.3, ..., 0.1, 0.5, ← contextWords 0.65</formula><p>← document tf-idf similarity Actions At each step, the agent is required to take two actions -a reconciliation decision d and a query choice q. The decision d on the newly extracted val- ues can be one of the following types: (1) accept a specific entity's value (one action per entity) 3 , (2) accept all entity values, (3) reject all values or (4) stop. In cases 1-3, the agent continues to inspect more articles, while the episode ends if a stop ac- tion (4) is chosen. The current values and confidence scores are simply updated with the accepted values and the corresponding confidences. <ref type="bibr">4</ref> The choice q is used to choose the next query from a set of automat- ically generated alternatives (details below) in order to retrieve the next article.</p><p>Rewards The reward function is chosen to maxi- mize the final extraction accuracy while minimizing the number of queries. The accuracy component is calculated using the difference between the accuracy of the current and the previous set of entity values:</p><formula xml:id="formula_1">R(s, a) = entity j Acc(e j cur ) − Acc(e j prev )</formula><p>There is a negative reward per step to penalize the agent for longer episodes.</p><p>Queries The queries are based on automatically generated templates, created using the title of an ar- ticle along with words 5 most likely to co-occur with each entity type in the training data. <ref type="table" target="#tab_1">Table 1</ref> pro- vides some examples -for instance, the second tem- plate contains words such as arrested and identified which often appear around the name of the shooter.  We use a search engine to query the web for arti- cles on the same event as the source article and re- trieve the top k links per query. <ref type="bibr">6</ref> Documents that are more than a month older than the original article are filtered out of the search results.</p><p>Transitions Each episode starts off with a single source article x i from which an initial set of entity values are extracted. The subsequent steps in the episode involve the extra articles, downloaded using different types of query formulations based on the source article. A single transition in the episode con- sists of the agent being given the state s containing information about the current and new set of values (extracted from a single article) using which the next action a = (d,</p><note type="other">q) is chosen. The transition function T (s |s, a) incorporates the reconciliation decision d from the agent in state s along with the values from the next article retrieved using query q and produces the next state s . The episode stops whenever d is a stop decision. Algorithm 1 details the entire MDP framework for the training phase. During the test phase, each source article is handled only once in a single episode (lines 8-23). Algorithm 1 MDP framework for Information Extrac- tion (Training Phase)</note><p>1: Initialize set of original articles</p><formula xml:id="formula_2">X 2: for x i ∈ X do 3:</formula><p>for each query template T q do Get decision d, query q from agent <ref type="bibr">19:</ref> if q == "end_episode" then break <ref type="bibr">20:</ref> e prev ← e cur 21:</p><formula xml:id="formula_3">e cur ← Reconcile(e cur , e new , d) 22: r ← entity j Acc(e j cur ) − Acc(e j prev ) 23:</formula><p>Send (s end , r) to agent</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Reinforcement Learning for Information Extraction</head><p>In order to learn a good policy for an agent, we uti- lize the paradigm of reinforcement learning (RL).</p><p>The MDP described in the previous section can be viewed in terms of a sequence of transitions (s, a, r, s ). The agent typically utilizes a state- action value function Q(s, a) to determine which action a to perform in state s. A commonly used technique for learning an optimal value function is Q-learning ( <ref type="bibr" target="#b18">Watkins and Dayan, 1992)</ref>, in which the agent iteratively updates Q(s, a) using the re- wards obtained from episodes. The updates are de- rived from the recursive Bellman equation (Sutton and Barto, 1998) for the optimal Q:</p><formula xml:id="formula_4">Q i+1 (s, a) = E[r + γ max a Q i (s , a ) | s, a]</formula><p>Here, r = R(s, a) is the reward and γ is a factor discounting the value of future rewards and the ex- pectation is taken over all transitions involving state s and action a.</p><p>Since our problem involves a continuous state space S, we use a deep Q-network (DQN) ( <ref type="bibr" target="#b11">Mnih et al., 2015</ref>) as a function ap- proximator Q(s, a) ≈ Q(s, a; θ). The DQN, in which the Q-function is approximated using a deep neural network, has been shown to learn better value functions than linear approximators ( <ref type="bibr" target="#b12">Narasimhan et al., 2015;</ref><ref type="bibr" target="#b6">He et al., 2015</ref>) and can capture non-linear interactions between the different pieces of information in our state.</p><p>We use a DQN consisting of two linear layers (20 hidden units each) followed by rectified linear units (ReLU), along with two separate output layers. <ref type="bibr">7</ref> The network takes the continuous state vector s as input and predicts Q(s, d) and Q(s, q) for reconciliation decisions d and query choices q simultaneously us- ing the different output layers (see Supplementary material for the model architecture).</p><p>Parameter Learning The parameters θ of the DQN are learnt using stochastic gradient de- scent with RMSprop (Tieleman and Hinton, 2012). Each parameter update aims to close the gap be- tween the Q(s t , a t ; θ) predicted by the DQN and the expected Q-value from the Bellman equation, r t + γ max a Q(s t+1 , a; θ </p><formula xml:id="formula_5">y j = r j , if s j+1 is terminal r j + γ max a Q(s j+1 , a ; θ t ), else 15:</formula><p>Perform gradient descent step on the loss L(θ) = (y j − Q(s j , a j ; θ)) <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>16:</head><p>if s t+1 == s end then break to have 'stable updates'. The target Q-network is periodically updated with the current parameters θ. We also make use of an experience replay memory D to store transitions. To perform updates, we sam- ple a batch of transitions (ˆ s, ˆ a, ˆ s , r) at random from D and minimize the loss function 8 :</p><formula xml:id="formula_6">L(θ) = E ˆ s,ˆ a [(y − Q(ˆ s, ˆ a; θ)) 2 ]</formula><p>where y = r + γ max a Q(ˆ s , a ; θ t ) is the target Q- value. The learning updates are made every training step using the following gradients:</p><formula xml:id="formula_7">θ L(θ) = E ˆ s,ˆ a [2(y − Q(ˆ s, ˆ a; θ)) θ Q(ˆ s, ˆ a; θ)]</formula><p>Algorithm 2 details the DQN training procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>Data We perform experiments on two different datasets. For the first set, we collected data from the Gun Violence archive, 9 a website tracking shootings in the United States. The data contains a news article on each shooting and annotations for (1) the name of the shooter, (2) the number of people killed, (3) the number of people wounded, and (4) the city where <ref type="table" target="#tab_1">Number  Shootings  Adulteration  Train Test  Dev Train Test  Dev  Source articles  306  292  66  292  148  42  Downloaded articles 8201 7904 1628 7686 5333 1537   Table 2</ref>: Stats for Shootings and Adulteration datasets the incident took place. We consider these as the entities of interest, to be extracted from the articles. The second dataset we use is the Foodshield EMA database 10 documenting adulteration incidents since 1980. This data contains annotations for (1) the af- fected food product, (2) the adulterant and (3) the location of the incident. Both datasets are classic examples where the number of recorded incidents is insufficient for large-scale IE systems to leverage.</p><p>For each source article in the above databases, we download extra articles (top 20 links) using the Bing Search API 11 with different automatically generated queries. We use only the source articles from the train portion to learn the parameters of the base ex- tractor. The entire train set with downloaded arti- cles is used to train the DQN agent and the meta- classifier baseline (described below). All parame- ters are tuned on the dev set. For the final results, we train the models on the combined train and dev sets and use the entire test set (source + downloaded articles) to evaluate. <ref type="table">Table 2</ref> provides data statistics.</p><p>Extraction model We use a maximum entropy classifier as the base extraction system, since it pro- vides flexibility to capture various local context fea- tures and has been shown to perform well for in- formation extraction ( <ref type="bibr">Chieu and Ng, 2002</ref>). The classifier is used to tag each word in a document as one of the entity types or not (e.g. {Shooter- Name, NumKilled, NumWounded, City, Other} in the Shootings domain). Then, for each tag except Other, we choose the mode of the values to obtain the set of entity extractions from the article. <ref type="bibr">12</ref> Fea- tures used in the classifier are provided in the Sup- plementary material.</p><p>The features and context window c = 4 of neigh- boring words are tuned to maximize performance on a dev set. We also experimented with a conditional random field (CRF) (with the same features) for the sequence tagging ( <ref type="bibr">Culotta and McCallum, 2004)</ref> but obtained worse empirical performance (see Sec- tion 6). The parameters of the base extraction model are not changed during training of the RL model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation</head><p>We evaluate the extracted entity val- ues against the gold annotations and report the corpus-level average accuracy on each entity type. For entities like ShooterName, the annotations (and the news articles) often contain multiple names (first and last) in various combinations, so we consider re- trieving either name as a successful extraction. For all other entities, we look for exact matches.</p><p>Baselines We explore 4 types of baselines:</p><p>Basic extractors: We use the CRF and the Maxent classifier mentioned previously.</p><p>Aggregation systems: We examine two systems that perform different types of value reconciliation. The first model (Confidence) chooses entity values with the highest confidence score assigned by the base extractor. The second system (Majority) takes a majority vote over all values extracted from these articles. Both methods filter new entity values using a threshold τ on the cosine similarity over the tf-idf representations of the source and new articles.</p><p>Meta-classifer: To demonstrate the importance of modeling the problem in the RL framework, we con- sider a meta-classifier baseline. The classifier oper- ates over the same input state space and produces the same set of reconciliation decisions {d} as the DQN. For training, we use the original source arti- cle for each event along with a related downloaded article to compute the state. If the downloaded ar- ticle has the correct value and the original one does not, we label it as a positive example for that entity class. If multiple such entity classes exist, we cre- ate several training instances with appropriate labels, and if none exist, we use the label corresponding to the reject all action. For each test event, the clas- sifier is used to provide decisions for all the down- loaded articles and the final extraction is performed by aggregating the value predictions using the Con- fidence-based scheme described above.</p><p>Oracle: Finally, we also have an ORACLE score which is computed assuming perfect reconciliation and querying decisions on top of the Maxent base extractor. This helps us analyze the contribution of the RL system in isolation of the inherent limitations of the base extractor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RL models</head><p>We perform experiments using three variants of RL agents -(1) RL-Basic, which per- forms only reconciliation decisions 13 , (2) RL-Query, which takes only query decisions with the reconcil- iation strategy fixed (similar to <ref type="bibr" target="#b8">Kanani and McCallum (2012)</ref>), and (3) RL-Extract, our full system in- corporating both reconciliation and query decisions.</p><p>We train the models for 10000 steps every epoch using the Maxent classifier as the base extractor, and evaluate on the entire test set every epoch. The final accuracies reported are averaged over 3 independent runs; each run's score is averaged over 20 epochs af- ter 100 epochs of training. The penalty per step is set to -0.001. For the DQN, we use the dev set to tune all parameters. We used a replay memory D of size 500k, and a discount (γ) of 0.8. We set the learn- ing rate to 2.5E −5 . The in -greedy exploration is annealed from 1 to 0.1 over 500k transitions. The target-Q network is updated every 5k steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Performance <ref type="table" target="#tab_5">Table 3</ref> demonstrates that our sys- tem (RL-Extract) obtains a substantial gain in ac- curacy over the basic extractors on all entity types over both domains. For instance, RL-Extract is 11.4% more accurate than the basic Maxent extrac- tor on City and 7.1% better on NumKilled, while also achieving gains of more than 5% on the other entities on the Shootings domain. The gains on the Adulteration dataset are also significant, up to a 11.5% increase on the Location entity.</p><p>We can also observe that simple aggregation schemes like the Confidence and Majority base- lines don't handle the complexity of the task well. RL-Extract outperforms these by 7.2% on Shoot- ings and 5% on Adulteration averaged over all enti- ties. Further, the importance of sequential decision- making is established by RL-Extract performing sig- nificantly better than the meta-classifier (7.0% on Shootings over all entities). This is also due to the fact that the meta-classifier aggregates over the en- tire set of extra documents, including the long tail of noisy, irrelevant documents. Finally, we see the ad- vantage of enabling the RL system to select queries as our full model RL-Extract obtains significant im- 45.2 (0.6) 70.3 (0.6) 72.3 (0.6) 55.8 (0.6) 56.0 (0.8) 54.0 (0.8) 69.2 (0.6) Majority Agg. (τ )</p><p>47.6 (0.6) 69.1 (0.9) 68.6 (0.9) 54.7 (0.7) 56.7 (0.5) 50.6 (0.95) 72.0 (0.    provements over RL-Basic on both domains. The full model also outperforms RL-Query, demonstrat- ing the importance of performing both query selec- tion and reconciliation in a joint fashion. <ref type="figure" target="#fig_6">Figure 4</ref> shows the learning curve of the agent by measuring reward on the test set after each training epoch. The reward improves gradually and the ac- curacy on each entity increases simultaneously. Ta- ble 4 provides some examples where our model is able to extract the right values when the baseline fails. One can see that in most cases this is due to the model making use of articles with prototypical language or articles containing the entities in readily extractable form.</p><p>Analysis We also analyze the importance of dif- ferent reconciliation schemes, rewards and context- vectors in RL-Extract on the Shootings domain (Ta- ble 5). In addition to simple replacement (Re- Step 50.0 77.6 74.6 65.6 9.4 place), we also experiment with using Confidence and Majority-based reconciliation schemes for RL- Extract. We observe that the Replace scheme per- forms much better than the others (2-6% on all enti- ties) and believe this is because it provides the agent with more flexibility in choosing the final values.</p><p>From the same table, we see that using the tf- idf counts of context words as part of the state pro- vides better performance than using no context or using simple unigram counts. In terms of reward structure, providing rewards after each step is em- pirically found to be significantly better (&gt;10% on average) compared to a single delayed reward per episode. The last column shows the average number of steps per episode -the values range from 6.8 to 10.0 steps for the different schemes. The best sys- tem (RL-Extract with Replace, tf-idf and step-based rewards) uses 9.4 steps per episode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper, we explore the task of acquiring and incorporating external evidence to improve informa- tion extraction accuracy for domains with limited access to training data. This process comprises is- suing search queries, extraction from new sources and reconciliation of extracted values, repeated until sufficient evidence is obtained. We use a reinforce- ment learning framework and learn optimal action sequences to maximize extraction accuracy while penalizing extra effort. We show that our model, trained as a deep Q-network, outperforms traditional extractors by 7.2% and 5% on average on two differ- ent domains, respectively. We also demonstrate the importance of sequential decision-making by com- paring our model to a meta-classifier operating on the same space, obtaining up to a 7% gain.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Sample news article on a shooting case. Note how the article contains both the name of the shooter and the number of people killed but both pieces of information require complex extraction schemes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Two other articles on the same shooting case. The first article clearly mentions that six people were killed. The second one portrays the shooter in an easily extractable form.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>States</head><label></label><figDesc>The state s in our MDP consists of the ex- tractor's confidence in predicted entity values, the context from which the values are extracted and the similarity between the new document and the origi- nal one. We represent the state as a continuous real- valued vector (Figure 3) incorporating these pieces of information: 1. Confidence scores of current and newly extracted entity values. 2. One-hot encoding of matches between current and new values. 3. Unigram/tf-idf counts 2 of context words. These are words that occur in the neighborhood of the entity values in a document (e.g. the words which, left, people and wounded in the phrase "which left 5 people wounded"). 4. tf-idf similarity between the original article and the new article.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Left: Illustration of a transition in the MDP-the top box in each state shows the current entities and the bottom one consists of the new entities extracted from a downloaded article on the same event. Right: Sample state representation (bottom) in the MDP based on current and new values of entities (top). currentConf : confidence scores of current entities, newConf : confidence scores of new entities, contextWords: tf-idf counts of context words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>title title + (police | identified | arrested | charged) title + (killed | shooting | injured | dead | people) title + (injured | wounded | victim) title + (city | county | area)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>4: Download articles with query T q (x i ) 5: Queue retrieved articles in Y q i 6: for epoch = 1, M do 7: for i = 1, |X| do //episode 8: Extract entities e 0 from x i 9: e cur ← e 0 10: q ← 0, r ← 0 //query type, reward 11: while Y q i not empty do 12: Pop next article y from Y q i 13: Extract entities e new from y 14: Compute tf-idf similarity Z(x i , y) 15: Compute context vector C(y) 16: Form state s using e cur , e new , Z(x i , y) and C(y) 17: Send (s, r) to agent 18:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Evolution of average reward (solid black) and accuracy on various entities (dashed lines; red=ShooterName, magenta=NumKilled, blue=NumWounded, green=City) on the test set of the Shootings domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>select Reconcile Q extract search ShooterName Scott Westerhuis NumKilled 4 NumWounded 2 City Platte ShooterName Scott Westerhuis NumKilled 6 NumWounded 0 City Platte query ShooterName Scott Westerhuis NumKilled 6 NumWounded 2 City Platte ShooterName Scott Westerhuis NumKilled 5 NumWounded 0</head><label></label><figDesc></figDesc><table>City 
S.D. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples of different query templates for web 
search for articles on mass shootings. The | symbol repre-
sents logical OR. The last 4 queries contain context words 
around values for entity types ShooterName, NumKilled, 
NumWounded and City, respectively. At query time, 
title is replaced by the source article's title. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>). Following Mnih et al. (2015), we make use of a (separate) target Q- network to calculate the expected Q-value, in order Algorithm 2 Training Procedure for DQN agent with</figDesc><table>-greedy exploration 
1: Initialize experience memory D 
2: Initialize parameters θ randomly 
3: for episode = 1, M do 

4: 

Initialize environment and get start state s 1 

5: 

for t = 1, N do 

6: 

if random() &lt; then 

7: 

Select a random action a t 

8: 

else 

9: 

Compute Q(s t , a) for all actions a 

10: 

Select a t = argmax Q(s t , a) 

11: 

Execute action a t and observe reward r t and 
new state s t+1 

12: 

Store transition (s t , a t , r t , s t+1 ) in D 

13: 

Sample random mini batch of transitions 
(s j , a j , r j , s j+1 ) from D 

14: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Accuracy of various baselines (italics), our system (DQN) and the Oracle on Shootings and Adulteration 
datasets. Agg. refers to aggregation baselines. Bold indicates best system scores.  *  statistical significance of p &lt; 
0.0005 vs basic Maxent extractor using the Student-t test. Numbers in parentheses indicate the optimal threshold (τ ) 
for the aggregation baselines. Confidence-based reconciliation was used for RL-Query. 

Entity 
System: Value 
Example 

ShooterName 
Basic: Stewart 
A source tells Channel 2 Action News that Thomas Lee has been arrested in 
Mississippi ... Sgt . Stewart Smith, with the Troup County Sheriff's office, said. 
RL-Extract: Lee 
Lee is accused of killing his wife, Christie; ... 

NumKilled 
Basic: 0 
Shooting leaves 25 year old Pittsfield man dead , 4 injured 

RL-Extract: 1 
One man is dead after a shooting Saturday night at the intersection of Dewey 
Avenue and Linden Street. 

NumWounded 
Basic: 0 
Three people are dead and a fourth is in the hospital after a murder suicide 
RL-Extract: 1 
3 dead, 1 injured in possible Fla. murder-suicide 

City 
Basic: Englewood 
A 2 year old girl and four other people were wounded in a shooting in West 
Englewood Thursday night, police said 

RL-Extract: Chicago 
At least 14 people were shot across Chicago between noon and 10:30 p.m. 
Thursday. The last shooting left five people wounded. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Sample outputs (along with corresponding article snippets) on the Shootings domain showing correct predic-
tions from RL-Extract where the basic extractor (Maxent) fails. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Effect of using different reconciliation schemes, context-vectors, and rewards in our RL framework (Shoot-
ings domain). The last row is the overall best scheme (deviations from this are in italics). Context refers to the 
type of word counts used in the state vector to represent entity context. Rewards are either per step or per episode. 
(S: ShooterName, K: NumKilled, W: NumWounded, C: City, Steps: Average number of steps per episode) 

</table></figure>

			<note place="foot" n="2"> Counts are computed on the documents used to train the basic extraction system.</note>

			<note place="foot" n="3"> No entity-specific features are used for action selection. 4 We also experiment with other forms of value reconciliation. See Section 5 for details.</note>

			<note place="foot" n="5"> Stop words, numeric terms and proper nouns are filtered. 6 We use k=20 in our experiments.</note>

			<note place="foot" n="7"> We did not observe significant differences with additional linear layers or the choice of non-linearity (Sigmoid/ReLU).</note>

			<note place="foot" n="8"> The expectation is over the transitions sampled uniformly at random from D. 9 www.shootingtracker.com/Main_Page</note>

			<note place="foot" n="10"> www.foodshield.org/member/login/ 11 www.bing.com/toolbox/bingsearchapi 12 We normalize numerical words (e.g. &quot;one&quot; to &quot;1&quot;) before taking the mode.</note>

			<note place="foot" n="13"> Articles are presented to the agent in a round-robin fashion from the different query lists.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank David Alvarez, Tao Lei and Ramya Ra-makrishnan for helpful discussions and feedback, and the members of the MIT NLP group and the anonymous reviewers for their insightful comments. We also gratefully acknowledge support from a Google faculty award. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<title level="m">of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="477" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Open information extraction: The second generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janara</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename><surname>Mausam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Incorporating vector space similarity in random walk inference over knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar,</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="397" to="406" />
		</imprint>
	</monogr>
	<note>October. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Traversing knowledge graphs in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="318" to="327" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Collective entity linking in web text: a graph-based method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval</title>
		<meeting>the 34th international ACM SIGIR conference on Research and development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="765" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.04636</idno>
		<title level="m">Deep reinforcement learning with an action space defined by natural language</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Knowledge base population: Successful approaches and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1148" to="1158" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Selecting actions for resource-bounded information extraction using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pallika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew K</forename><surname>Kanani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM international conference on Web search and data mining</title>
		<meeting>the fifth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint entity and event coreference resolution across documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-field information extraction and cross-document fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gideon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd annual meeting on association for computational linguistics</title>
		<meeting>the 43rd annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="483" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stig</forename><surname>Petersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Charles Beattie, Amir Sadik, Ioannis Antonoglou</title>
		<meeting><address><addrLine>Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
	<note>and Demis Hassabis</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Language understanding for text-based games using deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tejas</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Compositional vector space models for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="156" to="166" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A simple distant supervision approach for the tac-kbp slot filling task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><forename type="middle">I</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Text Analysis Conference 2010 Workshop</title>
		<meeting>Text Analysis Conference 2010 Workshop</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Introduction to reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew G</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tijmen</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COURSERA: Neural Networks for Machine Learning</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Qlearning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jch</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="279" to="292" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Knowledge base completion via search-based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on World wide web</title>
		<meeting>the 23rd international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="515" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Open information extraction using wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel S Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th</title>
		<meeting>the 48th</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="118" to="127" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6575</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
